{
  "filename": "7965-unsupervised-cross-modal-alignment-of-speech-and-text-embedding-spaces.pdf",
  "metadata": {
    "title": "Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces",
    "author": "Yu-An Chung, Wei-Hung Weng, Schrasing Tong, James Glass",
    "date": 2018,
    "journal": "Conference on Neural Information Processing Systems",
    "abstract": "Recent research has shown that word embedding spaces learned from text corpora of different languages can be aligned without any parallel data supervision. Inspired by the success in unsupervised cross-lingual word embeddings, in this paper we target learning a cross-modal alignment between the embedding spaces of speech and text learned from corpora of their respective modalities in an unsupervised fashion. The proposed framework learns the individual speech and text embedding spaces, and attempts to align the two spaces via adversarial training, followed by a refinement procedure. We show how our framework could be used to perform spoken word classification and translation, and the experimental results on these two tasks demonstrate that the performance of our unsupervised alignment approach is comparable to its supervised counterpart. Our framework is especially useful for developing automatic speech recognition (ASR) and speech-to-text translation systems for lowor zero-resource languages, which have little parallel audio-text data for training modern supervised ASR and speech-to-text translation models, but account for the majority of the languages spoken across the world."
  },
  "keywords": [
    {
      "term": "ICLR",
      "url": "https://en.wikipedia.org/wiki/ICLR"
    },
    {
      "term": "word embedding",
      "url": "https://en.wikipedia.org/wiki/word_embedding"
    },
    {
      "term": "neural machine translation",
      "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
    },
    {
      "term": "machine translation",
      "url": "https://en.wikipedia.org/wiki/machine_translation"
    },
    {
      "term": "NIPS",
      "url": "https://en.wikipedia.org/wiki/NIPS"
    },
    {
      "term": "Recurrent Neural Network",
      "url": "https://en.wikipedia.org/wiki/Recurrent_Neural_Network"
    },
    {
      "term": "EMNLP",
      "url": "https://en.wikipedia.org/wiki/EMNLP"
    },
    {
      "term": "automatic speech recognition",
      "url": "https://en.wikipedia.org/wiki/automatic_speech_recognition"
    },
    {
      "term": "stochastic gradient descent",
      "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
    },
    {
      "term": "ICASSP",
      "url": "https://en.wikipedia.org/wiki/ICASSP"
    },
    {
      "term": "speech recognition",
      "url": "https://en.wikipedia.org/wiki/speech_recognition"
    },
    {
      "term": "word vector",
      "url": "https://en.wikipedia.org/wiki/word_vector"
    },
    {
      "term": "continuous bag-of-words",
      "url": "https://en.wikipedia.org/wiki/continuous_bag-of-words"
    }
  ],
  "highlights": [
    "Word embeddings—continuous-valued vector representations of words—are almost ubiquitous in recent natural language processing research",
    "Exploiting word co-occurrence statistics in a text corpus leads to word vectors that reflect semantic similarities and dissimilarities: similar words are geometrically close in the embedding space, and dissimilar words are far apart",
    "Recent research has shown that such cross-lingual alignments can be learned without relying on any form of bilingual supervision [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>], and has been applied to training neural machine translation (NMT) systems in a completely unsupervised fashion [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]",
    "In Section 4, we describe the tasks of spoken word classification and translation, which are similar to automatic speech recognition and speech-to-text translation, respectively, except that the input are audio segments corresponding to words",
    "The two tasks are similar to standard automatic speech recognition and speech-to-text translation, respectively, except that the input is an audio segment corresponding to a word.\n4.1",
    "We propose a framework capable of aligning speech and text embedding spaces in an unsupervised manner"
  ],
  "key_statements": [
    "Word embeddings—continuous-valued vector representations of words—are almost ubiquitous in recent natural language processing research",
    "Exploiting word co-occurrence statistics in a text corpus leads to word vectors that reflect semantic similarities and dissimilarities: similar words are geometrically close in the embedding space, and dissimilar words are far apart",
    "Recent research has shown that such cross-lingual alignments can be learned without relying on any form of bilingual supervision [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>], and has been applied to training neural machine translation (NMT) systems in a completely unsupervised fashion [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]",
    "In Section 4, we describe the tasks of spoken word classification and translation, which are similar to automatic speech recognition and speech-to-text translation, respectively, except that the input are audio segments corresponding to words",
    "Since a cross-modal alignment is learned to link the word embedding spaces of speech and text, we perform the tasks of spoken word classification and translation to directly evaluate the effectiveness of the alignment",
    "The two tasks are similar to standard automatic speech recognition and speech-to-text translation, respectively, except that the input is an audio segment corresponding to a word.\n4.1",
    "We propose a framework capable of aligning speech and text embedding spaces in an unsupervised manner"
  ],
  "summary": [
    "Word embeddings—continuous-valued vector representations of words—are almost ubiquitous in recent natural language processing research.",
    "The Speech2Vec [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>] model was developed to be capable of representing audio segments excised from a speech corpus as fixed dimensional vectors that contain semantic information of the underlying spoken words.",
    "In Section 4, we describe the tasks of spoken word classification and translation, which are similar to ASR and speech-to-text translation, respectively, except that the input are audio segments corresponding to words.",
    "By using the same training methodology (Skip-grams or CBOW) as Word2Vec, it is reasonable to assume that the embedding space learned by Speech2Vec from speech exhibits similar structure to that learned by Word2Vec from text.",
    "After training the Speech2Vec model, each audio segment is transformed into an embedding vector that contains the semantic information of the underlying word.",
    "The domain-adversarial training step learns a rotation matrix W that aligns the speech and text embedding spaces.",
    "Since a cross-modal alignment is learned to link the word embedding spaces of speech and text, we perform the tasks of spoken word classification and translation to directly evaluate the effectiveness of the alignment.",
    "The two tasks are similar to standard ASR and speech-to-text translation, respectively, except that the input is an audio segment corresponding to a word.",
    "The speech and text embedding spaces, denoted by S and T , can be obtained by training Speech2Vec and Word2Vec on the respective corpus.",
    "Alignment-Based Approaches Given the speech and text embeddings, alignment-based approaches learn the alignment between them in an either supervised or unsupervised way; for an input audio segment, they perform spoken word classification and translation as described in Section 4.",
    "In configuration A, the speech training data was segmented into words using forced alignment with respect to the reference transcription, and the embeddings of the same word were grouped together using their word identities.",
    "We implemented configuration A∗, which trained Speech2Vec in the same way as configuration A, but learned the alignment using a parallel dictionary as cross-modal data supervision.",
    "For alignment-based approaches, configuration A∗ achieves the highest accuracies under all corpora settings by using a parallel dictionary as cross-modal supervision for learning the alignment.",
    "The method learns the alignment from independent corpora of speech and text, without requiring any cross-modal supervision, which is especially important for lowor zeroresource languages that lack parallel data with both audio and text.",
    "We plan to extend current spoken word classification and translation systems to perform standard ASR and speech-to-text translation, respectively."
  ],
  "headline": "We show how our framework could be used to perform spoken word classification and translation, and the experimental results on these two tasks demonstrate that the performance of our unsupervised alignment approach is comparable to its supervised counterpart",
  "reference_links": [
    {
      "id": "1",
      "entry": "[1] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their compositionality,” in NIPS, 2013.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20T.%20Sutskever%2C%20I.%20Chen%2C%20K.%20Corrado%2C%20G.S.%20%E2%80%9CDistributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%2C%E2%80%9D%20in%20NIPS%202013"
    },
    {
      "id": "2",
      "entry": "[2] J. Pennington, R. Socher, and C. D. Manning, “GloVe: Global vectors for word representation,” in EMNLP, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20J.%20Socher%2C%20R.%20Manning%2C%20C.D.%20%E2%80%9CGloVe%3A%20Global%20vectors%20for%20word%20representation%2C%E2%80%9D%20in%20EMNLP%202014"
    },
    {
      "id": "3",
      "entry": "[3] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word vectors with subword information,” Transactions of the Association for Computational Linguistics, vol. 5, pp. 135–146, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojanowski%2C%20P.%20Grave%2C%20E.%20Joulin%2C%20A.%20Mikolov%2C%20T.%20Enriching%20word%20vectors%20with%20subword%20information%2C%202017",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Bojanowski%2C%20P.%20Grave%2C%20E.%20Joulin%2C%20A.%20Mikolov%2C%20T.%20Enriching%20word%20vectors%20with%20subword%20information%2C%202017"
    },
    {
      "id": "4",
      "entry": "[4] Z. S. Harris, “Distributional structure,” Word, vol. 10, no. 2-3, pp. 146–162, 1954.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Harris%2C%20Z.S.%20Distributional%20structure%2C%201954",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Harris%2C%20Z.S.%20Distributional%20structure%2C%201954"
    },
    {
      "id": "5",
      "entry": "[5] T. Mikolov, Q. Le, and I. Sutskever, “Exploiting similarities among languages for machine translation,” arXiv preprint arXiv:1309.4168, 2013.",
      "arxiv_url": "https://arxiv.org/pdf/1309.4168"
    },
    {
      "id": "6",
      "entry": "[6] M. Faruqui and C. Dyer, “Improving vector space word representations using multilingual correlation,” in EACL, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Faruqui%2C%20M.%20Dyer%2C%20C.%20%E2%80%9CImproving%20vector%20space%20word%20representations%20using%20multilingual%20correlation%2C%E2%80%9D%20in%20EACL%202014"
    },
    {
      "id": "7",
      "entry": "[7] C. Xing, D. Wang, C. Liu, and Y. Lin, “Normalized word embedding and orthogonal transform for bilingual word translation,” in NAACL HLT, 2015.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Xing%2C%20C.%20Wang%2C%20D.%20Liu%2C%20C.%20Lin%2C%20Y.%20Normalized%20word%20embedding%20and%20orthogonal%20transform%20for%20bilingual%20word%20translation%2C%202015",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Xing%2C%20C.%20Wang%2C%20D.%20Liu%2C%20C.%20Lin%2C%20Y.%20Normalized%20word%20embedding%20and%20orthogonal%20transform%20for%20bilingual%20word%20translation%2C%202015"
    },
    {
      "id": "8",
      "entry": "[8] M. Artetxe, G. Labaka, and E. Agirre, “Learning principled bilingual mappings of word embeddings while preserving monolingual invariance,” in EMNLP, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20M.%20Labaka%2C%20G.%20Agirre%2C%20E.%20%E2%80%9CLearning%20principled%20bilingual%20mappings%20of%20word%20embeddings%20while%20preserving%20monolingual%20invariance%2C%E2%80%9D%20in%20EMNLP%202016"
    },
    {
      "id": "9",
      "entry": "[9] S. L. Smith, D. Turban, S. Hamblin, and N. Hammerla, “Offline bilingual word vectors, orthogonal transformations and the inverted softmax,” in ICLR, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20S.L.%20Turban%2C%20D.%20Hamblin%2C%20S.%20Hammerla%2C%20N.%20%E2%80%9COffline%20bilingual%20word%20vectors%2C%20orthogonal%20transformations%20and%20the%20inverted%20softmax%2C%E2%80%9D%20in%20ICLR%202016"
    },
    {
      "id": "10",
      "entry": "[10] M. Artetxe, G. Labaka, and E. Agirre, “Learning bilingual word embeddings with (almost) no bilingual data,” in ACL, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20M.%20Labaka%2C%20G.%20Agirre%2C%20E.%20%E2%80%9CLearning%20bilingual%20word%20embeddings%20with%20%28almost%29%20no%20bilingual%20data%2C%E2%80%9D%20in%20ACL%202017"
    },
    {
      "id": "11",
      "entry": "[11] H. Cao, T. Zhao, S. Zhang, and Y. Meng, “A distribution-based model to learn bilingual word embeddings,” in COLING, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20H.%20Zhao%2C%20T.%20Zhang%2C%20S.%20Meng%2C%20Y.%20%E2%80%9CA%20distribution-based%20model%20to%20learn%20bilingual%20word%20embeddings%2C%E2%80%9D%20in%20COLING%202016"
    },
    {
      "id": "12",
      "entry": "[12] L. Duong, H. Kanayama, T. Ma, S. Bird, and T. Cohn, “Learning crosslingual word embeddings without bilingual corpora,” in EMNLP, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Duong%2C%20L.%20Kanayama%2C%20H.%20Ma%2C%20T.%20Bird%2C%20S.%20%E2%80%9CLearning%20crosslingual%20word%20embeddings%20without%20bilingual%20corpora%2C%E2%80%9D%20in%20EMNLP%202016"
    },
    {
      "id": "13",
      "entry": "[13] M. Zhang, Y. Liu, H. Luan, and M. Sun, “Adversarial training for unsupervised bilingual lexicon induction,” in ACL, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20M.%20Liu%2C%20Y.%20Luan%2C%20H.%20Sun%2C%20M.%20%E2%80%9CAdversarial%20training%20for%20unsupervised%20bilingual%20lexicon%20induction%2C%E2%80%9D%20in%20ACL%202017"
    },
    {
      "id": "14",
      "entry": "[14] A. Conneau, G. Lample, M. Ranzato, L. Denoyer, and H. Jégou, “Word translation without parallel data,” in ICLR, 2018.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Conneau%2C%20A.%20Lample%2C%20G.%20Ranzato%2C%20M.%20Denoyer%2C%20L.%20%E2%80%9CWord%20translation%20without%20parallel%20data%2C%E2%80%9D%20in%20ICLR%202018"
    },
    {
      "id": "15",
      "entry": "[15] M. Zhang, Y. Liu, H. Luan, and M. Sun, “Earth mover’s distance minimization for unsupervised bilingual lexicon induction,” in EMNLP, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20M.%20Liu%2C%20Y.%20Luan%2C%20H.%20Sun%2C%20M.%20%E2%80%9CEarth%20mover%E2%80%99s%20distance%20minimization%20for%20unsupervised%20bilingual%20lexicon%20induction%2C%E2%80%9D%20in%20EMNLP%202017"
    },
    {
      "id": "16",
      "entry": "[16] M. Artetxe, G. Labaka, E. Agirre, and K. Cho, “Unsupervised neural machine translation,” in ICLR, 2018.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20M.%20Labaka%2C%20G.%20Agirre%2C%20E.%20Cho%2C%20K.%20%E2%80%9CUnsupervised%20neural%20machine%20translation%2C%E2%80%9D%20in%20ICLR%202018"
    },
    {
      "id": "17",
      "entry": "[17] G. Lample, L. Denoyer, and M. Ranzato, “Unsupervised machine translation using monolingual corpora only,” in ICLR, 2018.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20G.%20Denoyer%2C%20L.%20Ranzato%2C%20M.%20%E2%80%9CUnsupervised%20machine%20translation%20using%20monolingual%20corpora%20only%2C%E2%80%9D%20in%20ICLR%202018"
    },
    {
      "id": "18",
      "entry": "[18] W. He, W. Wang, and K. Livescu, “Multi-view recurrent neural acoustic word embeddings,” in ICLR, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20W.%20Wang%2C%20W.%20Livescu%2C%20K.%20%E2%80%9CMulti-view%20recurrent%20neural%20acoustic%20word%20embeddings%2C%E2%80%9D%20in%20ICLR%202017"
    },
    {
      "id": "19",
      "entry": "[19] S. Settle and K. Livescu, “Discriminative acoustic word embeddings: Recurrent neural networkbased approaches,” in SLT, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Settle%2C%20S.%20Livescu%2C%20K.%20Discriminative%20acoustic%20word%20embeddings%3A%20Recurrent%20neural%20networkbased%20approaches%2C%202016",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Settle%2C%20S.%20Livescu%2C%20K.%20Discriminative%20acoustic%20word%20embeddings%3A%20Recurrent%20neural%20networkbased%20approaches%2C%202016"
    },
    {
      "id": "20",
      "entry": "[20] Y.-A. Chung, C.-C. Wu, C.-H. Shen, H.-Y. Lee, and L.-S. Lee, “Audio word2vec: Unsupervised learning of audio segment representations using sequence-to-sequence autoencoder,” in INTERSPEECH, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Y.-A.%20Wu%2C%20C.-C.%20Shen%2C%20C.-H.%20Lee%2C%20H.-Y.%20%E2%80%9CAudio%20word2vec%3A%20Unsupervised%20learning%20of%20audio%20segment%20representations%20using%20sequence-to-sequence%20autoencoder%2C%E2%80%9D%20in%20INTERSPEECH%202016"
    },
    {
      "id": "21",
      "entry": "[21] H. Kamper, W. Wang, and K. Livescu, “Deep convolutional acoustic word embeddings using word-pair side information,” in ICASSP, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Wang%2C%20W.%20Livescu%2C%20K.%20%E2%80%9CDeep%20convolutional%20acoustic%20word%20embeddings%20using%20word-pair%20side%20information%2C%E2%80%9D%20in%20ICASSP%202016"
    },
    {
      "id": "22",
      "entry": "[22] S. Bengio and G. Heigold, “Word embeddings for speech recognition,” in INTERSPEECH, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20S.%20Heigold%2C%20G.%20Word%20embeddings%20for%20speech%20recognition%2C%202014",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20S.%20Heigold%2C%20G.%20Word%20embeddings%20for%20speech%20recognition%2C%202014"
    },
    {
      "id": "23",
      "entry": "[23] K. Levin, K. Henry, A. Jansen, and K. Livescu, “Fixed-dimensional acoustic embeddings of variable-length segments in low-resource settings,” in ASRU, 2013.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Levin%2C%20K.%20Henry%2C%20K.%20Jansen%2C%20A.%20Livescu%2C%20K.%20%E2%80%9CFixed-dimensional%20acoustic%20embeddings%20of%20variable-length%20segments%20in%20low-resource%20settings%2C%E2%80%9D%20in%20ASRU%202013"
    },
    {
      "id": "24",
      "entry": "[24] Y.-A. Chung and J. Glass, “Speech2vec: A sequence-to-sequence framework for learning word embeddings from speech,” in INTERSPEECH, 2018.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Y.-A.%20Glass%2C%20J.%20%E2%80%9CSpeech2vec%3A%20A%20sequence-to-sequence%20framework%20for%20learning%20word%20embeddings%20from%20speech%2C%E2%80%9D%20in%20INTERSPEECH%202018"
    },
    {
      "id": "25",
      "entry": "[25] I. Sutskever, O. Vinyals, and Q. Le, “Sequence to sequence learning with neural networks,” in NIPS, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20I.%20Vinyals%2C%20O.%20Le%2C%20Q.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%2C%202014",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20I.%20Vinyals%2C%20O.%20Le%2C%20Q.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%2C%202014"
    },
    {
      "id": "26",
      "entry": "[26] K. Cho, B. van Merriënboer, Ç. Gülçehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio, “Learning phrase representations using RNN encoder-decoder for statistical machine translation,” in EMNLP, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20K.%20van%20Merri%C3%ABnboer%2C%20B.%20G%C3%BCl%C3%A7ehre%2C%20%C3%87.%20Bahdanau%2C%20D.%20%E2%80%9CLearning%20phrase%20representations%20using%20RNN%20encoder-decoder%20for%20statistical%20machine%20translation%2C%E2%80%9D%20in%20EMNLP%202014"
    },
    {
      "id": "27",
      "entry": "[27] Y.-C. Chen, C.-H. Shen, S.-F. Huang, and H.-Y. Lee, “Towards unsupervised automatic speech recognition trained by unaligned speech and text only,” arXiv preprint arXiv:1803.10952, 2018.",
      "arxiv_url": "https://arxiv.org/pdf/1803.10952"
    },
    {
      "id": "28",
      "entry": "[28] Y.-A. Chung and J. Glass, “Learning word embeddings from speech,” in NIPS ML4Audio Workshop, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Y.-A.%20Glass%2C%20J.%20%E2%80%9CLearning%20word%20embeddings%20from%20speech%2C%E2%80%9D%20in%20NIPS%20ML4Audio%20Workshop%202017"
    },
    {
      "id": "29",
      "entry": "[29] A. Park and J. Glass, “Unsupervised pattern discovery in speech,” IEEE Transactions on Audio, Speech, and Language Processing, vol. 16, no. 1, pp. 186–197, 2008.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20A.%20Glass%2C%20J.%20Unsupervised%20pattern%20discovery%20in%20speech%2C%202008",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20A.%20Glass%2C%20J.%20Unsupervised%20pattern%20discovery%20in%20speech%2C%202008"
    },
    {
      "id": "30",
      "entry": "[30] A. Jansen and B. Van Durme, “Efficient spoken term discovery using randomized algorithms,” in ASRU, 2011.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Jansen%2C%20A.%20Durme%2C%20B.Van%20%E2%80%9CEfficient%20spoken%20term%20discovery%20using%20randomized%20algorithms%2C%E2%80%9D%20in%20ASRU%202011"
    },
    {
      "id": "31",
      "entry": "[31] H. Kamper, A. Jansen, and S. Goldwater, “Unsupervised word segmentation and lexicon discovery using acoustic word embeddings,” IEEE Transactions on Audio, Speech, and Language Processing, vol. 24, no. 4, pp. 669–679, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20Unsupervised%20word%20segmentation%20and%20lexicon%20discovery%20using%20acoustic%20word%20embeddings%2C%202016",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20Unsupervised%20word%20segmentation%20and%20lexicon%20discovery%20using%20acoustic%20word%20embeddings%2C%202016"
    },
    {
      "id": "32",
      "entry": "[32] C.-Y. Lee, T. J. O’Donnell, and J. Glass, “Unsupervised lexicon discovery from acoustic input,” Transactions of the Association for Computational Linguistics, vol. 3, pp. 389–403, 2015.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=C.-Y.%20Lee%2C%20T.%20J.%20O%E2%80%99Donnell%20Glass%2C%20J.%20Unsupervised%20lexicon%20discovery%20from%20acoustic%20input%2C%202015",
      "oa_query": "https://api.scholarcy.com/oa_version?query=C.-Y.%20Lee%2C%20T.%20J.%20O%E2%80%99Donnell%20Glass%2C%20J.%20Unsupervised%20lexicon%20discovery%20from%20acoustic%20input%2C%202015"
    },
    {
      "id": "33",
      "entry": "[33] M. Sun and H. Van hamme, “Joint training of non-negative tucker decomposition and discrete density hidden markov models,” Computer Speech and Language, vol. 27, no. 4, pp. 969–988, 2013.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20M.%20hamme%2C%20H.Van%20Joint%20training%20of%20non-negative%20tucker%20decomposition%20and%20discrete%20density%20hidden%20markov%20models%2C%202013",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20M.%20hamme%2C%20H.Van%20Joint%20training%20of%20non-negative%20tucker%20decomposition%20and%20discrete%20density%20hidden%20markov%20models%2C%202013"
    },
    {
      "id": "34",
      "entry": "[34] O. Walter, T. Korthals, R. Haeb-Umbach, and B. Raj, “A hierarchical system for word discovery exploiting dtw-based initialization,” in ASRU, 2013.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Walter%2C%20O.%20Korthals%2C%20T.%20Haeb-Umbach%2C%20R.%20Raj%2C%20B.%20%E2%80%9CA%20hierarchical%20system%20for%20word%20discovery%20exploiting%20dtw-based%20initialization%2C%E2%80%9D%20in%20ASRU%202013"
    },
    {
      "id": "35",
      "entry": "[35] H. Kamper, A. Jansen, and S. Goldwater, “A segmental framework for fully-unsupervised large-vocabulary speech recognition,” Computer Speech and Language, vol. 46, pp. 154–174, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20A%20segmental%20framework%20for%20fully-unsupervised%20large-vocabulary%20speech%20recognition%2C%202017",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20A%20segmental%20framework%20for%20fully-unsupervised%20large-vocabulary%20speech%20recognition%2C%202017"
    },
    {
      "id": "36",
      "entry": "[36] H. Kamper, K. Livescu, and S. Goldwater, “An embedded segmental k-means model for unsupervised segmentation and clustering of speech,” in ASRU, 2017.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Livescu%2C%20K.%20Goldwater%2C%20S.%20%E2%80%9CAn%20embedded%20segmental%20k-means%20model%20for%20unsupervised%20segmentation%20and%20clustering%20of%20speech%2C%E2%80%9D%20in%20ASRU%202017"
    },
    {
      "id": "37",
      "entry": "[37] O. Räsänen, G. Doyle, and M. C. Frank, “Unsupervised word discovery from speech using automatic segmentation into syllable-like units,” in INTERSPEECH, 2015.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=R%C3%A4s%C3%A4nen%2C%20O.%20Doyle%2C%20G.%20Frank%2C%20M.C.%20%E2%80%9CUnsupervised%20word%20discovery%20from%20speech%20using%20automatic%20segmentation%20into%20syllable-like%20units%2C%E2%80%9D%20in%20INTERSPEECH%202015"
    },
    {
      "id": "38",
      "entry": "[38] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in NIPS, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20%E2%80%9CGenerative%20adversarial%20nets%2C%E2%80%9D%20in%20NIPS%202014"
    },
    {
      "id": "39",
      "entry": "[39] G. Dinu, A. Lazaridou, and M. Baroni, “Improving zero-shot learning by mitigating the hubness problem,” in ICLR Workshop Track, 2015.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Dinu%2C%20G.%20Lazaridou%2C%20A.%20Baroni%2C%20M.%20Improving%20zero-shot%20learning%20by%20mitigating%20the%20hubness%20problem%2C%202015",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Dinu%2C%20G.%20Lazaridou%2C%20A.%20Baroni%2C%20M.%20Improving%20zero-shot%20learning%20by%20mitigating%20the%20hubness%20problem%2C%202015"
    },
    {
      "id": "40",
      "entry": "[40] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with deep recurrent neural networks,” in ICASSP, 2013.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Mohamed%2C%20A.-r%20Hinton%2C%20G.%20%E2%80%9CSpeech%20recognition%20with%20deep%20recurrent%20neural%20networks%2C%E2%80%9D%20in%20ICASSP%202013"
    },
    {
      "id": "41",
      "entry": "[41] A. Graves and N. Jaitly, “Towards end-to-end speech recognition with recurrent neural networks,” in ICML, 2014.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Jaitly%2C%20N.%20%E2%80%9CTowards%20end-to-end%20speech%20recognition%20with%20recurrent%20neural%20networks%2C%E2%80%9D%20in%20ICML%202014"
    },
    {
      "id": "42",
      "entry": "[42] J. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio, “Attention-based models for speech recognition,” in NIPS, 2015.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Chorowski%2C%20J.K.%20Bahdanau%2C%20D.%20Serdyuk%2C%20D.%20Cho%2C%20K.%20%E2%80%9CAttention-based%20models%20for%20speech%20recognition%2C%E2%80%9D%20in%20NIPS%202015"
    },
    {
      "id": "43",
      "entry": "[43] W. Chan, N. Jaitly, Q. Le, and O. Vinyals, “Listen, attend and spell: A neural network for large vocabulary conversational speech recognition,” in ICASSP, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Chan%2C%20W.%20Jaitly%2C%20N.%20Le%2C%20Q.%20Vinyals%2C%20O.%20%E2%80%9CListen%2C%20attend%20and%20spell%3A%20A%20neural%20network%20for%20large%20vocabulary%20conversational%20speech%20recognition%2C%E2%80%9D%20in%20ICASSP%202016"
    },
    {
      "id": "44",
      "entry": "[44] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen et al., “Deep speech 2: End-to-end speech recognition in english and mandarin,” in ICML, 2016.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Amodei%2C%20D.%20Ananthanarayanan%2C%20S.%20Anubhai%2C%20R.%20Bai%2C%20J.%20%E2%80%9CDeep%20speech%202%3A%20End-to-end%20speech%20recognition%20in%20english%20and%20mandarin%2C%E2%80%9D%20in%20ICML%202016"
    },
    {
      "id": "45",
      "entry": "[45] A. Waibel and C. Fugen, “Spoken language translation,” IEEE Signal Processing Magazine, vol. 3, no. 25, pp. 70–79, 2008.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Waibel%2C%20A.%20Fugen%2C%20C.%20Spoken%20language%20translation%2C%202008",
      "oa_query": "https://api.scholarcy.com/oa_version?query=Waibel%2C%20A.%20Fugen%2C%20C.%20Spoken%20language%20translation%2C%202008"
    },
    {
      "id": "46",
      "entry": "[46] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “LibriSpeech: An ASR corpus based on public domain audio books,” in ICASSP, 2015.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Panayotov%2C%20V.%20Chen%2C%20G.%20Povey%2C%20D.%20Khudanpur%2C%20S.%20%E2%80%9CLibriSpeech%3A%20An%20ASR%20corpus%20based%20on%20public%20domain%20audio%20books%2C%E2%80%9D%20in%20ICASSP%202015"
    },
    {
      "id": "47",
      "entry": "[47] A. Kocabiyikoglu, L. Besacier, and O. Kraif, “Augmenting Librispeech with French translations: A multimodal corpus for direct speech translation evaluation,” in LREC, 2018.",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=Kocabiyikoglu%2C%20A.%20Besacier%2C%20L.%20Kraif%2C%20O.%20%E2%80%9CAugmenting%20Librispeech%20with%20French%20translations%3A%20A%20multimodal%20corpus%20for%20direct%20speech%20translation%20evaluation%2C%E2%80%9D%20in%20LREC%202018"
    },
    {
      "id": "48",
      "entry": "[48] A. Köhn, F. Stegen, and T. Baumann, “Mining the spoken wikipedia for speech data and beyond,” in LREC, 2016. ",
      "scholar_url": "https://scholar.google.co.uk/scholar?q=K%C3%B6hn%2C%20A.%20Stegen%2C%20F.%20Baumann%2C%20T.%20%E2%80%9CMining%20the%20spoken%20wikipedia%20for%20speech%20data%20and%20beyond%2C%E2%80%9D%20in%20LREC%202016"
    }
  ]
}