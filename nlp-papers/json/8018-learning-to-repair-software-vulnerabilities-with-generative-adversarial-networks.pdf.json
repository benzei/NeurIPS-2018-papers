{
    "filename": "8018-learning-to-repair-software-vulnerabilities-with-generative-adversarial-networks.pdf",
    "metadata": {
        "title": "Learning to Repair Software Vulnerabilities with Generative Adversarial Networks",
        "author": "Jacob Harer, Onur Ozdemir, Tomo Lazovich, Christopher Reale, Rebecca Russell, Louis Kim, peter chin",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8018-learning-to-repair-software-vulnerabilities-with-generative-adversarial-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Motivated by the problem of automated repair of software vulnerabilities, we propose an adversarial learning approach that maps from one discrete source domain to another target domain without requiring paired labeled examples or source and target domains to be bijections. We demonstrate that the proposed adversarial learning approach is an effective technique for repairing software vulnerabilities, performing close to seq2seq approaches that require labeled pairs. The proposed Generative Adversarial Network approach is application-agnostic in that it can be applied to other problems similar to code repair, such as grammar correction or sentiment translation."
    },
    "keywords": [
        {
            "term": "software vulnerability",
            "url": "https://en.wikipedia.org/wiki/software_vulnerability"
        },
        {
            "term": "Context Free Grammar",
            "url": "https://en.wikipedia.org/wiki/Context_Free_Grammar"
        },
        {
            "term": "neural machine translation",
            "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
        },
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        },
        {
            "term": "Air Force Research Laboratory",
            "url": "https://en.wikipedia.org/wiki/Air_Force_Research_Laboratory"
        },
        {
            "term": "Common Weakness Enumeration",
            "url": "https://en.wikipedia.org/wiki/Common_Weakness_Enumeration"
        }
    ],
    "highlights": [
        "Security vulnerabilities in software programs pose serious risks to computer systems",
        "By far the most common method of training Neural Machine Translation systems is to use labeled pairs of examples to compare the likelihood of network output to a desired version, necessitating a one-to-one mapping between input and desired output data",
        "We address this problem by using a discriminator which operates directly on the expected outputs of the Neural Machine Translation system during training, which we thoroughly discuss in Section 3.2",
        "In addition to Generative Adversarial Networks training, we train our generator as an autoencoder on data sampled from correct sequences",
        "We have proposed a Generative Adversarial Networks based approach to train an Neural Machine Translation system for discrete domain mapping applications",
        "Key to our approach is the addition of two novel generator loss functions which enforce accurate domain mapping without needing multiple generators or domains to be bijective"
    ],
    "key_statements": [
        "Security vulnerabilities in software programs pose serious risks to computer systems",
        "By far the most common method of training Neural Machine Translation systems is to use labeled pairs of examples to compare the likelihood of network output to a desired version, necessitating a one-to-one mapping between input and desired output data",
        "We address this problem by using a discriminator which operates directly on the expected outputs of the Neural Machine Translation system during training, which we thoroughly discuss in Section 3.2",
        "In addition to Generative Adversarial Networks training, we train our generator as an autoencoder on data sampled from correct sequences",
        "We focus our experiments on datasets which contain paired examples. This enables us to meaningfully evaluate the performance of our approach, even though our Generative Adversarial Networks approach does not require pairs to train. These datasets allow us to train seq2seq networks and use their performance as an upper bound to our Generative Adversarial Networks based approach",
        "In order to assess our domain mapping approach and evaluate the usefulness of our self-regularizer loss functions defined in Section 3.3, we compute the percentage of sequences which have valid orderings but not necessarily valid domain mappings, which we refer to as \u2018Order Accuracy\u2019",
        "In order to have a dataset which is fair for both Generative Adversarial Networks and seq2seq training, we created paired data by taking each example of vulnerable code and sampling one of its repairs randomly",
        "We have proposed a Generative Adversarial Networks based approach to train an Neural Machine Translation system for discrete domain mapping applications",
        "Key to our approach is the addition of two novel generator loss functions which enforce accurate domain mapping without needing multiple generators or domains to be bijective"
    ],
    "summary": [
        "Security vulnerabilities in software programs pose serious risks to computer systems.",
        "By far the most common method of training NMT systems is to use labeled pairs of examples to compare the likelihood of network output to a desired version, necessitating a one-to-one mapping between input and desired output data.",
        "We would sample from st to generate a sequence and provide that to the discriminator along with the real data for training, but this sampling process is non-differentiable.",
        "Such a discriminator would not provide useful information for training the generator since it does not pay attention to the sequential dependencies between tokens.",
        "We sample a random set of data pairs, where x is a bad version of y, and compute Wasserstein loss values, LWGAN(D, G) as defined in (2), for two separate cases.",
        "As we observe in Figure 1a, the simpler network architecture (1-layer CNN in this case) with the original Wasserstein loss provides better separation, i.e., better signal, for training the generator.",
        "In addition to GAN training, we train our generator as an autoencoder on data sampled from correct sequences.",
        "These datasets allow us to train seq2seq networks and use their performance as an upper bound to our GAN based approach.",
        "We start our experiments by exploring two hand-curated datasets, namely sequences of sorted numbers and Context Free Grammar (CFG), which help highlight the benefits of our proposed GAN approach to address the domain mapping problem.",
        "In order to assess our domain mapping approach and evaluate the usefulness of our self-regularizer loss functions defined in Section 3.3, we compute the percentage of sequences which have valid orderings but not necessarily valid domain mappings, which we refer to as \u2018Order Accuracy\u2019.",
        "The results in Table 1 show that our proposed GAN approach is able to achieve high CFG accuracy, in terms of generating correct sequences that fit the CFG.",
        "In order to have a dataset which is fair for both GAN and seq2seq training, we created paired data by taking each example of vulnerable code and sampling one of its repairs randomly.",
        "We divided the data into two disjoint sets by placing either a vulnerable function or its candidate repairs into the training dataset with equal probability.",
        "As shown in Table 1, our proposed GAN approach achieves progressively better results when we add (a) curriculum training, and (b) either LAUTO or LFREQ regularization loss.",
        "We have proposed a GAN based approach to train an NMT system for discrete domain mapping applications.",
        "Even though we only apply our approach to the problem of source code correction, it is applicable to other sequence correction problems, such as Grammatical Error Correction or language sentiment translation, e.g., converting negative reviews into positive ones"
    ],
    "headline": "Motivated by the problem of automated repair of software vulnerabilities, we propose an adversarial learning approach that maps from one discrete source domain to another target domain without requiring paired labeled examples or source and target domains to be bijections",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] MITRE. Common vulnerabilities and exposures. cve.mitre.org.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M.I.T.R.E.%20Common%20vulnerabilities%20and%20exposures"
        },
        {
            "id": "2",
            "entry": "[2] T. D. LaToza, G. Venolia, and R. DeLine. Maintaining mental models: A study of developer work habits. International Conference on Software Engineering (ICSE), 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LaToza%2C%20T.D.%20Venolia%2C%20G.%20DeLine%2C%20R.%20Maintaining%20mental%20models%3A%20A%20study%20of%20developer%20work%20habits%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LaToza%2C%20T.D.%20Venolia%2C%20G.%20DeLine%2C%20R.%20Maintaining%20mental%20models%3A%20A%20study%20of%20developer%20work%20habits%202006"
        },
        {
            "id": "3",
            "entry": "[3] J. Ji, Q. Wang, K. Toutanova, Y. Gong, S. Truong, and J. Gao. A Nested Attention Neural Hybrid Model for Grammatical Error Correction. Annual Meeting of the Association for Computational Linguistics (ACL), pages 753\u2013762, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ji%2C%20J.%20Wang%2C%20Q.%20Toutanova%2C%20K.%20Gong%2C%20Y.%20A%20Nested%20Attention%20Neural%20Hybrid%20Model%20for%20Grammatical%20Error%20Correction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ji%2C%20J.%20Wang%2C%20Q.%20Toutanova%2C%20K.%20Gong%2C%20Y.%20A%20Nested%20Attention%20Neural%20Hybrid%20Model%20for%20Grammatical%20Error%20Correction%202017"
        },
        {
            "id": "4",
            "entry": "[4] Z. Yuan and T. Briscoe. Grammatical error correction using neural machine translation. North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yuan%2C%20Z.%20Briscoe%2C%20T.%20Grammatical%20error%20correction%20using%20neural%20machine%20translation.%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%202016"
        },
        {
            "id": "5",
            "entry": "[5] A. Schmaltz, Y. Kim, A. M. Rush, and S. M. Shieber. Adapting Sequence Models for Sentence Correction. Empirical Methods in Natural Language Processing (EMNLP), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmaltz%2C%20A.%20Kim%2C%20Y.%20Rush%2C%20A.M.%20Shieber%2C%20S.M.%20Adapting%20Sequence%20Models%20for%20Sentence%20Correction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmaltz%2C%20A.%20Kim%2C%20Y.%20Rush%2C%20A.M.%20Shieber%2C%20S.M.%20Adapting%20Sequence%20Models%20for%20Sentence%20Correction%202017"
        },
        {
            "id": "6",
            "entry": "[6] Z. Xie, A. Avati, N. Arivazhagan, D. Jurafsky, and A. Y. Ng. Neural Language Correction with Character-Based Attention. arXiv:1603.09727, March 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.09727"
        },
        {
            "id": "7",
            "entry": "[7] J. A. Harer, L. Y. Kim, R. L. Russell, O. Ozdemir, L. R. Kosta, A. Rangamani, L. H. Hamilton, G. I. Centeno, J. R. Key, P. M. Ellingwood, M. W. McConley, J. M. Opper, P. Chin, and T. Lazovich. Automated software vulnerability detection with machine learning. arXiv:1803.04497, February 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.04497"
        },
        {
            "id": "8",
            "entry": "[8] Fourth workshop on the llvm compiler infrastructure in hpc. LLVM-HPC, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Fourth%20workshop%20on%20the%20llvm%20compiler%20infrastructure%20in%20hpc%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Fourth%20workshop%20on%20the%20llvm%20compiler%20infrastructure%20in%20hpc%202017"
        },
        {
            "id": "9",
            "entry": "[9] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative Adversarial Networks. Neural Information Processing Systems (NIPS), June 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=I%20J%20Goodfellow%20J%20PougetAbadie%20M%20Mirza%20B%20Xu%20D%20WardeFarley%20S%20Ozair%20A%20Courville%20and%20Y%20Bengio%20Generative%20Adversarial%20Networks%20Neural%20Information%20Processing%20Systems%20NIPS%20June%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=I%20J%20Goodfellow%20J%20PougetAbadie%20M%20Mirza%20B%20Xu%20D%20WardeFarley%20S%20Ozair%20A%20Courville%20and%20Y%20Bengio%20Generative%20Adversarial%20Networks%20Neural%20Information%20Processing%20Systems%20NIPS%20June%202014"
        },
        {
            "id": "10",
            "entry": "[10] M. Monperrus. Automatic software repair: A bibliography. ACM Computing Surveys (CSUR), 51(1):17:1\u201317:24, January 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Monperrus%2C%20M.%20Automatic%20software%20repair%3A%20A%20bibliography%202018-01-24",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Monperrus%2C%20M.%20Automatic%20software%20repair%3A%20A%20bibliography%202018-01-24"
        },
        {
            "id": "11",
            "entry": "[11] X. B. D. Le, D. Lo, and C. Le Goues. History driven program repair. Software Analysis, Evolution, and Reengineering (SANER), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Le%2C%20X.B.D.%20Lo%2C%20D.%20C.%20Le%20Goues.%20History%20driven%20program%20repair%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Le%2C%20X.B.D.%20Lo%2C%20D.%20C.%20Le%20Goues.%20History%20driven%20program%20repair%202016"
        },
        {
            "id": "12",
            "entry": "[12] F. Long and M. Rinard. Automatic patch generation by learning correct code. Principles of Programming Languages (POPL), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20F.%20Rinard%2C%20M.%20Automatic%20patch%20generation%20by%20learning%20correct%20code%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20F.%20Rinard%2C%20M.%20Automatic%20patch%20generation%20by%20learning%20correct%20code%202016"
        },
        {
            "id": "13",
            "entry": "[13] Devlin, Jacob, Uesato, Jonathan, Singh, Rishabh, and Kohli, Pushmeet. Semantic Code Repair using Neuro-Symbolic Transformation Networks. arXiv:1710.11054, October 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.11054"
        },
        {
            "id": "14",
            "entry": "[14] R. Gupta, S. Pal, A. Kanade, and S. Shevade. Deepfix: Fixing common c language errors by deep learning. Association for the Advancement of Artifical Intelligence (AAAI), pages 1345\u20131351, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20R.%20Pal%2C%20S.%20Kanade%2C%20A.%20Shevade%2C%20S.%20Deepfix%3A%20Fixing%20common%20c%20language%20errors%20by%20deep%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20R.%20Pal%2C%20S.%20Kanade%2C%20A.%20Shevade%2C%20S.%20Deepfix%3A%20Fixing%20common%20c%20language%20errors%20by%20deep%20learning%202017"
        },
        {
            "id": "15",
            "entry": "[15] I. J. Goodfellow, O. Vinyals, and A. M. Saxe. Qualitatively characterizing neural network optimization problems. International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.J.%20Vinyals%2C%20O.%20Saxe%2C%20A.M.%20Qualitatively%20characterizing%20neural%20network%20optimization%20problems%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.J.%20Vinyals%2C%20O.%20Saxe%2C%20A.M.%20Qualitatively%20characterizing%20neural%20network%20optimization%20problems%202015"
        },
        {
            "id": "16",
            "entry": "[16] M. Arjovsky and L. Bottou. Towards Principled Methods for Training Generative Adversarial Networks. International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20M.%20Bottou%2C%20L.%20Towards%20Principled%20Methods%20for%20Training%20Generative%20Adversarial%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20M.%20Bottou%2C%20L.%20Towards%20Principled%20Methods%20for%20Training%20Generative%20Adversarial%20Networks%202017"
        },
        {
            "id": "17",
            "entry": "[17] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein Generative Adversarial Networks. International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20M.%20Chintala%2C%20S.%20Bottou%2C%20L.%20Wasserstein%20Generative%20Adversarial%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20M.%20Chintala%2C%20S.%20Bottou%2C%20L.%20Wasserstein%20Generative%20Adversarial%20Networks%202017"
        },
        {
            "id": "18",
            "entry": "[18] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. Neural Information Processing Systems (NIPS), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "19",
            "entry": "[19] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta, and A. A. Bharath. Generative adversarial networks: An overview. IEEE Signal Processing Magazine, 35(1):53\u201365, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Creswell%2C%20A.%20White%2C%20T.%20Dumoulin%2C%20V.%20Arulkumaran%2C%20K.%20Generative%20adversarial%20networks%3A%20An%20overview%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Creswell%2C%20A.%20White%2C%20T.%20Dumoulin%2C%20V.%20Arulkumaran%2C%20K.%20Generative%20adversarial%20networks%3A%20An%20overview%202018"
        },
        {
            "id": "20",
            "entry": "[20] A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20A.%20Metz%2C%20L.%20Chintala%2C%20S.%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20A.%20Metz%2C%20L.%20Chintala%2C%20S.%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "21",
            "entry": "[21] L. Yu, W. Zhang, J. Wang, and Y. Yu. SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. Association for the Advancement of Artifical Intelligence (AAAI), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20L.%20Zhang%2C%20W.%20Wang%2C%20J.%20Yu%2C%20Y.%20SeqGAN%3A%20Sequence%20Generative%20Adversarial%20Nets%20with%20Policy%20Gradient.%20Association%20for%20the%20Advancement%20of%20Artifical%20Intelligence%20%28AAAI%29%202017"
        },
        {
            "id": "22",
            "entry": "[22] Y. Zhang, Z. Gan, K. Fan, Z. Chen, R. Henao, D. Shen, and L. Carin. Adversarial Feature Matching for Text Generation. International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Y.%20Gan%2C%20Z.%20Fan%2C%20K.%20Chen%2C%20Z.%20Adversarial%20Feature%20Matching%20for%20Text%20Generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Y.%20Gan%2C%20Z.%20Fan%2C%20K.%20Chen%2C%20Z.%20Adversarial%20Feature%20Matching%20for%20Text%20Generation%202017"
        },
        {
            "id": "23",
            "entry": "[23] O. Press, A. Bar, B. Bogin, J. Berant, and L. Wolf. Language Generation with Recurrent Generative Adversarial Networks without Pre-training. 1st Workshop on Subword and Character Level Models in NLP (SCLeM), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Press%2C%20O.%20Bar%2C%20A.%20Bogin%2C%20B.%20Berant%2C%20J.%20Language%20Generation%20with%20Recurrent%20Generative%20Adversarial%20Networks%20without%20Pre-training.%201st%20Workshop%20on%20Subword%20and%20Character%20Level%20Models%20in%20NLP%20%28SCLeM%29%202017"
        },
        {
            "id": "24",
            "entry": "[24] S. Rajeswar, S. Subramanian, F. Dutil, C. Pal, and A. Courville. Adversarial Generation of Natural Language. 2nd Workshop on Representation Learning for NLP (RepL4NLP), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rajeswar%2C%20S.%20Subramanian%2C%20S.%20Dutil%2C%20F.%20Pal%2C%20C.%20Adversarial%20Generation%20of%20Natural%20Language.%202nd%20Workshop%20on%20Representation%20Learning%20for%20NLP%202017"
        },
        {
            "id": "25",
            "entry": "[25] M. Mirza and S. Osindero. Conditional Generative Adversarial Nets. arXiv:1411.1784, November 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "26",
            "entry": "[26] Z. Yang, W. Chen, F. Wang, and B. Xu. Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets. North American Chapter of the Association for Computational Linguistics (NAACL), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Z.%20Chen%2C%20W.%20Wang%2C%20F.%20Xu%2C%20B.%20Improving%20Neural%20Machine%20Translation%20with%20Conditional%20Sequence%20Generative%20Adversarial%20Nets%202018"
        },
        {
            "id": "27",
            "entry": "[27] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. International Conference on Computer Vision (ICCV), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20Image-to-Image%20Translation%20using%20Cycle-Consistent%20Adversarial%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20Image-to-Image%20Translation%20using%20Cycle-Consistent%20Adversarial%20Networks%202017"
        },
        {
            "id": "28",
            "entry": "[28] A. N. Gomez, S. Huang, I. Zhang, B. M. Li, M. Osama, and L. Kaiser. Unsupervised Cipher Cracking Using Discrete GANs. International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gomez%2C%20A.N.%20Huang%2C%20S.%20Zhang%2C%20I.%20Li%2C%20B.M.%20Unsupervised%20Cipher%20Cracking%20Using%20Discrete%20GANs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gomez%2C%20A.N.%20Huang%2C%20S.%20Zhang%2C%20I.%20Li%2C%20B.M.%20Unsupervised%20Cipher%20Cracking%20Using%20Discrete%20GANs%202018"
        },
        {
            "id": "29",
            "entry": "[29] G. Lample, L. Denoyer, and M. Ranzato. Unsupervised Machine Translation Using Monolingual Corpora Only. International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20G.%20Denoyer%2C%20L.%20Ranzato%2C%20M.%20Unsupervised%20Machine%20Translation%20Using%20Monolingual%20Corpora%20Only%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lample%2C%20G.%20Denoyer%2C%20L.%20Ranzato%2C%20M.%20Unsupervised%20Machine%20Translation%20Using%20Monolingual%20Corpora%20Only%202018"
        },
        {
            "id": "30",
            "entry": "[30] A. Shrivastava, T. Pfister, O. Tuzel, J. Susskind, W. Wang, and R. Webb. Learning from Simulated and Unsupervised Images through Adversarial Training. Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shrivastava%2C%20A.%20Pfister%2C%20T.%20Tuzel%2C%20O.%20Susskind%2C%20J.%20Learning%20from%20Simulated%20and%20Unsupervised%20Images%20through%20Adversarial%20Training%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shrivastava%2C%20A.%20Pfister%2C%20T.%20Tuzel%2C%20O.%20Susskind%2C%20J.%20Learning%20from%20Simulated%20and%20Unsupervised%20Images%20through%20Adversarial%20Training%202017"
        },
        {
            "id": "31",
            "entry": "[31] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville. Improved Training of Wasserstein GANs. Neural Information Processing Systems (NIPS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20I.%20Ahmed%2C%20F.%20Arjovsky%2C%20M.%20Dumoulin%2C%20V.%20Improved%20Training%20of%20Wasserstein%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20I.%20Ahmed%2C%20F.%20Arjovsky%2C%20M.%20Dumoulin%2C%20V.%20Improved%20Training%20of%20Wasserstein%20GANs%202017"
        },
        {
            "id": "32",
            "entry": "[32] E. Jang, S. Gu, and B. Poole. Categorical Reparameterization with Gumbel-Softmax. International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jang%2C%20E.%20Gu%2C%20S.%20Poole%2C%20B.%20Categorical%20Reparameterization%20with%20Gumbel-Softmax.%20International%20Conference%20on%20Learning%20Representations%20%28ICLR%29%202017"
        },
        {
            "id": "33",
            "entry": "[33] C. J. Maddison, A. Mnih, and Y. W. Teh. The Concrete Distribution - A Continuous Relaxation of Discrete Random Variables. International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maddison%2C%20C.J.%20Mnih%2C%20A.%20W%2C%20Y.%20Teh.%20The%20Concrete%20Distribution%20-%20A%20Continuous%20Relaxation%20of%20Discrete%20Random%20Variables%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maddison%2C%20C.J.%20Mnih%2C%20A.%20W%2C%20Y.%20Teh.%20The%20Concrete%20Distribution%20-%20A%20Continuous%20Relaxation%20of%20Discrete%20Random%20Variables%202017"
        },
        {
            "id": "34",
            "entry": "[34] M.-T. Luong, H. Pham, and C. D. Manning. Effective Approaches to Attentionbased Neural Machine Translation. Empirical Methods in Natural Language Processing (EMNLP), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=MT%20Luong%20H%20Pham%20and%20C%20D%20Manning%20Effective%20Approaches%20to%20Attentionbased%20Neural%20Machine%20Translation%20Empirical%20Methods%20in%20Natural%20Language%20Processing%20EMNLP%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=MT%20Luong%20H%20Pham%20and%20C%20D%20Manning%20Effective%20Approaches%20to%20Attentionbased%20Neural%20Machine%20Translation%20Empirical%20Methods%20in%20Natural%20Language%20Processing%20EMNLP%202015"
        },
        {
            "id": "35",
            "entry": "[35] S. Hochreiter and J. Schmidhuber. Long Short-term Memory. Neural Computation, 9(8):1735\u20131780, December 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20Short-term%20Memory%201997-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20Short-term%20Memory%201997-12"
        },
        {
            "id": "36",
            "entry": "[36] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol. Extracting and composing robust features with denoising autoencoders. International Conference on Machine Learning (ICML), 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vincent%2C%20P.%20Larochelle%2C%20H.%20Bengio%2C%20Y.%20Manzagol%2C%20P.-A.%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vincent%2C%20P.%20Larochelle%2C%20H.%20Bengio%2C%20Y.%20Manzagol%2C%20P.-A.%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders%202008"
        },
        {
            "id": "37",
            "entry": "[37] R. J. Williams and D. Zipser. A Learning Algorithm for Continually Running Fully Recurrent Neural Networks. Neural Computation, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20R.J.%20Zipser%2C%20D.%20A%20Learning%20Algorithm%20for%20Continually%20Running%20Fully%20Recurrent%20Neural%20Networks%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20R.J.%20Zipser%2C%20D.%20A%20Learning%20Algorithm%20for%20Continually%20Running%20Fully%20Recurrent%20Neural%20Networks%201989"
        },
        {
            "id": "38",
            "entry": "[38] V. Okun, A. Delaitre, and P. E. Black. Report on the Static Analysis Tool Exposition (SATE) IV. Technical report, 2013. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Okun%2C%20V.%20Delaitre%2C%20A.%20Black%2C%20P.E.%20Report%20on%20the%20Static%20Analysis%20Tool%20Exposition%20%28SATE%29%20IV%202013"
        }
    ]
}
