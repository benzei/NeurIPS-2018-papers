{
    "filename": "7965-unsupervised-cross-modal-alignment-of-speech-and-text-embedding-spaces.pdf",
    "metadata": {
        "title": "Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces",
        "author": "Yu-An Chung, Wei-Hung Weng, Schrasing Tong, James Glass",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7965-unsupervised-cross-modal-alignment-of-speech-and-text-embedding-spaces.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Recent research has shown that word embedding spaces learned from text corpora of different languages can be aligned without any parallel data supervision. Inspired by the success in unsupervised cross-lingual word embeddings, in this paper we target learning a cross-modal alignment between the embedding spaces of speech and text learned from corpora of their respective modalities in an unsupervised fashion. The proposed framework learns the individual speech and text embedding spaces, and attempts to align the two spaces via adversarial training, followed by a refinement procedure. We show how our framework could be used to perform spoken word classification and translation, and the experimental results on these two tasks demonstrate that the performance of our unsupervised alignment approach is comparable to its supervised counterpart. Our framework is especially useful for developing automatic speech recognition (ASR) and speech-to-text translation systems for lowor zero-resource languages, which have little parallel audio-text data for training modern supervised ASR and speech-to-text translation models, but account for the majority of the languages spoken across the world."
    },
    "keywords": [
        {
            "term": "continuous bag-of-words",
            "url": "https://en.wikipedia.org/wiki/continuous_bag-of-words"
        },
        {
            "term": "ICLR",
            "url": "https://en.wikipedia.org/wiki/ICLR"
        },
        {
            "term": "NIPS",
            "url": "https://en.wikipedia.org/wiki/NIPS"
        },
        {
            "term": "automatic speech recognition",
            "url": "https://en.wikipedia.org/wiki/automatic_speech_recognition"
        },
        {
            "term": "machine translation",
            "url": "https://en.wikipedia.org/wiki/machine_translation"
        },
        {
            "term": "EMNLP",
            "url": "https://en.wikipedia.org/wiki/EMNLP"
        },
        {
            "term": "Recurrent Neural Network",
            "url": "https://en.wikipedia.org/wiki/Recurrent_Neural_Network"
        },
        {
            "term": "word vector",
            "url": "https://en.wikipedia.org/wiki/word_vector"
        },
        {
            "term": "ICASSP",
            "url": "https://en.wikipedia.org/wiki/ICASSP"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "word embedding",
            "url": "https://en.wikipedia.org/wiki/word_embedding"
        },
        {
            "term": "neural machine translation",
            "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
        }
    ],
    "highlights": [
        "Word embeddings\u2014continuous-valued vector representations of words\u2014are almost ubiquitous in recent natural language processing research",
        "Exploiting word co-occurrence statistics in a text corpus leads to word vectors that reflect semantic similarities and dissimilarities: similar words are geometrically close in the embedding space, and dissimilar words are far apart",
        "Several studies have focused on designing algorithms that exploit this similarity to learn a cross-lingual alignment between the embedding spaces of two languages, where the two embedding spaces are trained from independent text corpora [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>]",
        "In Section 4, we describe the tasks of spoken word classification and translation, which are similar to automatic speech recognition and speech-to-text translation, respectively, except that the input are audio segments corresponding to words",
        "The two tasks are similar to standard automatic speech recognition and speech-to-text translation, respectively, except that the input is an audio segment corresponding to a word.\n4.1",
        "We propose a framework capable of aligning speech and text embedding spaces in an unsupervised manner"
    ],
    "key_statements": [
        "Word embeddings\u2014continuous-valued vector representations of words\u2014are almost ubiquitous in recent natural language processing research",
        "Exploiting word co-occurrence statistics in a text corpus leads to word vectors that reflect semantic similarities and dissimilarities: similar words are geometrically close in the embedding space, and dissimilar words are far apart",
        "Several studies have focused on designing algorithms that exploit this similarity to learn a cross-lingual alignment between the embedding spaces of two languages, where the two embedding spaces are trained from independent text corpora [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>]",
        "Recent research has shown that such cross-lingual alignments can be learned without relying on any form of bilingual supervision [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>], and has been applied to training neural machine translation (NMT) systems in a completely unsupervised fashion [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]",
        "In Section 4, we describe the tasks of spoken word classification and translation, which are similar to automatic speech recognition and speech-to-text translation, respectively, except that the input are audio segments corresponding to words",
        "Since a cross-modal alignment is learned to link the word embedding spaces of speech and text, we perform the tasks of spoken word classification and translation to directly evaluate the effectiveness of the alignment",
        "The two tasks are similar to standard automatic speech recognition and speech-to-text translation, respectively, except that the input is an audio segment corresponding to a word.\n4.1",
        "We propose a framework capable of aligning speech and text embedding spaces in an unsupervised manner"
    ],
    "summary": [
        "Word embeddings\u2014continuous-valued vector representations of words\u2014are almost ubiquitous in recent natural language processing research.",
        "The Speech2Vec [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>] model was developed to be capable of representing audio segments excised from a speech corpus as fixed dimensional vectors that contain semantic information of the underlying spoken words.",
        "In Section 4, we describe the tasks of spoken word classification and translation, which are similar to ASR and speech-to-text translation, respectively, except that the input are audio segments corresponding to words.",
        "By using the same training methodology (Skip-grams or CBOW) as Word2Vec, it is reasonable to assume that the embedding space learned by Speech2Vec from speech exhibits similar structure to that learned by Word2Vec from text.",
        "After training the Speech2Vec model, each audio segment is transformed into an embedding vector that contains the semantic information of the underlying word.",
        "The domain-adversarial training step learns a rotation matrix W that aligns the speech and text embedding spaces.",
        "Since a cross-modal alignment is learned to link the word embedding spaces of speech and text, we perform the tasks of spoken word classification and translation to directly evaluate the effectiveness of the alignment.",
        "The two tasks are similar to standard ASR and speech-to-text translation, respectively, except that the input is an audio segment corresponding to a word.",
        "The speech and text embedding spaces, denoted by S and T , can be obtained by training Speech2Vec and Word2Vec on the respective corpus.",
        "Alignment-Based Approaches Given the speech and text embeddings, alignment-based approaches learn the alignment between them in an either supervised or unsupervised way; for an input audio segment, they perform spoken word classification and translation as described in Section 4.",
        "In configuration A, the speech training data was segmented into words using forced alignment with respect to the reference transcription, and the embeddings of the same word were grouped together using their word identities.",
        "We implemented configuration A\u2217, which trained Speech2Vec in the same way as configuration A, but learned the alignment using a parallel dictionary as cross-modal data supervision.",
        "For alignment-based approaches, configuration A\u2217 achieves the highest accuracies under all corpora settings by using a parallel dictionary as cross-modal supervision for learning the alignment.",
        "The method learns the alignment from independent corpora of speech and text, without requiring any cross-modal supervision, which is especially important for lowor zeroresource languages that lack parallel data with both audio and text.",
        "We plan to extend current spoken word classification and translation systems to perform standard ASR and speech-to-text translation, respectively."
    ],
    "headline": "We show how our framework could be used to perform spoken word classification and translation, and the experimental results on these two tasks demonstrate that the performance of our unsupervised alignment approach is comparable to its supervised counterpart",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \u201cDistributed representations of words and phrases and their compositionality,\u201d in NIPS, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20T.%20Sutskever%2C%20I.%20Chen%2C%20K.%20Corrado%2C%20G.S.%20%E2%80%9CDistributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%2C%E2%80%9D%20in%20NIPS%202013"
        },
        {
            "id": "2",
            "entry": "[2] J. Pennington, R. Socher, and C. D. Manning, \u201cGloVe: Global vectors for word representation,\u201d in EMNLP, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20J.%20Socher%2C%20R.%20Manning%2C%20C.D.%20%E2%80%9CGloVe%3A%20Global%20vectors%20for%20word%20representation%2C%E2%80%9D%20in%20EMNLP%202014"
        },
        {
            "id": "3",
            "entry": "[3] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, \u201cEnriching word vectors with subword information,\u201d Transactions of the Association for Computational Linguistics, vol. 5, pp. 135\u2013146, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojanowski%2C%20P.%20Grave%2C%20E.%20Joulin%2C%20A.%20Mikolov%2C%20T.%20Enriching%20word%20vectors%20with%20subword%20information%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bojanowski%2C%20P.%20Grave%2C%20E.%20Joulin%2C%20A.%20Mikolov%2C%20T.%20Enriching%20word%20vectors%20with%20subword%20information%2C%202017"
        },
        {
            "id": "4",
            "entry": "[4] Z. S. Harris, \u201cDistributional structure,\u201d Word, vol. 10, no. 2-3, pp. 146\u2013162, 1954.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harris%2C%20Z.S.%20Distributional%20structure%2C%201954",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Harris%2C%20Z.S.%20Distributional%20structure%2C%201954"
        },
        {
            "id": "5",
            "entry": "[5] T. Mikolov, Q. Le, and I. Sutskever, \u201cExploiting similarities among languages for machine translation,\u201d arXiv preprint arXiv:1309.4168, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1309.4168"
        },
        {
            "id": "6",
            "entry": "[6] M. Faruqui and C. Dyer, \u201cImproving vector space word representations using multilingual correlation,\u201d in EACL, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Faruqui%2C%20M.%20Dyer%2C%20C.%20%E2%80%9CImproving%20vector%20space%20word%20representations%20using%20multilingual%20correlation%2C%E2%80%9D%20in%20EACL%202014"
        },
        {
            "id": "7",
            "entry": "[7] C. Xing, D. Wang, C. Liu, and Y. Lin, \u201cNormalized word embedding and orthogonal transform for bilingual word translation,\u201d in NAACL HLT, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xing%2C%20C.%20Wang%2C%20D.%20Liu%2C%20C.%20Lin%2C%20Y.%20Normalized%20word%20embedding%20and%20orthogonal%20transform%20for%20bilingual%20word%20translation%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xing%2C%20C.%20Wang%2C%20D.%20Liu%2C%20C.%20Lin%2C%20Y.%20Normalized%20word%20embedding%20and%20orthogonal%20transform%20for%20bilingual%20word%20translation%2C%202015"
        },
        {
            "id": "8",
            "entry": "[8] M. Artetxe, G. Labaka, and E. Agirre, \u201cLearning principled bilingual mappings of word embeddings while preserving monolingual invariance,\u201d in EMNLP, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20M.%20Labaka%2C%20G.%20Agirre%2C%20E.%20%E2%80%9CLearning%20principled%20bilingual%20mappings%20of%20word%20embeddings%20while%20preserving%20monolingual%20invariance%2C%E2%80%9D%20in%20EMNLP%202016"
        },
        {
            "id": "9",
            "entry": "[9] S. L. Smith, D. Turban, S. Hamblin, and N. Hammerla, \u201cOffline bilingual word vectors, orthogonal transformations and the inverted softmax,\u201d in ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20S.L.%20Turban%2C%20D.%20Hamblin%2C%20S.%20Hammerla%2C%20N.%20%E2%80%9COffline%20bilingual%20word%20vectors%2C%20orthogonal%20transformations%20and%20the%20inverted%20softmax%2C%E2%80%9D%20in%20ICLR%202016"
        },
        {
            "id": "10",
            "entry": "[10] M. Artetxe, G. Labaka, and E. Agirre, \u201cLearning bilingual word embeddings with (almost) no bilingual data,\u201d in ACL, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20M.%20Labaka%2C%20G.%20Agirre%2C%20E.%20%E2%80%9CLearning%20bilingual%20word%20embeddings%20with%20%28almost%29%20no%20bilingual%20data%2C%E2%80%9D%20in%20ACL%202017"
        },
        {
            "id": "11",
            "entry": "[11] H. Cao, T. Zhao, S. Zhang, and Y. Meng, \u201cA distribution-based model to learn bilingual word embeddings,\u201d in COLING, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20H.%20Zhao%2C%20T.%20Zhang%2C%20S.%20Meng%2C%20Y.%20%E2%80%9CA%20distribution-based%20model%20to%20learn%20bilingual%20word%20embeddings%2C%E2%80%9D%20in%20COLING%202016"
        },
        {
            "id": "12",
            "entry": "[12] L. Duong, H. Kanayama, T. Ma, S. Bird, and T. Cohn, \u201cLearning crosslingual word embeddings without bilingual corpora,\u201d in EMNLP, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duong%2C%20L.%20Kanayama%2C%20H.%20Ma%2C%20T.%20Bird%2C%20S.%20%E2%80%9CLearning%20crosslingual%20word%20embeddings%20without%20bilingual%20corpora%2C%E2%80%9D%20in%20EMNLP%202016"
        },
        {
            "id": "13",
            "entry": "[13] M. Zhang, Y. Liu, H. Luan, and M. Sun, \u201cAdversarial training for unsupervised bilingual lexicon induction,\u201d in ACL, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20M.%20Liu%2C%20Y.%20Luan%2C%20H.%20Sun%2C%20M.%20%E2%80%9CAdversarial%20training%20for%20unsupervised%20bilingual%20lexicon%20induction%2C%E2%80%9D%20in%20ACL%202017"
        },
        {
            "id": "14",
            "entry": "[14] A. Conneau, G. Lample, M. Ranzato, L. Denoyer, and H. J\u00e9gou, \u201cWord translation without parallel data,\u201d in ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Conneau%2C%20A.%20Lample%2C%20G.%20Ranzato%2C%20M.%20Denoyer%2C%20L.%20%E2%80%9CWord%20translation%20without%20parallel%20data%2C%E2%80%9D%20in%20ICLR%202018"
        },
        {
            "id": "15",
            "entry": "[15] M. Zhang, Y. Liu, H. Luan, and M. Sun, \u201cEarth mover\u2019s distance minimization for unsupervised bilingual lexicon induction,\u201d in EMNLP, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20M.%20Liu%2C%20Y.%20Luan%2C%20H.%20Sun%2C%20M.%20%E2%80%9CEarth%20mover%E2%80%99s%20distance%20minimization%20for%20unsupervised%20bilingual%20lexicon%20induction%2C%E2%80%9D%20in%20EMNLP%202017"
        },
        {
            "id": "16",
            "entry": "[16] M. Artetxe, G. Labaka, E. Agirre, and K. Cho, \u201cUnsupervised neural machine translation,\u201d in ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20M.%20Labaka%2C%20G.%20Agirre%2C%20E.%20Cho%2C%20K.%20%E2%80%9CUnsupervised%20neural%20machine%20translation%2C%E2%80%9D%20in%20ICLR%202018"
        },
        {
            "id": "17",
            "entry": "[17] G. Lample, L. Denoyer, and M. Ranzato, \u201cUnsupervised machine translation using monolingual corpora only,\u201d in ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20G.%20Denoyer%2C%20L.%20Ranzato%2C%20M.%20%E2%80%9CUnsupervised%20machine%20translation%20using%20monolingual%20corpora%20only%2C%E2%80%9D%20in%20ICLR%202018"
        },
        {
            "id": "18",
            "entry": "[18] W. He, W. Wang, and K. Livescu, \u201cMulti-view recurrent neural acoustic word embeddings,\u201d in ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20W.%20Wang%2C%20W.%20Livescu%2C%20K.%20%E2%80%9CMulti-view%20recurrent%20neural%20acoustic%20word%20embeddings%2C%E2%80%9D%20in%20ICLR%202017"
        },
        {
            "id": "19",
            "entry": "[19] S. Settle and K. Livescu, \u201cDiscriminative acoustic word embeddings: Recurrent neural networkbased approaches,\u201d in SLT, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Settle%2C%20S.%20Livescu%2C%20K.%20Discriminative%20acoustic%20word%20embeddings%3A%20Recurrent%20neural%20networkbased%20approaches%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Settle%2C%20S.%20Livescu%2C%20K.%20Discriminative%20acoustic%20word%20embeddings%3A%20Recurrent%20neural%20networkbased%20approaches%2C%202016"
        },
        {
            "id": "20",
            "entry": "[20] Y.-A. Chung, C.-C. Wu, C.-H. Shen, H.-Y. Lee, and L.-S. Lee, \u201cAudio word2vec: Unsupervised learning of audio segment representations using sequence-to-sequence autoencoder,\u201d in INTERSPEECH, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Y.-A.%20Wu%2C%20C.-C.%20Shen%2C%20C.-H.%20Lee%2C%20H.-Y.%20%E2%80%9CAudio%20word2vec%3A%20Unsupervised%20learning%20of%20audio%20segment%20representations%20using%20sequence-to-sequence%20autoencoder%2C%E2%80%9D%20in%20INTERSPEECH%202016"
        },
        {
            "id": "21",
            "entry": "[21] H. Kamper, W. Wang, and K. Livescu, \u201cDeep convolutional acoustic word embeddings using word-pair side information,\u201d in ICASSP, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Wang%2C%20W.%20Livescu%2C%20K.%20%E2%80%9CDeep%20convolutional%20acoustic%20word%20embeddings%20using%20word-pair%20side%20information%2C%E2%80%9D%20in%20ICASSP%202016"
        },
        {
            "id": "22",
            "entry": "[22] S. Bengio and G. Heigold, \u201cWord embeddings for speech recognition,\u201d in INTERSPEECH, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20S.%20Heigold%2C%20G.%20Word%20embeddings%20for%20speech%20recognition%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20S.%20Heigold%2C%20G.%20Word%20embeddings%20for%20speech%20recognition%2C%202014"
        },
        {
            "id": "23",
            "entry": "[23] K. Levin, K. Henry, A. Jansen, and K. Livescu, \u201cFixed-dimensional acoustic embeddings of variable-length segments in low-resource settings,\u201d in ASRU, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levin%2C%20K.%20Henry%2C%20K.%20Jansen%2C%20A.%20Livescu%2C%20K.%20%E2%80%9CFixed-dimensional%20acoustic%20embeddings%20of%20variable-length%20segments%20in%20low-resource%20settings%2C%E2%80%9D%20in%20ASRU%202013"
        },
        {
            "id": "24",
            "entry": "[24] Y.-A. Chung and J. Glass, \u201cSpeech2vec: A sequence-to-sequence framework for learning word embeddings from speech,\u201d in INTERSPEECH, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Y.-A.%20Glass%2C%20J.%20%E2%80%9CSpeech2vec%3A%20A%20sequence-to-sequence%20framework%20for%20learning%20word%20embeddings%20from%20speech%2C%E2%80%9D%20in%20INTERSPEECH%202018"
        },
        {
            "id": "25",
            "entry": "[25] I. Sutskever, O. Vinyals, and Q. Le, \u201cSequence to sequence learning with neural networks,\u201d in NIPS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20I.%20Vinyals%2C%20O.%20Le%2C%20Q.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20I.%20Vinyals%2C%20O.%20Le%2C%20Q.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%2C%202014"
        },
        {
            "id": "26",
            "entry": "[26] K. Cho, B. van Merri\u00ebnboer, \u00c7. G\u00fcl\u00e7ehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio, \u201cLearning phrase representations using RNN encoder-decoder for statistical machine translation,\u201d in EMNLP, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20K.%20van%20Merri%C3%ABnboer%2C%20B.%20G%C3%BCl%C3%A7ehre%2C%20%C3%87.%20Bahdanau%2C%20D.%20%E2%80%9CLearning%20phrase%20representations%20using%20RNN%20encoder-decoder%20for%20statistical%20machine%20translation%2C%E2%80%9D%20in%20EMNLP%202014"
        },
        {
            "id": "27",
            "entry": "[27] Y.-C. Chen, C.-H. Shen, S.-F. Huang, and H.-Y. Lee, \u201cTowards unsupervised automatic speech recognition trained by unaligned speech and text only,\u201d arXiv preprint arXiv:1803.10952, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.10952"
        },
        {
            "id": "28",
            "entry": "[28] Y.-A. Chung and J. Glass, \u201cLearning word embeddings from speech,\u201d in NIPS ML4Audio Workshop, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Y.-A.%20Glass%2C%20J.%20%E2%80%9CLearning%20word%20embeddings%20from%20speech%2C%E2%80%9D%20in%20NIPS%20ML4Audio%20Workshop%202017"
        },
        {
            "id": "29",
            "entry": "[29] A. Park and J. Glass, \u201cUnsupervised pattern discovery in speech,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 16, no. 1, pp. 186\u2013197, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20A.%20Glass%2C%20J.%20Unsupervised%20pattern%20discovery%20in%20speech%2C%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20A.%20Glass%2C%20J.%20Unsupervised%20pattern%20discovery%20in%20speech%2C%202008"
        },
        {
            "id": "30",
            "entry": "[30] A. Jansen and B. Van Durme, \u201cEfficient spoken term discovery using randomized algorithms,\u201d in ASRU, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jansen%2C%20A.%20Durme%2C%20B.Van%20%E2%80%9CEfficient%20spoken%20term%20discovery%20using%20randomized%20algorithms%2C%E2%80%9D%20in%20ASRU%202011"
        },
        {
            "id": "31",
            "entry": "[31] H. Kamper, A. Jansen, and S. Goldwater, \u201cUnsupervised word segmentation and lexicon discovery using acoustic word embeddings,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 24, no. 4, pp. 669\u2013679, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20Unsupervised%20word%20segmentation%20and%20lexicon%20discovery%20using%20acoustic%20word%20embeddings%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20Unsupervised%20word%20segmentation%20and%20lexicon%20discovery%20using%20acoustic%20word%20embeddings%2C%202016"
        },
        {
            "id": "32",
            "entry": "[32] C.-Y. Lee, T. J. O\u2019Donnell, and J. Glass, \u201cUnsupervised lexicon discovery from acoustic input,\u201d Transactions of the Association for Computational Linguistics, vol. 3, pp. 389\u2013403, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=C.-Y.%20Lee%2C%20T.%20J.%20O%E2%80%99Donnell%20Glass%2C%20J.%20Unsupervised%20lexicon%20discovery%20from%20acoustic%20input%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=C.-Y.%20Lee%2C%20T.%20J.%20O%E2%80%99Donnell%20Glass%2C%20J.%20Unsupervised%20lexicon%20discovery%20from%20acoustic%20input%2C%202015"
        },
        {
            "id": "33",
            "entry": "[33] M. Sun and H. Van hamme, \u201cJoint training of non-negative tucker decomposition and discrete density hidden markov models,\u201d Computer Speech and Language, vol. 27, no. 4, pp. 969\u2013988, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20M.%20hamme%2C%20H.Van%20Joint%20training%20of%20non-negative%20tucker%20decomposition%20and%20discrete%20density%20hidden%20markov%20models%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20M.%20hamme%2C%20H.Van%20Joint%20training%20of%20non-negative%20tucker%20decomposition%20and%20discrete%20density%20hidden%20markov%20models%2C%202013"
        },
        {
            "id": "34",
            "entry": "[34] O. Walter, T. Korthals, R. Haeb-Umbach, and B. Raj, \u201cA hierarchical system for word discovery exploiting dtw-based initialization,\u201d in ASRU, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Walter%2C%20O.%20Korthals%2C%20T.%20Haeb-Umbach%2C%20R.%20Raj%2C%20B.%20%E2%80%9CA%20hierarchical%20system%20for%20word%20discovery%20exploiting%20dtw-based%20initialization%2C%E2%80%9D%20in%20ASRU%202013"
        },
        {
            "id": "35",
            "entry": "[35] H. Kamper, A. Jansen, and S. Goldwater, \u201cA segmental framework for fully-unsupervised large-vocabulary speech recognition,\u201d Computer Speech and Language, vol. 46, pp. 154\u2013174, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20A%20segmental%20framework%20for%20fully-unsupervised%20large-vocabulary%20speech%20recognition%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamper%2C%20H.%20Jansen%2C%20A.%20Goldwater%2C%20S.%20A%20segmental%20framework%20for%20fully-unsupervised%20large-vocabulary%20speech%20recognition%2C%202017"
        },
        {
            "id": "36",
            "entry": "[36] H. Kamper, K. Livescu, and S. Goldwater, \u201cAn embedded segmental k-means model for unsupervised segmentation and clustering of speech,\u201d in ASRU, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamper%2C%20H.%20Livescu%2C%20K.%20Goldwater%2C%20S.%20%E2%80%9CAn%20embedded%20segmental%20k-means%20model%20for%20unsupervised%20segmentation%20and%20clustering%20of%20speech%2C%E2%80%9D%20in%20ASRU%202017"
        },
        {
            "id": "37",
            "entry": "[37] O. R\u00e4s\u00e4nen, G. Doyle, and M. C. Frank, \u201cUnsupervised word discovery from speech using automatic segmentation into syllable-like units,\u201d in INTERSPEECH, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=R%C3%A4s%C3%A4nen%2C%20O.%20Doyle%2C%20G.%20Frank%2C%20M.C.%20%E2%80%9CUnsupervised%20word%20discovery%20from%20speech%20using%20automatic%20segmentation%20into%20syllable-like%20units%2C%E2%80%9D%20in%20INTERSPEECH%202015"
        },
        {
            "id": "38",
            "entry": "[38] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u201cGenerative adversarial nets,\u201d in NIPS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20%E2%80%9CGenerative%20adversarial%20nets%2C%E2%80%9D%20in%20NIPS%202014"
        },
        {
            "id": "39",
            "entry": "[39] G. Dinu, A. Lazaridou, and M. Baroni, \u201cImproving zero-shot learning by mitigating the hubness problem,\u201d in ICLR Workshop Track, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dinu%2C%20G.%20Lazaridou%2C%20A.%20Baroni%2C%20M.%20Improving%20zero-shot%20learning%20by%20mitigating%20the%20hubness%20problem%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dinu%2C%20G.%20Lazaridou%2C%20A.%20Baroni%2C%20M.%20Improving%20zero-shot%20learning%20by%20mitigating%20the%20hubness%20problem%2C%202015"
        },
        {
            "id": "40",
            "entry": "[40] A. Graves, A.-r. Mohamed, and G. Hinton, \u201cSpeech recognition with deep recurrent neural networks,\u201d in ICASSP, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Mohamed%2C%20A.-r%20Hinton%2C%20G.%20%E2%80%9CSpeech%20recognition%20with%20deep%20recurrent%20neural%20networks%2C%E2%80%9D%20in%20ICASSP%202013"
        },
        {
            "id": "41",
            "entry": "[41] A. Graves and N. Jaitly, \u201cTowards end-to-end speech recognition with recurrent neural networks,\u201d in ICML, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Jaitly%2C%20N.%20%E2%80%9CTowards%20end-to-end%20speech%20recognition%20with%20recurrent%20neural%20networks%2C%E2%80%9D%20in%20ICML%202014"
        },
        {
            "id": "42",
            "entry": "[42] J. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio, \u201cAttention-based models for speech recognition,\u201d in NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chorowski%2C%20J.K.%20Bahdanau%2C%20D.%20Serdyuk%2C%20D.%20Cho%2C%20K.%20%E2%80%9CAttention-based%20models%20for%20speech%20recognition%2C%E2%80%9D%20in%20NIPS%202015"
        },
        {
            "id": "43",
            "entry": "[43] W. Chan, N. Jaitly, Q. Le, and O. Vinyals, \u201cListen, attend and spell: A neural network for large vocabulary conversational speech recognition,\u201d in ICASSP, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chan%2C%20W.%20Jaitly%2C%20N.%20Le%2C%20Q.%20Vinyals%2C%20O.%20%E2%80%9CListen%2C%20attend%20and%20spell%3A%20A%20neural%20network%20for%20large%20vocabulary%20conversational%20speech%20recognition%2C%E2%80%9D%20in%20ICASSP%202016"
        },
        {
            "id": "44",
            "entry": "[44] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen et al., \u201cDeep speech 2: End-to-end speech recognition in english and mandarin,\u201d in ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amodei%2C%20D.%20Ananthanarayanan%2C%20S.%20Anubhai%2C%20R.%20Bai%2C%20J.%20%E2%80%9CDeep%20speech%202%3A%20End-to-end%20speech%20recognition%20in%20english%20and%20mandarin%2C%E2%80%9D%20in%20ICML%202016"
        },
        {
            "id": "45",
            "entry": "[45] A. Waibel and C. Fugen, \u201cSpoken language translation,\u201d IEEE Signal Processing Magazine, vol. 3, no. 25, pp. 70\u201379, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Waibel%2C%20A.%20Fugen%2C%20C.%20Spoken%20language%20translation%2C%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Waibel%2C%20A.%20Fugen%2C%20C.%20Spoken%20language%20translation%2C%202008"
        },
        {
            "id": "46",
            "entry": "[46] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, \u201cLibriSpeech: An ASR corpus based on public domain audio books,\u201d in ICASSP, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Panayotov%2C%20V.%20Chen%2C%20G.%20Povey%2C%20D.%20Khudanpur%2C%20S.%20%E2%80%9CLibriSpeech%3A%20An%20ASR%20corpus%20based%20on%20public%20domain%20audio%20books%2C%E2%80%9D%20in%20ICASSP%202015"
        },
        {
            "id": "47",
            "entry": "[47] A. Kocabiyikoglu, L. Besacier, and O. Kraif, \u201cAugmenting Librispeech with French translations: A multimodal corpus for direct speech translation evaluation,\u201d in LREC, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kocabiyikoglu%2C%20A.%20Besacier%2C%20L.%20Kraif%2C%20O.%20%E2%80%9CAugmenting%20Librispeech%20with%20French%20translations%3A%20A%20multimodal%20corpus%20for%20direct%20speech%20translation%20evaluation%2C%E2%80%9D%20in%20LREC%202018"
        },
        {
            "id": "48",
            "entry": "[48] A. K\u00f6hn, F. Stegen, and T. Baumann, \u201cMining the spoken wikipedia for speech data and beyond,\u201d in LREC, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=K%C3%B6hn%2C%20A.%20Stegen%2C%20F.%20Baumann%2C%20T.%20%E2%80%9CMining%20the%20spoken%20wikipedia%20for%20speech%20data%20and%20beyond%2C%E2%80%9D%20in%20LREC%202016"
        }
    ]
}
