{
    "filename": "8246-using-trusted-data-to-train-deep-networks-on-labels-corrupted-by-severe-noise.pdf",
    "metadata": {
        "title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise",
        "author": "Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8246-using-trusted-data-to-train-deep-networks-on-labels-corrupted-by-severe-noise.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling, non-expert labeling, and label corruption by data poisoning adversaries. In the latter case, corruptions may be arbitrarily bad, even so bad that a classifier predicts the wrong labels with high confidence. To protect against such sources of noise, we leverage the fact that a small set of clean labels is often easy to procure. We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods."
    },
    "keywords": [
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "clean label",
            "url": "https://en.wikipedia.org/wiki/clean_label"
        },
        {
            "term": "supervised learning",
            "url": "https://en.wikipedia.org/wiki/supervised_learning"
        },
        {
            "term": "natural language processing",
            "url": "https://en.wikipedia.org/wiki/natural_language_processing"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "small set",
            "url": "https://en.wikipedia.org/wiki/small_set"
        }
    ],
    "highlights": [
        "Robustness to label noise is set to become an increasingly important property of supervised learning models",
        "To leverage the additional information from trusted labels, we propose a new loss correction and empirically verify it on a number of vision and natural language datasets with label corruption",
        "We have shown the impact of having a small set of trusted examples on label noise robustness in neural network classifiers",
        "We proposed the Gold Loss Correction (GLC), a method for coping with label noise",
        "This method leverages the assumption that the model has access to a small set of correct labels in order to yield accurate estimates of the noise distribution",
        "The Gold Loss Correction surpasses previous label noise robustness methods across various natural language processing and vision domains which we showed by considering several corruptions and numerous strengths, including severe strengths"
    ],
    "key_statements": [
        "Robustness to label noise is set to become an increasingly important property of supervised learning models",
        "To leverage the additional information from trusted labels, we propose a new loss correction and empirically verify it on a number of vision and natural language datasets with label corruption",
        "We have shown the impact of having a small set of trusted examples on label noise robustness in neural network classifiers",
        "We proposed the Gold Loss Correction (GLC), a method for coping with label noise",
        "This method leverages the assumption that the model has access to a small set of correct labels in order to yield accurate estimates of the noise distribution",
        "The Gold Loss Correction surpasses previous label noise robustness methods across various natural language processing and vision domains which we showed by considering several corruptions and numerous strengths, including severe strengths",
        "These results demonstrate that the Gold Loss Correction is a powerful, data-efficient method for improving robustness to label noise"
    ],
    "summary": [
        "Robustness to label noise is set to become an increasingly important property of supervised learning models.",
        "The forward correction method from Patrini et al [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>] obtains C by training a classifier on the noisy labels, and using the resulting softmax probabilities.",
        "To examine the effect of training on trusted labels as done by the GLC, we augment the Forward method by replacing its estimate of C with the identity on trusted examples.",
        "The distillation method of Li et al [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] involves training a neural network on a large trusted dataset and using this network to provide soft targets for the untrusted data.",
        "We train the models described in Section 4.1 under uniform, label-flipping, and hierarchical label corruptions at various fractions of trusted data.",
        "On MNIST, training on the trusted data alone outperforms all methods save for the GLC and Confusion Matrix, but performs significantly worse on CIFAR-100, even with large trusted fractions.",
        "We compare the GLC to the recent work of Ren et al [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>], which proposes a loss correction that uses a trusted set and meta-learning.",
        "This results in noisy labels which we use in place of the labels obtained through the uniform, flip, and hierarchical corruption methods.",
        "Clothing1M is a massive dataset with both human-annotated and noisy labels, which we use to compare the data efficiency of the GLC to that of Distillation when very few trusted labels are present.",
        "For both the GLC and Distillation, we first fine-tune a ResNet-34 on untrusted training examples for four epochs, and use this to estimate our corruption matrix.",
        "10N0umber of Tr5u0s0ted Example1s000 layer ResNeXt [<a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>] on untrusted training examples to estimate our corruption matrix.",
        "To see the extent to which this could impact performance, and whether simple methods for improving p(y | x) could help, we ran several variants of the GLC experiment on CIFAR-100 under the label flipping corruption at a trusted fraction of 5/100 which we describe.",
        "We have shown the impact of having a small set of trusted examples on label noise robustness in neural network classifiers.",
        "This method leverages the assumption that the model has access to a small set of correct labels in order to yield accurate estimates of the noise distribution.",
        "The GLC surpasses previous label noise robustness methods across various natural language processing and vision domains which we showed by considering several corruptions and numerous strengths, including severe strengths.",
        "These results demonstrate that the GLC is a powerful, data-efficient method for improving robustness to label noise."
    ],
    "headline": "We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] B Biggio, B Nelson, and P Laskov. \u201cSupport Vector Machines Under Adversarial Label Noise\u201d. In: ACML (2011).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Biggio%2C%20B.%20Nelson%2C%20B.%20Laskov%2C%20P.%20Support%20Vector%20Machines%20Under%20Adversarial%20Label%20Noise%202011"
        },
        {
            "id": "2",
            "entry": "[2] Beno\u00eet Fr\u00e9nay and Michel Verleysen. \u201cClassification in the presence of label noise: a survey\u201d. In: IEEE Trans Neural Netw Learn Syst (2014).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fr%C3%A9nay%2C%20Beno%C3%AEt%20Verleysen%2C%20Michel%20Classification%20in%20the%20presence%20of%20label%20noise%3A%20a%20survey%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fr%C3%A9nay%2C%20Beno%C3%AEt%20Verleysen%2C%20Michel%20Classification%20in%20the%20presence%20of%20label%20noise%3A%20a%20survey%202014"
        },
        {
            "id": "3",
            "entry": "[3] Kevin Gimpel et al. \u201cPart-of-speech Tagging for Twitter: Annotation, Features, and Experiments\u201d. In: ACL (2011).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gimpel%2C%20Kevin%20Part-of-speech%20Tagging%20for%20Twitter%3A%20Annotation%2C%20Features%2C%20and%20Experiments%202011"
        },
        {
            "id": "4",
            "entry": "[4] Chuan Guo et al. \u201cOn Calibration of Modern Neural Networks\u201d. In: ICML (2017).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Chuan%20On%20Calibration%20of%20Modern%20Neural%20Networks%202017"
        },
        {
            "id": "5",
            "entry": "[5] Dan Hendrycks and Kevin Gimpel. \u201cBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units\u201d. In: CoRR (2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hendrycks%2C%20Dan%20Gimpel%2C%20Kevin%20Bridging%20Nonlinearities%20and%20Stochastic%20Regularizers%20with%20Gaussian%20Error%20Linear%20Units%202016"
        },
        {
            "id": "6",
            "entry": "[6] Diederik P. Kingma and Jimmy Ba. \u201cAdam: A Method for Stochastic Optimization\u201d. In: ICLR",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20Method%20for%20Stochastic%20Optimization"
        },
        {
            "id": "7",
            "entry": "[7] J Larsen et al. \u201cDesign of robust neural network classifiers\u201d. In: Acoustics, Speech and Signal Processing, 1998. Proceedings of the 1998 IEEE International Conference on. 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Larsen%2C%20J.%20Design%20of%20robust%20neural%20network%20classifiers%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Larsen%2C%20J.%20Design%20of%20robust%20neural%20network%20classifiers%201998"
        },
        {
            "id": "8",
            "entry": "[8] Bo Li et al. \u201cData Poisoning Attacks on Factorization-Based Collaborative Filtering\u201d. In: NIPS",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Bo%20Data%20Poisoning%20Attacks%20on%20Factorization-Based%20Collaborative%20Filtering"
        },
        {
            "id": "9",
            "entry": "[9] Yuncheng Li et al. \u201cLearning from Noisy Labels with Distillation\u201d. In: ICCV (2017).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Yuncheng%20Learning%20from%20Noisy%20Labels%20with%20Distillation%202017"
        },
        {
            "id": "10",
            "entry": "[10] Ilya Loshchilov and Frank Hutter. \u201cSGDR: Stochastic Gradient Descent with Warm Restarts\u201d. In: ICLR (2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loshchilov%2C%20Ilya%20Hutter%2C%20Frank%20SGDR%3A%20Stochastic%20Gradient%20Descent%20with%20Warm%20Restarts%202016"
        },
        {
            "id": "11",
            "entry": "[11] Andrew L. Maas et al. \u201cLearning Word Vectors for Sentiment Analysis\u201d. In: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maas%2C%20Andrew%20L.%20Learning%20Word%20Vectors%20for%20Sentiment%20Analysis%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maas%2C%20Andrew%20L.%20Learning%20Word%20Vectors%20for%20Sentiment%20Analysis%202011"
        },
        {
            "id": "12",
            "entry": "[12] Aditya Krishna Menon, Brendan van Rooyen, and Nagarajan Natarajan. \u201cLearning from Binary Labels with Instance-Dependent Corruption\u201d. In: CoRR (2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Menon%2C%20Aditya%20Krishna%20van%20Rooyen%2C%20Brendan%20Natarajan%2C%20Nagarajan%20Learning%20from%20Binary%20Labels%20with%20Instance-Dependent%20Corruption%202016"
        },
        {
            "id": "13",
            "entry": "[13] Volodymyr Mnih and Geoffrey E Hinton. \u201cLearning to label aerial images from noisy data\u201d. In: ICML (2012).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Hinton%2C%20Geoffrey%20E.%20Learning%20to%20label%20aerial%20images%20from%20noisy%20data%202012"
        },
        {
            "id": "14",
            "entry": "[14] Nagarajan Natarajan et al. \u201cLearning with Noisy Labels\u201d. In: Advances in Neural Information Processing Systems 26. 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Natarajan%2C%20Nagarajan%20Learning%20with%20Noisy%20Labels%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Natarajan%2C%20Nagarajan%20Learning%20with%20Noisy%20Labels%202013"
        },
        {
            "id": "15",
            "entry": "[15] David F Nettleton, Albert Orriols-Puig, and Albert Fornells. \u201cA study of the effect of different types of noise on the precision of supervised learning techniques\u201d. In: Artif Intell Rev (2010).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nettleton%2C%20David%20F.%20Orriols-Puig%2C%20Albert%20Fornells%2C%20Albert%20A%20study%20of%20the%20effect%20of%20different%20types%20of%20noise%20on%20the%20precision%20of%20supervised%20learning%20techniques%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nettleton%2C%20David%20F.%20Orriols-Puig%2C%20Albert%20Fornells%2C%20Albert%20A%20study%20of%20the%20effect%20of%20different%20types%20of%20noise%20on%20the%20precision%20of%20supervised%20learning%20techniques%202010"
        },
        {
            "id": "16",
            "entry": "[16] Giorgio Patrini et al. \u201cMaking Deep Neural Networks Robust to Label Noise: a Loss Correction Approach\u201d. In: CVPR (2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Patrini%2C%20Giorgio%20Making%20Deep%20Neural%20Networks%20Robust%20to%20Label%20Noise%3A%20a%20Loss%20Correction%20Approach%202016"
        },
        {
            "id": "17",
            "entry": "[17] M Pechenizkiy et al. \u201cClass Noise and Supervised Learning in Medical Domains: The Effect of Feature Extraction\u201d. In: 19th IEEE Symposium on Computer-Based Medical Systems (CBMS\u201906). 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pechenizkiy%2C%20M.%20Class%20Noise%20and%20Supervised%20Learning%20in%20Medical%20Domains%3A%20The%20Effect%20of%20Feature%20Extraction%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pechenizkiy%2C%20M.%20Class%20Noise%20and%20Supervised%20Learning%20in%20Medical%20Domains%3A%20The%20Effect%20of%20Feature%20Extraction%202006"
        },
        {
            "id": "18",
            "entry": "[18] Scott Reed et al. \u201cTraining Deep Neural Networks on Noisy Labels with Bootstrapping\u201d. In: ICLR Workshop (2014).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Reed%2C%20Scott%20Training%20Deep%20Neural%20Networks%20on%20Noisy%20Labels%20with%20Bootstrapping%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Reed%2C%20Scott%20Training%20Deep%20Neural%20Networks%20on%20Noisy%20Labels%20with%20Bootstrapping%202014"
        },
        {
            "id": "19",
            "entry": "[19] Thu Mengye Ren et al. \u201cLearning to Reweight Examples for Robust Deep Learning\u201d. In: ICML (2018).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20Thu%20Mengye%20Learning%20to%20Reweight%20Examples%20for%20Robust%20Deep%20Learning%202018"
        },
        {
            "id": "20",
            "entry": "[20] Richard Socher et al. \u201cRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\u201d. In: Conference on Empirical Methods in Natural Language Processing. 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Socher%2C%20Richard%20Recursive%20Deep%20Models%20for%20Semantic%20Compositionality%20Over%20a%20Sentiment%20Treebank%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Socher%2C%20Richard%20Recursive%20Deep%20Models%20for%20Semantic%20Compositionality%20Over%20a%20Sentiment%20Treebank%202013"
        },
        {
            "id": "21",
            "entry": "[21] Nitish Srivastava et al. \u201cDropout: A simple way to prevent neural networks from overfitting\u201d. In: The Journal of Machine Learning Research (2014).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014"
        },
        {
            "id": "22",
            "entry": "[22] Jacob Steinhardt, Pang Wei Koh, and Percy Liang. \u201cCertified Defenses for Data Poisoning Attacks\u201d. In: NIPS. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Steinhardt%2C%20Jacob%20Koh%2C%20Pang%20Wei%20Liang%2C%20Percy%20Certified%20Defenses%20for%20Data%20Poisoning%20Attacks%202017"
        },
        {
            "id": "23",
            "entry": "[23] Sainbayar Sukhbaatar et al. \u201cTraining Convolutional Networks with Noisy Labels\u201d. In: ICLR Workshop (2014).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sukhbaatar%2C%20Sainbayar%20Training%20Convolutional%20Networks%20with%20Noisy%20Labels%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sukhbaatar%2C%20Sainbayar%20Training%20Convolutional%20Networks%20with%20Noisy%20Labels%202014"
        },
        {
            "id": "24",
            "entry": "[24] Andreas Veit et al. \u201cLearning From Noisy Large-Scale Datasets With Minimal Supervision\u201d. In: CVPR (2017).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Veit%2C%20Andreas%20Learning%20From%20Noisy%20Large-Scale%20Datasets%20With%20Minimal%20Supervision%202017"
        },
        {
            "id": "25",
            "entry": "[25] Tong Xiao et al. \u201cLearning from massive noisy labeled data for image classification\u201d. In: CVPR (2015).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xiao%2C%20Tong%20Learning%20from%20massive%20noisy%20labeled%20data%20for%20image%20classification%202015"
        },
        {
            "id": "26",
            "entry": "[26] Saining Xie et al. \u201cAggregated Residual Transformations for Deep Neural Networks\u201d. In: CVPR (2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20Saining%20Aggregated%20Residual%20Transformations%20for%20Deep%20Neural%20Networks%202016"
        },
        {
            "id": "27",
            "entry": "[27] Sergey Zagoruyko and Nikos Komodakis. \u201cWide Residual Networks\u201d. In: BMVC (2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zagoruyko%2C%20Sergey%20Komodakis%2C%20Nikos%20Wide%20Residual%20Networks%202016"
        },
        {
            "id": "28",
            "entry": "[28] Xingquan Zhu and Xindong Wu. \u201cClass Noise vs. Attribute Noise: A Quantitative Study\u201d. In: Artificial Intelligence Review (2004). ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Xingquan%20Wu%2C%20Xindong%20Class%20Noise%20vs.%20Attribute%20Noise%3A%20A%20Quantitative%20Study%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Xingquan%20Wu%2C%20Xindong%20Class%20Noise%20vs.%20Attribute%20Noise%3A%20A%20Quantitative%20Study%202004"
        }
    ]
}
