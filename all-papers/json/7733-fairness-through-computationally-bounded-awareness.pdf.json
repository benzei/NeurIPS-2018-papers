{
    "filename": "7733-fairness-through-computationally-bounded-awareness.pdf",
    "metadata": {
        "title": "Fairness Through Computationally-Bounded Awareness",
        "author": "Michael Kim, Omer Reingold, Guy Rothblum",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7733-fairness-through-computationally-bounded-awareness.pdf"
        },
        "abstract": "We study the problem of fair classification within the versatile framework of Dwork et al. [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], which assumes the existence of a metric that measures similarity between pairs of individuals. Unlike earlier work, we do not assume that the entire metric is known to the learning algorithm; instead, the learner can query this arbitrary metric a bounded number of times. We propose a new notion of fairness called metric multifairness and show how to achieve this notion in our setting. Metric multifairness is parameterized by a similarity metric d on pairs of individuals to classify and a rich collection C of (possibly overlapping) \u201ccomparison sets\" over pairs of individuals. At a high level, metric multifairness guarantees that similar subpopulations are treated similarly, as long as these subpopulations are identified within the class C."
    },
    "keywords": [
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        }
    ],
    "highlights": [
        "Machine learning systems are being used to make predictions about people",
        "It feels that the objectives of fair classification are at odds with obtaining high-utility predictions",
        "We propose a new theoretical framework for fair classification based on fairness through awareness \u2013 which we dub \u201cfairness through computationally-bounded awareness\u201d \u2013 that eliminates the considerable issue of requiring the metric to be known exactly",
        "If we take C to be a family defined according to some class of computations of bounded dimension \u2013 think, the set of conjunctions of a constant number of boolean features or short decision trees \u2013 we can hope to accurately estimate and enforce the metric multifairness conditions",
        "The predictions are not required to generalize out of sample. This means the metric multifairness guarantee does not generalize outside the N individuals; on the other hand, because the predictions need not come from a bounded hypothesis class, their utility can only improve compared to learning a metric multifair hypothesis directly",
        "We show a general reduction from the problem of searching for a violated comparison S 2 C to the problem of agnostic learning over the corresponding family of boolean functions"
    ],
    "key_statements": [
        "Machine learning systems are being used to make predictions about people",
        "It feels that the objectives of fair classification are at odds with obtaining high-utility predictions",
        "We propose a new theoretical framework for fair classification based on fairness through awareness \u2013 which we dub \u201cfairness through computationally-bounded awareness\u201d \u2013 that eliminates the considerable issue of requiring the metric to be known exactly",
        "If we take C to be a family defined according to some class of computations of bounded dimension \u2013 think, the set of conjunctions of a constant number of boolean features or short decision trees \u2013 we can hope to accurately estimate and enforce the metric multifairness conditions",
        "The predictions are not required to generalize out of sample. This means the metric multifairness guarantee does not generalize outside the N individuals; on the other hand, because the predictions need not come from a bounded hypothesis class, their utility can only improve compared to learning a metric multifair hypothesis directly",
        "We show a general reduction from the problem of searching for a violated comparison S 2 C to the problem of agnostic learning over the corresponding family of boolean functions",
        "Metric multifairness does not directly generalize either [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>] or [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], but we argue that it provides a more flexible alternative to these approaches for subpopulation fairness"
    ],
    "summary": [
        "Machine learning systems are being used to make predictions about people.",
        "As in [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], we investigate how to learn a classifier that achieves optimal utility under similarity-based fairness constraints, assuming a weaker model of limited access to the metric.",
        "If there is some subset S 2 C that identifies a set of pairs whose metric distance is small, any metric multifair hypothesis must satisfy the stronger individual metric fairness notion on many pairs from S.",
        "If the class C is rich enough to correlate well with various comparisons that reveal significant information about the metric, any metric multifair hypothesis will satisfy individual-level fairness on a significant fraction of the population!",
        "If we take C to be a family defined according to some class of computations of bounded dimension \u2013 think, the set of conjunctions of a constant number of boolean features or short decision trees \u2013 we can hope to accurately estimate and enforce the metric multifairness conditions.",
        "We can think of the input labels to Algorithm 1 to be the output of any predictor that was trained separately.6 For instance, if we have learned a highly-accurate model, but are unsure of its fairness, we can instantiate our framework with, say, the squared loss between the original predictions and the returned predictions; we can view the program as a procedure to project the highly-accurate predictions onto the set of metric multifair predictions.",
        "This means the metric multifairness guarantee does not generalize outside the N individuals; on the other hand, because the predictions need not come from a bounded hypothesis class, their utility can only improve compared to learning a metric multifair hypothesis directly.",
        "We give a reduction from inverting a boolean concept c 2 C to learning a hypothesis f that is metric multifair on a collection H derived from C, where the metric samples from d encode information about the concept c.",
        "While we argued earlier that some relaxation of metric fairness is necessary if we want to learn from a small set of metric samples, it is not clear that multifairness with respect to C is the strongest relaxation we can obtain.",
        "Theorem access to d4.anLdetout,p\u2327ut>s a0 be constants and suppose A is an algorithm C, d, \u2327 -metric multifair set of predictions for that has random sample -large C.",
        "Assuming one-way functions exist, there is no efficient algorithm for computing C, \u2327 -optimal C, d, \u2327 -metric multifair predictions for general C, d, and constant \u2327 ."
    ],
    "headline": "We study the problem of fair classification within the versatile framework of Dwork et al. , which assumes the existence of a metric that measures similarity between pairs of individuals",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias: There\u2019s software used across the country to predict future criminals. and it\u2019s biased against blacks. ProPublica, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Angwin%2C%20Julia%20Larson%2C%20Jeff%20Mattu%2C%20Surya%20Kirchner%2C%20Lauren%20Machine%20bias%3A%20There%E2%80%99s%20software%20used%20across%20the%20country%20to%20predict%20future%20criminals.%20and%20it%E2%80%99s%20biased%20against%20blacks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Angwin%2C%20Julia%20Larson%2C%20Jeff%20Mattu%2C%20Surya%20Kirchner%2C%20Lauren%20Machine%20bias%3A%20There%E2%80%99s%20software%20used%20across%20the%20country%20to%20predict%20future%20criminals.%20and%20it%E2%80%99s%20biased%20against%20blacks%202016"
        },
        {
            "id": "2",
            "entry": "[2] Andrej Bogdanov and Alon Rosen. Pseudorandom functions: Three decades later. In Tutorials on the Foundations of Cryptography, pages 79\u2013158.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bogdanov%2C%20Andrej%20Rosen%2C%20Alon%20Pseudorandom%20functions%3A%20Three%20decades%20later",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bogdanov%2C%20Andrej%20Rosen%2C%20Alon%20Pseudorandom%20functions%3A%20Three%20decades%20later"
        },
        {
            "id": "3",
            "entry": "[3] Joy Buolamwini and Timnit Gebru. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on Fairness, Accountability and Transparency, pages 77\u201391, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Buolamwini%2C%20Joy%20Gebru%2C%20Timnit%20Gender%20shades%3A%20Intersectional%20accuracy%20disparities%20in%20commercial%20gender%20classification%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Buolamwini%2C%20Joy%20Gebru%2C%20Timnit%20Gender%20shades%3A%20Intersectional%20accuracy%20disparities%20in%20commercial%20gender%20classification%202018"
        },
        {
            "id": "4",
            "entry": "[4] Alexandra Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big Data, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chouldechova%2C%20Alexandra%20Fair%20prediction%20with%20disparate%20impact%3A%20A%20study%20of%20bias%20in%20recidivism%20prediction%20instruments%202017"
        },
        {
            "id": "5",
            "entry": "[5] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. Algorithmic decision making and the cost of fairness. KDD, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Corbett-Davies%2C%20Sam%20Pierson%2C%20Emma%20Feller%2C%20Avi%20Goel%2C%20Sharad%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Corbett-Davies%2C%20Sam%20Pierson%2C%20Emma%20Feller%2C%20Avi%20Goel%2C%20Sharad%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017"
        },
        {
            "id": "6",
            "entry": "[6] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S. Zemel. Fairness through awareness. In Innovations in Theoretical Computer Science (ITCS), pages 214\u2013226, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Reingold%2C%20Omer%20Fairness%20through%20awareness%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Reingold%2C%20Omer%20Fairness%20through%20awareness%202012"
        },
        {
            "id": "7",
            "entry": "[7] Vitaly Feldman. Distribution-specific agnostic boosting. In Proceedings of the First Symposium on Innovations in Computer Science\u201910, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feldman%2C%20Vitaly%20Distribution-specific%20agnostic%20boosting%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feldman%2C%20Vitaly%20Distribution-specific%20agnostic%20boosting%202010"
        },
        {
            "id": "8",
            "entry": "[8] Vitaly Feldman, Venkatesan Guruswami, Prasad Raghavendra, and Yi Wu. Agnostic learning of monomials by halfspaces is hard. SIAM Journal on Computing, 41(6):1558\u20131590, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feldman%2C%20Vitaly%20Guruswami%2C%20Venkatesan%20Raghavendra%2C%20Prasad%20Wu%2C%20Yi%20Agnostic%20learning%20of%20monomials%20by%20halfspaces%20is%20hard%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feldman%2C%20Vitaly%20Guruswami%2C%20Venkatesan%20Raghavendra%2C%20Prasad%20Wu%2C%20Yi%20Agnostic%20learning%20of%20monomials%20by%20halfspaces%20is%20hard%202012"
        },
        {
            "id": "9",
            "entry": "[9] Avi Feller, Emma Pierson, Sam Corbett-Davies, and Sharad Goel. A computer program used for bail and sentencing decisions was labeled biased against blacks. it\u2019s actually not that clear. The Washington Post, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feller%2C%20Avi%20Pierson%2C%20Emma%20Corbett-Davies%2C%20Sam%20Goel%2C%20Sharad%20A%20computer%20program%20used%20for%20bail%20and%20sentencing%20decisions%20was%20labeled%20biased%20against%20blacks.%20it%E2%80%99s%20actually%20not%20that%20clear%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feller%2C%20Avi%20Pierson%2C%20Emma%20Corbett-Davies%2C%20Sam%20Goel%2C%20Sharad%20A%20computer%20program%20used%20for%20bail%20and%20sentencing%20decisions%20was%20labeled%20biased%20against%20blacks.%20it%E2%80%99s%20actually%20not%20that%20clear%202016"
        },
        {
            "id": "10",
            "entry": "[10] Stephen Gillen, Christopher Jung, Michael J. Kearns, and Aaron Roth. Online learning with an unknown fairness metric. arXiv preprint arXiv:1802.06936, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.06936"
        },
        {
            "id": "11",
            "entry": "[11] Oded Goldreich, Shafi Goldwasser, and Silvio Micali. How to construct random functions. In Foundations of Computer Science, 1984. 25th Annual Symposium on, pages 464\u2013479. IEEE, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldreich%2C%20Oded%20Goldwasser%2C%20Shafi%20Micali%2C%20Silvio%20How%20to%20construct%20random%20functions%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldreich%2C%20Oded%20Goldwasser%2C%20Shafi%20Micali%2C%20Silvio%20How%20to%20construct%20random%20functions%201984"
        },
        {
            "id": "12",
            "entry": "[12] Parikshit Gopalan, Adam Tauman Kalai, and Adam R Klivans. Agnostically learning decision trees. In Proceedings of the fortieth annual ACM symposium on Theory of computing, pages 527\u2013536. ACM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gopalan%2C%20Parikshit%20Kalai%2C%20Adam%20Tauman%20Klivans%2C%20Adam%20R.%20Agnostically%20learning%20decision%20trees%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gopalan%2C%20Parikshit%20Kalai%2C%20Adam%20Tauman%20Klivans%2C%20Adam%20R.%20Agnostically%20learning%20decision%20trees%202008"
        },
        {
            "id": "13",
            "entry": "[13] Moritz Hardt, Eric Price, and Nathan Srebro. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems, pages 3315\u20133323, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20Moritz%20Price%2C%20Eric%20Srebro%2C%20Nathan%20Equality%20of%20opportunity%20in%20supervised%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20Moritz%20Price%2C%20Eric%20Srebro%2C%20Nathan%20Equality%20of%20opportunity%20in%20supervised%20learning%202016"
        },
        {
            "id": "14",
            "entry": "[14] \u00darsula H\u00e9bert-Johnson, Michael P. Kim, Omer Reingold, and Guy N. Rothblum. Calibration for the (computationally-identifiable) masses. ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%A9bert-Johnson%2C%20%C3%9Arsula%20Kim%2C%20Michael%20P.%20Reingold%2C%20Omer%20Rothblum%2C%20Guy%20N.%20Calibration%20for%20the%20%28computationally-identifiable%29%20masses%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=H%C3%A9bert-Johnson%2C%20%C3%9Arsula%20Kim%2C%20Michael%20P.%20Reingold%2C%20Omer%20Rothblum%2C%20Guy%20N.%20Calibration%20for%20the%20%28computationally-identifiable%29%20masses%202018"
        },
        {
            "id": "15",
            "entry": "[15] Michael Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM (JACM), 45(6):983\u20131006, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kearns%2C%20Michael%20Efficient%20noise-tolerant%20learning%20from%20statistical%20queries%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kearns%2C%20Michael%20Efficient%20noise-tolerant%20learning%20from%20statistical%20queries%201998"
        },
        {
            "id": "16",
            "entry": "[16] Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. Preventing fairness gerrymandering: Auditing and learning for subgroup fairness. ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kearns%2C%20Michael%20Neel%2C%20Seth%20Roth%2C%20Aaron%20Wu%2C%20Zhiwei%20Steven%20Preventing%20fairness%20gerrymandering%3A%20Auditing%20and%20learning%20for%20subgroup%20fairness%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kearns%2C%20Michael%20Neel%2C%20Seth%20Roth%2C%20Aaron%20Wu%2C%20Zhiwei%20Steven%20Preventing%20fairness%20gerrymandering%3A%20Auditing%20and%20learning%20for%20subgroup%20fairness%202018"
        },
        {
            "id": "17",
            "entry": "[17] Michael J. Kearns, Robert E. Schapire, and Linda M. Sellie. Toward efficient agnostic learning. Machine Learning, 17(2-3):115\u2013141, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kearns%2C%20Michael%20J.%20Schapire%2C%20Robert%20E.%20Sellie%2C%20Linda%20M.%20Toward%20efficient%20agnostic%20learning%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kearns%2C%20Michael%20J.%20Schapire%2C%20Robert%20E.%20Sellie%2C%20Linda%20M.%20Toward%20efficient%20agnostic%20learning%201994"
        },
        {
            "id": "18",
            "entry": "[18] Michael P. Kim, Amirata Ghorbani, and James Zou. Multiaccuracy: Black-box post-processing for fairness in classification. arXiv preprint arXiv:1805.12317, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.12317"
        },
        {
            "id": "19",
            "entry": "[19] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. Inherent trade-offs in the fair determination of risk scores. ITCS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kleinberg%2C%20Jon%20Mullainathan%2C%20Sendhil%20Raghavan%2C%20Manish%20Inherent%20trade-offs%20in%20the%20fair%20determination%20of%20risk%20scores%202017"
        },
        {
            "id": "20",
            "entry": "[20] Yurii Nesterov. Primal-dual subgradient methods for convex problems. Mathematical programming, 120(1):221\u2013259, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Primal-dual%20subgradient%20methods%20for%20convex%20problems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Primal-dual%20subgradient%20methods%20for%20convex%20problems%202009"
        },
        {
            "id": "21",
            "entry": "[21] Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q. Weinberger. On fairness and calibration. NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pleiss%2C%20Geoff%20Raghavan%2C%20Manish%20Wu%2C%20Felix%20Kleinberg%2C%20Jon%20On%20fairness%20and%20calibration%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pleiss%2C%20Geoff%20Raghavan%2C%20Manish%20Wu%2C%20Felix%20Kleinberg%2C%20Jon%20On%20fairness%20and%20calibration%202017"
        },
        {
            "id": "22",
            "entry": "[22] Guy N. Rothblum and Gal Yona. Probably approximately metric-fair learning. ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rothblum%2C%20Guy%20N.%20Yona%2C%20Gal%20Probably%20approximately%20metric-fair%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rothblum%2C%20Guy%20N.%20Yona%2C%20Gal%20Probably%20approximately%20metric-fair%20learning%202018"
        },
        {
            "id": "23",
            "entry": "[23] Leslie G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134\u20131142, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Valiant%2C%20Leslie%20G.%20A%20theory%20of%20the%20learnable%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Valiant%2C%20Leslie%20G.%20A%20theory%20of%20the%20learnable%201984"
        },
        {
            "id": "24",
            "entry": "[24] Kaveh Waddell. How algorithms can bring down minorities\u2019 credit scores. The Atlantic, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Waddell%2C%20Kaveh%20How%20algorithms%20can%20bring%20down%20minorities%E2%80%99%20credit%20scores%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Waddell%2C%20Kaveh%20How%20algorithms%20can%20bring%20down%20minorities%E2%80%99%20credit%20scores%202016"
        },
        {
            "id": "25",
            "entry": "[25] Blake Woodworth, Suriya Gunasekar, Mesrob I Ohannessian, and Nathan Srebro. Learning non-discriminatory predictors. COLT, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Woodworth%2C%20Blake%20Gunasekar%2C%20Suriya%20Ohannessian%2C%20Mesrob%20I.%20Srebro%2C%20Nathan%20Learning%20non-discriminatory%20predictors%202017"
        }
    ]
}
