{
    "filename": "7908-a-theory-based-evaluation-of-nearest-neighbor-models-put-into-practice.pdf",
    "metadata": {
        "title": "A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice",
        "author": "Hendrik Fichtenberger\u2217 TU Dortmund",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7908-a-theory-based-evaluation-of-nearest-neighbor-models-put-into-practice.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In the k-nearest neighborhood model (k-NN), we are given a set of points P , and we shall answer queries q by returning the k nearest neighbors of q in P according to some metric. This concept is crucial in many areas of data analysis and data processing, e.g., computer vision, document retrieval and machine learning. Many k-NN algorithms have been published and implemented, but often the relation between parameters and accuracy of the computed k-NN is not explicit. We study property testing of k-NN graphs in theory and evaluate it empirically: given a point set P \u2282 R\u03b4 and a directed graph G = (P, E), is G a k-NN graph, i.e., every point p \u2208 P has outgoing edges to its k nearest neighbors, or is it -far from being a k-NN graph? Here, -far means that one has to change more than an -fraction of the edges in order to make G a k-NN graph. We develop a randomized algorithm wNiNthpornoep-esritdye,dweirthrocrotmhaptledxeictiydeOs (t\u221ahins kq2u/es2ti)omn,eia.esu.,readpirnopteerrtmysteosftetrhefonrutmhebekrof vertices and edges it inspects, and we prove a lower bound of \u03a9( n/ k). We evaluate our tester empirically on the k-NN models computed by various algorithms and show that it can be used to detect k-NN models with bad accuracy in significantly less time than the building time of the k-NN model."
    },
    "keywords": [
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "property testing",
            "url": "https://en.wikipedia.org/wiki/property_testing"
        },
        {
            "term": "nearest neighbor",
            "url": "https://en.wikipedia.org/wiki/nearest_neighbor"
        },
        {
            "term": "MNIST",
            "url": "https://en.wikipedia.org/wiki/MNIST"
        }
    ],
    "highlights": [
        "The k-nearest neighborhood (k-NN) of a point q with respect to some set of points P is one of the most fundamental concepts used in data analysis tasks such as classification, regression and machine learning",
        "We chose to evaluate the tester for k = 10 because indices that are very close to 10-NN graphs \u2013 which is the hard case for the property tester to detect \u2013 can be computed by the approximate nearest neighbor algorithms in reasonable time, and we support this decision by an additional experiment for k = 50",
        "We evaluate the recall of the property tester by distance of a tested approximate nearest neighbor index to ground truth, where graphs that are no k-nearest neighbourhood graphs are relevant",
        "We have studied the task of efficiently identifying NN models with low accuracy by exploring possibilities within the theoretical framework of sublinear algorithms and evaluated our approach by moving tester with ctoomepxlpeexriitmy eOnc,ui.lea.r,, we have proved that there is a one-sided error a sublinear algorithm that decides property whether an input graph G is a k-nearest neighbourhood graph or requires many edge modifications to become a k-nearest neighbourhood graph (i.e., Figure 2: Recall of the property tester by -distance of the approximate nearest neighbor index to a k-nearest neighbourhood graph for different choices of the tester\u2019s parameters and k = {10, 50}",
        "Our experiments of the property tester on approximate nearest neighbor indices computed by various algorithms indicate that testing comes at almost no additional cost, i.e., the testing time is significantly smaller than the building time of the approximate nearest neighbor index that is tested"
    ],
    "key_statements": [
        "The k-nearest neighborhood (k-NN) of a point q with respect to some set of points P is one of the most fundamental concepts used in data analysis tasks such as classification, regression and machine learning",
        "Testing whether G is at least close to a k-nearest neighbourhood graph will suffice for many purposes",
        "Property testing is a framework for the theoretical analysis of decision and verification problems that are relaxed in favor of sublinear complexity",
        "We chose to evaluate the tester for k = 10 because indices that are very close to 10-NN graphs \u2013 which is the hard case for the property tester to detect \u2013 can be computed by the approximate nearest neighbor algorithms in reasonable time, and we support this decision by an additional experiment for k = 50",
        "We evaluate the recall of the property tester by distance of a tested approximate nearest neighbor index to ground truth, where graphs that are no k-nearest neighbourhood graphs are relevant",
        "We have studied the task of efficiently identifying NN models with low accuracy by exploring possibilities within the theoretical framework of sublinear algorithms and evaluated our approach by moving tester with ctoomepxlpeexriitmy eOnc,ui.lea.r,, we have proved that there is a one-sided error a sublinear algorithm that decides property whether an input graph G is a k-nearest neighbourhood graph or requires many edge modifications to become a k-nearest neighbourhood graph (i.e., Figure 2: Recall of the property tester by -distance of the approximate nearest neighbor index to a k-nearest neighbourhood graph for different choices of the tester\u2019s parameters and k = {10, 50}",
        "Our experiments of the property tester on approximate nearest neighbor indices computed by various algorithms indicate that testing comes at almost no additional cost, i.e., the testing time is significantly smaller than the building time of the approximate nearest neighbor index that is tested"
    ],
    "summary": [
        "The k-nearest neighborhood (k-NN) of a point q with respect to some set of points P is one of the most fundamental concepts used in data analysis tasks such as classification, regression and machine learning.",
        "A one-sided error -tester for a property P of graphs with average degree bounded by d has to accept every graph G \u2208 P and it has to reject every graph H that is -far from P with probability at least 2/3.",
        "Main Results Our first result is a property tester with one-sided error for the property that a given geometric graph G with bounded average degree is a k-nearest neighborhood graph of its underlying point set.",
        "We provide an experimental evaluation of our property tester on approximate nearest neighbor (ANN) indices computed by various ANN algorithms.",
        "A one-sided -tester for a property P with query complexity q is a randomized algorithm that makes q queries to fG, dG and coordG for a graph G.",
        "We chose to evaluate the tester for k = 10 because indices that are very close to 10-NN graphs \u2013 which is the hard case for the property tester to detect \u2013 can be computed by the ANN algorithms in reasonable time, and we support this decision by an additional experiment for k = 50.",
        "We evaluate the recall of the property tester by distance of a tested ANN index to ground truth, where graphs that are no k-NN graphs are relevant.",
        "We compare the property tester against the minimum cost that every algorithm that uses an ANN index must invest before it can employ it or even just draw conclusions about its quality: the build time of the index.",
        "We have studied the task of efficiently identifying NN models with low accuracy by exploring possibilities within the theoretical framework of sublinear algorithms and evaluated our approach by moving tester with ctoomepxlpeexriitmy eOnc,ui.lea.r,, we have proved that there is a one-sided error a sublinear algorithm that decides property whether an input graph G is a k-NN graph or requires many edge modifications to become a k-NN graph (i.e., Figure 2: Recall of the property tester by -distance of the ANN index to a k-NN graph for different choices of the tester\u2019s parameters and k = {10, 50}.",
        "Our experiments of the property tester on ANN indices computed by various algorithms indicate that testing comes at almost no additional cost, i.e., the testing time is significantly smaller than the building time of the ANN index that is tested.",
        "It would be interesting to investigate what results can be obtained under established oracle access models, which are oblivious of the graph\u2019s structure, and whether other useful models can be devised"
    ],
    "headline": "We study property testing of k-nearest neighbourhood graphs in theory and evaluate it empirically: given a point set P \u2282 R\u03b4 and a directed graph G = , is G a k-nearest neighbourhood graph, i.e., every point p \u2208 P has outgoing edges to its k nearest neighbors, or is it -far from being a k-nearest neighbourhood graph? Here, -far means that one has to change more than an -fraction of the edges in order to make G a k-nearest neighbourhood graph",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Ann Arbor Algorithms. KGraph: A Library for k-Nearest Neighbor Search, 2018. URL https://github.com/aaalgo/kgraph.",
            "url": "https://github.com/aaalgo/kgraph",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Algorithms%2C%20Ann%20Arbor%20KGraph%3A%20A%20Library%20for%20k-Nearest%20Neighbor%202018"
        },
        {
            "id": "2",
            "entry": "[2] Martin Aum\u00fcller, Erik Bernhardsson, and Alexander Faithfull. ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor Algorithms. In Similarity Search and Applications, Lecture Notes in Computer Science, pages 34\u201349. Springer, 2017. doi: 10.1007/978-3-319-68474-1_3.",
            "crossref": "https://dx.doi.org/10.1007/978-3-319-68474-1_3",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/978-3-319-68474-1_3"
        },
        {
            "id": "3",
            "entry": "[3] Oren Ben-Zwi, Oded Lachish, and Ilan Newman. Lower Bounds for Testing Euclidean Minimum Spanning Trees. Information Processing Letters, 102(6):219\u2013225, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-Zwi%2C%20Oren%20Lachish%2C%20Oded%20Newman%2C%20Ilan%20Lower%20Bounds%20for%20Testing%20Euclidean%20Minimum%20Spanning%20Trees%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-Zwi%2C%20Oren%20Lachish%2C%20Oded%20Newman%2C%20Ilan%20Lower%20Bounds%20for%20Testing%20Euclidean%20Minimum%20Spanning%20Trees%202007"
        },
        {
            "id": "4",
            "entry": "[4] Erik Bernhardsson. ANN-Benchmarks: Benchmarks of Approximate Nearest Neighbor Libraries in Python, 2018. URL https://github.com/erikbern/ann-benchmarks.",
            "url": "https://github.com/erikbern/ann-benchmarks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bernhardsson%2C%20Erik%20ANN-Benchmarks%3A%20Benchmarks%20of%20Approximate%20Nearest%20Neighbor%20Libraries%20in%202018"
        },
        {
            "id": "5",
            "entry": "[5] Erik Bernhardsson. ANN-Benchmarks, algos.yaml, commit 4805b1, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bernhardsson%2C%20Erik%20ANN-Benchmarks%2C%20algos.yaml%2C%20commit%204805b1%202018"
        },
        {
            "id": "URL_0000_a",
            "entry": "URL https://github.com/erikbern/ann-benchmarks/blob/",
            "url": "https://github.com/erikbern/ann-benchmarks/blob/"
        },
        {
            "id": "6",
            "entry": "[6] Erik Bernhardsson, Martin Aum\u00fcller, Alexander Faithfull, Leonid Boytsov, Ilya Razenshteyn, Ann Arbor Algorithms, www, Leland McInnes, Yury Malkov, Asier Erramuzpe, Ole, Ben Frederickson, Hendrik Fichtenberger, and Dennis Rohde. hfichtenberger/ann-benchmarks: NIPS paper version, October 2018. URL https://doi.org/10.5281/zenodo.1463824.",
            "crossref": "https://dx.doi.org/10.5281/zenodo.1463824"
        },
        {
            "id": "7",
            "entry": "[7] Leonid Boytsov and Bilegsaikhan Naidan. Engineering Efficient and Effective Non-metric Space Library. In Similarity Search and Applications, pages 280\u2013293, 2013. doi: 10.1007/ 978-3-642-41062-8_28.",
            "crossref": "https://dx.doi.org/10.1007/978-3-642-41062-8_28"
        },
        {
            "id": "8",
            "entry": "[8] Paul B. Callahan and Sambasiva R. Kosaraju. A Decomposition of Multidimensional Point Sets with Applications to K-Nearest-Neighbors and N-Body Potential Fields. Journal of the ACM, 42(1):67\u201390, 1995. doi: 10.1145/200836.200853.",
            "crossref": "https://dx.doi.org/10.1145/200836.200853",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/200836.200853"
        },
        {
            "id": "9",
            "entry": "[9] Jie Chen, Haw-ren Fang, and Yousef Saad. Fast Approximate kNN Graph Construction for High Dimensional Data via Recursive Lanczos Bisection. Journal of Machine Learning Research, 10: 1989\u20132012, 2009. ISSN 1533-7928. URL http://www.jmlr.org/papers/v10/chen09b.html.",
            "url": "http://www.jmlr.org/papers/v10/chen09b.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Jie%20Fang%2C%20Haw-ren%20Saad%2C%20Yousef%20Fast%20Approximate%20kNN%20Graph%20Construction%20for%20High%20Dimensional%20Data%20via%20Recursive%20Lanczos%20Bisection%201989"
        },
        {
            "id": "10",
            "entry": "[10] Michael Connor and Piyush Kumar. Fast Construction of K-Nearest Neighbor Graphs for Point Clouds. IEEE Transactions on Visualization and Computer Graphics, 16(4):599\u2013608, 2010. doi: 10.1109/TVCG.2010.9.",
            "crossref": "https://dx.doi.org/10.1109/TVCG.2010.9",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TVCG.2010.9"
        },
        {
            "id": "11",
            "entry": "[11] Artur Czumaj and Christian Sohler. Testing Euclidean Minimum Spanning Trees in the Plane. ACM Transactions on Algorithms (TALG), 4(3):31, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Czumaj%2C%20Artur%20Sohler%2C%20Christian%20Testing%20Euclidean%20Minimum%20Spanning%20Trees%20in%20the%20Plane%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Czumaj%2C%20Artur%20Sohler%2C%20Christian%20Testing%20Euclidean%20Minimum%20Spanning%20Trees%20in%20the%20Plane%202008"
        },
        {
            "id": "12",
            "entry": "[12] Artur Czumaj and Christian Sohler. Estimating the Weight of Metric Minimum Spanning Trees in Sublinear Time. SIAM Journal on Computing, 39(3):904\u2013922, 2009. doi: 10.1137/ 060672121.",
            "crossref": "https://dx.doi.org/10.1137/060672121",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1137/060672121"
        },
        {
            "id": "13",
            "entry": "[13] Artur Czumaj, Christian Sohler, and Martin Ziegler. Property Testing in Computational Geometry, pages 155\u2013166. Springer, 2000. ISBN 978-3-540-45253-9. doi: 10.1007/3-540-45253-2_15. URL http://dx.doi.org/10.1007/3-540-45253-2_15.",
            "crossref": "https://dx.doi.org/10.1007/3-540-45253-2_15",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/3-540-45253-2_15"
        },
        {
            "id": "14",
            "entry": "[14] Artur Czumaj, Funda Erg\u00fcn, Lance Fortnow, Avner Magen, Ilan Newman, Ronitt Rubinfeld, and Christian Sohler. Approximating the Weight of the Euclidean Minimum Spanning Tree in Sublinear Time. SIAM Journal on Computing, 35(1):91\u2013109, 2005. doi: 10.1137/S0097539703435297.",
            "crossref": "https://dx.doi.org/10.1137/S0097539703435297",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1137/S0097539703435297"
        },
        {
            "id": "15",
            "entry": "[15] Belur V. Dasarathy. Nearest Neighbor Norms: NN Pattern Classification Techniques. IEEE Computer Society Press, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dasarathy%2C%20Belur%20V.%20Nearest%20Neighbor%20Norms%3A%20NN%20Pattern%20Classification%20Techniques%201991"
        },
        {
            "id": "16",
            "entry": "[16] Hendrik Fichtenberger and Dennis Rohde. A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice. URL http://arxiv.org/abs/1810.05064.",
            "url": "http://arxiv.org/abs/1810.05064",
            "arxiv_url": "https://arxiv.org/pdf/1810.05064"
        },
        {
            "id": "17",
            "entry": "[17] Hendrik Fichtenberger and Dennis Rohde. hfichtenberger/knn_tester: NIPS paper version, October 2018. URL https://doi.org/10.5281/zenodo.1463804.",
            "crossref": "https://dx.doi.org/10.5281/zenodo.1463804"
        },
        {
            "id": "18",
            "entry": "[18] Jerome H. Friedman, Forest Baskett, and Leonard J. Shustek. An Algorithm for Finding Nearest Neighbors. IEEE Transactions on Computers, C-24(10):1000\u20131006, 1975. doi: 10.1109/T-C.1975.224110.",
            "crossref": "https://dx.doi.org/10.1109/T-C.1975.224110",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/T-C.1975.224110"
        },
        {
            "id": "19",
            "entry": "[19] Xiping Fu, Brendan McCane, Steven Mills, Michael Albert, and Lech Szymanski. UCI Machine Learning Repository: SIFT10M Data Set, 2018. URL https://archive.ics.uci.edu/ml/datasets/SIFT10M.",
            "url": "https://archive.ics.uci.edu/ml/datasets/SIFT10M",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xiping%20Fu%20Brendan%20McCane%20Steven%20Mills%20Michael%20Albert%20and%20Lech%20Szymanski%20UCI%20Machine%20Learning%20Repository%20SIFT10M%20Data%20Set%202018%20URL%20httpsarchiveicsuciedumldatasetsSIFT10M"
        },
        {
            "id": "20",
            "entry": "[20] Keinosuke Fukunaga and Patrenahalli M. Narendra. A Branch and Bound Algorithm for Computing k-Nearest Neighbors. IEEE Transactions on Computers, C-24(7):750\u2013753, 1975. doi: 10.1109/T-C.1975.224297.",
            "crossref": "https://dx.doi.org/10.1109/T-C.1975.224297",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/T-C.1975.224297"
        },
        {
            "id": "21",
            "entry": "[21] Oded Goldreich, Shari Goldwasser, and Dana Ron. Property Testing and Its Connection to Learning and Approximation. Journal of the ACM, 45(4):653\u2013750, 1998. doi: 10.1145/285055. 285060.",
            "crossref": "https://dx.doi.org/10.1145/285055.285060",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/285055.285060"
        },
        {
            "id": "22",
            "entry": "[22] Frank Hellweg, Melanie Schmidt, and Christian Sohler. Testing Euclidean Spanners. Property Testing, 6390:306\u2013311, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hellweg%2C%20Frank%20Schmidt%2C%20Melanie%20Sohler%2C%20Christian%20Testing%20Euclidean%20Spanners%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hellweg%2C%20Frank%20Schmidt%2C%20Melanie%20Sohler%2C%20Christian%20Testing%20Euclidean%20Spanners%202010"
        },
        {
            "id": "23",
            "entry": "[23] Piotr Indyk and Rajeev Motwani. Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. In Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, STOC, pages 604\u2013613. ACM, 1998. doi: 10.1145/276698.276876.",
            "crossref": "https://dx.doi.org/10.1145/276698.276876",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/276698.276876"
        },
        {
            "id": "24",
            "entry": "[24] Grigorii Anatol\u2019evich Kabatiansky and Vladimir Iosifovich Levenshtein. On Bounds for Packings on a Sphere and in Space. Problemy Peredachi Informatsii, 14(1):3\u201325, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Grigorii%20Anatol%E2%80%99evich%20Kabatiansky%20and%20Vladimir%20Iosifovich%20Levenshtein.%20On%20Bounds%20for%20Packings%20on%20a%20Sphere%20and%20in%20Space%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Grigorii%20Anatol%E2%80%99evich%20Kabatiansky%20and%20Vladimir%20Iosifovich%20Levenshtein.%20On%20Bounds%20for%20Packings%20on%20a%20Sphere%20and%20in%20Space%201978"
        },
        {
            "id": "25",
            "entry": "[25] Yann LeCun, Corinna Cortes, and Chris Burges. MNIST Handwritten Digit Database, 2018. URL http://yann.lecun.com/exdb/mnist/.",
            "url": "http://yann.lecun.com/exdb/mnist/",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yann%20LeCun%20Corinna%20Cortes%20and%20Chris%20Burges%20MNIST%20Handwritten%20Digit%20Database%202018%20URL%20httpyannlecuncomexdbmnist"
        },
        {
            "id": "26",
            "entry": "[26] Jesus Maillo, Sergio Ram\u00edrez, Isaac Triguero, and Francisco Herrera. kNN-IS: An Iterative Spark-Based Design of the k-Nearest Neighbors Classifier for Big Data. Knowledge-Based Systems, 117:3\u201315, 2017. doi: 10.1016/j.knosys.2016.06.012.",
            "crossref": "https://dx.doi.org/10.1016/j.knosys.2016.06.012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.knosys.2016.06.012"
        },
        {
            "id": "27",
            "entry": "[27] Marius Muja and David G. Lowe. Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration. In In VISAPP International Conference on Computer Vision Theory and Applications, pages 331\u2013340, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Muja%2C%20Marius%20Lowe%2C%20David%20G.%20Fast%20Approximate%20Nearest%20Neighbors%20with%20Automatic%20Algorithm%20Configuration%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muja%2C%20Marius%20Lowe%2C%20David%20G.%20Fast%20Approximate%20Nearest%20Neighbors%20with%20Automatic%20Algorithm%20Configuration%202009"
        },
        {
            "id": "28",
            "entry": "[28] Bilegsaikhan Naidan, Leonid Boytsov, Yury Malkov, David Novak, and Ben Frederickson. Non-Metric Space Library (NMSLIB): An Efficient Similarity Search Library and a Toolkit for Evaluation of k-NN Methods for Generic Non-Metric Spaces, 2018. URL https://github.com/nmslib/nmslib.",
            "url": "https://github.com/nmslib/nmslib"
        },
        {
            "id": "29",
            "entry": "[29] Michal Parnas and Dana Ron. Testing Metric Properties. In 33rd Annual ACM Symposium on Theory of Computing, STOC, pages 276\u2013285. ACM, 2001. doi: 10.1145/380752.380811.",
            "crossref": "https://dx.doi.org/10.1145/380752.380811",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/380752.380811"
        },
        {
            "id": "30",
            "entry": "[30] Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and Edouard Duchesnay. Scikit-Learn: Machine Learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011. ISSN 1533-7928. URL http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html.",
            "url": "http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pedregosa%2C%20Fabian%20Varoquaux%2C%20Gael%20Gramfort%2C%20Alexandre%20Michel%2C%20Vincent%20ISSN%201533-7928%202011"
        },
        {
            "id": "31",
            "entry": "[31] Zalando Research. Fashion-MNIST: A MNIST-like Fashion Product Database, 2018. URL https://github.com/zalandoresearch/fashion-mnist.",
            "url": "https://github.com/zalandoresearch/fashion-mnist",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Research%2C%20Zalando%20Fashion-MNIST%3A%20A%20MNIST-like%20Fashion%20Product%202018"
        },
        {
            "id": "32",
            "entry": "[32] Ronitt Rubinfeld and Madhu Sudan. Robust Characterizations of Polynomials with Applications to Program Testing. SIAM Journal on Computing, 25(2):252\u2013271, 1996. doi: 10.1137/ S0097539793255151.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rubinfeld%2C%20Ronitt%20Sudan%2C%20Madhu%20Robust%20Characterizations%20of%20Polynomials%20with%20Applications%20to%20Program%20Testing%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rubinfeld%2C%20Ronitt%20Sudan%2C%20Madhu%20Robust%20Characterizations%20of%20Polynomials%20with%20Applications%20to%20Program%20Testing%201996"
        },
        {
            "id": "33",
            "entry": "[33] Gregory Shakhnarovich, Trevor Darrell, and Piotr Indyk, editors. Nearest-Neighbor Methods in Learning and Vision: Theory and Practice. Neural Information Processing Series. MIT Press, 2006. ISBN 0-262-19547-X.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gregory%20Shakhnarovich%20Trevor%20Darrell%20and%20Piotr%20Indyk%20editors%20NearestNeighbor%20Methods%20in%20Learning%20and%20Vision%20Theory%20and%20Practice%20Neural%20Information%20Processing%20Series%20MIT%20Press%202006%20ISBN%20026219547X",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gregory%20Shakhnarovich%20Trevor%20Darrell%20and%20Piotr%20Indyk%20editors%20NearestNeighbor%20Methods%20in%20Learning%20and%20Vision%20Theory%20and%20Practice%20Neural%20Information%20Processing%20Series%20MIT%20Press%202006%20ISBN%20026219547X"
        },
        {
            "id": "34",
            "entry": "[34] Aaron D. Wyner. Capabilities of Bounded Discrepancy Decoding. Bell System Technical Journal, 44(6):1061\u20131122, 1965.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wyner%2C%20Aaron%20D.%20Capabilities%20of%20Bounded%20Discrepancy%20Decoding%201965",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wyner%2C%20Aaron%20D.%20Capabilities%20of%20Bounded%20Discrepancy%20Decoding%201965"
        },
        {
            "id": "35",
            "entry": "[35] Kenneth Zeger and Allen Gersho. Number of Nearest Neighbors in a Euclidean Code. IEEE Transactions on Information Theory, 40(5):1647\u20131649, 1994-09. doi: 10.1109/18.333884.",
            "crossref": "https://dx.doi.org/10.1109/18.333884",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/18.333884"
        },
        {
            "id": "36",
            "entry": "[36] Shichao Zhang, Xuelong Li, Ming Zong, Xiaofeng Zhu, and Ruili Wang. Efficient kNN Classification with Different Numbers of Nearest Neighbors. IEEE Transactions on Neural Networks and Learning Systems, 29(5):1774\u20131785, 2018. doi: 10.1109/TNNLS.2017.2673241. ",
            "crossref": "https://dx.doi.org/10.1109/TNNLS.2017.2673241",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TNNLS.2017.2673241"
        }
    ]
}
