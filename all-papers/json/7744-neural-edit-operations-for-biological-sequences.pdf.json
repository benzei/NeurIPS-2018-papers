{
    "filename": "7744-neural-edit-operations-for-biological-sequences.pdf",
    "metadata": {
        "title": "Neural Edit Operations for Biological Sequences",
        "author": "Satoshi Koide, Keisuke Kawano, Takuro Kutsuna",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7744-neural-edit-operations-for-biological-sequences.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "The evolution of biological sequences, such as proteins or DNAs, is driven by the three basic edit operations: substitution, insertion, and deletion. Motivated by the recent progress of neural network models for biological tasks, we implement two neural network architectures that can treat such edit operations. The first proposal is the edit invariant neural networks, based on differentiable NeedlemanWunsch algorithms. The second is the use of deep CNNs with concatenations. Our analysis shows that CNNs can recognize star-free regular expressions, and that deeper CNNs can recognize more complex regular expressions including the insertion/deletion of characters. The experimental results for the protein secondary structure prediction task suggest the importance of insertion/deletion. The test accuracy on the widely-used CB513 dataset is 71.5%, which is 1.2-points better than the current best result on non-ensemble models."
    },
    "keywords": [
        {
            "term": "regular expression",
            "url": "https://en.wikipedia.org/wiki/regular_expression"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "connectionist temporal classification",
            "url": "https://en.wikipedia.org/wiki/connectionist_temporal_classification"
        },
        {
            "term": "Dynamic time warping",
            "url": "https://en.wikipedia.org/wiki/Dynamic_time_warping"
        }
    ],
    "highlights": [
        "Neural networks are used in many applications, not limited to classical fields such as image processing, speech recognition, and natural language processing",
        "We investigate the effect of Edit Invariant Neural Networks using simplified models and datasets",
        "Figure 6 (a) shows the Tiny-CNN while the Tiny-Edit Invariant Neural Networks is obtained by replacing the Conv-5 layers with the Edit Invariant Neural Networks convolutional layer proposed in Section 2",
        "We report the CB513 accuracy at epoch 30",
        "We proposed Edit Invariant Neural Networks that consisted of differentiable NW algorithm modules",
        "For the protein secondary structure prediction task on the CB513 test dataset, the accuracy of our deep CNN was better than the current best result among the non-ensemble models"
    ],
    "key_statements": [
        "Neural networks are used in many applications, not limited to classical fields such as image processing, speech recognition, and natural language processing",
        "We propose the edit invariant neural networks",
        "We introduce star-free regular expressions from the formal language theory, which is a subset of the standard regular expressions",
        "We have shown how to treat insertion and deletion of characters in a string, which is expected to be important for biological tasks",
        "We investigate the effect of Edit Invariant Neural Networks using simplified models and datasets",
        "Figure 6 (a) shows the Tiny-CNN while the Tiny-Edit Invariant Neural Networks is obtained by replacing the Conv-5 layers with the Edit Invariant Neural Networks convolutional layer proposed in Section 2",
        "We report the CB513 accuracy at epoch 30",
        "We proposed Edit Invariant Neural Networks that consisted of differentiable NW algorithm modules",
        "For the protein secondary structure prediction task on the CB513 test dataset, the accuracy of our deep CNN was better than the current best result among the non-ensemble models"
    ],
    "summary": [
        "Neural networks are used in many applications, not limited to classical fields such as image processing, speech recognition, and natural language processing.",
        "We discussed a differentiable sequence alignment, EINN, to render the neural networks edit invariant.",
        "The following are the star-free regular expressions: 1) Empty set \u2205; 2) Empty string \u03b5; 3) A single character \u2200a \u2208 \u03a3.",
        "The following sets of strings are star-free regular expressions.",
        "We can confirm that the sets of strings represented by the two motifs mentioned above are the star-free regular expressions.",
        "The recognizer for a regular expression /ac/ can be emulated by a 1d-convolutional layer of kernel size k = 3 consisting of w2 = and b2 = \u22121 (Fig. 2).",
        "Given a star-free regular expression R, we can construct a two-layered convolutional network that accepts R .",
        "Given a star-free regular expression R, there exists a CNN that can verify whether a given string x matches R for each position of x.",
        "According to Proposition 2, shallow yet wide neural networks can recognize an arbitrary star-free regular expression R.",
        "We first showed that even shallow CNNs can treat star-free regular expressions in principle (Proposition 2).",
        "We discuss the advantages and disadvantages of EINNs and CNNs. CNNs and EINNs. In the previous sections, we have shown how to treat insertion and deletion of characters in a string, which is expected to be important for biological tasks.",
        "If the target regular expression involves many insertions and deletions, the number of convolutional filters required to represent it will increase rapidly.",
        "We focus on CNNs and reveal the relationship to star-free regular expressions (Section 3).",
        "We will demonstrate that for protein structure prediction, it is important to adopt network architectures that consider insertions/deletions, as we have discussed previously.",
        "To investigate the effect of the EINNs, we replace the convolutions shaded in Fig. 6 (b) in the first ConvBlock with EINNs of the same filter and kernel sizes.",
        "We investigate how network architecture affects performance by replacing the ConvBlock with the modified ConvBlock (Fig. 6 (c)), which involves convolutional layers with concatenations.",
        "We discussed how to make neural networks edit-invariant, a new important feature for ML tasks for biological sequences.",
        "We discussed that sufficiently deep CNNs with concatenation could emulate complex star-free regular expressions.",
        "For the protein secondary structure prediction task on the CB513 test dataset, the accuracy of our deep CNN was better than the current best result among the non-ensemble models."
    ],
    "headline": "We propose the edit invariant neural networks",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] S. Altschul, W. Gish, W. Miller, E. Myers, and D. Lipman. Basic local alignment search tool. Journal of Molecular Biology, 215:403\u2013410, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Altschul%2C%20S.%20Gish%2C%20W.%20Miller%2C%20W.%20Myers%2C%20E.%20Basic%20local%20alignment%20search%20tool%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Altschul%2C%20S.%20Gish%2C%20W.%20Miller%2C%20W.%20Myers%2C%20E.%20Basic%20local%20alignment%20search%20tool%201990"
        },
        {
            "id": "2",
            "entry": "[2] A. Busia and N. Jaitly. Next-Step Conditioned Deep Convolutional Neural Networks Improve Protein Secondary Structure Prediction. CoRR, abs/1702.03865, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.03865"
        },
        {
            "id": "3",
            "entry": "[3] M. Cuturi and M. Blondel. Soft-DTW: a Differentiable Loss Function for Time-Series. In Proc. ICML\u201917, pages 894\u2013903, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cuturi%2C%20M.%20M.%20Blondel.%20Soft-DTW%3A%20a%20Differentiable%20Loss%20Function%20for%20Time-Series%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cuturi%2C%20M.%20M.%20Blondel.%20Soft-DTW%3A%20a%20Differentiable%20Loss%20Function%20for%20Time-Series%202017"
        },
        {
            "id": "4",
            "entry": "[4] P. Di lena, K. Nagata, and P. Baldi. Deep architectures for protein contact map prediction. Bioinformatics, 28(19):2449\u20132457, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=lena%2C%20P.Di%20Nagata%2C%20K.%20Baldi%2C%20P.%20Deep%20architectures%20for%20protein%20contact%20map%20prediction%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=lena%2C%20P.Di%20Nagata%2C%20K.%20Baldi%2C%20P.%20Deep%20architectures%20for%20protein%20contact%20map%20prediction%202012"
        },
        {
            "id": "5",
            "entry": "[5] H. Ding, G. Trajcevski, P. Scheuermann, X. Wang, and E. Keogh. Querying and mining of time series data: experimental comparison of representations and distance measures. Proceedings of the VLDB Endowment, 1(2):1542\u20131552, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ding%2C%20H.%20Trajcevski%2C%20G.%20Scheuermann%2C%20P.%20Wang%2C%20X.%20Querying%20and%20mining%20of%20time%20series%20data%3A%20experimental%20comparison%20of%20representations%20and%20distance%20measures%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ding%2C%20H.%20Trajcevski%2C%20G.%20Scheuermann%2C%20P.%20Wang%2C%20X.%20Querying%20and%20mining%20of%20time%20series%20data%3A%20experimental%20comparison%20of%20representations%20and%20distance%20measures%202008"
        },
        {
            "id": "6",
            "entry": "[6] M. L. Forcada and R. C. Carrasco. Finite-State Computation in Analog Neural Networks: Steps towards Biologically Plausible Models? Emergent neural computational architectures based on neuroscience, pages 480\u2013493, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Forcada%2C%20M.L.%20Carrasco%2C%20R.C.%20Finite-State%20Computation%20in%20Analog%20Neural%20Networks%3A%20Steps%20towards%20Biologically%20Plausible%20Models%3F%20Emergent%20neural%20computational%20architectures%20based%20on%20neuroscience%202001"
        },
        {
            "id": "7",
            "entry": "[7] K. Fukushima. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics, 36(4):193\u2013202, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fukushima%2C%20K.%20Neocognitron%3A%20A%20self-organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern%20recognition%20unaffected%20by%20shift%20in%20position%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fukushima%2C%20K.%20Neocognitron%3A%20A%20self-organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern%20recognition%20unaffected%20by%20shift%20in%20position%201980"
        },
        {
            "id": "8",
            "entry": "[8] F. A. Gers and J. Schmidhuber. LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages. IEEE Transactions on Neural Networks, 12(6):1333\u20131340, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gers%2C%20F.A.%20Schmidhuber%2C%20J.%20LSTM%20Recurrent%20Networks%20Learn%20Simple%20Context%20Free%20and%20Context%20Sensitive%20Languages%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gers%2C%20F.A.%20Schmidhuber%2C%20J.%20LSTM%20Recurrent%20Networks%20Learn%20Simple%20Context%20Free%20and%20Context%20Sensitive%20Languages%202001"
        },
        {
            "id": "9",
            "entry": "[9] V. Golkov, M. J. Skwark, A. Golkov, A. Dosovitskiy, T. Brox, J. Meiler, and D. Cremers. Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images. In Proc. NIPS\u201916, pages 4222\u20134230. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Golkov%2C%20V.%20Skwark%2C%20M.J.%20Golkov%2C%20A.%20Dosovitskiy%2C%20A.%20Protein%20contact%20prediction%20from%20amino%20acid%20co-evolution%20using%20convolutional%20networks%20for%20graph-valued%20images%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Golkov%2C%20V.%20Skwark%2C%20M.J.%20Golkov%2C%20A.%20Dosovitskiy%2C%20A.%20Protein%20contact%20prediction%20from%20amino%20acid%20co-evolution%20using%20convolutional%20networks%20for%20graph-valued%20images%202017"
        },
        {
            "id": "10",
            "entry": "[10] A. Graves, S. Fernandez, F. Gomez, and J. Schmidhuber. Connectionist Temporal Classification : Labelling Unsegmented Sequence Data with Recurrent Neural Networks. In Proc. ICML\u201906, pages 369\u2013376, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Fernandez%2C%20S.%20F.%20Connectionist%20Temporal%20Classification%20%3A%20Labelling%20Unsegmented%20Sequence%20Data%20with%20Recurrent%20Neural%20Networks%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20A.%20Fernandez%2C%20S.%20F.%20Connectionist%20Temporal%20Classification%20%3A%20Labelling%20Unsegmented%20Sequence%20Data%20with%20Recurrent%20Neural%20Networks%202006"
        },
        {
            "id": "11",
            "entry": "[11] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proc. CVPR\u201916, pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "12",
            "entry": "[12] G. Huang, Z. Liu, L. v. d. Maaten, and K. Q. Weinberger. Densely Connected Convolutional Networks. In Proc. CVPR\u201917, pages 2261\u20132269, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20G.%20Liu%2C%20Z.%20v.%20d.%20Maaten%2C%20L.%20Weinberger%2C%20K.Q.%20Densely%20Connected%20Convolutional%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20G.%20Liu%2C%20Z.%20v.%20d.%20Maaten%2C%20L.%20Weinberger%2C%20K.Q.%20Densely%20Connected%20Convolutional%20Networks%202017"
        },
        {
            "id": "13",
            "entry": "[13] D. R. Kelley, J. Snoek, and J. L. Rinn. Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks. Genome research, 26(7):990\u20139, Jul. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kelley%2C%20D.R.%20Snoek%2C%20J.%20Rinn%2C%20J.L.%20Basset%3A%20learning%20the%20regulatory%20code%20of%20the%20accessible%20genome%20with%20deep%20convolutional%20neural%20networks%202016-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kelley%2C%20D.R.%20Snoek%2C%20J.%20Rinn%2C%20J.L.%20Basset%3A%20learning%20the%20regulatory%20code%20of%20the%20accessible%20genome%20with%20deep%20convolutional%20neural%20networks%202016-07"
        },
        {
            "id": "14",
            "entry": "[14] Z. Li and Y. Yu. Protein Secondary Structure Prediction Using Cascaded Convolutional and Recurrent Neural Networks. In Proc. IJCAI\u201916, pages 2560\u20132567, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Z.%20Yu%2C%20Y.%20Protein%20Secondary%20Structure%20Prediction%20Using%20Cascaded%20Convolutional%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Z.%20Yu%2C%20Y.%20Protein%20Secondary%20Structure%20Prediction%20Using%20Cascaded%20Convolutional%202016"
        },
        {
            "id": "15",
            "entry": "[15] Z. Lin, J. Lanchantin, and Y. Qi. MUST-CNN: A Multilayer Shift-and-Stitch Deep Convolutional Architecture for Sequence-based Protein Structure Prediction. In Proc. AAAI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Z.%20Lanchantin%2C%20J.%20Qi%2C%20Y.%20MUST-CNN%3A%20A%20Multilayer%20Shift-and-Stitch%20Deep%20Convolutional%20Architecture%20for%20Sequence-based%20Protein%20Structure%20Prediction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Z.%20Lanchantin%2C%20J.%20Qi%2C%20Y.%20MUST-CNN%3A%20A%20Multilayer%20Shift-and-Stitch%20Deep%20Convolutional%20Architecture%20for%20Sequence-based%20Protein%20Structure%20Prediction%202016"
        },
        {
            "id": "16",
            "entry": "[16] C. N. Magnan and P. Baldi. SSpro/ACCpro 5: Almost perfect prediction of protein secondary structure and relative solvent accessibility using profiles, machine learning and structural similarity. Bioinformatics, 30(18):2592\u20132597, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Magnan%2C%20C.N.%20Baldi%2C%20P.%20SSpro/ACCpro%205%3A%20Almost%20perfect%20prediction%20of%20protein%20secondary%20structure%20and%20relative%20solvent%20accessibility%20using%20profiles%2C%20machine%20learning%20and%20structural%20similarity%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Magnan%2C%20C.N.%20Baldi%2C%20P.%20SSpro/ACCpro%205%3A%20Almost%20perfect%20prediction%20of%20protein%20secondary%20structure%20and%20relative%20solvent%20accessibility%20using%20profiles%2C%20machine%20learning%20and%20structural%20similarity%202014"
        },
        {
            "id": "17",
            "entry": "[17] M. Minsky. Computation : finite and infinite machines. Prentice-Hall, 1967.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M.%20Minsky.%20Computation%20%3A%20finite%20and%20infinite%20machines%201967"
        },
        {
            "id": "18",
            "entry": "[18] S. Needleman and C. Wunsch. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48(3):443\u2013453, 3 1970.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Needleman%2C%20S.%20Wunsch%2C%20C.%20A%20general%20method%20applicable%20to%20the%20search%20for%20similarities%20in%20the%20amino%20acid%20sequence%20of%20two%20proteins%201970",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Needleman%2C%20S.%20Wunsch%2C%20C.%20A%20general%20method%20applicable%20to%20the%20search%20for%20similarities%20in%20the%20amino%20acid%20sequence%20of%20two%20proteins%201970"
        },
        {
            "id": "19",
            "entry": "[19] J. Peng, L. Bo, and J. Xu. Conditional Neural Fields. In Proc. NIPS\u201909, pages 1419\u20131427, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=J%20Peng%20L%20Bo%20and%20J%20Xu%20Conditional%20Neural%20Fields%20In%20Proc%20NIPS09%20pages%2014191427%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=J%20Peng%20L%20Bo%20and%20J%20Xu%20Conditional%20Neural%20Fields%20In%20Proc%20NIPS09%20pages%2014191427%202009"
        },
        {
            "id": "20",
            "entry": "[20] Y. Qi, M. Oja, J. Weston, and W. S. Noble. A unified multitask architecture for predicting local protein properties. PLoS ONE, 7(3), 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Qi%2C%20Y.%20Oja%2C%20M.%20Weston%2C%20J.%20Noble%2C%20W.S.%20A%20unified%20multitask%20architecture%20for%20predicting%20local%20protein%20properties%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Qi%2C%20Y.%20Oja%2C%20M.%20Weston%2C%20J.%20Noble%2C%20W.S.%20A%20unified%20multitask%20architecture%20for%20predicting%20local%20protein%20properties%202012"
        },
        {
            "id": "21",
            "entry": "[21] H. Saigo, J.-P. Vert, and T. Akutsu. Optimizing amino acid substitution matrices with a local alignment kernel. BMC bioinformatics, 7:246, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saigo%2C%20H.%20Vert%2C%20J.-P.%20Akutsu%2C%20T.%20Optimizing%20amino%20acid%20substitution%20matrices%20with%20a%20local%20alignment%20kernel%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saigo%2C%20H.%20Vert%2C%20J.-P.%20Akutsu%2C%20T.%20Optimizing%20amino%20acid%20substitution%20matrices%20with%20a%20local%20alignment%20kernel%202006"
        },
        {
            "id": "22",
            "entry": "[22] H. Sakoe and S. Chiba. Dynamic programming algorithm optimization for spoken word recognition. IEEE Transactions on Acoustics, Speech, and Signal Processing, 26(1):43\u201349, Feb. 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sakoe%2C%20H.%20Chiba%2C%20S.%20Dynamic%20programming%20algorithm%20optimization%20for%20spoken%20word%20recognition%201978-02",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sakoe%2C%20H.%20Chiba%2C%20S.%20Dynamic%20programming%20algorithm%20optimization%20for%20spoken%20word%20recognition%201978-02"
        },
        {
            "id": "23",
            "entry": "[23] T. F. Smith and M. S. Waterman. Identification of common molecular subsequences. Journal of molecular biology, 147(1):195\u20137, Mar. 1981.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20T.F.%20Waterman%2C%20M.S.%20Identification%20of%20common%20molecular%20subsequences%201981-03",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smith%2C%20T.F.%20Waterman%2C%20M.S.%20Identification%20of%20common%20molecular%20subsequences%201981-03"
        },
        {
            "id": "24",
            "entry": "[24] O. W. S\u00f8ren Kaae S\u00f8nderby. Protein secondary structure prediction with long short term memory networks. In arXiv:1412.7828, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1412.7828"
        },
        {
            "id": "25",
            "entry": "[25] S. Wang, J. Peng, J. Ma, and J. Xu. Protein Secondary Structure Prediction Using Deep Convolutional Neural Fields. Scientific reports, 6(18962), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20S.%20Peng%2C%20J.%20Ma%2C%20J.%20Xu%2C%20J.%20Protein%20Secondary%20Structure%20Prediction%20Using%20Deep%20Convolutional%20Neural%20Fields%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20S.%20Peng%2C%20J.%20Ma%2C%20J.%20Xu%2C%20J.%20Protein%20Secondary%20Structure%20Prediction%20Using%20Deep%20Convolutional%20Neural%20Fields%202016"
        },
        {
            "id": "26",
            "entry": "[26] D. E. Worrall, S. J. Garbin, D. Turmukhambetov, and G. J. Brostow. Harmonic Networks: Deep Translation and Rotation Equivariance. In Proc. CVPR\u201917, pages 5028\u20135037, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Worrall%2C%20D.E.%20Garbin%2C%20S.J.%20Turmukhambetov%2C%20D.%20Brostow%2C%20G.J.%20Harmonic%20Networks%3A%20Deep%20Translation%20and%20Rotation%20Equivariance%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Worrall%2C%20D.E.%20Garbin%2C%20S.J.%20Turmukhambetov%2C%20D.%20Brostow%2C%20G.J.%20Harmonic%20Networks%3A%20Deep%20Translation%20and%20Rotation%20Equivariance%202017"
        },
        {
            "id": "27",
            "entry": "[27] J. Zhou and O. G. Troyanskaya. Deep supervised and convolutional generative stochastic network for protein secondary structure prediction. In Proc. ICML\u201914, pages 745\u2013753, 2014. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20J.%20Troyanskaya%2C%20O.G.%20Deep%20supervised%20and%20convolutional%20generative%20stochastic%20network%20for%20protein%20secondary%20structure%20prediction%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20J.%20Troyanskaya%2C%20O.G.%20Deep%20supervised%20and%20convolutional%20generative%20stochastic%20network%20for%20protein%20secondary%20structure%20prediction%202014"
        }
    ]
}
