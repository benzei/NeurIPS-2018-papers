{
    "filename": "7302-fast-similarity-search-via-optimal-sparse-lifting.pdf",
    "metadata": {
        "title": "Fast Similarity Search via Optimal Sparse Lifting",
        "author": "Wenye Li, Jingwei Mao, Yin Zhang, Shuguang Cui",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7302-fast-similarity-search-via-optimal-sparse-lifting.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Similarity search is a fundamental problem in computing science with various applications and has attracted significant research attention, especially in largescale search with high dimensions. Motivated by the evidence in biological science, our work develops a novel approach for similarity search. Fundamentally different from existing methods that typically reduce the dimension of the data to lessen the computational complexity and speed up the search, our approach projects the data into an even higher-dimensional space while ensuring the sparsity of the data in the output space, with the objective of further improving precision and speed. Specifically, our approach has two key steps. Firstly, it computes the optimal sparse lifting for given input samples and increases the dimension of the data while approximately preserving their pairwise similarity. Secondly, it seeks the optimal lifting operator that maps input samples to the optimal sparse lifting. Computationally, both steps are modeled as optimization problems that can be efficiently and effectively solved by the Frank-Wolfe algorithm. Simple as it is, our approach reported significantly improved results in empirical evaluations, and exhibited its high potentials in solving practical problems."
    },
    "keywords": [
        {
            "term": "computational complexity",
            "url": "https://en.wikipedia.org/wiki/computational_complexity"
        },
        {
            "term": "similarity search",
            "url": "https://en.wikipedia.org/wiki/similarity_search"
        },
        {
            "term": "frank wolfe",
            "url": "https://en.wikipedia.org/wiki/Frank_Wolfe"
        },
        {
            "term": "locality sensitive hashing",
            "url": "https://en.wikipedia.org/wiki/locality_sensitive_hashing"
        },
        {
            "term": "information retrieval",
            "url": "https://en.wikipedia.org/wiki/information_retrieval"
        },
        {
            "term": "pattern classification",
            "url": "https://en.wikipedia.org/wiki/pattern_classification"
        }
    ],
    "highlights": [
        "Similarity search refers to the problem of finding a subset of objects which are similar to a given query from a specific dataset",
        "Comparing with the locality sensitive hashing method, similarity search based on the sparse binary vectors has reported improved precision and speed in a series of empirical studies [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>]",
        "Feature vectors of a dataset are lifted to sparse binary vectors in a higher-dimensional space, and feature values are replaced by their \u201chigh energy concentration\u201d locations that are encoded in the sparse binary vectors",
        "Instead of performing sparse lifting randomly, we showed that when some prior information is available, a designed projection matrix can outperform a randomized one, resulting in the so-called sparse lifting framework",
        "Our proof-of-concept experiments in similarity search indicate that the proposed optimal sparse lifting approach can significantly outperform, in terms of accuracy, the random sparse lifting and the locality sensitive hashing methods"
    ],
    "key_statements": [
        "Similarity search refers to the problem of finding a subset of objects which are similar to a given query from a specific dataset",
        "Comparing with the locality sensitive hashing method, similarity search based on the sparse binary vectors has reported improved precision and speed in a series of empirical studies [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>]",
        "Our work provides a practical solution for similarity search",
        "Feature vectors of a dataset are lifted to sparse binary vectors in a higher-dimensional space, and feature values are replaced by their \u201chigh energy concentration\u201d locations that are encoded in the sparse binary vectors",
        "Instead of performing sparse lifting randomly, we showed that when some prior information is available, a designed projection matrix can outperform a randomized one, resulting in the so-called sparse lifting framework",
        "Our proof-of-concept experiments in similarity search indicate that the proposed optimal sparse lifting approach can significantly outperform, in terms of accuracy, the random sparse lifting and the locality sensitive hashing methods"
    ],
    "summary": [
        "Similarity search refers to the problem of finding a subset of objects which are similar to a given query from a specific dataset.",
        "The fly algorithm projects each input data sample to a higher-dimensional output space with a randomly generated sparse binary matrix.",
        "Comparing with the locality sensitive hashing method, similarity search based on the sparse binary vectors has reported improved precision and speed in a series of empirical studies [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>].",
        "Sparse lifting is a sparse binary vector representation of the input data in a higher-dimensional space, such that the pairwise similarity between input data samples can be roughly preserved.",
        "The fly algorithm uses a randomly generated data transform matrix W that maps the dense input X to W X in a higher-dimensional space, followed by a sparsification and binarization process.",
        "The fly algorithm randomly generates the projection matrix W and can be regarded as a random lifting method.",
        "With the same set of input images, we normalized each vector Xi to be of length ki where ki is the number of light pixels in Gi. We computed the optimal lifting of these images in an 80 \u00d7 80-dimensional output space by Algorithm 1.",
        "The second experiment aimed to evaluate the performance of the proposed optimal lifting framework in similarity search applications by comparing its accuracies against the fly and related algorithms.",
        "Sparse binary vectors of these training samples were firstly generated with Algorithm 1 and used to train the optimal lifting operator W\u2217.",
        "The autoencoder algorithm was trained with the same samples as our optimal lifting approach.",
        "For the fly and the optimal lifting algorithms, the output dimensions are set to d = 20k and d = 2, 000 respectively.",
        "It can be seen that the output vectors generated from the optimal lifting approach outperformed the vectors from fly and",
        "On SIFT and MNIST datasets, it can be seen that, when the hash length is small (k = 2, 4, 8), the improvement of optimal lifting is still evident.",
        "On SIFT dataset with d = 128 dimensions, the autoencoder reported slightly higher precision than our optimal lifting approach on the hash length k = 32.",
        "On 20 \u00d7 k output dimensions, our approach runs magnitude faster than the autoencoder algorithm on all hash lengths.",
        "We reported the total query time on the output vectors of the LSH, autoencoder and optimal lifting algorithms respectively.",
        "Our proof-of-concept experiments in similarity search indicate that the proposed optimal sparse lifting approach can significantly outperform, in terms of accuracy, the random sparse lifting and the locality sensitive hashing methods."
    ],
    "headline": "Motivated by the evidence in biological science, our work develops a novel approach for similarity search",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] D. Achlioptas. Database-friendly random projections: Johnson-Lindenstrauss with binary coins. Journal of Computer and System Sciences, 66(4):671\u2013687, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Achlioptas%2C%20D.%20Database-friendly%20random%20projections%3A%20Johnson-Lindenstrauss%20with%20binary%20coins%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Achlioptas%2C%20D.%20Database-friendly%20random%20projections%3A%20Johnson-Lindenstrauss%20with%20binary%20coins%202003"
        },
        {
            "id": "2",
            "entry": "[2] Z. Allen-Zhu, R. Gelashvili, S. Micali, and N. Shavit. Sparse sign-consistent johnson\u2013lindenstrauss matrices: Compression with neuroscience-based constraints. Proceedings of the National Academy of Sciences, 111(47):16872\u201316876, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allen-Zhu%2C%20Z.%20Gelashvili%2C%20R.%20Micali%2C%20S.%20Shavit%2C%20N.%20Sparse%20sign-consistent%20johnson%E2%80%93lindenstrauss%20matrices%3A%20Compression%20with%20neuroscience-based%20constraints%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allen-Zhu%2C%20Z.%20Gelashvili%2C%20R.%20Micali%2C%20S.%20Shavit%2C%20N.%20Sparse%20sign-consistent%20johnson%E2%80%93lindenstrauss%20matrices%3A%20Compression%20with%20neuroscience-based%20constraints%202014"
        },
        {
            "id": "3",
            "entry": "[3] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In 47th Annual IEEE Symposium on Foundations of Computer Science, pages 459\u2013468. IEEE, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andoni%2C%20A.%20Indyk%2C%20P.%20Near-optimal%20hashing%20algorithms%20for%20approximate%20nearest%20neighbor%20in%20high%20dimensions%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andoni%2C%20A.%20Indyk%2C%20P.%20Near-optimal%20hashing%20algorithms%20for%20approximate%20nearest%20neighbor%20in%20high%20dimensions%202006"
        },
        {
            "id": "4",
            "entry": "[4] A. Andoni and I. Razenshteyn. Optimal data-dependent hashing for approximate near neighbors. In Proceedings of the 47th Annual ACM Symposium on Theory of Computing, pages 793\u2013801. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andoni%2C%20A.%20Razenshteyn%2C%20I.%20Optimal%20data-dependent%20hashing%20for%20approximate%20near%20neighbors%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andoni%2C%20A.%20Razenshteyn%2C%20I.%20Optimal%20data-dependent%20hashing%20for%20approximate%20near%20neighbors%202015"
        },
        {
            "id": "5",
            "entry": "[5] R. Baeza-Yates and B. Ribeiro-Neto. Modern information retrieval, volume 463. ACM press New York, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baeza-Yates%2C%20R.%20Ribeiro-Neto%2C%20B.%20Modern%20information%20retrieval%2C%20volume%20463%201999"
        },
        {
            "id": "6",
            "entry": "[6] S. Caron, V. Ruta, L. Abbott, and R. Axel. Random convergence of olfactory inputs in the drosophila mushroom body. Nature, 497(7447):113, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caron%2C%20S.%20Ruta%2C%20V.%20Abbott%2C%20L.%20Axel%2C%20R.%20Random%20convergence%20of%20olfactory%20inputs%20in%20the%20drosophila%20mushroom%20body%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caron%2C%20S.%20Ruta%2C%20V.%20Abbott%2C%20L.%20Axel%2C%20R.%20Random%20convergence%20of%20olfactory%20inputs%20in%20the%20drosophila%20mushroom%20body%202013"
        },
        {
            "id": "7",
            "entry": "[7] M. Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings of the 34th Annual ACM Symposium on Theory of Computing, pages 380\u2013388. ACM, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charikar%2C%20M.%20Similarity%20estimation%20techniques%20from%20rounding%20algorithms%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charikar%2C%20M.%20Similarity%20estimation%20techniques%20from%20rounding%20algorithms%202002"
        },
        {
            "id": "8",
            "entry": "[8] S. Dasgupta, C. Stevens, and S. Navlakha. A neural algorithm for a fundamental computing problem. Science, 358(6364):793\u2013796, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dasgupta%2C%20S.%20Stevens%2C%20C.%20Navlakha%2C%20S.%20A%20neural%20algorithm%20for%20a%20fundamental%20computing%20problem%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dasgupta%2C%20S.%20Stevens%2C%20C.%20Navlakha%2C%20S.%20A%20neural%20algorithm%20for%20a%20fundamental%20computing%20problem%202017"
        },
        {
            "id": "9",
            "entry": "[9] R. Duda, P. Hart, and D. Stork. Pattern classification. John Wiley & Sons, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duda%2C%20R.%20Hart%2C%20P.%20Stork%2C%20D.%20Pattern%20classification%202012"
        },
        {
            "id": "10",
            "entry": "[10] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics (NRL), 3(1-2):95\u2013110, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Frank%2C%20M.%20Wolfe%2C%20P.%20An%20algorithm%20for%20quadratic%20programming%201956",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Frank%2C%20M.%20Wolfe%2C%20P.%20An%20algorithm%20for%20quadratic%20programming%201956"
        },
        {
            "id": "11",
            "entry": "[11] A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In VLDB, volume 99, pages 518\u2013529, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gionis%2C%20A.%20Indyk%2C%20P.%20Motwani%2C%20R.%20Similarity%20search%20in%20high%20dimensions%20via%20hashing%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gionis%2C%20A.%20Indyk%2C%20P.%20Motwani%2C%20R.%20Similarity%20search%20in%20high%20dimensions%20via%20hashing%201999"
        },
        {
            "id": "12",
            "entry": "[12] G. Hinton and R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504\u2013507, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20G.%20Salakhutdinov%2C%20R.%20Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20G.%20Salakhutdinov%2C%20R.%20Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks%202006"
        },
        {
            "id": "13",
            "entry": "[13] M. Jaggi. Revisiting Frank-Wolfe: Projection-free sparse convex optimization. In Proceedings of the 30th International Conference on Machine Learning, pages 427\u2013435, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaggi%2C%20M.%20Revisiting%20Frank-Wolfe%3A%20Projection-free%20sparse%20convex%20optimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaggi%2C%20M.%20Revisiting%20Frank-Wolfe%3A%20Projection-free%20sparse%20convex%20optimization%202013"
        },
        {
            "id": "14",
            "entry": "[14] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(1):117\u2013128, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jegou%2C%20H.%20Douze%2C%20M.%20Schmid%2C%20C.%20Product%20quantization%20for%20nearest%20neighbor%20search%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jegou%2C%20H.%20Douze%2C%20M.%20Schmid%2C%20C.%20Product%20quantization%20for%20nearest%20neighbor%20search%202011"
        },
        {
            "id": "15",
            "entry": "[15] W. Johnson and J. Lindenstrauss. Extensions of lipschitz mappings into a hilbert space. Contemporary Mathematics, 26(189-206):1, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20W.%20Lindenstrauss%2C%20J.%20Extensions%20of%20lipschitz%20mappings%20into%20a%20hilbert%20space%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20W.%20Lindenstrauss%2C%20J.%20Extensions%20of%20lipschitz%20mappings%20into%20a%20hilbert%20space%201984"
        },
        {
            "id": "16",
            "entry": "[16] R. Jortner, S. Farivar, and G. Laurent. A simple connectivity scheme for sparse coding in an olfactory system. Journal of Neuroscience, 27(7):1659\u20131669, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jortner%2C%20R.%20Farivar%2C%20S.%20Laurent%2C%20G.%20A%20simple%20connectivity%20scheme%20for%20sparse%20coding%20in%20an%20olfactory%20system%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jortner%2C%20R.%20Farivar%2C%20S.%20Laurent%2C%20G.%20A%20simple%20connectivity%20scheme%20for%20sparse%20coding%20in%20an%20olfactory%20system%202007"
        },
        {
            "id": "17",
            "entry": "[17] J. Kleinberg. Two algorithms for nearest-neighbor search in high dimensions. In Proceedings of the 29th Annual ACM Symposium on Theory of Computing, pages 599\u2013608. ACM, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kleinberg%2C%20J.%20Two%20algorithms%20for%20nearest-neighbor%20search%20in%20high%20dimensions%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kleinberg%2C%20J.%20Two%20algorithms%20for%20nearest-neighbor%20search%20in%20high%20dimensions%201997"
        },
        {
            "id": "18",
            "entry": "[18] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "19",
            "entry": "[19] A. Lin, A. Bygrave, A. De Calignon, T. Lee, and G. Miesenb\u00f6ck. Sparse, decorrelated odor coding in the mushroom body enhances learned odor discrimination. Nature Neuroscience, 17(4):559, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20A.%20Bygrave%2C%20A.%20Calignon%2C%20A.De%20Lee%2C%20T.%20Sparse%2C%20decorrelated%20odor%20coding%20in%20the%20mushroom%20body%20enhances%20learned%20odor%20discrimination%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20A.%20Bygrave%2C%20A.%20Calignon%2C%20A.De%20Lee%2C%20T.%20Sparse%2C%20decorrelated%20odor%20coding%20in%20the%20mushroom%20body%20enhances%20learned%20odor%20discrimination%202014"
        },
        {
            "id": "20",
            "entry": "[20] Y. Lin, R. Jin, D. Cai, S. Yan, and X. Li. Compressed hashing. In 2013 IEEE Conference on Computer Vision and Pattern Recognition, pages 446\u2013451. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Y.%20Jin%2C%20R.%20Cai%2C%20D.%20Yan%2C%20S.%20Compressed%20hashing%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Y.%20Jin%2C%20R.%20Cai%2C%20D.%20Yan%2C%20S.%20Compressed%20hashing%202013"
        },
        {
            "id": "21",
            "entry": "[21] C. Manning, P. Raghavan, and H. Sch\u00fctze. Introduction to information retrieval. Cambridge University Press, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Manning%2C%20C.%20Raghavan%2C%20P.%20Sch%C3%BCtze%2C%20H.%20Introduction%20to%20information%20retrieval%202008"
        },
        {
            "id": "22",
            "entry": "[22] N. Otsu. A threshold selection method from gray-level histograms. IEEE Transactions on Systems, Man, and Cybernetics, 9(1):62\u201366, 1979.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Otsu%2C%20N.%20A%20threshold%20selection%20method%20from%20gray-level%20histograms%201979",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Otsu%2C%20N.%20A%20threshold%20selection%20method%20from%20gray-level%20histograms%201979"
        },
        {
            "id": "23",
            "entry": "[23] M. Papadopoulou, S. Cassenaer, T. Nowotny, and G. Laurent. Normalization for sparse encoding of odors by a wide-field interneuron. Science, 332(6030):721\u2013725, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Papadopoulou%2C%20M.%20Cassenaer%2C%20S.%20Nowotny%2C%20T.%20Laurent%2C%20G.%20Normalization%20for%20sparse%20encoding%20of%20odors%20by%20a%20wide-field%20interneuron%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Papadopoulou%2C%20M.%20Cassenaer%2C%20S.%20Nowotny%2C%20T.%20Laurent%2C%20G.%20Normalization%20for%20sparse%20encoding%20of%20odors%20by%20a%20wide-field%20interneuron%202011"
        },
        {
            "id": "24",
            "entry": "[24] J. Pennington, R. Socher, and C. Manning. Glove: Global vectors for word representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1532\u20131543, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20J.%20Socher%2C%20R.%20Manning%2C%20C.%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pennington%2C%20J.%20Socher%2C%20R.%20Manning%2C%20C.%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014"
        },
        {
            "id": "25",
            "entry": "[25] A. Schrijver. Theory of linear and integer programming. John Wiley & Sons, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schrijver%2C%20A.%20Theory%20of%20linear%20and%20integer%20programming%201998"
        },
        {
            "id": "26",
            "entry": "[26] G. Turner, M. Bazhenov, and G. Laurent. Olfactory representations by drosophila mushroom body neurons. Journal of Neurophysiology, 99(2):734\u2013746, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Turner%2C%20G.%20Bazhenov%2C%20M.%20Laurent%2C%20G.%20Olfactory%20representations%20by%20drosophila%20mushroom%20body%20neurons%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Turner%2C%20G.%20Bazhenov%2C%20M.%20Laurent%2C%20G.%20Olfactory%20representations%20by%20drosophila%20mushroom%20body%20neurons%202008"
        },
        {
            "id": "27",
            "entry": "[27] Z. Zheng, S. Lauritzen, E. Perlman, C. Robinson, et al. A complete electron microscopy volume of the brain of adult drosophila melanogaster. Cell, 174(3):730\u2013743, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20Z.%20Lauritzen%2C%20S.%20Perlman%2C%20E.%20Robinson%2C%20C.%20A%20complete%20electron%20microscopy%20volume%20of%20the%20brain%20of%20adult%20drosophila%20melanogaster%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20Z.%20Lauritzen%2C%20S.%20Perlman%2C%20E.%20Robinson%2C%20C.%20A%20complete%20electron%20microscopy%20volume%20of%20the%20brain%20of%20adult%20drosophila%20melanogaster%202018"
        }
    ]
}
