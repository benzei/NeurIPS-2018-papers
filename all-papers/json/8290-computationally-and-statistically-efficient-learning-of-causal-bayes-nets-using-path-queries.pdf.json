{
    "filename": "8290-computationally-and-statistically-efficient-learning-of-causal-bayes-nets-using-path-queries.pdf",
    "metadata": {
        "title": "Computationally and statistically efficient learning of causal Bayes nets using path queries",
        "author": "Kevin Bello, Jean Honorio",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8290-computationally-and-statistically-efficient-learning-of-causal-bayes-nets-using-path-queries.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Causal discovery from empirical data is a fundamental problem in many scientific domains. Observational data allows for identifiability only up to Markov equivalence class. In this paper we first propose a polynomial time algorithm for learning the exact correctly-oriented structure of the transitive reduction of any causal Bayesian network with high probability, by using interventional path queries. Each path query takes as input an origin node and a target node, and answers whether there is a directed path from the origin to the target. This is done by intervening on the origin node and observing samples from the target node. We theoretically show the logarithmic sample complexity for the size of interventional data per path query, for continuous and discrete networks. We then show how to learn the transitive edges using also logarithmic sample complexity (albeit in time exponential in the maximum number of parents for discrete networks), which allows us to learn the full network. We further extend our work by reducing the number of interventional path queries for learning rooted trees. We also provide an analysis of imperfect interventions."
    },
    "keywords": [
        {
            "term": "probability mass function",
            "url": "https://en.wikipedia.org/wiki/probability_mass_function"
        },
        {
            "term": "conditional probability tables",
            "url": "https://en.wikipedia.org/wiki/Conditional_Probability_Table"
        },
        {
            "term": "directed acyclic graph",
            "url": "https://en.wikipedia.org/wiki/directed_acyclic_graph"
        },
        {
            "term": "causal relationship",
            "url": "https://en.wikipedia.org/wiki/causal_relationship"
        },
        {
            "term": "active learning",
            "url": "https://en.wikipedia.org/wiki/active_learning"
        },
        {
            "term": "Bayesian network",
            "url": "https://en.wikipedia.org/wiki/Bayesian_network"
        },
        {
            "term": "transitive reduction",
            "url": "https://en.wikipedia.org/wiki/transitive_reduction"
        }
    ],
    "highlights": [
        "[<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] analyzed the number of interventions sufficient and in the worst-case necessary to determine the structure of any directed acyclic graph, no algorithm or sample complexity analysis was provided",
        "We propose a polynomial time algorithm with provable guarantees for exact learning of the transitive reduction of any causal Bayesian network by using interventional path queries",
        "We present a theorem that formally characterizes the class of continuous causal Bayesian network that our algorithm can learn, and provides the sample complexity for each noisy path query",
        "The time complexity to answer a transitive query for a discrete causal Bayesian network is exponential in the maximum number of parents in the worst case",
        "In Appendix C, we show that the sample complexity for discrete causal Bayesian network is scaled by \u03b1\u22121, where \u03b1 accounts for the degree of uncertainty in the intervention"
    ],
    "key_statements": [
        "[<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] analyzed the number of interventions sufficient and in the worst-case necessary to determine the structure of any directed acyclic graph, no algorithm or sample complexity analysis was provided",
        "We propose a polynomial time algorithm with provable guarantees for exact learning of the transitive reduction of any causal Bayesian network by using interventional path queries",
        "We present a theorem that formally characterizes the class of continuous causal Bayesian network that our algorithm can learn, and provides the sample complexity for each noisy path query",
        "The time complexity to answer a transitive query for a discrete causal Bayesian network is exponential in the maximum number of parents in the worst case",
        "In Appendix C, we show that the sample complexity for discrete causal Bayesian network is scaled by \u03b1\u22121, where \u03b1 accounts for the degree of uncertainty in the intervention"
    ],
    "summary": [
        "[<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] analyzed the number of interventions sufficient and in the worst-case necessary to determine the structure of any DAG, no algorithm or sample complexity analysis was provided.",
        "We propose a polynomial time algorithm with provable guarantees for exact learning of the transitive reduction of any CBN by using interventional path queries.",
        "We present two extensions: for learning rooted trees the number of path queries is reduced to O(n log n), which is an improvement from the n2 for general DAGs. We provide an analysis of imperfect interventions.",
        "The CBN can be used to answer interventional queries, which specify probabilities after we intervene in the model, forcibly setting one or more variables to take on particular values.",
        "Note that Definition 3 requires a noisy path query to be correct only in certain cases, when one variable is parent of the other, or when there is no directed path between them.",
        "We first focus in learning general DAGs, in which a number of \u03a9(n2) path queries is in the worst case necessary for any conceivable algorithm.",
        "Later we show that a number of O (n log n) noisy path queries2 suffices for learning rooted trees.",
        "See Appendix B.2 (Algorithms 5 and 6) for the specific details of the algorithms for discrete and continuous CBNs. Algorithm 2 Noisy path query algorithm",
        "In this paper we use conditional probability tables (CPTs) as the representation of the CPDs for discrete CBNs. we present a theorem that provides the sample complexity of a noisy path query.",
        "Interventional samples are used per \u03b4-noisy partially-correct path query in Algorithm 5.",
        "For continuous CBNs, our algorithm compares two empirical expected values for answering a path query.",
        "We present a theorem that formally characterizes the class of continuous CBNs that our algorithm can learn, and provides the sample complexity for each noisy path query.",
        "Let \u03bcj|do(Xi=z) and \u03c3j2|do(Xi=z) denote the expected value and variance of Xj after intervening Xi with value z, assuming that the variables remain sub-Gaussian after performing an intervention.",
        "Algorithms 7 and 8 show how to answer a transitive query for discrete and continuous CBNs respectively.",
        "The time complexity to answer a transitive query for a discrete CBN is exponential in the maximum number of parents in the worst case.",
        ") interventional samples are used per \u03b4-noisy transitive query in Algorithm 7.",
        "Interventional samples are used per \u03b4-noisy path query in Algorithm 5."
    ],
    "headline": "We theoretically show the logarithmic sample complexity for the size of interventional data per path query, for continuous and discrete networks",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Aho, A., Garey, M., and Ullman, J. The transitive reduction of a directed graph. SIAM Journal on Computing, 1(2):131\u2013137, 1972.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aho%2C%20A.%20Garey%2C%20M.%20Ullman%2C%20J.%20The%20transitive%20reduction%20of%20a%20directed%20graph%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aho%2C%20A.%20Garey%2C%20M.%20Ullman%2C%20J.%20The%20transitive%20reduction%20of%20a%20directed%20graph%201972"
        },
        {
            "id": "2",
            "entry": "[2] Brenner, E. and Sontag, D. SparsityBoost: A new scoring function for learning Bayesian network structure. UAI, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brenner%2C%20E.%20Sontag%2C%20D.%20SparsityBoost%3A%20A%20new%20scoring%20function%20for%20learning%20Bayesian%20network%20structure%202013"
        },
        {
            "id": "3",
            "entry": "[3] Cheng, J., Greiner, R., Kelly, J., Bell, D., and Liu, W. Learning Bayesian networks from data: An information-theory based approach. Artificial Intelligence Journal, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cheng%2C%20J.%20Greiner%2C%20R.%20Kelly%2C%20J.%20Bell%2C%20D.%20Learning%20Bayesian%20networks%20from%20data%3A%20An%20information-theory%20based%20approach%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cheng%2C%20J.%20Greiner%2C%20R.%20Kelly%2C%20J.%20Bell%2C%20D.%20Learning%20Bayesian%20networks%20from%20data%3A%20An%20information-theory%20based%20approach%202002"
        },
        {
            "id": "4",
            "entry": "[4] Chickering, D. Learning Bayesian networks is NP-complete. In Learning from data, pp. 121\u2013130.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20D.%20Learning%20Bayesian%20networks%20is%20NP-complete.%20In%20Learning%20from%20data"
        },
        {
            "id": "5",
            "entry": "[5] Chickering, D. and Meek, C. Finding optimal Bayesian networks. UAI, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20D.%20Meek%2C%20C.%20Finding%20optimal%20Bayesian%20networks%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chickering%2C%20D.%20Meek%2C%20C.%20Finding%20optimal%20Bayesian%20networks%202002"
        },
        {
            "id": "6",
            "entry": "[6] Dvoretzky, A., Kiefer, J., and Wolfowitz, J. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, pp. 642\u2013669, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dvoretzky%2C%20A.%20Kiefer%2C%20J.%20Wolfowitz%2C%20J.%20Asymptotic%20minimax%20character%20of%20the%20sample%20distribution%20function%20and%20of%20the%20classical%20multinomial%20estimator%201956",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dvoretzky%2C%20A.%20Kiefer%2C%20J.%20Wolfowitz%2C%20J.%20Asymptotic%20minimax%20character%20of%20the%20sample%20distribution%20function%20and%20of%20the%20classical%20multinomial%20estimator%201956"
        },
        {
            "id": "7",
            "entry": "[7] Eaton, D. and Murphy, K. Exact Bayesian structure learning from uncertain interventions. In Artificial Intelligence and Statistics, pp. 107\u2013114, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eaton%2C%20D.%20Murphy%2C%20K.%20Exact%20Bayesian%20structure%20learning%20from%20uncertain%20interventions%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eaton%2C%20D.%20Murphy%2C%20K.%20Exact%20Bayesian%20structure%20learning%20from%20uncertain%20interventions%202007"
        },
        {
            "id": "8",
            "entry": "[8] Eberhardt, F., Glymour, C., and Scheines, R. On the number of experiments sufficient and in the worst case necessary to identify all causal relations among N variables. In UAI, pp. 178\u2013184. AUAI Press, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eberhardt%2C%20F.%20Glymour%2C%20C.%20Scheines%2C%20R.%20On%20the%20number%20of%20experiments%20sufficient%20and%20in%20the%20worst%20case%20necessary%20to%20identify%20all%20causal%20relations%20among%20N%20variables%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eberhardt%2C%20F.%20Glymour%2C%20C.%20Scheines%2C%20R.%20On%20the%20number%20of%20experiments%20sufficient%20and%20in%20the%20worst%20case%20necessary%20to%20identify%20all%20causal%20relations%20among%20N%20variables%202005"
        },
        {
            "id": "9",
            "entry": "[9] Harbison, Christopher T, Gordon, D Benjamin, Lee, Tong Ihn, Rinaldi, Nicola J, Macisaac, Kenzie D, Danford, Timothy W, Hannett, Nancy M, Tagne, Jean-Bosco, Reynolds, David B, Yoo, Jane, et al. Transcriptional regulatory code of a eukaryotic genome. Nature, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harbison%2C%20Christopher%20T.%20Gordon%2C%20D.Benjamin%20Lee%2C%20Tong%20Ihn%20Rinaldi%2C%20Nicola%20J.%20Transcriptional%20regulatory%20code%20of%20a%20eukaryotic%20genome%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Harbison%2C%20Christopher%20T.%20Gordon%2C%20D.Benjamin%20Lee%2C%20Tong%20Ihn%20Rinaldi%2C%20Nicola%20J.%20Transcriptional%20regulatory%20code%20of%20a%20eukaryotic%20genome%202004"
        },
        {
            "id": "10",
            "entry": "[10] Hauser, A. and B\u00fchlmann, P. Two optimal strategies for active learning of causal models from interventions. In Proceedings of the 6th European Workshop on Probabilistic Graphical Models, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hauser%2C%20A.%20B%C3%BChlmann%2C%20P.%20Two%20optimal%20strategies%20for%20active%20learning%20of%20causal%20models%20from%20interventions%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hauser%2C%20A.%20B%C3%BChlmann%2C%20P.%20Two%20optimal%20strategies%20for%20active%20learning%20of%20causal%20models%20from%20interventions%202012"
        },
        {
            "id": "11",
            "entry": "[11] He, Y. and Geng, Z. Active learning of causal networks with intervention experiments and optimal designs. Journal of Machine Learning Research, 9(Nov), 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Y.%20Geng%2C%20Z.%20Active%20learning%20of%20causal%20networks%20with%20intervention%20experiments%20and%20optimal%20designs%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Y.%20Geng%2C%20Z.%20Active%20learning%20of%20causal%20networks%20with%20intervention%20experiments%20and%20optimal%20designs%202008"
        },
        {
            "id": "12",
            "entry": "[12] H\u00f6ffgen, K. Learning and robust learning of product distributions. COLT, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%B6ffgen%2C%20K.%20Learning%20and%20robust%20learning%20of%20product%20distributions%201993"
        },
        {
            "id": "13",
            "entry": "[13] Kocaoglu, Murat, Shanmugam, Karthikeyan, and Bareinboim, Elias. Experimental design for learning causal graphs with latent variables. In Advances in Neural Information Processing Systems, pp. 7021\u20137031, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kocaoglu%2C%20Murat%20Shanmugam%2C%20Karthikeyan%20Bareinboim%2C%20Elias%20Experimental%20design%20for%20learning%20causal%20graphs%20with%20latent%20variables%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kocaoglu%2C%20Murat%20Shanmugam%2C%20Karthikeyan%20Bareinboim%2C%20Elias%20Experimental%20design%20for%20learning%20causal%20graphs%20with%20latent%20variables%202017"
        },
        {
            "id": "14",
            "entry": "[14] Koller, D. and Friedman, N. Probabilistic Graphical Models: Principles and Techniques. The MIT Press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koller%2C%20D.%20Friedman%2C%20N.%20Probabilistic%20Graphical%20Models%3A%20Principles%20and%20Techniques%202009"
        },
        {
            "id": "15",
            "entry": "[15] LeGall, F. Powers of tensors and fast matrix multiplication. In Proceedings of the 39th international symposium on symbolic and algebraic computation, pp. 296\u2013303. ACM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeGall%2C%20F.%20Powers%20of%20tensors%20and%20fast%20matrix%20multiplication%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeGall%2C%20F.%20Powers%20of%20tensors%20and%20fast%20matrix%20multiplication%202014"
        },
        {
            "id": "16",
            "entry": "[16] Liu, H., Wasserman, L., and Lafferty, J. Exponential concentration for mutual information estimation with application to forests. In Advances in Neural Information Processing Systems, pp. 2537\u20132545, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20H.%20Wasserman%2C%20L.%20Lafferty%2C%20J.%20Exponential%20concentration%20for%20mutual%20information%20estimation%20with%20application%20to%20forests%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20H.%20Wasserman%2C%20L.%20Lafferty%2C%20J.%20Exponential%20concentration%20for%20mutual%20information%20estimation%20with%20application%20to%20forests%202012"
        },
        {
            "id": "17",
            "entry": "[17] Louizos, Christos, Shalit, Uri, Mooij, Joris, Sontag, David, Zemel, Richard, and Welling, Max. Causal effect inference with deep latent-variable models. NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Louizos%2C%20Christos%20Shalit%2C%20Uri%20Mooij%2C%20Joris%20Sontag%2C%20David%20Causal%20effect%20inference%20with%20deep%20latent-variable%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Louizos%2C%20Christos%20Shalit%2C%20Uri%20Mooij%2C%20Joris%20Sontag%2C%20David%20Causal%20effect%20inference%20with%20deep%20latent-variable%20models%202017"
        },
        {
            "id": "18",
            "entry": "[18] Massart, P. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of Probability, pp. 1269\u20131283, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Massart%2C%20P.%20The%20tight%20constant%20in%20the%20Dvoretzky-Kiefer-Wolfowitz%20inequality%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Massart%2C%20P.%20The%20tight%20constant%20in%20the%20Dvoretzky-Kiefer-Wolfowitz%20inequality%201990"
        },
        {
            "id": "19",
            "entry": "[19] Murphy, K. Active learning of causal Bayes net structure. Technical report, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Murphy%2C%20K.%20Active%20learning%20of%20causal%20Bayes%20net%20structure%202001"
        },
        {
            "id": "20",
            "entry": "[20] Obozinski, Guillaume R, Wainwright, Martin J, and Jordan, Michael I. High-dimensional support union recovery in multivariate regression. In Advances in Neural Information Processing Systems, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Obozinski%2C%20Guillaume%20R.%20Wainwright%2C%20Martin%20J.%20Jordan%2C%20Michael%20I.%20High-dimensional%20support%20union%20recovery%20in%20multivariate%20regression%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Obozinski%2C%20Guillaume%20R.%20Wainwright%2C%20Martin%20J.%20Jordan%2C%20Michael%20I.%20High-dimensional%20support%20union%20recovery%20in%20multivariate%20regression%202009"
        },
        {
            "id": "21",
            "entry": "[21] Pearl, J. Causality: Models, Reasoning and Inference. Cambridge University Press, 2nd edition, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pearl%2C%20J.%20Causality%3A%20Models%2C%20Reasoning%20and%20Inference%202009"
        },
        {
            "id": "22",
            "entry": "[22] Peters, J., Janzing, D., and Sch\u00f6lkopf, B. Identifying cause and effect on discrete data using additive noise models. In AIStats, pp. 597\u2013604, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Identifying%20cause%20and%20effect%20on%20discrete%20data%20using%20additive%20noise%20models%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Identifying%20cause%20and%20effect%20on%20discrete%20data%20using%20additive%20noise%20models%202010"
        },
        {
            "id": "23",
            "entry": "[23] Peters, J., Mooij, J., Janzing, D., Sch\u00f6lkopf, B., et al. Causal discovery with continuous additive noise models. Journal of Machine Learning Research, 15(1):2009\u20132053, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peters%2C%20J.%20Mooij%2C%20J.%20Janzing%2C%20D.%20Sch%C3%B6lkopf%2C%20B.%20Causal%20discovery%20with%20continuous%20additive%20noise%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peters%2C%20J.%20Mooij%2C%20J.%20Janzing%2C%20D.%20Sch%C3%B6lkopf%2C%20B.%20Causal%20discovery%20with%20continuous%20additive%20noise%20models%202014"
        },
        {
            "id": "24",
            "entry": "[24] Ravikumar, P., Wainwright, M., Raskutti, G., B.Yu, et al. High-dimensional covariance estimation by minimizing 1-penalized log-determinant divergence. Electronic Journal of Statistics, 5: 935\u2013980, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ravikumar%2C%20P.%20Wainwright%2C%20M.%20Raskutti%2C%20G.%20Yu%2C%20B.%20High-dimensional%20covariance%20estimation%20by%20minimizing%201-penalized%20log-determinant%20divergence%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ravikumar%2C%20P.%20Wainwright%2C%20M.%20Raskutti%2C%20G.%20Yu%2C%20B.%20High-dimensional%20covariance%20estimation%20by%20minimizing%201-penalized%20log-determinant%20divergence%202011"
        },
        {
            "id": "25",
            "entry": "[25] Shanmugam, K., Kocaoglu, M., Dimakis, A., and Vishwanath, S. Learning causal graphs with small interventions. In Advances in Neural Information Processing Systems, pp. 3195\u20133203, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shanmugam%2C%20K.%20Kocaoglu%2C%20M.%20Dimakis%2C%20A.%20Vishwanath%2C%20S.%20Learning%20causal%20graphs%20with%20small%20interventions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shanmugam%2C%20K.%20Kocaoglu%2C%20M.%20Dimakis%2C%20A.%20Vishwanath%2C%20S.%20Learning%20causal%20graphs%20with%20small%20interventions%202015"
        },
        {
            "id": "26",
            "entry": "[26] Shimizu, Shohei, Hoyer, Patrik O, Hyv\u00e4rinen, Aapo, and Kerminen, Antti. A linear nongaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(Oct): 2003\u20132030, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shimizu%2C%20Shohei%20Hoyer%2C%20Patrik%20O.%20Hyv%C3%A4rinen%2C%20Aapo%20Kerminen%2C%20Antti%20A%20linear%20nongaussian%20acyclic%20model%20for%20causal%20discovery%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shimizu%2C%20Shohei%20Hoyer%2C%20Patrik%20O.%20Hyv%C3%A4rinen%2C%20Aapo%20Kerminen%2C%20Antti%20A%20linear%20nongaussian%20acyclic%20model%20for%20causal%20discovery%202006"
        },
        {
            "id": "27",
            "entry": "[27] Spirtes, P., Glymour, C., and Scheines, R. Causation, Prediction and Search. The MIT Press, second edition edition, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spirtes%2C%20P.%20Glymour%2C%20C.%20Scheines%2C%20R.Causation%20Prediction%20and%20Search%202000"
        },
        {
            "id": "28",
            "entry": "[28] Tong, S. and Koller, D. Active learning for structure in Bayesian networks. In International joint conference on artificial intelligence, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tong%2C%20S.%20Koller%2C%20D.%20Active%20learning%20for%20structure%20in%20Bayesian%20networks%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tong%2C%20S.%20Koller%2C%20D.%20Active%20learning%20for%20structure%20in%20Bayesian%20networks%202001"
        },
        {
            "id": "29",
            "entry": "[29] Triantafillou, S. and Tsamardinos, I. Constraint-based causal discovery from multiple interventions over overlapping variable sets. Journal of Machine Learning Research, 16:2147\u20132205, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Triantafillou%2C%20S.%20Tsamardinos%2C%20I.%20Constraint-based%20causal%20discovery%20from%20multiple%20interventions%20over%20overlapping%20variable%20sets%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Triantafillou%2C%20S.%20Tsamardinos%2C%20I.%20Constraint-based%20causal%20discovery%20from%20multiple%20interventions%20over%20overlapping%20variable%20sets%202015"
        },
        {
            "id": "30",
            "entry": "[30] Tsamardinos, I., Brown, L., and Aliferis, C. The max-min hill climbing Bayesian network structure learning algorithm. Machine Learning, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsamardinos%2C%20I.%20Brown%2C%20L.%20Aliferis%2C%20C.%20The%20max-min%20hill%20climbing%20Bayesian%20network%20structure%20learning%20algorithm%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsamardinos%2C%20I.%20Brown%2C%20L.%20Aliferis%2C%20C.%20The%20max-min%20hill%20climbing%20Bayesian%20network%20structure%20learning%20algorithm%202006"
        },
        {
            "id": "31",
            "entry": "[31] Verma, T. and Pearl, J. Equivalence and synthesis of causal models. In Proceedings of the Sixth Annual Conference on Uncertainty in Artificial Intelligence, UAI \u201990. Elsevier Science Inc., 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Verma%2C%20T.%20Pearl%2C%20J.%20Equivalence%20and%20synthesis%20of%20causal%20models%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Verma%2C%20T.%20Pearl%2C%20J.%20Equivalence%20and%20synthesis%20of%20causal%20models%201991"
        },
        {
            "id": "32",
            "entry": "[32] Wang, Z. and Honorio, J. Reconstructing a bounded-degree directed tree using path queries. arXiv preprint arXiv:1606.05183, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.05183"
        },
        {
            "id": "33",
            "entry": "[33] Xiao, Yun, Gong, Yonghui, Lv, Yanling, Lan, Yujia, Hu, Jing, Li, Feng, Xu, Jinyuan, Bai, Jing, Deng, Yulan, Liu, Ling, et al. Gene perturbation atlas (gpa): a single-gene perturbation repository for characterizing functional mechanisms of coding and non-coding genes. Scientific reports, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xiao%2C%20Yun%20Gong%2C%20Yonghui%20Lv%2C%20Yanling%20Lan%2C%20Yujia%20Gene%20perturbation%20atlas%20%28gpa%29%3A%20a%20single-gene%20perturbation%20repository%20for%20characterizing%20functional%20mechanisms%20of%20coding%20and%20non-coding%20genes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xiao%2C%20Yun%20Gong%2C%20Yonghui%20Lv%2C%20Yanling%20Lan%2C%20Yujia%20Gene%20perturbation%20atlas%20%28gpa%29%3A%20a%20single-gene%20perturbation%20repository%20for%20characterizing%20functional%20mechanisms%20of%20coding%20and%20non-coding%20genes%202015"
        },
        {
            "id": "34",
            "entry": "[34] Zuk, O., Margel, S., and Domany, E. On the number of samples needed to learn the correct structure of a Bayesian network. UAI, 2006. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zuk%2C%20O.%20Margel%2C%20S.%20Domany%2C%20E.%20On%20the%20number%20of%20samples%20needed%20to%20learn%20the%20correct%20structure%20of%20a%20Bayesian%20network%202006"
        }
    ]
}
