{
    "filename": "7859-deep-neural-networks-with-box-convolutions.pdf",
    "metadata": {
        "title": "Deep Neural Networks with Box Convolutions",
        "author": "Egor Burkov, Victor Lempitsky",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7859-deep-neural-networks-with-box-convolutions.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Box filters computed using integral images have been part of the computer vision toolset for a long time. Here, we show that a convolutional layer that computes box filter responses in a sliding manner can be used within deep architectures, whereas the dimensions and the offsets of the sliding boxes in such a layer can be learned as a part of an end-to-end loss minimization. Crucially, the training process can make the size of the boxes in such a layer arbitrarily large without incurring extra computational cost and without the need to increase the number of learnable parameters. Due to its ability to integrate information over large boxes, the new layer facilitates long-range propagation of information and leads to the efficient increase of the receptive fields of network units. By incorporating the new layer into existing architectures for semantic segmentation, we are able to achieve both the increase in segmentation accuracy as well as the decrease in the computational cost and the number of learnable parameters."
    },
    "keywords": [
        {
            "term": "receptive field",
            "url": "https://en.wikipedia.org/wiki/receptive_field"
        },
        {
            "term": "computational cost",
            "url": "https://en.wikipedia.org/wiki/computational_cost"
        },
        {
            "term": "learning process",
            "url": "https://en.wikipedia.org/wiki/learning_process"
        },
        {
            "term": "Conditional Random Fields",
            "url": "https://en.wikipedia.org/wiki/Conditional_Random_Field"
        },
        {
            "term": "integral image",
            "url": "https://en.wikipedia.org/wiki/integral_image"
        }
    ],
    "highlights": [
        "High-accuracy visual recognition requires integrating information from spatially-distant locations in the visual field in order to discern and to analyze long-range correlations and regularities",
        "The new layer combines the following merits: (i) large-size convolutional filtering, low number of learnable parameters, computational efficiency achieved via integral images, effective integration of spatial information over large spatial extents",
        "We evaluate and analyze the performance of the new layer for the task of semantic segmentation, which is among vision tasks that are most sensitive to the ability to propagate contextual evidence and to preserve spatial information",
        "We have introduced a new convolutional layer that computes box filter responses at every location, while optimizing the parameters of the boxes within the end-to-end learning process",
        "The new layer combines the ability to aggregate information over large areas, the low number of learnable parameters, and the computational efficiency achieved via the integral image trick",
        "We have shown that the learning process leads to large boxes within the new layer, and that the incorporation of the new layer increases the receptive fields of the units in the middle of semantic segmentation networks very considerably, explaining the improved segmentation accuracy"
    ],
    "key_statements": [
        "High-accuracy visual recognition requires integrating information from spatially-distant locations in the visual field in order to discern and to analyze long-range correlations and regularities",
        "The new layer combines the following merits: (i) large-size convolutional filtering, low number of learnable parameters, computational efficiency achieved via integral images, effective integration of spatial information over large spatial extents",
        "We evaluate and analyze the performance of the new layer for the task of semantic segmentation, which is among vision tasks that are most sensitive to the ability to propagate contextual evidence and to preserve spatial information",
        "We have introduced a new convolutional layer that computes box filter responses at every location, while optimizing the parameters of the boxes within the end-to-end learning process",
        "The new layer combines the ability to aggregate information over large areas, the low number of learnable parameters, and the computational efficiency achieved via the integral image trick",
        "We have shown that the learning process leads to large boxes within the new layer, and that the incorporation of the new layer increases the receptive fields of the units in the middle of semantic segmentation networks very considerably, explaining the improved segmentation accuracy"
    ],
    "summary": [
        "High-accuracy visual recognition requires integrating information from spatially-distant locations in the visual field in order to discern and to analyze long-range correlations and regularities.",
        "The approach is based on box filtering and relies on integral images [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], as many classical works in computer vision do [<a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>].",
        "The new layer combines the following merits: (i) large-size convolutional filtering, low number of learnable parameters, computational efficiency achieved via integral images, effective integration of spatial information over large spatial extents.",
        "Through 2000s, a large number of architectures that use box filtering to integrate spatial context information have been proposed.",
        "We evaluate and analyze the performance of the new layer for the task of semantic segmentation, which is among vision tasks that are most sensitive to the ability to propagate contextual evidence and to preserve spatial information.",
        "To perform the evaluation of the new layer and the embedding block, we consider two base architectures for semantic segmentation: ENet [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] and ERFNet [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>].",
        "To assess the importance of this aspect, we have evaluated the ablated architectures BoxENet\u2020 and BoxERFNet\u2020 that are identical to BoxENet and BoxERFNet, but have the coordinates of the boxes in the box convolution layers frozen at initialization.",
        "Once box-based architectures are trained, we round the box coordinates to the nearest integers, fix them and fine-tune the network, so that at test time we do not have to deal with fractional parts of integration intervals.",
        "BoxOnlyENet performs in-between ENet and BoxENet, suggesting that the optimal approach might be to combine standard 3x3 convolutions with box convolutions.",
        "We measure the spread by taking a random image from the Cityscapes dataset, considering a random location (p, q) in the visual fields, and computing the gradient response map M (p, q, k,\u02c6I0) for a certain level k of the network.",
        "We conclude that networks with box convolutions have much bigger effective receptive fields, both for units in early layers as well as for the output units.",
        "We have introduced a new convolutional layer that computes box filter responses at every location, while optimizing the parameters of the boxes within the end-to-end learning process.",
        "The new layer combines the ability to aggregate information over large areas, the low number of learnable parameters, and the computational efficiency achieved via the integral image trick.",
        "We have shown that the learning process leads to large boxes within the new layer, and that the incorporation of the new layer increases the receptive fields of the units in the middle of semantic segmentation networks very considerably, explaining the improved segmentation accuracy.",
        "The code of the new layer, as well as the implementation of BoxENet and BoxERFNet architectures, are available at the project website"
    ],
    "headline": "We show that a convolutional layer that computes box filter responses in a sliding manner can be used within deep architectures, whereas the dimensions and the offsets of the sliding boxes in such a layer can be learned as a part of an end-to-end loss minimization",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] A. Babenko and V. Lempitsky. Aggregating local deep features for image retrieval. Proc. ICCV, pp. 1269\u20131277, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Babenko%2C%20A.%20Lempitsky%2C%20V.%20Aggregating%20local%20deep%20features%20for%20image%20retrieval%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Babenko%2C%20A.%20Lempitsky%2C%20V.%20Aggregating%20local%20deep%20features%20for%20image%20retrieval%202015"
        },
        {
            "id": "2",
            "entry": "[2] S. Chandra and I. Kokkinos. Fast, exact and multi-scale inference for semantic image segmentation with deep gaussian CRFs. Proc. ECCV, pp. 402\u2013418.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chandra%2C%20S.%20Fast%2C%20I.Kokkinos%20exact%20and%20multi-scale%20inference%20for%20semantic%20image%20segmentation%20with%20deep%20gaussian%20CRFs",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chandra%2C%20S.%20Fast%2C%20I.Kokkinos%20exact%20and%20multi-scale%20inference%20for%20semantic%20image%20segmentation%20with%20deep%20gaussian%20CRFs"
        },
        {
            "id": "3",
            "entry": "[3] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. T-PAMI, 40(4):834\u2013848, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20L.-C.%20Papandreou%2C%20G.%20Kokkinos%2C%20I.%20Murphy%2C%20K.%20Deeplab%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%2C%20atrous%20convolution%2C%20and%20fully%20connected%20CRFs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20L.-C.%20Papandreou%2C%20G.%20Kokkinos%2C%20I.%20Murphy%2C%20K.%20Deeplab%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%2C%20atrous%20convolution%2C%20and%20fully%20connected%20CRFs%202018"
        },
        {
            "id": "4",
            "entry": "[4] L.-C. Chen, A. Schwing, A. Yuille, and R. Urtasun. Learning deep structured models. Proc. ICML, pp. 1785\u20131794, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20L.-C.%20Schwing%2C%20A.%20Yuille%2C%20A.%20Urtasun%2C%20R.%20Learning%20deep%20structured%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20L.-C.%20Schwing%2C%20A.%20Yuille%2C%20A.%20Urtasun%2C%20R.%20Learning%20deep%20structured%20models%202015"
        },
        {
            "id": "5",
            "entry": "[5] F. Chollet. Xception: Deep learning with depthwise separable convolutions. Proc. CVPR, pp. 1251\u20131258, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chollet%2C%20F.%20Xception%3A%20Deep%20learning%20with%20depthwise%20separable%20convolutions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chollet%2C%20F.%20Xception%3A%20Deep%20learning%20with%20depthwise%20separable%20convolutions%202017"
        },
        {
            "id": "6",
            "entry": "[6] R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: A matlab-like environment for machine learning. BigLearn, NIPS Workshop, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20R.%20Kavukcuoglu%2C%20K.%20Farabet%2C%20C.%20Torch7%3A%20A%20matlab-like%20environment%20for%20machine%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20R.%20Kavukcuoglu%2C%20K.%20Farabet%2C%20C.%20Torch7%3A%20A%20matlab-like%20environment%20for%20machine%20learning%202011"
        },
        {
            "id": "7",
            "entry": "[7] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele. The cityscapes dataset for semantic urban scene understanding. Proc. CVPR, pp. 3213\u20133223, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cordts%2C%20M.%20Omran%2C%20M.%20Ramos%2C%20S.%20Rehfeld%2C%20T.%20The%20cityscapes%20dataset%20for%20semantic%20urban%20scene%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cordts%2C%20M.%20Omran%2C%20M.%20Ramos%2C%20S.%20Rehfeld%2C%20T.%20The%20cityscapes%20dataset%20for%20semantic%20urban%20scene%20understanding%202016"
        },
        {
            "id": "8",
            "entry": "[8] A. Criminisi, J. Shotton, E. Konukoglu, et al. Decision forests: A unified framework for classification, regression, density estimation, manifold learning and semi-supervised learning. Foundations and Trends R in Computer Graphics and Vision, 7(2\u20133):81\u2013227, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Criminisi%2C%20A.%20Shotton%2C%20J.%20Konukoglu%2C%20E.%20Decision%20forests%3A%20A%20unified%20framework%20for%20classification%2C%20regression%2C%20density%20estimation%2C%20manifold%20learning%20and%20semi-supervised%20learning%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Criminisi%2C%20A.%20Shotton%2C%20J.%20Konukoglu%2C%20E.%20Decision%20forests%3A%20A%20unified%20framework%20for%20classification%2C%20regression%2C%20density%20estimation%2C%20manifold%20learning%20and%20semi-supervised%20learning%202012"
        },
        {
            "id": "9",
            "entry": "[9] P. Doll\u00e1r, Z. Tu, P. Perona, and S. Belongie. Integral channel features. Proc. BMVC. BMVC Press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Doll%C3%A1r%2C%20P.%20Tu%2C%20Z.%20Perona%2C%20P.%20Belongie%2C%20S.%20Integral%20channel%20features%202009"
        },
        {
            "id": "10",
            "entry": "[10] A. Ghodrati, A. Diba, M. Pedersoli, T. Tuytelaars, and L. Van Gool. DeepProposals: Hunting objects and actions by cascading deep convolutional layers. IJCV, 124(2):115\u2013131, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghodrati%2C%20A.%20Diba%2C%20A.%20Pedersoli%2C%20M.%20Tuytelaars%2C%20T.%20DeepProposals%3A%20Hunting%20objects%20and%20actions%20by%20cascading%20deep%20convolutional%20layers%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghodrati%2C%20A.%20Diba%2C%20A.%20Pedersoli%2C%20M.%20Tuytelaars%2C%20T.%20DeepProposals%3A%20Hunting%20objects%20and%20actions%20by%20cascading%20deep%20convolutional%20layers%202017"
        },
        {
            "id": "11",
            "entry": "[11] R. Girshick. Fast R-CNN. Proc. ICCV, pp. 1440\u20131448. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=R%20Girshick%20Fast%20RCNN%20Proc%20ICCV%20pp%2014401448%20IEEE%202015"
        },
        {
            "id": "12",
            "entry": "[12] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. Proc. CVPR, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "13",
            "entry": "[13] M. Holschneider, R. Kronland-Martinet, J. Morlet, and P. Tchamitchian. A real-time algorithm for signal analysis with the help of the wavelet transform. Wavelets, pp. 286\u2013297.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Holschneider%2C%20M.%20Kronland-Martinet%2C%20R.%20Morlet%2C%20J.%20Tchamitchian%2C%20P.%20A%20real-time%20algorithm%20for%20signal%20analysis%20with%20the%20help%20of%20the%20wavelet%20transform",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Holschneider%2C%20M.%20Kronland-Martinet%2C%20R.%20Morlet%2C%20J.%20Tchamitchian%2C%20P.%20A%20real-time%20algorithm%20for%20signal%20analysis%20with%20the%20help%20of%20the%20wavelet%20transform"
        },
        {
            "id": "14",
            "entry": "[14] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. Proc. ICML, pp. 448\u2013456, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "15",
            "entry": "[15] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "16",
            "entry": "[16] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4):541\u2013551, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Y.%20Boser%2C%20B.%20Denker%2C%20J.S.%20Henderson%2C%20D.%20Backpropagation%20applied%20to%20handwritten%20zip%20code%20recognition%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Y.%20Boser%2C%20B.%20Denker%2C%20J.S.%20Henderson%2C%20D.%20Backpropagation%20applied%20to%20handwritten%20zip%20code%20recognition%201989"
        },
        {
            "id": "17",
            "entry": "[17] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "18",
            "entry": "[18] J. P. Lewis. Fast template matching. Vision interface, v. 95, pp. 15\u201319, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lewis%2C%20J.P.%20Fast%20template%20matching.%20Vision%20interface%2C%20v%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lewis%2C%20J.P.%20Fast%20template%20matching.%20Vision%20interface%2C%20v%201995"
        },
        {
            "id": "19",
            "entry": "[19] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. Proc. CVPR, pp. 3431\u20133440, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20J.%20Shelhamer%2C%20E.%20Darrell%2C%20T.%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20J.%20Shelhamer%2C%20E.%20Darrell%2C%20T.%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015"
        },
        {
            "id": "20",
            "entry": "[20] A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello. Enet: A deep neural network architecture for real-time semantic segmentation. CoRR, abs/1606.02147, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.02147"
        },
        {
            "id": "21",
            "entry": "[21] E. Romera, J. M. Alvarez, L. M. Bergasa, and R. Arroyo. Erfnet: Efficient residual factorized convnet for real-time semantic segmentation. IEEE Transactions on Intelligent Transportation Systems, 19(1):263\u2013272, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Romera%2C%20E.%20Alvarez%2C%20J.M.%20Bergasa%2C%20L.M.%20Arroyo%2C%20R.%20Erfnet%3A%20Efficient%20residual%20factorized%20convnet%20for%20real-time%20semantic%20segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Romera%2C%20E.%20Alvarez%2C%20J.M.%20Bergasa%2C%20L.M.%20Arroyo%2C%20R.%20Erfnet%3A%20Efficient%20residual%20factorized%20convnet%20for%20real-time%20semantic%20segmentation%202018"
        },
        {
            "id": "22",
            "entry": "[22] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. Proc. MICCAI, pp. 234\u2013241.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ronneberger%2C%20O.%20Fischer%2C%20P.%20Brox%2C%20T.%20U-net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ronneberger%2C%20O.%20Fischer%2C%20P.%20Brox%2C%20T.%20U-net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation"
        },
        {
            "id": "23",
            "entry": "[23] J. Shotton, M. Johnson, and R. Cipolla. Semantic texton forests for image categorization and segmentation. Proc. CVPR, pp. 1\u20138. IEEE, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shotton%2C%20J.%20Johnson%2C%20M.%20Cipolla%2C%20R.%20Semantic%20texton%20forests%20for%20image%20categorization%20and%20segmentation%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shotton%2C%20J.%20Johnson%2C%20M.%20Cipolla%2C%20R.%20Semantic%20texton%20forests%20for%20image%20categorization%20and%20segmentation%202008"
        },
        {
            "id": "24",
            "entry": "[24] J. Shotton, J. Winn, C. Rother, and A. Criminisi. Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation. Proc. ECCV, pp. 1\u201315.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shotton%2C%20J.%20Winn%2C%20J.%20Rother%2C%20C.%20Criminisi%2C%20A.%20Textonboost%3A%20Joint%20appearance%2C%20shape%20and%20context%20modeling%20for%20multi-class%20object%20recognition%20and%20segmentation",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shotton%2C%20J.%20Winn%2C%20J.%20Rother%2C%20C.%20Criminisi%2C%20A.%20Textonboost%3A%20Joint%20appearance%2C%20shape%20and%20context%20modeling%20for%20multi-class%20object%20recognition%20and%20segmentation"
        },
        {
            "id": "25",
            "entry": "[25] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "26",
            "entry": "[26] S. Song, S. P. Lichtenberg, and J. Xiao. SUN RGB-D: A RGB-D scene understanding benchmark suite. Proc. CVPR, v. 5, p. 6, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20S.%20Lichtenberg%2C%20S.P.%20Xiao%2C%20J.%20SUN%20RGB-D%3A%20A%20RGB-D%20scene%20understanding%20benchmark%20suite%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20S.%20Lichtenberg%2C%20S.P.%20Xiao%2C%20J.%20SUN%20RGB-D%3A%20A%20RGB-D%20scene%20understanding%20benchmark%20suite%202015"
        },
        {
            "id": "27",
            "entry": "[27] J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller. Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6806"
        },
        {
            "id": "28",
            "entry": "[28] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. JMLR, 15(1):1929\u20131958, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20N.%20Hinton%2C%20G.%20Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20N.%20Hinton%2C%20G.%20Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014"
        },
        {
            "id": "29",
            "entry": "[29] R. K. Srivastava, K. Greff, and J. Schmidhuber. Highway networks. arXiv preprint arXiv:1505.00387, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1505.00387"
        },
        {
            "id": "30",
            "entry": "[30] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. AAAI, v. 4, p. 12, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Ioffe%2C%20S.%20Vanhoucke%2C%20V.%20Alemi%2C%20A.A.%20Inception-v4%2C%20inception-resnet%20and%20the%20impact%20of%20residual%20connections%20on%20learning.%20AAAI%2C%20v%202017"
        },
        {
            "id": "31",
            "entry": "[31] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. Proc. CVPR. IEEE, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Viola%2C%20P.%20Jones%2C%20M.%20Rapid%20object%20detection%20using%20a%20boosted%20cascade%20of%20simple%20features%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Viola%2C%20P.%20Jones%2C%20M.%20Rapid%20object%20detection%20using%20a%20boosted%20cascade%20of%20simple%20features%202001"
        },
        {
            "id": "32",
            "entry": "[32] P. Viola, M. J. Jones, and D. Snow. Detecting pedestrians using patterns of motion and appearance. IJCV, 63(2):153\u2013161, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Viola%2C%20P.%20Jones%2C%20M.J.%20Snow%2C%20D.%20Detecting%20pedestrians%20using%20patterns%20of%20motion%20and%20appearance%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Viola%2C%20P.%20Jones%2C%20M.J.%20Snow%2C%20D.%20Detecting%20pedestrians%20using%20patterns%20of%20motion%20and%20appearance%202005"
        },
        {
            "id": "33",
            "entry": "[33] F. Yu and V. Koltun. Multi-scale context aggregation by dilated convolutions. Proc. ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20F.%20Koltun%2C%20V.%20Multi-scale%20context%20aggregation%20by%20dilated%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20F.%20Koltun%2C%20V.%20Multi-scale%20context%20aggregation%20by%20dilated%20convolutions%202015"
        },
        {
            "id": "34",
            "entry": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. Proc. CVPR, pp. 2881\u20132890, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20H.%20Shi%2C%20J.%20Qi%2C%20X.%20Wang%2C%20X.%20Pyramid%20scene%20parsing%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20H.%20Shi%2C%20J.%20Qi%2C%20X.%20Wang%2C%20X.%20Pyramid%20scene%20parsing%20network%202017"
        },
        {
            "id": "35",
            "entry": "[35] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. H. Torr. Conditional random fields as recurrent neural networks. Proc. ICCV, pp. 1529\u20131537, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20S.%20Jayasumana%2C%20S.%20Romera-Paredes%2C%20B.%20Vineet%2C%20V.%20Conditional%20random%20fields%20as%20recurrent%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20S.%20Jayasumana%2C%20S.%20Romera-Paredes%2C%20B.%20Vineet%2C%20V.%20Conditional%20random%20fields%20as%20recurrent%20neural%20networks%202015"
        }
    ]
}
