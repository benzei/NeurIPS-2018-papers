{
    "filename": "8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf",
    "metadata": {
        "title": "Neural Proximal Gradient Descent for Compressive Imaging",
        "author": "Morteza Mardani, Qingyun Sun, David Donoho, Vardan Papyan, Hatef Monajemi, Shreyas Vasanawala, John Pauly",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Recovering high-resolution images from limited sensory data typically leads to a serious ill-posed inverse problem, demanding inversion algorithms that effectively capture the prior information. Learning a good inverse mapping from training data faces severe challenges, including: (i) scarcity of training data; (ii) need for plausible reconstructions that are physically feasible; (iii) need for fast reconstruction, especially in real-time applications. We develop a successful system solving all these challenges, using as basic architecture the recurrent application of proximal gradient algorithm. We learn a proximal map that works well with real images based on residual networks. Contraction of the resulting map is analyzed, and incoherence conditions are investigated that drive the convergence of the iterates. Extensive experiments are carried out under different settings: (a) reconstructing abdominal MRI of pediatric patients from highly undersampled Fourier-space data and (b) superresolving natural face images. Our key findings include: 1. a recurrent ResNet with a single residual block unrolled from an iterative algorithm yields an effective proximal which accurately reveals MR image details. 2. Our architecture significantly outperforms conventional non-recurrent deep ResNets by 2dB SNR; it is also trained much more rapidly. 3. It outperforms state-of-the-art compressed-sensing Wavelet-based methods by 4dB SNR, with 100x speedups in reconstruction time."
    },
    "keywords": [
        {
            "term": "batch normalization",
            "url": "https://en.wikipedia.org/wiki/batch_normalization"
        },
        {
            "term": "sparse coding",
            "url": "https://en.wikipedia.org/wiki/sparse_coding"
        },
        {
            "term": "real time",
            "url": "https://en.wikipedia.org/wiki/real_time"
        },
        {
            "term": "compressed sensing",
            "url": "https://en.wikipedia.org/wiki/compressed_sensing"
        },
        {
            "term": "residual network",
            "url": "https://en.wikipedia.org/wiki/residual_network"
        },
        {
            "term": "ISTA",
            "url": "https://en.wikipedia.org/wiki/ISTA"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "image reconstruction",
            "url": "https://en.wikipedia.org/wiki/image_reconstruction"
        },
        {
            "term": "proximal gradient",
            "url": "https://en.wikipedia.org/wiki/proximal_gradient"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "inverse problem",
            "url": "https://en.wikipedia.org/wiki/inverse_problem"
        }
    ],
    "highlights": [
        "Linear inverse problems appear broadly in image restoration tasks, in applications ranging from natural image superresolution to biomedical image reconstruction",
        "One oftentimes encounters a seriously ill-posed recovery task, which necessitates regularization with proper statistical priors. This is impeded by the following challenges: c1) real-time and interactive tasks demand a low overhead for inference; e.g., imagine MRI visualization for neurosurgery [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>], or, interactive superresolution on cell phones [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]; c2) the need for recovering plausible images that are consistent with the physical model; this is particularly important for medical diagnosis, which is sensitive to artifacts; c3) and limited labeled training data especially for medical imaging",
        "In order to assess the impact of network architecture on image recovery performance, the RNN was trained for a variable number of iterations (T ) with a variable number of residual blocks (RBs). 10K slices (67 patients) from the train dataset were randomly picked for training, and 1, 280 slices (9 patients) from the test dataset for test",
        "This paper develops a novel neural proximal gradient descent scheme for recovery of images from highly compressed measurements",
        "Unrolling the proximal gradient iterations, a recurrent architecture is proposed that models the proximal map via Residual networks",
        "Our findings for MRI indicate that a small Residual networks can effectively model the proximal, and significantly improve the quality and complexity of recent deep architectures as well as conventional compressed sensing-MRI"
    ],
    "key_statements": [
        "Linear inverse problems appear broadly in image restoration tasks, in applications ranging from natural image superresolution to biomedical image reconstruction",
        "One oftentimes encounters a seriously ill-posed recovery task, which necessitates regularization with proper statistical priors. This is impeded by the following challenges: c1) real-time and interactive tasks demand a low overhead for inference; e.g., imagine MRI visualization for neurosurgery [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>], or, interactive superresolution on cell phones [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]; c2) the need for recovering plausible images that are consistent with the physical model; this is particularly important for medical diagnosis, which is sensitive to artifacts; c3) and limited labeled training data especially for medical imaging",
        "Performance of our novel neural proximal gradient descent scheme was assessed in two tasks: reconstructing pediatric MR images from undersampled k-space data; and superresolving natural face images",
        "In order to assess the impact of network architecture on image recovery performance, the RNN was trained for a variable number of iterations (T ) with a variable number of residual blocks (RBs). 10K slices (67 patients) from the train dataset were randomly picked for training, and 1, 280 slices (9 patients) from the test dataset for test",
        "Considering the training and inference overhead and the quality of reconstructed images, RNN with 10 iterations and 1 residual blocks proximal is promising to implement in clinical scanners.\n5.3",
        "Verification of the contraction conditions To verify the contraction analysis developed for Proposition 1, we focus on the image superresolution (SR) task",
        "This paper develops a novel neural proximal gradient descent scheme for recovery of images from highly compressed measurements",
        "Unrolling the proximal gradient iterations, a recurrent architecture is proposed that models the proximal map via Residual networks",
        "Our findings for MRI indicate that a small Residual networks can effectively model the proximal, and significantly improve the quality and complexity of recent deep architectures as well as conventional compressed sensing-MRI"
    ],
    "summary": [
        "Linear inverse problems appear broadly in image restoration tasks, in applications ranging from natural image superresolution to biomedical image reconstruction.",
        "Feasible, and plausible image recovery in ill-posed linear inverse tasks, this paper puts forth a novel neural proximal gradient descent algorithm that learns the proximal map using a recurrent ResNet. Local convergence of the iterates is studied for the inference phase assuming that the true image is a fixed point for a proximal.",
        "Our recurrent ResNet architecture outperforms general deep network schemes by about 2dB SNR, with much less training data needed.",
        "Performance of our novel neural proximal gradient descent scheme was assessed in two tasks: reconstructing pediatric MR images from undersampled k-space data; and superresolving natural face images.",
        "In order to assess the impact of network architecture on image recovery performance, the RNN was trained for a variable number of iterations (T ) with a variable number of residual blocks (RBs).",
        "Using three iterations instead of one achieves more than 2dB SNR gain for 1 RB, and more than 3dB for 2 RBs. Interestingly, when using a single iteration, adding more than 5 RBs to make a deeper network does not yield further improvements; the SNR=24.33 for 10 RBs, and SNR=24.15 for 5 RBs. Notice that a single RB tends to be reasonably expressive to model the MR image denoising proximal, and as a result, repeating it several times, the SNR does not seem to exceed 27dB.",
        "Considering the training and inference overhead and the quality of reconstructed images, RNN with 10 iterations and 1 RB proximal is promising to implement in clinical scanners.",
        "Contraction of the proximal map and subsequently the local convergence of the iterates is studied and empirically evaluated.",
        "Our findings for MRI indicate that a small ResNet can effectively model the proximal, and significantly improve the quality and complexity of recent deep architectures as well as conventional CS-MRI.",
        "While this paper sheds some light on the local convergence of neural proximal gradient descent, our ongoing research focuses on a more rigorous analysis to derive simple and interpretable contraction conditions.",
        "Other important avenues that are the focus of our current research include: 1)Stable training of neural PGD for large iteration counts using gated recurrent networks; 2) comparing with existing deep learning based MRI reconstruction schemes such as deep ADMM-net and LDMAP; 3) more extensive experiments for natural image superresolution with deeper proximals and possibly using dilated convolutions for capturing large image field of view."
    ],
    "headline": "We develop a successful system solving all these challenges, using as basic architecture the recurrent application of proximal gradient algorithm",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] http://www.mriinterventions.com/clearpoint/clearpoint-overview.html.",
            "url": "http://www.mriinterventions.com/clearpoint/clearpoint-overview.html"
        },
        {
            "id": "2",
            "entry": "[2] Yaniv Romano, John Isidoro, and Peyman Milanfar. RAISR: rapid and accurate image super resolution. IEEE Transactions on Computational Imaging, 3(1):110\u2013125, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Romano%2C%20Yaniv%20Isidoro%2C%20John%20Milanfar%2C%20Peyman%20RAISR%3A%20rapid%20and%20accurate%20image%20super%20resolution%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Romano%2C%20Yaniv%20Isidoro%2C%20John%20Milanfar%2C%20Peyman%20RAISR%3A%20rapid%20and%20accurate%20image%20super%20resolution%202017"
        },
        {
            "id": "3",
            "entry": "[3] David L Donoho. Compressed sensing. IEEE Transactions on information theory, 52(4):1289\u20131306, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donoho%2C%20David%20L.%20Compressed%20sensing%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donoho%2C%20David%20L.%20Compressed%20sensing%202006"
        },
        {
            "id": "4",
            "entry": "[4] Michael Lustig, David Donoho, and John M. Pauly. Sparse MRI: The application of compressed sensing for rapid MR imaging. Magnetic Resonance in Medicine, 58(6):1182\u20131195, December 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lustig%2C%20Michael%20Donoho%2C%20David%20Pauly%2C%20John%20M.%20Sparse%20MRI%3A%20The%20application%20of%20compressed%20sensing%20for%20rapid%20MR%20imaging%202007-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lustig%2C%20Michael%20Donoho%2C%20David%20Pauly%2C%20John%20M.%20Sparse%20MRI%3A%20The%20application%20of%20compressed%20sensing%20for%20rapid%20MR%20imaging%202007-12"
        },
        {
            "id": "5",
            "entry": "[5] Julio Martin Duarte-Carvajalino and Guillermo Sapiro. Learning to sense sparse signals: Simultaneous sensing matrix and sparsifying dictionary optimization. IEEE Transactions on Image Processing, 18(7):1395\u20131408, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duarte-Carvajalino%2C%20Julio%20Martin%20Sapiro%2C%20Guillermo%20Learning%20to%20sense%20sparse%20signals%3A%20Simultaneous%20sensing%20matrix%20and%20sparsifying%20dictionary%20optimization%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duarte-Carvajalino%2C%20Julio%20Martin%20Sapiro%2C%20Guillermo%20Learning%20to%20sense%20sparse%20signals%3A%20Simultaneous%20sensing%20matrix%20and%20sparsifying%20dictionary%20optimization%202009"
        },
        {
            "id": "6",
            "entry": "[6] Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings of the 27th International Conference on Machine Learning (ICML), pages 399\u2013406, June 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gregor%2C%20Karol%20LeCun%2C%20Yann%20Learning%20fast%20approximations%20of%20sparse%20coding%202010-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gregor%2C%20Karol%20LeCun%2C%20Yann%20Learning%20fast%20approximations%20of%20sparse%20coding%202010-06"
        },
        {
            "id": "7",
            "entry": "[7] Pablo Sprechmann, Alexander M Bronstein, and Guillermo Sapiro. Learning efficient sparse and low rank models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(9):1821\u20131833, January 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sprechmann%2C%20Pablo%20Bronstein%2C%20Alexander%20M.%20Sapiro%2C%20Guillermo%20Learning%20efficient%20sparse%20and%20low%20rank%20models%202015-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sprechmann%2C%20Pablo%20Bronstein%2C%20Alexander%20M.%20Sapiro%2C%20Guillermo%20Learning%20efficient%20sparse%20and%20low%20rank%20models%202015-01"
        },
        {
            "id": "8",
            "entry": "[8] Bo Xin, Yizhou Wang, Wen Gao, David Wipf, and Baoyuan Wang. Maximal sparsity with deep networks? In Advances in Neural Information Processing Systems, pages 4340\u20134348, December 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xin%2C%20Bo%20Wang%2C%20Yizhou%20Gao%2C%20Wen%20Wipf%2C%20David%20Maximal%20sparsity%20with%20deep%20networks%3F%202016-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xin%2C%20Bo%20Wang%2C%20Yizhou%20Gao%2C%20Wen%20Wipf%2C%20David%20Maximal%20sparsity%20with%20deep%20networks%3F%202016-12"
        },
        {
            "id": "9",
            "entry": "[9] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, December 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014-12"
        },
        {
            "id": "10",
            "entry": "[10] Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European Conference on Computer Vision, pages 694\u2013711.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution"
        },
        {
            "id": "11",
            "entry": "[11] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley. Least squares generative adversarial networks. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 2813\u20132821. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mao%2C%20Xudong%20Li%2C%20Qing%20Xie%2C%20Haoran%20Lau%2C%20Raymond%20Y.K.%20Least%20squares%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mao%2C%20Xudong%20Li%2C%20Qing%20Xie%2C%20Haoran%20Lau%2C%20Raymond%20Y.K.%20Least%20squares%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "12",
            "entry": "[12] Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic single image superresolution using a generative adversarial network. arXiv preprint, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20superresolution%20using%20a%20generative%20adversarial%20network.%20arXiv%20p%202016"
        },
        {
            "id": "13",
            "entry": "[13] Raymond Yeh, Chen Chen, Teck Yian Lim, Mark Hasegawa-Johnson, and Minh N Do. Semantic image inpainting with perceptual and contextual losses. arXiv preprint arXiv:1607.07539, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.07539"
        },
        {
            "id": "14",
            "entry": "[14] Hang Zhao, Orazio Gallo, Iuri Frosio, and Jan Kautz. Loss functions for image restoration with neural networks. IEEE Transactions on Computational Imaging, 3(1):47\u201357, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Hang%20Gallo%2C%20Orazio%20Frosio%2C%20Iuri%20Kautz%2C%20Jan%20Loss%20functions%20for%20image%20restoration%20with%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Hang%20Gallo%2C%20Orazio%20Frosio%2C%20Iuri%20Kautz%2C%20Jan%20Loss%20functions%20for%20image%20restoration%20with%20neural%20networks%202017"
        },
        {
            "id": "15",
            "entry": "[15] A. Majumdar. Real-time dynamic MRI reconstruction using stacked denoising autoencoder. arXiv preprint, arXiv:1503.06383 [cs.CV], March 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.06383"
        },
        {
            "id": "16",
            "entry": "[16] Jian Sun, Huibin Li, Zongben Xu, et al. Deep ADMM-net for compressive sensing MRI. In Advances in Neural Information Processing Systems, pages 10\u201318, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Jian%20Li%2C%20Huibin%20Xu%2C%20Zongben%20Deep%20ADMM-net%20for%20compressive%20sensing%20MRI%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Jian%20Li%2C%20Huibin%20Xu%2C%20Zongben%20Deep%20ADMM-net%20for%20compressive%20sensing%20MRI%202016"
        },
        {
            "id": "17",
            "entry": "[17] Hu Chen, Yi Zhang, Mannudeep K Kalra, Feng Lin, Yang Chen, Peixi Liao, Jiliu Zhou, and Ge Wang. Low-dose CT with a residual encoder-decoder convolutional neural network. IEEE transactions on medical imaging, 36(12):2524\u20132535, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Hu%20Zhang%2C%20Yi%20Kalra%2C%20Mannudeep%20K.%20Lin%2C%20Feng%20Low-dose%20CT%20with%20a%20residual%20encoder-decoder%20convolutional%20neural%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Hu%20Zhang%2C%20Yi%20Kalra%2C%20Mannudeep%20K.%20Lin%2C%20Feng%20Low-dose%20CT%20with%20a%20residual%20encoder-decoder%20convolutional%20neural%20network%202017"
        },
        {
            "id": "18",
            "entry": "[18] Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Deeply-recursive convolutional network for image super-resolution. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Jiwon%20Lee%2C%20Jung%20Kwon%20and%20Kyoung%20Mu%20Lee.%20Deeply-recursive%20convolutional%20network%20for%20image%20super-resolution%202016-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Jiwon%20Lee%2C%20Jung%20Kwon%20and%20Kyoung%20Mu%20Lee.%20Deeply-recursive%20convolutional%20network%20for%20image%20super-resolution%202016-06"
        },
        {
            "id": "19",
            "entry": "[19] Morteza Mardani, Enhao Gong, Joseph Y Cheng, Shreyas Vasanawala, Greg Zaharchuk, Lei Xing, and John M. Pauly. Generative Adversarial Neural Networks for Compressive Sensing (GANCS) MRI. IEEE transactions on medical imaging, July 2018 (to appear).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mardani%2C%20Morteza%20Gong%2C%20Enhao%20Cheng%2C%20Joseph%20Y.%20Vasanawala%2C%20Shreyas%20Generative%20Adversarial%20Neural%20Networks%20for%20Compressive%20Sensing%20%28GANCS%29%20MRI%202018-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mardani%2C%20Morteza%20Gong%2C%20Enhao%20Cheng%2C%20Joseph%20Y.%20Vasanawala%2C%20Shreyas%20Generative%20Adversarial%20Neural%20Networks%20for%20Compressive%20Sensing%20%28GANCS%29%20MRI%202018-07"
        },
        {
            "id": "20",
            "entry": "[20] Bo Zhu, Jeremiah Z. Liu, Bruce R. Rosen, and Matthew S. Rosen. Neural network MR image reconstruction with AUTOMAP: Automated transform by manifold approximation. In Proceedings of the 25st Annual Meeting of ISMRM, Honolulu, HI, USA, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Bo%20Liu%2C%20Jeremiah%20Z.%20Rosen%2C%20Bruce%20R.%20Rosen%2C%20Matthew%20S.%20Neural%20network%20MR%20image%20reconstruction%20with%20AUTOMAP%3A%20Automated%20transform%20by%20manifold%20approximation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Bo%20Liu%2C%20Jeremiah%20Z.%20Rosen%2C%20Bruce%20R.%20Rosen%2C%20Matthew%20S.%20Neural%20network%20MR%20image%20reconstruction%20with%20AUTOMAP%3A%20Automated%20transform%20by%20manifold%20approximation%202017"
        },
        {
            "id": "21",
            "entry": "[21] Shanshan Wang, Ningbo Huang, Tao Zhao, Yong Yang, Leslie Ying, and Dong Liang. 1D partial fourier parallel MR imaging with deep convolutional neural network. In Proceedings of the 25st Annual Meeting of ISMRM, Honolulu, HI, USA, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Shanshan%20Huang%2C%20Ningbo%20Zhao%2C%20Tao%20Yang%2C%20Yong%201D%20partial%20fourier%20parallel%20MR%20imaging%20with%20deep%20convolutional%20neural%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Shanshan%20Huang%2C%20Ningbo%20Zhao%2C%20Tao%20Yang%2C%20Yong%201D%20partial%20fourier%20parallel%20MR%20imaging%20with%20deep%20convolutional%20neural%20network%202017"
        },
        {
            "id": "22",
            "entry": "[22] Jo Schlemper, Jose Caballero, Joseph V. Hajnal, Anthony Price, and Daniel Rueckert. A deep cascade of convolutional neural networks for MR image reconstruction. In Proceedings of the 25st Annual Meeting of ISMRM, Honolulu, HI, USA, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schlemper%2C%20Jo%20Caballero%2C%20Jose%20Hajnal%2C%20Joseph%20V.%20Price%2C%20Anthony%20A%20deep%20cascade%20of%20convolutional%20neural%20networks%20for%20MR%20image%20reconstruction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schlemper%2C%20Jo%20Caballero%2C%20Jose%20Hajnal%2C%20Joseph%20V.%20Price%2C%20Anthony%20A%20deep%20cascade%20of%20convolutional%20neural%20networks%20for%20MR%20image%20reconstruction%202017"
        },
        {
            "id": "23",
            "entry": "[23] Dongwook Lee, Jaejun Yoo, and Jong Chul Ye. Compressed sensing and parallel MRI using deep residual learning. In Proceedings of the 25st Annual Meeting of ISMRM, Honolulu, HI, USA, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Dongwook%20Yoo%2C%20Jaejun%20Ye%2C%20Jong%20Chul%20Compressed%20sensing%20and%20parallel%20MRI%20using%20deep%20residual%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Dongwook%20Yoo%2C%20Jaejun%20Ye%2C%20Jong%20Chul%20Compressed%20sensing%20and%20parallel%20MRI%20using%20deep%20residual%20learning%202017"
        },
        {
            "id": "24",
            "entry": "[24] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In European Conference on Computer Vision, pages 630\u2013645.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Identity%20mappings%20in%20deep%20residual%20networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Identity%20mappings%20in%20deep%20residual%20networks"
        },
        {
            "id": "25",
            "entry": "[25] Steven Diamond, Vincent Sitzmann, Felix Heide, and Gordon Wetzstein. Unrolled optimization with deep priors. arXiv preprint arXiv:1705.08041, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.08041"
        },
        {
            "id": "26",
            "entry": "[26] Chris Metzler, Ali Mousavi, and Richard Baraniuk. Learned D-AMP: Principled neural network based compressive image recovery. In Advances in Neural Information Processing Systems, pages 1770\u20131781, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Metzler%2C%20Chris%20Mousavi%2C%20Ali%20Baraniuk%2C%20Richard%20Learned%20D-AMP%3A%20Principled%20neural%20network%20based%20compressive%20image%20recovery%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Metzler%2C%20Chris%20Mousavi%2C%20Ali%20Baraniuk%2C%20Richard%20Learned%20D-AMP%3A%20Principled%20neural%20network%20based%20compressive%20image%20recovery%202017"
        },
        {
            "id": "27",
            "entry": "[27] Jonas Adler and Ozan \u00d6ktem. Learned primal-dual reconstruction. arXiv preprint arXiv:1707.06474, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06474"
        },
        {
            "id": "28",
            "entry": "[28] Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using generative models. arXiv preprint arXiv:1703.03208, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.03208"
        },
        {
            "id": "29",
            "entry": "[29] Paul Hand and Vladislav Voroninski. Global guarantees for enforcing deep generative priors by empirical risk. arXiv preprint arXiv:1705.07576, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.07576"
        },
        {
            "id": "30",
            "entry": "[30] Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and Trends R in Optimization, 1(3):127\u2013239, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parikh%2C%20Neal%20Boyd%2C%20Stephen%20Proximal%20algorithms%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parikh%2C%20Neal%20Boyd%2C%20Stephen%20Proximal%20algorithms%202014"
        },
        {
            "id": "31",
            "entry": "[31] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM journal on imaging sciences, 2(1):183\u2013202, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beck%2C%20Amir%20Teboulle%2C%20Marc%20A%20fast%20iterative%20shrinkage-thresholding%20algorithm%20for%20linear%20inverse%20problems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beck%2C%20Amir%20Teboulle%2C%20Marc%20A%20fast%20iterative%20shrinkage-thresholding%20algorithm%20for%20linear%20inverse%20problems%202009"
        },
        {
            "id": "32",
            "entry": "[32] Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramachandran%2C%20Prajit%20Zoph%2C%20Barret%20Le%2C%20Quoc%20V.%20Searching%20for%20activation%20functions%202018"
        },
        {
            "id": "33",
            "entry": "[33] Klaus Greff, Rupesh K Srivastava, and J\u00fcrgen Schmidhuber. Highway and residual networks learn unrolled iterative estimation. arXiv preprint arXiv:1612.07771, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.07771"
        },
        {
            "id": "34",
            "entry": "[34] Sergey Zagoruyko and Nikos Komodakis. Diracnets: training very deep neural networks without skipconnections. arXiv preprint arXiv:1706.00388, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.00388"
        },
        {
            "id": "35",
            "entry": "[35] https://github.com/MortezaMardani/NeuralPGD.html.",
            "url": "https://github.com/MortezaMardani/NeuralPGD.html"
        },
        {
            "id": "36",
            "entry": "[36] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Processing, 13(4):600\u2013612, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004"
        },
        {
            "id": "37",
            "entry": "[37] Jonathan I Tamir, Frank Ong, Joseph Y Cheng, Martin Uecker, and Michael Lustig. Generalized Magnetic Resonance Image Reconstruction using The Berkeley Advanced Reconstruction Toolbox. In ISMRM Workshop on Data Sampling and Image Reconstruction, Sedona, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tamir%2C%20Jonathan%20I.%20Ong%2C%20Frank%20Cheng%2C%20Joseph%20Y.%20Uecker%2C%20Martin%20Generalized%20Magnetic%20Resonance%20Image%20Reconstruction%20using%20The%20Berkeley%20Advanced%20Reconstruction%20Toolbox%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tamir%2C%20Jonathan%20I.%20Ong%2C%20Frank%20Cheng%2C%20Joseph%20Y.%20Uecker%2C%20Martin%20Generalized%20Magnetic%20Resonance%20Image%20Reconstruction%20using%20The%20Berkeley%20Advanced%20Reconstruction%20Toolbox%202016"
        },
        {
            "id": "38",
            "entry": "[38] Joan Bruna, Pablo Sprechmann, and Yann LeCun. Super-resolution with deep convolutional sufficient statistics. arXiv preprint arXiv:1511.05666, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05666"
        },
        {
            "id": "39",
            "entry": "[39] Casper Kaae S\u00f8nderby, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc Husz\u00e1r. Amortised map inference for image super-resolution. arXiv preprint arXiv:1610.04490, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.04490"
        },
        {
            "id": "40",
            "entry": "[40] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), 2015. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        }
    ]
}
