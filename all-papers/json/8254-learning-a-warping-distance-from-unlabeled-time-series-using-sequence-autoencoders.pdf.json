{
    "filename": "8254-learning-a-warping-distance-from-unlabeled-time-series-using-sequence-autoencoders.pdf",
    "metadata": {
        "date": 2018,
        "title": "Autowarp: Learning a Warping Distance from Unlabeled Time Series Using Sequence Autoencoders",
        "author": "Abubakar Abid Stanford University a12d@stanford.edu",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8254-learning-a-warping-distance-from-unlabeled-time-series-using-sequence-autoencoders.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Measuring similarities between unlabeled time series trajectories is an important problem in domains as diverse as medicine, astronomy, finance, and computer vision. It is often unclear what is the appropriate metric to use because of the complex nature of noise in the trajectories (e.g. different sampling rates or outliers). Domain experts typically hand-craft or manually select a specific metric, such as dynamic time warping (DTW), to apply on their data. In this paper, we propose Autowarp, an end-to-end algorithm that optimizes and learns a good metric given unlabeled trajectories. We define a flexible and differentiable family of warping metrics, which encompasses common metrics such as DTW, Euclidean, and edit distance. Autowarp then leverages the representation power of sequence autoencoders to optimize for a member of this warping distance family. The output is a metric which is easy to interpret and can be robustly learned from relatively few trajectories. In systematic experiments across different domains, we show that Autowarp often outperforms hand-crafted trajectory similarity metrics."
    },
    "keywords": [
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        },
        {
            "term": "Australian Sign Language",
            "url": "https://en.wikipedia.org/wiki/Australian_Sign_Language"
        },
        {
            "term": "Dynamic Time Warping",
            "url": "https://en.wikipedia.org/wiki/Dynamic_Time_Warping"
        },
        {
            "term": "recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_networks"
        },
        {
            "term": "dynamic time",
            "url": "https://en.wikipedia.org/wiki/dynamic_time"
        },
        {
            "term": "unsupervised learning",
            "url": "https://en.wikipedia.org/wiki/unsupervised_learning"
        }
    ],
    "highlights": [
        "We propose an alternative to hand-crafting a distance: we develop an end-to-end framework to learn a good similarity metric directly from unlabeled time series data",
        "We show through systematic experiments that learning an appropriate warping distance can provide insight into the nature of the time series data, and can be used to cluster, query, or visualize the data effectively",
        "Recall that Autowarp learns a distance from unlabeled trajectory data in two steps: first, a latent representation is learned for each trajectory; secondly, a warping distance is identified that is most similar to the learned latent representations",
        "Our method learns a warping distance that is similar to latent representations that are learned for a trajectory by a sequence-to-sequence autoencoder",
        "Our experiments suggest that both steps of Autowarp \u2013 first, learning latent representations using sequence-to-sequence autoencoders, and second, finding a warping distance that agrees with the latent representation \u2013 are important to learning a good similarity metric",
        "Some of which are shown in Figure S5 in Appendix A, show that even deeper autoencoders are unable to learn useful similarity metrics, without the regularization afforded by restricting ourselves to a family of warping distances"
    ],
    "key_statements": [
        "We propose an alternative to hand-crafting a distance: we develop an end-to-end framework to learn a good similarity metric directly from unlabeled time series data",
        "A key question that is often asked about time series data is: \"How similar are two given trajectories?\" A notion of trajectory similarity allows one to do unsupervised learning, such as clustering and visualization, of time series data, as well as supervised learning, such as classification [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>]",
        "Measuring the distance between trajectories is complex, because of the temporal correlation between data in a time series and the complex nature of the noise that may be present in the data [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "We show through systematic experiments that learning an appropriate warping distance can provide insight into the nature of the time series data, and can be used to cluster, query, or visualize the data effectively",
        "We show that the computation of the BetaCV over the family of warping distances defined above is differentiable with respect to quantities \u03b1, \u03b3, that parametrize the family of warping distances",
        "In Section 2, we proposed that a warping distance can be identified by the distance d \u2208 D that minimizes the BetaCV computed from the latent representations",
        "Recall that Autowarp learns a distance from unlabeled trajectory data in two steps: first, a latent representation is learned for each trajectory; secondly, a warping distance is identified that is most similar to the learned latent representations",
        "We investigate whether both the autoencoder and the search through warping distances are necessary for effective metric learning",
        "Needed: using the latent representations alone results in noisy clustering, while the warping distance search cannot be applied in the original trajectory space to get meaningful results (Fig. 1)",
        "We show the result of our Fig. 6(b) for various values of k, showing that the learned distance is as compact as Symmetric Segment-Path Distance, if not more compact",
        "We propose Autowarp, a novel method to learn a similarity metric from a dataset of unlabeled trajectories",
        "Our method learns a warping distance that is similar to latent representations that are learned for a trajectory by a sequence-to-sequence autoencoder",
        "Our experiments suggest that both steps of Autowarp \u2013 first, learning latent representations using sequence-to-sequence autoencoders, and second, finding a warping distance that agrees with the latent representation \u2013 are important to learning a good similarity metric",
        "We carried out experiments with deeper autoencoders to determine if increasing the capacity of the autoencoders would allow the autoencoder alone to learn a similarity metric",
        "Some of which are shown in Figure S5 in Appendix A, show that even deeper autoencoders are unable to learn useful similarity metrics, without the regularization afforded by restricting ourselves to a family of warping distances",
        "In Figure 7, we show that the Autowarp distance outperforms most other distances on the Australian Sign Language dataset, including the Edit Distance on Real Sequence distance, which was validated on this dataset"
    ],
    "summary": [
        "We propose an alternative to hand-crafting a distance: we develop an end-to-end framework to learn a good similarity metric directly from unlabeled time series data.",
        "To allow a comparison between latent representations and trajectory distances, we use the concept of betaCV: Definition 3.",
        "In Section 2, we proposed that a warping distance can be identified by the distance d \u2208 D that minimizes the BetaCV computed from the latent representations.",
        "Recall that Autowarp learns a distance from unlabeled trajectory data in two steps: first, a latent representation is learned for each trajectory; secondly, a warping distance is identified that is most similar to the learned latent representations.",
        "We consider computing the betaCV based on the Euclidean distance of the original trajectories, rather than the Euclidean distance between the latent representations.",
        "Needed: using the latent representations alone results in noisy clustering, while the warping distance search cannot be applied in the original trajectory space to get meaningful results (Fig. 1).",
        "We turn to two such public datasets, and demonstrate how Autowarp can be used to learn an appropriate warping distance from the data.",
        "The trajectories in this dataset are labeled, so to evaluate the quality of our learned distance, we computed the accuracy of doing nearest neighbors on the data.",
        "We propose Autowarp, a novel method to learn a similarity metric from a dataset of unlabeled trajectories.",
        "Our method learns a warping distance that is similar to latent representations that are learned for a trajectory by a sequence-to-sequence autoencoder.",
        "We show through systematic experiments that learning an appropriate warping distance can provide insight into the nature of the time series data, and can be used to cluster, query, or visualize the data effectively.",
        "Our experiments suggest that both steps of Autowarp \u2013 first, learning latent representations using sequence-to-sequence autoencoders, and second, finding a warping distance that agrees with the latent representation \u2013 are important to learning a good similarity metric.",
        "Some of which are shown in Figure S5 in Appendix A, show that even deeper autoencoders are unable to learn useful similarity metrics, without the regularization afforded by restricting ourselves to a family of warping distances.",
        "Autowarp can be implemented efficiently because we have defined a differentiable, parametrized family of warping distances over which it is possible to do batched gradient descent.",
        "These results confirm that Autowarp can learn useful distances without prior knowledge of labels or clusters within the data."
    ],
    "headline": "We propose Autowarp, an end-to-end algorithm that optimizes and learns a good metric given unlabeled trajectories",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Eamonn Keogh, Jessica Lin, Ada Waichee Fu, and Helga VanHerle. Finding unusual medical time-series subsequences: Algorithms and applications. IEEE Transactions on Information Technology in Biomedicine, 10(3):429\u2013439, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Keogh%2C%20Eamonn%20Lin%2C%20Jessica%20Fu%2C%20Ada%20Waichee%20VanHerle%2C%20Helga%20Finding%20unusual%20medical%20time-series%20subsequences%3A%20Algorithms%20and%20applications%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Keogh%2C%20Eamonn%20Lin%2C%20Jessica%20Fu%2C%20Ada%20Waichee%20VanHerle%2C%20Helga%20Finding%20unusual%20medical%20time-series%20subsequences%3A%20Algorithms%20and%20applications%202006"
        },
        {
            "id": "2",
            "entry": "[2] Ruey S Tsay. Analysis of Financial Time Series, volume 543. John Wiley & Sons, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsay%2C%20Ruey%20S.%20Analysis%20of%20Financial%20Time%20Series%2C%20volume%20543%202005"
        },
        {
            "id": "3",
            "entry": "[3] Jeffrey D Scargle. Studies in astronomical time series analysis. ii-statistical aspects of spectral analysis of unevenly spaced data. The Astrophysical Journal, 263:835\u2013853, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scargle%2C%20Jeffrey%20D.%20Studies%20in%20astronomical%20time%20series%20analysis.%20ii-statistical%20aspects%20of%20spectral%20analysis%20of%20unevenly%20spaced%20data%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scargle%2C%20Jeffrey%20D.%20Studies%20in%20astronomical%20time%20series%20analysis.%20ii-statistical%20aspects%20of%20spectral%20analysis%20of%20unevenly%20spaced%20data%201982"
        },
        {
            "id": "4",
            "entry": "[4] Rake & Agrawal King-lp Lin and Harpreet S Sawhney Kyuseok Shim. Fast similarity search in the presence of noise, scaling, and translation in time-series databases. In Proceeding of the 21th International Conference on Very Large Databases, pages 490\u2013501.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rake%20Lin%2C%20Agrawal%20King-lp%20Shim%2C%20Harpreet%20S.Sawhney%20Kyuseok%20Fast%20similarity%20search%20in%20the%20presence%20of%20noise%2C%20scaling%2C%20and%20translation%20in%20time-series%20databases",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rake%20Lin%2C%20Agrawal%20King-lp%20Shim%2C%20Harpreet%20S.Sawhney%20Kyuseok%20Fast%20similarity%20search%20in%20the%20presence%20of%20noise%2C%20scaling%2C%20and%20translation%20in%20time-series%20databases"
        },
        {
            "id": "5",
            "entry": "[5] Eric P Xing, Michael I Jordan, Stuart J Russell, and Andrew Y Ng. Distance metric learning with application to clustering with side-information. In Advances in Neural Information Processing Systems, pages 521\u2013528, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Y%20Ng.%20Distance%20metric%20learning%20with%20application%20to%20clustering%20with%20side-information%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Y%20Ng.%20Distance%20metric%20learning%20with%20application%20to%20clustering%20with%20side-information%202003"
        },
        {
            "id": "6",
            "entry": "[6] Hongsheng Yin, Honggang Qi, Jingwen Xu, William NN Hung, and Xiaoyu Song. Generalized framework for similarity measure of time series. Mathematical Problems in Engineering, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yin%2C%20Hongsheng%20Qi%2C%20Honggang%20Xu%2C%20Jingwen%20Hung%2C%20William%20N.N.%20Generalized%20framework%20for%20similarity%20measure%20of%20time%20series%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yin%2C%20Hongsheng%20Qi%2C%20Honggang%20Xu%2C%20Jingwen%20Hung%2C%20William%20N.N.%20Generalized%20framework%20for%20similarity%20measure%20of%20time%20series%202014"
        },
        {
            "id": "7",
            "entry": "[7] Philippe Besse, Brendan Guillouet, Jean-Michel Loubes, and Royer Fran\u00e7ois. Review and perspective for distance based trajectory clustering. arXiv preprint arXiv:1508.04904, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1508.04904"
        },
        {
            "id": "8",
            "entry": "[8] Haozhou Wang, Han Su, Kai Zheng, Shazia Sadiq, and Xiaofang Zhou. An effectiveness study on trajectory similarity measures. In Proceedings of the Twenty-Fourth Australasian Database Conference, pages 13\u201322. Australian Computer Society, Inc., 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Haozhou%20Su%2C%20Han%20Zheng%2C%20Kai%20Sadiq%2C%20Shazia%20An%20effectiveness%20study%20on%20trajectory%20similarity%20measures%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Haozhou%20Su%2C%20Han%20Zheng%2C%20Kai%20Sadiq%2C%20Shazia%20An%20effectiveness%20study%20on%20trajectory%20similarity%20measures%202013"
        },
        {
            "id": "9",
            "entry": "[9] Zhiguang Wang, Weizhong Yan, and Tim Oates. Time series classification from scratch with deep neural networks: A strong baseline. In 2017 International Joint Conference on Neural Networks, pages 1578\u20131585. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhiguang%20Yan%2C%20Weizhong%20Oates%2C%20Tim%20Time%20series%20classification%20from%20scratch%20with%20deep%20neural%20networks%3A%20A%20strong%20baseline%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhiguang%20Yan%2C%20Weizhong%20Oates%2C%20Tim%20Time%20series%20classification%20from%20scratch%20with%20deep%20neural%20networks%3A%20A%20strong%20baseline%202017"
        },
        {
            "id": "10",
            "entry": "[10] Thanawin Rakthanmanon, Bilson Campana, Abdullah Mueen, Gustavo Batista, Brandon Westover, Qiang Zhu, Jesin Zakaria, and Eamonn Keogh. Searching and mining trillions of time series subsequences under dynamic time warping. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 262\u2013270. ACM, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rakthanmanon%2C%20Thanawin%20Campana%2C%20Bilson%20Mueen%2C%20Abdullah%20Batista%2C%20Gustavo%20Searching%20and%20mining%20trillions%20of%20time%20series%20subsequences%20under%20dynamic%20time%20warping%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rakthanmanon%2C%20Thanawin%20Campana%2C%20Bilson%20Mueen%2C%20Abdullah%20Batista%2C%20Gustavo%20Searching%20and%20mining%20trillions%20of%20time%20series%20subsequences%20under%20dynamic%20time%20warping%202012"
        },
        {
            "id": "11",
            "entry": "[11] Hiroaki Sakoe and Seibi Chiba. Dynamic programming algorithm optimization for spoken word recognition. IEEE Transactions on Acoustics, Speech, and Signal Processing, 26(1):43\u201349, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sakoe%2C%20Hiroaki%20Chiba%2C%20Seibi%20Dynamic%20programming%20algorithm%20optimization%20for%20spoken%20word%20recognition%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sakoe%2C%20Hiroaki%20Chiba%2C%20Seibi%20Dynamic%20programming%20algorithm%20optimization%20for%20spoken%20word%20recognition%201978"
        },
        {
            "id": "12",
            "entry": "[12] Lei Chen, M Tamer \u00d6zsu, and Vincent Oria. Robust and fast similarity search for moving object trajectories. In Proceedings of the 2005 ACM SIGMOD International Conference on Management of Data, pages 491\u2013502. ACM, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lei%20Chen%2C%20M.Tamer%20%C3%96zsu%20Oria%2C%20Vincent%20Robust%20and%20fast%20similarity%20search%20for%20moving%20object%20trajectories%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lei%20Chen%2C%20M.Tamer%20%C3%96zsu%20Oria%2C%20Vincent%20Robust%20and%20fast%20similarity%20search%20for%20moving%20object%20trajectories%202005"
        },
        {
            "id": "13",
            "entry": "[13] Lei Chen and Raymond Ng. On the marriage of lp-norms and edit distance. In Proceedings of the Thirtieth International Conference on Very Large Databases, pages 792\u2013803. VLDB Endowment, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Lei%20Ng%2C%20Raymond%20On%20the%20marriage%20of%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Lei%20Ng%2C%20Raymond%20On%20the%20marriage%20of%202004"
        },
        {
            "id": "14",
            "entry": "[14] Joe K Kearney and Stuart Hansen. Stream editing for animation. Technical report, Iowa University, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kearney%2C%20Joe%20K.%20Hansen%2C%20Stuart%20Stream%20editing%20for%20animation%201990"
        },
        {
            "id": "15",
            "entry": "[15] Dev Goyal, Zeeshan Syed, and Jenna Wiens. Clinically meaningful comparisons over time: An approach to measuring patient similarity based on subsequence alignment. arXiv preprint arXiv:1803.00744, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.00744"
        },
        {
            "id": "16",
            "entry": "[16] Pierre-Fran\u00e7ois Marteau. Time warp edit distance with stiffness adjustment for time series matching. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(2):306\u2013318, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20stiffness%20adjustment%20for%20time%20series%20matching%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20stiffness%20adjustment%20for%20time%20series%20matching%202009"
        },
        {
            "id": "17",
            "entry": "[17] Zachary C Lipton, David C Kale, Charles Elkan, and Randall Wetzel. Learning to diagnose with lstm recurrent neural networks. arXiv preprint arXiv:1511.03677, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.03677"
        },
        {
            "id": "18",
            "entry": "[18] Wenjie Pei, David MJ Tax, and Laurens van der Maaten. Modeling time series similarity with siamese recurrent networks. arXiv preprint arXiv:1603.04713, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.04713"
        },
        {
            "id": "19",
            "entry": "[19] Martin L\u00e4ngkvist, Lars Karlsson, and Amy Loutfi. A review of unsupervised feature learning and deep learning for time-series modeling. Pattern Recognition Letters, 42:11\u201324, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=L%C3%A4ngkvist%2C%20Martin%20Karlsson%2C%20Lars%20Loutfi%2C%20Amy%20A%20review%20of%20unsupervised%20feature%20learning%20and%20deep%20learning%20for%20time-series%20modeling%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=L%C3%A4ngkvist%2C%20Martin%20Karlsson%2C%20Lars%20Loutfi%2C%20Amy%20A%20review%20of%20unsupervised%20feature%20learning%20and%20deep%20learning%20for%20time-series%20modeling%202014"
        },
        {
            "id": "20",
            "entry": "[20] Pankaj Malhotra, Vishnu TV, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Timenet: Pre-trained deep recurrent neural network for time series classification. arXiv preprint arXiv:1706.08838, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.08838"
        },
        {
            "id": "21",
            "entry": "[21] Dominique T Shipmon, Jason M Gurevitch, Paolo M Piselli, and Stephen T Edwards. Time series anomaly detection; detection of anomalous drops with limited features and sparse examples in noisy highly periodic data. arXiv preprint arXiv:1708.03665, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.03665"
        },
        {
            "id": "22",
            "entry": "[22] Pablo Romeu, Francisco Zamora-Mart\u00ednez, Paloma Botella-Rocamora, and Juan Pardo. Stacked denoising auto-encoders for short-term time series forecasting. In Artificial Neural Networks, pages 463\u2013486.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Romeu%2C%20Pablo%20Zamora-Mart%C3%ADnez%2C%20Francisco%20Botella-Rocamora%2C%20Paloma%20Pardo%2C%20Juan%20Stacked%20denoising%20auto-encoders%20for%20short-term%20time%20series%20forecasting",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Romeu%2C%20Pablo%20Zamora-Mart%C3%ADnez%2C%20Francisco%20Botella-Rocamora%2C%20Paloma%20Pardo%2C%20Juan%20Stacked%20denoising%20auto-encoders%20for%20short-term%20time%20series%20forecasting"
        },
        {
            "id": "23",
            "entry": "[23] Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. In Advances in Neural Information Processing Systems, pages 3079\u20133087, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20Andrew%20M.%20Le%2C%20Quoc%20V.%20Semi-supervised%20sequence%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20Andrew%20M.%20Le%2C%20Quoc%20V.%20Semi-supervised%20sequence%20learning%202015"
        },
        {
            "id": "24",
            "entry": "[24] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pages 3104\u20133112, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014"
        },
        {
            "id": "25",
            "entry": "[25] Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov. Unsupervised learning of video representations using lstms. In International Conference on Machine Learning, pages 843\u2013852, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Mansimov%2C%20Elman%20Salakhudinov%2C%20Ruslan%20Unsupervised%20learning%20of%20video%20representations%20using%20lstms%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Mansimov%2C%20Elman%20Salakhudinov%2C%20Ruslan%20Unsupervised%20learning%20of%20video%20representations%20using%20lstms%202015"
        },
        {
            "id": "26",
            "entry": "[26] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.02531"
        },
        {
            "id": "27",
            "entry": "[27] Mohammed J Zaki, Wagner Meira Jr, and Wagner Meira. Data mining and analysis: fundamental concepts and algorithms. Cambridge University Press, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zaki%2C%20Mohammed%20J.%20Meira%2C%20Jr%2C%20Wagner%20Meira%2C%20Wagner%20Data%20mining%20and%20analysis%3A%20fundamental%20concepts%20and%20algorithms%202014"
        },
        {
            "id": "28",
            "entry": "[28] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111\u20133119, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013"
        },
        {
            "id": "29",
            "entry": "[29] Stan Salvador and Philip Chan. Toward accurate dynamic time warping in linear time and space. Intelligent Data Analysis, 11(5):561\u2013580, 2007. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salvador%2C%20Stan%20Chan%2C%20Philip%20Toward%20accurate%20dynamic%20time%20warping%20in%20linear%20time%20and%20space%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salvador%2C%20Stan%20Chan%2C%20Philip%20Toward%20accurate%20dynamic%20time%20warping%20in%20linear%20time%20and%20space%202007"
        }
    ]
}
