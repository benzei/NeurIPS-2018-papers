{
    "filename": "7315-metaanchor-learning-to-detect-objects-with-customized-anchors.pdf",
    "metadata": {
        "title": "MetaAnchor: Learning to Detect Objects with Customized Anchors",
        "author": "Tong Yang, Xiangyu Zhang, Zeming Li, Wenqiang Zhang, Jian Sun",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7315-metaanchor-learning-to-detect-objects-with-customized-anchors.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks. Unlike many previous detectors model anchors via a predefined manner, in MetaAnchor anchor functions could be dynamically generated from the arbitrary customized prior boxes. Taking advantage of weight prediction, MetaAnchor is able to work with most of the anchor-based object detection systems such as RetinaNet. Compared with the predefined anchor scheme, we empirically find that MetaAnchor is more robust to anchor settings and bounding box distributions; in addition, it also shows the potential on transfer tasks. Our experiment on COCO detection task shows that MetaAnchor consistently outperforms the counterparts in various scenarios."
    },
    "keywords": [
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "convolutional neural networks",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_networks"
        },
        {
            "term": "pedestrian detection",
            "url": "https://en.wikipedia.org/wiki/pedestrian_detection"
        },
        {
            "term": "single shot",
            "url": "https://en.wikipedia.org/wiki/single_shot"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "object detection",
            "url": "https://en.wikipedia.org/wiki/object_detection"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "The last few years have seen the success of deep neural networks in object detection task [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "# of Anchors 3 \u00d7 3 5 \u00d7 5 7 \u00d7 7 9 \u00d7 9 search\n26.0 26.6 26.8 26.7 27.0 26.7 27.3 27.5 27.5 27.7 26.1 26.9 27.0 27.1 27.3 26.3 27.2 27.4 27.4 27.6 make the anchor functions to generate a wider range of predictions, which may enhance the model capability; second, rather than predefined anchor functions with independent parameters, MetaAnchor allows all the training boxes to contribute to the shared generators, which seems beneficial to the robustness over the different configurations or object box distributions",
        "We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks, in which anchor functions could be dynamically generated from the arbitrary customized prior boxes",
        "Compared with the predefined anchor scheme, we empirically find that MetaAnchor is more robust to anchor settings and bounding box distributions; in addition, it shows the potential on transfer tasks",
        "Our experiment on COCO detection task shows that MetaAnchor consistently outperforms the counterparts in various scenarios.\n4https://github.com/pjreddie/darknet 8 (a)"
    ],
    "key_statements": [
        "The last few years have seen the success of deep neural networks in object detection task [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "Object detection often requires to generate a set of bounding boxes along with their classification labels associated with each object in the given image",
        "We propose a flexible alternative to model anchors: instead of enumerating every possible bounding box prior bi and modeling the corresponding anchor functions respectively, in our framework anchor functions are dynamically generated from bi",
        "In Sec. 3, we present that with weight prediction mechanism [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] anchor function generator could be elegantly implemented and embedded into existing object detection frameworks for joint optimization",
        "Following the common practice [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] in COCO detection task, for training we use two different dataset splits: COCO-all and COCO-mini; while for test, all results are evaluated on the minival set which contains 5000 images",
        "# of Anchors 3 \u00d7 3 5 \u00d7 5 7 \u00d7 7 9 \u00d7 9 search\n26.0 26.6 26.8 26.7 27.0 26.7 27.3 27.5 27.5 27.7 26.1 26.9 27.0 27.1 27.3 26.3 27.2 27.4 27.4 27.6 make the anchor functions to generate a wider range of predictions, which may enhance the model capability; second, rather than predefined anchor functions with independent parameters, MetaAnchor allows all the training boxes to contribute to the shared generators, which seems beneficial to the robustness over the different configurations or object box distributions",
        "We find results of all the baseline models suffer from significantly drops especially on AP50, which implies the degradation of anchor functions; increasing the number of anchors works little on the performance",
        "After some ground truth boxes are erased, all the scores drop significantly; compared with the RetinaNet baseline, MetaAnchor suffers from smaller degradations and generates much better predictions, which shows the potential on the transfer tasks",
        "We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks, in which anchor functions could be dynamically generated from the arbitrary customized prior boxes",
        "Compared with the predefined anchor scheme, we empirically find that MetaAnchor is more robust to anchor settings and bounding box distributions; in addition, it shows the potential on transfer tasks",
        "Our experiment on COCO detection task shows that MetaAnchor consistently outperforms the counterparts in various scenarios.\n4https://github.com/pjreddie/darknet 8 (a)"
    ],
    "summary": [
        "The last few years have seen the success of deep neural networks in object detection task [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>].",
        "Note that in MetaAnchor the prior set B is not necessarily predefined; instead, it works as a customized manner \u2013 during inference, users could specify any anchor boxes, generate the corresponding anchor functions and use the latter to predict object boxes.",
        "Many traditional strategies use independent weights to model different anchor functions, so it is very likely for the anchors associated with few ground truth object boxes in training to produce poor results.",
        "In order to keep consistent with the original design, in MetaAnchor we use the same anchor generator function G(\u00b7, wcls) and G(\u00b7, wreg) for each level of detection head; while the \u201cstandard boxes\u201d (AH, AW ) in Equ. 7 are different between levels: suppose the standard box size in l-th level is (AHl, AWl), for (l + 1)-th level we set (AHl+1, AWl+1) = (2AHl, 2AWl).",
        "Following the common practice [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] in COCO detection task, for training we use two different dataset splits: COCO-all and COCO-mini; while for test, all results are evaluated on the minival set which contains 5000 images.",
        "26.0 26.6 26.8 26.7 27.0 26.7 27.3 27.5 27.5 27.7 26.1 26.9 27.0 27.1 27.3 26.3 27.2 27.4 27.4 27.6 make the anchor functions to generate a wider range of predictions, which may enhance the model capability; second, rather than predefined anchor functions with independent parameters, MetaAnchor allows all the training boxes to contribute to the shared generators, which seems beneficial to the robustness over the different configurations or object box distributions.",
        "What about the performance if the detection model is trained with another dataset which has the same class labels but different distributions of object box sizes?",
        "After some ground truth boxes are erased, all the scores drop significantly; compared with the RetinaNet baseline, MetaAnchor suffers from smaller degradations and generates much better predictions, which shows the potential on the transfer tasks.",
        "We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks, in which anchor functions could be dynamically generated from the arbitrary customized prior boxes.",
        "MetaAnchor is able to work with most of the anchor-based object detection systems such as RetinaNet. Compared with the predefined anchor scheme, we empirically find that MetaAnchor is more robust to anchor settings and bounding box distributions; in addition, it shows the potential on transfer tasks.",
        "Our experiment on COCO detection task shows that MetaAnchor consistently outperforms the counterparts in various scenarios"
    ],
    "headline": "We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Andrychowicz, M. Denil, S. Gomez, M. W. Hoffman, D. Pfau, T. Schaul, and N. de Freitas. Learning to learn by gradient descent by gradient descent. In Advances in Neural Information Processing Systems, pages 3981\u20133989, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andrychowicz%2C%20M.%20Denil%2C%20M.%20Gomez%2C%20S.%20Hoffman%2C%20M.W.%20Learning%20to%20learn%20by%20gradient%20descent%20by%20gradient%20descent%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andrychowicz%2C%20M.%20Denil%2C%20M.%20Gomez%2C%20S.%20Hoffman%2C%20M.W.%20Learning%20to%20learn%20by%20gradient%20descent%20by%20gradient%20descent%202016"
        },
        {
            "id": "2",
            "entry": "[2] J. Dai, Y. Li, K. He, and J. Sun. R-fcn: Object detection via region-based fully convolutional networks. In Advances in neural information processing systems, pages 379\u2013387, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20J.%20Li%2C%20Y.%20He%2C%20K.%20Sun%2C%20J.%20R-fcn%3A%20Object%20detection%20via%20region-based%20fully%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20J.%20Li%2C%20Y.%20He%2C%20K.%20Sun%2C%20J.%20R-fcn%3A%20Object%20detection%20via%20region-based%20fully%20convolutional%20networks%202016"
        },
        {
            "id": "3",
            "entry": "[3] P. Dollar, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: An evaluation of the state of the art. IEEE transactions on pattern analysis and machine intelligence, 34(4):743\u2013761, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dollar%2C%20P.%20Wojek%2C%20C.%20Schiele%2C%20B.%20Perona%2C%20P.%20Pedestrian%20detection%3A%20An%20evaluation%20of%20the%20state%20of%20the%20art%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dollar%2C%20P.%20Wojek%2C%20C.%20Schiele%2C%20B.%20Perona%2C%20P.%20Pedestrian%20detection%3A%20An%20evaluation%20of%20the%20state%20of%20the%20art%202012"
        },
        {
            "id": "4",
            "entry": "[4] M. Elhoseiny, B. Saleh, and A. Elgammal. Write a classifier: Zero-shot learning using purely textual descriptions. In Computer Vision (ICCV), 2013 IEEE International Conference on, pages 2584\u20132591. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Elhoseiny%2C%20M.%20Saleh%2C%20B.%20Elgammal%2C%20A.%20Write%20a%20classifier%3A%20Zero-shot%20learning%20using%20purely%20textual%20descriptions%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Elhoseiny%2C%20M.%20Saleh%2C%20B.%20Elgammal%2C%20A.%20Write%20a%20classifier%3A%20Zero-shot%20learning%20using%20purely%20textual%20descriptions%202013"
        },
        {
            "id": "5",
            "entry": "[5] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2147\u20132154, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Erhan%2C%20D.%20Szegedy%2C%20C.%20Toshev%2C%20A.%20Anguelov%2C%20D.%20Scalable%20object%20detection%20using%20deep%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Erhan%2C%20D.%20Szegedy%2C%20C.%20Toshev%2C%20A.%20Anguelov%2C%20D.%20Scalable%20object%20detection%20using%20deep%20neural%20networks%202014"
        },
        {
            "id": "6",
            "entry": "[6] C.-Y. Fu, W. Liu, A. Ranga, A. Tyagi, and A. C. Berg. Dssd: Deconvolutional single shot detector. arXiv preprint arXiv:1701.06659, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.06659"
        },
        {
            "id": "7",
            "entry": "[7] R. Girshick. Fast r-cnn. arXiv preprint arXiv:1504.08083, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1504.08083"
        },
        {
            "id": "8",
            "entry": "[8] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 580\u2013587, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Girshick%2C%20R.%20Donahue%2C%20J.%20Darrell%2C%20T.%20Malik%2C%20J.%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Girshick%2C%20R.%20Donahue%2C%20J.%20Darrell%2C%20T.%20Malik%2C%20J.%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation%202014"
        },
        {
            "id": "9",
            "entry": "[9] D. Ha, A. Dai, and Q. V. Le. Hypernetworks. arXiv preprint arXiv:1609.09106, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.09106"
        },
        {
            "id": "10",
            "entry": "[10] K. He, G. Gkioxari, P. Doll\u00e1r, and R. Girshick. Mask r-cnn. In Computer Vision (ICCV), 2017 IEEE International Conference on, pages 2980\u20132988. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=K%20He%20G%20Gkioxari%20P%20Doll%C3%A1r%20and%20R%20Girshick%20Mask%20rcnn%20In%20Computer%20Vision%20ICCV%202017%20IEEE%20International%20Conference%20on%20pages%2029802988%20IEEE%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=K%20He%20G%20Gkioxari%20P%20Doll%C3%A1r%20and%20R%20Girshick%20Mask%20rcnn%20In%20Computer%20Vision%20ICCV%202017%20IEEE%20International%20Conference%20on%20pages%2029802988%20IEEE%202017"
        },
        {
            "id": "11",
            "entry": "[11] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. In european conference on computer vision, pages 346\u2013361.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Spatial%20pyramid%20pooling%20in%20deep%20convolutional%20networks%20for%20visual%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Spatial%20pyramid%20pooling%20in%20deep%20convolutional%20networks%20for%20visual%20recognition"
        },
        {
            "id": "12",
            "entry": "[12] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "13",
            "entry": "[13] J. Hoffman, S. Guadarrama, E. S. Tzeng, R. Hu, J. Donahue, R. Girshick, T. Darrell, and K. Saenko. Lsda: Large scale detection through adaptation. In Advances in Neural Information Processing Systems, pages 3536\u20133544, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Guadarrama%2C%20S.%20Tzeng%2C%20E.S.%20Hu%2C%20R.%20Lsda%3A%20Large%20scale%20detection%20through%20adaptation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Guadarrama%2C%20S.%20Tzeng%2C%20E.S.%20Hu%2C%20R.%20Lsda%3A%20Large%20scale%20detection%20through%20adaptation%202014"
        },
        {
            "id": "14",
            "entry": "[14] R. Hu, P. Doll\u00e1r, K. He, T. Darrell, and R. Girshick. Learning to segment every thing. arXiv preprint arXiv:1711.10370, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.10370"
        },
        {
            "id": "15",
            "entry": "[15] L. Huang, Y. Yang, Y. Deng, and Y. Yu. Densebox: Unifying landmark localization with end to end object detection. arXiv preprint arXiv:1509.04874, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1509.04874"
        },
        {
            "id": "16",
            "entry": "[16] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1502.03167"
        },
        {
            "id": "17",
            "entry": "[17] Z. Li, C. Peng, G. Yu, X. Zhang, Y. Deng, and J. Sun. Light-head r-cnn: In defense of two-stage object detector. arXiv preprint arXiv:1711.07264, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.07264"
        },
        {
            "id": "18",
            "entry": "[18] Z. Li, C. Peng, G. Yu, X. Zhang, Y. Deng, and J. Sun. Detnet: A backbone network for object detection. arXiv preprint arXiv:1804.06215, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.06215"
        },
        {
            "id": "19",
            "entry": "[19] Z. Li and F. Zhou. Fssd: Feature fusion single shot multibox detector. arXiv preprint arXiv:1712.00960, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.00960"
        },
        {
            "id": "20",
            "entry": "[20] T.-Y. Lin, P. Doll\u00e1r, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. In CVPR, volume 1, page 4, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feature%20pyramid%20networks%20for%20object%20detection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feature%20pyramid%20networks%20for%20object%20detection%202017"
        },
        {
            "id": "21",
            "entry": "[21] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll\u00e1r. Focal loss for dense object detection. arXiv preprint arXiv:1708.02002, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.02002"
        },
        {
            "id": "22",
            "entry": "[22] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740\u2013755.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=TY%20Lin%20M%20Maire%20S%20Belongie%20J%20Hays%20P%20Perona%20D%20Ramanan%20P%20Doll%C3%A1r%20and%20C%20L%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20European%20conference%20on%20computer%20vision%20pages%20740755",
            "oa_query": "https://api.scholarcy.com/oa_version?query=TY%20Lin%20M%20Maire%20S%20Belongie%20J%20Hays%20P%20Perona%20D%20Ramanan%20P%20Doll%C3%A1r%20and%20C%20L%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20European%20conference%20on%20computer%20vision%20pages%20740755"
        },
        {
            "id": "23",
            "entry": "[23] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg. Ssd: Single shot multibox detector. In European conference on computer vision, pages 21\u201337.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20W.%20Anguelov%2C%20D.%20Erhan%2C%20D.%20Szegedy%2C%20C.%20Ssd%3A%20Single%20shot%20multibox%20detector",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20W.%20Anguelov%2C%20D.%20Erhan%2C%20D.%20Szegedy%2C%20C.%20Ssd%3A%20Single%20shot%20multibox%20detector"
        },
        {
            "id": "24",
            "entry": "[24] J. Mao, T. Xiao, Y. Jiang, and Z. Cao. What can help pedestrian detection? In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 1, page 3, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mao%2C%20J.%20Xiao%2C%20T.%20Jiang%2C%20Y.%20Cao%2C%20Z.%20What%20can%20help%20pedestrian%20detection%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mao%2C%20J.%20Xiao%2C%20T.%20Jiang%2C%20Y.%20Cao%2C%20Z.%20What%20can%20help%20pedestrian%20detection%3F%202017"
        },
        {
            "id": "25",
            "entry": "[25] I. Misra, A. Gupta, and M. Hebert. From red wine to red tomato: Composition with context. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 3, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Misra%2C%20I.%20Gupta%2C%20A.%20Hebert%2C%20M.%20From%20red%20wine%20to%20red%20tomato%3A%20Composition%20with%20context%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Misra%2C%20I.%20Gupta%2C%20A.%20Hebert%2C%20M.%20From%20red%20wine%20to%20red%20tomato%3A%20Composition%20with%20context%202017"
        },
        {
            "id": "26",
            "entry": "[26] M. Najibi, P. Samangouei, R. Chellappa, and L. Davis. Ssh: Single stage headless face detector. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4875\u20134884, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Najibi%2C%20M.%20Samangouei%2C%20P.%20Chellappa%2C%20R.%20Davis%2C%20L.%20Ssh%3A%20Single%20stage%20headless%20face%20detector%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Najibi%2C%20M.%20Samangouei%2C%20P.%20Chellappa%2C%20R.%20Davis%2C%20L.%20Ssh%3A%20Single%20stage%20headless%20face%20detector%202017"
        },
        {
            "id": "27",
            "entry": "[27] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10):1345\u20131359, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010"
        },
        {
            "id": "28",
            "entry": "[28] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 779\u2013788, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Redmon%2C%20J.%20Divvala%2C%20S.%20Girshick%2C%20R.%20Farhadi%2C%20A.%20You%20only%20look%20once%3A%20Unified%2C%20real-time%20object%20detection%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Redmon%2C%20J.%20Divvala%2C%20S.%20Girshick%2C%20R.%20Farhadi%2C%20A.%20You%20only%20look%20once%3A%20Unified%2C%20real-time%20object%20detection%202016"
        },
        {
            "id": "29",
            "entry": "[29] J. Redmon and A. Farhadi. Yolo9000: better, faster, stronger. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Redmon%2C%20J.%20Farhadi%2C%20A.%20Yolo9000%3A%20better%2C%20faster%2C%20stronger.%20arXiv%20p%202017"
        },
        {
            "id": "30",
            "entry": "[30] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91\u201399, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20S.%20He%2C%20K.%20Girshick%2C%20R.%20Sun%2C%20J.%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20S.%20He%2C%20K.%20Girshick%2C%20R.%20Sun%2C%20J.%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015"
        },
        {
            "id": "31",
            "entry": "[31] S. H. Rezatofighi, R. Kaskman, F. T. Motlagh, Q. Shi, D. Cremers, L. Leal-Taix\u00e9, and I. Reid. Deep perm-set net: Learn to predict sets with unknown permutation and cardinality using deep neural networks. arXiv preprint arXiv:1805.00613, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.00613"
        },
        {
            "id": "32",
            "entry": "[32] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "33",
            "entry": "[33] Z. Shen, Z. Liu, J. Li, Y.-G. Jiang, Y. Chen, and X. Xue. Dsod: Learning deeply supervised object detectors from scratch. In The IEEE International Conference on Computer Vision (ICCV), volume 3, page 7, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shen%2C%20Z.%20Liu%2C%20Z.%20Li%2C%20J.%20Jiang%2C%20Y.-G.%20Dsod%3A%20Learning%20deeply%20supervised%20object%20detectors%20from%20scratch%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shen%2C%20Z.%20Liu%2C%20Z.%20Li%2C%20J.%20Jiang%2C%20Y.-G.%20Dsod%3A%20Learning%20deeply%20supervised%20object%20detectors%20from%20scratch%202017"
        },
        {
            "id": "34",
            "entry": "[34] G. Song, Y. Liu, M. Jiang, Y. Wang, J. Yan, and B. Leng. Beyond trade-off: Accelerate fcn-based face detector with higher accuracy. arXiv preprint arXiv:1804.05197, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.05197"
        },
        {
            "id": "35",
            "entry": "[35] R. Stewart, M. Andriluka, and A. Y. Ng. End-to-end people detection in crowded scenes. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2325\u20132333, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stewart%2C%20R.%20Andriluka%2C%20M.%20Ng%2C%20A.Y.%20End-to-end%20people%20detection%20in%20crowded%20scenes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stewart%2C%20R.%20Andriluka%2C%20M.%20Ng%2C%20A.Y.%20End-to-end%20people%20detection%20in%20crowded%20scenes%202016"
        },
        {
            "id": "36",
            "entry": "[36] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, et al. Going deeper with convolutions. Cvpr, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=C%20Szegedy%20W%20Liu%20Y%20Jia%20P%20Sermanet%20S%20Reed%20D%20Anguelov%20D%20Erhan%20V%20Vanhoucke%20A%20Rabinovich%20et%20al%20Going%20deeper%20with%20convolutions%20Cvpr%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=C%20Szegedy%20W%20Liu%20Y%20Jia%20P%20Sermanet%20S%20Reed%20D%20Anguelov%20D%20Erhan%20V%20Vanhoucke%20A%20Rabinovich%20et%20al%20Going%20deeper%20with%20convolutions%20Cvpr%202015"
        },
        {
            "id": "37",
            "entry": "[37] C. Szegedy, S. Reed, D. Erhan, D. Anguelov, and S. Ioffe. Scalable, high-quality object detection. arXiv preprint arXiv:1412.1441, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.1441"
        },
        {
            "id": "38",
            "entry": "[38] J. Wang, Y. Yuan, G. Yu, and S. Jian. Sface: An efficient network for face detection in large scale variations. arXiv preprint arXiv:1804.06559, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.06559"
        },
        {
            "id": "39",
            "entry": "[39] X. Wang, T. Xiao, Y. Jiang, S. Shao, J. Sun, and C. Shen. Repulsion loss: Detecting pedestrians in a crowd. arXiv preprint arXiv:1711.07752, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.07752"
        },
        {
            "id": "40",
            "entry": "[40] Y.-X. Wang and M. Hebert. Learning to learn: Model regression networks for easy small sample learning. In European Conference on Computer Vision, pages 616\u2013634.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Y.-X.%20Hebert%2C%20M.%20Learning%20to%20learn%3A%20Model%20regression%20networks%20for%20easy%20small%20sample%20learning",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Y.-X.%20Hebert%2C%20M.%20Learning%20to%20learn%3A%20Model%20regression%20networks%20for%20easy%20small%20sample%20learning"
        },
        {
            "id": "41",
            "entry": "[41] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao. Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters, 23(10):1499\u20131503, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20K.%20Zhang%2C%20Z.%20Li%2C%20Z.%20Qiao%2C%20Y.%20Joint%20face%20detection%20and%20alignment%20using%20multitask%20cascaded%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20K.%20Zhang%2C%20Z.%20Li%2C%20Z.%20Qiao%2C%20Y.%20Joint%20face%20detection%20and%20alignment%20using%20multitask%20cascaded%20convolutional%20networks%202016"
        },
        {
            "id": "42",
            "entry": "[42] L. Zhang, L. Lin, X. Liang, and K. He. Is faster r-cnn doing well for pedestrian detection? In European Conference on Computer Vision, pages 443\u2013457.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20L.%20Lin%2C%20L.%20Liang%2C%20X.%20He%2C%20K.%20Is%20faster%20r-cnn%20doing%20well%20for%20pedestrian%20detection%3F",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20L.%20Lin%2C%20L.%20Liang%2C%20X.%20He%2C%20K.%20Is%20faster%20r-cnn%20doing%20well%20for%20pedestrian%20detection%3F"
        },
        {
            "id": "43",
            "entry": "[43] S. Zhang, X. Zhu, Z. Lei, H. Shi, X. Wang, and S. Z. Li. S3fd: Single shot scale-invariant face detector. arXiv preprint arXiv:1708.05237, 2017. ",
            "arxiv_url": "https://arxiv.org/pdf/1708.05237"
        }
    ]
}
