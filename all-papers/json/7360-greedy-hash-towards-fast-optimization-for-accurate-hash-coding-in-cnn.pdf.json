{
    "filename": "7360-greedy-hash-towards-fast-optimization-for-accurate-hash-coding-in-cnn.pdf",
    "metadata": {
        "title": "Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN",
        "author": "Shupeng Su, Chao Zhang, Kai Han, Yonghong Tian",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7360-greedy-hash-towards-fast-optimization-for-accurate-hash-coding-in-cnn.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "To convert the input into binary code, hashing algorithm has been widely used for approximate nearest neighbor search on large-scale image sets due to its computation and storage efficiency. Deep hashing further improves the retrieval quality by combining the hash coding with deep neural network. However, a major difficulty in deep hashing lies in the discrete constraints imposed on the network output, which generally makes the optimization NP hard. In this work, we adopt the greedy principle to tackle this NP hard problem by iteratively updating the network toward the probable optimal discrete solution in each iteration. A hash coding layer is designed to implement our approach which strictly uses the sign function in forward propagation to maintain the discrete constraints, while in back propagation the gradients are transmitted intactly to the front layer to avoid the vanishing gradients. In addition to the theoretical derivation, we provide a new perspective to visualize and understand the effectiveness and efficiency of our algorithm. Experiments on benchmark datasets show that our scheme outperforms state-of-the-art hashing methods in both supervised and unsupervised tasks."
    },
    "keywords": [
        {
            "term": "sign function",
            "url": "https://en.wikipedia.org/wiki/sign_function"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "Mean Average Precision",
            "url": "https://en.wikipedia.org/wiki/Mean_Average_Precision"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "storage efficiency",
            "url": "https://en.wikipedia.org/wiki/storage_efficiency"
        },
        {
            "term": "binary code",
            "url": "https://en.wikipedia.org/wiki/binary_code"
        }
    ],
    "highlights": [
        "In the era of big data, searching for the desired information has become an important topic in such a vast ocean of data",
        "This paper proposes a faster and more accurate algorithm to integrate the hash coding with neural network",
        "(1) We propose to adopt greedy algorithm for fast processing of hashing discrete optimization, and a new coding layer is designed, in which the sign function is strictly used in forward propagation against the quantization error, and later the gradients are transmitted intactly to the front layer which effectively prevents the vanishing gradients and updates all bits together",
        "The dynamic classification loss and Mean Average Precision are shown on Figure 3(b) and 3(c), in which label tanh means using tanh function as relaxation, penalty denotes method adding penalty term to generate features as discrete as possible, and original represents training without hash coding",
        "It is interesting to discover that retrieval with hash binary code is better than the retrieval with original unrestricted features, probably because the softmax function generally needs adding retrieval loss to further constrain the image feature, which is exactly the merit of hashing that owns the nature of aggregating the inputs in each quadrant as is demonstrated in Section 2.3",
        "In this paper we propose to adopt greedy algorithm to tackle the discrete hashing optimization, and we design a new neural layer to implement our approach, which fixedly uses the sign function in forward propagation without any relaxation to avoid the quantization error, while in backward propagation the gradients are transmitted intactly to the front layer, preventing the vanishing gradients and helping to achieve fast convergence"
    ],
    "key_statements": [
        "In the era of big data, searching for the desired information has become an important topic in such a vast ocean of data",
        "This paper proposes a faster and more accurate algorithm to integrate the hash coding with neural network",
        "(1) We propose to adopt greedy algorithm for fast processing of hashing discrete optimization, and a new coding layer is designed, in which the sign function is strictly used in forward propagation against the quantization error, and later the gradients are transmitted intactly to the front layer which effectively prevents the vanishing gradients and updates all bits together",
        "The dynamic classification loss and Mean Average Precision are shown on Figure 3(b) and 3(c), in which label tanh means using tanh function as relaxation, penalty denotes method adding penalty term to generate features as discrete as possible, and original represents training without hash coding",
        "It is interesting to discover that retrieval with hash binary code is better than the retrieval with original unrestricted features, probably because the softmax function generally needs adding retrieval loss to further constrain the image feature, which is exactly the merit of hashing that owns the nature of aggregating the inputs in each quadrant as is demonstrated in Section 2.3",
        "In this paper we propose to adopt greedy algorithm to tackle the discrete hashing optimization, and we design a new neural layer to implement our approach, which fixedly uses the sign function in forward propagation without any relaxation to avoid the quantization error, while in backward propagation the gradients are transmitted intactly to the front layer, preventing the vanishing gradients and helping to achieve fast convergence"
    ],
    "summary": [
        "In the era of big data, searching for the desired information has become an important topic in such a vast ocean of data.",
        "(1) We propose to adopt greedy algorithm for fast processing of hashing discrete optimization, and a new coding layer is designed, in which the sign function is strictly used in forward propagation against the quantization error, and later the gradients are transmitted intactly to the front layer which effectively prevents the vanishing gradients and updates all bits together.",
        "For fair comparison with the previous works, we use the pre-trained AlexNet [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>] as our neural network, in which we append a new fc layer after fc7 to generate feature of desired length and append our hash layer to produce binary code.",
        "We rerun the code released by the DSDH author and we follow the experiment setting in their program: using pre-trained CNN and encoding the images with maximum 48 bits as well as minimum 12 bits on supervised CIFAR-10 (I).",
        "The dynamic classification loss and MAP are shown on Figure 3(b) and 3(c), in which label tanh means using tanh function as relaxation, penalty denotes method adding penalty term to generate features as discrete as possible, and original represents training without hash coding.",
        "It is interesting to discover that retrieval with hash binary code is better than the retrieval with original unrestricted features, probably because the softmax function generally needs adding retrieval loss to further constrain the image feature, which is exactly the merit of hashing that owns the nature of aggregating the inputs in each quadrant as is demonstrated in Section 2.3.",
        "Notice that we have specially compared our method with DPLM [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] in Table 2, which distinctly reveals that using deep learned features as input can improve the performance of DPLM while our method can further boost the results as we better integrate hash coding with CNN and simultaneously realize efficient end-to-end training of the network.",
        "In this paper we propose to adopt greedy algorithm to tackle the discrete hashing optimization, and we design a new neural layer to implement our approach, which fixedly uses the sign function in forward propagation without any relaxation to avoid the quantization error, while in backward propagation the gradients are transmitted intactly to the front layer, preventing the vanishing gradients and helping to achieve fast convergence.",
        "The superiority of our method is proved from a novel visual perspective as well as abundant experiments on different retrieval tasks"
    ],
    "headline": "In addition to the theoretical derivation, we provide a new perspective to visualize and understand the effectiveness and efficiency of our algorithm",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] H. Attouch, J. Bolte, and B. F. Svaiter. Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward\u2013backward splitting, and regularized gauss\u2013seidel methods. Mathematical Programming, 137(1-2):91\u2013129, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Attouch%2C%20H.%20Bolte%2C%20J.%20Svaiter%2C%20B.F.%20Convergence%20of%20descent%20methods%20for%20semi-algebraic%20and%20tame%20problems%3A%20proximal%20algorithms%2C%20forward%E2%80%93backward%20splitting%2C%20and%20regularized%20gauss%E2%80%93seidel%20methods%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Attouch%2C%20H.%20Bolte%2C%20J.%20Svaiter%2C%20B.F.%20Convergence%20of%20descent%20methods%20for%20semi-algebraic%20and%20tame%20problems%3A%20proximal%20algorithms%2C%20forward%E2%80%93backward%20splitting%2C%20and%20regularized%20gauss%E2%80%93seidel%20methods%202013"
        },
        {
            "id": "2",
            "entry": "[2] Y. Bengio, N. L\u00e9onard, and A. Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1308.3432"
        },
        {
            "id": "3",
            "entry": "[3] J. Bolte, S. Sabach, and M. Teboulle. Proximal alternating linearized minimization or nonconvex and nonsmooth problems. Mathematical Programming, 146(1-2):459\u2013494, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bolte%2C%20J.%20Sabach%2C%20S.%20Teboulle%2C%20M.%20Proximal%20alternating%20linearized%20minimization%20or%20nonconvex%20and%20nonsmooth%20problems%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bolte%2C%20J.%20Sabach%2C%20S.%20Teboulle%2C%20M.%20Proximal%20alternating%20linearized%20minimization%20or%20nonconvex%20and%20nonsmooth%20problems%202014"
        },
        {
            "id": "4",
            "entry": "[4] Z. Cao, M. Long, J. Wang, and P. S. Yu. Hashnet: Deep learning to hash by continuation. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Z.%20Long%2C%20M.%20Wang%2C%20J.%20Yu%2C%20P.S.%20Hashnet%3A%20Deep%20learning%20to%20hash%20by%20continuation%202017-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Z.%20Long%2C%20M.%20Wang%2C%20J.%20Yu%2C%20P.S.%20Hashnet%3A%20Deep%20learning%20to%20hash%20by%20continuation%202017-10"
        },
        {
            "id": "5",
            "entry": "[5] K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. arXiv preprint arXiv:1405.3531, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1405.3531"
        },
        {
            "id": "6",
            "entry": "[6] T.-T. Do, D.-K. Le Tan, T. T. Pham, and N.-M. Cheung. Simultaneous feature aggregating and hashing for large-scale image search. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6618\u20136627, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Do%2C%20T.-T.%20Tan%2C%20D.-K.Le%20Pham%2C%20T.T.%20Cheung%2C%20N.-M.%20Simultaneous%20feature%20aggregating%20and%20hashing%20for%20large-scale%20image%20search%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Do%2C%20T.-T.%20Tan%2C%20D.-K.Le%20Pham%2C%20T.T.%20Cheung%2C%20N.-M.%20Simultaneous%20feature%20aggregating%20and%20hashing%20for%20large-scale%20image%20search%202017"
        },
        {
            "id": "7",
            "entry": "[7] A. Gionis, P. Indyk, R. Motwani, et al. Similarity search in high dimensions via hashing. In Vldb, volume 99, pages 518\u2013529, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gionis%2C%20A.%20Indyk%2C%20P.%20Motwani%2C%20R.%20Similarity%20search%20in%20high%20dimensions%20via%20hashing%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gionis%2C%20A.%20Indyk%2C%20P.%20Motwani%2C%20R.%20Similarity%20search%20in%20high%20dimensions%20via%20hashing%201999"
        },
        {
            "id": "8",
            "entry": "[8] Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(12):2916\u20132929, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20Y.%20Lazebnik%2C%20S.%20Gordo%2C%20A.%20Perronnin%2C%20F.%20Iterative%20quantization%3A%20A%20procrustean%20approach%20to%20learning%20binary%20codes%20for%20large-scale%20image%20retrieval%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20Y.%20Lazebnik%2C%20S.%20Gordo%2C%20A.%20Perronnin%2C%20F.%20Iterative%20quantization%3A%20A%20procrustean%20approach%20to%20learning%20binary%20codes%20for%20large-scale%20image%20retrieval%202013"
        },
        {
            "id": "9",
            "entry": "[9] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio. Deep learning, volume 1. MIT press Cambridge, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Bengio%2C%20Y.%20Courville%2C%20A.%20Bengio%2C%20Y.%20Deep%20learning%2C%20volume%201%202016"
        },
        {
            "id": "10",
            "entry": "[10] K. He, F. Wen, and J. Sun. K-means hashing: An affinity-preserving quantization method for learning binary compact codes. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 2938\u20132945. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Wen%2C%20F.%20Sun%2C%20J.%20K-means%20hashing%3A%20An%20affinity-preserving%20quantization%20method%20for%20learning%20binary%20compact%20codes%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Wen%2C%20F.%20Sun%2C%20J.%20K-means%20hashing%3A%20An%20affinity-preserving%20quantization%20method%20for%20learning%20binary%20compact%20codes%202013"
        },
        {
            "id": "11",
            "entry": "[11] J.-P. Heo, Y. Lee, J. He, S.-F. Chang, and S.-E. Yoon. Spherical hashing. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2957\u20132964. IEEE, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heo%2C%20J.-P.%20Lee%2C%20Y.%20He%2C%20J.%20Chang%2C%20S.-F.%20Spherical%20hashing%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heo%2C%20J.-P.%20Lee%2C%20Y.%20He%2C%20J.%20Chang%2C%20S.-F.%20Spherical%20hashing%202012"
        },
        {
            "id": "12",
            "entry": "[12] M. Hu, Y. Yang, F. Shen, N. Xie, and H. T. Shen. Hashing with angular reconstructive embeddings. IEEE Transactions on Image Processing, 27(2):545\u2013555, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20M.%20Yang%2C%20Y.%20Shen%2C%20F.%20Xie%2C%20N.%20Hashing%20with%20angular%20reconstructive%20embeddings%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20M.%20Yang%2C%20Y.%20Shen%2C%20F.%20Xie%2C%20N.%20Hashing%20with%20angular%20reconstructive%20embeddings%202018"
        },
        {
            "id": "13",
            "entry": "[13] A. Krizhevsky. One weird trick for parallelizing convolutional neural networks. arXiv preprint arXiv:1404.5997, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1404.5997"
        },
        {
            "id": "14",
            "entry": "[14] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Hinton%2C%20G.%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "15",
            "entry": "[15] H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lai%2C%20H.%20Pan%2C%20Y.%20Liu%2C%20Y.%20Yan%2C%20S.%20Simultaneous%20feature%20learning%20and%20hash%20coding%20with%20deep%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lai%2C%20H.%20Pan%2C%20Y.%20Liu%2C%20Y.%20Yan%2C%20S.%20Simultaneous%20feature%20learning%20and%20hash%20coding%20with%20deep%20neural%20networks%202015"
        },
        {
            "id": "16",
            "entry": "[16] Q. Li, Z. Sun, R. He, and T. Tan. Deep supervised discrete hashing. In Advances in Neural Information Processing Systems, pages 2479\u20132488, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Q.%20Sun%2C%20Z.%20He%2C%20R.%20Tan%2C%20T.%20Deep%20supervised%20discrete%20hashing%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Q.%20Sun%2C%20Z.%20He%2C%20R.%20Tan%2C%20T.%20Deep%20supervised%20discrete%20hashing%202017"
        },
        {
            "id": "17",
            "entry": "[17] W.-J. Li, S. Wang, and W.-C. Kang. Feature learning based deep supervised hashing with pairwise labels. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, pages 1711\u20131717. AAAI Press, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20W.-J.%20Wang%2C%20S.%20Kang%2C%20W.-C.%20Feature%20learning%20based%20deep%20supervised%20hashing%20with%20pairwise%20labels%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20W.-J.%20Wang%2C%20S.%20Kang%2C%20W.-C.%20Feature%20learning%20based%20deep%20supervised%20hashing%20with%20pairwise%20labels%202016"
        },
        {
            "id": "18",
            "entry": "[18] K. Lin, J. Lu, C.-S. Chen, and J. Zhou. Learning compact binary descriptors with unsupervised deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1183\u20131192, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20K.%20Lu%2C%20J.%20Chen%2C%20C.-S.%20Zhou%2C%20J.%20Learning%20compact%20binary%20descriptors%20with%20unsupervised%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20K.%20Lu%2C%20J.%20Chen%2C%20C.-S.%20Zhou%2C%20J.%20Learning%20compact%20binary%20descriptors%20with%20unsupervised%20deep%20neural%20networks%202016"
        },
        {
            "id": "19",
            "entry": "[19] K. Lin, H.-F. Yang, J.-H. Hsiao, and C.-S. Chen. Deep learning of binary hash codes for fast image retrieval. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on, pages 27\u201335. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20K.%20Yang%2C%20H.-F.%20Hsiao%2C%20J.-H.%20Chen%2C%20C.-S.%20Deep%20learning%20of%20binary%20hash%20codes%20for%20fast%20image%20retrieval%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20K.%20Yang%2C%20H.-F.%20Hsiao%2C%20J.-H.%20Chen%2C%20C.-S.%20Deep%20learning%20of%20binary%20hash%20codes%20for%20fast%20image%20retrieval%202015"
        },
        {
            "id": "20",
            "entry": "[20] H. Liu, R. Wang, S. Shan, and X. Chen. Deep supervised hashing for fast image retrieval. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2064\u20132072, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20H.%20Wang%2C%20R.%20Shan%2C%20S.%20Chen%2C%20X.%20Deep%20supervised%20hashing%20for%20fast%20image%20retrieval%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20H.%20Wang%2C%20R.%20Shan%2C%20S.%20Chen%2C%20X.%20Deep%20supervised%20hashing%20for%20fast%20image%20retrieval%202016"
        },
        {
            "id": "21",
            "entry": "[21] W. Liu, J. Wang, R. Ji, Y.-G. Jiang, and S.-F. Chang. Supervised hashing with kernels. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2074\u20132081. IEEE, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20W.%20Wang%2C%20J.%20Ji%2C%20R.%20Jiang%2C%20Y.-G.%20Supervised%20hashing%20with%20kernels%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20W.%20Wang%2C%20J.%20Ji%2C%20R.%20Jiang%2C%20Y.-G.%20Supervised%20hashing%20with%20kernels%202012"
        },
        {
            "id": "22",
            "entry": "[22] J. Masci, M. M. Bronstein, A. M. Bronstein, and J. Schmidhuber. Multimodal similarity-preserving hashing. IEEE transactions on pattern analysis and machine intelligence, 36(4):824\u2013830, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Masci%2C%20J.%20Bronstein%2C%20M.M.%20Bronstein%2C%20A.M.%20Schmidhuber%2C%20J.%20Multimodal%20similarity-preserving%20hashing%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Masci%2C%20J.%20Bronstein%2C%20M.M.%20Bronstein%2C%20A.M.%20Schmidhuber%2C%20J.%20Multimodal%20similarity-preserving%20hashing%202014"
        },
        {
            "id": "23",
            "entry": "[23] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer. Automatic differentiation in pytorch. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20A.%20Gross%2C%20S.%20Chintala%2C%20S.%20Chanan%2C%20G.%20Automatic%20differentiation%20in%20pytorch%202017"
        },
        {
            "id": "24",
            "entry": "[24] T. Raiko, M. Berglund, G. Alain, and L. Dinh. Techniques for learning binary stochastic feedforward neural networks. arXiv preprint arXiv:1406.2989, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1406.2989"
        },
        {
            "id": "25",
            "entry": "[25] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "26",
            "entry": "[26] F. Shen, C. Shen, W. Liu, and H. T. Shen. Supervised discrete hashing. In CVPR, volume 2, page 5, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shen%2C%20F.%20Shen%2C%20C.%20Liu%2C%20W.%20Shen%2C%20H.T.%20Supervised%20discrete%20hashing%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shen%2C%20F.%20Shen%2C%20C.%20Liu%2C%20W.%20Shen%2C%20H.T.%20Supervised%20discrete%20hashing%202015"
        },
        {
            "id": "27",
            "entry": "[27] F. Shen, X. Zhou, Y. Yang, J. Song, H. T. Shen, and D. Tao. A fast optimization method for general binary code learning. IEEE Transactions on Image Processing, 25(12):5610\u20135621, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shen%2C%20F.%20Zhou%2C%20X.%20Yang%2C%20Y.%20Song%2C%20J.%20A%20fast%20optimization%20method%20for%20general%20binary%20code%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shen%2C%20F.%20Zhou%2C%20X.%20Yang%2C%20Y.%20Song%2C%20J.%20A%20fast%20optimization%20method%20for%20general%20binary%20code%20learning%202016"
        },
        {
            "id": "28",
            "entry": "[28] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "29",
            "entry": "[29] X. Wang, Y. Shi, and K. M. Kitani. Deep supervised hashing with triplet labels. In Asian Conference on",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20X.%20Shi%2C%20Y.%20Kitani%2C%20K.M.%20Deep%20supervised%20hashing%20with%20triplet%20labels",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20X.%20Shi%2C%20Y.%20Kitani%2C%20K.M.%20Deep%20supervised%20hashing%20with%20triplet%20labels"
        },
        {
            "id": "30",
            "entry": "[30] R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, volume 1, page 2, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xia%2C%20R.%20Pan%2C%20Y.%20Lai%2C%20H.%20Liu%2C%20C.%20Supervised%20hashing%20for%20image%20retrieval%20via%20image%20representation%20learning%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xia%2C%20R.%20Pan%2C%20Y.%20Lai%2C%20H.%20Liu%2C%20C.%20Supervised%20hashing%20for%20image%20retrieval%20via%20image%20representation%20learning%202014"
        },
        {
            "id": "31",
            "entry": "[31] H.-F. Yang, K. Lin, and C.-S. Chen. Supervised learning of semantics-preserving hashing via deep neural networks for large-scale image search. arXiv preprint arXiv:1507.00101, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.00101"
        },
        {
            "id": "32",
            "entry": "[32] R. Zhang, L. Lin, R. Zhang, W. Zuo, and L. Zhang. Bit-scalable deep hashing with regularized similarity learning for image retrieval and person re-identification. IEEE Transactions on Image Processing, 24(12):4766\u20134779, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20R.%20Lin%2C%20L.%20Zhang%2C%20R.%20Zuo%2C%20W.%20Bit-scalable%20deep%20hashing%20with%20regularized%20similarity%20learning%20for%20image%20retrieval%20and%20person%20re-identification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20R.%20Lin%2C%20L.%20Zhang%2C%20R.%20Zuo%2C%20W.%20Bit-scalable%20deep%20hashing%20with%20regularized%20similarity%20learning%20for%20image%20retrieval%20and%20person%20re-identification%202015"
        },
        {
            "id": "33",
            "entry": "[33] Z. Zhang, Y. Chen, and V. Saligrama. Efficient training of very deep neural networks for supervised hashing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1487\u20131495, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Z.%20Chen%2C%20Y.%20Saligrama%2C%20V.%20Efficient%20training%20of%20very%20deep%20neural%20networks%20for%20supervised%20hashing%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Z.%20Chen%2C%20Y.%20Saligrama%2C%20V.%20Efficient%20training%20of%20very%20deep%20neural%20networks%20for%20supervised%20hashing%202016"
        },
        {
            "id": "34",
            "entry": "[34] F. Zhao, Y. Huang, L. Wang, and T. Tan. Deep semantic ranking based hashing for multi-label image retrieval. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pages 1556\u2013 1564. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20F.%20Huang%2C%20Y.%20Wang%2C%20L.%20Tan%2C%20T.%20Deep%20semantic%20ranking%20based%20hashing%20for%20multi-label%20image%20retrieval%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20F.%20Huang%2C%20Y.%20Wang%2C%20L.%20Tan%2C%20T.%20Deep%20semantic%20ranking%20based%20hashing%20for%20multi-label%20image%20retrieval%202015"
        },
        {
            "id": "35",
            "entry": "[35] Y. Zhou, S. Huang, Y. Zhang, and Y. Wang. Deep hashing with triplet quantization loss. arXiv preprint arXiv:1710.11445, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.11445"
        },
        {
            "id": "36",
            "entry": "[36] H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI, pages 2415\u20132421, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20H.%20Long%2C%20M.%20Wang%2C%20J.%20Cao%2C%20Y.%20Deep%20hashing%20network%20for%20efficient%20similarity%20retrieval%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20H.%20Long%2C%20M.%20Wang%2C%20J.%20Cao%2C%20Y.%20Deep%20hashing%20network%20for%20efficient%20similarity%20retrieval%202016"
        }
    ]
}
