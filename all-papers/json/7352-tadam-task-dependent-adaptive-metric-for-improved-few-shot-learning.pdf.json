{
    "filename": "7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.pdf",
    "metadata": {
        "title": "TADAM: Task dependent adaptive metric for improved few-shot learning",
        "author": "Boris Oreshkin, Pau Rodr\u00edguez L\u00f3pez, Alexandre Lacoste",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.pdf"
        },
        "abstract": "8 1. Please provide an \"overall score\" for this submission. 9 3: A clear reject. I vote and argue for rejecting this submission. 2. Please provide a \"confidence score\" for your assessment of this submission. 5: You are absolutely certain about your assessment. You are very familiar with the related work. 3. Please provide detailed comments that explain your \"overall score\" and \"confidence score\" for this submis13 sion. You should summarize the main ideas of the submission and relate these ideas to previous work at NIPS and in other archival conferences and journals. You should then summarize the strengths and weaknesses of the submission, focusing on each of the following four criteria: quality, clarity, originality, and significance."
    },
    "keywords": [
        {
            "term": "mathematical analysis",
            "url": "https://en.wikipedia.org/wiki/mathematical_analysis"
        },
        {
            "term": "non trivial",
            "url": "https://en.wikipedia.org/wiki/non_trivial"
        },
        {
            "term": "Recurrent Neural Network",
            "url": "https://en.wikipedia.org/wiki/Recurrent_Neural_Network"
        }
    ],
    "highlights": [
        "28 The theoretical contribution of this paper is to write out the gradient of the objective function from [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>] with the addition of the temperature scaling parameter in the softmax computation",
        "The lower layers closer to the similarity metric need to be conditioned more than the shallower layers closer to the image because pixel-level features extracted by shallow level layers are not task specific.\" Authors, response to Reviewer #2, point 3 To address the concerns of the reviewer we have removed these statements. Reviewer #2, point 4 A conceptual point is made in the conclusion unnecessarily: it does not appear that the fact that \"the scaled cosine similarity...does not belong to the class of Bregman divergences\" is used anywhere in the paper, yet it is mentioned in the conclusion. Authors, response to Reviewer #2, point 4 In order to address the reviewers comment we removed this point and replaced it with the following: \u201cWe showed that the scaled cosine similarity performs at par with Euclidean distance, unlike its unscaled counterpart\u201d CLARITY 61 The paper is reasonably clear",
        "To address the reviewer\u2019s concern we have further clarified this point in the section \u201cSummary of contributions\u201d. - \"Task conditioning\" makes use of a task-dataset-conditioning network to predict the scale and offset parameters of batch normalization layers as in [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]. Authors, response to Reviewer #2, point To address the point raised by the reviewer, we have extended the related work section discussion of the modifications we introduced to make this approach work in the few-shot learning setting. Reviewer #2, point - Auxiliary tasks are known to be beneficial to few-shot learning [*,**] and learning in general. Authors, response to Reviewer #2, point 13\n130 References [*,**] do not seem to address FSL scenario",
        "We chose not to expand the discussion on the possibility of using the unlabelled samples in the support set, because it is clearly outside of the scope of the paper. Reviewer #2, point pg. 1: It is strange to introduce few-shot learning with Ravi & Larochelle as the first citation, to claim that the problem has subsequently been reframed by Ravi & Larochelle as meta-learning \u2013 they are the same paper! This needs to be rewritten to correctly capture the nuanced difference between few-shot and meta-learning. Authors, response to Reviewer #2, point 16\n159 We addressed the comment by removing Ravi & Larochelle from the first citation.\n160 Reviewer #2, point 17 161 pg. 1: The claim that certain approaches to few-shot learning and meta-learning are \"influential\" and \"central to the field\" is subjective and Authors, response to Reviewer #2, point 17 164 We replaced \u201cinfluencial\u201d and removed \u201ccentral to the field\u201d with \u201crecent\u201d to make the statement more balanced.\n165 Reviewer #2, point 18 166 pg. 1: \"a feature extractor\" A feature extractor is more general than a neural network with 167 learned parameters, so this relationship needs to be reversed",
        "The training criterion for [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>] is discussed in lines 62-63 but [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>]\u2019s is not. Authors, response to Reviewer #2, point 20 183 We addressed the comment by including a more detailed explanation of the Matching networks by inserting the following sentence \u201cFor example, Matching networks[<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] use sample-wise attention mechanism to perform kernel label regression).\u201d Reviewer #2, point 21 187 line 60: \"proposed to introduce inductive bias\" Framing the computation of the class centroid as an \"inductive bias\" is not useful in this context unless it is identified why it is a useful inductive bias. Authors, response to Reviewer #2, point 21 190 We addressed the comment by removing the \u201cinductive bias\u201d\n191 Reviewer #2, point 22 192 line 61: \"a unique feature representation\" The mean of embeddings is not necessarily unique.\n193 Authors, response to Reviewer #2, point 22 194 we replaced this by \u201cdefined a feature representation\u201d line 61: \"for each class k\" It is confusing to use k to index classes when above K have been used to count examples in each class. Authors, response to Reviewer #2, point 23\n199 We addressed the comment by using K for the number of classes and M for the number of shots consistently throughout the paper. Reviewer #2, point line 77-8: \"This is the case of Matching Networks [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>], which use a Recurrent Neural Network (RNN) to accumulate information about a given task.\" The vanilla version of MNs does NOT use an Recurrent Neural Network; only the \"full-context embedding\" version requires it. Authors, response to Reviewer #2, point 24\n206 We addressed this comment by rephrazing the relevant part of the sentence as follows: \u201c...which optionally use a Recurrent Neural Network (RNN)...\u201d Reviewer #2, point line 108-109: \"We observed that this improvement could be directly attributed to the interference of the different scaling of the metrics with the softmax.\" This needs an experimental result, and so likely does not belong in the \"Model Description\" section. Authors, response to Reviewer #2, point 25\n213 We would like to thank the reviewer for pointing this out",
        "The idea of scaling is mentioned in some other papers like Geoffrey Hinton et al, Distilling the Knowledge in a Neural Network, 2015 It would be great to discuss the relatedness. Authors, response to Reviewer #4, point W5 The main theoretical contribution of our paper is the mathematical analysis of the effect of the limiting cases of \u03b1 on the few-shot update rule"
    ],
    "key_statements": [
        "28 The theoretical contribution of this paper is to write out the gradient of the objective function from [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>] with the addition of the temperature scaling parameter in the softmax computation",
        "Based on Lemma 1 and insights obtained from the analysis of the limiting cases, we posed the following hypothesis: \u201cthere is an optimal value of scaling parameter \u03b1 for a given combination of dataset, metric and task\u201d",
        "This hypothesis was validated on two independent datasets in the experimental part of the paper",
        "The lower layers closer to the similarity metric need to be conditioned more than the shallower layers closer to the image because pixel-level features extracted by shallow level layers are not task specific.\" Authors, response to Reviewer #2, point 3 To address the concerns of the reviewer we have removed these statements. Reviewer #2, point 4 A conceptual point is made in the conclusion unnecessarily: it does not appear that the fact that \"the scaled cosine similarity...does not belong to the class of Bregman divergences\" is used anywhere in the paper, yet it is mentioned in the conclusion. Authors, response to Reviewer #2, point 4 In order to address the reviewers comment we removed this point and replaced it with the following: \u201cWe showed that the scaled cosine similarity performs at par with Euclidean distance, unlike its unscaled counterpart\u201d CLARITY 61 The paper is reasonably clear",
        "To address the reviewer\u2019s concern we have further clarified this point in the section \u201cSummary of contributions\u201d. - \"Task conditioning\" makes use of a task-dataset-conditioning network to predict the scale and offset parameters of batch normalization layers as in [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]. Authors, response to Reviewer #2, point To address the point raised by the reviewer, we have extended the related work section discussion of the modifications we introduced to make this approach work in the few-shot learning setting. Reviewer #2, point - Auxiliary tasks are known to be beneficial to few-shot learning [*,**] and learning in general. Authors, response to Reviewer #2, point 13\n130 References [*,**] do not seem to address FSL scenario",
        "We removed the part of discussion related to task sampling tuning from the conclusion section. SPECIFIC COMMENTS Reviewer #2, point pg. 1: \"...one aims to...learn a model that extracts information from a set of labeled examples...\" Introduce the terminology \"support set\" alongside \"sample set\"",
        "I believe the restriction to the labelled support/unlabelled query setting is not representative of recent works in few-shot learning; e.g., consider [***, ****], which deal with learning with unlabelled data in the support set. Authors, response to Reviewer #2, point 15\n151 We addressed the comment by introducing the notion of support set together with sample set",
        "We chose not to expand the discussion on the possibility of using the unlabelled samples in the support set, because it is clearly outside of the scope of the paper. Reviewer #2, point pg. 1: It is strange to introduce few-shot learning with Ravi & Larochelle as the first citation, to claim that the problem has subsequently been reframed by Ravi & Larochelle as meta-learning \u2013 they are the same paper! This needs to be rewritten to correctly capture the nuanced difference between few-shot and meta-learning. Authors, response to Reviewer #2, point 16\n159 We addressed the comment by removing Ravi & Larochelle from the first citation.\n160 Reviewer #2, point 17 161 pg. 1: The claim that certain approaches to few-shot learning and meta-learning are \"influential\" and \"central to the field\" is subjective and Authors, response to Reviewer #2, point 17 164 We replaced \u201cinfluencial\u201d and removed \u201ccentral to the field\u201d with \u201crecent\u201d to make the statement more balanced.\n165 Reviewer #2, point 18 166 pg. 1: \"a feature extractor\" A feature extractor is more general than a neural network with 167 learned parameters, so this relationship needs to be reversed",
        "We addressed it by rewriting text fragement as \u201ca feature extractor\u201d. Reviewer #2, point 19 173 line 57: \"parameterized by \u03c6, mapping x to z, a representation space of dimension Dz\" z is an element of the representation space, not the representation space itself. Authors, response to Reviewer #2, point 19 176 We thank the reviewer for pointing out this inconsistency",
        "The training criterion for [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>] is discussed in lines 62-63 but [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>]\u2019s is not. Authors, response to Reviewer #2, point 20 183 We addressed the comment by including a more detailed explanation of the Matching networks by inserting the following sentence \u201cFor example, Matching networks[<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] use sample-wise attention mechanism to perform kernel label regression).\u201d Reviewer #2, point 21 187 line 60: \"proposed to introduce inductive bias\" Framing the computation of the class centroid as an \"inductive bias\" is not useful in this context unless it is identified why it is a useful inductive bias. Authors, response to Reviewer #2, point 21 190 We addressed the comment by removing the \u201cinductive bias\u201d\n191 Reviewer #2, point 22 192 line 61: \"a unique feature representation\" The mean of embeddings is not necessarily unique.\n193 Authors, response to Reviewer #2, point 22 194 we replaced this by \u201cdefined a feature representation\u201d line 61: \"for each class k\" It is confusing to use k to index classes when above K have been used to count examples in each class. Authors, response to Reviewer #2, point 23\n199 We addressed the comment by using K for the number of classes and M for the number of shots consistently throughout the paper. Reviewer #2, point line 77-8: \"This is the case of Matching Networks [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>], which use a Recurrent Neural Network (RNN) to accumulate information about a given task.\" The vanilla version of MNs does NOT use an Recurrent Neural Network; only the \"full-context embedding\" version requires it. Authors, response to Reviewer #2, point 24\n206 We addressed this comment by rephrazing the relevant part of the sentence as follows: \u201c...which optionally use a Recurrent Neural Network (RNN)...\u201d Reviewer #2, point line 108-109: \"We observed that this improvement could be directly attributed to the interference of the different scaling of the metrics with the softmax.\" This needs an experimental result, and so likely does not belong in the \"Model Description\" section. Authors, response to Reviewer #2, point 25\n213 We would like to thank the reviewer for pointing this out",
        "You should summarize the strengths and weaknesses of the submission, focusing on each of the following four criteria: quality, clarity, originality, and significance. This paper introduces a novel prototypical network-inspired architecture for few-shot learning that incorporates several useful modifications that lead to wins in classification accuracy",
        "We explicitly introduce a task representation computed as the mean of the task class centroids",
        "We have provided more details on the architectural complexity of the algorithms compared in Table 1 to provide for for more informative comparison. Reviewer #4, point W3 W3",
        "The idea of scaling is mentioned in some other papers like Geoffrey Hinton et al, Distilling the Knowledge in a Neural Network, 2015 It would be great to discuss the relatedness. Authors, response to Reviewer #4, point W5 The main theoretical contribution of our paper is the mathematical analysis of the effect of the limiting cases of \u03b1 on the few-shot update rule",
        "Why the experiment on the popular Omniglot dataset is not conducted?\n Authors, response to Reviewer #4, point W7\n We focused on miniImagenet and CIFAR as they are more challenging, and the error rate is more sensitive to model improvements"
    ],
    "summary": [
        "28 The theoretical contribution of this paper is to write out the gradient of the objective function from [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>] with the addition of the temperature scaling parameter in the softmax computation.",
        "17 This work proposes improvements to the prototypical network approach to few-shot classification introduced in [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>].",
        "In order to address the reviewers comment we removed this point and replaced it with the following: \u201cWe showed that the scaled cosine similarity performs at par with Euclidean distance, unlike its unscaled counterpart\u201d CLARITY The paper is reasonably clear.",
        "In Table 3 we see that when task conditioning 85 (TC) is added without auxiliary training (AT) the overall performance drops significantly.",
        "SIGNIFICANCE The work is incremental as a combination of previously proposed methods applied to prototypical networks for the task of few-shot classification.",
        "To address the point raised by the reviewer, we have extended the related work section discussion of the modifications we introduced to make this approach work in the few-shot learning setting.",
        "We removed the part of discussion related to task 143 sampling tuning from the conclusion section.",
        "Reviewer #2, point 20 line 59: \"can directly be used to solve the few-shot learning classification problem by association\" This needs a more thorough explanation and a more thorough description of the differences between [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] and [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>].",
        "Authors, response to Reviewer #2, point 20 We addressed the comment by including a more detailed explanation of the Matching networks by inserting the following sentence \u201cFor example, Matching networks[<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] use sample-wise attention mechanism to perform kernel label regression).\u201d",
        "line 108-109: \"We observed that this improvement could be directly attributed to the interference of the different scaling of the metrics with the softmax.\" This needs an experimental result, and so likely does not belong in the \"Model Description\" section.",
        "This paper introduces a novel prototypical network-inspired architecture for few-shot learning that incorporates several useful modifications that lead to wins in classification accuracy.",
        "The paper provides an insightful introduction and related work to categorize 284 existing few-shot learning algorithms.",
        "The idea of scaling is mentioned in some other papers like Geoffrey Hinton et al, Distilling the 330 Knowledge in a Neural Network, 2015 It would be great to discuss the relatedness.",
        "332 The main theoretical contribution of our paper is the mathematical analysis of the effect of the limiting cases of \u03b1 on the few-shot update rule.",
        "To address reviewer\u2019s concern, we have incorporated the paper pointed out as a reference and outlined the novelty of the current work with respect to it."
    ],
    "headline": "The 49 lower layers closer to the similarity metric need to be conditioned more than the shallower layers closer to the image 50 because pixel-level features extracted by shallow level layers are not task specific.\" 51 Authors, response to Reviewer #2, point 3 52 To address the concerns of the reviewer we have removed these statements. 53 Reviewer #2, point 4 54 A conceptual point is made in the conclusion unnecessarily: it does not appear that the fact that \"the scaled cosine 55 similarity...does not belong to the class of Bregman divergences\" is used anywhere in the paper, yet it is mentioned in 56 the conclusion. 57 Authors, response to Reviewer #2, point 4 58 In order to address the reviewers comment we removed this point and replaced it with the following: \u201cWe showed that 59 the scaled cosine similarity performs at par with Euclidean distance, unlike its unscaled counterpart\u201d 60 CLARITY 61 The paper is reasonably clear",
    "reference_links": [
        {
            "id": "33",
            "entry": "33 The main theoretical contribution is the mathematical analysis of the limiting cases of \u03b1. To our knowledge, this is 34 novel and non-trivial. It covers a very different case and provides very different insights than Hinton et al. Distilling 35 . . . 2015 (incorporated as a reference). To address reviewer\u2019s concern we have moved the proof of Lemma 1 into the 36 main body of the paper.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20The%20main%20theoretical%20contribution%20is%20the%20mathematical%20analysis%20of%20the%20limiting%20cases%20of%20%CE%B1.%20To%20our%20knowledge%2C%20this%20is%2034%20novel%20and%20non-trivial.%20It%20covers%20a%20very%20different%20case%20and%20provides%20very%20different%20insights%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20The%20main%20theoretical%20contribution%20is%20the%20mathematical%20analysis%20of%20the%20limiting%20cases%20of%20%CE%B1.%20To%20our%20knowledge%2C%20this%20is%2034%20novel%20and%20non-trivial.%20It%20covers%20a%20very%20different%20case%20and%20provides%20very%20different%20insights%202015"
        },
        {
            "id": "220",
            "entry": "220 We did not experiment with the original code, because we were able to reproduce the original results using our 221 re-implementation. 222 [*] Alonso, H\u00e9ctor Mart\u00ednez, and Barbara Plank. \"When is multitask learning effective? Semantic sequence prediction 223 under varying data conditions.\" arXiv preprint arXiv:1612.02251 (2016). 224 [**] Rei, Marek. \"Semi-supervised multitask learning for sequence labeling.\" arXiv preprint arXiv:1704.07156 (2017). 225 [***] Finn, Chelsea, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, and Sergey Levine. \"One-shot visual imitation learning 226 via meta-learning.\" In CoRL, 2017. 227 [****] Metz, Luke, Niru Maheswaranathan, Brian Cheung, and Jascha Sohl-Dickstein. \"Learning Unsupervised 228 Learning Rules.\" arXiv preprint arXiv:1804.00222 (2018). 229 4. How confident are you that this submission could be reproduced by others, assuming equal access to data 230 and resources? 231 3: Very confident",
            "arxiv_url": "https://arxiv.org/pdf/1612.02251"
        },
        {
            "id": "332",
            "entry": "332 The main theoretical contribution of our paper is the mathematical analysis of the effect of the limiting cases of \u03b1 on the few-shot update rule. To our knowledge, this is novel and non-trivial. It covers a very different case and provides very different insights than Geoffrey Hinton et al., Distilling the Knowledge in a Neural Network, 2015. To address reviewer\u2019s concern, we have incorporated the paper pointed out as a reference and outlined the novelty of the current work with respect to it.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=The%20main%20theoretical%20contribution%20of%20our%20paper%20is%20the%20mathematical%20analysis%20of%20the%20effect%20of%20the%20limiting%20cases%20of%20%CE%B1%20on%20the%20fewshot%20update%20rule%20To%20our%20knowledge%20this%20is%20novel%20and%20nontrivial%20It%20covers%20a%20very%20different%20case%20and%20provides%20very%20different%20insights%20than%20Geoffrey%20Hinton%20et%20al%20Distilling%20the%20Knowledge%20in%20a%20Neural%20Network%202015%20To%20address%20reviewers%20concern%20we%20have%20incorporated%20the%20paper%20pointed%20out%20as%20a%20reference%20and%20outlined%20the%20novelty%20of%20the%20current%20work%20with%20respect%20to%20it"
        }
    ]
}
