{
    "filename": "8108-adaptive-path-integral-autoencoders-representation-learning-and-planning-for-dynamical-systems.pdf",
    "metadata": {
        "title": "Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems",
        "author": "Jung-Su Ha, Young-Jin Park, Hyeok-Joo Chae, Soon-Seo Park, Han-Lim Choi",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8108-adaptive-path-integral-autoencoders-representation-learning-and-planning-for-dynamical-systems.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We present a representation learning algorithm that learns a low-dimensional latent dynamical system from high-dimensional sequential raw data, e.g., video. The framework builds upon recent advances in amortized inference methods that use both an inference network and a refinement procedure to output samples from a variational distribution given an observation sequence, and takes advantage of the duality between control and inference to approximately solve the intractable inference problem using the path integral control approach. The learned dynamical model can be used to predict and plan the future states; we also present the efficient planning method that exploits the learned low-dimensional latent dynamics. Numerical experiments show that the proposed path-integral control based variational inference method leads to tighter lower bounds in statistical model learning of sequential data. The supplementary video1 and the implementation code2 are available online."
    },
    "keywords": [
        {
            "term": "high dimensional",
            "url": "https://en.wikipedia.org/wiki/high_dimensional"
        },
        {
            "term": "particle filter",
            "url": "https://en.wikipedia.org/wiki/particle_filter"
        },
        {
            "term": "stochastic differential equation",
            "url": "https://en.wikipedia.org/wiki/stochastic_differential_equation"
        },
        {
            "term": "inference network",
            "url": "https://en.wikipedia.org/wiki/inference_network"
        },
        {
            "term": "state space model",
            "url": "https://en.wikipedia.org/wiki/State_Space_Model"
        },
        {
            "term": "approximate inference",
            "url": "https://en.wikipedia.org/wiki/approximate_inference"
        },
        {
            "term": "maximum likelihood estimation",
            "url": "https://en.wikipedia.org/wiki/maximum_likelihood_estimation"
        },
        {
            "term": "evidence lower bound",
            "url": "https://en.wikipedia.org/wiki/evidence_lower_bound"
        }
    ],
    "highlights": [
        "Such learning problems are formulated as latent or generative model learning assuming that observations were emerged from the low-dimensional latent states, which includes an intractable posterior inference of latent states for given input data",
        "For a generative model given by a state space model, an initial state distribution and control inputs serve as parameters of variational distributions; the inference network is trained to output these variational parameters such that the corresponding latent trajectory well-describes the observation sequence",
        "Our method utilizes the structured inference network based on the principle of optimality which has a similar structure to the inference network of deep Kalman smoother [<a class=\"ref-link\" id=\"cKrishnan_et+al_2017_a\" href=\"#rKrishnan_et+al_2017_a\">Krishnan et al, 2017</a>]",
        "The proposed framework utilized the structured inference network based on the principle of optimality and adopted the adaptive path-integral control method as a refinement procedure",
        "The experiments showed that the refinement procedure helped the learning algorithm achieve tighter lower bound",
        "It is shown that the valid dynamical model can be identified from sequential raw data and utilized to plan the future configurations"
    ],
    "key_statements": [
        "Such learning problems are formulated as latent or generative model learning assuming that observations were emerged from the low-dimensional latent states, which includes an intractable posterior inference of latent states for given input data",
        "For a generative model given by a state space model, an initial state distribution and control inputs serve as parameters of variational distributions; the inference network is trained to output these variational parameters such that the corresponding latent trajectory well-describes the observation sequence",
        "Our method utilizes the structured inference network based on the principle of optimality which has a similar structure to the inference network of deep Kalman smoother [<a class=\"ref-link\" id=\"cKrishnan_et+al_2017_a\" href=\"#rKrishnan_et+al_2017_a\">Krishnan et al, 2017</a>]",
        "In [<a class=\"ref-link\" id=\"cTamar_et+al_2016_a\" href=\"#rTamar_et+al_2016_a\">Tamar et al, 2016</a>, <a class=\"ref-link\" id=\"cOkada_et+al_2017_a\" href=\"#rOkada_et+al_2017_a\">Okada et al, 2017</a>, <a class=\"ref-link\" id=\"cKarkus_et+al_2017_a\" href=\"#rKarkus_et+al_2017_a\">Karkus et al, 2017</a>], similar iterative refinement procedures were built as differentiable networks to learn solutions of control problems in an end-to-end manner; the fact that iterative methods were generally used to solve control problems can be a rationale for utilizing refinement to approximate inference for sequential data",
        "It is thought that powerful inference methods via resampling or refinements make the bound tighter, but achieving a tighter bound during learning does not directly imply a better model learning [<a class=\"ref-link\" id=\"cRainforth_et+al_2018_a\" href=\"#rRainforth_et+al_2018_a\">Rainforth et al, 2018</a>]",
        "We can observe that learning with both the resampling and path-integral refinements resulted in the best reconstruction ability as well as the tightest bound, but the best prediction was achieved by the model learned only with the refinements",
        "The proposed framework utilized the structured inference network based on the principle of optimality and adopted the adaptive path-integral control method as a refinement procedure",
        "The experiments showed that the refinement procedure helped the learning algorithm achieve tighter lower bound",
        "It is shown that the valid dynamical model can be identified from sequential raw data and utilized to plan the future configurations"
    ],
    "summary": [
        "Such learning problems are formulated as latent or generative model learning assuming that observations were emerged from the low-dimensional latent states, which includes an intractable posterior inference of latent states for given input data.",
        "The efficient end-to-end training with the amortized inference is possible here, where the inference network should output the variational distribution of latent state trajectories for given observation sequences.",
        "For a generative model given by a state space model, an initial state distribution and control inputs serve as parameters of variational distributions; the inference network is trained to output these variational parameters such that the corresponding latent trajectory well-describes the observation sequence.",
        "Because the proposed framework is based on the SOC method, the same structure can be utilized to plan the future observation sequence, where the learned low-dimensional stochastic dynamics is used to explore the high-dimensional observation space efficiently.",
        "To address the issue of the amortization gap, a hybrid approach can be considered; for each observation, the variational distribution is refined individually from the output of the inference network.",
        "<a class=\"ref-link\" id=\"cMaddison_et+al_2017_a\" href=\"#rMaddison_et+al_2017_a\"><a class=\"ref-link\" id=\"cMaddison_et+al_2017_a\" href=\"#rMaddison_et+al_2017_a\">Maddison et al [2017</a></a>], <a class=\"ref-link\" id=\"cLe_et+al_2018_a\" href=\"#rLe_et+al_2018_a\">Le et al [2018</a>], <a class=\"ref-link\" id=\"cNaesseth_et+al_2018_a\" href=\"#rNaesseth_et+al_2018_a\">Naesseth et al [2018</a>] adapted the particle filter (PF) algorithm as their inference models and utilized a PF\u2019s estimator of the marginal likelihood as an objective function of training which <a class=\"ref-link\" id=\"cMaddison_et+al_2017_a\" href=\"#rMaddison_et+al_2017_a\"><a class=\"ref-link\" id=\"cMaddison_et+al_2017_a\" href=\"#rMaddison_et+al_2017_a\">Maddison et al [2017</a></a>] named the filtering variational objectives (FIVOs).",
        "These approaches can be viewed as attempts to reduce the approximation gap; by building the inference model in sophisticated ways that exploit underlying structure of data, the resulting variational family could flexibly approximate the posterior distribution.",
        "To overcome the amortization gap caused by inference networks, the semi-amortized method utilizes an iterative refinement procedure for improving variational distribution.",
        "<a class=\"ref-link\" id=\"cHjelm_et+al_2016_a\" href=\"#rHjelm_et+al_2016_a\">Hjelm et al [2016</a>] adopted adaptive importance sampling to refine the variational parameters, and the generative and inference networks are trained separately with \u03b8L(q\u2217, \u03b8; x) and \u03c6DKL(q\u2217||q\u03c6), respectively.",
        "In [<a class=\"ref-link\" id=\"cTamar_et+al_2016_a\" href=\"#rTamar_et+al_2016_a\">Tamar et al, 2016</a>, <a class=\"ref-link\" id=\"cOkada_et+al_2017_a\" href=\"#rOkada_et+al_2017_a\">Okada et al, 2017</a>, <a class=\"ref-link\" id=\"cKarkus_et+al_2017_a\" href=\"#rKarkus_et+al_2017_a\">Karkus et al, 2017</a>], similar iterative refinement procedures were built as differentiable networks to learn solutions of control problems in an end-to-end manner; the fact that iterative methods were generally used to solve control problems can be a rationale for utilizing refinement to approximate inference for sequential data.",
        "The proposed framework utilized the structured inference network based on the principle of optimality and adopted the adaptive path-integral control method as a refinement procedure.",
        "It is shown that the valid dynamical model can be identified from sequential raw data and utilized to plan the future configurations"
    ],
    "headline": "We present a representation learning algorithm that learns a low-dimensional latent dynamical system from high-dimensional sequential raw data, e.g., video",
    "reference_links": [
        {
            "id": "Abadi_et+al_2016_a",
            "entry": "Mart\u00edn Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorflow: A system for large-scale machine learning. In OSDI, volume 16, pages 265\u2013283, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20Mart%C3%ADn%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20Mart%C3%ADn%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016"
        },
        {
            "id": "Banijamali_et+al_2018_a",
            "entry": "Ershad Banijamali, Rui Shu, Mohammad Ghavamzadeh, Hung Bui, and Ali Ghodsi. Robust locallylinear controllable embedding. International Conference on Artificial Intelligence and Statistics (AISTATS), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Banijamali%2C%20Ershad%20Shu%2C%20Rui%20Ghavamzadeh%2C%20Mohammad%20Bui%2C%20Hung%20Robust%20locallylinear%20controllable%20embedding%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Banijamali%2C%20Ershad%20Shu%2C%20Rui%20Ghavamzadeh%2C%20Mohammad%20Bui%2C%20Hung%20Robust%20locallylinear%20controllable%20embedding%202018"
        },
        {
            "id": "Bellman_2013_a",
            "entry": "Richard Bellman. Dynamic programming. Courier Corporation, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bellman%2C%20Richard%20Dynamic%20programming%202013"
        },
        {
            "id": "Burda_et+al_2016_a",
            "entry": "Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Burda%2C%20Yuri%20Grosse%2C%20Roger%20Salakhutdinov%2C%20Ruslan%20Importance%20weighted%20autoencoders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Burda%2C%20Yuri%20Grosse%2C%20Roger%20Salakhutdinov%2C%20Ruslan%20Importance%20weighted%20autoencoders%202016"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "Nutan Chen, Maximilian Karl, and Patrick van der Smagt. Dynamic movement primitives in latent space of time-dependent variational autoencoders. In International Conference on Humanoid Robots (Humanoids), pages 629\u2013636. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Nutan%20Karl%2C%20Maximilian%20van%20der%20Smagt%2C%20Patrick%20Dynamic%20movement%20primitives%20in%20latent%20space%20of%20time-dependent%20variational%20autoencoders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Nutan%20Karl%2C%20Maximilian%20van%20der%20Smagt%2C%20Patrick%20Dynamic%20movement%20primitives%20in%20latent%20space%20of%20time-dependent%20variational%20autoencoders%202016"
        },
        {
            "id": "Cremer_et+al_2017_a",
            "entry": "Chris Cremer, Quaid Morris, and David Duvenaud. Reinterpreting importance-weighted autoencoders. ICLR Workshop, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cremer%2C%20Chris%20Morris%2C%20Quaid%20Duvenaud%2C%20David%20Reinterpreting%20importance-weighted%20autoencoders%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cremer%2C%20Chris%20Morris%2C%20Quaid%20Duvenaud%2C%20David%20Reinterpreting%20importance-weighted%20autoencoders%202017"
        },
        {
            "id": "Cremer_et+al_2018_a",
            "entry": "Chris Cremer, Xuechen Li, and David Duvenaud. Inference suboptimality in variational autoencoders. arXiv preprint arXiv:1801.03558, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.03558"
        },
        {
            "id": "Fraccaro_et+al_2017_a",
            "entry": "Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther. A disentangled recognition and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information Processing Systems (NIPS), pages 3604\u20133613, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fraccaro%2C%20Marco%20Kamronn%2C%20Simon%20Paquet%2C%20Ulrich%20Winther%2C%20Ole%20A%20disentangled%20recognition%20and%20nonlinear%20dynamics%20model%20for%20unsupervised%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fraccaro%2C%20Marco%20Kamronn%2C%20Simon%20Paquet%2C%20Ulrich%20Winther%2C%20Ole%20A%20disentangled%20recognition%20and%20nonlinear%20dynamics%20model%20for%20unsupervised%20learning%202017"
        },
        {
            "id": "Gardiner_1985_a",
            "entry": "Crispin W Gardiner et al. Handbook of stochastic methods, volume 4. Springer Berlin, 1985.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crispin%20W%20Gardiner%20et%20al%20Handbook%20of%20stochastic%20methods%20volume%204%20Springer%20Berlin%201985",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Crispin%20W%20Gardiner%20et%20al%20Handbook%20of%20stochastic%20methods%20volume%204%20Springer%20Berlin%201985"
        },
        {
            "id": "Genewein_et+al_2015_a",
            "entry": "Tim Genewein, Felix Leibfried, Jordi Grau-Moya, and Daniel Alexander Braun. Bounded rationality, abstraction, and hierarchical decision-making: An information-theoretic optimality principle. Frontiers in Robotics and AI, 2:27, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Genewein%2C%20Tim%20Leibfried%2C%20Felix%20Grau-Moya%2C%20Jordi%20Braun%2C%20Daniel%20Alexander%20Bounded%20rationality%2C%20abstraction%2C%20and%20hierarchical%20decision-making%3A%20An%20information-theoretic%20optimality%20principle%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Genewein%2C%20Tim%20Leibfried%2C%20Felix%20Grau-Moya%2C%20Jordi%20Braun%2C%20Daniel%20Alexander%20Bounded%20rationality%2C%20abstraction%2C%20and%20hierarchical%20decision-making%3A%20An%20information-theoretic%20optimality%20principle%202015"
        },
        {
            "id": "Ha_et+al_2018_a",
            "entry": "Jung-Su Ha, Hyeok-Joo Chae, and Han-Lim Choi. Approximate inference-based motion planning by learning and exploiting low-dimensional latent variable models. In Robotics and Automation Letters (RA-L/IROS\u201918). IEEE, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ha%2C%20Jung-Su%20Chae%2C%20Hyeok-Joo%20Choi%2C%20Han-Lim%20Approximate%20inference-based%20motion%20planning%20by%20learning%20and%20exploiting%20low-dimensional%20latent%20variable%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ha%2C%20Jung-Su%20Chae%2C%20Hyeok-Joo%20Choi%2C%20Han-Lim%20Approximate%20inference-based%20motion%20planning%20by%20learning%20and%20exploiting%20low-dimensional%20latent%20variable%20models%202018"
        },
        {
            "id": "Hjelm_et+al_2016_a",
            "entry": "Devon Hjelm, Ruslan R Salakhutdinov, Kyunghyun Cho, Nebojsa Jojic, Vince Calhoun, and Junyoung Chung. Iterative refinement of the approximate posterior for directed belief networks. In Advances in Neural Information Processing Systems (NIPS), pages 4691\u20134699, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hjelm%2C%20Devon%20Salakhutdinov%2C%20Ruslan%20R.%20Cho%2C%20Kyunghyun%20Jojic%2C%20Nebojsa%20Iterative%20refinement%20of%20the%20approximate%20posterior%20for%20directed%20belief%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hjelm%2C%20Devon%20Salakhutdinov%2C%20Ruslan%20R.%20Cho%2C%20Kyunghyun%20Jojic%2C%20Nebojsa%20Iterative%20refinement%20of%20the%20approximate%20posterior%20for%20directed%20belief%20networks%202016"
        },
        {
            "id": "Ichter_et+al_2018_a",
            "entry": "Brian Ichter, James Harrison, and Marco Pavone. Learning sampling distributions for robot motion planning. International Conference on Robotics and Automation (ICRA), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ichter%2C%20Brian%20Harrison%2C%20James%20Pavone%2C%20Marco%20Learning%20sampling%20distributions%20for%20robot%20motion%20planning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ichter%2C%20Brian%20Harrison%2C%20James%20Pavone%2C%20Marco%20Learning%20sampling%20distributions%20for%20robot%20motion%20planning%202018"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Matthew Johnson, David K Duvenaud, Alex Wiltschko, Ryan P Adams, and Sandeep R Datta. Composing graphical models with neural networks for structured representations and fast inference. In Advances in neural information processing systems (NIPS), pages 2946\u20132954, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Matthew%20Duvenaud%2C%20David%20K.%20Wiltschko%2C%20Alex%20Adams%2C%20Ryan%20P.%20Composing%20graphical%20models%20with%20neural%20networks%20for%20structured%20representations%20and%20fast%20inference%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Matthew%20Duvenaud%2C%20David%20K.%20Wiltschko%2C%20Alex%20Adams%2C%20Ryan%20P.%20Composing%20graphical%20models%20with%20neural%20networks%20for%20structured%20representations%20and%20fast%20inference%202016"
        },
        {
            "id": "Jonschkowski_2015_a",
            "entry": "Rico Jonschkowski and Oliver Brock. Learning state representations with robotic priors. Autonomous Robots, 39(3):407\u2013428, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jonschkowski%2C%20Rico%20Brock%2C%20Oliver%20Learning%20state%20representations%20with%20robotic%20priors%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jonschkowski%2C%20Rico%20Brock%2C%20Oliver%20Learning%20state%20representations%20with%20robotic%20priors%202015"
        },
        {
            "id": "Kappen_2016_a",
            "entry": "Hilbert Johan Kappen and Hans Christian Ruiz. Adaptive importance sampling for control and inference. Journal of Statistical Physics, 162(5):1244\u20131266, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kappen%2C%20Hilbert%20Johan%20Ruiz%2C%20Hans%20Christian%20Adaptive%20importance%20sampling%20for%20control%20and%20inference%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kappen%2C%20Hilbert%20Johan%20Ruiz%2C%20Hans%20Christian%20Adaptive%20importance%20sampling%20for%20control%20and%20inference%202016"
        },
        {
            "id": "Karkus_et+al_2017_a",
            "entry": "Peter Karkus, David Hsu, and Wee Sun Lee. Qmdp-net: Deep learning for planning under partial observability. In Advances in Neural Information Processing Systems (NIPS), pages 4697\u20134707, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karkus%2C%20Peter%20Hsu%2C%20David%20Lee%2C%20Wee%20Sun%20Qmdp-net%3A%20Deep%20learning%20for%20planning%20under%20partial%20observability%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karkus%2C%20Peter%20Hsu%2C%20David%20Lee%2C%20Wee%20Sun%20Qmdp-net%3A%20Deep%20learning%20for%20planning%20under%20partial%20observability%202017"
        },
        {
            "id": "Karl_et+al_2017_a",
            "entry": "Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep variational bayes filters: Unsupervised learning of state space models from raw data. International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karl%2C%20Maximilian%20Soelch%2C%20Maximilian%20Bayer%2C%20Justin%20van%20der%20Smagt%2C%20Patrick%20Deep%20variational%20bayes%20filters%3A%20Unsupervised%20learning%20of%20state%20space%20models%20from%20raw%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karl%2C%20Maximilian%20Soelch%2C%20Maximilian%20Bayer%2C%20Justin%20van%20der%20Smagt%2C%20Patrick%20Deep%20variational%20bayes%20filters%3A%20Unsupervised%20learning%20of%20state%20space%20models%20from%20raw%20data%202017"
        },
        {
            "id": "Kim_et+al_2018_a",
            "entry": "Yoon Kim, Sam Wiseman, Andrew C Miller, David Sontag, and Alexander M Rush. Semi-amortized variational autoencoders. arXiv preprint arXiv:1802.02550, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.02550"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Max Welling. Auto-encoding variational bayes. International Conference on Learning Representations (ICLR), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "Krishnan_et+al_2017_a",
            "entry": "Rahul G Krishnan, Uri Shalit, and David Sontag. Structured inference networks for nonlinear state space models. In AAAI, pages 2101\u20132109, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krishnan%2C%20Rahul%20G.%20Shalit%2C%20Uri%20Sontag%2C%20David%20Structured%20inference%20networks%20for%20nonlinear%20state%20space%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krishnan%2C%20Rahul%20G.%20Shalit%2C%20Uri%20Sontag%2C%20David%20Structured%20inference%20networks%20for%20nonlinear%20state%20space%20models%202017"
        },
        {
            "id": "Krishnan_et+al_2018_a",
            "entry": "Rahul G Krishnan, Dawen Liang, and Matthew Hoffman. On the challenges of learning with inference networks on sparse, high-dimensional data. International Conference on Artificial Intelligence and Statistics (AISTATS), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krishnan%2C%20Rahul%20G.%20Liang%2C%20Dawen%20Hoffman%2C%20Matthew%20On%20the%20challenges%20of%20learning%20with%20inference%20networks%20on%20sparse%2C%20high-dimensional%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krishnan%2C%20Rahul%20G.%20Liang%2C%20Dawen%20Hoffman%2C%20Matthew%20On%20the%20challenges%20of%20learning%20with%20inference%20networks%20on%20sparse%2C%20high-dimensional%20data%202018"
        },
        {
            "id": "Le_et+al_2018_a",
            "entry": "Tuan Anh Le, Maximilian Igl, Tom Jin, Tom Rainforth, and Frank Wood. Auto-encoding sequential monte carlo. International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Le%2C%20Tuan%20Anh%20Igl%2C%20Maximilian%20Jin%2C%20Tom%20Rainforth%2C%20Tom%20Auto-encoding%20sequential%20monte%20carlo%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Le%2C%20Tuan%20Anh%20Igl%2C%20Maximilian%20Jin%2C%20Tom%20Rainforth%2C%20Tom%20Auto-encoding%20sequential%20monte%20carlo%202018"
        },
        {
            "id": "Lesort_et+al_2018_a",
            "entry": "Timoth\u00e9e Lesort, Natalia D\u00edaz-Rodr\u00edguez, Jean-Fran\u00e7ois Goudou, and David Filliat. State representation learning for control: An overview. arXiv preprint arXiv:1802.04181, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04181"
        },
        {
            "id": "Maddison_et+al_2017_a",
            "entry": "Chris J Maddison, Dieterich Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih, Arnaud Doucet, and Yee Whye Teh. Filtering variational objectives. In Advances in neural information processing systems (NIPS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maddison%2C%20Chris%20J.%20Lawson%2C%20Dieterich%20Tucker%2C%20George%20Heess%2C%20Nicolas%20Filtering%20variational%20objectives%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maddison%2C%20Chris%20J.%20Lawson%2C%20Dieterich%20Tucker%2C%20George%20Heess%2C%20Nicolas%20Filtering%20variational%20objectives%202017"
        },
        {
            "id": "Mnih_2016_a",
            "entry": "Andriy Mnih and Danilo Rezende. Variational inference for monte carlo objectives. In International Conference on Machine Learning (ICML), pages 2188\u20132196, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Andriy%20Rezende%2C%20Danilo%20Variational%20inference%20for%20monte%20carlo%20objectives%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Andriy%20Rezende%2C%20Danilo%20Variational%20inference%20for%20monte%20carlo%20objectives%202016"
        },
        {
            "id": "Naesseth_et+al_2018_a",
            "entry": "Christian A Naesseth, Scott W Linderman, Rajesh Ranganath, and David M Blei. Variational sequential monte carlo. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Naesseth%2C%20Christian%20A.%20Linderman%2C%20Scott%20W.%20Ranganath%2C%20Rajesh%20Blei%2C%20David%20M.%20Variational%20sequential%20monte%20carlo%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Naesseth%2C%20Christian%20A.%20Linderman%2C%20Scott%20W.%20Ranganath%2C%20Rajesh%20Blei%2C%20David%20M.%20Variational%20sequential%20monte%20carlo%202018"
        },
        {
            "id": "Okada_et+al_2017_a",
            "entry": "Masashi Okada, Luca Rigazio, and Takenobu Aoshima. Path integral networks: End-to-end differentiable optimal control. arXiv preprint arXiv:1706.09597, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.09597"
        },
        {
            "id": "Rainforth_et+al_2018_a",
            "entry": "Tom Rainforth, Adam R Kosiorek, Tuan Anh Le, Chris J Maddison, Maximilian Igl, Frank Wood, and Yee Whye Teh. Tighter variational bounds are not necessarily better. In International Conference on Machine Learning (ICML), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rainforth%2C%20Tom%20Kosiorek%2C%20Adam%20R.%20Le%2C%20Tuan%20Anh%20Maddison%2C%20Chris%20J.%20Tighter%20variational%20bounds%20are%20not%20necessarily%20better%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rainforth%2C%20Tom%20Kosiorek%2C%20Adam%20R.%20Le%2C%20Tuan%20Anh%20Maddison%2C%20Chris%20J.%20Tighter%20variational%20bounds%20are%20not%20necessarily%20better%202018"
        },
        {
            "id": "Rezende_et+al_2014_a",
            "entry": "Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In International Conference on Machine Learning (ICML), pages 1278\u20131286, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014"
        },
        {
            "id": "Ruiz_2017_a",
            "entry": "Hans-Christian Ruiz and Hilbert J Kappen. Particle smoothing for hidden diffusion processes: Adaptive path integral smoother. IEEE Transactions on Signal Processing, 65(12):3191\u20133203, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ruiz%2C%20Hans-Christian%20Kappen%2C%20Hilbert%20J.%20Particle%20smoothing%20for%20hidden%20diffusion%20processes%3A%20Adaptive%20path%20integral%20smoother%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ruiz%2C%20Hans-Christian%20Kappen%2C%20Hilbert%20J.%20Particle%20smoothing%20for%20hidden%20diffusion%20processes%3A%20Adaptive%20path%20integral%20smoother%202017"
        },
        {
            "id": "Tamar_et+al_2016_a",
            "entry": "Aviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, and Pieter Abbeel. Value iteration networks. In Advances in Neural Information Processing Systems (NIPS), pages 2154\u20132162, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aviv%20Tamar%20Yi%20Wu%20Garrett%20Thomas%20Sergey%20Levine%20and%20Pieter%20Abbeel%20Value%20iteration%20networks%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20NIPS%20pages%2021542162%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aviv%20Tamar%20Yi%20Wu%20Garrett%20Thomas%20Sergey%20Levine%20and%20Pieter%20Abbeel%20Value%20iteration%20networks%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20NIPS%20pages%2021542162%202016"
        },
        {
            "id": "Tassa_et+al_2018_a",
            "entry": "Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de Las Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, et al. DeepMind Control Suite. arXiv preprint arXiv:1801.00690, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.00690"
        },
        {
            "id": "Thijssen_2015_a",
            "entry": "Sep Thijssen and HJ Kappen. Path integral control and state-dependent feedback. Physical Review E, 91(3):032104, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thijssen%2C%20Sep%20Kappen%2C%20H.J.%20Path%20integral%20control%20and%20state-dependent%20feedback%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thijssen%2C%20Sep%20Kappen%2C%20H.J.%20Path%20integral%20control%20and%20state-dependent%20feedback%202015"
        },
        {
            "id": "Todorov_2008_a",
            "entry": "Emanuel Todorov. General duality between optimal control and estimation. In IEEE Conference on Decision and Control, pages 4286\u20134292. IEEE, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Todorov%2C%20Emanuel%20General%20duality%20between%20optimal%20control%20and%20estimation%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Todorov%2C%20Emanuel%20General%20duality%20between%20optimal%20control%20and%20estimation%202008"
        },
        {
            "id": "Todorov_2009_a",
            "entry": "Emanuel Todorov. Efficient computation of optimal actions. Proceedings of the national academy of sciences, 106(28):11478\u201311483, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Todorov%2C%20Emanuel%20Efficient%20computation%20of%20optimal%20actions%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Todorov%2C%20Emanuel%20Efficient%20computation%20of%20optimal%20actions%202009"
        },
        {
            "id": "Vernaza_2012_a",
            "entry": "Paul Vernaza and Daniel D Lee. Learning and exploiting low-dimensional structure for efficient holonomic motion planning in high-dimensional spaces. The International Journal of Robotics Research, 31(14):1739\u20131760, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vernaza%2C%20Paul%20Lee%2C%20Daniel%20D.%20Learning%20and%20exploiting%20low-dimensional%20structure%20for%20efficient%20holonomic%20motion%20planning%20in%20high-dimensional%20spaces%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vernaza%2C%20Paul%20Lee%2C%20Daniel%20D.%20Learning%20and%20exploiting%20low-dimensional%20structure%20for%20efficient%20holonomic%20motion%20planning%20in%20high-dimensional%20spaces%202012"
        },
        {
            "id": "Wang_et+al_2008_a",
            "entry": "Jack M Wang, David J Fleet, and Aaron Hertzmann. Gaussian process dynamical models for human motion. IEEE transactions on pattern analysis and machine intelligence, 30(2):283\u2013298, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Jack%20M.%20Fleet%2C%20David%20J.%20Hertzmann%2C%20Aaron%20Gaussian%20process%20dynamical%20models%20for%20human%20motion%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Jack%20M.%20Fleet%2C%20David%20J.%20Hertzmann%2C%20Aaron%20Gaussian%20process%20dynamical%20models%20for%20human%20motion%202008"
        },
        {
            "id": "Watter_et+al_2015_a",
            "entry": "Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to control: A locally linear latent dynamics model for control from raw images. In Advances in neural information processing systems (NIPS), pages 2746\u20132754, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Watter%2C%20Manuel%20Springenberg%2C%20Jost%20Boedecker%2C%20Joschka%20Riedmiller%2C%20Martin%20Embed%20to%20control%3A%20A%20locally%20linear%20latent%20dynamics%20model%20for%20control%20from%20raw%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Watter%2C%20Manuel%20Springenberg%2C%20Jost%20Boedecker%2C%20Joschka%20Riedmiller%2C%20Martin%20Embed%20to%20control%3A%20A%20locally%20linear%20latent%20dynamics%20model%20for%20control%20from%20raw%20images%202015"
        },
        {
            "id": "Zhang_et+al_2018_a",
            "entry": "Clark Zhang, Jinwook Huh, and Daniel D Lee. Learning implicit sampling distributions for motion planning. arXiv preprint arXiv:1806.01968, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01968"
        },
        {
            "id": "Chicago_2008_a",
            "entry": "Chicago, IL, USA, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chicago%20IL%20USA%202008"
        }
    ]
}
