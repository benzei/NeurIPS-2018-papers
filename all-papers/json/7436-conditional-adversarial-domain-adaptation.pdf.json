{
    "filename": "7436-conditional-adversarial-domain-adaptation.pdf",
    "metadata": {
        "title": "Conditional Adversarial Domain Adaptation",
        "author": "Mingsheng Long, ZHANGJIE CAO, Jianmin Wang, Michael I. Jordan",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7436-conditional-adversarial-domain-adaptation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may struggle to align different domains of multimodal distributions that are native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the cross-covariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. Experiments testify that the proposed approach exceeds the state-of-the-art results on five benchmark datasets."
    },
    "keywords": [
        {
            "term": "Clip Art",
            "url": "https://en.wikipedia.org/wiki/Clip_Art"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "multimodal distribution",
            "url": "https://en.wikipedia.org/wiki/multimodal_distribution"
        },
        {
            "term": "deep network",
            "url": "https://en.wikipedia.org/wiki/deep_network"
        },
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        }
    ],
    "highlights": [
        "Deep networks have significantly improved the state-of-the-arts for diverse machine learning problems and applications",
        "Motivated by the conditioning insight, this paper presents Conditional Domain Adversarial Networks (CDANs) to exploit discriminative information conveyed in the classifier predictions to assist adversarial adaptation",
        "Conditional Domain Adversarial Network We enable conditional adversarial domain adaptation over the domain-specific feature representation f and classifier prediction g",
        "The results on Office-31 based on AlexNet and ResNet are reported in Table 1, with results of baselines directly reported from their original papers wherever available",
        "Conditioning Strategies Besides multilinear conditioning, we investigate Domain Adversarial Neural Network-f and Domain Adversarial Neural Network-g with domain discriminator plugged in feature layer f and classifier layer g, Domain Adversarial Neural Network-[f,g] with domain discriminator imposed on the concatenation of f and g",
        "This paper presented conditional domain adversarial network (CDAN), a novel approach to domain adaptation with multimodal distributions"
    ],
    "key_statements": [
        "Deep networks have significantly improved the state-of-the-arts for diverse machine learning problems and applications",
        "While in many real applications, there is the need to transfer a deep network from a source domain where sufficient training data is available to a target domain where only unlabeled data is available, such a transfer learning paradigm is hindered by the shift in data distributions across domains [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>]",
        "Motivated by the conditioning insight, this paper presents Conditional Domain Adversarial Networks (CDANs) to exploit discriminative information conveyed in the classifier predictions to assist adversarial adaptation",
        "The key to the Conditional Domain Adversarial Networks models is a novel conditional domain discriminator conditioned on the crosscovariance of domain-specific feature representations and classifier predictions",
        "The joint distributions of feature representation f and classifier prediction g should still be non-identical in these domain adversarial networks",
        "Motivated by conditional Generative Adversarial Networks, we observe that in adversarial domain adaptation, the classifier prediction g conveys discriminative information potentially revealing the multimodal structures, which can be conditioned on when adapting feature representation f",
        "Conditional Domain Adversarial Network We enable conditional adversarial domain adaptation over the domain-specific feature representation f and classifier prediction g",
        ", where \u03bb is a hyper-parameter between source classifier and conditional domain discriminator, and note that h = (f , g) is the joint variable of domain-specific feature representation f and classifier prediction g for adversarial adaptation",
        "We evaluate the proposed conditional domain adversarial networks with many state-of-the-art transfer learning and deep learning methods",
        "The results on Office-31 based on AlexNet and ResNet are reported in Table 1, with results of baselines directly reported from their original papers wherever available",
        "Conditioning Strategies Besides multilinear conditioning, we investigate Domain Adversarial Neural Network-f and Domain Adversarial Neural Network-g with domain discriminator plugged in feature layer f and classifier layer g, Domain Adversarial Neural Network-[f,g] with domain discriminator imposed on the concatenation of f and g",
        "This paper presented conditional domain adversarial network (CDAN), a novel approach to domain adaptation with multimodal distributions"
    ],
    "summary": [
        "Deep networks have significantly improved the state-of-the-arts for diverse machine learning problems and applications.",
        "Motivated by the conditioning insight, this paper presents Conditional Domain Adversarial Networks (CDANs) to exploit discriminative information conveyed in the classifier predictions to assist adversarial adaptation.",
        "The key to the CDAN models is a novel conditional domain discriminator conditioned on the crosscovariance of domain-specific feature representations and classifier predictions.",
        "These methods do not explore the dependency between the features and classes in a unified conditional domain discriminator, which is important to capture the multimodal structures underlying data distributions.",
        "This paper extends the conditioning adversarial mechanism to enable discriminative and transferable domain adaptation, by defining the domain discriminator on the features while conditioning it on the class information.",
        "The error function of the domain discriminator corresponds well to the discrepancy between feature distributions P (f ) and Q(f ) [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], a key to bound the target risk in the domain adaptation theory [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>].",
        "The joint distributions of feature representation f and classifier prediction g should still be non-identical in these domain adversarial networks.",
        "Motivated by conditional GANs, we observe that in adversarial domain adaptation, the classifier prediction g conveys discriminative information potentially revealing the multimodal structures, which can be conditioned on when adapting feature representation f .",
        "Domain variances in both feature representation f and classifier prediction g can be modeled simultaneously.",
        "With the concatenation strategy, f and g are independent on each other, failing to fully capture multiplicative interactions between feature representation and classifier prediction, which are crucial to domain adaptation.",
        ", where \u03bb is a hyper-parameter between source classifier and conditional domain discriminator, and note that h = (f , g) is the joint variable of domain-specific feature representation f and classifier prediction g for adversarial adaptation.",
        "We evaluate the proposed conditional domain adversarial networks with many state-of-the-art transfer learning and deep learning methods.",
        "We compare Conditional Domain Adversarial Network (CDAN) with state-of-art domain adaptation methods: Deep Adaptation Network (DAN) [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>], Residual Transfer Network (RTN) [<a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>], Domain Adversarial Neural Network (DANN) [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>], Adversarial Discriminative Domain Adaptation (ADDA) [<a class=\"ref-link\" id=\"c51\" href=\"#r51\">51</a>], Joint Adaptation Network (JAN) [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>], Unsupervised Image-to-Image Translation (UNIT) [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>], Generate to Adapt (GTA) [<a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>], Cycle-Consistent Adversarial Domain Adaptation (CyCADA) [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>].",
        "This paper presented conditional domain adversarial network (CDAN), a novel approach to domain adaptation with multimodal distributions.",
        "Unlike previous adversarial adaptation methods that solely match the feature representation across domains which is prone to under-matching, the proposed approach further conditions the adversarial domain adaptation on discriminative information to enable alignment of multimodal distributions."
    ],
    "headline": "We present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Arjovsky and L. Bottou. Towards principled methods for training generative adversarial networks. In International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20M.%20Bottou%2C%20L.%20Towards%20principled%20methods%20for%20training%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20M.%20Bottou%2C%20L.%20Towards%20principled%20methods%20for%20training%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "2",
            "entry": "[2] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gan. In International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%20Arjovsky%20S%20Chintala%20and%20L%20Bottou%20Wasserstein%20gan%20In%20International%20Conference%20on%20Machine%20Learning%20ICML%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%20Arjovsky%20S%20Chintala%20and%20L%20Bottou%20Wasserstein%20gan%20In%20International%20Conference%20on%20Machine%20Learning%20ICML%202017"
        },
        {
            "id": "3",
            "entry": "[3] S. Arora, R. Ge, Y. Liang, T. Ma, and Y. Zhang. Generalization and equilibrium in generative adversarial nets (gans). In International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20S.%20Ge%2C%20R.%20Liang%2C%20Y.%20Ma%2C%20T.%20Generalization%20and%20equilibrium%20in%20generative%20adversarial%20nets%20%28gans%29%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20S.%20Ge%2C%20R.%20Liang%2C%20Y.%20Ma%2C%20T.%20Generalization%20and%20equilibrium%20in%20generative%20adversarial%20nets%20%28gans%29%202017"
        },
        {
            "id": "4",
            "entry": "[4] S. Arora and Y. Zhang. Do gans actually learn the distribution? an empirical study. arXiv preprint arXiv:1706.08224, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.08224"
        },
        {
            "id": "5",
            "entry": "[5] S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. W. Vaughan. A theory of learning from different domains. Machine Learning, 79(1-2):151\u2013175, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20S.%20Blitzer%2C%20J.%20Crammer%2C%20K.%20Kulesza%2C%20A.%20A%20theory%20of%20learning%20from%20different%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20S.%20Blitzer%2C%20J.%20Crammer%2C%20K.%20Kulesza%2C%20A.%20A%20theory%20of%20learning%20from%20different%20domains%202010"
        },
        {
            "id": "6",
            "entry": "[6] Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 35(8):1798\u20131828, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Y.%20Courville%2C%20A.%20Vincent%2C%20P.%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Y.%20Courville%2C%20A.%20Vincent%2C%20P.%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013"
        },
        {
            "id": "7",
            "entry": "[7] T. Che, Y. Li, A. P. Jacob, Y. Bengio, and W. Li. Mode regularized generative adversarial networks. International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Che%2C%20T.%20Li%2C%20Y.%20Jacob%2C%20A.P.%20Bengio%2C%20Y.%20Mode%20regularized%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Che%2C%20T.%20Li%2C%20Y.%20Jacob%2C%20A.P.%20Bengio%2C%20Y.%20Mode%20regularized%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "8",
            "entry": "[8] Y. Chen, W. Chen, Y. Chen, B. Tsai, Y. F. Wang, and M. Sun. No more discrimination: Cross city adaptation of road scene segmenters. In The IEEE International Conference on Computer Vision (ICCV), pages 2011\u20132020, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Y.%20Chen%2C%20W.%20Chen%2C%20Y.%20Tsai%2C%20B.%20No%20more%20discrimination%3A%20Cross%20city%20adaptation%20of%20road%20scene%20segmenters%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Y.%20Chen%2C%20W.%20Chen%2C%20Y.%20Tsai%2C%20B.%20No%20more%20discrimination%3A%20Cross%20city%20adaptation%20of%20road%20scene%20segmenters%202011"
        },
        {
            "id": "9",
            "entry": "[9] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. Journal of Machine Learning Research (JMLR), 12:2493\u20132537, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20R.%20Weston%2C%20J.%20Bottou%2C%20L.%20Karlen%2C%20M.%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20R.%20Weston%2C%20J.%20Bottou%2C%20L.%20Karlen%2C%20M.%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011"
        },
        {
            "id": "10",
            "entry": "[10] N. Courty, R. Flamary, A. Habrard, and A. Rakotomamonjy. Joint distribution optimal transportation for domain adaptation. In Advances in Neural Information Processing Systems 30, pages 3730\u20133739. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Courty%2C%20N.%20Flamary%2C%20R.%20Habrard%2C%20A.%20Rakotomamonjy%2C%20A.%20Joint%20distribution%20optimal%20transportation%20for%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Courty%2C%20N.%20Flamary%2C%20R.%20Habrard%2C%20A.%20Rakotomamonjy%2C%20A.%20Joint%20distribution%20optimal%20transportation%20for%20domain%20adaptation%202017"
        },
        {
            "id": "11",
            "entry": "[11] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In International Conference on Machine Learning (ICML), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20J.%20Jia%2C%20Y.%20Vinyals%2C%20O.%20Hoffman%2C%20J.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20J.%20Jia%2C%20Y.%20Vinyals%2C%20O.%20Hoffman%2C%20J.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014"
        },
        {
            "id": "12",
            "entry": "[12] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. In International Conference on Machine Learning (ICML), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Y.%20Lempitsky%2C%20V.%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Y.%20Lempitsky%2C%20V.%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015"
        },
        {
            "id": "13",
            "entry": "[13] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. Lempitsky. Domain-adversarial training of neural networks. The Journal of Machine Learning Research (JMLR), 17(1):2096\u20132030, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Y.%20Ustinova%2C%20E.%20Ajakan%2C%20H.%20Germain%2C%20P.%20Domain-adversarial%20training%20of%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Y.%20Ustinova%2C%20E.%20Ajakan%2C%20H.%20Germain%2C%20P.%20Domain-adversarial%20training%20of%20neural%20networks%202016"
        },
        {
            "id": "14",
            "entry": "[14] X. Glorot, A. Bordes, and Y. Bengio. Domain adaptation for large-scale sentiment classification: A deep learning approach. In International Conference on Machine Learning (ICML), 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20X.%20Bordes%2C%20A.%20Bengio%2C%20Y.%20Domain%20adaptation%20for%20large-scale%20sentiment%20classification%3A%20A%20deep%20learning%20approach%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20X.%20Bordes%2C%20A.%20Bengio%2C%20Y.%20Domain%20adaptation%20for%20large-scale%20sentiment%20classification%3A%20A%20deep%20learning%20approach%202011"
        },
        {
            "id": "15",
            "entry": "[15] B. Gong, K. Grauman, and F. Sha. Connecting the dots with landmarks: Discriminatively learning domaininvariant features for unsupervised domain adaptation. In International Conference on Machine Learning (ICML), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domaininvariant%20features%20for%20unsupervised%20domain%20adaptation%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domaininvariant%20features%20for%20unsupervised%20domain%20adaptation%202013"
        },
        {
            "id": "16",
            "entry": "[16] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Shi%2C%20Y.%20Sha%2C%20F.%20Grauman%2C%20K.%20Geodesic%20flow%20kernel%20for%20unsupervised%20domain%20adaptation%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Shi%2C%20Y.%20Sha%2C%20F.%20Grauman%2C%20K.%20Geodesic%20flow%20kernel%20for%20unsupervised%20domain%20adaptation%202012"
        },
        {
            "id": "17",
            "entry": "[17] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems (NIPS), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "18",
            "entry": "[18] R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In IEEE International Conference on Computer Vision (ICCV), 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gopalan%2C%20R.%20Li%2C%20R.%20Chellappa%2C%20R.%20Domain%20adaptation%20for%20object%20recognition%3A%20An%20unsupervised%20approach%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gopalan%2C%20R.%20Li%2C%20R.%20Chellappa%2C%20R.%20Domain%20adaptation%20for%20object%20recognition%3A%20An%20unsupervised%20approach%202011"
        },
        {
            "id": "19",
            "entry": "[19] Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. In Advances in Neural Information Processing Systems, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grandvalet%2C%20Y.%20Bengio%2C%20Y.%20Semi-supervised%20learning%20by%20entropy%20minimization%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grandvalet%2C%20Y.%20Bengio%2C%20Y.%20Semi-supervised%20learning%20by%20entropy%20minimization%202005"
        },
        {
            "id": "20",
            "entry": "[20] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "21",
            "entry": "[21] J. Hoffman, S. Guadarrama, E. Tzeng, R. Hu, J. Donahue, R. Girshick, T. Darrell, and K. Saenko. LSDA: Large scale detection through adaptation. In Advances in Neural Information Processing Systems, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Guadarrama%2C%20S.%20Tzeng%2C%20E.%20Hu%2C%20R.%20LSDA%3A%20Large%20scale%20detection%20through%20adaptation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Guadarrama%2C%20S.%20Tzeng%2C%20E.%20Hu%2C%20R.%20LSDA%3A%20Large%20scale%20detection%20through%20adaptation%202014"
        },
        {
            "id": "22",
            "entry": "[22] J. Hoffman, E. Tzeng, T. Park, J.-Y. Zhu, P. Isola, K. Saenko, A. Efros, and T. Darrell. CyCADA: Cycleconsistent adversarial domain adaptation. In Proceedings of the 35th International Conference on Machine Learning, pages 1989\u20131998, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Tzeng%2C%20E.%20Park%2C%20T.%20Zhu%2C%20J.-Y.%20CyCADA%3A%20Cycleconsistent%20adversarial%20domain%20adaptation%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Tzeng%2C%20E.%20Park%2C%20T.%20Zhu%2C%20J.-Y.%20CyCADA%3A%20Cycleconsistent%20adversarial%20domain%20adaptation%201989"
        },
        {
            "id": "23",
            "entry": "[23] J. Hoffman, D. Wang, F. Yu, and T. Darrell. Fcns in the wild: Pixel-level adversarial and constraint-based adaptation. CoRR, abs/1612.02649, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.02649"
        },
        {
            "id": "24",
            "entry": "[24] J. Huang, A. J. Smola, A. Gretton, K. M. Borgwardt, and B. Sch\u00f6lkopf. Correcting sample selection bias by unlabeled data. In Advances in Neural Information Processing Systems (NIPS), 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20J.%20Smola%2C%20A.J.%20Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20J.%20Smola%2C%20A.J.%20Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202006"
        },
        {
            "id": "25",
            "entry": "[25] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros. Image-to-image translation with conditional adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20P.%20Zhu%2C%20J.-Y.%20Zhou%2C%20T.%20Efros%2C%20A.A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20P.%20Zhu%2C%20J.-Y.%20Zhou%2C%20T.%20Efros%2C%20A.A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "26",
            "entry": "[26] P. Kar and H. Karnick. Random feature maps for dot product kernels. In International Conference on Artificial Intelligence and Statistics (AISTATS), volume 22, pages 583\u2013591, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kar%2C%20P.%20Karnick%2C%20H.%20Random%20feature%20maps%20for%20dot%20product%20kernels%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kar%2C%20P.%20Karnick%2C%20H.%20Random%20feature%20maps%20for%20dot%20product%20kernels%202012"
        },
        {
            "id": "27",
            "entry": "[27] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems (NIPS), 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "28",
            "entry": "[28] M.-Y. Liu, T. Breuel, and J. Kautz. Unsupervised image-to-image translation networks. In Advances in Neural Information Processing Systems 30, pages 700\u2013708. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "29",
            "entry": "[29] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation networks. In International Conference on Machine Learning (ICML), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Cao%2C%20Y.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Cao%2C%20Y.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015"
        },
        {
            "id": "30",
            "entry": "[30] M. Long, J. Wang, and M. I. Jordan. Deep transfer learning with joint adaptation networks. In International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Deep%20transfer%20learning%20with%20joint%20adaptation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Deep%20transfer%20learning%20with%20joint%20adaptation%20networks%202017"
        },
        {
            "id": "31",
            "entry": "[31] M. Long, H. Zhu, J. Wang, and M. I. Jordan. Unsupervised domain adaptation with residual transfer networks. In Advances in Neural Information Processing Systems (NIPS), pages 136\u2013144, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Unsupervised%20domain%20adaptation%20with%20residual%20transfer%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Unsupervised%20domain%20adaptation%20with%20residual%20transfer%20networks%202016"
        },
        {
            "id": "32",
            "entry": "[32] L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of Machine Learning Research (JMLR), 9(Nov):2579\u20132605, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=v.%20d.%20Maaten%2C%20L.%20Hinton%2C%20G.%20Visualizing%20data%20using%20t-sne%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=v.%20d.%20Maaten%2C%20L.%20Hinton%2C%20G.%20Visualizing%20data%20using%20t-sne%202008"
        },
        {
            "id": "33",
            "entry": "[33] Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In Conference on Computational Learning Theory (COLT), 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%3A%20Learning%20bounds%20and%20algorithms%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%3A%20Learning%20bounds%20and%20algorithms%202009"
        },
        {
            "id": "34",
            "entry": "[34] M. Mirza and S. Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "35",
            "entry": "[35] A. Odena, C. Olah, and J. Shlens. Conditional image synthesis with auxiliary classifier gans. In International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Odena%2C%20A.%20Olah%2C%20C.%20Shlens%2C%20J.%20Conditional%20image%20synthesis%20with%20auxiliary%20classifier%20gans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Odena%2C%20A.%20Olah%2C%20C.%20Shlens%2C%20J.%20Conditional%20image%20synthesis%20with%20auxiliary%20classifier%20gans%202017"
        },
        {
            "id": "36",
            "entry": "[36] M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Learning and transferring mid-level image representations using convolutional neural networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oquab%2C%20M.%20Bottou%2C%20L.%20Laptev%2C%20I.%20Sivic%2C%20J.%20Learning%20and%20transferring%20mid-level%20image%20representations%20using%20convolutional%20neural%20networks%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oquab%2C%20M.%20Bottou%2C%20L.%20Laptev%2C%20I.%20Sivic%2C%20J.%20Learning%20and%20transferring%20mid-level%20image%20representations%20using%20convolutional%20neural%20networks%202013"
        },
        {
            "id": "37",
            "entry": "[37] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. IEEE Transactions on Neural Networks (TNN), 22(2):199\u2013210, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.J.%20Tsang%2C%20I.W.%20Kwok%2C%20J.T.%20Yang%2C%20Q.%20Domain%20adaptation%20via%20transfer%20component%20analysis%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.J.%20Tsang%2C%20I.W.%20Kwok%2C%20J.T.%20Yang%2C%20Q.%20Domain%20adaptation%20via%20transfer%20component%20analysis%202011"
        },
        {
            "id": "38",
            "entry": "[38] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering (TKDE), 22(10):1345\u20131359, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010"
        },
        {
            "id": "39",
            "entry": "[39] J. Quionero-Candela, M. Sugiyama, A. Schwaighofer, and N. D. Lawrence. Dataset shift in machine learning. The MIT Press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Quionero-Candela%2C%20J.%20Sugiyama%2C%20M.%20Schwaighofer%2C%20A.%20Lawrence%2C%20N.D.%20Dataset%20shift%20in%20machine%20learning%202009"
        },
        {
            "id": "40",
            "entry": "[40] A. Rahimi and B. Recht. Random features for large-scale kernel machines. In Advances in neural information processing systems (NIPS), pages 1177\u20131184, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rahimi%2C%20A.%20Recht%2C%20B.%20Random%20features%20for%20large-scale%20kernel%20machines%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rahimi%2C%20A.%20Recht%2C%20B.%20Random%20features%20for%20large-scale%20kernel%20machines%202008"
        },
        {
            "id": "41",
            "entry": "[41] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20ImageNet%20Large%20Scale%20Visual%20Recognition%20Challenge%202014"
        },
        {
            "id": "42",
            "entry": "[42] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In European Conference on Computer Vision (ECCV), 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saenko%2C%20K.%20Kulis%2C%20B.%20Fritz%2C%20M.%20Darrell%2C%20T.%20Adapting%20visual%20category%20models%20to%20new%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saenko%2C%20K.%20Kulis%2C%20B.%20Fritz%2C%20M.%20Darrell%2C%20T.%20Adapting%20visual%20category%20models%20to%20new%20domains%202010"
        },
        {
            "id": "43",
            "entry": "[43] S. Sankaranarayanan, Y. Balaji, C. D. Castillo, and R. Chellappa. Generate to adapt: Aligning domains using generative adversarial networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sankaranarayanan%2C%20S.%20Balaji%2C%20Y.%20Castillo%2C%20C.D.%20Chellappa%2C%20R.%20Generate%20to%20adapt%3A%20Aligning%20domains%20using%20generative%20adversarial%20networks%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sankaranarayanan%2C%20S.%20Balaji%2C%20Y.%20Castillo%2C%20C.D.%20Chellappa%2C%20R.%20Generate%20to%20adapt%3A%20Aligning%20domains%20using%20generative%20adversarial%20networks%202018-06"
        },
        {
            "id": "44",
            "entry": "[44] L. Song, B. Boots, S. M. Siddiqi, G. J. Gordon, and A. Smola. Hilbert space embeddings of hidden markov models. In International Conference on Machine Learning (ICML), 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20L.%20Boots%2C%20B.%20Siddiqi%2C%20S.M.%20Gordon%2C%20G.J.%20Hilbert%20space%20embeddings%20of%20hidden%20markov%20models%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20L.%20Boots%2C%20B.%20Siddiqi%2C%20S.M.%20Gordon%2C%20G.J.%20Hilbert%20space%20embeddings%20of%20hidden%20markov%20models%202010"
        },
        {
            "id": "45",
            "entry": "[45] L. Song and B. Dai. Robust low rank kernel embeddings of multivariate distributions. In Advances in Neural Information Processing Systems (NIPS), pages 3228\u20133236, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20L.%20Dai%2C%20B.%20Robust%20low%20rank%20kernel%20embeddings%20of%20multivariate%20distributions%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20L.%20Dai%2C%20B.%20Robust%20low%20rank%20kernel%20embeddings%20of%20multivariate%20distributions%202013"
        },
        {
            "id": "46",
            "entry": "[46] L. Song, K. Fukumizu, and A. Gretton. Kernel embeddings of conditional distributions: A unified kernel framework for nonparametric inference in graphical models. IEEE Signal Processing Magazine, 30(4):98\u2013111, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20L.%20Fukumizu%2C%20K.%20Gretton%2C%20A.%20Kernel%20embeddings%20of%20conditional%20distributions%3A%20A%20unified%20kernel%20framework%20for%20nonparametric%20inference%20in%20graphical%20models%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20L.%20Fukumizu%2C%20K.%20Gretton%2C%20A.%20Kernel%20embeddings%20of%20conditional%20distributions%3A%20A%20unified%20kernel%20framework%20for%20nonparametric%20inference%20in%20graphical%20models%202013"
        },
        {
            "id": "47",
            "entry": "[47] L. Song, J. Huang, A. Smola, and K. Fukumizu. Hilbert space embeddings of conditional distributions with applications to dynamical systems. In International Conference on Machine Learning (ICML), 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20L.%20Huang%2C%20J.%20Smola%2C%20A.%20Fukumizu%2C%20K.%20Hilbert%20space%20embeddings%20of%20conditional%20distributions%20with%20applications%20to%20dynamical%20systems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20L.%20Huang%2C%20J.%20Smola%2C%20A.%20Fukumizu%2C%20K.%20Hilbert%20space%20embeddings%20of%20conditional%20distributions%20with%20applications%20to%20dynamical%20systems%202009"
        },
        {
            "id": "48",
            "entry": "[48] M. Sugiyama, M. Krauledat, and K.-R. Muller. Covariate shift adaptation by importance weighted cross validation. Journal of Machine Learning Research (JMLR), 8(May):985\u20131005, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sugiyama%2C%20M.%20Krauledat%2C%20M.%20Muller%2C%20K.-R.%20Covariate%20shift%20adaptation%20by%20importance%20weighted%20cross%20validation%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sugiyama%2C%20M.%20Krauledat%2C%20M.%20Muller%2C%20K.-R.%20Covariate%20shift%20adaptation%20by%20importance%20weighted%20cross%20validation%202007"
        },
        {
            "id": "49",
            "entry": "[49] M. Sugiyama, S. Nakajima, H. Kashima, P. V. Buenau, and M. Kawanabe. Direct importance estimation with model selection and its application to covariate shift adaptation. In Advances in Neural Information Processing Systems (NIPS), 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sugiyama%2C%20M.%20Nakajima%2C%20S.%20Kashima%2C%20H.%20Buenau%2C%20P.V.%20Direct%20importance%20estimation%20with%20model%20selection%20and%20its%20application%20to%20covariate%20shift%20adaptation%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sugiyama%2C%20M.%20Nakajima%2C%20S.%20Kashima%2C%20H.%20Buenau%2C%20P.V.%20Direct%20importance%20estimation%20with%20model%20selection%20and%20its%20application%20to%20covariate%20shift%20adaptation%202008"
        },
        {
            "id": "50",
            "entry": "[50] Y. Tsai, W. Hung, S. Schulter, K. Sohn, M. Yang, and M. Chandraker. Learning to adapt structured output space for semantic segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsai%2C%20Y.%20Hung%2C%20W.%20Schulter%2C%20S.%20Sohn%2C%20K.%20Learning%20to%20adapt%20structured%20output%20space%20for%20semantic%20segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsai%2C%20Y.%20Hung%2C%20W.%20Schulter%2C%20S.%20Sohn%2C%20K.%20Learning%20to%20adapt%20structured%20output%20space%20for%20semantic%20segmentation%202018"
        },
        {
            "id": "51",
            "entry": "[51] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017"
        },
        {
            "id": "52",
            "entry": "[52] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell. Deep domain confusion: Maximizing for domain invariance. CoRR, abs/1412.3474, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.3474"
        },
        {
            "id": "53",
            "entry": "[53] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell. Simultaneous deep transfer across domains and tasks. In IEEE International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Zhang%2C%20N.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Zhang%2C%20N.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015"
        },
        {
            "id": "54",
            "entry": "[54] H. Venkateswara, J. Eusebio, S. Chakraborty, and S. Panchanathan. Deep hashing network for unsupervised domain adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Venkateswara%2C%20H.%20Eusebio%2C%20J.%20Chakraborty%2C%20S.%20Panchanathan%2C%20S.%20Deep%20hashing%20network%20for%20unsupervised%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Venkateswara%2C%20H.%20Eusebio%2C%20J.%20Chakraborty%2C%20S.%20Panchanathan%2C%20S.%20Deep%20hashing%20network%20for%20unsupervised%20domain%20adaptation%202017"
        },
        {
            "id": "55",
            "entry": "[55] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural networks? In Advances in Neural Information Processing Systems (NIPS), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yosinski%2C%20J.%20Clune%2C%20J.%20Bengio%2C%20Y.%20Lipson%2C%20H.%20How%20transferable%20are%20features%20in%20deep%20neural%20networks%3F%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yosinski%2C%20J.%20Clune%2C%20J.%20Bengio%2C%20Y.%20Lipson%2C%20H.%20How%20transferable%20are%20features%20in%20deep%20neural%20networks%3F%202014"
        },
        {
            "id": "56",
            "entry": "[56] K. Zhang, B. Sch\u00f6lkopf, K. Muandet, and Z. Wang. Domain adaptation under target and conditional shift. In International Conference on Machine Learning (ICML), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20K.%20Sch%C3%B6lkopf%2C%20B.%20Muandet%2C%20K.%20Wang%2C%20Z.%20Domain%20adaptation%20under%20target%20and%20conditional%20shift%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20K.%20Sch%C3%B6lkopf%2C%20B.%20Muandet%2C%20K.%20Wang%2C%20Z.%20Domain%20adaptation%20under%20target%20and%20conditional%20shift%202013"
        },
        {
            "id": "57",
            "entry": "[57] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017-10"
        }
    ]
}
