{
    "filename": "7924-causal-inference-with-noisy-and-missing-covariates-via-matrix-factorization.pdf",
    "metadata": {
        "title": "Causal Inference with Noisy and Missing Covariates via Matrix Factorization",
        "author": "Nathan Kallus, Xiaojie Mao, Madeleine Udell",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7924-causal-inference-with-noisy-and-missing-covariates-via-matrix-factorization.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Valid causal inference in observational studies often requires controlling for confounders. However, in practice measurements of confounders may be noisy, and can lead to biased estimates of causal effects. We show that we can reduce bias induced by measurement noise using a large number of noisy measurements of the underlying confounders. We propose the use of matrix factorization to infer the confounders from noisy covariates. This flexible and principled framework adapts to missing values, accommodates a wide variety of data types, and can enhance a wide variety of causal inference methods. We bound the error for the induced average treatment effect estimator and show it is consistent in a linear regression setting, using Exponential Family Matrix Completion preprocessing. We demonstrate the effectiveness of the proposed procedure in numerical experiments with both synthetic data and real clinical data."
    },
    "keywords": [
        {
            "term": "proxy variable",
            "url": "https://en.wikipedia.org/wiki/proxy_variable"
        },
        {
            "term": "logistic regression",
            "url": "https://en.wikipedia.org/wiki/logistic_regression"
        },
        {
            "term": "root mean squared error",
            "url": "https://en.wikipedia.org/wiki/root_mean_squared_error"
        },
        {
            "term": "matrix factorization",
            "url": "https://en.wikipedia.org/wiki/matrix_factorization"
        },
        {
            "term": "average treatment effect",
            "url": "https://en.wikipedia.org/wiki/average_treatment_effect"
        },
        {
            "term": "latent variable model",
            "url": "https://en.wikipedia.org/wiki/latent_variable_model"
        },
        {
            "term": "matrix completion",
            "url": "https://en.wikipedia.org/wiki/matrix_completion"
        },
        {
            "term": "large number",
            "url": "https://en.wikipedia.org/wiki/large_number"
        }
    ],
    "highlights": [
        "Estimating the causal effect of an intervention is a fundamental goal across many domains",
        "We rigorously investigate the theoretical implication of the matrix factorization preprocessing with respect to causal effect estimation",
        "We show that using a large number of noisy covariates can effectively alleviate the average treatment effect estimation bias resulted from measurement noise in linear regression setting",
        "We address the problem of measurement noise prevalent in causal inference",
        "We show that with a large number of noisy proxies, we can reduce the bias resulting from measurement noise by using matrix factorization preprocessing to infer latent confounders",
        "We guarantee the effectiveness of this approach in a linear regression setting, and show its effectiveness numerically on both synthetic and real clinical datasets. These results demonstrate that preprocessing by matrix factorization to infer latent confounders has a number of advantages: it can accommodate a wide variety of data types, ensures robustness to missing values, and can improve causal effect estimation when used in conjunction with a wide variety of causal inference methods"
    ],
    "key_statements": [
        "Estimating the causal effect of an intervention is a fundamental goal across many domains",
        "We show in a linear regression setting that the bias due to measurement noise can be effectively alleviated by using many proxies for the underlying confounders (Section 2.2)",
        "To address the aforementioned problems, we propose to use low rank matrix factorization as a principled approach to preprocess covariate matrices for causal inference",
        "We rigorously investigate the theoretical implication of the matrix factorization preprocessing with respect to causal effect estimation",
        "We evaluate the effectiveness of our proposed procedure on both synthetic datasets and a clinical dataset involving the mortality of twins born in the USA introduced by Louizos et al [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>]",
        "We empirically demonstrate that matrix factorization can accurately estimate causal effects by inferring the latent confounders from a large number of noisy covariates",
        "We show that the bias caused by measurement noise in linear regression is alleviated when more covariates are used",
        "We show that using a large number of noisy covariates can effectively alleviate the average treatment effect estimation bias resulted from measurement noise in linear regression setting",
        "We propose to recover the latent confounders {Ui}iN=1 from noisy and incomplete observations P\u03a9(X) by using low rank matrix factorization methods, which rely on the assumption: Assumption 2 (Low Rank Matrix)",
        "We theoretically justify matrix factorization preprocessing for estimating causal effect in linear regression setting",
        "We prove that Exponential Family Matrix Completion leads to accurate average treatment effect estimator with high probability under some generative assumptions on confounder matrix U as well as covariate loading matrix V",
        "We show that low rank matrix factorization effectively reduces the average treatment effect estimation error caused by measurement noise using two experimental settings: 1) synthetic datasets with both continuous and binary covariates and 2) the twins dataset introduced by Louizos et al [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>]",
        "For high dimensional data, matrix factorization preprocessing dominates all other feasible methods and its root mean squared error is very close to the oracle regression for sufficiently large number of covariates",
        "The gain from using matrix factorization is more dramatic for binary covariates, which demonstrates the advantage of matrix factorization preprocessing with loss functions adapting to the data types",
        "Our results demonstrate that matrix factorization preprocessing can augment popular causal inference methods beyond linear regression",
        "We address the problem of measurement noise prevalent in causal inference",
        "We show that with a large number of noisy proxies, we can reduce the bias resulting from measurement noise by using matrix factorization preprocessing to infer latent confounders",
        "We guarantee the effectiveness of this approach in a linear regression setting, and show its effectiveness numerically on both synthetic and real clinical datasets. These results demonstrate that preprocessing by matrix factorization to infer latent confounders has a number of advantages: it can accommodate a wide variety of data types, ensures robustness to missing values, and can improve causal effect estimation when used in conjunction with a wide variety of causal inference methods"
    ],
    "summary": [
        "Estimating the causal effect of an intervention is a fundamental goal across many domains.",
        "We empirically demonstrate that matrix factorization can accurately estimate causal effects by inferring the latent confounders from a large number of noisy covariates.",
        "We show that using a large number of noisy covariates can effectively alleviate the ATE estimation bias resulted from measurement noise in linear regression setting.",
        "We theoretically justify matrix factorization preprocessing for estimating causal effect in linear regression setting.",
        "We prove that EFMC leads to accurate ATE estimator with high probability under some generative assumptions on confounder matrix U as well as covariate loading matrix V .",
        "Assume that the following assumptions hold: (a) Assumption 1 - 5 (Unconfoundedness, Low Rank Matrix, Missing Completely at Random, Natural Exponential Family, Latent Confounders and Covariate Loadings); (b) \u03b1 max \u2264 A for a positive constant A in Theorem 1); (c) Xij is sub-Exponential conditionally on Ui with parameter \u03c3 for any (i, j); (d) Ti is almost surely not a linear combination of Ui; \u221a",
        "We show that low rank matrix factorization effectively reduces the ATE estimation error caused by measurement noise using two experimental settings: 1) synthetic datasets with both continuous and binary covariates and 2) the twins dataset introduced by Louizos et al [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>].",
        "We consider covariates generated from both indepedent Gaussian noise and independent Bernoulli noise: Xij \u223c N (Ui Vj, 5) and Xij \u223c Bernoulli(\u03c3(Ui Vj)) for Vj \u2208 Rr. We set the dimension of the latent confounders r = 5, use \u03b1 = [\u22122, 3, \u22122, \u22123, \u22122] and \u03b2 = [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], and choose \u03c4 = 2 in our example.",
        "For high dimensional data, matrix factorization preprocessing dominates all other feasible methods and its RMSE is very close to the oracle regression for sufficiently large number of covariates.",
        "We consider logistic regression using data output from different preprocessing method: imputing missing values by column-wise mode, multiple imputation using the R package MICE with 5 repeated imputations [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>], and the estimated confounders {Ui}Ni=1 from matrix factorization.",
        "We show that with a large number of noisy proxies, we can reduce the bias resulting from measurement noise by using matrix factorization preprocessing to infer latent confounders.",
        "These results demonstrate that preprocessing by matrix factorization to infer latent confounders has a number of advantages: it can accommodate a wide variety of data types, ensures robustness to missing values, and can improve causal effect estimation when used in conjunction with a wide variety of causal inference methods.",
        "Matrix factorization allows more principled and accurate estimation of causal effects from observational data"
    ],
    "headline": "We show that we can reduce bias induced by measurement noise using a large number of noisy measurements of the underlying confounders",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. Recommendations as treatments: Debiasing learning and evaluation. arXiv preprint arXiv:1602.05352, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.05352"
        },
        {
            "id": "2",
            "entry": "[2] Alfred F Connors, Theodore Speroff, Neal V Dawson, Charles Thomas, Frank E Harrell, Douglas Wagner, Norman Desbiens, Lee Goldman, Albert W Wu, Robert M Califf, et al. The effectiveness of right heart catheterization in the initial care of critically iii patients. Journal of American Medical Association, 276(11):889\u2013897, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Connors%2C%20Alfred%20F.%20Speroff%2C%20Theodore%20Dawson%2C%20Neal%20V.%20Thomas%2C%20Charles%20The%20effectiveness%20of%20right%20heart%20catheterization%20in%20the%20initial%20care%20of%20critically%20iii%20patients%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Connors%2C%20Alfred%20F.%20Speroff%2C%20Theodore%20Dawson%2C%20Neal%20V.%20Thomas%2C%20Charles%20The%20effectiveness%20of%20right%20heart%20catheterization%20in%20the%20initial%20care%20of%20critically%20iii%20patients%201996"
        },
        {
            "id": "3",
            "entry": "[3] Joshua D Angrist and Alan B Keueger. Does compulsory school attendance affect schooling and earnings? The Quarterly Journal of Economics, 106(4):979\u20131014, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Angrist%2C%20Joshua%20D.%20Keueger%2C%20Alan%20B.%20Does%20compulsory%20school%20attendance%20affect%20schooling%20and%20earnings%3F%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Angrist%2C%20Joshua%20D.%20Keueger%2C%20Alan%20B.%20Does%20compulsory%20school%20attendance%20affect%20schooling%20and%20earnings%3F%201991"
        },
        {
            "id": "4",
            "entry": "[4] Guido W Imbens and Donald B Rubin. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Imbens%2C%20Guido%20W.%20Rubin%2C%20Donald%20B.%20Causal%20inference%20in%20statistics%2C%20social%2C%20and%20biomedical%20sciences%202015"
        },
        {
            "id": "5",
            "entry": "[5] Peter A Frost. Proxy variables and specification bias. The review of economics and Statistics, pages 323\u2013325, 1979.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Frost%2C%20Peter%20A.%20Proxy%20variables%20and%20specification%20bias.%20The%20review%20of%20economics%20and%201979",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Frost%2C%20Peter%20A.%20Proxy%20variables%20and%20specification%20bias.%20The%20review%20of%20economics%20and%201979"
        },
        {
            "id": "6",
            "entry": "[6] Michael R Wickens. A note on the use of proxy variables. Econometrica: Journal of the Econometric Society, pages 759\u2013761, 1972.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wickens%2C%20Michael%20R.%20A%20note%20on%20the%20use%20of%20proxy%20variables%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wickens%2C%20Michael%20R.%20A%20note%20on%20the%20use%20of%20proxy%20variables%201972"
        },
        {
            "id": "7",
            "entry": "[7] Jeffrey M Wooldridge. Introductory econometrics: A modern approach. Nelson Education, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wooldridge%2C%20Jeffrey%20M.%20Introductory%20econometrics%3A%20A%20modern%20approach%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wooldridge%2C%20Jeffrey%20M.%20Introductory%20econometrics%3A%20A%20modern%20approach%202015"
        },
        {
            "id": "8",
            "entry": "[8] Suriya Gunasekar, Pradeep Ravikumar, and Joydeep Ghosh. Exponential family matrix completion under structural constraints. In International Conference on Machine Learning, pages 1917\u20131925, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gunasekar%2C%20Suriya%20Ravikumar%2C%20Pradeep%20Ghosh%2C%20Joydeep%20Exponential%20family%20matrix%20completion%20under%20structural%20constraints%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gunasekar%2C%20Suriya%20Ravikumar%2C%20Pradeep%20Ghosh%2C%20Joydeep%20Exponential%20family%20matrix%20completion%20under%20structural%20constraints%202014"
        },
        {
            "id": "9",
            "entry": "[9] Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. Causal effect inference with deep latent-variable models. In Advances in Neural Information Processing Systems, pages 6449\u20136459, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Louizos%2C%20Christos%20Shalit%2C%20Uri%20Mooij%2C%20Joris%20M.%20Sontag%2C%20David%20Causal%20effect%20inference%20with%20deep%20latent-variable%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Louizos%2C%20Christos%20Shalit%2C%20Uri%20Mooij%2C%20Joris%20M.%20Sontag%2C%20David%20Causal%20effect%20inference%20with%20deep%20latent-variable%20models%202017"
        },
        {
            "id": "10",
            "entry": "[10] James Bennett, Stan Lanning, et al. The netflix prize. In Proceedings of KDD cup and workshop, volume 2007, page 35. New York, NY, USA, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bennett%2C%20James%20Lanning%2C%20Stan%20The%20netflix%20prize%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bennett%2C%20James%20Lanning%2C%20Stan%20The%20netflix%20prize%202007"
        },
        {
            "id": "11",
            "entry": "[11] Feilong Cao, Miaomiao Cai, and Yuanpeng Tan. Image interpolation via low-rank matrix completion and recovery. IEEE Transactions on Circuits and Systems for Video Technology, 25(8):1261\u20131270, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Feilong%20Cai%2C%20Miaomiao%20Tan%2C%20Yuanpeng%20Image%20interpolation%20via%20low-rank%20matrix%20completion%20and%20recovery%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Feilong%20Cai%2C%20Miaomiao%20Tan%2C%20Yuanpeng%20Image%20interpolation%20via%20low-rank%20matrix%20completion%20and%20recovery%202015"
        },
        {
            "id": "12",
            "entry": "[12] Alejandro Schuler, Vincent Liu, Joe Wan, Alison Callahan, Madeleine Udell, David E Stark, and Nigam H Shah. Discovering patient phenotypes using generalized low rank models. In Biocomputing 2016: Proceedings of the Pacific Symposium, pages 144\u2013155. World Scientific, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schuler%2C%20Alejandro%20Liu%2C%20Vincent%20Wan%2C%20Joe%20Callahan%2C%20Alison%20Discovering%20patient%20phenotypes%20using%20generalized%20low%20rank%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schuler%2C%20Alejandro%20Liu%2C%20Vincent%20Wan%2C%20Joe%20Callahan%2C%20Alison%20Discovering%20patient%20phenotypes%20using%20generalized%20low%20rank%20models%202016"
        },
        {
            "id": "13",
            "entry": "[13] Emmanuel J Cand\u00e8s and Benjamin Recht. Exact matrix completion via convex optimization. Foundations of Computational mathematics, 9(6):717, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cand%C3%A8s%2C%20Emmanuel%20J.%20Recht%2C%20Benjamin%20Exact%20matrix%20completion%20via%20convex%20optimization%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cand%C3%A8s%2C%20Emmanuel%20J.%20Recht%2C%20Benjamin%20Exact%20matrix%20completion%20via%20convex%20optimization%202009"
        },
        {
            "id": "14",
            "entry": "[14] Emmanuel J Cand\u00e8s and Terence Tao. The power of convex relaxation: Near-optimal matrix completion. IEEE Transactions on Information Theory, 56(5):2053\u20132080, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cand%C3%A8s%2C%20Emmanuel%20J.%20Tao%2C%20Terence%20The%20power%20of%20convex%20relaxation%3A%20Near-optimal%20matrix%20completion%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cand%C3%A8s%2C%20Emmanuel%20J.%20Tao%2C%20Terence%20The%20power%20of%20convex%20relaxation%3A%20Near-optimal%20matrix%20completion%202010"
        },
        {
            "id": "15",
            "entry": "[15] Emmanuel J Candes and Yaniv Plan. Matrix completion with noise. Proceedings of the IEEE, 98(6):925\u2013936, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Candes%2C%20Emmanuel%20J.%20Plan%2C%20Yaniv%20Matrix%20completion%20with%20noise%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Candes%2C%20Emmanuel%20J.%20Plan%2C%20Yaniv%20Matrix%20completion%20with%20noise%202010"
        },
        {
            "id": "16",
            "entry": "[16] Benjamin Recht. A simpler approach to matrix completion. Journal of Machine Learning Research, 12(Dec):3413\u20133430, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Recht%2C%20Benjamin%20A%20simpler%20approach%20to%20matrix%20completion%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Recht%2C%20Benjamin%20A%20simpler%20approach%20to%20matrix%20completion%202011"
        },
        {
            "id": "17",
            "entry": "[17] Raghunandan H Keshavan, Andrea Montanari, and Sewoong Oh. Matrix completion from a few entries. IEEE Transactions on Information Theory, 56(6):2980\u20132998, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Keshavan%2C%20Raghunandan%20H.%20Montanari%2C%20Andrea%20Oh%2C%20Sewoong%20Matrix%20completion%20from%20a%20few%20entries%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Keshavan%2C%20Raghunandan%20H.%20Montanari%2C%20Andrea%20Oh%2C%20Sewoong%20Matrix%20completion%20from%20a%20few%20entries%202010"
        },
        {
            "id": "18",
            "entry": "[18] Madeleine Udell, Corinne Horn, Reza Zadeh, Stephen Boyd, et al. Generalized low rank models. Foundations and Trends R in Machine Learning, 9(1):1\u2013118, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Udell%2C%20Madeleine%20Horn%2C%20Corinne%20Zadeh%2C%20Reza%20Boyd%2C%20Stephen%20Generalized%20low%20rank%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Udell%2C%20Madeleine%20Horn%2C%20Corinne%20Zadeh%2C%20Reza%20Boyd%2C%20Stephen%20Generalized%20low%20rank%20models%202016"
        },
        {
            "id": "19",
            "entry": "[19] Susan Athey, Mohsen Bayati, Nikolay Doudchenko, Guido Imbens, and Khashayar Khosravi. Matrix completion methods for causal panel data models. arXiv preprint arXiv:1710.10251, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10251"
        },
        {
            "id": "20",
            "entry": "[20] Raymond J Carroll, David Ruppert, Ciprian M Crainiceanu, and Leonard A Stefanski. Measurement error in nonlinear models: a modern perspective. Chapman and Hall/CRC, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carroll%2C%20Raymond%20J.%20Ruppert%2C%20David%20Crainiceanu%2C%20Ciprian%20M.%20Stefanski%2C%20Leonard%20A.%20Measurement%20error%20in%20nonlinear%20models%3A%20a%20modern%20perspective%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carroll%2C%20Raymond%20J.%20Ruppert%2C%20David%20Crainiceanu%2C%20Ciprian%20M.%20Stefanski%2C%20Leonard%20A.%20Measurement%20error%20in%20nonlinear%20models%3A%20a%20modern%20perspective%202006"
        },
        {
            "id": "21",
            "entry": "[21] Manabu Kuroki and Judea Pearl. Measurement bias and effect restoration in causal inference. Biometrika, 101(2):423\u2013437, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuroki%2C%20Manabu%20Pearl%2C%20Judea%20Measurement%20bias%20and%20effect%20restoration%20in%20causal%20inference%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuroki%2C%20Manabu%20Pearl%2C%20Judea%20Measurement%20bias%20and%20effect%20restoration%20in%20causal%20inference%202014"
        },
        {
            "id": "22",
            "entry": "[22] Wang Miao, Zhi Geng, and Eric Tchetgen Tchetgen. Identifying causal effects with proxy variables of an unmeasured confounder. arXiv preprint arXiv:1609.08816, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.08816"
        },
        {
            "id": "23",
            "entry": "[23] Charles Spearman. \" general intelligence,\" objectively determined and measured. The American Journal of Psychology, 15(2):201\u2013292, 1904.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Charles%20Spearman.%20%22%20general%20intelligence%2C%22%20objectively%20determined%20and%20measured%201904",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Charles%20Spearman.%20%22%20general%20intelligence%2C%22%20objectively%20determined%20and%20measured%201904"
        },
        {
            "id": "24",
            "entry": "[24] Madeleine Udell and Alex Townsend. Nice latent variable models have log-rank. arXiv preprint arXiv:1705.07474, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.07474"
        },
        {
            "id": "25",
            "entry": "[25] Roderick JA Little and Donald B Rubin. Statistical analysis with missing data, volume 333. John Wiley & Sons, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Little%2C%20Roderick%20J.A.%20Rubin%2C%20Donald%20B.%20Statistical%20analysis%20with%20missing%20data%2C%20volume%20333%202014"
        },
        {
            "id": "26",
            "entry": "[26] Peter McCullagh. Generalized linear models. European Journal of Operational Research, 16(3):285\u2013292, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McCullagh%2C%20Peter%20Generalized%20linear%20models%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McCullagh%2C%20Peter%20Generalized%20linear%20models%201984"
        },
        {
            "id": "27",
            "entry": "[27] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20Stephen%20Vandenberghe%2C%20Lieven%20Convex%20optimization%202004"
        },
        {
            "id": "28",
            "entry": "[28] Nathan Kallus and Madeleine Udell. Dynamic assortment personalization in high dimensions. arXiv preprint arXiv:1610.05604, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.05604"
        },
        {
            "id": "29",
            "entry": "[29] Ajit P Singh and Geoffrey J Gordon. A unified view of matrix factorization models. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 358\u2013373.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Singh%2C%20Ajit%20P.%20Gordon%2C%20Geoffrey%20J.%20A%20unified%20view%20of%20matrix%20factorization%20models",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Singh%2C%20Ajit%20P.%20Gordon%2C%20Geoffrey%20J.%20A%20unified%20view%20of%20matrix%20factorization%20models"
        },
        {
            "id": "30",
            "entry": "[30] Andrew Y Ng. Feature selection, l 1 vs. l 2 regularization, and rotational invariance. In Proceedings of the twenty-first international conference on Machine learning, page 78. ACM, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ng%2C%20Andrew%20Y.%20Feature%20selection%2C%20l%201%20vs.%20l%202%20regularization%2C%20and%20rotational%20invariance%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ng%2C%20Andrew%20Y.%20Feature%20selection%2C%20l%201%20vs.%20l%202%20regularization%2C%20and%20rotational%20invariance%202004"
        },
        {
            "id": "31",
            "entry": "[31] T Tony Cai, Anru Zhang, et al. Rate-optimal perturbation bounds for singular subspaces with applications to high-dimensional statistics. The Annals of Statistics, 46(1):60\u201389, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cai%2C%20T.Tony%20Zhang%2C%20Anru%20Rate-optimal%20perturbation%20bounds%20for%20singular%20subspaces%20with%20applications%20to%20high-dimensional%20statistics%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cai%2C%20T.Tony%20Zhang%2C%20Anru%20Rate-optimal%20perturbation%20bounds%20for%20singular%20subspaces%20with%20applications%20to%20high-dimensional%20statistics%202018"
        },
        {
            "id": "32",
            "entry": "[32] Trevor Hastie, Rahul Mazumder, Jason D Lee, and Reza Zadeh. Matrix completion and low-rank svd via fast alternating least squares. Journal of Machine Learning Research, 16:3367\u20133402, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hastie%2C%20Trevor%20Mazumder%2C%20Rahul%20Lee%2C%20Jason%20D.%20Zadeh%2C%20Reza%20Matrix%20completion%20and%20low-rank%20svd%20via%20fast%20alternating%20least%20squares%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hastie%2C%20Trevor%20Mazumder%2C%20Rahul%20Lee%2C%20Jason%20D.%20Zadeh%2C%20Reza%20Matrix%20completion%20and%20low-rank%20svd%20via%20fast%20alternating%20least%20squares%202015"
        },
        {
            "id": "33",
            "entry": "[33] Michael Collins, Sanjoy Dasgupta, and Robert E Schapire. A generalization of principal components analysis to the exponential family. In Advances in neural information processing systems, pages 617\u2013624, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collins%2C%20Michael%20Dasgupta%2C%20Sanjoy%20Schapire%2C%20Robert%20E.%20A%20generalization%20of%20principal%20components%20analysis%20to%20the%20exponential%20family%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collins%2C%20Michael%20Dasgupta%2C%20Sanjoy%20Schapire%2C%20Robert%20E.%20A%20generalization%20of%20principal%20components%20analysis%20to%20the%20exponential%20family%202002"
        },
        {
            "id": "34",
            "entry": "[34] Ben B. Hansen and Stephanie Olsen Klopfer. Optimal full matching and related designs via network flows. Journal of Computational and Graphical Statistics, 15(3):609\u2013627, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hansen%2C%20Ben%20B.%20Klopfer%2C%20Stephanie%20Olsen%20Optimal%20full%20matching%20and%20related%20designs%20via%20network%20flows%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hansen%2C%20Ben%20B.%20Klopfer%2C%20Stephanie%20Olsen%20Optimal%20full%20matching%20and%20related%20designs%20via%20network%20flows%202006"
        },
        {
            "id": "35",
            "entry": "[35] Stef van Buuren and Karin Groothuis-Oudshoorn. mice: Multivariate imputation by chained equations in r. Journal of Statistical Software, 45(3):1\u201367, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20Buuren%2C%20Stef%20Groothuis-Oudshoorn%2C%20Karin%20mice%3A%20Multivariate%20imputation%20by%20chained%20equations%20in%20r%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20Buuren%2C%20Stef%20Groothuis-Oudshoorn%2C%20Karin%20mice%3A%20Multivariate%20imputation%20by%20chained%20equations%20in%20r%202011"
        },
        {
            "id": "36",
            "entry": "[36] Gautam Tripathi. A matrix extension of the cauchy-schwarz inequality. Economics Letters, 63(1):1\u20133, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tripathi%2C%20Gautam%20A%20matrix%20extension%20of%20the%20cauchy-schwarz%20inequality%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tripathi%2C%20Gautam%20A%20matrix%20extension%20of%20the%20cauchy-schwarz%20inequality%201999"
        },
        {
            "id": "37",
            "entry": "[37] Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint arXiv:1011.3027, 2010.",
            "arxiv_url": "https://arxiv.org/pdf/1011.3027"
        },
        {
            "id": "38",
            "entry": "[38] Daniel Hsu, Sham Kakade, Tong Zhang, et al. A tail inequality for quadratic forms of subgaussian random vectors. Electronic Communications in Probability, 17, 2012. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hsu%2C%20Daniel%20Kakade%2C%20Sham%20Zhang%2C%20Tong%20A%20tail%20inequality%20for%20quadratic%20forms%20of%20subgaussian%20random%20vectors%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hsu%2C%20Daniel%20Kakade%2C%20Sham%20Zhang%2C%20Tong%20A%20tail%20inequality%20for%20quadratic%20forms%20of%20subgaussian%20random%20vectors%202012"
        }
    ]
}
