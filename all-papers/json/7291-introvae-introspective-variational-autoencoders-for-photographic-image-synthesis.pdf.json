{
    "filename": "7291-introvae-introspective-variational-autoencoders-for-photographic-image-synthesis.pdf",
    "metadata": {
        "title": "IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis",
        "author": "Huaibo Huang, zhihang li, Ran He, Zhenan Sun, Tieniu Tan",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7291-introvae-introspective-variational-autoencoders-for-photographic-image-synthesis.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We present a novel introspective variational autoencoder (IntroVAE) model for synthesizing high-resolution photographic images. IntroVAE is capable of selfevaluating the quality of its generated samples and improving itself accordingly. Its inference and generator models are jointly trained in an introspective way. On one hand, the generator is required to reconstruct the input images from the noisy outputs of the inference model as normal VAEs. On the other hand, the inference model is encouraged to classify between the generated and real samples while the generator tries to fool it as GANs. These two famous generative frameworks are integrated in a simple yet efficient single-stream architecture that can be trained in a single stage. IntroVAE preserves the advantages of VAEs, such as stable training and nice latent manifold. Unlike most other hybrid models of VAEs and GANs, IntroVAE requires no extra discriminators, because the inference model itself serves as a discriminator to distinguish between the generated and real samples. Experiments demonstrate that our method produces high-resolution photo-realistic images (e.g., CELEBA images at 10242), which are comparable to or better than the state-of-the-art GANs."
    },
    "keywords": [
        {
            "term": "single stage",
            "url": "https://en.wikipedia.org/wiki/single_stage"
        },
        {
            "term": "single stream",
            "url": "https://en.wikipedia.org/wiki/single_stream"
        },
        {
            "term": "approximate inference",
            "url": "https://en.wikipedia.org/wiki/approximate_inference"
        },
        {
            "term": "image synthesis",
            "url": "https://en.wikipedia.org/wiki/image_synthesis"
        },
        {
            "term": "latent variable",
            "url": "https://en.wikipedia.org/wiki/latent_variable"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        }
    ],
    "highlights": [
        "As our work is a specific hybrid model of Variational Autoencoders and Generative Adversarial Networks, we start with a brief review of Variational Autoencoders, Generative Adversarial Networks and their hybrid models.<br/><br/>Variational Autoencoders (VAEs) consist of two networks: a generative network (Generator) p\u03b8(x|z) that samples the visible variables x given the latent variables z and an approximate inference network (Encoder) q\u03c6(z|x) that maps the visible variables x to the latent variables z which approximate a prior p(z)",
        "Our contribution is three-fold. i) We propose a new training technique for Variational Autoencoders, that trains Variational Autoencoders in an introspective manner such that the model itself estimates the differences between the generated and real images without extra discriminators. ii) We propose a single-stream single-stage adversarial model for high-resolution photographic image synthesis, which is, to our knowledge, the first feasible method for Generative Adversarial Networks to generate high-resolution images in such a simple yet efficient manner, e.g., CELEBA images at 10242. iii) Experiments demonstrate that our method combines the strengths of Generative Adversarial Networks and Variational Autoencoders, producing high-resolution photographic images comparable to those produced by the state-of-the-art Generative Adversarial Networks while preserving the advantages of Variational Autoencoders, such as stable training and nice latent manifold",
        "We provide the visual quality results in Large-scale Scene Understanding BEDROOM in Fig. 4, which further demonstrate that our method is capable to synthesize high quality images that are comparable with PGGAN\u2019s. (More visual results on extra datasets are provided in Appendix F & G.)\n4.3",
        "We have introduced introspective Variational Autoencoders, a novel and simple approach to training Variational Autoencoders for synthesizing high-resolution photographic images",
        "The inference model not only learns a nice latent manifold structure, but acts as a discriminator to maximize the divergence of the approximate posterior with the prior for the generated data",
        "The proposed IntroVAE has an introspection capability to self-estimate the quality of the generated images and improve itself"
    ],
    "key_statements": [
        "As our work is a specific hybrid model of Variational Autoencoders and Generative Adversarial Networks, we start with a brief review of Variational Autoencoders, Generative Adversarial Networks and their hybrid models.<br/><br/>Variational Autoencoders (VAEs) consist of two networks: a generative network (Generator) p\u03b8(x|z) that samples the visible variables x given the latent variables z and an approximate inference network (Encoder) q\u03c6(z|x) that maps the visible variables x to the latent variables z which approximate a prior p(z)",
        "We introduce an introspective variational autoencoder (IntroVAE), a simple yet efficient approach to training Variational Autoencoders for photographic image synthesis",
        "Our contribution is three-fold. i) We propose a new training technique for Variational Autoencoders, that trains Variational Autoencoders in an introspective manner such that the model itself estimates the differences between the generated and real images without extra discriminators. ii) We propose a single-stream single-stage adversarial model for high-resolution photographic image synthesis, which is, to our knowledge, the first feasible method for Generative Adversarial Networks to generate high-resolution images in such a simple yet efficient manner, e.g., CELEBA images at 10242. iii) Experiments demonstrate that our method combines the strengths of Generative Adversarial Networks and Variational Autoencoders, producing high-resolution photographic images comparable to those produced by the state-of-the-art Generative Adversarial Networks while preserving the advantages of Variational Autoencoders, such as stable training and nice latent manifold",
        "The main limitation of Variational Autoencoders is that the generated samples tend to be blurry, which is often attributed to the limited expressiveness of the inference models, the injected noise and imperfect element-wise criteria such as the squared error [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>, <a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>]",
        "We introduce IntroVAE to alleviate these problems by combining Generative Adversarial Networks with Variational Autoencoders in an introspective manner",
        "The addition of the reconstruction error LAE builds a bridge between the inference model E and the generator G and results in a specific hybrid models of Variational Autoencoders and Generative Adversarial Networks",
        "We provide the visual quality results in Large-scale Scene Understanding BEDROOM in Fig. 4, which further demonstrate that our method is capable to synthesize high quality images that are comparable with PGGAN\u2019s. (More visual results on extra datasets are provided in Appendix F & G.)\n4.3",
        "We have introduced introspective Variational Autoencoders, a novel and simple approach to training Variational Autoencoders for synthesizing high-resolution photographic images",
        "The inference model not only learns a nice latent manifold structure, but acts as a discriminator to maximize the divergence of the approximate posterior with the prior for the generated data",
        "The proposed IntroVAE has an introspection capability to self-estimate the quality of the generated images and improve itself"
    ],
    "summary": [
        "As our work is a specific hybrid model of VAEs and GANs, we start with a brief review of VAEs, GANs and their hybrid models.<br/><br/>Variational Autoencoders (VAEs) consist of two networks: a generative network (Generator) p\u03b8(x|z) that samples the visible variables x given the latent variables z and an approximate inference network (Encoder) q\u03c6(z|x) that maps the visible variables x to the latent variables z which approximate a prior p(z).",
        "The divergence object is adversarially optimized along with the reconstruction error, which increases the difficulty of distinguishing between the generated and real images for the inference model, even for those with high-resolution.",
        "I) We propose a new training technique for VAEs, that trains VAEs in an introspective manner such that the model itself estimates the differences between the generated and real images without extra discriminators.",
        "To synthesize high-resolution images, several studies have trained GANs in a Laplacian pyramid [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>] or a tree-like structure [<a class=\"ref-link\" id=\"c42\" href=\"#r42\">42</a>, <a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>] with multi-scale discriminators [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>], mostly in a coarse-to-fine manner, including the state-of-the-art PGGAN method [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>].",
        "Ulyanov et al [<a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>] propose adversarial generator-encoder networks (AGE) that shares some similarity with ours in the architecture of two components, while the two models differ in many ways, such as the design of the inference models, the training objects, and the divergence computations.",
        "The addition of the reconstruction error LAE builds a bridge between the inference model E and the generator G and results in a specific hybrid models of VAEs and GANs. For a data sample x from the",
        "Relationships with other hybrid models Compared to other hybrid models [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>, <a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] of VAEs and GANs, which always use a discriminator to regularize the latent code and generated data individually or jointly, the proposed method adds prior regularization into both the latent space and data space in an introspective manner.",
        "Similar to VAE/GAN [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>], we train IntroVAE to discriminate real samples from both the model samples and reconstructions.",
        "Network architecture We design the inference and generator models of IntroVAE in a similar way to the discriminator and generator in PGGAN except of the use of residual blocks to accelerate the training convergence.",
        "As illustrated in Fig. 3(d), our method is able to synthesize high-resolution high-quality samples comparable with PGGAN, which are both distinguishable with the real images.",
        "The learning objective is to play a min-max game between the inference and generator models of VAEs. The inference model not only learns a nice latent manifold structure, but acts as a discriminator to maximize the divergence of the approximate posterior with the prior for the generated data.",
        "Compared to other state-of-the-art methods, the proposed model is simpler and more efficient with a single-stream network in a single stage, and it can synthesize high-resolution photographic images using a stable training process.",
        "Since our model has a standard VAE architecture, it may be extended to various VAEs-related tasks, such as conditional image synthesis"
    ],
    "headline": "We present a novel introspective variational autoencoder  model for synthesizing high-resolution photographic images",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Arjovsky, Martin, Chintala, Soumith, and Bottou, L\u00e9on. Wasserstein GAN. arXiv preprint arXiv:1701.07875, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.07875"
        },
        {
            "id": "2",
            "entry": "[2] Berthelot, David, Schumm, Tom, and Metz, Luke. BEGAN: Boundary equilibrium generative adversarial networks. arXiv preprint arXiv:1703.10717, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.10717"
        },
        {
            "id": "3",
            "entry": "[3] Brock, Andrew, Lim, Theodore, Ritchie, James M, and Weston, Nick. Neural photo editing with introspective adversarial networks. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brock%2C%20Andrew%20Lim%2C%20Theodore%20Ritchie%2C%20James%20M.%20Weston%2C%20Nick%20Neural%20photo%20editing%20with%20introspective%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brock%2C%20Andrew%20Lim%2C%20Theodore%20Ritchie%2C%20James%20M.%20Weston%2C%20Nick%20Neural%20photo%20editing%20with%20introspective%20adversarial%20networks%202017"
        },
        {
            "id": "4",
            "entry": "[4] Chen, Xi, Kingma, Diederik P, Salimans, Tim, Duan, Yan, Dhariwal, Prafulla, Schulman, John, Sutskever, Ilya, and Abbeel, Pieter. Variational lossy autoencoder. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%20Xi%20Kingma%20Diederik%20P%20Salimans%20Tim%20Duan%20Yan%20Dhariwal%20Prafulla%20Schulman%20John%20Sutskever%20Ilya%20and%20Abbeel%20Pieter%20Variational%20lossy%20autoencoder%20In%20ICLR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%20Xi%20Kingma%20Diederik%20P%20Salimans%20Tim%20Duan%20Yan%20Dhariwal%20Prafulla%20Schulman%20John%20Sutskever%20Ilya%20and%20Abbeel%20Pieter%20Variational%20lossy%20autoencoder%20In%20ICLR%202017"
        },
        {
            "id": "5",
            "entry": "[5] Dahl, Ryan, Norouzi, Mohammad, and Shlens, Jonathon. Pixel recursive super resolution. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dahl%2C%20Ryan%20Norouzi%2C%20Mohammad%20Shlens%2C%20Jonathon%20Pixel%20recursive%20super%20resolution%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dahl%2C%20Ryan%20Norouzi%2C%20Mohammad%20Shlens%2C%20Jonathon%20Pixel%20recursive%20super%20resolution%202017"
        },
        {
            "id": "6",
            "entry": "[6] Denton, Emily L, Chintala, Soumith, Fergus, Rob, et al. Deep generative image models using a laplacian pyramid of adversarial networks. In NIPS, pp. 1486\u20131494, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20L.%20Chintala%2C%20Soumith%20Fergus%2C%20Rob%20Deep%20generative%20image%20models%20using%20a%20laplacian%20pyramid%20of%20adversarial%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20L.%20Chintala%2C%20Soumith%20Fergus%2C%20Rob%20Deep%20generative%20image%20models%20using%20a%20laplacian%20pyramid%20of%20adversarial%20networks%202015"
        },
        {
            "id": "7",
            "entry": "[7] Dinh, Laurent, Sohl-Dickstein, Jascha, and Bengio, Samy. Density estimation using real NVP. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dinh%2C%20Laurent%20Sohl-Dickstein%2C%20Jascha%20Bengio%2C%20Samy%20Density%20estimation%20using%20real%20NVP%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dinh%2C%20Laurent%20Sohl-Dickstein%2C%20Jascha%20Bengio%2C%20Samy%20Density%20estimation%20using%20real%20NVP%202017"
        },
        {
            "id": "8",
            "entry": "[8] Donahue, Jeff, Kr\u00e4henb\u00fchl, Philipp, and Darrell, Trevor. Adversarial feature learning. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20Jeff%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Darrell%2C%20Trevor%20Adversarial%20feature%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20Jeff%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Darrell%2C%20Trevor%20Adversarial%20feature%20learning%202017"
        },
        {
            "id": "9",
            "entry": "[9] Dosovitskiy, Alexey and Brox, Thomas. Generating images with perceptual similarity metrics based on deep networks. In NIPS, pp. 658\u2013666, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Generating%20images%20with%20perceptual%20similarity%20metrics%20based%20on%20deep%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Generating%20images%20with%20perceptual%20similarity%20metrics%20based%20on%20deep%20networks%202016"
        },
        {
            "id": "10",
            "entry": "[10] Dumoulin, Vincent, Belghazi, Ishmael, Poole, Ben, Mastropietro, Olivier, Lamb, Alex, Arjovsky, Martin, and Courville, Aaron. Adversarially learned inference. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dumoulin%20Vincent%20Belghazi%20Ishmael%20Poole%20Ben%20Mastropietro%20Olivier%20Lamb%20Alex%20Arjovsky%20Martin%20and%20Courville%20Aaron%20Adversarially%20learned%20inference%20In%20ICLR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dumoulin%20Vincent%20Belghazi%20Ishmael%20Poole%20Ben%20Mastropietro%20Olivier%20Lamb%20Alex%20Arjovsky%20Martin%20and%20Courville%20Aaron%20Adversarially%20learned%20inference%20In%20ICLR%202017"
        },
        {
            "id": "11",
            "entry": "[11] Durugkar, Ishan, Gemp, Ian, and Mahadevan, Sridhar. Generative multi-adversarial networks. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Durugkar%2C%20Ishan%20Gemp%2C%20Ian%20Mahadevan%2C%20Sridhar%20Generative%20multi-adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Durugkar%2C%20Ishan%20Gemp%2C%20Ian%20Mahadevan%2C%20Sridhar%20Generative%20multi-adversarial%20networks%202017"
        },
        {
            "id": "12",
            "entry": "[12] Gibiansky, Andrew, Arik, Sercan, Diamos, Gregory, Miller, John, Peng, Kainan, Ping, Wei, Raiman, Jonathan, and Zhou, Yanqi. Deep voice 2: Multi-speaker neural text-to-speech. In NIPS, pp. 2966\u20132974, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gibiansky%2C%20Andrew%20Arik%2C%20Sercan%20Diamos%2C%20Gregory%20Miller%2C%20John%20Deep%20voice%202%3A%20Multi-speaker%20neural%20text-to-speech%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gibiansky%2C%20Andrew%20Arik%2C%20Sercan%20Diamos%2C%20Gregory%20Miller%2C%20John%20Deep%20voice%202%3A%20Multi-speaker%20neural%20text-to-speech%202017"
        },
        {
            "id": "13",
            "entry": "[13] Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua. Generative adversarial nets. In NIPS, pp. 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "14",
            "entry": "[14] Goodfellow, Ian, Bengio, Yoshua, Courville, Aaron, and Bengio, Yoshua. Deep learning, volume 1. MIT press Cambridge, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Bengio%2C%20Yoshua%20Deep%20learning%2C%20volume%201%202016"
        },
        {
            "id": "15",
            "entry": "[15] Gulrajani, Ishaan, Ahmed, Faruk, Arjovsky, Martin, Dumoulin, Vincent, and Courville, Aaron C. Improved training of wasserstein GANs. In NIPS, pp. 5769\u20135779, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20GANs%202017"
        },
        {
            "id": "16",
            "entry": "[16] Heusel, Martin, Ramsauer, Hubert, Unterthiner, Thomas, Nessler, Bernhard, and Hochreiter, Sepp. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In NIPS, pp. 6626\u20136637, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20Gans%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20nash%20equilibrium%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20Gans%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20nash%20equilibrium%202017"
        },
        {
            "id": "17",
            "entry": "[17] Huang, Huaibo, He, Ran, Sun, Zhenan, and Tan, Tieniu. Wavelet-srnet: A wavelet-based cnn for multi-scale face super resolution. In ICCV, pp. 1689\u20131697, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Huaibo%20He%2C%20Ran%20Sun%2C%20Zhenan%20Tan%2C%20Tieniu%20Wavelet-srnet%3A%20A%20wavelet-based%20cnn%20for%20multi-scale%20face%20super%20resolution%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Huaibo%20He%2C%20Ran%20Sun%2C%20Zhenan%20Tan%2C%20Tieniu%20Wavelet-srnet%3A%20A%20wavelet-based%20cnn%20for%20multi-scale%20face%20super%20resolution%202017"
        },
        {
            "id": "18",
            "entry": "[18] Karras, Tero, Aila, Timo, Laine, Samuli, and Lehtinen, Jaakko. Progressive growing of GANs for improved quality, stability, and variation. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018"
        },
        {
            "id": "19",
            "entry": "[19] Kingma, Diederik and Ba, Jimmy. Adam: A method for stochastic optimization. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014"
        },
        {
            "id": "20",
            "entry": "[20] Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "21",
            "entry": "[21] Kingma, Diederik P, Salimans, Tim, Jozefowicz, Rafal, Chen, Xi, Sutskever, Ilya, and Welling, Max. Improved variational inference with inverse autoregressive flow. In NIPS, pp. 4743\u20134751, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Salimans%2C%20Tim%20Jozefowicz%2C%20Rafal%20Chen%2C%20Xi%20Improved%20variational%20inference%20with%20inverse%20autoregressive%20flow%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Salimans%2C%20Tim%20Jozefowicz%2C%20Rafal%20Chen%2C%20Xi%20Improved%20variational%20inference%20with%20inverse%20autoregressive%20flow%202016"
        },
        {
            "id": "22",
            "entry": "[22] Lample, Guillaume, Zeghidour, Neil, Usunier, Nicolas, Bordes, Antoine, Denoyer, Ludovic, et al. Fader networks: Manipulating images by sliding attributes. In NIPS, pp. 5969\u20135978, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20Guillaume%20Zeghidour%2C%20Neil%20Usunier%2C%20Nicolas%20Bordes%2C%20Antoine%20Fader%20networks%3A%20Manipulating%20images%20by%20sliding%20attributes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lample%2C%20Guillaume%20Zeghidour%2C%20Neil%20Usunier%2C%20Nicolas%20Bordes%2C%20Antoine%20Fader%20networks%3A%20Manipulating%20images%20by%20sliding%20attributes%202017"
        },
        {
            "id": "23",
            "entry": "[23] Larsen, Anders Boesen Lindbo, S\u00f8nderby, S\u00f8ren Kaae, Larochelle, Hugo, and Winther, Ole. Autoencoding beyond pixels using a learned similarity metric. In ICML, pp. 1558\u20131566, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Larsen%2C%20Anders%20Boesen%20Lindbo%20S%C3%B8nderby%2C%20S%C3%B8ren%20Kaae%20Larochelle%2C%20Hugo%20Winther%2C%20Ole%20Autoencoding%20beyond%20pixels%20using%20a%20learned%20similarity%20metric%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Larsen%2C%20Anders%20Boesen%20Lindbo%20S%C3%B8nderby%2C%20S%C3%B8ren%20Kaae%20Larochelle%2C%20Hugo%20Winther%2C%20Ole%20Autoencoding%20beyond%20pixels%20using%20a%20learned%20similarity%20metric%202016"
        },
        {
            "id": "24",
            "entry": "[24] Li, Yujia, Swersky, Kevin, and Zemel, Rich. Generative moment matching networks. In ICML, pp. 1718\u20131727, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Yujia%20Swersky%2C%20Kevin%20Zemel%2C%20Rich%20Generative%20moment%20matching%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Yujia%20Swersky%2C%20Kevin%20Zemel%2C%20Rich%20Generative%20moment%20matching%20networks%202015"
        },
        {
            "id": "25",
            "entry": "[25] Liu, Ming-Yu, Breuel, Thomas, and Kautz, Jan. Unsupervised image-to-image translation networks. In NIPS, pp. 700\u2013708, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "26",
            "entry": "[26] Liu, Ziwei, Luo, Ping, Wang, Xiaogang, and Tang, Xiaoou. Deep learning face attributes in the wild. In ICCV, pp. 3730\u20133738, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%202015"
        },
        {
            "id": "27",
            "entry": "[27] Ma, Liqian, Jia, Xu, Sun, Qianru, Schiele, Bernt, Tuytelaars, Tinne, and Van Gool, Luc. Pose guided person image generation. In NIPS, pp. 405\u2013415, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Liqian%20Jia%2C%20Xu%20Sun%2C%20Qianru%20Schiele%2C%20Bernt%20Pose%20guided%20person%20image%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Liqian%20Jia%2C%20Xu%20Sun%2C%20Qianru%20Schiele%2C%20Bernt%20Pose%20guided%20person%20image%20generation%202017"
        },
        {
            "id": "28",
            "entry": "[28] Makhzani, Alireza, Shlens, Jonathon, Jaitly, Navdeep, Goodfellow, Ian, and Frey, Brendan. Adversarial autoencoders. arXiv preprint arXiv:1511.05644, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05644"
        },
        {
            "id": "29",
            "entry": "[29] Nguyen, Tu, Le, Trung, Vu, Hung, and Phung, Dinh. Dual discriminator generative adversarial nets. In NIPS, pp. 2667\u20132677, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20Tu%20Le%2C%20Trung%20Vu%2C%20Hung%20Phung%2C%20Dinh%20Dual%20discriminator%20generative%20adversarial%20nets%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20Tu%20Le%2C%20Trung%20Vu%2C%20Hung%20Phung%2C%20Dinh%20Dual%20discriminator%20generative%20adversarial%20nets%202017"
        },
        {
            "id": "30",
            "entry": "[30] Odena, Augustus, Olah, Christopher, and Shlens, Jonathon. Conditional image synthesis with auxiliary classifier GANs. In ICML, pp. 2642\u20132651, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Odena%2C%20Augustus%20Olah%2C%20Christopher%20Shlens%2C%20Jonathon%20Conditional%20image%20synthesis%20with%20auxiliary%20classifier%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Odena%2C%20Augustus%20Olah%2C%20Christopher%20Shlens%2C%20Jonathon%20Conditional%20image%20synthesis%20with%20auxiliary%20classifier%20GANs%202017"
        },
        {
            "id": "31",
            "entry": "[31] Radford, Alec, Metz, Luke, and Chintala, Soumith. Unsupervised representation learning with deep convolutional generative adversarial networks. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "32",
            "entry": "[32] Rezende, Danilo Jimenez, Mohamed, Shakir, and Wierstra, Daan. Stochastic backpropagation and approximate inference in deep generative models. In ICML, pp. 1278\u20131286, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014"
        },
        {
            "id": "33",
            "entry": "[33] Salimans, Tim, Goodfellow, Ian, Zaremba, Wojciech, Cheung, Vicki, Radford, Alec, and Chen, Xi. Improved techniques for training GANs. In NIPS, pp. 2234\u20132242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20GANs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20GANs%202016"
        },
        {
            "id": "34",
            "entry": "[34] S\u00f8nderby, Casper Kaae, Raiko, Tapani, Maal\u00f8e, Lars, S\u00f8nderby, S\u00f8ren Kaae, and Winther, Ole. Ladder variational autoencoders. In NIPS, pp. 3738\u20133746, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=S%C3%B8nderby%2C%20Casper%20Kaae%20Raiko%2C%20Tapani%20Maal%C3%B8e%2C%20Lars%20S%C3%B8nderby%2C%20S%C3%B8ren%20Kaae%20Ladder%20variational%20autoencoders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=S%C3%B8nderby%2C%20Casper%20Kaae%20Raiko%2C%20Tapani%20Maal%C3%B8e%2C%20Lars%20S%C3%B8nderby%2C%20S%C3%B8ren%20Kaae%20Ladder%20variational%20autoencoders%202016"
        },
        {
            "id": "35",
            "entry": "[35] Srivastava, Akash, Valkoz, Lazar, Russell, Chris, Gutmann, Michael U, and Sutton, Charles. VEEGAN: Reducing mode collapse in gans using implicit variational learning. In NIPS, pp. 3310\u20133320, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Akash%20Valkoz%2C%20Lazar%20Russell%2C%20Chris%20Gutmann%2C%20Michael%20U.%20VEEGAN%3A%20Reducing%20mode%20collapse%20in%20gans%20using%20implicit%20variational%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Akash%20Valkoz%2C%20Lazar%20Russell%2C%20Chris%20Gutmann%2C%20Michael%20U.%20VEEGAN%3A%20Reducing%20mode%20collapse%20in%20gans%20using%20implicit%20variational%20learning%202017"
        },
        {
            "id": "36",
            "entry": "[36] Ulyanov, Dmitry, Vedaldi, Andrea, and Lempitsky, Victor. It takes (only) two: Adversarial generatorencoder networks. In AAAI, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ulyanov%2C%20Dmitry%20Vedaldi%2C%20Andrea%20Lempitsky%2C%20Victor%20It%20takes%20%28only%29%20two%3A%20Adversarial%20generatorencoder%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ulyanov%2C%20Dmitry%20Vedaldi%2C%20Andrea%20Lempitsky%2C%20Victor%20It%20takes%20%28only%29%20two%3A%20Adversarial%20generatorencoder%20networks%202018"
        },
        {
            "id": "37",
            "entry": "[37] van den Oord, Aaron, Kalchbrenner, Nal, Espeholt, Lasse, Vinyals, Oriol, Graves, Alex, et al. Conditional image generation with pixelcnn decoders. In NIPS, pp. 4790\u20134798, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20den%20Oord%20Aaron%2C%20Kalchbrenner%20Nal%2C%20Espeholt%20Lasse%2C%20Vinyals%20Conditional%20image%20generation%20with%20pixelcnn%20decoders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20den%20Oord%20Aaron%2C%20Kalchbrenner%20Nal%2C%20Espeholt%20Lasse%2C%20Vinyals%20Conditional%20image%20generation%20with%20pixelcnn%20decoders%202016"
        },
        {
            "id": "38",
            "entry": "[38] Van Oord, Aaron, Kalchbrenner, Nal, and Kavukcuoglu, Koray. Pixel recurrent neural networks. In ICML, pp. 1747\u20131756, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oord%2C%20Van%20Aaron%2C%20Kalchbrenner%20Nal%20Kavukcuoglu%2C%20Koray%20Pixel%20recurrent%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oord%2C%20Van%20Aaron%2C%20Kalchbrenner%20Nal%20Kavukcuoglu%2C%20Koray%20Pixel%20recurrent%20neural%20networks%202016"
        },
        {
            "id": "39",
            "entry": "[39] Wang, Ting-Chun, Liu, Ming-Yu, Zhu, Jun-Yan, Tao, Andrew, Kautz, Jan, and Catanzaro, Bryan. Highresolution image synthesis and semantic manipulation with conditional GANs. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Ting-Chun%20Liu%2C%20Ming-Yu%20Zhu%2C%20Jun-Yan%20Tao%2C%20Andrew%20Highresolution%20image%20synthesis%20and%20semantic%20manipulation%20with%20conditional%20GANs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Ting-Chun%20Liu%2C%20Ming-Yu%20Zhu%2C%20Jun-Yan%20Tao%2C%20Andrew%20Highresolution%20image%20synthesis%20and%20semantic%20manipulation%20with%20conditional%20GANs%202018"
        },
        {
            "id": "40",
            "entry": "[40] Yu, Fisher, Seff, Ari, Zhang, Yinda, Song, Shuran, Funkhouser, Thomas, and Xiao, Jianxiong. Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1506.03365"
        },
        {
            "id": "41",
            "entry": "[41] Zhang, Han, Xu, Tao, Li, Hongsheng, Zhang, Shaoting, Huang, Xiaolei, Wang, Xiaogang, and Metaxas, Dimitris. StackGAN: Text to photo-realistic image synthesis with stacked generative adversarial networks. In ICCV, pp. 5907\u20135915, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Han%20Xu%2C%20Tao%20Li%2C%20Hongsheng%20Zhang%2C%20Shaoting%20StackGAN%3A%20Text%20to%20photo-realistic%20image%20synthesis%20with%20stacked%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Han%20Xu%2C%20Tao%20Li%2C%20Hongsheng%20Zhang%2C%20Shaoting%20StackGAN%3A%20Text%20to%20photo-realistic%20image%20synthesis%20with%20stacked%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "42",
            "entry": "[42] Zhang, Han, Xu, Tao, Li, Hongsheng, Zhang, Shaoting, Wang, Xiaogang, Huang, Xiaolei, and Metaxas, Dimitris. StackGAN++: Realistic image synthesis with stacked generative adversarial networks. arXiv preprint arXiv:1710.10916v2, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10916v2"
        },
        {
            "id": "43",
            "entry": "[43] Zhang, Zizhao, Xie, Yuanpu, and Yang, Lin. Photographic text-to-image synthesis with a hierarchicallynested adversarial network. arXiv preprint arXiv:1802.09178, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.09178"
        },
        {
            "id": "44",
            "entry": "[44] Zhao, Junbo, Mathieu, Michael, and LeCun, Yann. Energy-based generative adversarial network. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Junbo%20Mathieu%2C%20Michael%20LeCun%2C%20Yann%20Energy-based%20generative%20adversarial%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Junbo%20Mathieu%2C%20Michael%20LeCun%2C%20Yann%20Energy-based%20generative%20adversarial%20network%202017"
        },
        {
            "id": "45",
            "entry": "[45] Zhao, Shengjia, Song, Jiaming, and Ermon, Stefano. InfoVAE: Information maximizing variational autoencoders. arXiv preprint arXiv:1706.02262, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.02262"
        },
        {
            "id": "46",
            "entry": "[46] Zhu, Jun-Yan, Zhang, Richard, Pathak, Deepak, Darrell, Trevor, Efros, Alexei A, Wang, Oliver, and Shechtman, Eli. Toward multimodal image-to-image translation. In NIPS, pp. 465\u2013476, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Zhang%2C%20Richard%20Pathak%2C%20Deepak%20Darrell%2C%20Trevor%20Toward%20multimodal%20image-to-image%20translation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Zhang%2C%20Richard%20Pathak%2C%20Deepak%20Darrell%2C%20Trevor%20Toward%20multimodal%20image-to-image%20translation%202017"
        }
    ]
}
