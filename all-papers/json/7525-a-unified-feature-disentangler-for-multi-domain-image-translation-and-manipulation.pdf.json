{
    "filename": "7525-a-unified-feature-disentangler-for-multi-domain-image-translation-and-manipulation.pdf",
    "metadata": {
        "title": "A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation",
        "author": "Alexander H. Liu, Yen-Cheng Liu, Yu-Ying Yeh, Yu-Chiang Frank Wang",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7525-a-unified-feature-disentangler-for-multi-domain-image-translation-and-manipulation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We present a novel and unified deep learning framework which is capable of learning domain-invariant representation from data across multiple domains. Realized by adversarial training with additional ability to exploit domain-specific information, the proposed network is able to perform continuous cross-domain image translation and manipulation, and produces desirable output images accordingly. In addition, the resulting feature representation exhibits superior performance of unsupervised domain adaptation, which also verifies the effectiveness of the proposed model in learning disentangled features for describing cross-domain data."
    },
    "keywords": [
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "image translation",
            "url": "https://en.wikipedia.org/wiki/image_translation"
        },
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        }
    ],
    "highlights": [
        "Learning interpretable feature representation has been an active research topic in the fields of computer vision and machine learning",
        "To perform joint feature disentanglement and translation across multiple data domains, we propose a compact yet effective model of Unified Feature Disentanglement Network (UFDN), which is composed of a pair of unified encoder and generator as shown in Figure 1",
        "We propose a Unified Feature Disentanglement Network (UFDN), which learns deep disentangled feature representation for multi-domain image translation and manipulation",
        "We present a unique and unified network architecture, Unified Feature Disentanglement Network (UFDN), which disentangles the domain information from latent space and derives domain-invariant representation from data across multiple domains",
        "We proposed a novel network architecture of unified feature disentanglement network (UFDN), which learns disentangled feature representation for data across multiple domains by a unique encodergenerator architecture with adversarial learning",
        "With superior properties over recent image translation works, our model not only produced promising qualitative results but allows unsupervised domain adaptation, which confirmed the effectiveness of the derived deep features in the above tasks"
    ],
    "key_statements": [
        "Learning interpretable feature representation has been an active research topic in the fields of computer vision and machine learning",
        "To perform joint feature disentanglement and translation across multiple data domains, we propose a compact yet effective model of Unified Feature Disentanglement Network (UFDN), which is composed of a pair of unified encoder and generator as shown in Figure 1",
        "It can be seen that our encoder takes data instances from multiple domains as inputs, and a domain-invariant latent feature space is derived via adversarial training, followed by a generator/decoder which recovers or translates data across domains",
        "We propose a Unified Feature Disentanglement Network (UFDN), which learns deep disentangled feature representation for multi-domain image translation and manipulation",
        "We present a unique and unified network architecture, Unified Feature Disentanglement Network (UFDN), which disentangles the domain information from latent space and derives domain-invariant representation from data across multiple domains",
        "While the above two datasets are handwritten digits, Street View House Number consists of digit images with the complex background and various illuminations",
        "We proposed a novel network architecture of unified feature disentanglement network (UFDN), which learns disentangled feature representation for data across multiple domains by a unique encodergenerator architecture with adversarial learning",
        "With superior properties over recent image translation works, our model not only produced promising qualitative results but allows unsupervised domain adaptation, which confirmed the effectiveness of the derived deep features in the above tasks"
    ],
    "summary": [
        "Learning interpretable feature representation has been an active research topic in the fields of computer vision and machine learning.",
        "It can be seen that our encoder takes data instances from multiple domains as inputs, and a domain-invariant latent feature space is derived via adversarial training, followed by a generator/decoder which recovers or translates data across domains.",
        "We propose a Unified Feature Disentanglement Network (UFDN), which learns deep disentangled feature representation for multi-domain image translation and manipulation.",
        "Our UFDN views both data domains and image attributes of interest as latent factors to be disentangled, wich realizes multi-domain image translation in a single unified framework.",
        "Continuous multi-domain image translation and manipulation can be performed using our UFDN, while the disentangled feature representation shows promising ability in crossdomain classification tasks.",
        "Choi et al [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>] recently proposed an unified model to achieve multi-domain image-to-image translation, their model does not exhibit ability in learning and disentangling desirable latent representations.",
        "1, our UFDN learns the multi-domain disentangled representation, which enables multi-domain image-to-image translation and manipulation and unsupervised domain adaption.",
        "We present a unique and unified network architecture, Unified Feature Disentanglement Network (UFDN), which disentangles the domain information from latent space and derives domain-invariant representation from data across multiple domains.",
        "This not only enables the task of multi-domain image translation/manipulation, the derived feature representation can be applied for unsupervised domain adaptation.",
        "Given image sets {Xc}cN=1 across N domains, our UFDN learns a domain-invariant representation z for the input image xc \u2208 Xc. This is realized by disentangling the domain information in the latent space as domain vector v \u2208 RN via self-supervised feature disentanglement (Sect.",
        "Without the need of pairwise training data, CycleGAN [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] learns bidirectional mapping between two pixel spaces, while they needed to learn the multiple individual networks for the task of multi-domain image translation.",
        "It is worth repeating that our UFDN does not require pairwise training data for learning multi-domain disentangled feature representation.",
        "As verified later in the experiments, our model not only enables multi-domain image-to-image translation and manipulation, the derived domain-invariant feature further allows unsupervised domain adaptation.",
        "Recent works [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] addressed the problem by using classifier with highlevel layers tied across domain and synthesized training data provided by image-to-image translation.",
        "With superior properties over recent image translation works, our model not only produced promising qualitative results but allows unsupervised domain adaptation, which confirmed the effectiveness of the derived deep features in the above tasks."
    ],
    "headline": "We present a novel and unified deep learning framework which is capable of learning domain-invariant representation from data across multiple domains",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 35(8):1798\u20131828, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Y.%20Courville%2C%20A.%20Vincent%2C%20P.%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Y.%20Courville%2C%20A.%20Vincent%2C%20P.%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013"
        },
        {
            "id": "2",
            "entry": "[2] K. Bousmalis, G. Trigeorgis, N. Silberman, D. Krishnan, and D. Erhan. Domain separation networks. In Advances in Neural Information Processing Systems (NIPS), pages 343\u2013351, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20K.%20Trigeorgis%2C%20G.%20Silberman%2C%20N.%20Krishnan%2C%20D.%20Domain%20separation%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20K.%20Trigeorgis%2C%20G.%20Silberman%2C%20N.%20Krishnan%2C%20D.%20Domain%20separation%20networks%202016"
        },
        {
            "id": "3",
            "entry": "[3] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems (NIPS), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "4",
            "entry": "[4] Y. Choi, M. Choi, M. Kim, J.-W. Ha, S. Kim, and J. Choo. Stargan: Unified generative adversarial networks for multi-domain image-to-image translation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Y.%20Choi%2C%20M.%20Kim%2C%20M.%20Ha%2C%20J.-W.%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Y.%20Choi%2C%20M.%20Kim%2C%20M.%20Ha%2C%20J.-W.%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018"
        },
        {
            "id": "5",
            "entry": "[5] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fernando%2C%20B.%20Habrard%2C%20A.%20Sebban%2C%20M.%20Tuytelaars%2C%20T.%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fernando%2C%20B.%20Habrard%2C%20A.%20Sebban%2C%20M.%20Tuytelaars%2C%20T.%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013"
        },
        {
            "id": "6",
            "entry": "[6] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. In Proceedings of the International Conference on Machine Learning (ICML), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Y.%20Lempitsky%2C%20V.%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Y.%20Lempitsky%2C%20V.%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015"
        },
        {
            "id": "7",
            "entry": "[7] M. Ghifary, W. B. Kleijn, M. Zhang, D. Balduzzi, and W. Li. Deep reconstruction-classification networks for unsupervised domain adaptation. In Proceedings of the European Conference on Computer Vision (ECCV), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghifary%2C%20M.%20Kleijn%2C%20W.B.%20Zhang%2C%20M.%20Balduzzi%2C%20D.%20Deep%20reconstruction-classification%20networks%20for%20unsupervised%20domain%20adaptation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghifary%2C%20M.%20Kleijn%2C%20W.B.%20Zhang%2C%20M.%20Balduzzi%2C%20D.%20Deep%20reconstruction-classification%20networks%20for%20unsupervised%20domain%20adaptation%202016"
        },
        {
            "id": "8",
            "entry": "[8] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems (NIPS), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "9",
            "entry": "[9] I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20I.%20Matthey%2C%20L.%20Pal%2C%20A.%20Burgess%2C%20C.%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20I.%20Matthey%2C%20L.%20Pal%2C%20A.%20Burgess%2C%20C.%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017"
        },
        {
            "id": "10",
            "entry": "[10] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros. Image-to-image translation with conditional adversarial networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20P.%20Zhu%2C%20J.-Y.%20Zhou%2C%20T.%20Efros%2C%20A.A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20P.%20Zhu%2C%20J.-Y.%20Zhou%2C%20T.%20Efros%2C%20A.A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "11",
            "entry": "[11] T. Kim, M. Cha, H. Kim, J. Lee, and J. Kim. Learning to discover cross-domain relations with generative adversarial networks. In Proceedings of the International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20T.%20Cha%2C%20M.%20Kim%2C%20H.%20Lee%2C%20J.%20Learning%20to%20discover%20cross-domain%20relations%20with%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20T.%20Cha%2C%20M.%20Kim%2C%20H.%20Lee%2C%20J.%20Learning%20to%20discover%20cross-domain%20relations%20with%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "12",
            "entry": "[12] D. P. Kingma, S. Mohamed, D. J. Rezende, and M. Welling. Semi-supervised learning with deep generative models. In Advances in Neural Information Processing Systems (NIPS), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Mohamed%2C%20S.%20Rezende%2C%20D.J.%20Welling%2C%20M.%20Semi-supervised%20learning%20with%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20D.P.%20Mohamed%2C%20S.%20Rezende%2C%20D.J.%20Welling%2C%20M.%20Semi-supervised%20learning%20with%20deep%20generative%20models%202014"
        },
        {
            "id": "13",
            "entry": "[13] D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "14",
            "entry": "[14] T. D. Kulkarni, W. F. Whitney, P. Kohli, and J. Tenenbaum. Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems (NIPS), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20T.D.%20Whitney%2C%20W.F.%20Kohli%2C%20P.%20Tenenbaum%2C%20J.%20Deep%20convolutional%20inverse%20graphics%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20T.D.%20Whitney%2C%20W.F.%20Kohli%2C%20P.%20Tenenbaum%2C%20J.%20Deep%20convolutional%20inverse%20graphics%20network%202015"
        },
        {
            "id": "15",
            "entry": "[15] G. Lample, N. Zeghidour, N. Usunier, A. Bordes, L. Denoyer, et al. Fader networks: Manipulating images by sliding attributes. In Advances in Neural Information Processing Systems (NIPS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20G.%20Zeghidour%2C%20N.%20Usunier%2C%20N.%20Bordes%2C%20A.%20Fader%20networks%3A%20Manipulating%20images%20by%20sliding%20attributes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lample%2C%20G.%20Zeghidour%2C%20N.%20Usunier%2C%20N.%20Bordes%2C%20A.%20Fader%20networks%3A%20Manipulating%20images%20by%20sliding%20attributes%202017"
        },
        {
            "id": "16",
            "entry": "[16] M.-Y. Liu, T. Breuel, and J. Kautz. Unsupervised image-to-image translation networks. In Advances in Neural Information Processing Systems (NIPS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "17",
            "entry": "[17] M.-Y. Liu and O. Tuzel. Coupled generative adversarial networks. In Advances in Neural Information Processing Systems (NIPS), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Tuzel%2C%20O.%20Coupled%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Tuzel%2C%20O.%20Coupled%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "18",
            "entry": "[18] Y.-C. Liu, Y.-Y. Yeh, T.-C. Fu, W.-C. Chiu, S.-D. Wang, and Y.-C. F. Wang. Detach and adapt: Learning cross-domain disentangled deep representation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.-C.%20Yeh%2C%20Y.-Y.%20Fu%2C%20T.-C.%20Chiu%2C%20W.-C.%20Detach%20and%20adapt%3A%20Learning%20cross-domain%20disentangled%20deep%20representation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.-C.%20Yeh%2C%20Y.-Y.%20Fu%2C%20T.-C.%20Chiu%2C%20W.-C.%20Detach%20and%20adapt%3A%20Learning%20cross-domain%20disentangled%20deep%20representation%202018"
        },
        {
            "id": "19",
            "entry": "[19] Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "20",
            "entry": "[20] A. Odena, C. Olah, and J. Shlens. Conditional image synthesis with auxiliary classifier gans. In Proceedings of the International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Odena%2C%20A.%20Olah%2C%20C.%20Shlens%2C%20J.%20Conditional%20image%20synthesis%20with%20auxiliary%20classifier%20gans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Odena%2C%20A.%20Olah%2C%20C.%20Shlens%2C%20J.%20Conditional%20image%20synthesis%20with%20auxiliary%20classifier%20gans%202017"
        },
        {
            "id": "21",
            "entry": "[21] A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "22",
            "entry": "[22] D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In Proceedings of the International Conference on Machine Learning (ICML), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rezende%2C%20D.J.%20Mohamed%2C%20S.%20Wierstra%2C%20D.%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rezende%2C%20D.J.%20Mohamed%2C%20S.%20Wierstra%2C%20D.%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014"
        },
        {
            "id": "23",
            "entry": "[23] S. Sankaranarayanan, Y. Balaji, C. D. Castillo, and R. Chellappa. Generate to adapt: Aligning domains using generative adversarial networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sankaranarayanan%2C%20S.%20Balaji%2C%20Y.%20Castillo%2C%20C.D.%20Chellappa%2C%20R.%20Generate%20to%20adapt%3A%20Aligning%20domains%20using%20generative%20adversarial%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sankaranarayanan%2C%20S.%20Balaji%2C%20Y.%20Castillo%2C%20C.D.%20Chellappa%2C%20R.%20Generate%20to%20adapt%3A%20Aligning%20domains%20using%20generative%20adversarial%20networks%202018"
        },
        {
            "id": "24",
            "entry": "[24] Y. Taigman, A. Polyak, and L. Wolf. Unsupervised cross-domain image generation. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Taigman%2C%20Y.%20Polyak%2C%20A.%20Wolf%2C%20L.%20Unsupervised%20cross-domain%20image%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Taigman%2C%20Y.%20Polyak%2C%20A.%20Wolf%2C%20L.%20Unsupervised%20cross-domain%20image%20generation%202017"
        },
        {
            "id": "25",
            "entry": "[25] L. Tran, X. Yin, and X. Liu. Disentangled representation learning gan for pose-invariant face recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tran%2C%20L.%20Yin%2C%20X.%20Liu%2C%20X.%20Disentangled%20representation%20learning%20gan%20for%20pose-invariant%20face%20recognition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tran%2C%20L.%20Yin%2C%20X.%20Liu%2C%20X.%20Disentangled%20representation%20learning%20gan%20for%20pose-invariant%20face%20recognition%202017"
        },
        {
            "id": "26",
            "entry": "[26] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015"
        },
        {
            "id": "27",
            "entry": "[27] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017"
        },
        {
            "id": "28",
            "entry": "[28] Z. Yi, H. Zhang, P. Tan, and M. Gong. Dualgan: Unsupervised dual learning for image-to-image translation. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yi%2C%20Z.%20Zhang%2C%20H.%20Tan%2C%20P.%20Gong%2C%20M.%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-to-image%20translation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yi%2C%20Z.%20Zhang%2C%20H.%20Tan%2C%20P.%20Gong%2C%20M.%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-to-image%20translation%202017"
        },
        {
            "id": "29",
            "entry": "[29] S. Zhao, J. Song, and S. Ermon. Towards deeper understanding of variational autoencoding models. In Proceedings of the International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20S.%20Song%2C%20J.%20Ermon%2C%20S.%20Towards%20deeper%20understanding%20of%20variational%20autoencoding%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20S.%20Song%2C%20J.%20Ermon%2C%20S.%20Towards%20deeper%20understanding%20of%20variational%20autoencoding%20models%202017"
        },
        {
            "id": "30",
            "entry": "[30] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017"
        }
    ]
}
