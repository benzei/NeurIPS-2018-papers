{
    "filename": "7986-diffusion-maps-for-textual-network-embedding.pdf",
    "metadata": {
        "title": "Diffusion Maps for Textual Network Embedding",
        "author": "Xinyuan Zhang, Yitong Li, Dinghan Shen, Lawrence Carin",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7986-diffusion-maps-for-textual-network-embedding.pdf"
        },
        "abstract": "Textual network embedding leverages rich text information associated with the network to learn low-dimensional vectorial representations of vertices. Rather than using typical natural language processing (NLP) approaches, recent research exploits the relationship of texts on the same edge to graphically embed text. However, these models neglect to measure the complete level of connectivity between any two texts in the graph. We present diffusion maps for textual network embedding (DMTE), integrating global structural information of the graph to capture the semantic relatedness between texts, with a diffusion-convolution operation applied on the text inputs. In addition, a new objective function is designed to efficiently preserve the high-order proximity using the graph diffusion. Experimental results show that the proposed approach outperforms state-of-the-art methods on the vertex-classification and link-prediction tasks."
    },
    "keywords": [
        {
            "term": "nonlinear dimensionality reduction",
            "url": "https://en.wikipedia.org/wiki/nonlinear_dimensionality_reduction"
        },
        {
            "term": "semantic relatedness",
            "url": "https://en.wikipedia.org/wiki/semantic_relatedness"
        },
        {
            "term": "natural language processing",
            "url": "https://en.wikipedia.org/wiki/natural_language_processing"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_networks"
        },
        {
            "term": "diffusion map",
            "url": "https://en.wikipedia.org/wiki/diffusion_map"
        }
    ],
    "highlights": [
        "Learning effective vectorial embeddings to represent text can lead to improvements in many natural language processing (NLP) tasks",
        "We propose a flexible approach for textual network embedding, including global structural information without increasing model complexity",
        "Evaluation and Parameter Settings For link prediction, we evaluate the performance with Area Under the Curve, which is widely used for a ranking list",
        "We have proposed a new DMTE model for textual network embedding",
        "That neglect semantic relatedness between texts or only exploit local pairwise relationship, the proposed method integrates global structural information of the graph to capture the level of connectivity between any two texts, by applying a diffusion convolutional operation on the text inputs",
        "We conducted experiments on three real-word networks for multi-label classification and link prediction, and the associated results demonstrate the superiority of the proposed DMTE model"
    ],
    "key_statements": [
        "Learning effective vectorial embeddings to represent text can lead to improvements in many natural language processing (NLP) tasks",
        "We propose a flexible approach for textual network embedding, including global structural information without increasing model complexity",
        "To demonstrate the effectiveness of our model, we focus on two common tasks in analysis of textual information networks: (i) multi-label classification, where we predict the labels of each text; and link prediction, where we predict the existence of an edge given a pair of vertices",
        "The superiority of the proposed approach indicates that the diffusion process helps to incorporate long-distance relationship between texts and to achieve more informative textual network embeddings.\n2 Related Work",
        "Evaluation and Parameter Settings For link prediction, we evaluate the performance with Area Under the Curve, which is widely used for a ranking list",
        "DMTE with only the word-embedding average as the text representation has comparable performance over baselines, demonstrating the effectiveness of the redesigned objective function, which calculates the conditional probability of generating vi given the diffusion map of vj",
        "We have proposed a new DMTE model for textual network embedding",
        "That neglect semantic relatedness between texts or only exploit local pairwise relationship, the proposed method integrates global structural information of the graph to capture the level of connectivity between any two texts, by applying a diffusion convolutional operation on the text inputs",
        "We conducted experiments on three real-word networks for multi-label classification and link prediction, and the associated results demonstrate the superiority of the proposed DMTE model"
    ],
    "summary": [
        "Learning effective vectorial embeddings to represent text can lead to improvements in many natural language processing (NLP) tasks.",
        "The learned representations containing structure and textual information can be used as features for network tasks, such as vertex classification [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>], link prediction [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>], and tag recommendation [<a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>].",
        "We propose a flexible approach for textual network embedding, including global structural information without increasing model complexity.",
        "To demonstrate the effectiveness of our model, we focus on two common tasks in analysis of textual information networks: (i) multi-label classification, where we predict the labels of each text; and link prediction, where we predict the existence of an edge given a pair of vertices.",
        "The superiority of the proposed approach indicates that the diffusion process helps to incorporate long-distance relationship between texts and to achieve more informative textual network embeddings.",
        "We employ a diffusion process to build long-distance semantic relatedness in text embeddings, and global structural information in the objective function.",
        "Information perform better than those only utilizes structure information, which indicates that text associated with each vertex helps to achieve more informative embeddings.",
        "For larger networks like Zhihu with high training data ratios, deep models with more parameters can be a good choice to encode input texts.",
        "DMTE with only the word-embedding average as the text representation has comparable performance over baselines, demonstrating the effectiveness of the redesigned objective function, which calculates the conditional probability of generating vi given the diffusion map of vj.",
        "The proposed DMTE model consistently achieves performance improvement at all training ratios, demonstrating that DMTE learns high-quality embeddings which can be used directly as features for multi-label vertex classification.",
        "5.3 Case Study To visualize the effectiveness of the learned embeddings, we retrieve the most similar vertices and their corresponding texts for a given query vertex.",
        "Direct neighbors vertices 1 and 2 are not only structurally but textually similar to the query vertex with multiple words aligned such as tree, index and multi-dimensional.",
        "This is an illustration that the embeddings learned by DMTE successfully incorporate both structure and text information, helping to explain the quality of the aforementioned results.",
        "That neglect semantic relatedness between texts or only exploit local pairwise relationship, the proposed method integrates global structural information of the graph to capture the level of connectivity between any two texts, by applying a diffusion convolutional operation on the text inputs.",
        "We conducted experiments on three real-word networks for multi-label classification and link prediction, and the associated results demonstrate the superiority of the proposed DMTE model.",
        "This research was supported in part by DARPA, DOE, NIH, ONR and NSF"
    ],
    "headline": "We present diffusion maps for textual network embedding , integrating global structural information of the graph to capture the semantic relatedness between texts, with a diffusion-convolution operation applied on the text inputs",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] E. Abrahamson and L. Rosenkopf. Social network effects on the extent of innovation diffusion: A computer simulation. Organization science, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abrahamson%2C%20E.%20Rosenkopf%2C%20L.%20Social%20network%20effects%20on%20the%20extent%20of%20innovation%20diffusion%3A%20A%20computer%20simulation%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abrahamson%2C%20E.%20Rosenkopf%2C%20L.%20Social%20network%20effects%20on%20the%20extent%20of%20innovation%20diffusion%3A%20A%20computer%20simulation%201997"
        },
        {
            "id": "2",
            "entry": "[2] J. Atwood and D. Towsley. Diffusion-convolutional neural networks. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Atwood%2C%20J.%20Towsley%2C%20D.%20Diffusion-convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Atwood%2C%20J.%20Towsley%2C%20D.%20Diffusion-convolutional%20neural%20networks%202016"
        },
        {
            "id": "3",
            "entry": "[3] M. Belkin and P. Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in neural information processing systems, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belkin%2C%20M.%20Niyogi%2C%20P.%20Laplacian%20eigenmaps%20and%20spectral%20techniques%20for%20embedding%20and%20clustering%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belkin%2C%20M.%20Niyogi%2C%20P.%20Laplacian%20eigenmaps%20and%20spectral%20techniques%20for%20embedding%20and%20clustering%202002"
        },
        {
            "id": "4",
            "entry": "[4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of machine Learning research, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blei%2C%20D.M.%20Ng%2C%20A.Y.%20Jordan%2C%20M.I.%20Latent%20dirichlet%20allocation%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blei%2C%20D.M.%20Ng%2C%20A.Y.%20Jordan%2C%20M.I.%20Latent%20dirichlet%20allocation%202003"
        },
        {
            "id": "5",
            "entry": "[5] S. Cao, W. Lu, and Q. Xu. Grarep: Learning graph representations with global structural information. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20S.%20Lu%2C%20W.%20Xu%2C%20Q.%20Grarep%3A%20Learning%20graph%20representations%20with%20global%20structural%20information%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20S.%20Lu%2C%20W.%20Xu%2C%20Q.%20Grarep%3A%20Learning%20graph%20representations%20with%20global%20structural%20information%202015"
        },
        {
            "id": "6",
            "entry": "[6] Z. Gan, Y. Pu, R. Henao, C. Li, X. He, and L. Carin. Learning generic sentence representations using convolutional neural networks. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gan%2C%20Z.%20Pu%2C%20Y.%20Henao%2C%20R.%20Li%2C%20C.%20Learning%20generic%20sentence%20representations%20using%20convolutional%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gan%2C%20Z.%20Pu%2C%20Y.%20Henao%2C%20R.%20Li%2C%20C.%20Learning%20generic%20sentence%20representations%20using%20convolutional%20neural%20networks%202017"
        },
        {
            "id": "7",
            "entry": "[7] A. Graves, N. Jaitly, and A.-r. Mohamed. Hybrid speech recognition with deep bidirectional lstm. In Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A%20Graves%20N%20Jaitly%20and%20Ar%20Mohamed%20Hybrid%20speech%20recognition%20with%20deep%20bidirectional%20lstm%20In%20Automatic%20Speech%20Recognition%20and%20Understanding%20ASRU%202013%20IEEE%20Workshop%20on%20IEEE%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A%20Graves%20N%20Jaitly%20and%20Ar%20Mohamed%20Hybrid%20speech%20recognition%20with%20deep%20bidirectional%20lstm%20In%20Automatic%20Speech%20Recognition%20and%20Understanding%20ASRU%202013%20IEEE%20Workshop%20on%20IEEE%202013"
        },
        {
            "id": "8",
            "entry": "[8] A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grover%2C%20A.%20Leskovec%2C%20J.%20node2vec%3A%20Scalable%20feature%20learning%20for%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grover%2C%20A.%20Leskovec%2C%20J.%20node2vec%3A%20Scalable%20feature%20learning%20for%20networks%202016"
        },
        {
            "id": "9",
            "entry": "[9] M. Iyyer, V. Manjunatha, J. Boyd-Graber, and H. Daum\u00e9 III. Deep unordered composition rivals syntactic methods for text classification. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), volume 1, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iyyer%2C%20M.%20Manjunatha%2C%20V.%20Boyd-Graber%2C%20J.%20Daum%C3%A9%2C%20III%2C%20H.%20Deep%20unordered%20composition%20rivals%20syntactic%20methods%20for%20text%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Iyyer%2C%20M.%20Manjunatha%2C%20V.%20Boyd-Graber%2C%20J.%20Daum%C3%A9%2C%20III%2C%20H.%20Deep%20unordered%20composition%20rivals%20syntactic%20methods%20for%20text%20classification%202015"
        },
        {
            "id": "10",
            "entry": "[10] N. Kalchbrenner, E. Grefenstette, and P. Blunsom. A convolutional neural network for modelling sentences. arXiv preprint arXiv:1404.2188, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1404.2188"
        },
        {
            "id": "11",
            "entry": "[11] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "12",
            "entry": "[12] R. Kiros, Y. Zhu, R. R. Salakhutdinov, R. Zemel, R. Urtasun, A. Torralba, and S. Fidler. Skip-thought vectors. In Advances in neural information processing systems, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kiros%2C%20R.%20Zhu%2C%20Y.%20Salakhutdinov%2C%20R.R.%20Zemel%2C%20R.%20Skip-thought%20vectors%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kiros%2C%20R.%20Zhu%2C%20Y.%20Salakhutdinov%2C%20R.R.%20Zemel%2C%20R.%20Skip-thought%20vectors%202015"
        },
        {
            "id": "13",
            "entry": "[13] Q. Le and T. Mikolov. Distributed representations of sentences and documents. In International Conference on Machine Learning, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Le%2C%20Q.%20Mikolov%2C%20T.%20Distributed%20representations%20of%20sentences%20and%20documents%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Le%2C%20Q.%20Mikolov%2C%20T.%20Distributed%20representations%20of%20sentences%20and%20documents%202014"
        },
        {
            "id": "14",
            "entry": "[14] L. L\u00fc and T. Zhou. Link prediction in complex networks: A survey. Physica A: statistical mechanics and its applications, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=L%C3%BC%2C%20L.%20Zhou%2C%20T.%20Link%20prediction%20in%20complex%20networks%3A%20A%20survey%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=L%C3%BC%2C%20L.%20Zhou%2C%20T.%20Link%20prediction%20in%20complex%20networks%3A%20A%20survey%202011"
        },
        {
            "id": "15",
            "entry": "[15] A. K. McCallum, K. Nigam, J. Rennie, and K. Seymore. Automating the construction of internet portals with machine learning. Information Retrieval, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McCallum%2C%20A.K.%20Nigam%2C%20K.%20Rennie%2C%20J.%20Seymore%2C%20K.%20Automating%20the%20construction%20of%20internet%20portals%20with%20machine%20learning%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McCallum%2C%20A.K.%20Nigam%2C%20K.%20Rennie%2C%20J.%20Seymore%2C%20K.%20Automating%20the%20construction%20of%20internet%20portals%20with%20machine%20learning%202000"
        },
        {
            "id": "16",
            "entry": "[16] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1301.3781"
        },
        {
            "id": "17",
            "entry": "[17] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20T.%20Sutskever%2C%20I.%20Chen%2C%20K.%20Corrado%2C%20G.S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mikolov%2C%20T.%20Sutskever%2C%20I.%20Chen%2C%20K.%20Corrado%2C%20G.S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013"
        },
        {
            "id": "18",
            "entry": "[18] J. Mitchell and M. Lapata. Composition in distributional models of semantics. Cognitive science, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mitchell%2C%20J.%20Lapata%2C%20M.%20Composition%20in%20distributional%20models%20of%20semantics%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mitchell%2C%20J.%20Lapata%2C%20M.%20Composition%20in%20distributional%20models%20of%20semantics%202010"
        },
        {
            "id": "19",
            "entry": "[19] S. Pan, J. Wu, X. Zhu, C. Zhang, and Y. Wang. Tri-party deep network representation. Network, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.%20Wu%2C%20J.%20Zhu%2C%20X.%20Zhang%2C%20C.%20Tri-party%20deep%20network%20representation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.%20Wu%2C%20J.%20Zhu%2C%20X.%20Zhang%2C%20C.%20Tri-party%20deep%20network%20representation%202016"
        },
        {
            "id": "20",
            "entry": "[20] B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perozzi%2C%20B.%20Al-Rfou%2C%20R.%20Skiena%2C%20S.%20Deepwalk%3A%20Online%20learning%20of%20social%20representations%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Perozzi%2C%20B.%20Al-Rfou%2C%20R.%20Skiena%2C%20S.%20Deepwalk%3A%20Online%20learning%20of%20social%20representations%202014"
        },
        {
            "id": "21",
            "entry": "[21] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by locally linear embedding. science, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roweis%2C%20S.T.%20Saul%2C%20L.K.%20Nonlinear%20dimensionality%20reduction%20by%20locally%20linear%20embedding%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roweis%2C%20S.T.%20Saul%2C%20L.K.%20Nonlinear%20dimensionality%20reduction%20by%20locally%20linear%20embedding%202000"
        },
        {
            "id": "22",
            "entry": "[22] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-Rad. Collective classification in network data. AI magazine, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sen%2C%20P.%20Namata%2C%20G.%20Bilgic%2C%20M.%20Getoor%2C%20L.%20Collective%20classification%20in%20network%20data%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sen%2C%20P.%20Namata%2C%20G.%20Bilgic%2C%20M.%20Getoor%2C%20L.%20Collective%20classification%20in%20network%20data%202008"
        },
        {
            "id": "23",
            "entry": "[23] D. Shen, G. Wang, W. Wang, M. Renqiang Min, Q. Su, Y. Zhang, C. Li, R. Henao, and L. Carin. Baseline needs more love: On simple word-embedding-based models and associated pooling mechanisms. In ACL, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shen%2C%20D.%20Wang%2C%20G.%20Wang%2C%20W.%20Min%2C%20M.Renqiang%20Baseline%20needs%20more%20love%3A%20On%20simple%20word-embedding-based%20models%20and%20associated%20pooling%20mechanisms%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shen%2C%20D.%20Wang%2C%20G.%20Wang%2C%20W.%20Min%2C%20M.Renqiang%20Baseline%20needs%20more%20love%3A%20On%20simple%20word-embedding-based%20models%20and%20associated%20pooling%20mechanisms%202018"
        },
        {
            "id": "24",
            "entry": "[24] D. Shen, X. Zhang, R. Henao, and L. Carin. Improved semantic-aware network embedding with fine-grained word alignment. arXiv preprint arXiv:1808.09633, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.09633"
        },
        {
            "id": "25",
            "entry": "[25] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical methods in natural language processing, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Socher%2C%20R.%20Perelygin%2C%20A.%20Wu%2C%20J.%20Chuang%2C%20J.%20Recursive%20deep%20models%20for%20semantic%20compositionality%20over%20a%20sentiment%20treebank%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Socher%2C%20R.%20Perelygin%2C%20A.%20Wu%2C%20J.%20Chuang%2C%20J.%20Recursive%20deep%20models%20for%20semantic%20compositionality%20over%20a%20sentiment%20treebank%202013"
        },
        {
            "id": "26",
            "entry": "[26] X. Sun, J. Guo, X. Ding, and T. Liu. A general framework for content-enhanced network representation learning. arXiv preprint arXiv:1610.02906, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.02906"
        },
        {
            "id": "27",
            "entry": "[27] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tang%2C%20J.%20Qu%2C%20M.%20Wang%2C%20M.%20Zhang%2C%20M.%20Line%3A%20Large-scale%20information%20network%20embedding%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tang%2C%20J.%20Qu%2C%20M.%20Wang%2C%20M.%20Zhang%2C%20M.%20Line%3A%20Large-scale%20information%20network%20embedding%202015"
        },
        {
            "id": "28",
            "entry": "[28] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. Arnetminer: extraction and mining of academic social networks. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tang%2C%20J.%20Zhang%2C%20J.%20Yao%2C%20L.%20Li%2C%20J.%20Arnetminer%3A%20extraction%20and%20mining%20of%20academic%20social%20networks%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tang%2C%20J.%20Zhang%2C%20J.%20Yao%2C%20L.%20Li%2C%20J.%20Arnetminer%3A%20extraction%20and%20mining%20of%20academic%20social%20networks%202008"
        },
        {
            "id": "29",
            "entry": "[29] J. B. Tenenbaum, V. De Silva, and J. C. Langford. A global geometric framework for nonlinear dimensionality reduction. science, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tenenbaum%2C%20J.B.%20Silva%2C%20V.De%20Langford%2C%20J.C.%20A%20global%20geometric%20framework%20for%20nonlinear%20dimensionality%20reduction%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tenenbaum%2C%20J.B.%20Silva%2C%20V.De%20Langford%2C%20J.C.%20A%20global%20geometric%20framework%20for%20nonlinear%20dimensionality%20reduction%202000"
        },
        {
            "id": "30",
            "entry": "[30] C. Tu, H. Liu, Z. Liu, and M. Sun. Cane: Context-aware network embedding for relation modeling. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tu%2C%20C.%20Liu%2C%20H.%20Liu%2C%20Z.%20Sun%2C%20M.%20Cane%3A%20Context-aware%20network%20embedding%20for%20relation%20modeling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tu%2C%20C.%20Liu%2C%20H.%20Liu%2C%20Z.%20Sun%2C%20M.%20Cane%3A%20Context-aware%20network%20embedding%20for%20relation%20modeling%202017"
        },
        {
            "id": "31",
            "entry": "[31] C. Tu, Z. Liu, and M. Sun. Inferring correspondences from multiple sources for microblog user tags. In Chinese National Conference on Social Media Processing. Springer, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tu%2C%20C.%20Liu%2C%20Z.%20Sun%2C%20M.%20Inferring%20correspondences%20from%20multiple%20sources%20for%20microblog%20user%20tags%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tu%2C%20C.%20Liu%2C%20Z.%20Sun%2C%20M.%20Inferring%20correspondences%20from%20multiple%20sources%20for%20microblog%20user%20tags%202014"
        },
        {
            "id": "32",
            "entry": "[32] D. Wang, P. Cui, and W. Zhu. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20D.%20Cui%2C%20P.%20Zhu%2C%20W.%20Structural%20deep%20network%20embedding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20D.%20Cui%2C%20P.%20Zhu%2C%20W.%20Structural%20deep%20network%20embedding%202016"
        },
        {
            "id": "33",
            "entry": "[33] C. Yang, Z. Liu, D. Zhao, M. Sun, and E. Y. Chang. Network representation learning with rich text information. In IJCAI, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20C.%20Liu%2C%20Z.%20Zhao%2C%20D.%20Sun%2C%20M.%20Network%20representation%20learning%20with%20rich%20text%20information%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20C.%20Liu%2C%20Z.%20Zhao%2C%20D.%20Sun%2C%20M.%20Network%20representation%20learning%20with%20rich%20text%20information%202015"
        },
        {
            "id": "34",
            "entry": "[34] X. Zhang, R. Henao, Z. Gan, Y. Li, and L. Carin. Multi-label learning from medical plain text with convolutional residual models. arXiv preprint arXiv:1801.05062, 2018. ",
            "arxiv_url": "https://arxiv.org/pdf/1801.05062"
        }
    ]
}
