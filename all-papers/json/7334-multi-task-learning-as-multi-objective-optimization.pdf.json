{
    "filename": "7334-multi-task-learning-as-multi-objective-optimization.pdf",
    "metadata": {
        "title": "Multi-Task Learning as Multi-Objective Optimization",
        "author": "Ozan Sener, Vladlen Koltun",
        "date": 1956,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7334-multi-task-learning-as-multi-objective-optimization.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In multi-task learning, multiple tasks are solved jointly, sharing inductive bias between them. Multi-task learning is inherently a multi-objective problem because different tasks may conflict, necessitating a trade-off. A common compromise is to optimize a proxy objective that minimizes a weighted linear combination of pertask losses. However, this workaround is only valid when the tasks do not compete, which is rarely the case. In this paper, we explicitly cast multi-task learning as multi-objective optimization, with the overall objective of finding a Pareto optimal solution. To this end, we use algorithms developed in the gradient-based multiobjective optimization literature. These algorithms are not directly applicable to large-scale learning problems since they scale poorly with the dimensionality of the gradients and the number of tasks. We therefore propose an upper bound for the multi-objective loss and show that it can be optimized efficiently. We further prove that optimizing this upper bound yields a Pareto optimal solution under realistic assumptions. We apply our method to a variety of multi-task deep learning problems including digit classification, scene understanding (joint semantic segmentation, instance segmentation, and depth estimation), and multilabel classification. Our method produces higher-performing models than recent multi-task learning formulations or per-task training."
    },
    "keywords": [
        {
            "term": "pareto optimal",
            "url": "https://en.wikipedia.org/wiki/pareto_optimal"
        },
        {
            "term": "multi-task learning",
            "url": "https://en.wikipedia.org/wiki/multi-task_learning"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "optimal solution",
            "url": "https://en.wikipedia.org/wiki/optimal_solution"
        },
        {
            "term": "Pareto set",
            "url": "https://en.wikipedia.org/wiki/Pareto_set"
        },
        {
            "term": "multiobjective optimization",
            "url": "https://en.wikipedia.org/wiki/multiobjective_optimization"
        },
        {
            "term": "inductive bias",
            "url": "https://en.wikipedia.org/wiki/inductive_bias"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "One of the most surprising results in statistics is Stein\u2019s paradox. <a class=\"ref-link\" id=\"cStein_1956_a\" href=\"#rStein_1956_a\"><a class=\"ref-link\" id=\"cStein_1956_a\" href=\"#rStein_1956_a\">Stein (1956</a></a>) showed that it is better to estimate the means of three or more Gaussian random variables using samples from all of them rather than estimating them separately, even when the Gaussians are independent",
        "Stein\u2019s paradox was an early motivation for multi-task learning (MTL) (<a class=\"ref-link\" id=\"cCaruana_1997_a\" href=\"#rCaruana_1997_a\">Caruana, 1997</a>), a learning paradigm in which data from multiple tasks is used with the hope to obtain superior performance over learning each task independently",
        "We prove that using our upper bound yields a Pareto optimal solution under realistic assumptions",
        "We focus on hard parameter sharing with gradient-based optimization, following the success of deep multi-task learning in computer vision (<a class=\"ref-link\" id=\"cBilen_2016_a\" href=\"#rBilen_2016_a\">Bilen and Vedaldi, 2016</a>; <a class=\"ref-link\" id=\"cMisra_et+al_2016_a\" href=\"#rMisra_et+al_2016_a\">Misra et al, 2016</a>; <a class=\"ref-link\" id=\"cRudd_et+al_2016_a\" href=\"#rRudd_et+al_2016_a\">Rudd et al, 2016</a>; <a class=\"ref-link\" id=\"cYang_2016_a\" href=\"#rYang_2016_a\">Yang and Hospedales, 2016</a>; <a class=\"ref-link\" id=\"cKokkinos_2017_a\" href=\"#rKokkinos_2017_a\">Kokkinos, 2017</a>; Zamir et al, 2018), natural language processing (<a class=\"ref-link\" id=\"cCollobert_2008_a\" href=\"#rCollobert_2008_a\">Collobert and Weston, 2008</a>; <a class=\"ref-link\" id=\"cDong_et+al_2015_a\" href=\"#rDong_et+al_2015_a\">Dong et al, 2015</a>; <a class=\"ref-link\" id=\"cLiu_et+al_2015_a\" href=\"#rLiu_et+al_2015_a\">Liu et al, 2015a</a>; Luong et al, 2015; <a class=\"ref-link\" id=\"cHashimoto_et+al_2017_a\" href=\"#rHashimoto_et+al_2017_a\">Hashimoto et al, 2017</a>), speech processing (<a class=\"ref-link\" id=\"cHuang_et+al_2013_a\" href=\"#rHuang_et+al_2013_a\">Huang et al, 2013</a>; <a class=\"ref-link\" id=\"cSeltzer_2013_a\" href=\"#rSeltzer_2013_a\">Seltzer and Droppo, 2013</a>; <a class=\"ref-link\" id=\"cHuang_et+al_2015_a\" href=\"#rHuang_et+al_2015_a\">Huang et al, 2015</a>), and even seemingly unrelated domains over multiple modalities (<a class=\"ref-link\" id=\"cKaiser_et+al_2017_a\" href=\"#rKaiser_et+al_2017_a\">Kaiser et al, 2017</a>)",
        "We described an approach to multi-task learning",
        "In order to apply multi-objective optimization to multi-task learning, we described an efficient algorithm as well as specific approximations that yielded a deep multi-task learning algorithm with almost no computational overhead"
    ],
    "key_statements": [
        "One of the most surprising results in statistics is Stein\u2019s paradox. <a class=\"ref-link\" id=\"cStein_1956_a\" href=\"#rStein_1956_a\"><a class=\"ref-link\" id=\"cStein_1956_a\" href=\"#rStein_1956_a\">Stein (1956</a></a>) showed that it is better to estimate the means of three or more Gaussian random variables using samples from all of them rather than estimating them separately, even when the Gaussians are independent",
        "Stein\u2019s paradox was an early motivation for multi-task learning (MTL) (<a class=\"ref-link\" id=\"cCaruana_1997_a\" href=\"#rCaruana_1997_a\">Caruana, 1997</a>), a learning paradigm in which data from multiple tasks is used with the hope to obtain superior performance over learning each task independently",
        "We prove that using our upper bound yields a Pareto optimal solution under realistic assumptions",
        "We focus on hard parameter sharing with gradient-based optimization, following the success of deep multi-task learning in computer vision (<a class=\"ref-link\" id=\"cBilen_2016_a\" href=\"#rBilen_2016_a\">Bilen and Vedaldi, 2016</a>; <a class=\"ref-link\" id=\"cMisra_et+al_2016_a\" href=\"#rMisra_et+al_2016_a\">Misra et al, 2016</a>; <a class=\"ref-link\" id=\"cRudd_et+al_2016_a\" href=\"#rRudd_et+al_2016_a\">Rudd et al, 2016</a>; <a class=\"ref-link\" id=\"cYang_2016_a\" href=\"#rYang_2016_a\">Yang and Hospedales, 2016</a>; <a class=\"ref-link\" id=\"cKokkinos_2017_a\" href=\"#rKokkinos_2017_a\">Kokkinos, 2017</a>; Zamir et al, 2018), natural language processing (<a class=\"ref-link\" id=\"cCollobert_2008_a\" href=\"#rCollobert_2008_a\">Collobert and Weston, 2008</a>; <a class=\"ref-link\" id=\"cDong_et+al_2015_a\" href=\"#rDong_et+al_2015_a\">Dong et al, 2015</a>; <a class=\"ref-link\" id=\"cLiu_et+al_2015_a\" href=\"#rLiu_et+al_2015_a\">Liu et al, 2015a</a>; Luong et al, 2015; <a class=\"ref-link\" id=\"cHashimoto_et+al_2017_a\" href=\"#rHashimoto_et+al_2017_a\">Hashimoto et al, 2017</a>), speech processing (<a class=\"ref-link\" id=\"cHuang_et+al_2013_a\" href=\"#rHuang_et+al_2013_a\">Huang et al, 2013</a>; <a class=\"ref-link\" id=\"cSeltzer_2013_a\" href=\"#rSeltzer_2013_a\">Seltzer and Droppo, 2013</a>; <a class=\"ref-link\" id=\"cHuang_et+al_2015_a\" href=\"#rHuang_et+al_2015_a\">Huang et al, 2015</a>), and even seemingly unrelated domains over multiple modalities (<a class=\"ref-link\" id=\"cKaiser_et+al_2017_a\" href=\"#rKaiser_et+al_2017_a\">Kaiser et al, 2017</a>)",
        "The multi-task learning update described in Algorithm 2 is applicable to any problem that uses optimization based on gradient descent",
        "We further show that optimizing this upper bound yields a Pareto optimal solution under realistic assumptions",
        "Stability analysis in convex optimization suggests that if gradients are computed with an error r \u2713Lt = r\u2713Lt + et (\u2713 corresponds to \u2713sh in (3)), as opposed to Z in the approximate problem in (MGDA-UB), the error in the solution is bounded as k\u21b5\u02c6 \u21b5k2",
        "We described an approach to multi-task learning",
        "In order to apply multi-objective optimization to multi-task learning, we described an efficient algorithm as well as specific approximations that yielded a deep multi-task learning algorithm with almost no computational overhead"
    ],
    "summary": [
        "One of the most surprising results in statistics is Stein\u2019s paradox. <a class=\"ref-link\" id=\"cStein_1956_a\" href=\"#rStein_1956_a\"><a class=\"ref-link\" id=\"cStein_1956_a\" href=\"#rStein_1956_a\">Stein (1956</a></a>) showed that it is better to estimate the means of three or more Gaussian random variables using samples from all of them rather than estimating them separately, even when the Gaussians are independent.",
        "These parameters are learned by solving an optimization problem that minimizes a weighted sum of the empirical risk for each task.",
        "One such approach is the multiple-gradient descent algorithm (MGDA), which uses gradient-based optimization and provably converges to a point on the Pareto set (D\u00e9sid\u00e9ri, 2012).",
        "It can use the gradients of each task and solve an optimization problem to decide on an update over the shared parameters.",
        "We provide an upper bound for the MGDA optimization objective and show that it can be computed via a single backward pass without explicit task-specific gradients, making the computational overhead of the method negligible.",
        "The result is an exact algorithm for multi-objective optimization of deep networks with negligible computational overhead.",
        "Multi-task learning (MTL) is typically conducted via hard or soft parameter sharing.",
        "Our work applies gradient-based multi-objective optimization to multi-task learning.",
        "We specify the multi-objective optimization formulation of MTL using a vector-valued loss L: min L(\u2713sh, \u27131, .",
        "We suggest in Section 3.2 a practical algorithm for performing multi-objective optimization over very large parameter spaces.",
        "In Section 3.3 we propose an efficient solution for multi-objective optimization designed directly for high-capacity deep networks.",
        "D\u00e9sid\u00e9ri (2012) showed that either the solution to this optimization problem is 0 and the resulting point satisfies the KKT conditions, or the solution gives a descent direction that improves all tasks.",
        "The MTL update described in Algorithm 2 is applicable to any problem that uses optimization based on gradient descent.",
        "The algorithm we described needs to compute r\u2713sh Lt(\u2713sh, \u2713t) for each task t, which requires a backward pass over the shared parameters for each task.",
        "Our method provably finds a Pareto stationary point with negligible computational overhead and can be applied to any deep multi-objective problem with an encoder-decoder model.",
        "This experiment demonstrates the effectiveness of our method as well as the necessity of treating MTL as multi-objective optimization.",
        "Stability analysis in convex optimization suggests that if gradients are computed with an error r \u2713Lt = r\u2713Lt + et (\u2713 corresponds to \u2713sh in (3)), as opposed to Z in the approximate problem in (MGDA-UB), the error in the solution is bounded as k\u21b5\u02c6 \u21b5k2",
        "In order to apply multi-objective optimization to MTL, we described an efficient algorithm as well as specific approximations that yielded a deep MTL algorithm with almost no computational overhead.",
        "Our experiments indicate that the resulting algorithm is effective for a wide range of multi-task scenarios"
    ],
    "headline": "We further prove that optimizing this upper bound yields a Pareto optimal solution under realistic assumptions",
    "reference_links": [
        {
            "id": "Argyriou_et+al_2007_a",
            "entry": "A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning. In NIPS, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Argyriou%2C%20A.%20Evgeniou%2C%20T.%20Pontil%2C%20M.%20Multi-task%20feature%20learning%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Argyriou%2C%20A.%20Evgeniou%2C%20T.%20Pontil%2C%20M.%20Multi-task%20feature%20learning%202007"
        },
        {
            "id": "Bagherjeiran_et+al_2005_a",
            "entry": "A. Bagherjeiran, R. Vilalta, and C. F. Eick. Content-based image retrieval through a multi-agent meta-learning framework. In International Conference on Tools with Artificial Intelligence, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bagherjeiran%2C%20A.%20Vilalta%2C%20R.%20Eick%2C%20C.F.%20Content-based%20image%20retrieval%20through%20a%20multi-agent%20meta-learning%20framework%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bagherjeiran%2C%20A.%20Vilalta%2C%20R.%20Eick%2C%20C.F.%20Content-based%20image%20retrieval%20through%20a%20multi-agent%20meta-learning%20framework%202005"
        },
        {
            "id": "Bakker_2003_a",
            "entry": "B. Bakker and T. Heskes. Task clustering and gating for Bayesian multitask learning. JMLR, 4:83\u201399, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bakker%2C%20B.%20Heskes%2C%20T.%20Task%20clustering%20and%20gating%20for%20Bayesian%20multitask%20learning%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bakker%2C%20B.%20Heskes%2C%20T.%20Task%20clustering%20and%20gating%20for%20Bayesian%20multitask%20learning%202003"
        },
        {
            "id": "Baxter_2000_a",
            "entry": "J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research, 12:149\u2013198, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baxter%2C%20J.%20A%20model%20of%20inductive%20bias%20learning%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baxter%2C%20J.%20A%20model%20of%20inductive%20bias%20learning%202000"
        },
        {
            "id": "Bilen_2016_a",
            "entry": "H. Bilen and A. Vedaldi. Integrated perception with recurrent multi-task neural networks. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bilen%2C%20H.%20Vedaldi%2C%20A.%20Integrated%20perception%20with%20recurrent%20multi-task%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bilen%2C%20H.%20Vedaldi%2C%20A.%20Integrated%20perception%20with%20recurrent%20multi-task%20neural%20networks%202016"
        },
        {
            "id": "Caruana_1997_a",
            "entry": "R. Caruana. Multitask learning. Machine Learning, 28(1):41\u201375, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caruana%2C%20R.%20Multitask%20learning%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caruana%2C%20R.%20Multitask%20learning%201997"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Z. Chen, V. Badrinarayanan, C. Lee, and A. Rabinovich. GradNorm: Gradient normalization for adaptive loss balancing in deep multitask networks. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Z.%20Badrinarayanan%2C%20V.%20Lee%2C%20C.%20Rabinovich%2C%20A.%20GradNorm%3A%20Gradient%20normalization%20for%20adaptive%20loss%20balancing%20in%20deep%20multitask%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Z.%20Badrinarayanan%2C%20V.%20Lee%2C%20C.%20Rabinovich%2C%20A.%20GradNorm%3A%20Gradient%20normalization%20for%20adaptive%20loss%20balancing%20in%20deep%20multitask%20networks%202018"
        },
        {
            "id": "Collobert_2008_a",
            "entry": "R. Collobert and J. Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20R.%20Weston%2C%20J.%20A%20unified%20architecture%20for%20natural%20language%20processing%3A%20Deep%20neural%20networks%20with%20multitask%20learning%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20R.%20Weston%2C%20J.%20A%20unified%20architecture%20for%20natural%20language%20processing%3A%20Deep%20neural%20networks%20with%20multitask%20learning%202008"
        },
        {
            "id": "Cordts_et+al_2016_a",
            "entry": "M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele. The Cityscapes dataset for semantic urban scene understanding. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cordts%2C%20M.%20Omran%2C%20M.%20Ramos%2C%20S.%20Rehfeld%2C%20T.%20The%20Cityscapes%20dataset%20for%20semantic%20urban%20scene%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cordts%2C%20M.%20Omran%2C%20M.%20Ramos%2C%20S.%20Rehfeld%2C%20T.%20The%20Cityscapes%20dataset%20for%20semantic%20urban%20scene%20understanding%202016"
        },
        {
            "id": "De_et+al_2012_a",
            "entry": "P. B. C. de Miranda, R. B. C. Prud\u00eancio, A. C. P. L. F. de Carvalho, and C. Soares. Combining a multi-objective optimization approach with meta-learning for SVM parameter selection. In International Conference on Systems, Man, and Cybernetics, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=de%20Miranda%2C%20P.B.C.%20Prud%C3%AAncio%2C%20R.B.C.%20de%20Carvalho%2C%20A.C.P.L.F.%20Soares%2C%20C.%20Combining%20a%20multi-objective%20optimization%20approach%20with%20meta-learning%20for%20SVM%20parameter%20selection%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=de%20Miranda%2C%20P.B.C.%20Prud%C3%AAncio%2C%20R.B.C.%20de%20Carvalho%2C%20A.C.P.L.F.%20Soares%2C%20C.%20Combining%20a%20multi-objective%20optimization%20approach%20with%20meta-learning%20for%20SVM%20parameter%20selection%202012"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20ImageNet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20ImageNet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "D_2012_a",
            "entry": "J.-A. D\u00e9sid\u00e9ri. Multiple-gradient descent algorithm (MGDA) for multiobjective optimization. Comptes Rendus Mathematique, 350(5):313\u2013318, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=D%C3%A9sid%C3%A9ri%2C%20J.-A.%20Multiple-gradient%20descent%20algorithm%20%28MGDA%29%20for%20multiobjective%20optimization%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=D%C3%A9sid%C3%A9ri%2C%20J.-A.%20Multiple-gradient%20descent%20algorithm%20%28MGDA%29%20for%20multiobjective%20optimization%202012"
        },
        {
            "id": "Dong_et+al_2015_a",
            "entry": "D. Dong, H. Wu, W. He, D. Yu, and H. Wang. Multi-task learning for multiple language translation. In ACL, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20D.%20Wu%2C%20H.%20He%2C%20W.%20Yu%2C%20D.%20Multi-task%20learning%20for%20multiple%20language%20translation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20D.%20Wu%2C%20H.%20He%2C%20W.%20Yu%2C%20D.%20Multi-task%20learning%20for%20multiple%20language%20translation%202015"
        },
        {
            "id": "Ehrgott_2005_a",
            "entry": "M. Ehrgott. Multicriteria Optimization (2. ed.). Springer, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ehrgott%2C%20M.%20Multicriteria%20Optimization%202005"
        },
        {
            "id": "Fliege_2000_a",
            "entry": "J. Fliege and B. F. Svaiter. Steepest descent methods for multicriteria optimization. Mathematical Methods of Operations Research, 51(3):479\u2013494, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fliege%2C%20J.%20Svaiter%2C%20B.F.%20Steepest%20descent%20methods%20for%20multicriteria%20optimization%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fliege%2C%20J.%20Svaiter%2C%20B.F.%20Steepest%20descent%20methods%20for%20multicriteria%20optimization%202000"
        },
        {
            "id": "Ghosh_et+al_2013_a",
            "entry": "S. Ghosh, C. Lovell, and S. R. Gunn. Towards Pareto descent directions in sampling experts for multiple tasks in an on-line learning paradigm. In AAAI Spring Symposium: Lifelong Machine Learning, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghosh%2C%20S.%20Lovell%2C%20C.%20Gunn%2C%20S.R.%20Towards%20Pareto%20descent%20directions%20in%20sampling%20experts%20for%20multiple%20tasks%20in%20an%20on-line%20learning%20paradigm%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghosh%2C%20S.%20Lovell%2C%20C.%20Gunn%2C%20S.R.%20Towards%20Pareto%20descent%20directions%20in%20sampling%20experts%20for%20multiple%20tasks%20in%20an%20on-line%20learning%20paradigm%202013"
        },
        {
            "id": "Hashimoto_et+al_2017_a",
            "entry": "K. Hashimoto, C. Xiong, Y. Tsuruoka, and R. Socher. A joint many-task model: Growing a neural network for multiple NLP tasks. In EMNLP, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hashimoto%2C%20K.%20Xiong%2C%20C.%20Tsuruoka%2C%20Y.%20Socher%2C%20R.%20A%20joint%20many-task%20model%3A%20Growing%20a%20neural%20network%20for%20multiple%20NLP%20tasks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hashimoto%2C%20K.%20Xiong%2C%20C.%20Tsuruoka%2C%20Y.%20Socher%2C%20R.%20A%20joint%20many-task%20model%3A%20Growing%20a%20neural%20network%20for%20multiple%20NLP%20tasks%202017"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hern_et+al_2016_a",
            "entry": "D. Hern\u00e1ndez-Lobato, J. M. Hern\u00e1ndez-Lobato, A. Shah, and R. P. Adams. Predictive entropy search for multi-objective bayesian optimization. In ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hern%C3%A1ndez-Lobato%2C%20D.%20Hern%C3%A1ndez-Lobato%2C%20J.M.%20Shah%2C%20A.%20Adams%2C%20R.P.%20Predictive%20entropy%20search%20for%20multi-objective%20bayesian%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hern%C3%A1ndez-Lobato%2C%20D.%20Hern%C3%A1ndez-Lobato%2C%20J.M.%20Shah%2C%20A.%20Adams%2C%20R.P.%20Predictive%20entropy%20search%20for%20multi-objective%20bayesian%20optimization%202016"
        },
        {
            "id": "Huang_et+al_2013_a",
            "entry": "J.-T. Huang, J. Li, D. Yu, L. Deng, and Y. Gong. Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers. In ICASSP, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20J.-T.%20Li%2C%20J.%20Yu%2C%20D.%20Deng%2C%20L.%20Cross-language%20knowledge%20transfer%20using%20multilingual%20deep%20neural%20network%20with%20shared%20hidden%20layers%202013"
        },
        {
            "id": "Huang_et+al_2015_a",
            "entry": "Z. Huang, J. Li, S. M. Siniscalchi, I.-F. Chen, J. Wu, and C.-H. Lee. Rapid adaptation for deep neural networks through multi-task learning. In Interspeech, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Z.%20Li%2C%20J.%20Siniscalchi%2C%20S.M.%20Chen%2C%20I.-F.%20Rapid%20adaptation%20for%20deep%20neural%20networks%20through%20multi-task%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Z.%20Li%2C%20J.%20Siniscalchi%2C%20S.M.%20Chen%2C%20I.-F.%20Rapid%20adaptation%20for%20deep%20neural%20networks%20through%20multi-task%20learning%202015"
        },
        {
            "id": "Jaggi_2013_a",
            "entry": "M. Jaggi. Revisiting Frank-Wolfe: Projection-free sparse convex optimization. In ICML, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaggi%2C%20M.%20Revisiting%20Frank-Wolfe%3A%20Projection-free%20sparse%20convex%20optimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaggi%2C%20M.%20Revisiting%20Frank-Wolfe%3A%20Projection-free%20sparse%20convex%20optimization%202013"
        },
        {
            "id": "Kaiser_et+al_2017_a",
            "entry": "L. Kaiser, A. N. Gomez, N. Shazeer, A. Vaswani, N. Parmar, L. Jones, and J. Uszkoreit. One model to learn them all. arXiv:1706.05137, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.05137"
        },
        {
            "id": "Kendall_et+al_2018_a",
            "entry": "A. Kendall, Y. Gal, and R. Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kendall%2C%20A.%20Gal%2C%20Y.%20Cipolla%2C%20R.%20Multi-task%20learning%20using%20uncertainty%20to%20weigh%20losses%20for%20scene%20geometry%20and%20semantics%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kendall%2C%20A.%20Gal%2C%20Y.%20Cipolla%2C%20R.%20Multi-task%20learning%20using%20uncertainty%20to%20weigh%20losses%20for%20scene%20geometry%20and%20semantics%202018"
        },
        {
            "id": "Kokkinos_2017_a",
            "entry": "I. Kokkinos. UberNet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kokkinos%2C%20I.%20UberNet%3A%20Training%20a%20universal%20convolutional%20neural%20network%20for%20low-%2C%20mid-%2C%20and%20high-level%20vision%20using%20diverse%20datasets%20and%20limited%20memory%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kokkinos%2C%20I.%20UberNet%3A%20Training%20a%20universal%20convolutional%20neural%20network%20for%20low-%2C%20mid-%2C%20and%20high-level%20vision%20using%20diverse%20datasets%20and%20limited%20memory%202017"
        },
        {
            "id": "Kuhn_1951_a",
            "entry": "H. W. Kuhn and A. W. Tucker. Nonlinear programming. In Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, Berkeley, Calif., 1951. University of California Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuhn%2C%20H.W.%20Tucker%2C%20A.W.%20Nonlinear%20programming%201951",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuhn%2C%20H.W.%20Tucker%2C%20A.W.%20Nonlinear%20programming%201951"
        },
        {
            "id": "Lecun_et+al_1998_a",
            "entry": "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "Li_et+al_2014_a",
            "entry": "C. Li, M. Georgiopoulos, and G. C. Anagnostopoulos. Pareto-path multi-task multiple kernel learning. arXiv:1404.3190, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1404.3190"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "X. Liu, J. Gao, X. He, L. Deng, K. Duh, and Y.-Y. Wang. Representation learning using multi-task deep neural networks for semantic classification and information retrieval. In NAACL HLT, 2015a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20X.%20Gao%2C%20J.%20He%2C%20X.%20Deng%2C%20L.%20Representation%20learning%20using%20multi-task%20deep%20neural%20networks%20for%20semantic%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20X.%20Gao%2C%20J.%20He%2C%20X.%20Deng%2C%20L.%20Representation%20learning%20using%20multi-task%20deep%20neural%20networks%20for%20semantic%20classification%202015"
        },
        {
            "id": "Liu_et+al_2015_b",
            "entry": "Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In ICCV, 2015b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%202015"
        },
        {
            "id": "Long_0000_a",
            "entry": "M. Long and J. Wang. Learning multiple tasks with deep relationship networks. arXiv:1506.02117, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1506.02117"
        },
        {
            "id": "Luong_et+al_0000_a",
            "entry": "M.-T. Luong, Q. V. Le, I. Sutskever, O. Vinyals, and L. Kaiser. Multi-task sequence to sequence learning. arXiv:1511.06114, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06114"
        },
        {
            "id": "Makimoto_et+al_1994_a",
            "entry": "N. Makimoto, I. Nakagawa, and A. Tamura. An efficient algorithm for finding the minimum norm point in the convex hull of a finite point set in the plane. Operations Research Letters, 16(1):33\u201340, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Makimoto%2C%20N.%20Nakagawa%2C%20I.%20Tamura%2C%20A.%20An%20efficient%20algorithm%20for%20finding%20the%20minimum%20norm%20point%20in%20the%20convex%20hull%20of%20a%20finite%20point%20set%20in%20the%20plane%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Makimoto%2C%20N.%20Nakagawa%2C%20I.%20Tamura%2C%20A.%20An%20efficient%20algorithm%20for%20finding%20the%20minimum%20norm%20point%20in%20the%20convex%20hull%20of%20a%20finite%20point%20set%20in%20the%20plane%201994"
        },
        {
            "id": "Miettinen_1998_a",
            "entry": "K. Miettinen. Nonlinear Multiobjective Optimization. Springer, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miettinen%2C%20K.%20Nonlinear%20Multiobjective%20Optimization%201998"
        },
        {
            "id": "Misra_et+al_2016_a",
            "entry": "I. Misra, A. Shrivastava, A. Gupta, and M. Hebert. Cross-stitch networks for multi-task learning. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Misra%2C%20I.%20Shrivastava%2C%20A.%20Gupta%2C%20A.%20Hebert%2C%20M.%20Cross-stitch%20networks%20for%20multi-task%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Misra%2C%20I.%20Shrivastava%2C%20A.%20Gupta%2C%20A.%20Hebert%2C%20M.%20Cross-stitch%20networks%20for%20multi-task%20learning%202016"
        },
        {
            "id": "Parisi_et+al_2014_a",
            "entry": "S. Parisi, M. Pirotta, N. Smacchia, L. Bascetta, and M. Restelli. Policy gradient approaches for multi-objective sequential decision making. In IJCNN, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parisi%2C%20S.%20Pirotta%2C%20M.%20Smacchia%2C%20N.%20Bascetta%2C%20L.%20Policy%20gradient%20approaches%20for%20multi-objective%20sequential%20decision%20making%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parisi%2C%20S.%20Pirotta%2C%20M.%20Smacchia%2C%20N.%20Bascetta%2C%20L.%20Policy%20gradient%20approaches%20for%20multi-objective%20sequential%20decision%20making%202014"
        },
        {
            "id": "Paszke_et+al_2017_a",
            "entry": "A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer. Automatic differentiation in PyTorch. In NIPS Workshops, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A%20Paszke%20S%20Gross%20S%20Chintala%20G%20Chanan%20E%20Yang%20Z%20DeVito%20Z%20Lin%20A%20Desmaison%20L%20Antiga%20and%20A%20Lerer%20Automatic%20differentiation%20in%20PyTorch%20In%20NIPS%20Workshops%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A%20Paszke%20S%20Gross%20S%20Chintala%20G%20Chanan%20E%20Yang%20Z%20DeVito%20Z%20Lin%20A%20Desmaison%20L%20Antiga%20and%20A%20Lerer%20Automatic%20differentiation%20in%20PyTorch%20In%20NIPS%20Workshops%202017"
        },
        {
            "id": "Peitz_2018_a",
            "entry": "S. Peitz and M. Dellnitz. Gradient-based multiobjective optimization with uncertainties. In NEO, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peitz%2C%20S.%20Dellnitz%2C%20M.%20Gradient-based%20multiobjective%20optimization%20with%20uncertainties%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peitz%2C%20S.%20Dellnitz%2C%20M.%20Gradient-based%20multiobjective%20optimization%20with%20uncertainties%202018"
        },
        {
            "id": "Pirotta_2016_a",
            "entry": "M. Pirotta and M. Restelli. Inverse reinforcement learning through policy gradient minimization. In AAAI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pirotta%2C%20M.%20Restelli%2C%20M.%20Inverse%20reinforcement%20learning%20through%20policy%20gradient%20minimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pirotta%2C%20M.%20Restelli%2C%20M.%20Inverse%20reinforcement%20learning%20through%20policy%20gradient%20minimization%202016"
        },
        {
            "id": "Poirion_et+al_2017_a",
            "entry": "F. Poirion, Q. Mercier, and J. D\u00e9sid\u00e9ri. Descent algorithm for nonsmooth stochastic multiobjective optimization. Computational Optimization and Applications, 68(2):317\u2013331, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Poirion%2C%20F.%20Mercier%2C%20Q.%20D%C3%A9sid%C3%A9ri%2C%20J.%20Descent%20algorithm%20for%20nonsmooth%20stochastic%20multiobjective%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Poirion%2C%20F.%20Mercier%2C%20Q.%20D%C3%A9sid%C3%A9ri%2C%20J.%20Descent%20algorithm%20for%20nonsmooth%20stochastic%20multiobjective%20optimization%202017"
        },
        {
            "id": "Roijers_et+al_2013_a",
            "entry": "D. M. Roijers, P. Vamplew, S. Whiteson, and R. Dazeley. A survey of multi-objective sequential decision-making. Journal of Artificial Intelligence Research, 48:67\u2013113, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roijers%2C%20D.M.%20Vamplew%2C%20P.%20Whiteson%2C%20S.%20Dazeley%2C%20R.%20A%20survey%20of%20multi-objective%20sequential%20decision-making%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roijers%2C%20D.M.%20Vamplew%2C%20P.%20Whiteson%2C%20S.%20Dazeley%2C%20R.%20A%20survey%20of%20multi-objective%20sequential%20decision-making%202013"
        },
        {
            "id": "Rosenbaum_et+al_2017_a",
            "entry": "C. Rosenbaum, T. Klinger, and M. Riemer. Routing networks: Adaptive selection of non-linear functions for multi-task learning. arXiv:1711.01239, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.01239"
        },
        {
            "id": "Rudd_et+al_2016_a",
            "entry": "E. M. Rudd, M. G\u00fcnther, and T. E. Boult. MOON: A mixed objective optimization network for the recognition of facial attributes. In ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rudd%2C%20E.M.%20G%C3%BCnther%2C%20M.%20Boult%2C%20T.E.%20MOON%3A%20A%20mixed%20objective%20optimization%20network%20for%20the%20recognition%20of%20facial%20attributes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rudd%2C%20E.M.%20G%C3%BCnther%2C%20M.%20Boult%2C%20T.E.%20MOON%3A%20A%20mixed%20objective%20optimization%20network%20for%20the%20recognition%20of%20facial%20attributes%202016"
        },
        {
            "id": "Ruder_2017_a",
            "entry": "S. Ruder. An overview of multi-task learning in deep neural networks. arXiv:1706.05098, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.05098"
        },
        {
            "id": "Sabour_et+al_2017_a",
            "entry": "S. Sabour, N. Frosst, and G. E. Hinton. Dynamic routing between capsules. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sabour%2C%20S.%20Frosst%2C%20N.%20Hinton%2C%20G.E.%20Dynamic%20routing%20between%20capsules%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sabour%2C%20S.%20Frosst%2C%20N.%20Hinton%2C%20G.E.%20Dynamic%20routing%20between%20capsules%202017"
        },
        {
            "id": "Schaeffler_et+al_2002_a",
            "entry": "S. Sch\u00e4ffler, R. Schultz, and K. Weinzierl. Stochastic method for the solution of unconstrained vector optimization problems. Journal of Optimization Theory and Applications, 114(1):209\u2013222, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sch%C3%A4ffler%2C%20S.%20Schultz%2C%20R.%20Weinzierl%2C%20K.%20Stochastic%20method%20for%20the%20solution%20of%20unconstrained%20vector%20optimization%20problems%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sch%C3%A4ffler%2C%20S.%20Schultz%2C%20R.%20Weinzierl%2C%20K.%20Stochastic%20method%20for%20the%20solution%20of%20unconstrained%20vector%20optimization%20problems%202002"
        },
        {
            "id": "Sekitani_1993_a",
            "entry": "K. Sekitani and Y. Yamamoto. A recursive algorithm for finding the minimum norm point in a polytope and a pair of closest points in two polytopes. Mathematical Programming, 61(1-3):233\u2013249, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sekitani%2C%20K.%20Yamamoto%2C%20Y.%20A%20recursive%20algorithm%20for%20finding%20the%20minimum%20norm%20point%20in%20a%20polytope%20and%20a%20pair%20of%20closest%20points%20in%20two%20polytopes%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sekitani%2C%20K.%20Yamamoto%2C%20Y.%20A%20recursive%20algorithm%20for%20finding%20the%20minimum%20norm%20point%20in%20a%20polytope%20and%20a%20pair%20of%20closest%20points%20in%20two%20polytopes%201993"
        },
        {
            "id": "Seltzer_2013_a",
            "entry": "M. L. Seltzer and J. Droppo. Multi-task learning in deep neural networks for improved phoneme recognition. In ICASSP, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seltzer%2C%20M.L.%20Droppo%2C%20J.%20Multi-task%20learning%20in%20deep%20neural%20networks%20for%20improved%20phoneme%20recognition%202013"
        },
        {
            "id": "Shah_2016_a",
            "entry": "A. Shah and Z. Ghahramani. Pareto frontier learning with expensive correlated objectives. In ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shah%2C%20A.%20Ghahramani%2C%20Z.%20Pareto%20frontier%20learning%20with%20expensive%20correlated%20objectives%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shah%2C%20A.%20Ghahramani%2C%20Z.%20Pareto%20frontier%20learning%20with%20expensive%20correlated%20objectives%202016"
        },
        {
            "id": "Stein_1956_a",
            "entry": "C. Stein. Inadmissibility of the usual estimator for the mean of a multivariate normal distribution. Technical report, Stanford University, US, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stein%2C%20C.%20Inadmissibility%20of%20the%20usual%20estimator%20for%20the%20mean%20of%20a%20multivariate%20normal%20distribution%201956"
        },
        {
            "id": "Wolfe_1976_a",
            "entry": "P. Wolfe. Finding the nearest point in a polytope. Mathematical Programming, 11(1):128\u2013149, 1976.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wolfe%2C%20P.%20Finding%20the%20nearest%20point%20in%20a%20polytope%201976",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wolfe%2C%20P.%20Finding%20the%20nearest%20point%20in%20a%20polytope%201976"
        },
        {
            "id": "Xue_et+al_2007_a",
            "entry": "Y. Xue, X. Liao, L. Carin, and B. Krishnapuram. Multi-task learning for classification with dirichlet process priors. JMLR, 8:35\u201363, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xue%2C%20Y.%20Liao%2C%20X.%20Carin%2C%20L.%20Krishnapuram%2C%20B.%20Multi-task%20learning%20for%20classification%20with%20dirichlet%20process%20priors%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xue%2C%20Y.%20Liao%2C%20X.%20Carin%2C%20L.%20Krishnapuram%2C%20B.%20Multi-task%20learning%20for%20classification%20with%20dirichlet%20process%20priors%202007"
        },
        {
            "id": "Yang_2016_a",
            "entry": "Y. Yang and T. M. Hospedales. Trace norm regularised deep multi-task learning. arXiv:1606.04038, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.04038"
        },
        {
            "id": "Zamir_et+al_2010_a",
            "entry": "A. R. Zamir, A. Sax, W. B. Shen, L. J. Guibas, J. Malik, and S. Savarese. Taskonomy: Disentangling task transfer learning. In CVPR, 2018. Y. Zhang and D. Yeung. A convex formulation for learning task relationships in multi-task learning. In UAI, 2010. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A%20R%20Zamir%20A%20Sax%20W%20B%20Shen%20L%20J%20Guibas%20J%20Malik%20and%20S%20Savarese%20Taskonomy%20Disentangling%20task%20transfer%20learning%20In%20CVPR%202018%20Y%20Zhang%20and%20D%20Yeung%20A%20convex%20formulation%20for%20learning%20task%20relationships%20in%20multitask%20learning%20In%20UAI%202010%20H%20Zhao%20J%20Shi%20X%20Qi%20X%20Wang%20and%20J%20Jia%20Pyramid%20scene%20parsing%20network%20In%20CVPR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A%20R%20Zamir%20A%20Sax%20W%20B%20Shen%20L%20J%20Guibas%20J%20Malik%20and%20S%20Savarese%20Taskonomy%20Disentangling%20task%20transfer%20learning%20In%20CVPR%202018%20Y%20Zhang%20and%20D%20Yeung%20A%20convex%20formulation%20for%20learning%20task%20relationships%20in%20multitask%20learning%20In%20UAI%202010%20H%20Zhao%20J%20Shi%20X%20Qi%20X%20Wang%20and%20J%20Jia%20Pyramid%20scene%20parsing%20network%20In%20CVPR%202017"
        },
        {
            "id": "Cvpr_2017_a",
            "entry": "CVPR, 2017a. D. Zhou, J. Wang, B. Jiang, H. Guo, and Y. Li. Multi-task multi-view learning based on cooperative multiobjective optimization. IEEE Access, 2017b. J. Zhou, J. Chen, and J. Ye. Clustered multi-task learning via alternating structure optimization. In NIPS, 2011a. J. Zhou, J. Chen, and J. Ye. MALSAR: Multi-task learning via structural regularization. Arizona State University, 2011b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Multi-task%20multi-view%20learning%20based%20on%20cooperative%20multiobjective%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Multi-task%20multi-view%20learning%20based%20on%20cooperative%20multiobjective%20optimization%202017"
        }
    ]
}
