{
    "filename": "7361-informative-features-for-model-comparison.pdf",
    "metadata": {
        "date": 2018,
        "title": "Informative Features for Model Comparison",
        "author": "Wittawat Jitkrittum Max Planck Institute for Intelligent Systems wittawat@tuebingen.mpg.de",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7361-informative-features-for-model-comparison.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Given two candidate models, and a set of target observations, we address the problem of measuring the relative goodness of fit of the two models. We propose two new statistical tests which are nonparametric, computationally efficient (runtime complexity is linear in the sample size), and interpretable. As a unique advantage, our tests can produce a set of examples (informative features) indicating the regions in the data domain where one model fits significantly better than the other. In a real-world problem of comparing GAN models, the test power of our new test matches that of the state-of-the-art test of relative goodness of fit, while being one order of magnitude faster."
    },
    "keywords": [
        {
            "term": "high dimensional",
            "url": "https://en.wikipedia.org/wiki/high_dimensional"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        },
        {
            "term": "empirical characteristic function",
            "url": "https://en.wikipedia.org/wiki/empirical_characteristic_function"
        },
        {
            "term": "Restricted Boltzmann Machine",
            "url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_Machine"
        },
        {
            "term": "approximate bayesian computation",
            "url": "https://en.wikipedia.org/wiki/approximate_bayesian_computation"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "reproducing kernel Hilbert space",
            "url": "https://en.wikipedia.org/wiki/reproducing_kernel_Hilbert_space"
        }
    ],
    "highlights": [
        "One of the most fruitful areas in recent machine learning research has been the development of effective generative models for very complex and high dimensional data",
        "In the experiment on comparing two Generative Adversarial Network models, we find that the performance of our new test matches that of Rel-Maximum Mean Discrepancy while being one order of magnitude faster",
        "By specifying V and setting W = V , testing with Rel-Unnormalized Mean Embeddings is equivalent to posing the question \u201cDoes Q fit to the data better than P does, as measured in the regions of V ?\u201d For instance, the observed sample from R might contain smiling and non-smiling faces, and P, Q are candidate generative models for face images",
        "For Rel-Unnormalized Mean Embeddings and Rel-Finite-Set Stein Discrepancy we set kX = kY = k, where the the Gaussian width of k, and the test locations are chosen by maximizing their respective power criteria described in Section 3 on 20% of the data",
        "Since the relative goodness of fit of p and q must be compared locally, the optimized test locations of Rel-Unnormalized Mean Embeddings are suitable for detecting such local differences",
        "Examining Generative Adversarial Network Training In the final experiment, we show that the power criterion of Rel-Unnormalized Mean Embeddings can be used to examine the relative change of the distribution of a Generative Adversarial Network model after training further for a few epochs"
    ],
    "key_statements": [
        "One of the most fruitful areas in recent machine learning research has been the development of effective generative models for very complex and high dimensional data",
        "Chief among these have been the generative adversarial networks [<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>, <a class=\"ref-link\" id=\"cArjovsky_et+al_2017_a\" href=\"#rArjovsky_et+al_2017_a\">Arjovsky et al, 2017</a>, <a class=\"ref-link\" id=\"cNowozin_et+al_2016_a\" href=\"#rNowozin_et+al_2016_a\">Nowozin et al, 2016</a>], where samples may be generated without an explicit generative model or likelihood function",
        "A related thread has emerged in the statistics community with the advent of Approximate Bayesian Computation, where simulation-based models without closed-form likelihoods are widely applied in bioinformatics applications [see <a class=\"ref-link\" id=\"cLintusaari_et+al_2017_a\" href=\"#rLintusaari_et+al_2017_a\">Lintusaari et al, 2017</a>, for a review]",
        "In the experiment on comparing two Generative Adversarial Network models, we find that the performance of our new test matches that of Rel-Maximum Mean Discrepancy while being one order of magnitude faster",
        "By specifying V and setting W = V , testing with Rel-Unnormalized Mean Embeddings is equivalent to posing the question \u201cDoes Q fit to the data better than P does, as measured in the regions of V ?\u201d For instance, the observed sample from R might contain smiling and non-smiling faces, and P, Q are candidate generative models for face images",
        "Figure 1a shows that when each component in r has the same mixing proportion, the power criterion of Rel-Unnormalized Mean Embeddings is a zero function indicating that p and q have the same goodness of fit to r everywhere",
        "For Rel-Unnormalized Mean Embeddings and Rel-Finite-Set Stein Discrepancy we set kX = kY = k, where the the Gaussian width of k, and the test locations are chosen by maximizing their respective power criteria described in Section 3 on 20% of the data",
        "Since the relative goodness of fit of p and q must be compared locally, the optimized test locations of Rel-Unnormalized Mean Embeddings are suitable for detecting such local differences",
        "We evaluate the power criterion of Rel-Unnormalized Mean Embeddings at each of the test locations in the pool individually",
        "There is a generic way of constructing a relative goodness-of-fit test based on repeated permutation of samples of P and Q to simulate from the null distribution",
        "Examining Generative Adversarial Network Training In the final experiment, we show that the power criterion of Rel-Unnormalized Mean Embeddings can be used to examine the relative change of the distribution of a Generative Adversarial Network model after training further for a few epochs"
    ],
    "summary": [
        "One of the most fruitful areas in recent machine learning research has been the development of effective generative models for very complex and high dimensional data.",
        "In the full generality of Rel-UME, two sets of test locations can be used: V = {vj}Jj=p 1 for computing UP2 , and W = {wj}Jj=q 1 for UQ2 .",
        "By specifying V and setting W = V , testing with Rel-UME is equivalent to posing the question \u201cDoes Q fit to the data better than P does, as measured in the regions of V ?\u201d For instance, the observed sample from R might contain smiling and non-smiling faces, and P, Q are candidate generative models for face images.",
        "We propose setting V to contain the locations which maximize the probability that the test can detect the better fit of",
        "Figure 1a shows that when each component in r has the same mixing proportion, the power criterion of Rel-UME is a zero function indicating that p and q have the same goodness of fit to r everywhere.",
        "The power criterion of Rel-FSSD indicates that q fits better at the right mode of r in the case of equal mixing proportion.",
        "For Rel-UME and Rel-FSSD we set kX = kY = k, where the the Gaussian width of k, and the test locations are chosen by maximizing their respective power criteria described in Section 3 on 20% of the data.",
        "In the Blobs problem (Figure 2b), it can be seen that Rel-UME achieves larger power at all sample sizes, compared to Rel-MMD.",
        "Since the relative goodness of fit of p and q must be compared locally, the optimized test locations of Rel-UME are suitable for detecting such local differences.",
        "Structural information provided by the density functions allows Rel-FSSD to detect the difference even at = 0.35, as can be seen from the high test powers.",
        "3. Informative Power Objective In this part, we demonstrate that test locations having positive values of the power criterion correctly indicate the regions in which Q has a better fit.",
        "We evaluate the power criterion of Rel-UME at each of the test locations in the pool individually.",
        "4. Testing GAN Models In this experiment, we apply the proposed Rel-UME test to comparing two generative adversarial networks (GANs) [<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>].",
        "There is a generic way of constructing a relative goodness-of-fit test based on repeated permutation of samples of P and Q to simulate from the null distribution.",
        "We notice that increasing the number of test locations of Rel-UME helps detect the better fit of Q."
    ],
    "headline": "A set of target observations, we address the problem of measuring the relative goodness of fit of the two models",
    "reference_links": [
        {
            "id": "Fern_et+al_2008_a",
            "entry": "V. Alba Fern\u00e1ndez, M. Jim\u00e9nez-Gamero, and J. Mu\u00f1oz Garcia. A test for the two-sample problem based on empirical characteristic functions. Computational Statistics and Data Analysis, 52: 3730\u20133748, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fern%C3%A1ndez%2C%20V.Alba%20Jim%C3%A9nez-Gamero%2C%20M.%20Garcia%2C%20J.Mu%C3%B1oz%20A%20test%20for%20the%20two-sample%20problem%20based%20on%20empirical%20characteristic%20functions%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fern%C3%A1ndez%2C%20V.Alba%20Jim%C3%A9nez-Gamero%2C%20M.%20Garcia%2C%20J.Mu%C3%B1oz%20A%20test%20for%20the%20two-sample%20problem%20based%20on%20empirical%20characteristic%20functions%202008"
        },
        {
            "id": "Amos_et+al_2016_a",
            "entry": "B. Amos, B. Ludwiczuk, and M. Satyanarayanan. Openface: A general-purpose face recognition library with mobile applications. Technical report, CMU-CS-16-118, CMU School of Computer Science, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amos%2C%20B.%20Ludwiczuk%2C%20B.%20Satyanarayanan%2C%20M.%20Openface%3A%20A%20general-purpose%20face%20recognition%20library%20with%20mobile%20applications%202016"
        },
        {
            "id": "Arjovsky_et+al_2017_a",
            "entry": "M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein generative adversarial networks. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20M.%20Chintala%2C%20S.%20Bottou%2C%20L.%20Wasserstein%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20M.%20Chintala%2C%20S.%20Bottou%2C%20L.%20Wasserstein%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Baringhaus_1988_a",
            "entry": "L. Baringhaus and N. Henze. A consistent test for multivariate normality based on the empirical characteristic function. Metrika, 35:339\u2013348, 1988.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baringhaus%2C%20L.%20Henze%2C%20N.%20A%20consistent%20test%20for%20multivariate%20normality%20based%20on%20the%20empirical%20characteristic%20function%201988",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baringhaus%2C%20L.%20Henze%2C%20N.%20A%20consistent%20test%20for%20multivariate%20normality%20based%20on%20the%20empirical%20characteristic%20function%201988"
        },
        {
            "id": "Binkowski_et+al_2018_a",
            "entry": "M. Binkowski, D. J. Sutherland, M. Arbel, and A. Gretton. Demystifying MMD GANs. In ICLR. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%20Binkowski%20D%20J%20Sutherland%20M%20Arbel%20and%20A%20Gretton%20Demystifying%20MMD%20GANs%20In%20ICLR%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%20Binkowski%20D%20J%20Sutherland%20M%20Arbel%20and%20A%20Gretton%20Demystifying%20MMD%20GANs%20In%20ICLR%202018"
        },
        {
            "id": "Bounliphone_et+al_2015_a",
            "entry": "W. Bounliphone, E. Belilovsky, M. B. Blaschko, I. Antonoglou, and A. Gretton. A test of relative similarity for model selection in generative models. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bounliphone%2C%20W.%20Belilovsky%2C%20E.%20Blaschko%2C%20M.B.%20Antonoglou%2C%20I.%20A%20test%20of%20relative%20similarity%20for%20model%20selection%20in%20generative%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bounliphone%2C%20W.%20Belilovsky%2C%20E.%20Blaschko%2C%20M.B.%20Antonoglou%2C%20I.%20A%20test%20of%20relative%20similarity%20for%20model%20selection%20in%20generative%20models%202015"
        },
        {
            "id": "Box_1976_a",
            "entry": "G. E. P. Box. Science and statistics. Journal of the American Statistical Association, 71:791\u2013799, 1976.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Box%2C%20G.E.P.%20Science%20and%20statistics%201976",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Box%2C%20G.E.P.%20Science%20and%20statistics%201976"
        },
        {
            "id": "Casella_2002_a",
            "entry": "G. Casella and R. L. Berger. Statistical inference, volume 2. Duxbury Pacific Grove, CA, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=G%20Casella%20and%20R%20L%20Berger%20Statistical%20inference%20volume%202%20Duxbury%20Pacific%20Grove%20CA%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=G%20Casella%20and%20R%20L%20Berger%20Statistical%20inference%20volume%202%20Duxbury%20Pacific%20Grove%20CA%202002"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel. InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets. In NIPS, pages 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "Chwialkowski_et+al_1972_a",
            "entry": "K. Chwialkowski, A. Ramdas, D. Sejdinovic, and A. Gretton. Fast two-sample testing with analytic representations of probability measures. In NIPS, pages 1972\u20131980, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chwialkowski%2C%20K.%20Ramdas%2C%20A.%20Sejdinovic%2C%20D.%20Gretton%2C%20A.%20Fast%20two-sample%20testing%20with%20analytic%20representations%20of%20probability%20measures%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chwialkowski%2C%20K.%20Ramdas%2C%20A.%20Sejdinovic%2C%20D.%20Gretton%2C%20A.%20Fast%20two-sample%20testing%20with%20analytic%20representations%20of%20probability%20measures%201972"
        },
        {
            "id": "Chwialkowski_et+al_2016_a",
            "entry": "K. Chwialkowski, H. Strathmann, and A. Gretton. A kernel test of goodness of fit. In ICML, pages 2606\u20132615, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chwialkowski%2C%20K.%20Strathmann%2C%20H.%20Gretton%2C%20A.%20A%20kernel%20test%20of%20goodness%20of%20fit%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chwialkowski%2C%20K.%20Strathmann%2C%20H.%20Gretton%2C%20A.%20A%20kernel%20test%20of%20goodness%20of%20fit%202016"
        },
        {
            "id": "Friedman_1979_a",
            "entry": "J. Friedman and L. Rafsky. Multivariate generalizations of the Wald-Wolfowitz and Smirnov two-sample tests. The Annals of Statistics, 7(4):697\u2013717, 1979.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Friedman%2C%20J.%20Rafsky%2C%20L.%20Multivariate%20generalizations%20of%20the%20Wald-Wolfowitz%20and%20Smirnov%20two-sample%20tests%201979",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Friedman%2C%20J.%20Rafsky%2C%20L.%20Multivariate%20generalizations%20of%20the%20Wald-Wolfowitz%20and%20Smirnov%20two-sample%20tests%201979"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gorham_2015_a",
            "entry": "J. Gorham and L. Mackey. Measuring sample quality with Stein\u2019s method. In NIPS, pages 226\u2013234, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gorham%2C%20J.%20Mackey%2C%20L.%20Measuring%20sample%20quality%20with%20Stein%E2%80%99s%20method%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gorham%2C%20J.%20Mackey%2C%20L.%20Measuring%20sample%20quality%20with%20Stein%E2%80%99s%20method%202015"
        },
        {
            "id": "Gretton_et+al_2012_a",
            "entry": "A. Gretton, K. Borgwardt, M. Rasch, B. Sch\u00f6lkopf, and A. Smola. A kernel two-sample test. Journal of Machine Learning Research, 13:723\u2013773, 2012a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20A.%20Borgwardt%2C%20K.%20Rasch%2C%20M.%20Sch%C3%B6lkopf%2C%20B.%20A%20kernel%20two-sample%20test%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20A.%20Borgwardt%2C%20K.%20Rasch%2C%20M.%20Sch%C3%B6lkopf%2C%20B.%20A%20kernel%20two-sample%20test%202012"
        },
        {
            "id": "Gretton_et+al_2012_b",
            "entry": "A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan, M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal kernel choice for large-scale two-sample tests. In NIPS, pages 1205\u20131213, 2012b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20A.%20Sejdinovic%2C%20D.%20Strathmann%2C%20H.%20Balakrishnan%2C%20S.%20Optimal%20kernel%20choice%20for%20large-scale%20two-sample%20tests%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20A.%20Sejdinovic%2C%20D.%20Strathmann%2C%20H.%20Balakrishnan%2C%20S.%20Optimal%20kernel%20choice%20for%20large-scale%20two-sample%20tests%202012"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville. Improved training of Wasserstein GANs. In NIPS, pages 5767\u20135777, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20I.%20Ahmed%2C%20F.%20Arjovsky%2C%20M.%20Dumoulin%2C%20V.%20Improved%20training%20of%20Wasserstein%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20I.%20Ahmed%2C%20F.%20Arjovsky%2C%20M.%20Dumoulin%2C%20V.%20Improved%20training%20of%20Wasserstein%20GANs%202017"
        },
        {
            "id": "Hall_2002_a",
            "entry": "P. Hall and N. Tajvidi. Permutation tests for equality of distributions in high-dimensional settings. Biometrika, 89(2):359\u2013374, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hall%2C%20P.%20Tajvidi%2C%20N.%20Permutation%20tests%20for%20equality%20of%20distributions%20in%20high-dimensional%20settings%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hall%2C%20P.%20Tajvidi%2C%20N.%20Permutation%20tests%20for%20equality%20of%20distributions%20in%20high-dimensional%20settings%202002"
        },
        {
            "id": "Harchaoui_et+al_2008_a",
            "entry": "Z. Harchaoui, F. Bach, and E. Moulines. Testing for homogeneity with kernel Fisher discriminant analysis. pages 609\u2013616. MIT Press, Cambridge, MA, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harchaoui%2C%20Z.%20Bach%2C%20F.%20Moulines%2C%20E.%20Testing%20for%20homogeneity%20with%20kernel%20Fisher%20discriminant%20analysis%202008"
        },
        {
            "id": "Heusel_et+al_2017_a",
            "entry": "M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. GANs trained by a two time-scale update rule converge to a local nash equilibrium. In NIPS. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heusel%2C%20M.%20Ramsauer%2C%20H.%20Unterthiner%2C%20T.%20Nessler%2C%20B.%20GANs%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20nash%20equilibrium.%20In%20NIPS%202017"
        },
        {
            "id": "Hoeffding_1948_a",
            "entry": "W. Hoeffding. A class of statistics with asymptotically normal distribution. Ann. Math. Statist., 19 (3):293\u2013325, 09 1948.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoeffding%2C%20W.%20A%20class%20of%20statistics%20with%20asymptotically%20normal%20distribution%201948",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoeffding%2C%20W.%20A%20class%20of%20statistics%20with%20asymptotically%20normal%20distribution%201948"
        },
        {
            "id": "W_2016_a",
            "entry": "W. Jitkrittum, Z. Szab\u00f3, K. P. Chwialkowski, and A. Gretton. Interpretable distribution features with maximum testing power. In NIPS, pages 181\u2013189. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=W.%20Jitkrittum%2C%20Z.%20Szab%C3%B3%2C%20K.%20P.%20Chwialkowski%20Gretton%2C%20A.%20Interpretable%20distribution%20features%20with%20maximum%20testing%20power%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=W.%20Jitkrittum%2C%20Z.%20Szab%C3%B3%2C%20K.%20P.%20Chwialkowski%20Gretton%2C%20A.%20Interpretable%20distribution%20features%20with%20maximum%20testing%20power%202016"
        },
        {
            "id": "W_2017_a",
            "entry": "W. Jitkrittum, Z. Szab\u00f3, and A. Gretton. An adaptive test of independence with analytic kernel embeddings. In ICML. 2017a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=W.%20Jitkrittum%2C%20Z.%20Szab%C3%B3%20Gretton%2C%20A.%20An%20adaptive%20test%20of%20independence%20with%20analytic%20kernel%20embeddings%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=W.%20Jitkrittum%2C%20Z.%20Szab%C3%B3%20Gretton%2C%20A.%20An%20adaptive%20test%20of%20independence%20with%20analytic%20kernel%20embeddings%202017"
        },
        {
            "id": "Jitkrittum_et+al_2017_a",
            "entry": "W. Jitkrittum, W. Xu, Z. Szabo, K. Fukumizu, and A. Gretton. A linear-time kernel goodness-of-fit test. In NIPS, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jitkrittum%2C%20W.%20Xu%2C%20W.%20Szabo%2C%20Z.%20Fukumizu%2C%20K.%20A%20linear-time%20kernel%20goodness-of-fit%20test%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jitkrittum%2C%20W.%20Xu%2C%20W.%20Szabo%2C%20Z.%20Fukumizu%2C%20K.%20A%20linear-time%20kernel%20goodness-of-fit%20test%202017"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. ArXiv e-prints, Dec. 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization.%20ArXiv%20e-prints%202014-12"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Hinton%2C%20G.%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Lintusaari_et+al_2017_a",
            "entry": "J. Lintusaari, M. Gutmann, R. Dutta, S. Kaski, and J. Corander. Fundamentals and recent developments in approximate bayesian computation. Systematic Biology, 66(1):e66\u2013e82, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lintusaari%2C%20J.%20Gutmann%2C%20M.%20Dutta%2C%20R.%20Kaski%2C%20S.%20Fundamentals%20and%20recent%20developments%20in%20approximate%20bayesian%20computation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lintusaari%2C%20J.%20Gutmann%2C%20M.%20Dutta%2C%20R.%20Kaski%2C%20S.%20Fundamentals%20and%20recent%20developments%20in%20approximate%20bayesian%20computation%202017"
        },
        {
            "id": "Liu_et+al_2016_a",
            "entry": "Q. Liu, J. Lee, and M. Jordan. A kernelized Stein discrepancy for goodness-of-fit tests. In ICML, pages 276\u2013284, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Q.%20Lee%2C%20J.%20Jordan%2C%20M.%20A%20kernelized%20Stein%20discrepancy%20for%20goodness-of-fit%20tests%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Q.%20Lee%2C%20J.%20Jordan%2C%20M.%20A%20kernelized%20Stein%20discrepancy%20for%20goodness-of-fit%20tests%202016"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "Lloyd_2015_a",
            "entry": "J. R. Lloyd and Z. Ghahramani. Statistical model criticism using kernel two sample tests. In NIPS, pages 829\u2013837, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lloyd%2C%20J.R.%20Ghahramani%2C%20Z.%20Statistical%20model%20criticism%20using%20kernel%20two%20sample%20tests%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lloyd%2C%20J.R.%20Ghahramani%2C%20Z.%20Statistical%20model%20criticism%20using%20kernel%20two%20sample%20tests%202015"
        },
        {
            "id": "Mao_et+al_2017_a",
            "entry": "X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. P. Smolley. Least squares generative adversarial networks. In Computer Vision (ICCV), 2017 IEEE International Conference on, pages 2813\u20132821. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mao%2C%20X.%20Li%2C%20Q.%20Xie%2C%20H.%20Lau%2C%20R.Y.%20Least%20squares%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mao%2C%20X.%20Li%2C%20Q.%20Xie%2C%20H.%20Lau%2C%20R.Y.%20Least%20squares%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Nowozin_et+al_2016_a",
            "entry": "S. Nowozin, B. Cseke, and R. Tomioka. f-GAN: Training generative neural samplers using variational divergence minimization. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nowozin%2C%20S.%20Cseke%2C%20B.%20Tomioka%2C%20R.%20f-GAN%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nowozin%2C%20S.%20Cseke%2C%20B.%20Tomioka%2C%20R.%20f-GAN%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016"
        },
        {
            "id": "Radford_et+al_2015_a",
            "entry": "A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "Rosenbaum_2005_a",
            "entry": "P. Rosenbaum. An exact distribution-free test comparing two multivariate distributions based on adjacency. Journal of the Royal Statistical Society B, 67(4):515\u2013530, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosenbaum%2C%20P.%20An%20exact%20distribution-free%20test%20comparing%20two%20multivariate%20distributions%20based%20on%20adjacency%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosenbaum%2C%20P.%20An%20exact%20distribution-free%20test%20comparing%20two%20multivariate%20distributions%20based%20on%20adjacency%202005"
        },
        {
            "id": "Salimans_et+al_2016_a",
            "entry": "T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved techniques for training GANs. ArXiv e-prints, June 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20T.%20Goodfellow%2C%20I.%20Zaremba%2C%20W.%20Cheung%2C%20V.%20Improved%20techniques%20for%20training%20GANs.%20ArXiv%20e-prints%202016-06"
        },
        {
            "id": "Serfling_2009_a",
            "entry": "R. J. Serfling. Approximation Theorems of Mathematical Statistics. John Wiley & Sons, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Serfling%2C%20R.J.%20Approximation%20Theorems%20of%20Mathematical%20Statistics%202009"
        },
        {
            "id": "Smola_et+al_2007_a",
            "entry": "A. Smola, A. Gretton, L. Song, and B. Sch\u00f6lkopf. A Hilbert space embedding for distributions. In International Conference on Algorithmic Learning Theory (ALT), pages 13\u201331, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smola%2C%20A.%20Gretton%2C%20A.%20Song%2C%20L.%20Sch%C3%B6lkopf%2C%20B.%20A%20Hilbert%20space%20embedding%20for%20distributions%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smola%2C%20A.%20Gretton%2C%20A.%20Song%2C%20L.%20Sch%C3%B6lkopf%2C%20B.%20A%20Hilbert%20space%20embedding%20for%20distributions%202007"
        },
        {
            "id": "Sriperumbudur_et+al_2011_a",
            "entry": "B. K. Sriperumbudur, K. Fukumizu, and G. R. G. Lanckriet. Universality, characteristic kernels and RKHS embedding of measures. Journal of Machine Learning Research, 12:2389\u20132410, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sriperumbudur%2C%20B.K.%20Fukumizu%2C%20K.%20Lanckriet%2C%20G.R.G.%20Universality%2C%20characteristic%20kernels%20and%20RKHS%20embedding%20of%20measures%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sriperumbudur%2C%20B.K.%20Fukumizu%2C%20K.%20Lanckriet%2C%20G.R.G.%20Universality%2C%20characteristic%20kernels%20and%20RKHS%20embedding%20of%20measures%202011"
        },
        {
            "id": "Srivastava_et+al_2017_a",
            "entry": "A. Srivastava, L. Valkov, C. Russell, M. U. Gutmann, and C. Sutton. VEEGAN: Reducing mode collapse in GANs using implicit variational learning. ArXiv e-prints, May 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20A.%20Valkov%2C%20L.%20Russell%2C%20C.%20Gutmann%2C%20M.U.%20VEEGAN%3A%20Reducing%20mode%20collapse%20in%20GANs%20using%20implicit%20variational%20learning.%20ArXiv%20e-prints%202017-05"
        },
        {
            "id": "Sutherland_et+al_2016_a",
            "entry": "D. J. Sutherland, H.-Y. Tung, H. Strathmann, S. De, A. Ramdas, A. Smola, and A. Gretton. Generative models and model criticism via optimized maximum mean discrepancy. In ICLR. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutherland%2C%20D.J.%20Tung%2C%20H.-Y.%20Strathmann%2C%20H.%20De%2C%20S.%20Generative%20models%20and%20model%20criticism%20via%20optimized%20maximum%20mean%20discrepancy.%20In%20ICLR%202016"
        },
        {
            "id": "Szegedy_et+al_2016_a",
            "entry": "C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2818\u20132826, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Vanhoucke%2C%20V.%20Ioffe%2C%20S.%20Shlens%2C%20J.%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20C.%20Vanhoucke%2C%20V.%20Ioffe%2C%20S.%20Shlens%2C%20J.%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016"
        },
        {
            "id": "Sz_2004_a",
            "entry": "G. Sz\u00e9kely and M. Rizzo. Testing for equal distributions in high dimension. InterStat, 5, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sz%C3%A9kely%2C%20G.%20Rizzo%2C%20M.%20Testing%20for%20equal%20distributions%20in%20high%20dimension%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sz%C3%A9kely%2C%20G.%20Rizzo%2C%20M.%20Testing%20for%20equal%20distributions%20in%20high%20dimension%202004"
        },
        {
            "id": "Sz_2005_a",
            "entry": "G. J. Sz\u00e9kely and M. L. Rizzo. A new test for multivariate normality. Journal of Multivariate Analysis, 93(1):58\u201380, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sz%C3%A9kely%2C%20G.J.%20Rizzo%2C%20M.L.%20A%20new%20test%20for%20multivariate%20normality%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sz%C3%A9kely%2C%20G.J.%20Rizzo%2C%20M.L.%20A%20new%20test%20for%20multivariate%20normality%202005"
        },
        {
            "id": "Yamada_et+al_2018_a",
            "entry": "M. Yamada, D. Wu, Y.-H. H. Tsai, I. Takeuchi, R. Salakhutdinov, and K. Fukumizu. Post selection inference with incomplete maximum mean discrepancy estimator. arXiv preprint arXiv:1802.06226, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.06226"
        }
    ]
}
