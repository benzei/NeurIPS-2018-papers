{
    "filename": "8270-autoconj-recognizing-and-exploiting-conjugacy-without-a-domain-specific-language.pdf",
    "metadata": {
        "title": "Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language",
        "author": "Matthew D. Hoffman",
        "date": 1999,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8270-autoconj-recognizing-and-exploiting-conjugacy-without-a-domain-specific-language.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Deriving conditional and marginal distributions using conjugacy relationships can be time consuming and error prone. In this paper, we propose a strategy for automating such derivations. Unlike previous systems which focus on relationships between pairs of random variables, our system (which we call Autoconj) operates directly on Python functions that compute log-joint distribution functions. Autoconj provides support for conjugacy-exploiting algorithms in any Pythonembedded PPL. This paves the way for accelerating development of novel inference algorithms and structure-exploiting modeling strategies."
    },
    "keywords": [
        {
            "term": "random variable",
            "url": "https://en.wikipedia.org/wiki/random_variable"
        },
        {
            "term": "evidence lower bound",
            "url": "https://en.wikipedia.org/wiki/evidence_lower_bound"
        },
        {
            "term": "Markov chain Monte Carlo",
            "url": "https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"
        },
        {
            "term": "exponential family",
            "url": "https://en.wikipedia.org/wiki/exponential_family"
        },
        {
            "term": "term rewriting",
            "url": "https://en.wikipedia.org/wiki/term_rewriting"
        },
        {
            "term": "variational inference",
            "url": "https://en.wikipedia.org/wiki/variational_inference"
        },
        {
            "term": "probabilistic programming language",
            "url": "https://en.wikipedia.org/wiki/probabilistic_programming_language"
        },
        {
            "term": "common subexpression elimination",
            "url": "https://en.wikipedia.org/wiki/common_subexpression_elimination"
        }
    ],
    "highlights": [
        "Exponential Families and Conjugacy<br/><br/>To develop a system that can automatically find and exploit conjugacy, we first develop a general perspective on exponential families",
        "If we had code for evaluating the functions g and {tzm }, along with a table of log-normalizer functions Azm corresponding to each tractable statistic tzm , we could use automatic differentiation to write a generic block coordinate-ascent variational inference algorithm",
        "The main novelty here is the application domain and specific concerns and capabilities that arise from it; we\u2019re manipulating exponential families of densities for multidimensional random variables, and our system is focused on matrix and tensor manipulations, which have limited support in other systems, and a specific canonical form informed by structure-exploiting approximate inference algorithms",
        "We demonstrate how one can implement the Kalman-filter recursion with Autoconj",
        "We proposed a strategy for automatically deriving conjugacy relationships",
        "Unlike previous systems which focus on relationships between pairs of random variables, Autoconj operates directly on Python functions that compute log-joint distribution functions"
    ],
    "key_statements": [
        "Exponential Families and Conjugacy<br/><br/>To develop a system that can automatically find and exploit conjugacy, we first develop a general perspective on exponential families",
        "If we had code for evaluating the functions g and {tzm }, along with a table of log-normalizer functions Azm corresponding to each tractable statistic tzm , we could use automatic differentiation to write a generic block coordinate-ascent variational inference algorithm",
        "The main novelty here is the application domain and specific concerns and capabilities that arise from it; we\u2019re manipulating exponential families of densities for multidimensional random variables, and our system is focused on matrix and tensor manipulations, which have limited support in other systems, and a specific canonical form informed by structure-exploiting approximate inference algorithms",
        "We demonstrate how one can implement the Kalman-filter recursion with Autoconj",
        "We proposed a strategy for automatically deriving conjugacy relationships",
        "Unlike previous systems which focus on relationships between pairs of random variables, Autoconj operates directly on Python functions that compute log-joint distribution functions"
    ],
    "summary": [
        "Exponential Families and Conjugacy<br/><br/>To develop a system that can automatically find and exploit conjugacy, we first develop a general perspective on exponential families.",
        "If asked to compute a marginal distribution, Autoconj returns a Python function that implements that marginal distribution\u2019s log-joint.",
        "This generic algorithm could be extended to work with any tractable exponential-family distribution by populating a table matching tractable statistics functions to their corresponding samplers.",
        "If we had code for evaluating the functions g and {tzm }, along with a table of log-normalizer functions Azm corresponding to each tractable statistic tzm , we could use automatic differentiation to write a generic block coordinate-ascent variational inference algorithm.",
        "It does this given log density functions written in plain Python and NumPy. And it reaps automatic structure-exploiting inference algorithms as a result.",
        "To extract sufficient statistics and natural parameters from a log-joint function, Autoconj first represent that function in a convenient canonical form.",
        "A tracer maps Python log-joint probability functions to symbolic term graphs; 2.",
        "The rewriting process aims to transform the term graph of a log joint density into the canonical sum-of-einsums polynomial form corresponding to Eq (3).",
        "Once we have processed the log-joint term graph into a canonical form, it is straightforward to extract the objects of interest, match the tractable statistics with corresponding log-normalizer and sampler functions from a table, and perform any further manipulations like automatic differentiation.",
        "The main novelty here is the application domain and specific concerns and capabilities that arise from it; we\u2019re manipulating exponential families of densities for multidimensional random variables, and our system is focused on matrix and tensor manipulations, which have limited support in other systems, and a specific canonical form informed by structure-exploiting approximate inference algorithms.",
        "Once the log-joint graph has been canonicalized as a sum of np.einsums of functions of the inputs, we can discover and extract exponential-family structure.",
        "One approach is to find a lower bound on the log-joint that is only a function of expected sufficient statistics of some exponential family (<a class=\"ref-link\" id=\"cJaakkola_1996_a\" href=\"#rJaakkola_1996_a\">Jaakkola and Jordan, 1996</a>; <a class=\"ref-link\" id=\"cBlei_2005_a\" href=\"#rBlei_2005_a\">Blei and Lafferty, 2005</a>).",
        "Autoconj naturally facilitates these strategies, since it does not require that the log-joint functions it is given exactly correspond to any true generative process.",
        "We can take a log-joint written in NumPy, extract complete conditionals or marginals from that model, and run the conditional or marginal computations in a TensorFlow graph.",
        "Unlike previous systems which focus on relationships between pairs of random variables, Autoconj operates directly on Python functions that compute log-joint distribution functions."
    ],
    "headline": "We propose a strategy for automating such derivations",
    "reference_links": [
        {
            "id": "Abadi_et+al_2016_a",
            "entry": "Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D. G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., and Zheng, X. (2016). Tensorflow: A system for large-scale machine learning. In Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI\u201916, pages 265\u2013283, Berkeley, CA, USA. USENIX Association.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016"
        },
        {
            "id": "Baader_1999_a",
            "entry": "Baader, F. and Nipkow, T. (1999). Term rewriting and all that. Cambridge University Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baader%2C%20F.%20Nipkow%2C%20T.%20Term%20rewriting%20and%20all%20that%201999"
        },
        {
            "id": "Blei_2005_a",
            "entry": "Blei, D. M. and Lafferty, J. D. (2005). Correlated topic models. In Proceedings of the 18th International Conference on Neural Information Processing Systems.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blei%2C%20D.M.%20Lafferty%2C%20J.D.%20Correlated%20topic%20models%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blei%2C%20D.M.%20Lafferty%2C%20J.D.%20Correlated%20topic%20models%202005"
        },
        {
            "id": "Carette_2016_a",
            "entry": "Carette, J. and Shan, C.-C. (2016). Simplifying probabilistic programs using computer algebra. In Gavanelli, M. and Reppy, J., editors, Practical Aspects of Declarative Languages, pages 135\u2013152, Cham. Springer International Publishing.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carette%2C%20J.%20Shan%2C%20C.-C.%20Simplifying%20probabilistic%20programs%20using%20computer%20algebra%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carette%2C%20J.%20Shan%2C%20C.-C.%20Simplifying%20probabilistic%20programs%20using%20computer%20algebra%202016"
        },
        {
            "id": "Cook_et+al_2006_a",
            "entry": "Cook, S. R., Gelman, A., and Rubin, D. B. (2006). Validation of software for bayesian models using posterior quantiles. Journal of Computational and Graphical Statistics, 15(3):675\u2013692.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cook%2C%20S.R.%20Gelman%2C%20A.%20Rubin%2C%20D.B.%20Validation%20of%20software%20for%20bayesian%20models%20using%20posterior%20quantiles%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cook%2C%20S.R.%20Gelman%2C%20A.%20Rubin%2C%20D.B.%20Validation%20of%20software%20for%20bayesian%20models%20using%20posterior%20quantiles%202006"
        },
        {
            "id": "Dempster_et+al_1977_a",
            "entry": "Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society. Series B (methodological), pages 1\u201338.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dempster%2C%20A.P.%20Laird%2C%20N.M.%20Rubin%2C%20D.B.%20Maximum%20likelihood%20from%20incomplete%20data%20via%20the%20em%20algorithm%201977",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dempster%2C%20A.P.%20Laird%2C%20N.M.%20Rubin%2C%20D.B.%20Maximum%20likelihood%20from%20incomplete%20data%20via%20the%20em%20algorithm%201977"
        },
        {
            "id": "Diehl_2013_a",
            "entry": "Diehl, S. (2013). Pyrewrite: Python term rewriting. Accessed: 2018-5-17.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diehl%2C%20S.%20Pyrewrite%3A%20Python%20term%20rewriting%202013"
        },
        {
            "id": "Gehr_et+al_2016_a",
            "entry": "Gehr, T., Misailovic, S., and Vechev, M. (2016). PSI: Exact symbolic inference for probabilistic programs. In International Conference on Computer Aided Verification, pages 62\u201383. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gehr%2C%20T.%20Misailovic%2C%20S.%20Vechev%2C%20M.%20PSI%3A%20Exact%20symbolic%20inference%20for%20probabilistic%20programs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gehr%2C%20T.%20Misailovic%2C%20S.%20Vechev%2C%20M.%20PSI%3A%20Exact%20symbolic%20inference%20for%20probabilistic%20programs%202016"
        },
        {
            "id": "Goodman_2014_a",
            "entry": "Goodman, N. D. and Stuhlm\u00fcller, A. (2014). The Design and Implementation of Probabilistic Programming Languages. http://dippl.org. Accessed:2018-5-17.",
            "url": "http://dippl.org"
        },
        {
            "id": "Griffiths_2004_a",
            "entry": "Griffiths, T. L. and Steyvers, M. (2004). Finding scientific topics. Proceedings of the National academy of Sciences, 101(suppl 1):5228\u20135235.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Griffiths%2C%20T.L.%20Steyvers%2C%20M.%20Finding%20scientific%20topics%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Griffiths%2C%20T.L.%20Steyvers%2C%20M.%20Finding%20scientific%20topics%202004"
        },
        {
            "id": "Hoffman_et+al_2013_a",
            "entry": "Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J. (2013). Stochastic variational inference. Journal of Machine Learning Research, 14:1303\u20131347.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20M.D.%20Blei%2C%20D.M.%20Wang%2C%20C.%20Paisley%2C%20J.%20Stochastic%20variational%20inference%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20M.D.%20Blei%2C%20D.M.%20Wang%2C%20C.%20Paisley%2C%20J.%20Stochastic%20variational%20inference%202013"
        },
        {
            "id": "Jaakkola_1996_a",
            "entry": "Jaakkola, T. and Jordan, M. (1996). A variational approach to Bayesian logistic regression models and their extensions. In International Workshop on Artificial Intelligence and Statistics, volume 82, page 4.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaakkola%2C%20T.%20Jordan%2C%20M.%20A%20variational%20approach%20to%20Bayesian%20logistic%20regression%20models%20and%20their%20extensions%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaakkola%2C%20T.%20Jordan%2C%20M.%20A%20variational%20approach%20to%20Bayesian%20logistic%20regression%20models%20and%20their%20extensions%201996"
        },
        {
            "id": "Jordan_et+al_1999_a",
            "entry": "Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., and Saul, L. K. (1999). An introduction to variational methods for graphical models. Machine learning, 37(2):183\u2013233.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jordan%2C%20M.I.%20Ghahramani%2C%20Z.%20Jaakkola%2C%20T.S.%20Saul%2C%20L.K.%20An%20introduction%20to%20variational%20methods%20for%20graphical%20models%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jordan%2C%20M.I.%20Ghahramani%2C%20Z.%20Jaakkola%2C%20T.S.%20Saul%2C%20L.K.%20An%20introduction%20to%20variational%20methods%20for%20graphical%20models%201999"
        },
        {
            "id": "Khan_et+al_2016_a",
            "entry": "Khan, M. E., Babanezhad, R., Lin, W., Schmidt, M., and Sugiyama, M. (2016). Faster stochastic variational inference using proximal-gradient methods with general divergence functions. In Conference on Uncertainty in Artificial Intelligence (UAI).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khan%2C%20M.E.%20Babanezhad%2C%20R.%20Lin%2C%20W.%20Schmidt%2C%20M.%20Faster%20stochastic%20variational%20inference%20using%20proximal-gradient%20methods%20with%20general%20divergence%20functions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khan%2C%20M.E.%20Babanezhad%2C%20R.%20Lin%2C%20W.%20Schmidt%2C%20M.%20Faster%20stochastic%20variational%20inference%20using%20proximal-gradient%20methods%20with%20general%20divergence%20functions%202016"
        },
        {
            "id": "Khan_et+al_2015_a",
            "entry": "Khan, M. E., Baqu\u00e9, P., Fleuret, F., and Fua, P. (2015). Kullback-leibler proximal variational inference. In Advances in Neural Information Processing Systems, pages 3402\u20133410.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khan%2C%20M.E.%20Baqu%C3%A9%2C%20P.%20Fleuret%2C%20F.%20Fua%2C%20P.%20Kullback-leibler%20proximal%20variational%20inference%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khan%2C%20M.E.%20Baqu%C3%A9%2C%20P.%20Fleuret%2C%20F.%20Fua%2C%20P.%20Kullback-leibler%20proximal%20variational%20inference%202015"
        },
        {
            "id": "Khan_2017_a",
            "entry": "Khan, M. E. and Wu, L. (2017). Conjugate-computation variational inference : Converting variational inference in non-conjugate models to inferences in conjugate models. In Artificial Intelligence and Statistics (AISTATS).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khan%2C%20M.E.%20Wu%2C%20L.%20Conjugate-computation%20variational%20inference%20%3A%20Converting%20variational%20inference%20in%20non-conjugate%20models%20to%20inferences%20in%20conjugate%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khan%2C%20M.E.%20Wu%2C%20L.%20Conjugate-computation%20variational%20inference%20%3A%20Converting%20variational%20inference%20in%20non-conjugate%20models%20to%20inferences%20in%20conjugate%20models%202017"
        },
        {
            "id": "Koller_2009_a",
            "entry": "Koller, D. and Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koller%2C%20D.%20Friedman%2C%20N.%20Probabilistic%20Graphical%20Models%3A%20Principles%20and%20Techniques%202009"
        },
        {
            "id": "Kucukelbir_et+al_2016_a",
            "entry": "Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and Blei, D. M. (2016). Automatic differentiation variational inference. arXiv preprint arXiv:1603.00788.",
            "arxiv_url": "https://arxiv.org/pdf/1603.00788"
        },
        {
            "id": "Maclaurin_et+al_2014_a",
            "entry": "Maclaurin, D., Duvenaud, D., Johnson, M., and Adams, R. P. (2014). Autograd: Reverse-mode differentiation of native Python. Accessed: 2018-5-17.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maclaurin%2C%20D.%20Duvenaud%2C%20D.%20Johnson%2C%20M.%20Adams%2C%20R.P.%20Autograd%3A%20Reverse-mode%20differentiation%20of%20native%20Python%202014"
        },
        {
            "id": "Murray_2018_a",
            "entry": "Murray, L. M., Lund\u00e9n, D., Kudlicka, J., Broman, D., and Sch\u00f6n, T. B. (2018). Delayed sampling and automatic rao-blackwellization of probabilistic programs. In Artificial Intelligence and Statistics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Delayed%20sampling%20and%20automatic%20rao-blackwellization%20of%20probabilistic%20programs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Delayed%20sampling%20and%20automatic%20rao-blackwellization%20of%20probabilistic%20programs%202018"
        },
        {
            "id": "Narayanan_et+al_2016_a",
            "entry": "Narayanan, P., Carette, J., Romano, W., Shan, C.-c., and Zinkov, R. (2016). Probabilistic inference by program transformation in hakaru (system description). In Kiselyov, O. and King, A., editors, Functional and Logic Programming, pages 62\u201379, Cham. Springer International Publishing.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Narayanan%2C%20P.%20Carette%2C%20J.%20Romano%2C%20W.%20Shan%2C%20C.-c%20Probabilistic%20inference%20by%20program%20transformation%20in%20hakaru%20%28system%20description%29%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Narayanan%2C%20P.%20Carette%2C%20J.%20Romano%2C%20W.%20Shan%2C%20C.-c%20Probabilistic%20inference%20by%20program%20transformation%20in%20hakaru%20%28system%20description%29%202016"
        },
        {
            "id": "Narayanan_2017_a",
            "entry": "Narayanan, P. and Shan, C.-c. (2017). Symbolic conditioning of arrays in probabilistic programs. Proceedings of the ACM on Programming Languages, 1(ICFP):11.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Narayanan%2C%20P.%20Shan%2C%20C.-c%20Symbolic%20conditioning%20of%20arrays%20in%20probabilistic%20programs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Narayanan%2C%20P.%20Shan%2C%20C.-c%20Symbolic%20conditioning%20of%20arrays%20in%20probabilistic%20programs%202017"
        },
        {
            "id": "Radul_2013_a",
            "entry": "Radul, A. (2013). Rules: An extensible pattern matching, pattern dispatch, and term rewriting system for MIT Scheme. Accessed: 2018-5-17.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radul%2C%20A.%20Rules%3A%20An%20extensible%20pattern%20matching%2C%20pattern%20dispatch%2C%20and%20term%20rewriting%20system%20for%20MIT%20Scheme%202013"
        },
        {
            "id": "Rozenberg_1997_a",
            "entry": "Rozenberg, G. (1997). Handbook of Graph Grammars and Comp., volume 1. World scientific.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rozenberg%2C%20G.%20Handbook%20of%20Graph%20Grammars%20and%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rozenberg%2C%20G.%20Handbook%20of%20Graph%20Grammars%20and%201997"
        },
        {
            "id": "Spiegelhalter_et+al_1995_a",
            "entry": "Spiegelhalter, D. J., Thomas, A., Best, N. G., and Gilks, W. R. (1995). BUGS: Bayesian inference using Gibbs sampling, version 0.50. MRC Biostatistics Unit, Cambridge.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spiegelhalter%2C%20D.J.%20Thomas%2C%20A.%20Best%2C%20N.G.%20Gilks%2C%20W.R.%20BUGS%3A%20Bayesian%20inference%20using%20Gibbs%20sampling%2C%20version%200.50%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Spiegelhalter%2C%20D.J.%20Thomas%2C%20A.%20Best%2C%20N.G.%20Gilks%2C%20W.R.%20BUGS%3A%20Bayesian%20inference%20using%20Gibbs%20sampling%2C%20version%200.50%201995"
        },
        {
            "id": "Sussman_et+al_2018_a",
            "entry": "Sussman, G. J., Abelson, H., Wisdom, J., Katzenelson, J., Mayer, H., Hanson, C. P., Halfant, M., Siebert, B., Rozas, G. J., Skordos, P., Koniaris, K., Lin, K., and Zuras, D. (2018). SCMUTILS. Accessed: 2018-5-17.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sussman%20G%20J%20Abelson%20H%20Wisdom%20J%20Katzenelson%20J%20Mayer%20H%20Hanson%20C%20P%20Halfant%20M%20Siebert%20B%20Rozas%20G%20J%20Skordos%20P%20Koniaris%20K%20Lin%20K%20and%20Zuras%20D%202018%20SCMUTILS%20Accessed%202018517"
        },
        {
            "id": "Tran_et+al_2018_a",
            "entry": "Tran, D., Hoffman, M. D., Moore, D., Suter, C., Vasudevan, S., Radul, A., Johnson, M., and Saurous, R. A. (2018). Simple, distributed, and accelerated probabilistic programming. In Neural Information Processing Systems.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tran%2C%20D.%20Hoffman%2C%20M.D.%20Moore%2C%20D.%20Suter%2C%20C.%20Simple%2C%20distributed%2C%20and%20accelerated%20probabilistic%20programming%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tran%2C%20D.%20Hoffman%2C%20M.D.%20Moore%2C%20D.%20Suter%2C%20C.%20Simple%2C%20distributed%2C%20and%20accelerated%20probabilistic%20programming%202018"
        },
        {
            "id": "Tristan_et+al_2014_a",
            "entry": "Tristan, J.-B., Huang, D., Tassarotti, J., Pocock, A. C., Green, S., and Steele, G. L. (2014). Augur: Data-parallel probabilistic modeling. In Neural Information Processing Systems.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tristan%2C%20J.-B.%20Huang%2C%20D.%20Tassarotti%2C%20J.%20Pocock%2C%20A.C.%20Augur%3A%20Data-parallel%20probabilistic%20modeling%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tristan%2C%20J.-B.%20Huang%2C%20D.%20Tassarotti%2C%20J.%20Pocock%2C%20A.C.%20Augur%3A%20Data-parallel%20probabilistic%20modeling%202014"
        },
        {
            "id": "Wainwright_2008_a",
            "entry": "Wainwright, M. J. and Jordan, M. I. (2008). Graphical models, exponential families, and variational inference. Found. Trends Mach. Learn., 1(1-2):1\u2013305.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wainwright%2C%20M.J.%20Jordan%2C%20M.I.%20Graphical%20models%2C%20exponential%20families%2C%20and%20variational%20inference%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wainwright%2C%20M.J.%20Jordan%2C%20M.I.%20Graphical%20models%2C%20exponential%20families%2C%20and%20variational%20inference%202008"
        },
        {
            "id": "Winn_2005_a",
            "entry": "Winn, J. and Bishop, C. M. (2005). Variational message passing. Journal of Machine Learning Research, 6(Apr):661\u2013694.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Winn%2C%20J.%20Bishop%2C%20C.M.%20Variational%20message%20passing%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Winn%2C%20J.%20Bishop%2C%20C.M.%20Variational%20message%20passing%202005"
        }
    ]
}
