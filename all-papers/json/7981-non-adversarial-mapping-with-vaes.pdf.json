{
    "filename": "7981-non-adversarial-mapping-with-vaes.pdf",
    "metadata": {
        "title": "Non-Adversarial Mapping with VAEs",
        "author": "Yedid Hoshen",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7981-non-adversarial-mapping-with-vaes.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "The study of cross-domain mapping without supervision has recently attracted much attention. Much of the recent progress was enabled by the use of adversarial training as well as cycle constraints. The practical difficulty of adversarial training motivates research into non-adversarial methods. In a recent paper, it was shown that cross-domain mapping is possible without the use of cycles or GANs. Although promising, this approach suffers from several drawbacks including costly inference and an optimization variable for every training example preventing the method from using large training sets. We present an alternative approach which is able to achieve non-adversarial mapping using a novel form of Variational Auto-Encoder. Our method is much faster at inference time, is able to leverage large datasets and has a simple interpretation."
    },
    "keywords": [
        {
            "term": "auto encoder",
            "url": "https://en.wikipedia.org/wiki/auto_encoder"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "analogy",
            "url": "https://en.wikipedia.org/wiki/analogy"
        }
    ],
    "highlights": [
        "Non-Adversarial Mapping attempts to learn two sets of variables, i) weights of mapping function TXY () ii) latent code zy for every training sample y",
        "The protocal consists of mapping images from MNIST to SVHN and are classified by a pre-trained SVHN classification network",
        "VAE-Non-Adversarial Mapping has some relation to CoGAN and UNIT, which assume that analogous images in the X and Y domains share the same latent code",
        "We presented VAE-Non-Adversarial Mapping, a method for learning to map across image domains without supervision",
        "The model parameterizes the latent space, and multiple analogies that can arise from a single input sample",
        "VAE-Non-Adversarial Mapping is shown to be better at using large datasets than Non-Adversarial Mapping, is simpler to train, generally converges to better solutions and is much faster at evaluation time"
    ],
    "key_statements": [
        "Non-Adversarial Mapping attempts to learn two sets of variables, i) weights of mapping function TXY () ii) latent code zy for every training sample y",
        "In this paper we present a new method VAE-Non-Adversarial Mapping, which overcomes the aforementioned issues with Non-Adversarial Mapping",
        "Non-Adversarial Mapping has significant advantages over other methods: it does not use adversarial training for learning a mapping, the mapping can be one to many and multiple solutions can be obtained for a single input image",
        "To address the variability issue suffered by AE-Non-Adversarial Mapping we present our final approach: VAE-Non-Adversarial Mapping",
        "We evaluate the proposed VAE-Non-Adversarial Mapping against Non-Adversarial Mapping, which is at present the only unsupervised cross-domain mapping method that does not use adversarial training",
        "The protocal consists of mapping images from MNIST to SVHN and are classified by a pre-trained SVHN classification network",
        "Exploring the latent space parametrized by \u03c32(y): VAE-Non-Adversarial Mapping finds a Gaussian probability distribution of X domain analogies",
        "VAE-Non-Adversarial Mapping has some relation to CoGAN and UNIT, which assume that analogous images in the X and Y domains share the same latent code",
        "We presented VAE-Non-Adversarial Mapping, a method for learning to map across image domains without supervision",
        "The model parameterizes the latent space, and multiple analogies that can arise from a single input sample",
        "VAE-Non-Adversarial Mapping is shown to be better at using large datasets than Non-Adversarial Mapping, is simpler to train, generally converges to better solutions and is much faster at evaluation time"
    ],
    "summary": [
        "NAM attempts to learn two sets of variables, i) weights of mapping function TXY () ii) latent code zy for every training sample y.",
        "Ii) NAM does not have a forward encoder, mapping a sample y to its X domain analogy.",
        "UNIT learns a Variational Auto-encoder (VAE) [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>] for each of the domains and adversarially ensures that both share the same latent space.",
        "NAM [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] is a recent method for unsupervised mapping across image domains.",
        "If a set of X domain training images was given as input, NAM assumes it is used to train a parametric unconditional generative model G(z) by some other method.",
        "NAM does not specify requirements on this method as long as the resulting model satisfies: i) compactness: for every allowed set of parameters z, the generated image G(z) lies within the X domain.",
        "NAM has significant advantages over other methods: it does not use adversarial training for learning a mapping, the mapping can be one to many and multiple solutions can be obtained for a single input image.",
        "From NAM, VAE-NAM does not directly estimate a latent code for each training image independently.",
        "VAE-NAM encodes every Y domain image y into a distribution of latent codes P rather than just a single deterministic transformation.",
        "VAEs model p(y|z) as a neural network decoder D(), mapping latent code z to reconstruct the original image y = D(z).",
        "We evaluate the proposed VAE-NAM against NAM, which is at present the only unsupervised cross-domain mapping method that does not use adversarial training.",
        "Exploring the latent space parametrized by \u03c32(y): VAE-NAM finds a Gaussian probability distribution of X domain analogies.",
        "Our method VAE-NAM presented a new interpretation for cross-domain mapping.",
        "The encoder E(y) maps the Y domain image into the pre-trained latent space of X .",
        "VAE-NAM has some relation to CoGAN and UNIT, which assume that analogous images in the X and Y domains share the same latent code.",
        "The success of VAE-NAM suggests that the main component required for unsupervised cross-domain mapping is a strong domain prior.",
        "For every new domain Y, the agent will train a VAE, with the decoder factorized by the known generative model GX (), and a learned mapping function TXY .",
        "We presented VAE-NAM, a method for learning to map across image domains without supervision.",
        "From NAM, it uses a parametric stochastic function to map input samples to latent codes, rather than learning the latent code by direct optimization.",
        "VAE-NAM is shown to be better at using large datasets than NAM, is simpler to train, generally converges to better solutions and is much faster at evaluation time"
    ],
    "headline": "We present an alternative approach which is able to achieve non-adversarial mapping using a novel form of Variational Auto-Encoder",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Yedid Hoshen and Lior Wolf. Identifying analogies across domains. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoshen%2C%20Yedid%20Wolf%2C%20Lior%20Identifying%20analogies%20across%20domains%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoshen%2C%20Yedid%20Wolf%2C%20Lior%20Identifying%20analogies%20across%20domains%202018"
        },
        {
            "id": "2",
            "entry": "[2] Yedid Hoshen and Lior Wolf. Nam - unsupervised cross-domain image mapping without cycles or gans. In ICLR Workshop, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoshen%2C%20Yedid%20Wolf%2C%20Lior%20Nam%20-%20unsupervised%20cross-domain%20image%20mapping%20without%20cycles%20or%20gans%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoshen%2C%20Yedid%20Wolf%2C%20Lior%20Nam%20-%20unsupervised%20cross-domain%20image%20mapping%20without%20cycles%20or%20gans%202018"
        },
        {
            "id": "3",
            "entry": "[3] Yedid Hoshen and Lior Wolf. Nam: Non-adversarial unsupervised domain mapping. In ECCV, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoshen%2C%20Yedid%20Wolf%2C%20Lior%20Nam%3A%20Non-adversarial%20unsupervised%20domain%20mapping%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoshen%2C%20Yedid%20Wolf%2C%20Lior%20Nam%3A%20Non-adversarial%20unsupervised%20domain%20mapping%202018"
        },
        {
            "id": "4",
            "entry": "[4] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "5",
            "entry": "[5] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris Metaxas. Stackgan++: Realistic image synthesis with stacked generative adversarial networks. arXiv: 1710.10916, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10916"
        },
        {
            "id": "6",
            "entry": "[6] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10196"
        },
        {
            "id": "7",
            "entry": "[7] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "8",
            "entry": "[8] Erik G Miller, Nicholas E Matsakis, and Paul A Viola. Learning from one example through shared densities on transforms. In CVPR, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miller%2C%20Erik%20G.%20Matsakis%2C%20Nicholas%20E.%20Viola%2C%20Paul%20A.%20Learning%20from%20one%20example%20through%20shared%20densities%20on%20transforms%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miller%2C%20Erik%20G.%20Matsakis%2C%20Nicholas%20E.%20Viola%2C%20Paul%20A.%20Learning%20from%20one%20example%20through%20shared%20densities%20on%20transforms%202000"
        },
        {
            "id": "9",
            "entry": "[9] Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jungkwon Lee, and Jiwon Kim. Learning to discover cross-domain relations with generative adversarial networks. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Taeksoo%20Cha%2C%20Moonsu%20Kim%2C%20Hyunsoo%20Lee%2C%20Jungkwon%20Learning%20to%20discover%20cross-domain%20relations%20with%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Taeksoo%20Cha%2C%20Moonsu%20Kim%2C%20Hyunsoo%20Lee%2C%20Jungkwon%20Learning%20to%20discover%20cross-domain%20relations%20with%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "10",
            "entry": "[10] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20Efros%2C%20Alexei%20A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20Efros%2C%20Alexei%20A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017"
        },
        {
            "id": "11",
            "entry": "[11] Zili Yi, Hao Zhang, Ping Tan, and Minglun Gong. Dualgan: Unsupervised dual learning for image-to-image translation. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yi%2C%20Zili%20Zhang%2C%20Hao%20Tan%2C%20Ping%20Gong%2C%20Minglun%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-to-image%20translation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yi%2C%20Zili%20Zhang%2C%20Hao%20Tan%2C%20Ping%20Gong%2C%20Minglun%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-to-image%20translation%202017"
        },
        {
            "id": "12",
            "entry": "[12] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Stargan: Unified generative adversarial networks for multi-domain image-to-image translation. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Yunjey%20Choi%2C%20Minje%20Kim%2C%20Munyoung%20Ha%2C%20Jung-Woo%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Yunjey%20Choi%2C%20Minje%20Kim%2C%20Munyoung%20Ha%2C%20Jung-Woo%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018"
        },
        {
            "id": "13",
            "entry": "[13] Yedid Hoshen and Lior Wolf. An iterative closest point method for unsupervised word translation. arXiv preprint arXiv:1801.06126, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.06126"
        },
        {
            "id": "14",
            "entry": "[14] Ming-Yu Liu and Oncel Tuzel. Coupled generative adversarial networks. In NIPS. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ming-Yu%20Tuzel%2C%20Oncel%20Coupled%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Tuzel%2C%20Oncel%20Coupled%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "15",
            "entry": "[15] Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised image-to-image translation networks. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "16",
            "entry": "[16] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "17",
            "entry": "[17] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein gan. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martin%20Arjovsky%20Soumith%20Chintala%20and%20L%C3%A9on%20Bottou%20Wasserstein%20gan%20In%20ICLR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martin%20Arjovsky%20Soumith%20Chintala%20and%20L%C3%A9on%20Bottou%20Wasserstein%20gan%20In%20ICLR%202017"
        },
        {
            "id": "18",
            "entry": "[18] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017"
        },
        {
            "id": "19",
            "entry": "[19] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miyato%2C%20Takeru%20Kataoka%2C%20Toshiki%20Koyama%2C%20Masanori%20Yoshida%2C%20Yuichi%20Spectral%20normalization%20for%20generative%20adversarial%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miyato%2C%20Takeru%20Kataoka%2C%20Toshiki%20Koyama%2C%20Masanori%20Yoshida%2C%20Yuichi%20Spectral%20normalization%20for%20generative%20adversarial%20networks%202018"
        },
        {
            "id": "20",
            "entry": "[20] Piotr Bojanowski, Armand Joulin, David Lopez-Paz, and Arthur Szlam. Optimizing the latent space of generative networks. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojanowski%2C%20Piotr%20Joulin%2C%20Armand%20Lopez-Paz%2C%20David%20Szlam%2C%20Arthur%20Optimizing%20the%20latent%20space%20of%20generative%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bojanowski%2C%20Piotr%20Joulin%2C%20Armand%20Lopez-Paz%2C%20David%20Szlam%2C%20Arthur%20Optimizing%20the%20latent%20space%20of%20generative%20networks%202018"
        },
        {
            "id": "21",
            "entry": "[21] Qifeng Chen and Vladlen Koltun. Photographic image synthesis with cascaded refinement networks. ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Qifeng%20Koltun%2C%20Vladlen%20Photographic%20image%20synthesis%20with%20cascaded%20refinement%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Qifeng%20Koltun%2C%20Vladlen%20Photographic%20image%20synthesis%20with%20cascaded%20refinement%20networks%202017"
        },
        {
            "id": "22",
            "entry": "[22] Sagie Benaim and Lior Wolf. One-sided unsupervised domain mapping. In NIPS. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Benaim%2C%20Sagie%20Wolf%2C%20Lior%20One-sided%20unsupervised%20domain%20mapping%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Benaim%2C%20Sagie%20Wolf%2C%20Lior%20One-sided%20unsupervised%20domain%20mapping%202017"
        },
        {
            "id": "23",
            "entry": "[23] Aron Yu and Kristen Grauman. Fine-grained visual comparisons with local learning. In CVPR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20Aron%20Grauman%2C%20Kristen%20Fine-grained%20visual%20comparisons%20with%20local%20learning%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20Aron%20Grauman%2C%20Kristen%20Fine-grained%20visual%20comparisons%20with%20local%20learning%202014"
        },
        {
            "id": "24",
            "entry": "[24] Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schoelkopf. Wasserstein autoencoders. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tolstikhin%2C%20Ilya%20Bousquet%2C%20Olivier%20Gelly%2C%20Sylvain%20Schoelkopf%2C%20Bernhard%20Wasserstein%20autoencoders%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tolstikhin%2C%20Ilya%20Bousquet%2C%20Olivier%20Gelly%2C%20Sylvain%20Schoelkopf%2C%20Bernhard%20Wasserstein%20autoencoders%202018"
        },
        {
            "id": "25",
            "entry": "[25] Otto Fabius and Joost R van Amersfoort. Variational recurrent auto-encoders. In ICLR Workshop, 2014. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fabius%2C%20Otto%20van%20Amersfoort%2C%20Joost%20R.%20Variational%20recurrent%20auto-encoders%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fabius%2C%20Otto%20van%20Amersfoort%2C%20Joost%20R.%20Variational%20recurrent%20auto-encoders%202014"
        }
    ]
}
