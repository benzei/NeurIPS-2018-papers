{
    "filename": "8009-distributed-k-clustering-for-data-with-heavy-noise.pdf",
    "metadata": {
        "title": "Distributed $k$-Clustering for Data with Heavy Noise",
        "author": "Shi Li, Xiangyu Guo",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8009-distributed-k-clustering-for-data-with-heavy-noise.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In this paper, we consider the k-center/median/means clustering with outliers problems (or the (k, z)-center/median/means problems) in the distributed setting. Most previous distributed algorithms have their communication costs linearly depending on z, the number of outliers. Recently Guha et al. [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] overcame this dependence issue by considering bi-criteria approximation algorithms that output solutions with 2z outliers. For the case where z is large, the extra z outliers discarded by the algorithms might be too large, considering that the data gathering process might be costly. In this paper, we improve the number of outliers to the best possible (1 + )z, while maintaining the O(1)-approximation ratio and independence of communication cost on z. The problems we consider include the (k, z)-center problem, and (k, z)-median/means problems in Euclidean metrics. Implementation of the our algorithm for (k, z)-center shows that it outperforms many previous algorithms, both in terms of the communication cost and quality of the output solution."
    },
    "keywords": [
        {
            "term": "approximation algorithm",
            "url": "https://en.wikipedia.org/wiki/approximation_algorithm"
        },
        {
            "term": "approximation ratio",
            "url": "https://en.wikipedia.org/wiki/approximation_ratio"
        },
        {
            "term": "optimization problem",
            "url": "https://en.wikipedia.org/wiki/optimization_problem"
        }
    ],
    "highlights": [
        "Clustering is a fundamental problem in unsupervised learning and data analytics",
        "Even deciding whether the optimum clustering with z outliers has cost 0 or not, for a dataset distributed on 2 machines, requires a communication cost of \u03a9(z) bits",
        "Our main contributions are in designing (O(1), 1 + )-bicriteria approximation algorithms for the (k, z)-center/median/means problems",
        "For (k, z)-median/means problems, our algorithm works for the Euclidean metric case and has communication cost depending on the dimension D of the Euclidean space",
        "For the (k, z)-median/means problem, we give a distributed (1 + , 1 + )-bicriteria approximation algorithm with communication cost O \u03a6D \u00b7 log \u2206 , where \u03a6 is the upper bound on the size of the coreset constructed using the algorithm of [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "Since the approximation ratio for this problem will go to both factors in the bicriteria ratio, we really need a (1 + )-approximation for the optimization problem"
    ],
    "key_statements": [
        "Clustering is a fundamental problem in unsupervised learning and data analytics",
        "Even deciding whether the optimum clustering with z outliers has cost 0 or not, for a dataset distributed on 2 machines, requires a communication cost of \u03a9(z) bits",
        "Our main contributions are in designing (O(1), 1 + )-bicriteria approximation algorithms for the (k, z)-center/median/means problems",
        "For (k, z)-median/means problems, our algorithm works for the Euclidean metric case and has communication cost depending on the dimension D of the Euclidean space",
        "For the (k, z)-median/means problem, we give a distributed (1 + , 1 + )-bicriteria approximation algorithm with communication cost O \u03a6D \u00b7 log \u2206 , where \u03a6 is the upper bound on the size of the coreset constructed using the algorithm of [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "Since the approximation ratio for this problem will go to both factors in the bicriteria ratio, we really need a (1 + )-approximation for the optimization problem"
    ],
    "summary": [
        "Clustering is a fundamental problem in unsupervised learning and data analytics.",
        "Guha et al [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] overcame the linear dependence issue, by giving distributed O(1)approximation algorithms for k-center/median/means with outliers problems with communication cost independent of z.",
        "Given such a negative result and the positive results of Guha et al [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], the following question is interesting from both the practical and theoretical points of view: Can we obtain distributed O(1)-approximation algorithms for k-center/median/means with outliers that have communication cost independent of z and output solutions with (1 + )z outliers, for any",
        "For the k-center objective, we solve the problem completely by giving a (24(1 + ), 1 + )-bicriteria approximation algorithm with communication cost O km \u00b7 log \u2206 , where \u2206 is the aspect ratio of the metric.",
        "For (k, z)-center/median/means problems, most known algorithms have communication complexity linearly depending on z, the number of outliers.",
        "Our main contributions are in designing (O(1), 1 + )-bicriteria approximation algorithms for the (k, z)-center/median/means problems.",
        "There is a 4-round, distributed algorithm for the (k, z)-center problem, that achieves a (24(1 + ), 1 + )-bicriteria approximation and O km \u00b7 log \u2206 communication cost, where \u2206 is the aspect ratio of the metric.",
        "For (k, z)-median/means problems, our algorithm works for the Euclidean metric case and has communication cost depending on the dimension D of the Euclidean space.",
        "There is a 2-round, distributed algorithm for the (k, z)-median/means problems in D-dimensional Euclidean space, that achieves a (1 + , 1 + )-bicriteria approximation ratio with probability 1 \u2212 \u03b4.",
        "We prove Theorem 1.1, by giving the (24(1 + ), 1 + )-approximation algorithm for (k, z)-center, with communication cost O km \u00b7 log \u2206 .",
        "Let zi = |Pi \u2229 O| = Pi \\ c\u2208C\u2217 ballPi (c, L) be the set of outliers in Pi. C\u2217 is a (k, zi)-center solution to the instance Pi with cost at most L.",
        "We give a distributed (24(1 + ), 1 + )-bicriteria approximation for the (k, z)-center problem, with communication cost O km \u00b7 log \u2206 .",
        "For the (k, z)-median/means problem, we give a distributed (1 + , 1 + )-bicriteria approximation algorithm with communication cost O \u03a6D \u00b7 log \u2206 , where \u03a6 is the upper bound on the size of the coreset constructed using the algorithm of [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>].",
        "The central coordinator needs to solve the optimization problem of finding a solution that is simultaneously good for O log(\u2206n/ ) k-median/means instances.",
        "It is interesting to study if a different approach can lead to a polynomial time distributed algorithm with O(1)-approximation guarantee"
    ],
    "headline": "Even deciding whether the optimum clustering with z outliers has cost 0 or not, for a dataset distributed on 2 machines, requires a communication cost of \u03a9 bits",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sara Ahmadian, Ashkan Norouzi-Fard, Ola Svensson, and Justin Ward. Better guarantees for k-means and euclidean k-median by primal-dual algorithms. In 58th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2017, Berkeley, CA, USA, October 15-17, 2017, pages 61\u201372, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahmadian%2C%20Sara%20Norouzi-Fard%2C%20Ashkan%20Svensson%2C%20Ola%20Ward%2C%20Justin%20Better%20guarantees%20for%20k-means%20and%20euclidean%20k-median%20by%20primal-dual%20algorithms%202017-10-15",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahmadian%2C%20Sara%20Norouzi-Fard%2C%20Ashkan%20Svensson%2C%20Ola%20Ward%2C%20Justin%20Better%20guarantees%20for%20k-means%20and%20euclidean%20k-median%20by%20primal-dual%20algorithms%202017-10-15"
        },
        {
            "id": "2",
            "entry": "[2] Maria-Florina Balcan, Steven Ehrlich, and Yingyu Liang. Distributed k-means and k-median clustering on general communication topologies. In Advances in Neural Information Processing Systems 26, NIPS 2013, December 5-8, 2013, Lake Tahoe, Nevada, United States., pages 1995\u20132003, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20Maria-Florina%20Ehrlich%2C%20Steven%20Liang%2C%20Yingyu%20Distributed%20k-means%20and%20k-median%20clustering%20on%20general%20communication%20topologies%202013-12-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20Maria-Florina%20Ehrlich%2C%20Steven%20Liang%2C%20Yingyu%20Distributed%20k-means%20and%20k-median%20clustering%20on%20general%20communication%20topologies%202013-12-05"
        },
        {
            "id": "3",
            "entry": "[3] Jaroslaw Byrka, Thomas Pensyl, Bartosz Rybicki, Aravind Srinivasan, and Khoa Trinh. An improved approximation for k-median and positive correlation in budgeted optimization. ACM Trans. Algorithms, 13(2):23:1\u201323:31, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Byrka%2C%20Jaroslaw%20Pensyl%2C%20Thomas%20Rybicki%2C%20Bartosz%20Srinivasan%2C%20Aravind%20An%20improved%20approximation%20for%20k-median%20and%20positive%20correlation%20in%20budgeted%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Byrka%2C%20Jaroslaw%20Pensyl%2C%20Thomas%20Rybicki%2C%20Bartosz%20Srinivasan%2C%20Aravind%20An%20improved%20approximation%20for%20k-median%20and%20positive%20correlation%20in%20budgeted%20optimization%202017"
        },
        {
            "id": "4",
            "entry": "[4] Moses Charikar, Samir Khuller, David M. Mount, and Giri Narasimhan. Algorithms for facility location problems with outliers. In Proceedings of the 12th Annual Symposium on Discrete Algorithms, January 7-9, 2001, Washington, DC, USA., pages 642\u2013651, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charikar%2C%20Moses%20Khuller%2C%20Samir%20Mount%2C%20David%20M.%20Narasimhan%2C%20Giri%20Algorithms%20for%20facility%20location%20problems%20with%20outliers%202001-01-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charikar%2C%20Moses%20Khuller%2C%20Samir%20Mount%2C%20David%20M.%20Narasimhan%2C%20Giri%20Algorithms%20for%20facility%20location%20problems%20with%20outliers%202001-01-07"
        },
        {
            "id": "5",
            "entry": "[5] Jiecao Chen, Erfan Sadeqi Azer, and Qin Zhang. A practical algorithm for distributed clustering and outlier detection. CoRR, abs/1805.09495, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.09495"
        },
        {
            "id": "6",
            "entry": "[6] Jiecao Chen, He Sun, David P. Woodruff, and Qin Zhang. Communication-optimal distributed clustering. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 3720\u20133728, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Jiecao%20Sun%2C%20He%20Woodruff%2C%20David%20P.%20Zhang%2C%20Qin%20Communication-optimal%20distributed%20clustering%202016-12-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Jiecao%20Sun%2C%20He%20Woodruff%2C%20David%20P.%20Zhang%2C%20Qin%20Communication-optimal%20distributed%20clustering%202016-12-05"
        },
        {
            "id": "7",
            "entry": "[7] Ke Chen. A constant factor approximation algorithm for k-median clustering with outliers. In Proceedings of the 19th Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2008, San Francisco, California, USA, January 20-22, 2008, pages 826\u2013835, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Ke%20A%20constant%20factor%20approximation%20algorithm%20for%20k-median%20clustering%20with%20outliers%202008-01-20",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Ke%20A%20constant%20factor%20approximation%20algorithm%20for%20k-median%20clustering%20with%20outliers%202008-01-20"
        },
        {
            "id": "8",
            "entry": "[8] Hu Ding, Yu Liu, Lingxiao Huang, and Jian Li. k-means clustering with distributed dimensions. In Proceedings of the 33rd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages 1339\u20131348, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ding%2C%20Hu%20Liu%2C%20Yu%20Huang%2C%20Lingxiao%20Li%2C%20Jian%20k-means%20clustering%20with%20distributed%20dimensions%202016-06-19",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ding%2C%20Hu%20Liu%2C%20Yu%20Huang%2C%20Lingxiao%20Li%2C%20Jian%20k-means%20clustering%20with%20distributed%20dimensions%202016-06-19"
        },
        {
            "id": "9",
            "entry": "[9] Alina Ene, Sungjin Im, and Benjamin Moseley. Fast clustering using mapreduce. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Diego, CA, USA, August 21-24, 2011, pages 681\u2013689, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ene%2C%20Alina%20Im%2C%20Sungjin%20Moseley%2C%20Benjamin%20Fast%20clustering%20using%20mapreduce%202011-08-21",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ene%2C%20Alina%20Im%2C%20Sungjin%20Moseley%2C%20Benjamin%20Fast%20clustering%20using%20mapreduce%202011-08-21"
        },
        {
            "id": "10",
            "entry": "[10] Sudipto Guha, Yi Li, and Qin Zhang. Distributed partial clustering. In Proceedings of the 29th ACM Symposium on Parallelism in Algorithms and Architectures, SPAA 2017, Washington DC, USA, July 24-26, 2017, pages 143\u2013152, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guha%2C%20Sudipto%20Li%2C%20Yi%20Zhang%2C%20Qin%20Distributed%20partial%20clustering%202017-07-24",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guha%2C%20Sudipto%20Li%2C%20Yi%20Zhang%2C%20Qin%20Distributed%20partial%20clustering%202017-07-24"
        },
        {
            "id": "11",
            "entry": "[11] Sungjin Im and Benjamin Moseley. Brief announcement: Fast and better distributed mapreduce algorithms for k-center clustering. In Proceedings of the 27th ACM on Symposium on Parallelism in Algorithms and Architectures, SPAA 2015, Portland, OR, USA, June 13-15, 2015, pages 65\u201367, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Sungjin%20Im%20and%20Benjamin%20Moseley.%20Brief%20announcement%3A%20Fast%20and%20better%20distributed%20mapreduce%20algorithms%20for%20k-center%20clustering%202015-06-13",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Sungjin%20Im%20and%20Benjamin%20Moseley.%20Brief%20announcement%3A%20Fast%20and%20better%20distributed%20mapreduce%20algorithms%20for%20k-center%20clustering%202015-06-13"
        },
        {
            "id": "12",
            "entry": "[12] Ravishankar Krishnaswamy, Shi Li, and Sai Sandeep. Constant approximation for k-median and k-means with outliers via iterative rounding. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2018, Los Angeles, CA, USA, June 25-29, 2018, pages 646\u2013659, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krishnaswamy%2C%20Ravishankar%20Li%2C%20Shi%20Sandeep%2C%20Sai%20Constant%20approximation%20for%20k-median%20and%20k-means%20with%20outliers%20via%20iterative%20rounding%202018-06-25",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krishnaswamy%2C%20Ravishankar%20Li%2C%20Shi%20Sandeep%2C%20Sai%20Constant%20approximation%20for%20k-median%20and%20k-means%20with%20outliers%20via%20iterative%20rounding%202018-06-25"
        },
        {
            "id": "13",
            "entry": "[13] Gustavo Malkomes, Matt J. Kusner, Wenlin Chen, Kilian Q. Weinberger, and Benjamin Moseley. Fast distributed k-center clustering with outliers on massive data. In Advances in Neural Information Processing Systems 28, NIPS 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 1063\u20131071, 2015. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Malkomes%2C%20Gustavo%20Kusner%2C%20Matt%20J.%20Chen%2C%20Wenlin%20Weinberger%2C%20Kilian%20Q.%20Fast%20distributed%20k-center%20clustering%20with%20outliers%20on%20massive%20data%202015-12-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Malkomes%2C%20Gustavo%20Kusner%2C%20Matt%20J.%20Chen%2C%20Wenlin%20Weinberger%2C%20Kilian%20Q.%20Fast%20distributed%20k-center%20clustering%20with%20outliers%20on%20massive%20data%202015-12-07"
        }
    ]
}
