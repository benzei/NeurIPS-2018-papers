{
    "filename": "7808-online-improper-learning-with-an-approximation-oracle.pdf",
    "metadata": {
        "title": "Online Improper Learning with an Approximation Oracle",
        "author": "Elad Hazan, Wei Hu, Yuanzhi Li, Zhiyuan Li",
        "date": 2018,
        "identifiers": {
            "arxiv": "1804.07837",
            "doi": null,
            "isbn": null,
            "doc_id": null,
            "url": "https://papers.nips.cc/paper/7808-online-improper-learning-with-an-approximation-oracle.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We revisit the question of reducing online learning to approximate optimization of the offline problem. In this setting, we give two algorithms with near-optimal performance in the full information setting: they guarantee optimal regret and require only poly-logarithmically many calls to the approximation oracle per iteration. Furthermore, these algorithms apply to the more general improper learning problems. In the bandit setting, our algorithm also significantly improves the best previously known oracle complexity while maintaining the same regret."
    },
    "keywords": [
        {
            "term": "approximation algorithm",
            "url": "https://en.wikipedia.org/wiki/approximation_algorithm"
        },
        {
            "term": "online convex optimization",
            "url": "https://en.wikipedia.org/wiki/online_convex_optimization"
        },
        {
            "term": "fully polynomial time approximation scheme",
            "url": "https://en.wikipedia.org/wiki/fully_polynomial_time_approximation_scheme"
        },
        {
            "term": "online learning",
            "url": "https://en.wikipedia.org/wiki/online_learning"
        }
    ],
    "highlights": [
        "A fundamental question in learning theory is whether one can efficiently learn a given problem using an optimization oracle",
        "In the face of NP-hardness, algorithm designers resort to approximation algorithms that are guaranteed to return a solution within a certain multiplicative factor of the optimum",
        "We show how to extend our mirror descent-based algorithm to the bandit setting and obtain the same O(T 2/3) regret as in (<a class=\"ref-link\" id=\"cKakade_et+al_2009_a\" href=\"#rKakade_et+al_2009_a\">Kakade et al, 2009</a>; <a class=\"ref-link\" id=\"cGarber_2017_a\" href=\"#rGarber_2017_a\">Garber, 2017</a>), but with a significantly lower computational cost",
        "<a class=\"ref-link\" id=\"cKalai_2005_a\" href=\"#rKalai_2005_a\">Kalai and Vempala (2005</a>) proposed a specialized reduction that works under certain conditions on the approximation oracle, satisfied by some known algorithms for problems such as MAX-CUT",
        "We have described two different algorithmic approaches to reducing regret minimization to offline approximation algorithms and maintaining optimal regret and poly-logarithmic oracle complexity per iteration, resolving previously stated open questions",
        "An intriguing openpproblem remaining is to find an efficient algorithm in the bandit setting that guarantees both O( T ) regret and poly oracle complexity per iteration"
    ],
    "key_statements": [
        "A fundamental question in learning theory is whether one can efficiently learn a given problem using an optimization oracle",
        "In the face of NP-hardness, algorithm designers resort to approximation algorithms that are guaranteed to return a solution within a certain multiplicative factor of the optimum",
        "We show how to extend our mirror descent-based algorithm to the bandit setting and obtain the same O(T 2/3) regret as in (<a class=\"ref-link\" id=\"cKakade_et+al_2009_a\" href=\"#rKakade_et+al_2009_a\">Kakade et al, 2009</a>; <a class=\"ref-link\" id=\"cGarber_2017_a\" href=\"#rGarber_2017_a\">Garber, 2017</a>), but with a significantly lower computational cost",
        "<a class=\"ref-link\" id=\"cKalai_2005_a\" href=\"#rKalai_2005_a\">Kalai and Vempala (2005</a>) proposed a specialized reduction that works under certain conditions on the approximation oracle, satisfied by some known algorithms for problems such as MAX-CUT",
        "Assuming the availability of a PAD oracle, one can use a standard analysis of online mirror descent to prove a regret bound for Algorithm 1 as in Theorem 3.1",
        "We have described two different algorithmic approaches to reducing regret minimization to offline approximation algorithms and maintaining optimal regret and poly-logarithmic oracle complexity per iteration, resolving previously stated open questions",
        "An intriguing openpproblem remaining is to find an efficient algorithm in the bandit setting that guarantees both O( T ) regret and poly oracle complexity per iteration"
    ],
    "summary": [
        "A fundamental question in learning theory is whether one can efficiently learn a given problem using an optimization oracle.",
        "Does efficient offline optimization for a certain problem imply efficient learning algorithm for the same setting?",
        "In many non-convex settings, such an optimization oracle is either unavailable or NP-hard to compute.",
        "We show how to extend our mirror descent-based algorithm to the bandit setting and obtain the same O(T 2/3) regret as in (<a class=\"ref-link\" id=\"cKakade_et+al_2009_a\" href=\"#rKakade_et+al_2009_a\">Kakade et al, 2009</a>; <a class=\"ref-link\" id=\"cGarber_2017_a\" href=\"#rGarber_2017_a\">Garber, 2017</a>), but with a significantly lower computational cost.",
        "The setting of online learning with approximation algorithms has been well studied since (<a class=\"ref-link\" id=\"cKalai_2005_a\" href=\"#rKalai_2005_a\">Kalai and Vempala, 2005</a>) with numerous applications.",
        "Our results imply an online algorithm that can predict as accurate as the best 0.878-approximation to the maximum cut in hindsight, and calls the SDP relaxation only logarithmically many times per iteration.",
        "<a class=\"ref-link\" id=\"cKalai_2005_a\" href=\"#rKalai_2005_a\">Kalai and Vempala (2005</a>) proposed a specialized reduction that works under certain conditions on the approximation oracle, satisfied by some known algorithms for problems such as MAX-CUT.",
        "For a convex set S equipped with a membership oracle, there exist polynomial-time algorithms for sampling from any log-concave distribution over S (Lov\u00e1sz and Vempala, 2007).",
        "We give an efficient online improper linear optimization algorithm (Algorithm 1) in the full information setting based pon online mirror descent (OMD) equipped with a strongly convex regularizer ', which achieves O( T ) regret when the regularizer ' and the domain of linear loss functions W satisfy the pairwise non-negative inner product (PNIP) property (Definition 2.4).",
        "Assuming the availability of a PAD oracle, one can use a standard analysis of OMD to prove a regret bound for Algorithm 1 as in Theorem 3.1.",
        "For each i, zi+1 is the Bregman projection of zi onto a halfspace containing K\u21e4, since the oracle the generalized Pythagorean theorem",
        "13: Feed ft to Algorithm 1 as the loss vector for round t (Note that when ft = 0, in the round Algorithm 1 can play according to the distribution computed in this round without any oracle calls.)",
        "This unboundedness creates problems with the unbiased estimator of loss vector, whose variance can be as large as certain geometric properties of the decision set.",
        "We have described two different algorithmic approaches to reducing regret minimization to offline approximation algorithms and maintaining optimal regret and poly-logarithmic oracle complexity per iteration, resolving previously stated open questions.",
        "An intriguing openpproblem remaining is to find an efficient algorithm in the bandit setting that guarantees both O( T ) regret and poly oracle complexity per iteration."
    ],
    "headline": "We present these two algorithms and their guarantees in Sections 3 and Appendix B",
    "reference_links": [
        {
            "id": "Awerbuch_2004_a",
            "entry": "Awerbuch, B. and Kleinberg, R. D. (2004). Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches. In Proceedings of the thirty-sixth annual ACM symposium on Theory of computing, pages 45\u201353. ACM.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Awerbuch%2C%20B.%20Kleinberg%2C%20R.D.%20Adaptive%20routing%20with%20end-to-end%20feedback%3A%20Distributed%20learning%20and%20geometric%20approaches%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Awerbuch%2C%20B.%20Kleinberg%2C%20R.D.%20Adaptive%20routing%20with%20end-to-end%20feedback%3A%20Distributed%20learning%20and%20geometric%20approaches%202004"
        },
        {
            "id": "Balcan_2006_a",
            "entry": "Balcan, M.-F. and Blum, A. (2006). Approximation algorithms and online mechanisms for item pricing. In Proceedings of the 7th ACM Conference on Electronic Commerce, pages 29\u201335. ACM.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20M.-F.%20Blum%2C%20A.%20Approximation%20algorithms%20and%20online%20mechanisms%20for%20item%20pricing%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20M.-F.%20Blum%2C%20A.%20Approximation%20algorithms%20and%20online%20mechanisms%20for%20item%20pricing%202006"
        },
        {
            "id": "Cesa-Bianchi_2006_a",
            "entry": "Cesa-Bianchi, N. and Lugosi, G. (2006). Prediction, learning, and games. Cambridge university press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cesa-Bianchi%2C%20N.%20Lugosi%2C%20G.%20Prediction%2C%20learning%2C%20and%20games%202006"
        },
        {
            "id": "Cover_1991_a",
            "entry": "Cover, T. M. (1991). Universal portfolios. Mathematical Finance, 1(1):1\u201329.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20T.M.%20Universal%20portfolios%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cover%2C%20T.M.%20Universal%20portfolios%201991"
        },
        {
            "id": "Dud_et+al_2016_a",
            "entry": "Dud\u00edk, M., Haghtalab, N., Luo, H., Schapire, R. E., Syrgkanis, V., and Vaughan, J. W. (2016). Oracle-efficient online learning and auction design. arXiv preprint arXiv:1611.01688.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01688"
        },
        {
            "id": "Fujita_et+al_2013_a",
            "entry": "Fujita, T., Hatano, K., and Takimoto, E. (2013). Combinatorial online prediction via metarounding. In International Conference on Algorithmic Learning Theory, pages 68\u201382. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fujita%2C%20T.%20Hatano%2C%20K.%20Takimoto%2C%20E.%20Combinatorial%20online%20prediction%20via%20metarounding%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fujita%2C%20T.%20Hatano%2C%20K.%20Takimoto%2C%20E.%20Combinatorial%20online%20prediction%20via%20metarounding%202013"
        },
        {
            "id": "Garber_2017_a",
            "entry": "Garber, D. (2017). Efficient online linear optimization with approximation algorithms. In Advances in Neural Information Processing Systems, pages 627\u2013635.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Garber%2C%20D.%20Efficient%20online%20linear%20optimization%20with%20approximation%20algorithms%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Garber%2C%20D.%20Efficient%20online%20linear%20optimization%20with%20approximation%20algorithms%202017"
        },
        {
            "id": "Goemans_1995_a",
            "entry": "Goemans, M. X. and Williamson, D. P. (1995). Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. J. ACM, 42(6):1115\u20131145.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goemans%2C%20M.X.%20Williamson%2C%20D.P.%20Improved%20approximation%20algorithms%20for%20maximum%20cut%20and%20satisfiability%20problems%20using%20semidefinite%20programming%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goemans%2C%20M.X.%20Williamson%2C%20D.P.%20Improved%20approximation%20algorithms%20for%20maximum%20cut%20and%20satisfiability%20problems%20using%20semidefinite%20programming%201995"
        },
        {
            "id": "Hazan_2016_a",
            "entry": "Hazan, E. (2016). Introduction to online convex optimization. Foundations and Trends R in Optimization, 2(3-4):157\u2013325.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20E.%20Introduction%20to%20online%20convex%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20E.%20Introduction%20to%20online%20convex%20optimization%202016"
        },
        {
            "id": "Hazan_2016_b",
            "entry": "Hazan, E. and Koren, T. (2016). The computational power of optimization in online learning. In Proceedings of the forty-eighth annual ACM symposium on Theory of Computing, pages 128\u2013141. ACM.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20E.%20Koren%2C%20T.%20The%20computational%20power%20of%20optimization%20in%20online%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20E.%20Koren%2C%20T.%20The%20computational%20power%20of%20optimization%20in%20online%20learning%202016"
        },
        {
            "id": "Kakade_et+al_2009_a",
            "entry": "Kakade, S. M., Kalai, A. T., and Ligett, K. (2009). Playing games with approximation algorithms. SIAM Journal on Computing, 39(3):1088\u20131106.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kakade%2C%20S.M.%20Kalai%2C%20A.T.%20Ligett%2C%20K.%20Playing%20games%20with%20approximation%20algorithms%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kakade%2C%20S.M.%20Kalai%2C%20A.T.%20Ligett%2C%20K.%20Playing%20games%20with%20approximation%20algorithms%202009"
        },
        {
            "id": "Kalai_2005_a",
            "entry": "Kalai, A. and Vempala, S. (2005). Efficient algorithms for online decision problems. Journal of Computer and System Sciences, 71(3):291\u2013307.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kalai%2C%20A.%20Vempala%2C%20S.%20Efficient%20algorithms%20for%20online%20decision%20problems%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kalai%2C%20A.%20Vempala%2C%20S.%20Efficient%20algorithms%20for%20online%20decision%20problems%202005"
        },
        {
            "id": "Lov_2007_a",
            "entry": "Lov\u00e1sz, L. and Vempala, S. (2007). The geometry of logconcave functions and sampling algorithms. Random Structures & Algorithms, 30(3):307\u2013358.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lov%C3%A1sz%2C%20L.%20Vempala%2C%20S.%20The%20geometry%20of%20logconcave%20functions%20and%20sampling%20algorithms%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lov%C3%A1sz%2C%20L.%20Vempala%2C%20S.%20The%20geometry%20of%20logconcave%20functions%20and%20sampling%20algorithms%202007"
        },
        {
            "id": "Pr_1973_a",
            "entry": "Pr\u00e9kopa, A. (1973). On logarithmic concave measures and functions. Acta Scientiarum Mathematicarum, 34:335\u2013343.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pr%C3%A9kopa%2C%20A.%20On%20logarithmic%20concave%20measures%20and%20functions%201973",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pr%C3%A9kopa%2C%20A.%20On%20logarithmic%20concave%20measures%20and%20functions%201973"
        },
        {
            "id": "Shalev-Shwartz_2012_a",
            "entry": "Shalev-Shwartz, S. (2012). Online learning and online convex optimization. Foundations and Trends R in Machine Learning, 4(2):107\u2013194.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shalev-Shwartz%2C%20S.%20Online%20learning%20and%20online%20convex%20optimization%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shalev-Shwartz%2C%20S.%20Online%20learning%20and%20online%20convex%20optimization%202012"
        },
        {
            "id": "Vovk_1990_a",
            "entry": "Vovk, V. G. (1990). Aggregating strategies. In Proceedings of the Third Annual Workshop on Computational Learning Theory, COLT \u201990, pages 371\u2013386.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vovk%2C%20V.G.%20Aggregating%20strategies%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vovk%2C%20V.G.%20Aggregating%20strategies%201990"
        }
    ]
}
