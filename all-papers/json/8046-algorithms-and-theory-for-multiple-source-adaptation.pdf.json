{
    "filename": "8046-algorithms-and-theory-for-multiple-source-adaptation.pdf",
    "metadata": {
        "title": "Algorithms and Theory for Multiple-Source Adaptation",
        "author": "Judy Hoffman, Mehryar Mohri, Ningshan Zhang",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8046-algorithms-and-theory-for-multiple-source-adaptation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We present a number of novel contributions to the multiple-source adaptation problem. We derive new normalized solutions with strong theoretical guarantees for the cross-entropy loss and other similar losses. We also provide new guarantees that hold in the case where the conditional probabilities for the source domains are distinct. Moreover, we give new algorithms for determining the distributionweighted combination solution for the cross-entropy loss and other losses. We report the results of a series of experiments with real-world datasets. We find that our algorithm outperforms competing approaches by producing a single robust model that performs well on any target mixture distribution. Altogether, our theory, algorithms, and empirical results provide a full solution for the multiple-source adaptation problem with very practical benefits."
    },
    "keywords": [
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        }
    ],
    "highlights": [
        "Often the learner has access to information about several source domains, including accurate predictors possibly trained and made available by others, but no direct information about a target domain for which one wishes to achieve a good performance",
        "The target domain can typically be viewed as a combination of the source domains, that is a mixture of their joint distributions, or it may be close to such mixtures",
        "When the conditional probabilities are distinct across the source domains, we propose a marginal distribution-weighted combination rule, which is already normalized",
        "For the more realistic scenario where the target domain is a mixture of any two or all three source domains, the performance of our method is comparable or marginally superior to that of the jointly trained network, despite the fact that we do not retrain any network parameters in our method and that we only use a small number of per-domain examples to learn the distribution weights \u2013 an optimization which may be solved on a single CPU in a matter of seconds for this problem",
        "We presented practically applicable multiple-source domain adaptation algorithms for the squared loss and the cross-entropy loss",
        "Our algorithms benefit from a series of very favorable theoretical guarantees"
    ],
    "key_statements": [
        "Often the learner has access to information about several source domains, including accurate predictors possibly trained and made available by others, but no direct information about a target domain for which one wishes to achieve a good performance",
        "The target domain can typically be viewed as a combination of the source domains, that is a mixture of their joint distributions, or it may be close to such mixtures",
        "When the conditional probabilities are distinct across the source domains, we propose a marginal distribution-weighted combination rule, which is already normalized",
        "For the more realistic scenario where the target domain is a mixture of any two or all three source domains, the performance of our method is comparable or marginally superior to that of the jointly trained network, despite the fact that we do not retrain any network parameters in our method and that we only use a small number of per-domain examples to learn the distribution weights \u2013 an optimization which may be solved on a single CPU in a matter of seconds for this problem",
        "We presented practically applicable multiple-source domain adaptation algorithms for the squared loss and the cross-entropy loss",
        "Our algorithms benefit from a series of very favorable theoretical guarantees"
    ],
    "summary": [
        "Often the learner has access to information about several source domains, including accurate predictors possibly trained and made available by others, but no direct information about a target domain for which one wishes to achieve a good performance.",
        "In the MSA problem, the learner\u2019s objective is to combine these predictors to design a predictor with small expected loss on a target domain that could be an arbitrary and unknown mixture of the source domains, the case we are particularly interested in, or even some other arbitrary distribution.",
        "For the probability model with cross-entropy loss, we introduce a normalized distribution weighted combination and prove that it benefits from strong theoretical guarantees.",
        "Theorem 1 shows the existence of \u2318 > and a mixture weight z \u2208 with a remarkable property: in the regression model (R), for any target distribution D whose conditional D (\u22c5\uffffx) is on average not too far away from D",
        "T P, The learning guarantee of Theorem 2 depends on the R\u00e9nyi divergence between the conditional probabilities of the source and target domains and a fixed pivot Q(\u22c5\uffffx).",
        "We discuss the important special case where L coincides with the cross-entropy loss in the probability model, and present a guarantee for a normalized distribution-weighted combination solution.",
        "When the conditional probabilities are distinct across the source domains, we propose a marginal distribution-weighted combination rule, which is already normalized.",
        "For both the regression and the probability model, there exists a vector z defining a distribution-weighted combination hypothesis h\u2318 that admits very favorable guarantees.",
        "This section reports the results of our experiments with our DC-programming algorithm for finding a robust domain generalization solution when using squared loss and cross-entropy loss.",
        "We evaluated our DC-programming solution applied to real-world datasets: a sentiment analysis dataset (<a class=\"ref-link\" id=\"cBlitzer_et+al_2007_a\" href=\"#rBlitzer_et+al_2007_a\">Blitzer et al, 2007</a>) with the squared loss, a visual domain adaptation benchmark dataset Office (<a class=\"ref-link\" id=\"cSaenko_et+al_2010_a\" href=\"#rSaenko_et+al_2010_a\">Saenko et al, 2010</a>), as well as a generalization of digit recognition task, with the cross-entropy loss.",
        "They show that our distribution-weighted learning scenarios of -comb parneddiKcMtoMr. DWWeoaultspoercfoormmpsaarelldboauser lrineseupltrsedwicitthortshdeewspeiitgehttheed pprrivediliecgteodr used in the empirical studies by <a class=\"ref-link\" id=\"cMansour_et+al_2008_a\" href=\"#rMansour_et+al_2008_a\">Mansour et al (2008</a>), which is not a realistic solution since it is using the unknown target mixture as z to compute h .",
        "For the more realistic scenario where the target domain is a mixture of any two or all three source domains, the performance of our method is comparable or marginally superior to that of the jointly trained network, despite the fact that we do not retrain any network parameters in our method and that we only use a small number of per-domain examples to learn the distribution weights \u2013 an optimization which may be solved on a single CPU in a matter of seconds for this problem.",
        "Our results further demonstrate empirically their effectiveness and their importance in adaptation problems in practice"
    ],
    "headline": "We present a number of novel contributions to the multiple-source adaptation problem",
    "reference_links": [
        {
            "id": "Arndt_2004_a",
            "entry": "C. Arndt. Information Measures: Information and its Description in Science and Engineering. Signals and Communication Technology. Springer Verlag, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arndt%2C%20C.%20Information%20Measures%3A%20Information%20and%20its%20Description%20in%20Science%20and%20Engineering.%20Signals%20and%20Communication%20Technology%202004"
        },
        {
            "id": "Ben-David_et+al_2006_a",
            "entry": "S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira. Analysis of representations for domain adaptation. In NIPS, pages 137\u2013144, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20S.%20Blitzer%2C%20J.%20Crammer%2C%20K.%20Pereira%2C%20F.%20Analysis%20of%20representations%20for%20domain%20adaptation%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20S.%20Blitzer%2C%20J.%20Crammer%2C%20K.%20Pereira%2C%20F.%20Analysis%20of%20representations%20for%20domain%20adaptation%202006"
        },
        {
            "id": "Blanchard_et+al_2011_a",
            "entry": "G. Blanchard, G. Lee, and C. Scott. Generalizing from several related classification tasks to a new unlabeled sample. In NIPS, pages 2178\u20132186, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blanchard%2C%20G.%20Lee%2C%20G.%20Scott%2C%20C.%20Generalizing%20from%20several%20related%20classification%20tasks%20to%20a%20new%20unlabeled%20sample%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blanchard%2C%20G.%20Lee%2C%20G.%20Scott%2C%20C.%20Generalizing%20from%20several%20related%20classification%20tasks%20to%20a%20new%20unlabeled%20sample%202011"
        },
        {
            "id": "Blitzer_et+al_2007_a",
            "entry": "J. Blitzer, M. Dredze, and F. Pereira. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL, pages 440\u2013447, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blitzer%2C%20J.%20Dredze%2C%20M.%20Biographies%2C%20F.Pereira%20bollywood%20boom-boxes%20and%20blenders%3A%20Domain%20adaptation%20for%20sentiment%20classification%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blitzer%2C%20J.%20Dredze%2C%20M.%20Biographies%2C%20F.Pereira%20bollywood%20boom-boxes%20and%20blenders%3A%20Domain%20adaptation%20for%20sentiment%20classification%202007"
        },
        {
            "id": "Cortes_2014_a",
            "entry": "C. Cortes and M. Mohri. Domain adaptation and sample bias correction theory and algorithm for regression. Theor. Comput. Sci., 519:103\u2013126, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20C.%20Mohri%2C%20M.%20Domain%20adaptation%20and%20sample%20bias%20correction%20theory%20and%20algorithm%20for%20regression%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20C.%20Mohri%2C%20M.%20Domain%20adaptation%20and%20sample%20bias%20correction%20theory%20and%20algorithm%20for%20regression%202014"
        },
        {
            "id": "Cortes_et+al_2015_a",
            "entry": "C. Cortes, M. Mohri, and A. Mu\u00f1oz Medina. Adaptation algorithm and theory based on generalized discrepancy. In KDD, pages 169\u2013178, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20C.%20Mohri%2C%20M.%20Medina%2C%20A.Mu%C3%B1oz%20Adaptation%20algorithm%20and%20theory%20based%20on%20generalized%20discrepancy%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20C.%20Mohri%2C%20M.%20Medina%2C%20A.Mu%C3%B1oz%20Adaptation%20algorithm%20and%20theory%20based%20on%20generalized%20discrepancy%202015"
        },
        {
            "id": "Cover_2006_a",
            "entry": "T. M. Cover and J. M. Thomas. Elements of Information Theory. Wiley-Interscience, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=T%20M%20Cover%20and%20J%20M%20Thomas%20Elements%20of%20Information%20Theory%20WileyInterscience%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=T%20M%20Cover%20and%20J%20M%20Thomas%20Elements%20of%20Information%20Theory%20WileyInterscience%202006"
        },
        {
            "id": "Crammer_et+al_0000_a",
            "entry": "K. Crammer, M. J. Kearns, and J. Wortman. Learning from multiple sources. Journal of Machine",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crammer%2C%20K.%20Kearns%2C%20M.J.%20Wortman%2C%20J.%20Learning%20from%20multiple%20sources",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Crammer%2C%20K.%20Kearns%2C%20M.J.%20Wortman%2C%20J.%20Learning%20from%20multiple%20sources"
        },
        {
            "id": "Research_2008_a",
            "entry": "Learning Research, 9(Aug):1757\u20131774, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Learning%20Research%209Aug17571774%202008"
        },
        {
            "id": "Donahue_et+al_2014_a",
            "entry": "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, volume 32, pages 647\u2013655, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20J.%20Jia%2C%20Y.%20Vinyals%2C%20O.%20Hoffman%2C%20J.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20J.%20Jia%2C%20Y.%20Vinyals%2C%20O.%20Hoffman%2C%20J.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014"
        },
        {
            "id": "Dredze_et+al_2008_a",
            "entry": "M. Dredze, K. Crammer, and F. Pereira. Confidence-weighted linear classification. In ICML, volume 307, pages 264\u2013271, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dredze%2C%20M.%20Crammer%2C%20K.%20Pereira%2C%20F.%20Confidence-weighted%20linear%20classification%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dredze%2C%20M.%20Crammer%2C%20K.%20Pereira%2C%20F.%20Confidence-weighted%20linear%20classification%202008"
        },
        {
            "id": "Duan_et+al_2009_a",
            "entry": "L. Duan, I. W. Tsang, D. Xu, and T. Chua. Domain adaptation from multiple sources via auxiliary classifiers. In ICML, volume 382, pages 289\u2013296, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duan%2C%20L.%20Tsang%2C%20I.W.%20Xu%2C%20D.%20Chua%2C%20T.%20Domain%20adaptation%20from%20multiple%20sources%20via%20auxiliary%20classifiers%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duan%2C%20L.%20Tsang%2C%20I.W.%20Xu%2C%20D.%20Chua%2C%20T.%20Domain%20adaptation%20from%20multiple%20sources%20via%20auxiliary%20classifiers%202009"
        },
        {
            "id": "Duan_et+al_2012_a",
            "entry": "L. Duan, D. Xu, and I. W. Tsang. Domain adaptation from multiple sources: A domain-dependent regularization approach. IEEE Transactions on Neural Networks and Learning Systems, 23(3): 504\u2013518, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duan%2C%20L.%20Xu%2C%20D.%20Tsang%2C%20I.W.%20Domain%20adaptation%20from%20multiple%20sources%3A%20A%20domain-dependent%20regularization%20approach%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duan%2C%20L.%20Xu%2C%20D.%20Tsang%2C%20I.W.%20Domain%20adaptation%20from%20multiple%20sources%3A%20A%20domain-dependent%20regularization%20approach%202012"
        },
        {
            "id": "Ganin_2015_a",
            "entry": "Y. Ganin and V. S. Lempitsky. Unsupervised domain adaptation by backpropagation. In ICML, volume 37, pages 1180\u20131189, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Y.%20Lempitsky%2C%20V.S.%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Y.%20Lempitsky%2C%20V.S.%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015"
        },
        {
            "id": "Girshick_et+al_2014_a",
            "entry": "R. B. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR, pages 580\u2013587, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Girshick%2C%20R.B.%20Donahue%2C%20J.%20Darrell%2C%20T.%20Malik%2C%20J.%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Girshick%2C%20R.B.%20Donahue%2C%20J.%20Darrell%2C%20T.%20Malik%2C%20J.%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation%202014"
        },
        {
            "id": "Gong_et+al_2012_a",
            "entry": "B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In CVPR, pages 2066\u20132073, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Shi%2C%20Y.%20Sha%2C%20F.%20Grauman%2C%20K.%20Geodesic%20flow%20kernel%20for%20unsupervised%20domain%20adaptation%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Shi%2C%20Y.%20Sha%2C%20F.%20Grauman%2C%20K.%20Geodesic%20flow%20kernel%20for%20unsupervised%20domain%20adaptation%202012"
        },
        {
            "id": "Gong_et+al_0000_a",
            "entry": "B. Gong, K. Grauman, and F. Sha. Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation. In ICML, volume 28, pages 222\u2013230, 2013a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domain-invariant%20features%20for%20unsupervised%20domain%20adaptation",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domain-invariant%20features%20for%20unsupervised%20domain%20adaptation"
        },
        {
            "id": "Gong_et+al_2013_a",
            "entry": "B. Gong, K. Grauman, and F. Sha. Reshaping visual datasets for domain adaptation. In NIPS, pages 1286\u20131294, 2013b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Reshaping%20visual%20datasets%20for%20domain%20adaptation%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Reshaping%20visual%20datasets%20for%20domain%20adaptation%202013"
        },
        {
            "id": "Hoffman_et+al_2012_a",
            "entry": "J. Hoffman, B. Kulis, T. Darrell, and K. Saenko. Discovering latent domains for multisource domain adaptation. In ECCV, volume 7573, pages 702\u2013715, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Kulis%2C%20B.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Discovering%20latent%20domains%20for%20multisource%20domain%20adaptation%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Kulis%2C%20B.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Discovering%20latent%20domains%20for%20multisource%20domain%20adaptation%202012"
        },
        {
            "id": "Hoffman_et+al_2013_a",
            "entry": "J. Hoffman, E. Rodner, J. Donahue, K. Saenko, and T. Darrell. Efficient learning of domain-invariant image representations. In ICLR, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Rodner%2C%20E.%20Donahue%2C%20J.%20Saenko%2C%20K.%20Efficient%20learning%20of%20domain-invariant%20image%20representations%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Rodner%2C%20E.%20Donahue%2C%20J.%20Saenko%2C%20K.%20Efficient%20learning%20of%20domain-invariant%20image%20representations%202013"
        },
        {
            "id": "Huang_et+al_2006_a",
            "entry": "J. Huang, A. J. Smola, A. Gretton, K. M. Borgwardt, and B. Sch\u00f6lkopf. Correcting sample selection bias by unlabeled data. In NIPS, pages 601\u2013608, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20J.%20Smola%2C%20A.J.%20Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20J.%20Smola%2C%20A.J.%20Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202006"
        },
        {
            "id": "Khosla_et+al_2012_a",
            "entry": "A. Khosla, T. Zhou, T. Malisiewicz, A. A. Efros, and A. Torralba. Undoing the damage of dataset bias. In ECCV, volume 7572, pages 158\u2013171, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khosla%2C%20A.%20Zhou%2C%20T.%20Malisiewicz%2C%20T.%20Efros%2C%20A.A.%20Undoing%20the%20damage%20of%20dataset%20bias%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khosla%2C%20A.%20Zhou%2C%20T.%20Malisiewicz%2C%20T.%20Efros%2C%20A.A.%20Undoing%20the%20damage%20of%20dataset%20bias%202012"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, pages 1106\u20131114, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Liao_2013_a",
            "entry": "H. Liao. Speaker adaptation of context dependent deep neural networks. In ICASSP, pages 7947\u20137951, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liao%2C%20H.%20Speaker%20adaptation%20of%20context%20dependent%20deep%20neural%20networks%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liao%2C%20H.%20Speaker%20adaptation%20of%20context%20dependent%20deep%20neural%20networks%202013"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation networks. In ICML, volume 37, pages 97\u2013105, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Cao%2C%20Y.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Cao%2C%20Y.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015"
        },
        {
            "id": "Mansour_et+al_2008_a",
            "entry": "Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain adaptation with multiple sources. In NIPS, pages 1041\u20131048, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%20with%20multiple%20sources%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%20with%20multiple%20sources%202008"
        },
        {
            "id": "Mansour_et+al_2009_a",
            "entry": "Y. Mansour, M. Mohri, and A. Rostamizadeh. Multiple source adaptation and the R\u00e9nyi divergence. In UAI, pages 367\u2013374, 2009a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Multiple%20source%20adaptation%20and%20the%20R%C3%A9nyi%20divergence%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Multiple%20source%20adaptation%20and%20the%20R%C3%A9nyi%20divergence%202009"
        },
        {
            "id": "Mansour_et+al_2009_b",
            "entry": "Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In COLT, 2009b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%3A%20Learning%20bounds%20and%20algorithms%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%3A%20Learning%20bounds%20and%20algorithms%202009"
        },
        {
            "id": "Muandet_et+al_2013_a",
            "entry": "K. Muandet, D. Balduzzi, and B. Sch\u00f6lkopf. Domain generalization via invariant feature representation. In ICML, volume 28, pages 10\u201318, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Muandet%2C%20K.%20Balduzzi%2C%20D.%20Sch%C3%B6lkopf%2C%20B.%20Domain%20generalization%20via%20invariant%20feature%20representation%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muandet%2C%20K.%20Balduzzi%2C%20D.%20Sch%C3%B6lkopf%2C%20B.%20Domain%20generalization%20via%20invariant%20feature%20representation%202013"
        },
        {
            "id": "Pan_2010_a",
            "entry": "S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Trans. Knowl. Data Eng., 22(10): 1345\u20131359, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010"
        },
        {
            "id": "Pei_et+al_2018_a",
            "entry": "Z. Pei, Z. Cao, M. Long, and J. Wang. Multi-adversarial domain adaptation. In AAAI, pages 3934\u20133941, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pei%2C%20Z.%20Cao%2C%20Z.%20Long%2C%20M.%20Wang%2C%20J.%20Multi-adversarial%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pei%2C%20Z.%20Cao%2C%20Z.%20Long%2C%20M.%20Wang%2C%20J.%20Multi-adversarial%20domain%20adaptation%202018"
        },
        {
            "id": "R_1961_a",
            "entry": "A. R\u00e9nyi. On measures of entropy and information. In Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, pages 547\u2013561, 1961.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=R%C3%A9nyi%2C%20A.%20On%20measures%20of%20entropy%20and%20information%201961",
            "oa_query": "https://api.scholarcy.com/oa_version?query=R%C3%A9nyi%2C%20A.%20On%20measures%20of%20entropy%20and%20information%201961"
        },
        {
            "id": "Roark_et+al_2012_a",
            "entry": "B. Roark, R. Sproat, C. Allauzen, M. Riley, J. Sorensen, and T. Tai. The opengrm open-source finite-state grammar software libraries. In ACL (System Demonstrations), pages 61\u201366, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roark%2C%20B.%20Sproat%2C%20R.%20Allauzen%2C%20C.%20Riley%2C%20M.%20The%20opengrm%20open-source%20finite-state%20grammar%20software%20libraries%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roark%2C%20B.%20Sproat%2C%20R.%20Allauzen%2C%20C.%20Riley%2C%20M.%20The%20opengrm%20open-source%20finite-state%20grammar%20software%20libraries%202012"
        },
        {
            "id": "Saenko_et+al_2010_a",
            "entry": "K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In ECCV, volume 6314, pages 213\u2013226, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saenko%2C%20K.%20Kulis%2C%20B.%20Fritz%2C%20M.%20Darrell%2C%20T.%20Adapting%20visual%20category%20models%20to%20new%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saenko%2C%20K.%20Kulis%2C%20B.%20Fritz%2C%20M.%20Darrell%2C%20T.%20Adapting%20visual%20category%20models%20to%20new%20domains%202010"
        },
        {
            "id": "Sriperumbudur_2012_a",
            "entry": "B. K. Sriperumbudur and G. R. G. Lanckriet. A proof of convergence of the concave-convex procedure using Zangwill\u2019s theory. Neural Computation, 24(6):1391\u20131407, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sriperumbudur%2C%20B.K.%20Lanckriet%2C%20G.R.G.%20A%20proof%20of%20convergence%20of%20the%20concave-convex%20procedure%20using%20Zangwill%E2%80%99s%20theory%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sriperumbudur%2C%20B.K.%20Lanckriet%2C%20G.R.G.%20A%20proof%20of%20convergence%20of%20the%20concave-convex%20procedure%20using%20Zangwill%E2%80%99s%20theory%202012"
        },
        {
            "id": "Taigman_et+al_2017_a",
            "entry": "Y. Taigman, A. Polyak, and L. Wolf. Unsupervised cross-domain image generation. In ICLR, 2017. P. D. Tao and L. T. H. An. Convex analysis approach to DC programming: theory, algorithms and applications. Acta Mathematica Vietnamica, 22(1):289\u2013355, 1997. P. D. Tao and L. T. H. An. A DC optimization algorithm for solving the trust-region subproblem.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Taigman%2C%20Y.%20Polyak%2C%20A.%20Wolf%2C%20L.%20Unsupervised%20cross-domain%20image%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Taigman%2C%20Y.%20Polyak%2C%20A.%20Wolf%2C%20L.%20Unsupervised%20cross-domain%20image%20generation%202017"
        },
        {
            "id": "A_2011_a",
            "entry": "SIAM Journal on Optimization, 8(2):476\u2013505, 1998. A. Torralba and A. A. Efros. Unbiased look at dataset bias. In CVPR, pages 1521\u20131528, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Torralba%2C%201998.%20A.%20Efros%2C%20A.%20A.%20SIAM%20Journal%20on%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Torralba%2C%201998.%20A.%20Efros%2C%20A.%20A.%20SIAM%20Journal%20on%202011"
        },
        {
            "id": "Tzeng_et+al_2015_a",
            "entry": "E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In ICCV, pages 4068\u20134076, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015"
        },
        {
            "id": "Xu_et+al_2014_a",
            "entry": "Z. Xu, W. Li, L. Niu, and D. Xu. Exploiting low-rank structure from latent domains for domain generalization. In ECCV, volume 8691, pages 628\u2013643, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Z.%20Li%2C%20W.%20Niu%2C%20L.%20Xu%2C%20D.%20Exploiting%20low-rank%20structure%20from%20latent%20domains%20for%20domain%20generalization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Z.%20Li%2C%20W.%20Niu%2C%20L.%20Xu%2C%20D.%20Exploiting%20low-rank%20structure%20from%20latent%20domains%20for%20domain%20generalization%202014"
        },
        {
            "id": "Yuille_2007_a",
            "entry": "In ACM Multimedia, pages 188\u2013197, 2007. A. L. Yuille and A. Rangarajan. The concave-convex procedure. Neural Computation, 15(4):915\u2013936, 2003. K. Zhang, M. Gong, and B. Sch\u00f6lkopf. Multi-source domain adaptation: A causal view. In AAAI, pages 3150\u20133157, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yuille%2C%20A.L.%20Rangarajan%2C%20A.%20The%20concave-convex%20procedure%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yuille%2C%20A.L.%20Rangarajan%2C%20A.%20The%20concave-convex%20procedure%202007"
        }
    ]
}
