{
    "filename": "7616-communication-efficient-parallel-algorithms-for-optimization-on-manifolds.pdf",
    "metadata": {
        "title": "Communication Efficient Parallel Algorithms for Optimization on Manifolds",
        "author": "Bayan Saparbayeva, Michael Zhang, Lizhen Lin",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7616-communication-efficient-parallel-algorithms-for-optimization-on-manifolds.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "The last decade has witnessed an explosion in the development of models, theory and computational algorithms for \u201cbig data\u201d analysis. In particular, distributed computing has served as a natural and dominating paradigm for statistical inference. However, the existing literature on parallel inference almost exclusively focuses on Euclidean data and parameters. While this assumption is valid for many applications, it is increasingly more common to encounter problems where the data or the parameters lie on a non-Euclidean space, like a manifold for example. Our work aims to fill a critical gap in the literature by generalizing parallel inference algorithms to optimization on manifolds. We show that our proposed algorithm is both communication efficient and carries theoretical convergence guarantees. In addition, we demonstrate the performance of our algorithm to the estimation of Fr\u00e9chet means on simulated spherical data and the low-rank matrix completion problem over Grassmann manifolds applied to the Netflix prize data set."
    },
    "keywords": [
        {
            "term": "statistical inference",
            "url": "https://en.wikipedia.org/wiki/statistical_inference"
        },
        {
            "term": "large sample theory",
            "url": "https://en.wikipedia.org/wiki/large_sample_theory"
        },
        {
            "term": "matrix completion",
            "url": "https://en.wikipedia.org/wiki/matrix_completion"
        },
        {
            "term": "diffusion tensor imaging",
            "url": "https://en.wikipedia.org/wiki/diffusion_tensor_imaging"
        },
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        },
        {
            "term": "euclidean space",
            "url": "https://en.wikipedia.org/wiki/euclidean_space"
        }
    ],
    "highlights": [
        "A natural representation for many statistical and machine learning problems is to assume the parameter of interest lies on a more general space than the Euclidean space",
        "We propose in this paper a communication efficient parallel algorithm for general optimization problems on manifolds which is applicable to many different manifold spaces and loss functions",
        "Our proposed algorithm can explore the geometry of the underlying space efficiently and perform well in simulation studies and practical examples all while having theoretical convergence guarantees",
        "In the age of \u201cbig data\u201d, the need for distributable inference algorithms is crucial as we cannot reliably expect entire datasets to sit on a single processor anymore",
        "Much of the previous work in parallel inference has only focused on data and parameters in Euclidean space",
        "We aim to extend the situations under which parallel inference algorithms are generalizable to manifolds and demonstrate more critical problems in which parallel inference is a crucial solution.\n2We select the step size parameter according to the modified Armijo algorithm seen in [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]"
    ],
    "key_statements": [
        "A natural representation for many statistical and machine learning problems is to assume the parameter of interest lies on a more general space than the Euclidean space",
        "We propose in this paper a communication efficient parallel algorithm for general optimization problems on manifolds which is applicable to many different manifold spaces and loss functions",
        "Our proposed algorithm can explore the geometry of the underlying space efficiently and perform well in simulation studies and practical examples all while having theoretical convergence guarantees",
        "In the age of \u201cbig data\u201d, the need for distributable inference algorithms is crucial as we cannot reliably expect entire datasets to sit on a single processor anymore",
        "Much of the previous work in parallel inference has only focused on data and parameters in Euclidean space",
        "Much of the data that we are interested in is better modeled by manifolds and we need fast inference algorithms that are provably suitable for situations beyond the Euclidean setting",
        "We aim to extend the situations under which parallel inference algorithms are generalizable to manifolds and demonstrate more critical problems in which parallel inference is a crucial solution.\n2We select the step size parameter according to the modified Armijo algorithm seen in [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]"
    ],
    "summary": [
        "A natural representation for many statistical and machine learning problems is to assume the parameter of interest lies on a more general space than the Euclidean space.",
        "The novelty of our paper is in the fact that is generalizable to a wide range of loss functions for manifold optimization problems and that we can parallelize the algorithm by splitting the data across processors.",
        "We focus on generalizing a particular parallel inference framework, the Iterative Local Estimation Algorithm (ILEA) [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], to manifolds.",
        "This algorithm optimizes an approximate, surrogate loss function instead of the global loss function as a way to avoid processor communication.",
        "We will use the ILEA framework as our working example to generalize parallel optimization algorithms.",
        "To establish some theoretical convergence rates on our algorithm, we have to impose some regularity conditions on the parameter space \u0398, the loss function L and the population risk L \u2217.",
        "We impose the following regularity conditions on the parameter space \u0398, the loss function L and the population risk L \u2217.",
        "We apply our algorithm to Netflix movie-ranking data set as an example of optimization over Grassmannian manifolds in the low-rank matrix completion problem.",
        "In this case we compare the estimator obtained from the parallel algorithm with the optimizer obtained from a gradient descent algorithm along the sphere applied to the entire data set.",
        "In order to build a better recommendation systems to users, we can frame the problem of predicting users\u2019 ratings for movies as a low-rank matrix completion problem by learning the rank-r Grassmannian manifold U \u2208 Gr(M, r) which optimizes for the set of observed entries (i , j ) \u2208 \u03a9 the loss function",
        "To optimize with respect to our loss function, we have to find Us+1 = arg min Ls. To do this, we move according to the steepest descent by taking step size \u03bb0 in the direction \u2207Ls(Us) by taking the retraction, Us+1 = R[Us] \u03bb0\u2207Ls (Us ) .2",
        "We propose in this paper a communication efficient parallel algorithm for general optimization problems on manifolds which is applicable to many different manifold spaces and loss functions.",
        "Our proposed algorithm can explore the geometry of the underlying space efficiently and perform well in simulation studies and practical examples all while having theoretical convergence guarantees.",
        "Much of the previous work in parallel inference has only focused on data and parameters in Euclidean space.",
        "Much of the data that we are interested in is better modeled by manifolds and we need fast inference algorithms that are provably suitable for situations beyond the Euclidean setting.",
        "We aim to extend the situations under which parallel inference algorithms are generalizable to manifolds and demonstrate more critical problems in which parallel inference is a crucial solution"
    ],
    "headline": "We show that our proposed algorithm is both communication efficient and carries theoretical convergence guarantees",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Andrew L Alexander, Jee Eun Lee, Mariana Lazar, and Aaron S. Field. Diffusion tensor imaging of the brain. Neurotherapeutics, 4(3):316\u2013329, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alexander%2C%20Andrew%20L.%20Lee%2C%20Jee%20Eun%20Lazar%2C%20Mariana%20Field%2C%20Aaron%20S.%20Diffusion%20tensor%20imaging%20of%20the%20brain%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alexander%2C%20Andrew%20L.%20Lee%2C%20Jee%20Eun%20Lazar%2C%20Mariana%20Field%2C%20Aaron%20S.%20Diffusion%20tensor%20imaging%20of%20the%20brain%202007"
        },
        {
            "id": "2",
            "entry": "[2] Abhishek Bhattacharya and Rabi Bhattacharya. Nonparametric Inference on Manifolds: With Applications to Shape Spaces. IMS Monograph #2. Cambridge University Press, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhattacharya%2C%20Abhishek%20Bhattacharya%2C%20Rabi%20Nonparametric%20Inference%20on%20Manifolds%3A%20With%20Applications%20to%20Shape%20Spaces.%20IMS%20Monograph%20%232%202012"
        },
        {
            "id": "3",
            "entry": "[3] Rabi Bhattacharya and Lizhen Lin. Omnibus CLTs for Fr\u00e9chet means and nonparametric inference on non-Euclidean spaces. The Proceedings of the American Mathematical Society, 145:13\u2013428, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhattacharya%2C%20Rabi%20Lin%2C%20Lizhen%20Omnibus%20CLTs%20for%20Fr%C3%A9chet%20means%20and%20nonparametric%20inference%20on%20non-Euclidean%20spaces%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhattacharya%2C%20Rabi%20Lin%2C%20Lizhen%20Omnibus%20CLTs%20for%20Fr%C3%A9chet%20means%20and%20nonparametric%20inference%20on%20non-Euclidean%20spaces%202017"
        },
        {
            "id": "4",
            "entry": "[4] Rabi Bhattacharya and Vic Patrangenaru. Large sample theory of intrinsic and extrinsic sample means on manifolds. The Annals of Statistics, 31(1):1\u201329, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhattacharya%2C%20Rabi%20Patrangenaru%2C%20Vic%20Large%20sample%20theory%20of%20intrinsic%20and%20extrinsic%20sample%20means%20on%20manifolds%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhattacharya%2C%20Rabi%20Patrangenaru%2C%20Vic%20Large%20sample%20theory%20of%20intrinsic%20and%20extrinsic%20sample%20means%20on%20manifolds%202003"
        },
        {
            "id": "5",
            "entry": "[5] Rabi Bhattacharya and Vic Patrangenaru. Large sample theory of intrinsic and extrinsic sample means on manifolds: II. Ann. Statist., 33:1225\u20131259, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhattacharya%2C%20Rabi%20Patrangenaru%2C%20Vic%20Large%20sample%20theory%20of%20intrinsic%20and%20extrinsic%20sample%20means%20on%20manifolds%3A%20II%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhattacharya%2C%20Rabi%20Patrangenaru%2C%20Vic%20Large%20sample%20theory%20of%20intrinsic%20and%20extrinsic%20sample%20means%20on%20manifolds%3A%20II%202005"
        },
        {
            "id": "6",
            "entry": "[6] Nicolas Boumal. Optimization and estimation on manifolds. PhD thesis, Universit\u00e9 catholique de Louvain, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boumal%2C%20Nicolas%20Optimization%20and%20estimation%20on%20manifolds%202014"
        },
        {
            "id": "7",
            "entry": "[7] Lisandro Dalc\u00edn, Rodrigo Paz, and Mario Storti. MPI for Python. Journal of Parallel and Distributed Computing, 65(9):1108 \u2013 1115, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dalc%C3%ADn%2C%20Lisandro%20Paz%2C%20Rodrigo%20Storti%2C%20Mario%20MPI%20for%20Python%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dalc%C3%ADn%2C%20Lisandro%20Paz%2C%20Rodrigo%20Storti%2C%20Mario%20MPI%20for%20Python%202005"
        },
        {
            "id": "8",
            "entry": "[8] T. Downs, J. Liebman, and W. Mackay. Statistical methods for vectorcardiogram orientations. International Symposium on Vectorcardiography, pages 216\u2013222, 1971.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Downs%2C%20T.%20Liebman%2C%20J.%20Mackay%2C%20W.%20Statistical%20methods%20for%20vectorcardiogram%20orientations%201971",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Downs%2C%20T.%20Liebman%2C%20J.%20Mackay%2C%20W.%20Statistical%20methods%20for%20vectorcardiogram%20orientations%201971"
        },
        {
            "id": "9",
            "entry": "[9] John C. Duchi, Alekh Agarwal, and Martin J. Wainwright. Dual averaging for distributed optimization: Convergence analysis and network scaling. IEEE Transactions on Automatic Control, 57:592\u2013606, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20C.%20Agarwal%2C%20Alekh%20Wainwright%2C%20Martin%20J.%20Dual%20averaging%20for%20distributed%20optimization%3A%20Convergence%20analysis%20and%20network%20scaling%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20C.%20Agarwal%2C%20Alekh%20Wainwright%2C%20Martin%20J.%20Dual%20averaging%20for%20distributed%20optimization%3A%20Convergence%20analysis%20and%20network%20scaling%202012"
        },
        {
            "id": "10",
            "entry": "[10] Maurice Fr\u00e9chet. L\u00e9s \u00e9lements al\u00e9atoires de nature quelconque dans un espace distanci\u00e9. Ann. Inst. H. Poincar\u00e9, 10:215\u2013310, 1948.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fr%C3%A9chet%2C%20Maurice%20L%C3%A9s%20%C3%A9lements%20al%C3%A9atoires%20de%20nature%20quelconque%20dans%20un%20espace%20distanci%C3%A9%201948",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fr%C3%A9chet%2C%20Maurice%20L%C3%A9s%20%C3%A9lements%20al%C3%A9atoires%20de%20nature%20quelconque%20dans%20un%20espace%20distanci%C3%A9%201948"
        },
        {
            "id": "11",
            "entry": "[11] Jeffrey Ho, Kuang-Chih Lee, Ming-Hsuan Yang, and David Kriegman. Visual tracking using learned linear subspaces. In Computer Vision and Pattern Recognition, volume 1, pages I\u2013782\u2013I\u2013789 Vol.1, June 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ho%2C%20Jeffrey%20Lee%2C%20Kuang-Chih%20Yang%2C%20Ming-Hsuan%20Kriegman%2C%20David%20Visual%20tracking%20using%20learned%20linear%20subspaces%202004-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ho%2C%20Jeffrey%20Lee%2C%20Kuang-Chih%20Yang%2C%20Ming-Hsuan%20Kriegman%2C%20David%20Visual%20tracking%20using%20learned%20linear%20subspaces%202004-06"
        },
        {
            "id": "12",
            "entry": "[12] Michael I. Jordan, Jason D. Lee, and Yun Yang. Communication-efficient distributed statistical inference. Journal of the American Statistical Association, 0(ja):0\u20130, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jordan%2C%20Michael%20I.%20Lee%2C%20Jason%20D.%20Yang%2C%20Yun%20Communication-efficient%20distributed%20statistical%20inference%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jordan%2C%20Michael%20I.%20Lee%2C%20Jason%20D.%20Yang%2C%20Yun%20Communication-efficient%20distributed%20statistical%20inference%202018"
        },
        {
            "id": "13",
            "entry": "[13] David G. Kendall. Shape manifolds, Procrustean metrics, and complex projective spaces. Bull. of the London Math. Soc., 16:81\u2013121, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kendall%2C%20David%20G.%20Shape%20manifolds%2C%20Procrustean%20metrics%2C%20and%20complex%20projective%20spaces%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kendall%2C%20David%20G.%20Shape%20manifolds%2C%20Procrustean%20metrics%2C%20and%20complex%20projective%20spaces%201984"
        },
        {
            "id": "14",
            "entry": "[14] Eric Kolaczyk, Lizhen Lin, Steven Rosenberg, and Jackson Walters. Averages of Unlabeled Networks: Geometric Characterization and Asymptotic Behavior. ArXiv e-prints, September 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kolaczyk%2C%20Eric%20Lin%2C%20Lizhen%20Rosenberg%2C%20Steven%20Walters%2C%20Jackson%20Averages%20of%20Unlabeled%20Networks%3A%20Geometric%20Characterization%20and%20Asymptotic%20Behavior.%20ArXiv%20e-prints%202017-09"
        },
        {
            "id": "15",
            "entry": "[15] Sebastian Kurtek, Eric Klassen, John C. Gore, Zhaohua Ding, and Anuj Srivastava. Elastic geodesic paths in shape space of parameterized surfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(9):1717\u20131730, Sept 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kurtek%2C%20Sebastian%20Klassen%2C%20Eric%20Gore%2C%20John%20C.%20Ding%2C%20Zhaohua%20Elastic%20geodesic%20paths%20in%20shape%20space%20of%20parameterized%20surfaces%202012-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kurtek%2C%20Sebastian%20Klassen%2C%20Eric%20Gore%2C%20John%20C.%20Ding%2C%20Zhaohua%20Elastic%20geodesic%20paths%20in%20shape%20space%20of%20parameterized%20surfaces%202012-09"
        },
        {
            "id": "16",
            "entry": "[16] Sebastian Kurtek, Anuj Srivastava, Eric Klassen, and Zhaohua Ding. Statistical modeling of curves using shapes and related features. Journal of the American Statistical Association, 107(499):1152\u20131165, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kurtek%2C%20Sebastian%20Srivastava%2C%20Anuj%20Klassen%2C%20Eric%20Ding%2C%20Zhaohua%20Statistical%20modeling%20of%20curves%20using%20shapes%20and%20related%20features%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kurtek%2C%20Sebastian%20Srivastava%2C%20Anuj%20Klassen%2C%20Eric%20Ding%2C%20Zhaohua%20Statistical%20modeling%20of%20curves%20using%20shapes%20and%20related%20features%202012"
        },
        {
            "id": "17",
            "entry": "[17] Jason D. Lee, Yuekai Sun, Qiang Liu, and Jonathan E. Taylor. Communication-efficient sparse regression: a one-shot approach. CoRR, abs/1503.04337, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.04337"
        },
        {
            "id": "18",
            "entry": "[18] Lizhen Lin, Vinayak Rao, and David B. Dunson. Bayesian nonparametric inference on the Stiefel manifold. Statistics Sinica, 27:535\u2013553, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Lizhen%20Rao%2C%20Vinayak%20Dunson%2C%20David%20B.%20Bayesian%20nonparametric%20inference%20on%20the%20Stiefel%20manifold%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Lizhen%20Rao%2C%20Vinayak%20Dunson%2C%20David%20B.%20Bayesian%20nonparametric%20inference%20on%20the%20Stiefel%20manifold%202017"
        },
        {
            "id": "19",
            "entry": "[19] Lester Mackey, Ameet Talwalkar, and Michael I Jordan. Distributed matrix completion and robust factorization. The Journal of Machine Learning Research, 16(1):913\u2013960, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mackey%2C%20Lester%20Talwalkar%2C%20Ameet%20Jordan%2C%20Michael%20I.%20Distributed%20matrix%20completion%20and%20robust%20factorization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mackey%2C%20Lester%20Talwalkar%2C%20Ameet%20Jordan%2C%20Michael%20I.%20Distributed%20matrix%20completion%20and%20robust%20factorization%202015"
        },
        {
            "id": "20",
            "entry": "[20] Stanislav Minsker, Sanvesh Srivastava, Lizhen Lin, and David B. Dunson. Robust and scalable Bayes via a median of subset posterior measures. Journal of Machine Learning Research, 18(124):1\u201340, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minsker%2C%20Stanislav%20Srivastava%2C%20Sanvesh%20Lin%2C%20Lizhen%20Dunson%2C%20David%20B.%20Robust%20and%20scalable%20Bayes%20via%20a%20median%20of%20subset%20posterior%20measures%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Minsker%2C%20Stanislav%20Srivastava%2C%20Sanvesh%20Lin%2C%20Lizhen%20Dunson%2C%20David%20B.%20Robust%20and%20scalable%20Bayes%20via%20a%20median%20of%20subset%20posterior%20measures%202017"
        },
        {
            "id": "21",
            "entry": "[21] Willie Neiswanger, Chong Wang, and Eric P. Xing. Asymptotically exact, embarrassingly parallel MCMC. In Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence, pages 623\u2013632, 2914.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neiswanger%2C%20Willie%20Wang%2C%20Chong%20Xing%2C%20Eric%20P.%20Asymptotically%20exact%2C%20embarrassingly%20parallel%20MCMC",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neiswanger%2C%20Willie%20Wang%2C%20Chong%20Xing%2C%20Eric%20P.%20Asymptotically%20exact%2C%20embarrassingly%20parallel%20MCMC"
        },
        {
            "id": "22",
            "entry": "[22] Christopher Nemeth, Chris Sherlock, et al. Merging MCMC subposteriors through Gaussianprocess approximations. Bayesian Analysis, 13(2):507\u2013530, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemeth%2C%20Christopher%20Sherlock%2C%20Chris%20Merging%20MCMC%20subposteriors%20through%20Gaussianprocess%20approximations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nemeth%2C%20Christopher%20Sherlock%2C%20Chris%20Merging%20MCMC%20subposteriors%20through%20Gaussianprocess%20approximations%202018"
        },
        {
            "id": "23",
            "entry": "[23] Benjamin Recht and Christopher R\u00e9. Parallel stochastic gradient algorithms for large-scale matrix completion. Mathematical Programming Computation, 5(2):201\u2013226, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Recht%2C%20Benjamin%20R%C3%A9%2C%20Christopher%20Parallel%20stochastic%20gradient%20algorithms%20for%20large-scale%20matrix%20completion%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Recht%2C%20Benjamin%20R%C3%A9%2C%20Christopher%20Parallel%20stochastic%20gradient%20algorithms%20for%20large-scale%20matrix%20completion%202013"
        },
        {
            "id": "24",
            "entry": "[24] Hesamoddin Salehian, Rudrasis Chakraborty, Edward Ofori, David Vaillancourt, and Baba C. Vemuri. An efficient recursive estimator of the Fr\u00e9chet mean on a hypersphere with applications to medical image analysis. In Mathematical Foundations of Computational Anatomy, volume 3, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salehian%2C%20Hesamoddin%20Chakraborty%2C%20Rudrasis%20Ofori%2C%20Edward%20Vaillancourt%2C%20David%20An%20efficient%20recursive%20estimator%20of%20the%20Fr%C3%A9chet%20mean%20on%20a%20hypersphere%20with%20applications%20to%20medical%20image%20analysis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salehian%2C%20Hesamoddin%20Chakraborty%2C%20Rudrasis%20Ofori%2C%20Edward%20Vaillancourt%2C%20David%20An%20efficient%20recursive%20estimator%20of%20the%20Fr%C3%A9chet%20mean%20on%20a%20hypersphere%20with%20applications%20to%20medical%20image%20analysis%202015"
        },
        {
            "id": "25",
            "entry": "[25] Steven L. Scott, Alexander W. Blocker, Fernando V. Bonassi, Hugh A. Chipman, Edward I. George, and Robert E. McCulloch. Bayes and big data: the consensus Monte Carlo algorithm. International Journal of Management Science and Engineering Management, 11(2):78\u201388, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scott%2C%20Steven%20L.%20Blocker%2C%20Alexander%20W.%20Bonassi%2C%20Fernando%20V.%20Chipman%2C%20Hugh%20A.%20Bayes%20and%20big%20data%3A%20the%20consensus%20Monte%20Carlo%20algorithm%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scott%2C%20Steven%20L.%20Blocker%2C%20Alexander%20W.%20Bonassi%2C%20Fernando%20V.%20Chipman%2C%20Hugh%20A.%20Bayes%20and%20big%20data%3A%20the%20consensus%20Monte%20Carlo%20algorithm%202016"
        },
        {
            "id": "26",
            "entry": "[26] Ohad Shamir, Nathan Srebro, and Tong Zhang. Communication-efficient distributed optimization using an approximate newton-type method. In International Conference on Machine Learning, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shamir%2C%20Ohad%20Srebro%2C%20Nathan%20Zhang%2C%20Tong%20Communication-efficient%20distributed%20optimization%20using%20an%20approximate%20newton-type%20method%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shamir%2C%20Ohad%20Srebro%2C%20Nathan%20Zhang%2C%20Tong%20Communication-efficient%20distributed%20optimization%20using%20an%20approximate%20newton-type%20method%202014"
        },
        {
            "id": "27",
            "entry": "[27] G. Prabhu Teja and Sundaram Ravi. Face recognition using subspaces techniques. In International Conference on Recent Trends In Information Technology, pages 103\u2013107, April 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Teja%2C%20G.Prabhu%20Ravi%2C%20Sundaram%20Face%20recognition%20using%20subspaces%20techniques%202012-04",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Teja%2C%20G.Prabhu%20Ravi%2C%20Sundaram%20Face%20recognition%20using%20subspaces%20techniques%202012-04"
        },
        {
            "id": "28",
            "entry": "[28] Xiangyu Wang, Fangjian Guo, Katherine A. Heller, and David B. Dunson. Parallelizing MCMC with random partition trees. In Advances in Neural Information Processing Systems, pages 451\u2013459. 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Xiangyu%20Guo%2C%20Fangjian%20Heller%2C%20Katherine%20A.%20Dunson%2C%20David%20B.%20Parallelizing%20MCMC%20with%20random%20partition%20trees%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Xiangyu%20Guo%2C%20Fangjian%20Heller%2C%20Katherine%20A.%20Dunson%2C%20David%20B.%20Parallelizing%20MCMC%20with%20random%20partition%20trees%202015"
        },
        {
            "id": "29",
            "entry": "[29] Michael Minyi Zhang, Henry Lam, and Lizhen Lin. Robust and parallel Bayesian model selection. Computational Statistics and Data Analysis, 127:229 \u2013 247, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Michael%20Minyi%20Lam%2C%20Henry%20Lin%2C%20Lizhen%20Robust%20and%20parallel%20Bayesian%20model%20selection%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Michael%20Minyi%20Lam%2C%20Henry%20Lin%2C%20Lizhen%20Robust%20and%20parallel%20Bayesian%20model%20selection%202018"
        },
        {
            "id": "30",
            "entry": "[30] Yuchen Zhang, John C. Duchi, and Martin J. Wainwright. Communication-efficient algorithms for statistical optimization. Journal of Machine Learning Research, 14:3321\u20133363, 2013. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Yuchen%20Duchi%2C%20John%20C.%20Wainwright%2C%20Martin%20J.%20Communication-efficient%20algorithms%20for%20statistical%20optimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Yuchen%20Duchi%2C%20John%20C.%20Wainwright%2C%20Martin%20J.%20Communication-efficient%20algorithms%20for%20statistical%20optimization%202013"
        }
    ]
}
