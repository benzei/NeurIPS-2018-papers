{
    "filename": "7714-spectral-filtering-for-general-linear-dynamical-systems.pdf",
    "metadata": {
        "title": "Spectral Filtering for General Linear Dynamical Systems",
        "date": 2018,
        "author": "Elad Hazan Princeton University & Google Brain ehazan@cs.princeton.edu",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7714-spectral-filtering-for-general-linear-dynamical-systems.pdf"
        },
        "abstract": "We give a polynomial-time algorithm for learning latent-state linear dynamical systems without system identification, and without assumptions on the spectral radius of the system\u2019s transition matrix. The algorithm extends the recently introduced technique of spectral filtering, previously applied only to systems with a symmetric transition matrix, using a novel convex relaxation to allow for the efficient identification of phases."
    },
    "keywords": [
        {
            "term": "spectral radius",
            "url": "https://en.wikipedia.org/wiki/spectral_radius"
        },
        {
            "term": "polynomial time algorithm",
            "url": "https://en.wikipedia.org/wiki/polynomial_time_algorithm"
        },
        {
            "term": "online convex optimization",
            "url": "https://en.wikipedia.org/wiki/online_convex_optimization"
        },
        {
            "term": "maximum likelihood estimation",
            "url": "https://en.wikipedia.org/wiki/maximum_likelihood_estimation"
        },
        {
            "term": "time series prediction",
            "url": "https://en.wikipedia.org/wiki/time_series_prediction"
        },
        {
            "term": "linear dynamical system",
            "url": "https://en.wikipedia.org/wiki/linear_dynamical_system"
        },
        {
            "term": "time series analysis",
            "url": "https://en.wikipedia.org/wiki/time_series_analysis"
        },
        {
            "term": "transition matrix",
            "url": "https://en.wikipedia.org/wiki/transition_matrix"
        },
        {
            "term": "recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_networks"
        },
        {
            "term": "system identification",
            "url": "https://en.wikipedia.org/wiki/system_identification"
        }
    ],
    "highlights": [
        "Linear dynamical systems (LDSs) are a cornerstone of signal processing and time series analysis",
        "The problem of predicting the response signal arising from a Linear dynamical systems is a fundamental problem in machine learning, with a history of more than half a century",
        "Building on recent advances in spectral filtering, we develop a novel convex relaxation for Linear dynamical systems, resulting in an efficient algorithm for the Linear dynamical systems prediction problem in the general setting",
        "We develop a more general analogue of the structural result from [HSZ17], which holds for systems with asymmetric transition matrix",
        "As an intermediate step toward the main theorem, we show a regret bound on the total least-squares prediction error made by Algorithm 1, compared to the best pseudo-Linear dynamical systems in hindsight",
        "We times a competitive ratio depending on the show this by showing that any noise has a bounded effect on the predictions of the pseudo-Linear dynamical systems.2"
    ],
    "key_statements": [
        "Linear dynamical systems (LDSs) are a cornerstone of signal processing and time series analysis",
        "The problem of predicting the response signal arising from a Linear dynamical systems is a fundamental problem in machine learning, with a history of more than half a century",
        "An Linear dynamical systems is given by matrices (",
        "Building on recent advances in spectral filtering, we develop a novel convex relaxation for Linear dynamical systems, resulting in an efficient algorithm for the Linear dynamical systems prediction problem in the general setting",
        "The structural result which drives the theorem is that the dynamics of any true Linear dynamical systems are approximated by such a pseudo-Linear dynamical systems, with reasonably small parameters and coefficients",
        "There are three parts to the analysis, which we outline in the following subsections: proving the approximability of an Linear dynamical systems by a pseudo-Linear dynamical systems, bounding the regret incurred by the algorithm against the best pseudo-Linear dynamical systems, and analyzing the effect of noise",
        "We develop a more general analogue of the structural result from [HSZ17], which holds for systems with asymmetric transition matrix",
        "As an intermediate step toward the main theorem, we show a regret bound on the total least-squares prediction error made by Algorithm 1, compared to the best pseudo-Linear dynamical systems in hindsight",
        "We times a competitive ratio depending on the show this by showing that any noise has a bounded effect on the predictions of the pseudo-Linear dynamical systems.2",
        "Be the predictions of the best pseudo-Linear dynamical systems, we have\n2In other words, the prediction error of the pseudo-Linear dynamical systems is stable to noise, and we bound its"
    ],
    "summary": [
        "Linear dynamical systems (LDSs) are a cornerstone of signal processing and time series analysis.",
        "Building on recent advances in spectral filtering, we develop a novel convex relaxation for LDSs, resulting in an efficient algorithm for the LDS prediction problem in the general setting.",
        "[HSZ17] show how to efficiently learn an LDS in the online prediction setting, without any generative assumptions, and without dependence on the condition number.",
        ", These are the straightforward analogues of the matrix norms defined in [KSST12], and appear in the regularization of the online prediction algorithm.",
        "Our online prediction algorithm is follow-the-regularized-leader (FTRL), which requires the solution of a convex program at each iteration.",
        ". The structural result which drives the theorem is that the dynamics of any true LDS are approximated by such a pseudo-LDS, with reasonably small parameters and coefficients.",
        "There are three parts to the analysis, which we outline in the following subsections: proving the approximability of an LDS by a pseudo-LDS, bounding the regret incurred by the algorithm against the best pseudo-LDS, and analyzing the effect of noise",
        "As an intermediate step toward the main theorem, we show a regret bound on the total least-squares prediction error made by Algorithm 1, compared to the best pseudo-LDS in hindsight.",
        "Denote the predictions made by the fixed pseudo-LDS minimizing the total squared-norm error.",
        ". To this end, we use a modification of the strongly convex matrix regularizer found in [KSST12], resulting in a regret bound with logarithmic dependence on",
        "We note that the regret analysis can be used directly with the approximation result for autoregressive models (Theorem 1), without wave-filtering.",
        "We times a competitive ratio depending on the show this by showing that any noise has a bounded effect on the predictions of the pseudo-LDS.2",
        "2In other words, the prediction error of the pseudo-LDS is stable to noise, and we bound its",
        "This comprises a hard case for direct system identification: long-term time dependences between input and output, and the optimization landscape is non-convex, with many local minima.",
        "To the best of our knowledge, polynomial-time algorithm for prediction in the general LDS setting without dependence on the spectral radius parameter of the underlying system.",
        "If the LDS is explicitly identified, the best predictor is the Kalman filter, which, when unrolled, depends on feedback for all previous time steps, and only incurs a cost"
    ],
    "headline": "Building on recent advances in spectral filtering, we develop a novel convex relaxation for Linear dynamical systems, resulting in an efficient algorithm for the Linear dynamical systems prediction problem in the general setting",
    "reference_links": [
        {
            "id": "Anava_et+al_2013_a",
            "entry": "[AHMS13] Oren Anava, Elad Hazan, Shie Mannor, and Ohad Shamir. Online learning for time series prediction. In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ, USA, pages 172\u2013184, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=AHMS13%20Oren%20Anava%20Elad%20Hazan%20Shie%20Mannor%20and%20Ohad%20Shamir%20Online%20learning%20for%20time%20series%20prediction%20In%20COLT%202013%20%20The%2026th%20Annual%20Conference%20on%20Learning%20Theory%20June%201214%202013%20Princeton%20University%20NJ%20USA%20pages%20172184%202013"
        },
        {
            "id": "Abbasi-Yadkori_2011_a",
            "entry": "[AYS11] Yasin Abbasi-Yadkori and Csaba Szepesv\u00e1ri. Regret bounds for the adaptive control of linear quadratic systems. In Proceedings of the 24th Annual Conference on Learning Theory, pages 1\u201326, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbasi-Yadkori%2C%20Yasin%20Szepesv%C3%A1ri%2C%20Csaba%20Regret%20bounds%20for%20the%20adaptive%20control%20of%20linear%20quadratic%20systems%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abbasi-Yadkori%2C%20Yasin%20Szepesv%C3%A1ri%2C%20Csaba%20Regret%20bounds%20for%20the%20adaptive%20control%20of%20linear%20quadratic%20systems%202011"
        },
        {
            "id": "Brockwell_2009_a",
            "entry": "[BD09] P. Brockwell and R. Davis. Time Series: Theory and Methods. Springer, 2 edition, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brockwell%2C%20P.%20Davis%2C%20R.%20Time%20Series%3A%20Theory%20and%20Methods%202009"
        },
        {
            "id": "Box_et+al_1994_a",
            "entry": "[BJR94] G. Box, G. Jenkins, and G. Reinsel. Time Series Analysis: Forecasting and Control. Prentice-Hall, 3 edition, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Box%2C%20G.%20Jenkins%2C%20G.%20Reinsel%2C%20G.%20Time%20Series%20Analysis%3A%20Forecasting%20and%20Control%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Box%2C%20G.%20Jenkins%2C%20G.%20Reinsel%2C%20G.%20Time%20Series%20Analysis%3A%20Forecasting%20and%20Control%201994"
        },
        {
            "id": "Belanger_2015_a",
            "entry": "[BK15] David Belanger and Sham Kakade. A linear dynamical system model for text. In International Conference on Machine Learning, pages 833\u2013842, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belanger%2C%20David%20Kakade%2C%20Sham%20A%20linear%20dynamical%20system%20model%20for%20text%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belanger%2C%20David%20Kakade%2C%20Sham%20A%20linear%20dynamical%20system%20model%20for%20text%202015"
        },
        {
            "id": "Boley_et+al_1998_a",
            "entry": "[BLV98] Daniel L Boley, Franklin T Luk, and David Vandevoorde. A fast method to diagonalize a Hankel matrix. Linear algebra and its applications, 284(1-3):41\u201352, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boley%2C%20Daniel%20L.%20Luk%2C%20Franklin%20T.%20Vandevoorde%2C%20David%20A%20fast%20method%20to%20diagonalize%20a%20Hankel%20matrix%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boley%2C%20Daniel%20L.%20Luk%2C%20Franklin%20T.%20Vandevoorde%2C%20David%20A%20fast%20method%20to%20diagonalize%20a%20Hankel%20matrix%201998"
        },
        {
            "id": "Beckermann_2017_a",
            "entry": "[BT17] Bernhard Beckermann and Alex Townsend. On the singular values of matrices with displacement structure. SIAM Journal on Matrix Analysis and Applications, 38(4):1227\u20131248, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beckermann%2C%20Bernhard%20Townsend%2C%20Alex%20On%20the%20singular%20values%20of%20matrices%20with%20displacement%20structure%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beckermann%2C%20Bernhard%20Townsend%2C%20Alex%20On%20the%20singular%20values%20of%20matrices%20with%20displacement%20structure%202017"
        },
        {
            "id": "Cesa-Bianchi_2006_a",
            "entry": "[CBL06] Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge University Press, New York, NY, USA, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cesa-Bianchi%2C%20Nicolo%20Prediction%2C%20Gabor%20Lugosi%20Learning%2C%20and%20Games%202006"
        },
        {
            "id": "Choi_1983_a",
            "entry": "[Cho83] Man-Duen Choi. Tricks or treats with the hilbert matrix. The American Mathematical Monthly, 90(5):301\u2013312, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Man-Duen%20Tricks%20or%20treats%20with%20the%20hilbert%20matrix%201983",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Man-Duen%20Tricks%20or%20treats%20with%20the%20hilbert%20matrix%201983"
        },
        {
            "id": "Dean_et+al_2017_a",
            "entry": "[DMM+17] Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, and Stephen Tu. On the sample complexity of the linear quadratic regulator. arXiv preprint arXiv:1710.01688, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.01688"
        },
        {
            "id": "Hazan_et+al_2007_a",
            "entry": "[HAK07] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Mach. Learn., 69(2-3):169\u2013192, December 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Agarwal%2C%20Amit%20Kale%2C%20Satyen%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Agarwal%2C%20Amit%20Kale%2C%20Satyen%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007-12"
        },
        {
            "id": "Hamilton_1994_a",
            "entry": "[Ham94] J. Hamilton. Time Series Analysis. Princeton Univ. Press, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hamilton%2C%20J.%20Time%20Series%20Analysis%201994"
        },
        {
            "id": "Hazan_2016_a",
            "entry": "[Haz16] Elad Hazan. Introduction to online convex optimization. Foundations and Trends in Optimization, 2(3-4):157\u2013325, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Introduction%20to%20online%20convex%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Introduction%20to%20online%20convex%20optimization%202016"
        },
        {
            "id": "Hilbert_0000_a",
            "entry": "[Hil94] David Hilbert. Ein beitrag zur theorie des legendre\u2019schen polynoms. Acta mathematica, 18(1):155\u2013159, 1894.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hilbert%2C%20David%20Ein%20beitrag%20zur%20theorie%20des%20legendre%E2%80%99schen%20polynoms",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hilbert%2C%20David%20Ein%20beitrag%20zur%20theorie%20des%20legendre%E2%80%99schen%20polynoms"
        },
        {
            "id": "Hardt_et+al_2016_a",
            "entry": "[HMR16] Moritz Hardt, Tengyu Ma, and Benjamin Recht. Gradient descent learns linear dynamical systems. arXiv preprint arXiv:1609.05191, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.05191"
        },
        {
            "id": "Hazan_et+al_2017_a",
            "entry": "[HSZ17] Elad Hazan, Karan Singh, and Cyril Zhang. Learning linear dynamical systems via spectral filtering. In Advances in Neural Information Processing Systems, pages 6705\u2013 6715, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Singh%2C%20Karan%20Zhang%2C%20Cyril%20Learning%20linear%20dynamical%20systems%20via%20spectral%20filtering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Singh%2C%20Karan%20Zhang%2C%20Cyril%20Learning%20linear%20dynamical%20systems%20via%20spectral%20filtering%202017"
        },
        {
            "id": "Kalman_1960_a",
            "entry": "[Kal60] Rudolph Emil Kalman. A new approach to linear filtering and prediction problems. Journal of Basic Engineering, 82.1:35\u201345, 1960.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kalman%2C%20Rudolph%20Emil%20A%20new%20approach%20to%20linear%20filtering%20and%20prediction%20problems%201960",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kalman%2C%20Rudolph%20Emil%20A%20new%20approach%20to%20linear%20filtering%20and%20prediction%20problems%201960"
        },
        {
            "id": "Kuznetsov_2016_a",
            "entry": "[KM16] Vitaly Kuznetsov and Mehryar Mohri. Time series prediction and online learning. In Vitaly Feldman, Alexander Rakhlin, and Ohad Shamir, editors, 29th Annual Conference on Learning Theory, volume 49 of Proceedings of Machine Learning Research, pages 1190\u20131213, Columbia University, New York, New York, USA, 23\u201326 Jun 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuznetsov%2C%20Vitaly%20Mohri%2C%20Mehryar%20Time%20series%20prediction%20and%20online%20learning%202016-06-23",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuznetsov%2C%20Vitaly%20Mohri%2C%20Mehryar%20Time%20series%20prediction%20and%20online%20learning%202016-06-23"
        },
        {
            "id": "Kuznetsov_2017_a",
            "entry": "[KM17] Vitaly Kuznetsov and Mehryar Mohri. Discriminative state space models. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5671\u20135679. Curran Associates, Inc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuznetsov%2C%20Vitaly%20Mohri%2C%20Mehryar%20Discriminative%20state%20space%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuznetsov%2C%20Vitaly%20Mohri%2C%20Mehryar%20Discriminative%20state%20space%20models%202017"
        },
        {
            "id": "Kakade_et+al_2012_a",
            "entry": "[KSST12] Sham M Kakade, Shai Shalev-Shwartz, and Ambuj Tewari. Regularization techniques for learning with matrices. Journal of Machine Learning Research, 13(Jun):1865\u2013 1890, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kakade%2C%20Sham%20M.%20Shalev-Shwartz%2C%20Shai%20Tewari%2C%20Ambuj%20Regularization%20techniques%20for%20learning%20with%20matrices%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kakade%2C%20Sham%20M.%20Shalev-Shwartz%2C%20Shai%20Tewari%2C%20Ambuj%20Regularization%20techniques%20for%20learning%20with%20matrices%202012"
        },
        {
            "id": "Ljung_1998_a",
            "entry": "[Lju98] Lennart Ljung. System identification: Theory for the User. Prentice Hall, Upper Saddle Riiver, NJ, 2 edition, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ljung%2C%20Lennart%20System%20identification%3A%20Theory%20for%20the%20User%201998"
        },
        {
            "id": "Moon_2007_a",
            "entry": "[MW07] Taesup Moon and Tsachy Weissman. Competitive on-line linear fir mmse filtering. In IEEE International Symposium on Information Theory - Proceedings, pages 1126 \u2013 1130, 07 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Moon%2C%20Taesup%20Weissman%2C%20Tsachy%20Competitive%20on-line%20linear%20fir%20mmse%20filtering%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Moon%2C%20Taesup%20Weissman%2C%20Tsachy%20Competitive%20on-line%20linear%20fir%20mmse%20filtering%202007"
        },
        {
            "id": "Roweis_1999_a",
            "entry": "[RG99] Sam Roweis and Zoubin Ghahramani. A unifying review of linear gaussian models. Neural computation, 11(2):305\u2013345, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roweis%2C%20Sam%20Ghahramani%2C%20Zoubin%20A%20unifying%20review%20of%20linear%20gaussian%20models%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roweis%2C%20Sam%20Ghahramani%2C%20Zoubin%20A%20unifying%20review%20of%20linear%20gaussian%20models%201999"
        },
        {
            "id": "Overschee_2012_a",
            "entry": "[VODM12] Peter Van Overschee and BL De Moor. Subspace Identification for Linear Systems. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Overschee%2C%20Peter%20Van%20Moor%2C%20B.L.De%20Subspace%20Identification%20for%20Linear%20Systems%202012"
        },
        {
            "id": "Zhou_et+al_1996_a",
            "entry": "[ZDG+96] Kemin Zhou, John Comstock Doyle, Keith Glover, et al. Robust and optimal control, volume 40. Prentice hall New Jersey, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Kemin%20Doyle%2C%20John%20Comstock%20Glover%2C%20Keith%20Robust%20and%20optimal%20control%2C%20volume%2040%201996"
        }
    ]
}
