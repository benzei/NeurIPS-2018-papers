{
    "filename": "8277-bias-and-generalization-in-deep-generative-models-an-empirical-study.pdf",
    "metadata": {
        "title": "Bias and Generalization in Deep Generative Models: An Empirical Study",
        "author": "Shengjia Zhao, Hongyu Ren, Arianna Yuan, Jiaming Song, Noah Goodman, Stefano Ermon",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8277-bias-and-generalization-in-deep-generative-models-an-empirical-study.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In high dimensional settings, density estimation algorithms rely crucially on their inductive bias. Despite recent empirical success, the inductive bias of deep generative models is not well understood. In this paper we propose a framework to systematically investigate bias and generalization in deep generative models of images. Inspired by experimental methods from cognitive psychology, we probe each learning algorithm with carefully designed training datasets to characterize when and how existing models generate novel attributes and their combinations. We identify similarities to human psychology and verify that these patterns are consistent across commonly used models and architectures."
    },
    "keywords": [
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        },
        {
            "term": "input output",
            "url": "https://en.wikipedia.org/wiki/input_output"
        },
        {
            "term": "psychology",
            "url": "https://en.wikipedia.org/wiki/psychology"
        },
        {
            "term": "high dimensional",
            "url": "https://en.wikipedia.org/wiki/high_dimensional"
        },
        {
            "term": "inductive bias",
            "url": "https://en.wikipedia.org/wiki/inductive_bias"
        },
        {
            "term": "empirical study",
            "url": "https://en.wikipedia.org/wiki/empirical_study"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        }
    ],
    "highlights": [
        "The goal of a density estimation algorithm is to learn a distribution from training data (Figure 1,A)",
        "When the modes are far from each other, convolution predicts the model\u2019s behavior very well. These results are consistent for Generative Adversarial Networks/variational autoencoders and different architectures/hyper-parameters (Appendix A).\n0.0 p0r.o2por0ti.o4n of0r.e6d co0l.o8r 1.0 density predicted by convolution\n6 4 2 0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0 density\n7.5 actual learned distribution\n5.0 2.5 0.0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0 density density\n0.0 p0r.o2por0ti.o4n of0r.e6d co0l.o8r 1.0\n0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0\n0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0",
        "As the variance increases, modes that did not demonstrate prototype enhancement are starting to merge, verifying our previous conclusions. These results are consistent for Generative Adversarial Networks/variational autoencoders and CNN/FC networks (Appendix A).\n5 Characterizing Generalization on Multiple Features",
        "In this paper we proposed an approach to study generative modeling algorithms using carefully designed training sets",
        "The first question is what is the key ingredient that leads to the behaviors we have observed, since we explored two types of models (GAN/variational autoencoders), both of which have two very different architectures, training objectives, and hyper-parameter choices (Appendix A)"
    ],
    "key_statements": [
        "The goal of a density estimation algorithm is to learn a distribution from training data (Figure 1,A)",
        "The assumptions made by a learning algorithm, or its inductive bias, are key when practical data regimes are concerned",
        "The challenge with this approach is that both inputs and outputs are high dimensional, making it difficult to exhaustively characterize the input-output relationship",
        "We propose to adopt experimental methods from cognitive psychology to characterize the generalization biases of machine intelligence",
        "When the modes are far from each other, convolution predicts the model\u2019s behavior very well. These results are consistent for Generative Adversarial Networks/variational autoencoders and different architectures/hyper-parameters (Appendix A).\n0.0 p0r.o2por0ti.o4n of0r.e6d co0l.o8r 1.0 density predicted by convolution\n6 4 2 0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0 density\n7.5 actual learned distribution\n5.0 2.5 0.0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0 density density\n0.0 p0r.o2por0ti.o4n of0r.e6d co0l.o8r 1.0\n0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0\n0 0.0 p0ro.2port0io.4n of0r.6ed c0o.l8or 1.0",
        "As the variance increases, modes that did not demonstrate prototype enhancement are starting to merge, verifying our previous conclusions. These results are consistent for Generative Adversarial Networks/variational autoencoders and CNN/FC networks (Appendix A).\n5 Characterizing Generalization on Multiple Features",
        "In this paper we proposed an approach to study generative modeling algorithms using carefully designed training sets",
        "We hope that the framework and methodology we propose will stimulate further investigation into the empirical behavior of generative modeling algorithms, as several questions are still open",
        "The first question is what is the key ingredient that leads to the behaviors we have observed, since we explored two types of models (GAN/variational autoencoders), both of which have two very different architectures, training objectives, and hyper-parameter choices (Appendix A)"
    ],
    "summary": [
        "The goal of a density estimation algorithm is to learn a distribution from training data (Figure 1,A).",
        "When presented with a training set where all images contain exactly 3 objects, both GANs and VAEs typically generate 2-5 objects, with a log-normal shaped distribution (Figure 1,B).",
        "An exception is when the modes are close to each other (e.g., 2 and 4 objects) where we observe prototype enhancement effect [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>]: the learned distribution assigns higher probability to the mean number of objects (3 in our example), even though no image with 3 objects was present in the training set (Figure 1,C).",
        "We take inspiration from cognitive psychology, and provide a novel framework to analyze empirically the inductive bias of generative algorithms via a set of probing features.",
        "Our goal is to investigate how p(z) differs from q(z), i.e. the generalization behavior of the learning algorithm restricted to the feature space Z.",
        "Results and Discussion As shown in Figure 2 and quantitatively evaluated in Figure 3, in both colored dots and CLEVR experiments, the learned distribution does not produce the same number of objects as in the dataset on which it was trained.",
        "Experimental Settings For these experiments we use the color proportion feature of the pie dataset in Figure 4.",
        "When studying if generalization on proportion of red color zred is independent of other features, the training distribution p is chosen such that the marginal on p is uniform on {0.3, 0.4, 0.9}.",
        "A perfect precision means that the learned distribution only generates combinations in the training set.",
        "This means that there is no mode missing, and essentially all combinations in the training set are captured by the learned distribution.",
        "The results are independent of the size of the dataset, and no difference was observed with only half or twice as many training examples.",
        "For multiple features we explored when the model generates novel combinations, and found strong dependence on the number of existing combinations in the training set.",
        "In addition we visualized the learned distribution and found that novel combinations are generated while preserving the marginal on each individual feature.",
        "The first question is what is the key ingredient that leads to the behaviors we have observed, since we explored two types of models (GAN/VAE), both of which have two very different architectures, training objectives, and hyper-parameter choices (Appendix A)."
    ],
    "headline": "In this paper we propose a framework to systematically investigate bias and generalization in deep generative models of images",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Rosenblatt, \u201cRemarks on some nonparametric estimates of a density function,\u201d The Annals of Mathematical Statistics, pp. 832\u2013837, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosenblatt%2C%20M.%20Remarks%20on%20some%20nonparametric%20estimates%20of%20a%20density%20function%2C%201956",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosenblatt%2C%20M.%20Remarks%20on%20some%20nonparametric%20estimates%20of%20a%20density%20function%2C%201956"
        },
        {
            "id": "2",
            "entry": "[2] S. Efromovich, \u201cOrthogonal series density estimation,\u201d Wiley Interdisciplinary Reviews: Computational Statistics, vol. 2, no. 4, pp. 467\u2013476, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Efromovich%2C%20S.%20Orthogonal%20series%20density%20estimation%2C%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Efromovich%2C%20S.%20Orthogonal%20series%20density%20estimation%2C%202010"
        },
        {
            "id": "3",
            "entry": "[3] S. Arora and Y. Zhang, \u201cDo gans actually learn the distribution? an empirical study,\u201d arXiv preprint arXiv:1706.08224, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.08224"
        },
        {
            "id": "4",
            "entry": "[4] D. P. Kingma and M. Welling, \u201cAuto-encoding variational bayes,\u201d arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "5",
            "entry": "[5] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u201cGenerative adversarial nets,\u201d in Advances in neural information processing systems, pp. 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%2C%202014"
        },
        {
            "id": "6",
            "entry": "[6] D. J. Rezende, S. Mohamed, and D. Wierstra, \u201cStochastic backpropagation and approximate inference in deep generative models,\u201d arXiv preprint arXiv:1401.4082, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1401.4082"
        },
        {
            "id": "7",
            "entry": "[7] S. Zhao, J. Song, and S. Ermon, \u201cA lagrangian perspective on latent variable generative models,\u201d Proc. 34th Conference on Uncertainty in Artificial Intelligence, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20S.%20Song%2C%20J.%20Ermon%2C%20S.%20A%20lagrangian%20perspective%20on%20latent%20variable%20generative%20models%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20S.%20Song%2C%20J.%20Ermon%2C%20S.%20A%20lagrangian%20perspective%20on%20latent%20variable%20generative%20models%2C%202018"
        },
        {
            "id": "8",
            "entry": "[8] J. Ho and S. Ermon, \u201cGenerative adversarial imitation learning,\u201d in Advances in Neural Information Processing Systems, pp. 4565\u20134573, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ho%2C%20J.%20Ermon%2C%20S.%20Generative%20adversarial%20imitation%20learning%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ho%2C%20J.%20Ermon%2C%20S.%20Generative%20adversarial%20imitation%20learning%2C%202016"
        },
        {
            "id": "9",
            "entry": "[9] G. A. Alvarez, \u201cRepresenting multiple objects as an ensemble enhances visual cognition,\u201d Trends in cognitive sciences, vol. 15, no. 3, pp. 122\u2013131, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alvarez%2C%20G.A.%20Representing%20multiple%20objects%20as%20an%20ensemble%20enhances%20visual%20cognition%2C%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alvarez%2C%20G.A.%20Representing%20multiple%20objects%20as%20an%20ensemble%20enhances%20visual%20cognition%2C%202011"
        },
        {
            "id": "10",
            "entry": "[10] J. P. Minda and J. D. Smith, \u201cPrototype models of categorization: Basic formulation, predictions, and limitations,\u201d Formal approaches in categorization, pp. 40\u201364, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minda%2C%20J.P.%20Smith%2C%20J.D.%20Prototype%20models%20of%20categorization%3A%20Basic%20formulation%2C%20predictions%2C%20and%20limitations%2C%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Minda%2C%20J.P.%20Smith%2C%20J.D.%20Prototype%20models%20of%20categorization%3A%20Basic%20formulation%2C%20predictions%2C%20and%20limitations%2C%202011"
        },
        {
            "id": "11",
            "entry": "[11] S. S. Stevens, Psychophysics: Introduction to its perceptual, neural and social prospects. Routledge, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stevens%2C%20S.S.%20Psychophysics%3A%20Introduction%20to%20its%20perceptual%2C%20neural%20and%20social%20prospects%202017"
        },
        {
            "id": "12",
            "entry": "[12] T. M. Mitchell, The need for biases in learning generalizations. Department of Computer Science, Laboratory for Computer Science Research, Rutgers Univ. New Jersey, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mitchell%2C%20T.M.%20The%20need%20for%20biases%20in%20learning%20generalizations%201980"
        },
        {
            "id": "13",
            "entry": "[13] C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals, \u201cUnderstanding deep learning requires rethinking generalization,\u201d arXiv preprint arXiv:1611.03530, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.03530"
        },
        {
            "id": "14",
            "entry": "[14] N. S. Keskar, D. Mudigere, J. Nocedal, M. Smelyanskiy, and P. T. P. Tang, \u201cOn large-batch training for deep learning: Generalization gap and sharp minima,\u201d arXiv preprint arXiv:1609.04836, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.04836"
        },
        {
            "id": "15",
            "entry": "[15] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel, \u201cInfogan: Interpretable representation learning by information maximizing generative adversarial nets,\u201d in Advances in Neural Information Processing Systems, pp. 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%2C%202016"
        },
        {
            "id": "16",
            "entry": "[16] S. Zhao, J. Song, and S. Ermon, \u201cLearning hierarchical features from deep generative models,\u201d in International Conference on Machine Learning, pp. 4091\u20134099, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20S.%20Song%2C%20J.%20Ermon%2C%20S.%20Learning%20hierarchical%20features%20from%20deep%20generative%20models%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20S.%20Song%2C%20J.%20Ermon%2C%20S.%20Learning%20hierarchical%20features%20from%20deep%20generative%20models%2C%202017"
        },
        {
            "id": "17",
            "entry": "[17] Y. Li, J. Song, and S. Ermon, \u201cInfogail: Interpretable imitation learning from visual demonstrations,\u201d in Advances in Neural Information Processing Systems, pp. 3812\u20133822, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Y.%20Song%2C%20J.%20Ermon%2C%20S.%20Infogail%3A%20Interpretable%20imitation%20learning%20from%20visual%20demonstrations%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Y.%20Song%2C%20J.%20Ermon%2C%20S.%20Infogail%3A%20Interpretable%20imitation%20learning%20from%20visual%20demonstrations%2C%202017"
        },
        {
            "id": "18",
            "entry": "[18] L. Theis, A. v. d. Oord, and M. Bethge, \u201cA note on the evaluation of generative models,\u201d arXiv preprint arXiv:1511.01844, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.01844"
        },
        {
            "id": "19",
            "entry": "[19] A. Borji, \u201cPros and cons of gan evaluation measures,\u201d arXiv preprint arXiv:1802.03446, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.03446"
        },
        {
            "id": "20",
            "entry": "[20] A. Grover, M. Dhar, and S. Ermon, \u201cFlow-GAN: Combining maximum likelihood and adversarial learning in generative models,\u201d in AAAI Conference on Artificial Intelligence, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grover%2C%20A.%20Dhar%2C%20M.%20Ermon%2C%20S.%20Flow-GAN%3A%20Combining%20maximum%20likelihood%20and%20adversarial%20learning%20in%20generative%20models%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grover%2C%20A.%20Dhar%2C%20M.%20Ermon%2C%20S.%20Flow-GAN%3A%20Combining%20maximum%20likelihood%20and%20adversarial%20learning%20in%20generative%20models%2C%202018"
        },
        {
            "id": "21",
            "entry": "[21] A. Gretton, K. M. Borgwardt, M. Rasch, B. Sch\u00f6lkopf, and A. J. Smola, \u201cA kernel method for the two-sample-problem,\u201d in Advances in neural information processing systems, pp. 513\u2013520, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Rasch%2C%20M.%20Sch%C3%B6lkopf%2C%20B.%20A%20kernel%20method%20for%20the%20two-sample-problem%2C%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Rasch%2C%20M.%20Sch%C3%B6lkopf%2C%20B.%20A%20kernel%20method%20for%20the%20two-sample-problem%2C%202007"
        },
        {
            "id": "22",
            "entry": "[22] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, G. Klambauer, and S. Hochreiter, \u201cGans trained by a two time-scale update rule converge to a nash equilibrium,\u201d arXiv preprint arXiv:1706.08500, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.08500"
        },
        {
            "id": "23",
            "entry": "[23] T. Che, Y. Li, A. P. Jacob, Y. Bengio, and W. Li, \u201cMode regularized generative adversarial networks,\u201d arXiv preprint arXiv:1612.02136, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.02136"
        },
        {
            "id": "24",
            "entry": "[24] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen, \u201cImproved techniques for training gans,\u201d in Advances in Neural Information Processing Systems, pp. 2234\u2013 2242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20T.%20Goodfellow%2C%20I.%20Zaremba%2C%20W.%20Cheung%2C%20V.%20Improved%20techniques%20for%20training%20gans%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20T.%20Goodfellow%2C%20I.%20Zaremba%2C%20W.%20Cheung%2C%20V.%20Improved%20techniques%20for%20training%20gans%2C%202016"
        },
        {
            "id": "25",
            "entry": "[25] M. Rosenblatt, \u201cA central limit theorem and a strong mixing condition,\u201d Proceedings of the National Academy of Sciences, vol. 42, no. 1, pp. 43\u201347, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosenblatt%2C%20M.%20A%20central%20limit%20theorem%20and%20a%20strong%20mixing%20condition%2C%201956",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosenblatt%2C%20M.%20A%20central%20limit%20theorem%20and%20a%20strong%20mixing%20condition%2C%201956"
        },
        {
            "id": "26",
            "entry": "[26] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville, \u201cImproved training of wasserstein gans,\u201d arXiv preprint arXiv:1704.00028, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.00028"
        },
        {
            "id": "27",
            "entry": "[27] A. Nieder, D. J. Freedman, and E. K. Miller, \u201cRepresentation of the quantity of visual items in the primate prefrontal cortex,\u201d Science, vol. 297, no. 5587, pp. 1708\u20131711, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nieder%2C%20A.%20Freedman%2C%20D.J.%20Miller%2C%20E.K.%20Representation%20of%20the%20quantity%20of%20visual%20items%20in%20the%20primate%20prefrontal%20cortex%2C%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nieder%2C%20A.%20Freedman%2C%20D.J.%20Miller%2C%20E.K.%20Representation%20of%20the%20quantity%20of%20visual%20items%20in%20the%20primate%20prefrontal%20cortex%2C%202002"
        },
        {
            "id": "28",
            "entry": "[28] M. Piazza, V. Izard, P. Pinel, D. Le Bihan, and S. Dehaene, \u201cTuning curves for approximate numerosity in the human intraparietal sulcus,\u201d Neuron, vol. 44, no. 3, pp. 547\u2013555, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Piazza%2C%20M.%20Izard%2C%20V.%20Pinel%2C%20P.%20Bihan%2C%20D.Le%20Tuning%20curves%20for%20approximate%20numerosity%20in%20the%20human%20intraparietal%20sulcus%2C%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Piazza%2C%20M.%20Izard%2C%20V.%20Pinel%2C%20P.%20Bihan%2C%20D.Le%20Tuning%20curves%20for%20approximate%20numerosity%20in%20the%20human%20intraparietal%20sulcus%2C%202004"
        },
        {
            "id": "29",
            "entry": "[29] J. Johnson, B. Hariharan, L. van der Maaten, L. Fei-Fei, C. L. Zitnick, and R. Girshick, \u201cClevr: A diagnostic dataset for compositional language and elementary visual reasoning,\u201d in CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20J.%20Hariharan%2C%20B.%20van%20der%20Maaten%2C%20L.%20Fei-Fei%2C%20L.%20%E2%80%9CClevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%2C%E2%80%9D%20in%20CVPR%202017"
        },
        {
            "id": "30",
            "entry": "[30] A. Nieder and E. K. Miller, \u201cCoding of cognitive magnitude: Compressed scaling of numerical information in the primate prefrontal cortex,\u201d Neuron, vol. 37, no. 1, pp. 149\u2013157, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nieder%2C%20A.%20Miller%2C%20E.K.%20Coding%20of%20cognitive%20magnitude%3A%20Compressed%20scaling%20of%20numerical%20information%20in%20the%20primate%20prefrontal%20cortex%2C%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nieder%2C%20A.%20Miller%2C%20E.K.%20Coding%20of%20cognitive%20magnitude%3A%20Compressed%20scaling%20of%20numerical%20information%20in%20the%20primate%20prefrontal%20cortex%2C%202003"
        },
        {
            "id": "31",
            "entry": "[31] A. Nieder and K. Merten, \u201cA labeled-line code for small and large numerosities in the monkey prefrontal cortex,\u201d Journal of Neuroscience, vol. 27, no. 22, pp. 5986\u20135993, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nieder%2C%20A.%20Merten%2C%20K.%20A%20labeled-line%20code%20for%20small%20and%20large%20numerosities%20in%20the%20monkey%20prefrontal%20cortex%2C%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nieder%2C%20A.%20Merten%2C%20K.%20A%20labeled-line%20code%20for%20small%20and%20large%20numerosities%20in%20the%20monkey%20prefrontal%20cortex%2C%202007"
        },
        {
            "id": "32",
            "entry": "[32] D. J. Smith and J. P. Minda, \u201cThirty categorization results in search of a model.,\u201d Journal of Experimental Psychology: Learning, Memory, and Cognition, vol. 26, no. 1, p. 3, 2000. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20D.J.%20Minda%2C%20J.P.%20Thirty%20categorization%20results%20in%20search%20of%20a%20model.%2C%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smith%2C%20D.J.%20Minda%2C%20J.P.%20Thirty%20categorization%20results%20in%20search%20of%20a%20model.%2C%202000"
        }
    ]
}
