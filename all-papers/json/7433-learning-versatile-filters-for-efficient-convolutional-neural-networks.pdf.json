{
    "filename": "7433-learning-versatile-filters-for-efficient-convolutional-neural-networks.pdf",
    "metadata": {
        "title": "Learning Versatile Filters for Efficient Convolutional Neural Networks",
        "author": "Yunhe Wang, Chang Xu, Chunjing XU, Chao Xu, Dacheng Tao",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "volume": "1",
        "abstract": "This paper introduces versatile filters to construct efficient convolutional neural network. Considering the demands of efficient deep learning techniques running on cost-effective hardware, a number of methods have been developed to learn compact neural networks. Most of these works aim to slim down filters in different ways, e.g. investigating small, sparse or binarized filters. In contrast, we treat filters from an additive perspective. A series of secondary filters can be derived from a primary filter. These secondary filters all inherit in the primary filter without occupying more storage, but once been unfolded in computation they could significantly enhance the capability of the filter by integrating information extracted from different receptive fields. Besides spatial versatile filters, we additionally investigate versatile filters from the channel perspective. The new techniques are general to upgrade filters in existing CNNs. Experimental results on benchmark datasets and neural networks demonstrate that CNNs constructed with our versatile filters are able to achieve comparable accuracy as that of original filters, but require less memory and FLOPs."
    },
    "keywords": [
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "receptive field",
            "url": "https://en.wikipedia.org/wiki/receptive_field"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "object detection",
            "url": "https://en.wikipedia.org/wiki/object_detection"
        }
    ],
    "highlights": [
        "Considerable computer vision applications have received remarkable progress with the help of convolutional neural networks (CNNs) in last decade",
        "We propose versatile filters for efficient convolutional neural networks",
        "Exploring convolutional neural networks with low memory usage and computational complexity is very essential so that these models can be used on mobile devices",
        "The main waste in a general neural network is that a convolution filter with massive parameters can only produce one feature for a given data",
        "In order to make full use of convolution filters, this paper proposes versatile convolution filters from spatial and channel perspectives",
        "Experiments conducted on benchmark image datasets and models show that the proposed method can not only reduce the requirement of storage and computational resources, but enhance performance of convolutional neural networks, which is very effective for establishing portable convolutional neural networks with high accuracies"
    ],
    "key_statements": [
        "Considerable computer vision applications have received remarkable progress with the help of convolutional neural networks (CNNs) in last decade",
        "We propose versatile filters for efficient convolutional neural networks",
        "We investigate versatile filters from the channel perspective.\n2.1",
        "The proposed method can generate multiple feature maps using a convolution filter whose size is larger than 2 \u00d7 2 (i.e., s = di/2 > 1), which will increase the number of channels in the layer and make the convolutional neural network enormous",
        "Comparing Versatile v2-ResNet-50 and Versatile v2-ResNeXt-50, we found that the memory usage of Versatile v2-ResNet-50 is lower than that of the Versatile v2-ResNeXt-50. This is because the proposed versatile filters can effectively reduce the memory and floating number multiplications of filters whose sizes are larger than 1 \u00d7 1, which provides a more flexible way for designing convolutional neural networks with high performance and portable architectures.\n3.3",
        "By exploiting the proposed versatile convolution filters on the ShuffleNet 2\u00d7 (g = 3), we reduced more than 30% weights of convolution filters and achieved the smallest model size with a comparable accuracy, which is a more portable convolutional neural network",
        "Exploring convolutional neural networks with low memory usage and computational complexity is very essential so that these models can be used on mobile devices",
        "The main waste in a general neural network is that a convolution filter with massive parameters can only produce one feature for a given data",
        "In order to make full use of convolution filters, this paper proposes versatile convolution filters from spatial and channel perspectives",
        "Experiments conducted on benchmark image datasets and models show that the proposed method can not only reduce the requirement of storage and computational resources, but enhance performance of convolutional neural networks, which is very effective for establishing portable convolutional neural networks with high accuracies"
    ],
    "summary": [
        "Considerable computer vision applications have received remarkable progress with the help of convolutional neural networks (CNNs) in last decade.",
        "The proposed spatial versatile convolution operation as shown in Fcn. 3 can generate multiple feature maps using a fixed number of convolution filters.",
        "Given a convolutional layer for extracting feature maps y \u2208 RH \u00d7W \u00d7n using the proposed spatial versatile filters (Fcn. 3), the space complexity of d \u00d7 d filters with c channels is O(d2cn/s) and the computational complexity is O( is=1(d \u2212 2i + 2)2cH W n/s).",
        "The proposes channel versatile filters can significantly reduce the memory usage and computational complexity of CNNs, which can be derived as that in Proposition 1.",
        "The proposed method can generate multiple feature maps using a convolution filter whose size is larger than 2 \u00d7 2 (i.e., s = di/2 > 1), which will increase the number of channels in the layer and make the convolutional neural network enormous.",
        "We reduce the number of convolution filters in each layer to make the amount of feature maps in Versatile-Model 2 and Versatile-Model 3 similar to that in the original network, as shown in Table 2.",
        "The performance of Model 3 is slightly higher than that of the baseline model, but has significantly lower memory usage and FLOPs, which demonstrates the effectiveness of the proposed versatile convolution filters.",
        "The proposed versatile convolution filters adopt a more complex approach to capture useful information from input images, i.e., a large filter consists of a series of smaller filters and each of them will employ on the input images to generate feature maps.",
        "After applying the proposed versatile convolution filter on the ResNeXt-50 model, we obtained a 7.0% top-5 classification error rate, which is slightly higher than its baseline model with only about half memory usage.",
        "This is because the proposed versatile filters can effectively reduce the memory and FLOPs of filters whose sizes are larger than 1 \u00d7 1, which provides a more flexible way for designing CNNs with high performance and portable architectures.",
        "By exploiting the proposed versatile convolution filters on the ShuffleNet 2\u00d7 (g = 3), we reduced more than 30% weights of convolution filters and achieved the smallest model size with a comparable accuracy, which is a more portable convolutional neural network.",
        "We selected the VDSR (Very Deep CNN for Image Super-resolution [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>]) as the baseline model and the Versatile-VDSR with the same amount of feature maps but less memory usage and FLOPs achieved a higher performance.",
        "The proposed method can be implemented using the existing convolution component, we will further embed it into other applications such as object detection and image segmentation"
    ],
    "headline": "This paper introduces versatile filters to construct efficient convolutional neural network",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sanjeev Arora, Aditya Bhaskara, Rong Ge, and Tengyu Ma. Provable bounds for learning some deep representations. ICML, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20Sanjeev%20Bhaskara%2C%20Aditya%20Ge%2C%20Rong%20Ma%2C%20Tengyu%20Provable%20bounds%20for%20learning%20some%20deep%20representations%202014"
        },
        {
            "id": "2",
            "entry": "[2] Fran\u00e7ois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:1610.02357, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.02357"
        },
        {
            "id": "3",
            "entry": "[3] Matthieu Courbariaux and Yoshua Bengio. Binarynet: Training deep neural networks with weights and activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.02830"
        },
        {
            "id": "4",
            "entry": "[4] Emily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In NIPS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20L.%20Zaremba%2C%20Wojciech%20Bruna%2C%20Joan%20LeCun%2C%20Yann%20Exploiting%20linear%20structure%20within%20convolutional%20networks%20for%20efficient%20evaluation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20L.%20Zaremba%2C%20Wojciech%20Bruna%2C%20Joan%20LeCun%2C%20Yann%20Exploiting%20linear%20structure%20within%20convolutional%20networks%20for%20efficient%20evaluation%202014"
        },
        {
            "id": "5",
            "entry": "[5] Michael Figurnov, Dmitry Vetrov, and Pushmeet Kohli. Perforatedcnns: Acceleration through elimination of redundant convolutions. NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Figurnov%2C%20Michael%20Vetrov%2C%20Dmitry%20Kohli%2C%20Pushmeet%20Perforatedcnns%3A%20Acceleration%20through%20elimination%20of%20redundant%20convolutions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Figurnov%2C%20Michael%20Vetrov%2C%20Dmitry%20Kohli%2C%20Pushmeet%20Perforatedcnns%3A%20Acceleration%20through%20elimination%20of%20redundant%20convolutions%202016"
        },
        {
            "id": "6",
            "entry": "[6] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20Song%20Mao%2C%20Huizi%20Dally%2C%20William%20J.%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20Song%20Mao%2C%20Huizi%20Dally%2C%20William%20J.%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%202016"
        },
        {
            "id": "7",
            "entry": "[7] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "8",
            "entry": "[8] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.02531"
        },
        {
            "id": "9",
            "entry": "[9] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04861"
        },
        {
            "id": "10",
            "entry": "[10] Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Accurate image super-resolution using very deep convolutional networks. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Jiwon%20Lee%2C%20Jung%20Kwon%20and%20Kyoung%20Mu%20Lee.%20Accurate%20image%20super-resolution%20using%20very%20deep%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Jiwon%20Lee%2C%20Jung%20Kwon%20and%20Kyoung%20Mu%20Lee.%20Accurate%20image%20super-resolution%20using%20very%20deep%20convolutional%20networks%202016"
        },
        {
            "id": "11",
            "entry": "[11] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "12",
            "entry": "[12] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "13",
            "entry": "[13] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20Jonathan%20Shelhamer%2C%20Evan%20Darrell%2C%20Trevor%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20Jonathan%20Shelhamer%2C%20Evan%20Darrell%2C%20Trevor%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015"
        },
        {
            "id": "14",
            "entry": "[14] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. arXiv preprint arXiv:1603.05279, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.05279"
        },
        {
            "id": "15",
            "entry": "[15] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015"
        },
        {
            "id": "16",
            "entry": "[16] Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6550"
        },
        {
            "id": "17",
            "entry": "[17] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. IJCV, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "18",
            "entry": "[18] Pierre Sermanet and Yann LeCun. Traffic sign recognition with multi-scale convolutional networks. In IJCNN, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sermanet%2C%20Pierre%20LeCun%2C%20Yann%20Traffic%20sign%20recognition%20with%20multi-scale%20convolutional%20networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sermanet%2C%20Pierre%20LeCun%2C%20Yann%20Traffic%20sign%20recognition%20with%20multi-scale%20convolutional%20networks%202011"
        },
        {
            "id": "19",
            "entry": "[19] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "20",
            "entry": "[20] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "21",
            "entry": "[21] Andrea Vedaldi and Karel Lenc. Matconvnet: Convolutional neural networks for matlab. In Proceedings of the 23rd Annual ACM Conference on Multimedia Conference, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vedaldi%2C%20Andrea%20Lenc%2C%20Karel%20Matconvnet%3A%20Convolutional%20neural%20networks%20for%20matlab%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vedaldi%2C%20Andrea%20Lenc%2C%20Karel%20Matconvnet%3A%20Convolutional%20neural%20networks%20for%20matlab%202015"
        },
        {
            "id": "22",
            "entry": "[22] Yunhe Wang, Chang Xu, Dacheng Tao, and Chao Xu. Beyond filters: Compact feature map for portable deep model. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yunhe%20Xu%2C%20Chang%20Tao%2C%20Dacheng%20Xu%2C%20Chao%20Beyond%20filters%3A%20Compact%20feature%20map%20for%20portable%20deep%20model%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Yunhe%20Xu%2C%20Chang%20Tao%2C%20Dacheng%20Xu%2C%20Chao%20Beyond%20filters%3A%20Compact%20feature%20map%20for%20portable%20deep%20model%202017"
        },
        {
            "id": "23",
            "entry": "[23] Yunhe Wang, Chang Xu, Shan You, Dacheng Tao, and Chao Xu. Cnnpack: Packing convolutional neural networks in the frequency domain. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yunhe%20Xu%2C%20Chang%20You%2C%20Shan%20Tao%2C%20Dacheng%20Cnnpack%3A%20Packing%20convolutional%20neural%20networks%20in%20the%20frequency%20domain%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Yunhe%20Xu%2C%20Chang%20You%2C%20Shan%20Tao%2C%20Dacheng%20Cnnpack%3A%20Packing%20convolutional%20neural%20networks%20in%20the%20frequency%20domain%202016"
        },
        {
            "id": "24",
            "entry": "[24] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wen%2C%20Wei%20Wu%2C%20Chunpeng%20Wang%2C%20Yandan%20Chen%2C%20Yiran%20Learning%20structured%20sparsity%20in%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wen%2C%20Wei%20Wu%2C%20Chunpeng%20Wang%2C%20Yandan%20Chen%2C%20Yiran%20Learning%20structured%20sparsity%20in%20deep%20neural%20networks%202016"
        },
        {
            "id": "25",
            "entry": "[25] Saining Xie, Ross Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20Saining%20Girshick%2C%20Ross%20Doll%C3%A1r%2C%20Piotr%20Tu%2C%20Zhuowen%20Aggregated%20residual%20transformations%20for%20deep%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20Saining%20Girshick%2C%20Ross%20Doll%C3%A1r%2C%20Piotr%20Tu%2C%20Zhuowen%20Aggregated%20residual%20transformations%20for%20deep%20neural%20networks%202017"
        },
        {
            "id": "26",
            "entry": "[26] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. arXiv preprint arXiv:1707.01083, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.01083"
        },
        {
            "id": "27",
            "entry": "[27] Pan Zhou, Yunqing Hou, and Jiashi Feng. Deep adversarial subspace clustering. In CVPR, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Pan%20Hou%2C%20Yunqing%20Feng%2C%20Jiashi%20Deep%20adversarial%20subspace%20clustering%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20Pan%20Hou%2C%20Yunqing%20Feng%2C%20Jiashi%20Deep%20adversarial%20subspace%20clustering%202018"
        }
    ]
}
