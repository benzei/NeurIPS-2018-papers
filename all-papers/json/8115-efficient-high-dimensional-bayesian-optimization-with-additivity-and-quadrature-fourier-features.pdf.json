{
    "filename": "8115-efficient-high-dimensional-bayesian-optimization-with-additivity-and-quadrature-fourier-features.pdf",
    "metadata": {
        "date": 2018,
        "title": "Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features",
        "author": "Mojm\u00edr Mutn\u00fd Department of Computer Science",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8115-efficient-high-dimensional-bayesian-optimization-with-additivity-and-quadrature-fourier-features.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret polynomial time (in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases exponentially with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations."
    },
    "keywords": [
        {
            "term": "additive model",
            "url": "https://en.wikipedia.org/wiki/additive_model"
        },
        {
            "term": "global optimization",
            "url": "https://en.wikipedia.org/wiki/global_optimization"
        },
        {
            "term": "bayesian optimization",
            "url": "https://en.wikipedia.org/wiki/bayesian_optimization"
        },
        {
            "term": "Thompson sampling",
            "url": "https://en.wikipedia.org/wiki/Thompson_sampling"
        },
        {
            "term": "gaussian process",
            "url": "https://en.wikipedia.org/wiki/gaussian_process"
        }
    ],
    "highlights": [
        "Bayesian Optimization (BO) is a versatile method for global optimization of a black-box function using noisy point-wise observations",
        "For the ease of exposition we focus our analysis on the squared exponential kernel only, but the methods extend to a broader class of kernels",
        "We prove that Thompson sampling and Gaussian process-UCB [<a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>] algorithms are no-regret when combined with Quadrature Fourier Features approximation, and for squared exponential kernel the bound is the same as without Quadrature Fourier Features approximation up to logarithmic factors",
        "We presented an algorithm for high dimensional Bayesian Optimization with generalized additive kernels based on Thompson sampling",
        "We show that the algorithm is no-regret and needs only a polynomial number of evaluations of the acquisition function with a fixed horizon",
        "We introduced a novel deterministic Fourier Features based approximation of a squared exponential kernel for this algorithm. This approximation is well suited for generalized additive models with a low effective dimension"
    ],
    "key_statements": [
        "Bayesian Optimization (BO) is a versatile method for global optimization of a black-box function using noisy point-wise observations",
        "Bayesian Optimization has been employed in selection of chemical compounds [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], online marketing [<a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>], reinforcement learning problems [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>], and in search for hyperparameters of machine learning algorithms [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>]",
        "There are two main problems associated with high dimensional Bayesian Optimization with generalized additive Gaussian process, namely, optimization of the acquisition function, and efficient handling of many data points - large-scale Bayesian Optimization",
        "For the ease of exposition we focus our analysis on the squared exponential kernel only, but the methods extend to a broader class of kernels",
        "We develop a novel approximation strategy for kernel methods and Gaussian process - Quadrature Fourier Features (QFF)",
        "By introducing Quadrature Fourier Features, the computational cost of the kernel inversion for generalized additive models reduces from O(T 3) to O(T2) measured in basic arithmetic operations, where T is the number of data points",
        "We prove that Thompson sampling and Gaussian process-UCB [<a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>] algorithms are no-regret when combined with Quadrature Fourier Features approximation, and for squared exponential kernel the bound is the same as without Quadrature Fourier Features approximation up to logarithmic factors",
        "We are able to provide a polynomial bound on the number of evaluations of the acquisition function for a fixed horizon T of queries to the black-box function",
        "Algorithm 1 Thompson sampling with Fourier Features and additive models",
        "We provide bounds on the cumulative regret for Thompson sampling and Gaussian process-UCB",
        "Let \u03b4 \u2208 (0, 1), k be additive squared exponential kernel with G components, and the black box function is bounded in RKHS norm",
        "We test Thompson sampling with Quadrature Fourier Features for a fixed horizon with high-dimensional functions used previously in [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>]",
        "We show that the runtime of our algorithm is an order of magnitude lower than the canonical algorithm, and reaches better solutions as we can afford to optimize the acquisition function to higher accuracy",
        "We presented an algorithm for high dimensional Bayesian Optimization with generalized additive kernels based on Thompson sampling",
        "We show that the algorithm is no-regret and needs only a polynomial number of evaluations of the acquisition function with a fixed horizon",
        "We introduced a novel deterministic Fourier Features based approximation of a squared exponential kernel for this algorithm. This approximation is well suited for generalized additive models with a low effective dimension"
    ],
    "summary": [
        "Bayesian Optimization (BO) is a versatile method for global optimization of a black-box function using noisy point-wise observations.",
        "There are two main problems associated with high dimensional BO with generalized additive GPs, namely, optimization of the acquisition function, and efficient handling of many data points - large-scale BO.",
        "To alleviate the two problems, using a generalized additive model assumption, and a popular acquisition function - Thompson sampling [<a class=\"ref-link\" id=\"c50\" href=\"#r50\">50</a>], we design efficient no-regret algorithms for solving high dimensional BO problems.",
        "We develop a novel approximation strategy for kernel methods and GPs - Quadrature Fourier Features (QFF).",
        "By introducing QFF, the computational cost of the kernel inversion for generalized additive models reduces from O(T 3) to O(T2) measured in basic arithmetic operations, where T is the number of data points.",
        "Using an additive kernel without overlapping groups and Thompson sampling acquisition function, QFF allow us to formulate a practical and provably computationally efficient algorithm for high dimensional BO.",
        "We use Hermite-Gauss quadrature (a standard technique in numerical integration) to provide a uniform approximation over D for the squared exponential kernel - Quadrature Fourier Features (QFF) with exponentially decreasing error on the uniform approximation.",
        "The general scaling of m with dimension d is exponential due to the use of Cartesian grids, our application area - BO usually involves either small dimensional problems up to 5 dimensions, or high dimensional BO with low effective dimensions - generalized additive models - where these methods are very effective.",
        "We are able to provide a polynomial bound on the number of evaluations of the acquisition function for a fixed horizon T of queries to the black-box function.",
        "Algorithm 1 Thompson sampling with Fourier Features and additive models",
        "For the exponentially decreasing error of QFF, we can prove that asymptotically our bound on the cumulative regret coincides with the bound on canonical Thompson sampling in the following theorem.",
        "Let \u03b4 \u2208 (0, 1), k be additive squared exponential kernel with G components, and the black box function is bounded in RKHS norm.",
        "We test Thompson sampling with QFF for a fixed horizon with high-dimensional functions used previously in [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>].",
        "We presented an algorithm for high dimensional BO with generalized additive kernels based on Thompson sampling.",
        "We show that the algorithm is no-regret and needs only a polynomial number of evaluations of the acquisition function with a fixed horizon.",
        "We introduced a novel deterministic Fourier Features based approximation of a squared exponential kernel for this algorithm.",
        "The approximation error decreases exponentially with the size of the basis for the squared exponential kernel"
    ],
    "headline": "We develop an efficient and provably no-regret Bayesian optimization  algorithm for optimization of black-box functions in high dimensions",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Yasin Abbasi-Yadkori and Csaba Szepesvari. Online learning for linearly parametrized control problems. PhD thesis, University of Alberta, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbasi-Yadkori%2C%20Yasin%20Szepesvari%2C%20Csaba%20Online%20learning%20for%20linearly%20parametrized%20control%20problems%202012"
        },
        {
            "id": "2",
            "entry": "[2] Sivaram Ambikasaran, Daniel Foreman-Mackey, Leslie Greengard, David W. Hogg, and Michael O\u2019Neil. Fast direct methods for Gaussian processes. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(2):252\u2013265, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ambikasaran%2C%20Sivaram%20Foreman-Mackey%2C%20Daniel%20Greengard%2C%20Leslie%20Hogg%2C%20David%20W.%20Fast%20direct%20methods%20for%20Gaussian%20processes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ambikasaran%2C%20Sivaram%20Foreman-Mackey%2C%20Daniel%20Greengard%2C%20Leslie%20Hogg%2C%20David%20W.%20Fast%20direct%20methods%20for%20Gaussian%20processes%202016"
        },
        {
            "id": "3",
            "entry": "[3] Haim Avron, Vikas Sindhwani, Jiyan Yang, and Michael Mahoney. Quasi-Monte Carlo feature maps for shift-invariant kernels. The Journal of Machine Learning Research, 17(1):4096\u20134133, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Avron%2C%20Haim%20Sindhwani%2C%20Vikas%20Yang%2C%20Jiyan%20Mahoney%2C%20Michael%20Quasi-Monte%20Carlo%20feature%20maps%20for%20shift-invariant%20kernels%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Avron%2C%20Haim%20Sindhwani%2C%20Vikas%20Yang%2C%20Jiyan%20Mahoney%2C%20Michael%20Quasi-Monte%20Carlo%20feature%20maps%20for%20shift-invariant%20kernels%202016"
        },
        {
            "id": "4",
            "entry": "[4] Matej Balog, Balaji Lakshminarayanan, Zoubin Ghahramani, Daniel M Roy, and Yee Whye Teh. The Mondrian kernel. In Uncertainty in Artificial Intelligence, pages 32\u201341, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matej%20Balog%20Balaji%20Lakshminarayanan%20Zoubin%20Ghahramani%20Daniel%20M%20Roy%20and%20Yee%20Whye%20Teh%20The%20Mondrian%20kernel%20In%20Uncertainty%20in%20Artificial%20Intelligence%20pages%203241%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matej%20Balog%20Balaji%20Lakshminarayanan%20Zoubin%20Ghahramani%20Daniel%20M%20Roy%20and%20Yee%20Whye%20Teh%20The%20Mondrian%20kernel%20In%20Uncertainty%20in%20Artificial%20Intelligence%20pages%203241%202016"
        },
        {
            "id": "5",
            "entry": "[5] John P Boyd. Exponentially convergent Fourier-Chebshev quadrature schemes on bounded and infinite intervals. Journal of scientific computing, 2(2):99\u2013109, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20John%20P.%20Exponentially%20convergent%20Fourier-Chebshev%20quadrature%20schemes%20on%20bounded%20and%20infinite%20intervals%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boyd%2C%20John%20P.%20Exponentially%20convergent%20Fourier-Chebshev%20quadrature%20schemes%20on%20bounded%20and%20infinite%20intervals%201987"
        },
        {
            "id": "6",
            "entry": "[6] John P Boyd. Chebyshev and Fourier spectral methods. Courier Corporation, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20John%20P.%20Chebyshev%20and%20Fourier%20spectral%20methods%202001"
        },
        {
            "id": "7",
            "entry": "[7] Eric Brochu, Vlad M Cora, and Nando De Freitas. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:1012.2599, 2010.",
            "arxiv_url": "https://arxiv.org/pdf/1012.2599"
        },
        {
            "id": "8",
            "entry": "[8] Bo Chen, Rui Castro, and Andreas Krause. Joint optimization and variable selection of highdimensional Gaussian processes. 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Bo%20Castro%2C%20Rui%20Krause%2C%20Andreas%20Joint%20optimization%20and%20variable%20selection%20of%20highdimensional%20Gaussian%20processes%202012"
        },
        {
            "id": "9",
            "entry": "[9] Sayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chowdhury%2C%20Sayak%20Ray%20Gopalan%2C%20Aditya%20On%20kernelized%20multi-armed%20bandits%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chowdhury%2C%20Sayak%20Ray%20Gopalan%2C%20Aditya%20On%20kernelized%20multi-armed%20bandits%202017"
        },
        {
            "id": "10",
            "entry": "[10] Tri Dao, Christopher M De Sa, and Christopher R\u00e9. Gaussian quadrature for kernel features. In Advances in Neural Information Processing Systems, pages 6109\u20136119, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dao%2C%20Tri%20Sa%2C%20Christopher%20M.De%20R%C3%A9%2C%20Christopher%20Gaussian%20quadrature%20for%20kernel%20features%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dao%2C%20Tri%20Sa%2C%20Christopher%20M.De%20R%C3%A9%2C%20Christopher%20Gaussian%20quadrature%20for%20kernel%20features%202017"
        },
        {
            "id": "11",
            "entry": "[11] Kai Diethelm. Error bounds for the numerical integration of functions with limited smoothness. SIAM Journal on Numerical Analysis, 52(2):877\u2013879, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diethelm%2C%20Kai%20Error%20bounds%20for%20the%20numerical%20integration%20of%20functions%20with%20limited%20smoothness%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diethelm%2C%20Kai%20Error%20bounds%20for%20the%20numerical%20integration%20of%20functions%20with%20limited%20smoothness%202014"
        },
        {
            "id": "12",
            "entry": "[12] Josip Djolonga, Andreas Krause, and Volkan Cevher. High-dimensional Gaussian process bandits. In Advances in Neural Information Processing Systems, pages 1025\u20131033, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Djolonga%2C%20Josip%20Krause%2C%20Andreas%20Cevher%2C%20Volkan%20High-dimensional%20Gaussian%20process%20bandits%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Djolonga%2C%20Josip%20Krause%2C%20Andreas%20Cevher%2C%20Volkan%20High-dimensional%20Gaussian%20process%20bandits%202013"
        },
        {
            "id": "13",
            "entry": "[13] David K Duvenaud, Hannes Nickisch, and Carl E Rasmussen. Additive Gaussian processes. In Advances in neural information processing systems, pages 226\u2013234, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duvenaud%2C%20David%20K.%20Nickisch%2C%20Hannes%20Rasmussen%2C%20Carl%20E.%20Additive%20Gaussian%20processes%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duvenaud%2C%20David%20K.%20Nickisch%2C%20Hannes%20Rasmussen%2C%20Carl%20E.%20Additive%20Gaussian%20processes%202011"
        },
        {
            "id": "14",
            "entry": "[14] Jacob Gardner, Chuan Guo, Kilian Weinberger, Roman Garnett, and Roger Grosse. Discovering and exploiting additive structure for Bayesian optimization. In Artificial Intelligence and Statistics, pages 1311\u20131319, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gardner%2C%20Jacob%20Guo%2C%20Chuan%20Weinberger%2C%20Kilian%20Garnett%2C%20Roman%20Discovering%20and%20exploiting%20additive%20structure%20for%20Bayesian%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gardner%2C%20Jacob%20Guo%2C%20Chuan%20Weinberger%2C%20Kilian%20Garnett%2C%20Roman%20Discovering%20and%20exploiting%20additive%20structure%20for%20Bayesian%20optimization%202017"
        },
        {
            "id": "15",
            "entry": "[15] Aditya Gopalan and Shie Mannor. Thompson sampling for learning parameterized markov decision processes. In Conference on Learning Theory, pages 861\u2013898, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gopalan%2C%20Aditya%20Mannor%2C%20Shie%20Thompson%20sampling%20for%20learning%20parameterized%20markov%20decision%20processes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gopalan%2C%20Aditya%20Mannor%2C%20Shie%20Thompson%20sampling%20for%20learning%20parameterized%20markov%20decision%20processes%202015"
        },
        {
            "id": "16",
            "entry": "[16] Trevor J Hastie and Robert J Tibshirani. Generalized additive models, volume 43 of monographs on statistics and applied probability, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hastie%2C%20Trevor%20J.%20Tibshirani%2C%20Robert%20J.%20Generalized%20additive%20models%2C%20volume%2043%20of%20monographs%20on%20statistics%20and%20applied%20probability%201990"
        },
        {
            "id": "17",
            "entry": "[17] Philipp Hennig and Christian J Schuler. Entropy search for information-efficient global optimization. Journal of Machine Learning Research, 13(Jun):1809\u20131837, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hennig%2C%20Philipp%20Schuler%2C%20Christian%20J.%20Entropy%20search%20for%20information-efficient%20global%20optimization%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hennig%2C%20Philipp%20Schuler%2C%20Christian%20J.%20Entropy%20search%20for%20information-efficient%20global%20optimization%202012"
        },
        {
            "id": "18",
            "entry": "[18] James Hensman, Nicolas Durrande, and Arno Solin. Variational Fourier features for Gaussian processes. Journal of Machine Learning Research, 18:1\u201352, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hensman%2C%20James%20Durrande%2C%20Nicolas%20Solin%2C%20Arno%20Variational%20Fourier%20features%20for%20Gaussian%20processes%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hensman%2C%20James%20Durrande%2C%20Nicolas%20Solin%2C%20Arno%20Variational%20Fourier%20features%20for%20Gaussian%20processes%202018"
        },
        {
            "id": "19",
            "entry": "[19] James Hensman, Nicolo Fusi, and Neil D Lawrence. Gaussian processes for big data. Uncertainty in Artificial Intelligence, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hensman%2C%20James%20Fusi%2C%20Nicolo%20Lawrence%2C%20Neil%20D.%20Gaussian%20processes%20for%20big%20data.%20Uncertainty%20in%20Artificial%20Intelligence%202013"
        },
        {
            "id": "20",
            "entry": "[20] Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Matthew W Hoffman, and Zoubin Ghahramani. Predictive entropy search for efficient global optimization of black-box functions. In Advances in neural information processing systems, pages 918\u2013926, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Hoffman%2C%20Matthew%20W.%20Ghahramani%2C%20Zoubin%20Predictive%20entropy%20search%20for%20efficient%20global%20optimization%20of%20black-box%20functions%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Hoffman%2C%20Matthew%20W.%20Ghahramani%2C%20Zoubin%20Predictive%20entropy%20search%20for%20efficient%20global%20optimization%20of%20black-box%20functions%202014"
        },
        {
            "id": "21",
            "entry": "[21] Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, James Requeima, Edward O. Pyzer-Knapp, and Al\u00e1n AspuruGuzik. Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical space. International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Requeima%2C%20James%20Pyzer-Knapp%2C%20Edward%20O.%20AspuruGuzik%2C%20Al%C3%A1n%20Parallel%20and%20distributed%20Thompson%20sampling%20for%20large-scale%20accelerated%20exploration%20of%20chemical%20space%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Requeima%2C%20James%20Pyzer-Knapp%2C%20Edward%20O.%20AspuruGuzik%2C%20Al%C3%A1n%20Parallel%20and%20distributed%20Thompson%20sampling%20for%20large-scale%20accelerated%20exploration%20of%20chemical%20space%202017"
        },
        {
            "id": "22",
            "entry": "[22] Francis Begnaud Hildebrand. Introduction to numerical analysis. Courier Corporation, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hildebrand%2C%20Francis%20Begnaud%20Introduction%20to%20numerical%20analysis%201987"
        },
        {
            "id": "23",
            "entry": "[23] Donald R Jones. Direct global optimization algorithmdirect global optimization algorithm. In Encyclopedia of optimization, pages 431\u2013440.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donald%20R%20Jones%20Direct%20global%20optimization%20algorithmdirect%20global%20optimization%20algorithm%20In%20Encyclopedia%20of%20optimization%20pages%20431440",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donald%20R%20Jones%20Direct%20global%20optimization%20algorithmdirect%20global%20optimization%20algorithm%20In%20Encyclopedia%20of%20optimization%20pages%20431440"
        },
        {
            "id": "24",
            "entry": "[24] Kirthevasan Kandasamy, Jeff Schneider, and Barnab\u00e1s P\u00f3czos. High dimensional Bayesian optimisation and bandits via additive models. In International Conference on Machine Learning, pages 295\u2013304, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kandasamy%2C%20Kirthevasan%20Schneider%2C%20Jeff%20P%C3%B3czos%2C%20Barnab%C3%A1s%20High%20dimensional%20Bayesian%20optimisation%20and%20bandits%20via%20additive%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kandasamy%2C%20Kirthevasan%20Schneider%2C%20Jeff%20P%C3%B3czos%2C%20Barnab%C3%A1s%20High%20dimensional%20Bayesian%20optimisation%20and%20bandits%20via%20additive%20models%202015"
        },
        {
            "id": "25",
            "entry": "[25] Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, and Frank Hutter. Fast Bayesian optimization of machine learning hyperparameters on large datasets. International Conference on Artificial Intelligence and Statistics, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Klein%2C%20Aaron%20Falkner%2C%20Stefan%20Bartels%2C%20Simon%20Hennig%2C%20Philipp%20Fast%20Bayesian%20optimization%20of%20machine%20learning%20hyperparameters%20on%20large%20datasets%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Klein%2C%20Aaron%20Falkner%2C%20Stefan%20Bartels%2C%20Simon%20Hennig%2C%20Philipp%20Fast%20Bayesian%20optimization%20of%20machine%20learning%20hyperparameters%20on%20large%20datasets%202017"
        },
        {
            "id": "26",
            "entry": "[26] Andreas Krause and Cheng S Ong. Contextual Gaussian process bandit optimization. In Advances in Neural Information Processing Systems, pages 2447\u20132455, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krause%2C%20Andreas%20Ong%2C%20Cheng%20S.%20Contextual%20Gaussian%20process%20bandit%20optimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krause%2C%20Andreas%20Ong%2C%20Cheng%20S.%20Contextual%20Gaussian%20process%20bandit%20optimization%202011"
        },
        {
            "id": "27",
            "entry": "[27] Beatrice Laurent and Pascal Massart. Adaptive estimation of a quadratic functional by model selection. Annals of Statistics, pages 1302\u20131338, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Laurent%2C%20Beatrice%20Massart%2C%20Pascal%20Adaptive%20estimation%20of%20a%20quadratic%20functional%20by%20model%20selection%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Laurent%2C%20Beatrice%20Massart%2C%20Pascal%20Adaptive%20estimation%20of%20a%20quadratic%20functional%20by%20model%20selection%202000"
        },
        {
            "id": "28",
            "entry": "[28] Miguel Lazaro-Gredilla, Joaquin Quionero-Candela, Carl Edward Rasmussen, and Anabal Figueiras-Vidal. Sparse spectrum Gaussian process regression. Journal of Machine Learning Research, 11(Jun):1865\u20131881, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lazaro-Gredilla%2C%20Miguel%20Quionero-Candela%2C%20Joaquin%20Rasmussen%2C%20Carl%20Edward%20Figueiras-Vidal%2C%20Anabal%20Sparse%20spectrum%20Gaussian%20process%20regression%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lazaro-Gredilla%2C%20Miguel%20Quionero-Candela%2C%20Joaquin%20Rasmussen%2C%20Carl%20Edward%20Figueiras-Vidal%2C%20Anabal%20Sparse%20spectrum%20Gaussian%20process%20regression%202010"
        },
        {
            "id": "29",
            "entry": "[29] Daniel J Lizotte, Tao Wang, Michael H Bowling, and Dale Schuurmans. Automatic gait optimization with Gaussian process regression. In IJCAI, volume 7, pages 944\u2013949, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lizotte%2C%20Daniel%20J.%20Wang%2C%20Tao%20Bowling%2C%20Michael%20H.%20Schuurmans%2C%20Dale%20Automatic%20gait%20optimization%20with%20Gaussian%20process%20regression%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lizotte%2C%20Daniel%20J.%20Wang%2C%20Tao%20Bowling%2C%20Michael%20H.%20Schuurmans%2C%20Dale%20Automatic%20gait%20optimization%20with%20Gaussian%20process%20regression%202007"
        },
        {
            "id": "30",
            "entry": "[30] Mitchell McIntire, Daniel Ratner, and Stefano Ermon. Sparse Gaussian processes for Bayesian optimization. In Uncertainty in Artificial Intelligence, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McIntire%2C%20Mitchell%20Ratner%2C%20Daniel%20Ermon%2C%20Stefano%20Sparse%20Gaussian%20processes%20for%20Bayesian%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McIntire%2C%20Mitchell%20Ratner%2C%20Daniel%20Ermon%2C%20Stefano%20Sparse%20Gaussian%20processes%20for%20Bayesian%20optimization%202016"
        },
        {
            "id": "31",
            "entry": "[31] Brian McWilliams, David Balduzzi, and Joachim M Buhmann. Correlated random features for fast semi-supervised learning. In Advances in Neural Information Processing Systems, pages 440\u2013448, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McWilliams%2C%20Brian%20Balduzzi%2C%20David%20Buhmann%2C%20Joachim%20M.%20Correlated%20random%20features%20for%20fast%20semi-supervised%20learning%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McWilliams%2C%20Brian%20Balduzzi%2C%20David%20Buhmann%2C%20Joachim%20M.%20Correlated%20random%20features%20for%20fast%20semi-supervised%20learning%202013"
        },
        {
            "id": "32",
            "entry": "[32] Mojm\u00edr Mutn\u00fd and Peter Richt\u00e1rik. Parallel stochastic newton method. Journal of Computational Mathematics, 36(3):405\u2013426, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mutn%C3%BD%2C%20Mojm%C3%ADr%20Richt%C3%A1rik%2C%20Peter%20Parallel%20stochastic%20newton%20method%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mutn%C3%BD%2C%20Mojm%C3%ADr%20Richt%C3%A1rik%2C%20Peter%20Parallel%20stochastic%20newton%20method%202018"
        },
        {
            "id": "33",
            "entry": "[33] Yurii Nesterov. Introduction to convex optimization: A basic course. Springer, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Introduction%20to%20convex%20optimization%3A%20A%20basic%20course%202004"
        },
        {
            "id": "34",
            "entry": "[34] Geoff Pleiss, Jacob R. Gardner, Kilian Q. Weinberger, and Andrew Gordon Wilson. Constanttime predictive distributions for Gaussian processes. International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pleiss%2C%20Geoff%20Gardner%2C%20Jacob%20R.%20Weinberger%2C%20Kilian%20Q.%20Wilson%2C%20Andrew%20Gordon%20Constanttime%20predictive%20distributions%20for%20Gaussian%20processes%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pleiss%2C%20Geoff%20Gardner%2C%20Jacob%20R.%20Weinberger%2C%20Kilian%20Q.%20Wilson%2C%20Andrew%20Gordon%20Constanttime%20predictive%20distributions%20for%20Gaussian%20processes%202018"
        },
        {
            "id": "35",
            "entry": "[35] Ali Rahimi and Benjamin Recht. Uniform approximation of functions with random bases. In Communication, Control, and Computing, 2008 46th Annual Allerton Conference on, pages 555\u2013561. IEEE, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Uniform%20approximation%20of%20functions%20with%20random%20bases%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Uniform%20approximation%20of%20functions%20with%20random%20bases%202008"
        },
        {
            "id": "36",
            "entry": "[36] Ali Rahimi, Benjamin Recht, et al. Random features for large-scale kernel machines. In Advances in Neural Information Processing Systems, volume 3, page 5, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Random%20features%20for%20large-scale%20kernel%20machines%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Random%20features%20for%20large-scale%20kernel%20machines%202007"
        },
        {
            "id": "37",
            "entry": "[37] Carl Rasmussen and Chris Williams. Gaussian processes for machine learning. The MIT Press, Cambridge, doi, 10:S0129065704001899, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rasmussen%2C%20Carl%20Williams%2C%20Chris%20Gaussian%20processes%20for%20machine%20learning%202006"
        },
        {
            "id": "38",
            "entry": "[38] Pradeep Ravikumar, Han Liu, John Lafferty, and Larry Wasserman. Spam: Sparse additive models. In Advances in Neural Information Processing Systems, pages 1201\u20131208. Curran Associates Inc., 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ravikumar%2C%20Pradeep%20Liu%2C%20Han%20Lafferty%2C%20John%20Wasserman%2C%20Larry%20Spam%3A%20Sparse%20additive%20models%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ravikumar%2C%20Pradeep%20Liu%2C%20Han%20Lafferty%2C%20John%20Wasserman%2C%20Larry%20Spam%3A%20Sparse%20additive%20models%202007"
        },
        {
            "id": "39",
            "entry": "[39] Paul Rolland, Jonathan Scarlett, Ilija Bogunovic, and Volkan Cevher. High-dimensional Bayesian optimization via additive models with overlapping groups. International Conference on Artificial Intelligence and Statistics, 84, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rolland%2C%20Paul%20Scarlett%2C%20Jonathan%20Bogunovic%2C%20Ilija%20Cevher%2C%20Volkan%20High-dimensional%20Bayesian%20optimization%20via%20additive%20models%20with%20overlapping%20groups%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rolland%2C%20Paul%20Scarlett%2C%20Jonathan%20Bogunovic%2C%20Ilija%20Cevher%2C%20Volkan%20High-dimensional%20Bayesian%20optimization%20via%20additive%20models%20with%20overlapping%20groups%202018"
        },
        {
            "id": "40",
            "entry": "[40] Walter Rudin. Principles of Mathematical Analysis (International Series in Pure & Applied Mathematics). McGraw-Hill Publishing Co., 1976.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rudin%2C%20Walter%20Principles%20of%20Mathematical%20Analysis%20%28International%20Series%20in%20Pure%20%26%20Applied%20Mathematics%29%201976"
        },
        {
            "id": "41",
            "entry": "[41] Daniel Russo and Benjamin Van Roy. Learning to optimize via posterior sampling. Mathematics of Operations Research, 39(4):1221\u20131243, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20Learning%20to%20optimize%20via%20posterior%20sampling%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20Learning%20to%20optimize%20via%20posterior%20sampling%202014"
        },
        {
            "id": "42",
            "entry": "[42] Bernhard Sch\u00f6lkopf, Ralf Herbrich, and Alex Smola. A generalized representer theorem. In Computational learning theory, pages 416\u2013426.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sch%C3%B6lkopf%2C%20Bernhard%20Herbrich%2C%20Ralf%20Smola%2C%20Alex%20A%20generalized%20representer%20theorem",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sch%C3%B6lkopf%2C%20Bernhard%20Herbrich%2C%20Ralf%20Smola%2C%20Alex%20A%20generalized%20representer%20theorem"
        },
        {
            "id": "43",
            "entry": "[43] Steven L Scott. Multi-armed bandit experiments in the online service economy. Applied Stochastic Models in Business and Industry, 31(1):37\u201345, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scott%2C%20Steven%20L.%20Multi-armed%20bandit%20experiments%20in%20the%20online%20service%20economy.%20Applied%20Stochastic%20Models%20in%20Business%20and%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scott%2C%20Steven%20L.%20Multi-armed%20bandit%20experiments%20in%20the%20online%20service%20economy.%20Applied%20Stochastic%20Models%20in%20Business%20and%202015"
        },
        {
            "id": "44",
            "entry": "[44] Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. In Advances in neural information processing systems, pages 1257\u20131264, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Snelson%2C%20Edward%20Ghahramani%2C%20Zoubin%20Sparse%20Gaussian%20processes%20using%20pseudo-inputs%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Snelson%2C%20Edward%20Ghahramani%2C%20Zoubin%20Sparse%20Gaussian%20processes%20using%20pseudo-inputs%202006"
        },
        {
            "id": "45",
            "entry": "[45] Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md Mostofa Ali Patwary, Mr Prabhat, and Ryan P Adams. Scalable Bayesian optimization using deep neural networks. In International Conference on Machine Learning, pages 2171\u20132180, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scalable%20Bayesian%20optimization%20using%20deep%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scalable%20Bayesian%20optimization%20using%20deep%20neural%20networks%202015"
        },
        {
            "id": "46",
            "entry": "[46] Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian optimization with robust Bayesian neural networks. In Advances in Neural Information Processing Systems, pages 4134\u20134142, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Springenberg%2C%20Jost%20Tobias%20Klein%2C%20Aaron%20Falkner%2C%20Stefan%20Hutter%2C%20Frank%20Bayesian%20optimization%20with%20robust%20Bayesian%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Springenberg%2C%20Jost%20Tobias%20Klein%2C%20Aaron%20Falkner%2C%20Stefan%20Hutter%2C%20Frank%20Bayesian%20optimization%20with%20robust%20Bayesian%20neural%20networks%202016"
        },
        {
            "id": "47",
            "entry": "[47] Niranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. International Conference on Machine Learning, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srinivas%2C%20Niranjan%20Krause%2C%20Andreas%20Kakade%2C%20Sham%20M.%20Seeger%2C%20Matthias%20Gaussian%20process%20optimization%20in%20the%20bandit%20setting%3A%20No%20regret%20and%20experimental%20design%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srinivas%2C%20Niranjan%20Krause%2C%20Andreas%20Kakade%2C%20Sham%20M.%20Seeger%2C%20Matthias%20Gaussian%20process%20optimization%20in%20the%20bandit%20setting%3A%20No%20regret%20and%20experimental%20design%202010"
        },
        {
            "id": "48",
            "entry": "[48] Bharath Sriperumbudur and Zolt\u00e1n Szab\u00f3. Optimal rates for random Fourier features. In Advances in Neural Information Processing Systems, pages 1144\u20131152, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sriperumbudur%2C%20Bharath%20Szab%C3%B3%2C%20Zolt%C3%A1n%20Optimal%20rates%20for%20random%20Fourier%20features%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sriperumbudur%2C%20Bharath%20Szab%C3%B3%2C%20Zolt%C3%A1n%20Optimal%20rates%20for%20random%20Fourier%20features%202015"
        },
        {
            "id": "49",
            "entry": "[49] Josef Stoer and Roland Bulirsch. Introduction to numerical analysis, 2nd printing. SpringerVerlag, Berlin and New York, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stoer%2C%20Josef%20Bulirsch%2C%20Roland%20Introduction%20to%20numerical%20analysis%2C%202nd%20printing%201983"
        },
        {
            "id": "50",
            "entry": "[50] William R Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3/4):285\u2013294, 1933.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thompson%2C%20William%20R.%20On%20the%20likelihood%20that%20one%20unknown%20probability%20exceeds%20another%20in%20view%20of%20the%20evidence%20of%20two%20samples%201933",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thompson%2C%20William%20R.%20On%20the%20likelihood%20that%20one%20unknown%20probability%20exceeds%20another%20in%20view%20of%20the%20evidence%20of%20two%20samples%201933"
        },
        {
            "id": "51",
            "entry": "[51] Michalis Titsias. Variational learning of inducing variables in sparse Gaussian processes. In Artificial Intelligence and Statistics, pages 567\u2013574, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Titsias%2C%20Michalis%20Variational%20learning%20of%20inducing%20variables%20in%20sparse%20Gaussian%20processes%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Titsias%2C%20Michalis%20Variational%20learning%20of%20inducing%20variables%20in%20sparse%20Gaussian%20processes%202009"
        },
        {
            "id": "52",
            "entry": "[52] Andrea Vedaldi and Andrew Zisserman. Efficient additive kernels via explicit feature maps. IEEE transactions on pattern analysis and machine intelligence, 34(3):480\u2013492, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Efficient%20additive%20kernels%20via%20explicit%20feature%20maps%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Efficient%20additive%20kernels%20via%20explicit%20feature%20maps%202012"
        },
        {
            "id": "53",
            "entry": "[53] Zi Wang, Clement Gehring, Pushmeet Kohli, and Stefanie Jegelka. Ensemble Bayesian optimization. International Conference on Artificial Intelligence and Statistics, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zi%20Gehring%2C%20Clement%20Kohli%2C%20Pushmeet%20Jegelka%2C%20Stefanie%20Ensemble%20Bayesian%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zi%20Gehring%2C%20Clement%20Kohli%2C%20Pushmeet%20Jegelka%2C%20Stefanie%20Ensemble%20Bayesian%20optimization%202017"
        },
        {
            "id": "54",
            "entry": "[54] Zi Wang, Clement Gehring, Pushmeet Kohli, and Stefanie Jegelka. Batched large-scale Bayesian optimization in high-dimensional spaces. International Conference on Artificial Intelligence and Statistics, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zi%20Gehring%2C%20Clement%20Kohli%2C%20Pushmeet%20Jegelka%2C%20Stefanie%20Batched%20large-scale%20Bayesian%20optimization%20in%20high-dimensional%20spaces%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zi%20Gehring%2C%20Clement%20Kohli%2C%20Pushmeet%20Jegelka%2C%20Stefanie%20Batched%20large-scale%20Bayesian%20optimization%20in%20high-dimensional%20spaces%202018"
        },
        {
            "id": "55",
            "entry": "[55] Zi Wang and Stefanie Jegelka. Max-value entropy search for efficient Bayesian optimization. International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zi%20Jegelka%2C%20Stefanie%20Max-value%20entropy%20search%20for%20efficient%20Bayesian%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zi%20Jegelka%2C%20Stefanie%20Max-value%20entropy%20search%20for%20efficient%20Bayesian%20optimization%202017"
        },
        {
            "id": "56",
            "entry": "[56] Ziyu Wang, Frank Hutter, Masrour Zoghi, David Matheson, and Nando de Feitas. Bayesian optimization in a billion dimensions via random embeddings. Journal of Artificial Intelligence Research, 55:361\u2013387, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Ziyu%20Hutter%2C%20Frank%20Zoghi%2C%20Masrour%20Matheson%2C%20David%20Bayesian%20optimization%20in%20a%20billion%20dimensions%20via%20random%20embeddings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Ziyu%20Hutter%2C%20Frank%20Zoghi%2C%20Masrour%20Matheson%2C%20David%20Bayesian%20optimization%20in%20a%20billion%20dimensions%20via%20random%20embeddings%202016"
        },
        {
            "id": "57",
            "entry": "[57] Christopher KI Williams and Matthias Seeger. Using the nystr\u00f6m method to speed up kernel machines. In Advances in neural information processing systems, pages 682\u2013688, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Christopher%20K.I.%20Seeger%2C%20Matthias%20Using%20the%20nystr%C3%B6m%20method%20to%20speed%20up%20kernel%20machines%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Christopher%20K.I.%20Seeger%2C%20Matthias%20Using%20the%20nystr%C3%B6m%20method%20to%20speed%20up%20kernel%20machines%202001"
        },
        {
            "id": "58",
            "entry": "[58] Andrew Gordon Wilson, Christoph Dann, and Hannes Nickisch. Thoughts on massively scalable Gaussian processes. arXiv preprint arXiv:1511.01870, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.01870"
        },
        {
            "id": "59",
            "entry": "[59] Andrew Gordon Wilson and Hannes Nickisch. Kernel interpolation for scalable structured Gaussian processes (KISS-GP). In International Conference on Machine Learning, pages 1775\u20131784, 2015. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wilson%2C%20Andrew%20Gordon%20Nickisch%2C%20Hannes%20Kernel%20interpolation%20for%20scalable%20structured%20Gaussian%20processes%20%28KISS-GP%29%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wilson%2C%20Andrew%20Gordon%20Nickisch%2C%20Hannes%20Kernel%20interpolation%20for%20scalable%20structured%20Gaussian%20processes%20%28KISS-GP%29%202015"
        }
    ]
}
