{
    "filename": "7793-a-dual-framework-for-low-rank-tensor-completion.pdf",
    "metadata": {
        "title": "A Dual Framework for Low-rank Tensor Completion",
        "author": "Madhav Nimishakavi, Pratik Kumar Jawanpuria, Bamdev Mishra",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7793-a-dual-framework-for-low-rank-tensor-completion.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "One of the popular approaches for low-rank tensor completion is to use the latent trace norm regularization. However, most existing works in this direction learn a sparse combination of tensors. In this work, we fill this gap by proposing a variant of the latent trace norm that helps in learning a non-sparse combination of tensors. We develop a dual framework for solving the low-rank tensor completion problem. We first show a novel characterization of the dual solution space with an interesting factorization of the optimal solution. Overall, the optimal solution is shown to lie on a Cartesian product of Riemannian manifolds. Furthermore, we exploit the versatile Riemannian optimization framework for proposing computationally efficient trust region algorithm. The experiments illustrate the efficacy of the proposed algorithm on several real-world datasets across applications."
    },
    "keywords": [
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "trace norm",
            "url": "https://en.wikipedia.org/wiki/trace_norm"
        },
        {
            "term": "conjugate gradients",
            "url": "https://en.wikipedia.org/wiki/conjugate_gradients"
        },
        {
            "term": "tensor decomposition",
            "url": "https://en.wikipedia.org/wiki/tensor_decomposition"
        },
        {
            "term": "root mean squared error",
            "url": "https://en.wikipedia.org/wiki/root_mean_squared_error"
        },
        {
            "term": "optimal solution",
            "url": "https://en.wikipedia.org/wiki/optimal_solution"
        },
        {
            "term": "riemannian manifold",
            "url": "https://en.wikipedia.org/wiki/riemannian_manifold"
        }
    ],
    "highlights": [
        "Tensors are multidimensional or K-way arrays, which provide a natural way to represent multi-modal data [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>]",
        "We propose a novel trace norm regularizer for low-rank tensor completion problem, which learns a tensor as a non-sparse combination of tensors",
        "Latent trace norm is another convex regularizer used for low-rank tensor learning [<a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>, <a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>, <a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "It can be observed that TR-MM converges to the lowest root mean squared error at a significantly faster rate compared to the other baselines",
        "We introduce a variant of trace norm regularizer for low-rank tensor completion problem which learns the tensor as a non-sparse combination of tensors",
        "A similar result on the latent trace norm, which learns a sparse combination of tensors, is presented in [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>]"
    ],
    "key_statements": [
        "Tensors are multidimensional or K-way arrays, which provide a natural way to represent multi-modal data [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>]",
        "We propose a novel trace norm regularizer for low-rank tensor completion problem, which learns a tensor as a non-sparse combination of tensors",
        "Latent trace norm is another convex regularizer used for low-rank tensor learning [<a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>, <a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>, <a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "We present the following result related to the form of the optimal solution of (3)",
        "It can be observed that TR-MM converges to the lowest root mean squared error at a significantly faster rate compared to the other baselines",
        "We introduce a variant of trace norm regularizer for low-rank tensor completion problem which learns the tensor as a non-sparse combination of tensors",
        "A similar result on the latent trace norm, which learns a sparse combination of tensors, is presented in [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>]"
    ],
    "summary": [
        "Tensors are multidimensional or K-way arrays, which provide a natural way to represent multi-modal data [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>].",
        "We focus on trace norm regularized low-rank tensor completion problem of the form min",
        "We propose a novel trace norm regularizer for low-rank tensor completion problem, which learns a tensor as a non-sparse combination of tensors.",
        "Latent trace norm is another convex regularizer used for low-rank tensor learning [<a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>, <a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>, <a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>].",
        "[<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] proposed a scalable latent trace norm based Frank-Wolfe algorithm for tensor completion.",
        "Our model learns a non-sparse combination of tensors, whereas the latent trace norm",
        "In the particular case of Baboon dataset, the latent trace norm essentially learns W as a low-rank matrix (W = W(3)) and obtains poor generalization.",
        "Remark 1: Theorem 1 shows that the optimal solutions W(k)\u2217 for all k in (3) are completely characterized by a single sparse tensor Z\u2217 and K low-rank positive semi-definite matrices {\u03981\u2217, .",
        "In addition to the trace norm based algorithms, we compare against algorithms that model tensor via Tucker decomposition with fixed multilinear ranks: Rprecon [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>], geomCG [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>], and Topt [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>].",
        "Table 3 shows the rank sets at which the proposed TR-MM and Tucker decomposition based tensor completion algorithms (Rprecon, geomGC, Topt) achieve best results across datasets.",
        "Trace norm based algorithms (TR-MM, FFW, Latent) model the tensor completion by approximating the input tensor as a combination of tensors.",
        "Tucker-decomposition based algorithms model the tensor completion problem as a factorization problem with the given Tucker rank.",
        "We observe that trace norm regularized algorithms (TR-MM, FFW, Hard, HaLTRC, Latent) are relatively more robust to outliers than Tucker-decomposition based algorithms (Rprecon, geomCG, Topt), CP-decomposition based algorithm (BayesCP), and tensor tubal-rank based algorithm (T-svd).",
        "We introduce a variant of trace norm regularizer for low-rank tensor completion problem which learns the tensor as a non-sparse combination of tensors.",
        "We recommend learning a non-sparse combination of tensors in trace norm regularized setting, especially since K is typically a small integer in most real-world applications.",
        "A similar result on the latent trace norm, which learns a sparse combination of tensors, is presented in [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>].",
        "This leads to a novel fixed-rank formulation, for which we exploit the Riemannian framework to develop scalable trust region algorithm.",
        "Our algorithm TR-MM obtains better generalization performance and is more robust to outliers than state-of-the-art low-rank tensor completion algorithms."
    ],
    "headline": "We develop a dual framework for solving the low-rank tensor completion problem",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] P.-A. Absil, R. Mahony, and R. Sepulchre. Optimization Algorithms on Matrix Manifolds. Princeton University Press, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Absil%2C%20P.-A.%20Mahony%2C%20R.%20Sepulchre%2C%20R.%20Optimization%20Algorithms%20on%20Matrix%20Manifolds%202008"
        },
        {
            "id": "2",
            "entry": "[2] E. Acar, D. M. Dunlavy, T. G. Kolda, and M. M\u00f8rup. Scalable tensor factorizations for incomplete data. Chemometrics and Intelligent Laboratory Systems, 106(1):41\u201356, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Acar%2C%20E.%20Dunlavy%2C%20D.M.%20Kolda%2C%20T.G.%20M%C3%B8rup%2C%20M.%20Scalable%20tensor%20factorizations%20for%20incomplete%20data%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Acar%2C%20E.%20Dunlavy%2C%20D.M.%20Kolda%2C%20T.G.%20M%C3%B8rup%2C%20M.%20Scalable%20tensor%20factorizations%20for%20incomplete%20data%202011"
        },
        {
            "id": "3",
            "entry": "[3] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning. In NIPS, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Argyriou%2C%20A.%20Evgeniou%2C%20T.%20Pontil%2C%20M.%20Multi-task%20feature%20learning%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Argyriou%2C%20A.%20Evgeniou%2C%20T.%20Pontil%2C%20M.%20Multi-task%20feature%20learning%202006"
        },
        {
            "id": "4",
            "entry": "[4] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bordes%2C%20A.%20Usunier%2C%20N.%20Garcia-Duran%2C%20A.%20Weston%2C%20J.%20Translating%20embeddings%20for%20modeling%20multi-relational%20data.%20In%20NIPS%202013"
        },
        {
            "id": "5",
            "entry": "[5] N. Boumal, B. Mishra, P.-A. Absil, and R. Sepulchre. Manopt, a Matlab toolbox for optimization on manifolds. Journal of Machine Learning Research, 15(Apr):1455\u20131459, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boumal%2C%20N.%20Mishra%2C%20B.%20Absil%2C%20P.-A.%20Sepulchre%2C%20R.%20Manopt%2C%20a%20Matlab%20toolbox%20for%20optimization%20on%20manifolds%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boumal%2C%20N.%20Mishra%2C%20B.%20Absil%2C%20P.-A.%20Sepulchre%2C%20R.%20Manopt%2C%20a%20Matlab%20toolbox%20for%20optimization%20on%20manifolds%202014"
        },
        {
            "id": "6",
            "entry": "[6] C. F. Caiafa and A. Cichocki. Stable, robust, and super fast reconstruction of tensors using multi-way projections. IEEE Transactions on Signal Processing, 63(3):780\u2013793, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caiafa%2C%20C.F.%20Stable%2C%20A.Cichocki%20robust%20and%20super%20fast%20reconstruction%20of%20tensors%20using%20multi-way%20projections%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caiafa%2C%20C.F.%20Stable%2C%20A.Cichocki%20robust%20and%20super%20fast%20reconstruction%20of%20tensors%20using%20multi-way%20projections%202014"
        },
        {
            "id": "7",
            "entry": "[7] H. Cheng, Y. Yu, X. Zhang, E. Xing, and D. Schuurmans. Scalable and sound low-rank tensor learning. In AISTATS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cheng%2C%20H.%20Yu%2C%20Y.%20Zhang%2C%20X.%20Xing%2C%20E.%20Scalable%20and%20sound%20low-rank%20tensor%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cheng%2C%20H.%20Yu%2C%20Y.%20Zhang%2C%20X.%20Xing%2C%20E.%20Scalable%20and%20sound%20low-rank%20tensor%20learning%202016"
        },
        {
            "id": "8",
            "entry": "[8] A. Cichocki, H.-A. Phan, Q. Zhao, N. Lee, I. Oseledets, and D. P. Mandic. Tensor networks for dimensionality reduction and large-scale optimization: Part 1 low-rank tensor decompositions. Foundations and Trends in Machine Learning, 9(4\u20135):249\u2013429, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cichocki%2C%20A.%20Phan%2C%20H.-A.%20Zhao%2C%20Q.%20Lee%2C%20N.%20Tensor%20networks%20for%20dimensionality%20reduction%20and%20large-scale%20optimization%3A%20Part%201%20low-rank%20tensor%20decompositions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cichocki%2C%20A.%20Phan%2C%20H.-A.%20Zhao%2C%20Q.%20Lee%2C%20N.%20Tensor%20networks%20for%20dimensionality%20reduction%20and%20large-scale%20optimization%3A%20Part%201%20low-rank%20tensor%20decompositions%202017"
        },
        {
            "id": "9",
            "entry": "[9] A. Cichocki, H.-A. Phan, Q. Zhao, N. Lee, I. Oseledets, and D. P. Mandic. Tensor networks for dimensionality reduction and large-scale optimization: Part 2 applications and future perspectives. Foundations and Trends in Machine Learning, 9(6):431\u2013673, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cichocki%2C%20A.%20Phan%2C%20H.-A.%20Zhao%2C%20Q.%20Lee%2C%20N.%20Tensor%20networks%20for%20dimensionality%20reduction%20and%20large-scale%20optimization%3A%20Part%202%20applications%20and%20future%20perspectives%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cichocki%2C%20A.%20Phan%2C%20H.-A.%20Zhao%2C%20Q.%20Lee%2C%20N.%20Tensor%20networks%20for%20dimensionality%20reduction%20and%20large-scale%20optimization%3A%20Part%202%20applications%20and%20future%20perspectives%202017"
        },
        {
            "id": "10",
            "entry": "[10] C. Cortes, M. Mohri, and A. Rostamizadeh. L2 regularization for learning kernels. In UAI, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20C.%20Mohri%2C%20M.%20A.%20Rostamizadeh.%20L2%20regularization%20for%20learning%20kernels%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20C.%20Mohri%2C%20M.%20A.%20Rostamizadeh.%20L2%20regularization%20for%20learning%20kernels%202009"
        },
        {
            "id": "11",
            "entry": "[11] A. Edelman, T.A. Arias, and S.T. Smith. The geometry of algorithms with orthogonality constraints. SIAM Journal on Matrix Analysis and Applications, 20(2):303\u2013353, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Edelman%2C%20A.%20Arias%2C%20T.A.%20Smith%2C%20S.T.%20The%20geometry%20of%20algorithms%20with%20orthogonality%20constraints%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Edelman%2C%20A.%20Arias%2C%20T.A.%20Smith%2C%20S.T.%20The%20geometry%20of%20algorithms%20with%20orthogonality%20constraints%201998"
        },
        {
            "id": "12",
            "entry": "[12] B. Ermis, E. Acar, and A. T. Cemgil. Link prediction in heterogeneous data via generalized coupled tensor factorization. In KDD, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ermis%2C%20B.%20Acar%2C%20E.%20Cemgil%2C%20A.T.%20Link%20prediction%20in%20heterogeneous%20data%20via%20generalized%20coupled%20tensor%20factorization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ermis%2C%20B.%20Acar%2C%20E.%20Cemgil%2C%20A.T.%20Link%20prediction%20in%20heterogeneous%20data%20via%20generalized%20coupled%20tensor%20factorization%202015"
        },
        {
            "id": "13",
            "entry": "[13] M. Filipovicand A. Jukic. Tucker factorization with missing data with application to low-n-rank tensor completion. Multidimensional Systems and Signal Processing, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jukic%2C%20M.Filipovicand%20A.%20Tucker%20factorization%20with%20missing%20data%20with%20application%20to%20low-n-rank%20tensor%20completion%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jukic%2C%20M.Filipovicand%20A.%20Tucker%20factorization%20with%20missing%20data%20with%20application%20to%20low-n-rank%20tensor%20completion%202015"
        },
        {
            "id": "14",
            "entry": "[14] D. H. Foster, S. M. C. Nascimento, and K. Amano. Information limits on neural identification of colored surfaces in natural scenes. Visual Neuroscience, 21(3):331\u2013336, 2004. URL: https://personalpages.manchester.ac.uk/staff/d.h.foster/.",
            "url": "https://personalpages.manchester.ac.uk/staff/d.h.foster/",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Foster%2C%20D.H.%20Nascimento%2C%20S.M.C.%20Amano%2C%20K.%20Information%20limits%20on%20neural%20identification%20of%20colored%20surfaces%20in%20natural%20scenes%202004"
        },
        {
            "id": "15",
            "entry": "[15] X. Guo, Q. Yao, and J. T. Kwok. Efficient sparse low-rank tensor completion using the frank-wolfe algorithm. In AAAI, 2017. URL: https://github.com/quanmingyao/FFWTensor.",
            "url": "https://github.com/quanmingyao/FFWTensor",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20X.%20Yao%2C%20Q.%20Kwok%2C%20J.T.%20Efficient%20sparse%20low-rank%20tensor%20completion%20using%20the%20frank-wolfe%20algorithm%202017"
        },
        {
            "id": "16",
            "entry": "[16] F. M. Harper and J. A. Konstan. The movielens datasets: History and context. ACM Transactions on Interactive Intelligent Systems, 5(4):19:1\u201319:19, 2015. URL: http://files.grouplens.org/datasets/movielens/ml-10m-README.html.",
            "url": "http://files.grouplens.org/datasets/movielens/ml-10m-README.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Harper%2C%20F.M.%20Konstan%2C%20J.A.%20The%20movielens%20datasets%3A%20History%20and%20context%202015"
        },
        {
            "id": "17",
            "entry": "[17] P. Jawanpuria, M. Lapin, M. Hein, and B. Schiele. Efficient output kernel learning for multiple tasks. In NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jawanpuria%2C%20P.%20Lapin%2C%20M.%20Hein%2C%20M.%20Schiele%2C%20B.%20Efficient%20output%20kernel%20learning%20for%20multiple%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jawanpuria%2C%20P.%20Lapin%2C%20M.%20Hein%2C%20M.%20Schiele%2C%20B.%20Efficient%20output%20kernel%20learning%20for%20multiple%20tasks%202015"
        },
        {
            "id": "18",
            "entry": "[18] P. Jawanpuria and B. Mishra. A unified framework for structured low-rank matrix learning. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jawanpuria%2C%20P.%20Mishra%2C%20B.%20A%20unified%20framework%20for%20structured%20low-rank%20matrix%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jawanpuria%2C%20P.%20Mishra%2C%20B.%20A%20unified%20framework%20for%20structured%20low-rank%20matrix%20learning%202018"
        },
        {
            "id": "19",
            "entry": "[19] P. Jawanpuria and J. S. Nath. Multi-task multiple kernel learning. In SIAM ICDM, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jawanpuria%2C%20P.%20Nath%2C%20J.S.%20Multi-task%20multiple%20kernel%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jawanpuria%2C%20P.%20Nath%2C%20J.S.%20Multi-task%20multiple%20kernel%20learning%202011"
        },
        {
            "id": "20",
            "entry": "[20] P. Jawanpuria, M. Varma, and J. S. Nath. On p-norm path following in multiple kernel learning for non-linear feature selection. In ICML, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jawanpuria%2C%20P.%20Varma%2C%20M.%20Nath%2C%20J.S.%20On%20p-norm%20path%20following%20in%20multiple%20kernel%20learning%20for%20non-linear%20feature%20selection%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jawanpuria%2C%20P.%20Varma%2C%20M.%20Nath%2C%20J.S.%20On%20p-norm%20path%20following%20in%20multiple%20kernel%20learning%20for%20non-linear%20feature%20selection%202014"
        },
        {
            "id": "21",
            "entry": "[21] M. Journ\u00e9e, F. Bach, P.-A. Absil, and R. Sepulchre. Low-rank optimization on the cone of positive semidefinite matrices. SIAM Journal on Optimization, 20(5):2327\u20132351, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Journ%C3%A9e%2C%20M.%20Bach%2C%20F.%20Absil%2C%20P.-A.%20Sepulchre%2C%20R.%20Low-rank%20optimization%20on%20the%20cone%20of%20positive%20semidefinite%20matrices%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Journ%C3%A9e%2C%20M.%20Bach%2C%20F.%20Absil%2C%20P.-A.%20Sepulchre%2C%20R.%20Low-rank%20optimization%20on%20the%20cone%20of%20positive%20semidefinite%20matrices%202010"
        },
        {
            "id": "22",
            "entry": "[22] H. Kasai and B. Mishra. Low-rank tensor completion: a Riemannian manifold preconditioning approach. In ICML, 2016. URL: https://bamdevmishra.in/codes/tensorcompletion/.",
            "url": "https://bamdevmishra.in/codes/tensorcompletion/",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kasai%2C%20H.%20Mishra%2C%20B.%20Low-rank%20tensor%20completion%3A%20a%20Riemannian%20manifold%20preconditioning%20approach%202016"
        },
        {
            "id": "23",
            "entry": "[23] T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM Review, 51(3):455\u2013 500, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kolda%2C%20T.G.%20Bader%2C%20B.W.%20Tensor%20decompositions%20and%20applications%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kolda%2C%20T.G.%20Bader%2C%20B.W.%20Tensor%20decompositions%20and%20applications%202009"
        },
        {
            "id": "24",
            "entry": "[24] D. Kressner, M. Steinlechner, and B. Vandereycken. Low-rank tensor completion by Riemannian optimization. BIT Numerical Mathematics, 54(2):447\u2013468, 2014. URL: anchp.epfl.ch/geomCG.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kressner%2C%20D.%20Steinlechner%2C%20M.%20Vandereycken%2C%20B.%20Low-rank%20tensor%20completion%20by%20Riemannian%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kressner%2C%20D.%20Steinlechner%2C%20M.%20Vandereycken%2C%20B.%20Low-rank%20tensor%20completion%20by%20Riemannian%20optimization%202014"
        },
        {
            "id": "25",
            "entry": "[25] J. Liu, P. Musialski, P. Wonka, and J. Ye. Tensor completion for estimating missing values in visual data. IEEE PAMI, 35(1):208\u2013220, 2013. URL: http://www.cs.rochester.edu/u/jliu/code/TensorCompletion.zip.",
            "url": "http://www.cs.rochester.edu/u/jliu/code/TensorCompletion.zip",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20J.%20Musialski%2C%20P.%20Wonka%2C%20P.%20Ye%2C%20J.%20Tensor%20completion%20for%20estimating%20missing%20values%20in%20visual%20data%202013"
        },
        {
            "id": "26",
            "entry": "[26] X.-Y. Liu, S. Aeron, V. Aggarwal, and X. Wang. Low-tubal-rank tensor completion using alternating minimization. In SPIE Conference on Defense and Security, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20X.-Y.%20Aeron%2C%20S.%20Aggarwal%2C%20V.%20Wang%2C%20X.%20Low-tubal-rank%20tensor%20completion%20using%20alternating%20minimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20X.-Y.%20Aeron%2C%20S.%20Aggarwal%2C%20V.%20Wang%2C%20X.%20Low-tubal-rank%20tensor%20completion%20using%20alternating%20minimization%202016"
        },
        {
            "id": "27",
            "entry": "[27] L. L\u00fc and T. Zhou. Link prediction in complex networks: A survey. Physica A: statistical mechanics and its applications, 390(6):1150\u20131170, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=L%C3%BC%2C%20L.%20Zhou%2C%20T.%20Link%20prediction%20in%20complex%20networks%3A%20A%20survey%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=L%C3%BC%2C%20L.%20Zhou%2C%20T.%20Link%20prediction%20in%20complex%20networks%3A%20A%20survey%202011"
        },
        {
            "id": "28",
            "entry": "[28] M. Nimishakavi, P. Jawanpuria, and B. Mishra. A dual framework for low-rank tensor completion. Technical report, arXiv preprint arXiv:1712.01193, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.01193"
        },
        {
            "id": "29",
            "entry": "[29] T. K. Pong, P. Tseng, S. Ji, and J. Ye. Trace norm regularization: Reformulations, algorithms, and multi-task learning. SIAM Journal on Optimization, 20(6):3465\u20133489, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pong%2C%20T.K.%20Tseng%2C%20P.%20Ji%2C%20S.%20Ye%2C%20J.%20Trace%20norm%20regularization%3A%20Reformulations%2C%20algorithms%2C%20and%20multi-task%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pong%2C%20T.K.%20Tseng%2C%20P.%20Ji%2C%20S.%20Ye%2C%20J.%20Trace%20norm%20regularization%3A%20Reformulations%2C%20algorithms%2C%20and%20multi-task%20learning%202010"
        },
        {
            "id": "30",
            "entry": "[30] B. Romera-paredes, H. Aung, N. Bianchi-berthouze, and M. Pontil. Multilinear multitask learning. In ICML, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Romera-paredes%2C%20B.%20Aung%2C%20H.%20Bianchi-berthouze%2C%20N.%20Pontil%2C%20M.%20Multilinear%20multitask%20learning%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Romera-paredes%2C%20B.%20Aung%2C%20H.%20Bianchi-berthouze%2C%20N.%20Pontil%2C%20M.%20Multilinear%20multitask%20learning%202013"
        },
        {
            "id": "31",
            "entry": "[31] H. Sato and T. Iwai. A new, globally convergent Riemannian conjugate gradient method. Optimization: A Journal of Mathematical Programming and Operations Research, 64(4):1011\u2013 1031, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sato%2C%20H.%20Iwai%2C%20T.%20A%20new%2C%20globally%20convergent%20Riemannian%20conjugate%20gradient%20method%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sato%2C%20H.%20Iwai%2C%20T.%20A%20new%2C%20globally%20convergent%20Riemannian%20conjugate%20gradient%20method%202013"
        },
        {
            "id": "32",
            "entry": "[32] H. Sato, H. Kasai, and B. Mishra. Riemannian stochastic variance reduced gradient. Technical report, arXiv preprint arXiv:1702.05594, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.05594"
        },
        {
            "id": "33",
            "entry": "[33] M. Signoretto, Q. T. Dinh, L. D. Lathauwer, and J. A. K. Suykens. Learning with tensors: a framework based on convex optimization and spectral regularization. Machine Learning, 94(3):303\u2013351, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Signoretto%2C%20M.%20Dinh%2C%20Q.T.%20Lathauwer%2C%20L.D.%20Suykens%2C%20J.A.K.%20Learning%20with%20tensors%3A%20a%20framework%20based%20on%20convex%20optimization%20and%20spectral%20regularization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Signoretto%2C%20M.%20Dinh%2C%20Q.T.%20Lathauwer%2C%20L.D.%20Suykens%2C%20J.A.K.%20Learning%20with%20tensors%3A%20a%20framework%20based%20on%20convex%20optimization%20and%20spectral%20regularization%202014"
        },
        {
            "id": "34",
            "entry": "[34] T. Suzuki. Unifying framework for fast learning rate of non-sparse multiple kernel learning. In NIPS, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Suzuki%2C%20T.%20Unifying%20framework%20for%20fast%20learning%20rate%20of%20non-sparse%20multiple%20kernel%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Suzuki%2C%20T.%20Unifying%20framework%20for%20fast%20learning%20rate%20of%20non-sparse%20multiple%20kernel%20learning%202011"
        },
        {
            "id": "35",
            "entry": "[35] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. Tag recommendations based on tensor dimensionality reduction. In RecSys, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Symeonidis%2C%20P.%20Nanopoulos%2C%20A.%20Manolopoulos%2C%20Y.%20Tag%20recommendations%20based%20on%20tensor%20dimensionality%20reduction%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Symeonidis%2C%20P.%20Nanopoulos%2C%20A.%20Manolopoulos%2C%20Y.%20Tag%20recommendations%20based%20on%20tensor%20dimensionality%20reduction%202008"
        },
        {
            "id": "36",
            "entry": "[36] L. Tang, X. Wang, and H. Liu. Uncovering groups via heterogeneous interaction analysis. In ICDM, 2009. URL: http://leitang.net/heterogeneous_network.html.",
            "url": "http://leitang.net/heterogeneous_network.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tang%2C%20L.%20Wang%2C%20X.%20Liu%2C%20H.%20Uncovering%20groups%20via%20heterogeneous%20interaction%20analysis%202009"
        },
        {
            "id": "37",
            "entry": "[37] R. Tomioka, K. Hayashi, and H. Kashima. Estimation of low-rank tensors via convex optimization. Technical report, arXiv preprint arXiv:1010.0789, 2010.",
            "arxiv_url": "https://arxiv.org/pdf/1010.0789"
        },
        {
            "id": "38",
            "entry": "[38] R. Tomioka and T. Suzuki. Convex tensor decomposition via structured schatten norm regularization. In NIPS, 2013. URL: http://tomioka.dk/softwares/.",
            "url": "http://tomioka.dk/softwares/",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tomioka%2C%20R.%20Suzuki%2C%20T.%20Convex%20tensor%20decomposition%20via%20structured%20schatten%20norm%20regularization%202013"
        },
        {
            "id": "39",
            "entry": "[39] R. Tomioka, T. Suzuki, K. Hayashi, and H. Kashima. Statistical performance of convex tensor decomposition. In NIPS, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tomioka%2C%20R.%20Suzuki%2C%20T.%20Hayashi%2C%20K.%20Kashima%2C%20H.%20Statistical%20performance%20of%20convex%20tensor%20decomposition%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tomioka%2C%20R.%20Suzuki%2C%20T.%20Hayashi%2C%20K.%20Kashima%2C%20H.%20Statistical%20performance%20of%20convex%20tensor%20decomposition%202011"
        },
        {
            "id": "40",
            "entry": "[40] K. Toutanova, D. Chen, P. Pantel, H. Poon, P. Choudhury, and M. Gamon. Representing text for joint embedding of text and knowledge bases. In EMNLP, 2015. URL: http://kristinatoutanova.com/.",
            "url": "http://kristinatoutanova.com/",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Toutanova%2C%20K.%20Chen%2C%20D.%20Pantel%2C%20P.%20Poon%2C%20H.%20Representing%20text%20for%20joint%20embedding%20of%20text%20and%20knowledge%20bases%202015"
        },
        {
            "id": "41",
            "entry": "[41] K. Wimalawarne, M. Sugiyama, and R. Tomioka. Multitask learning meets tensor factorization: task imputation via convex optimization. In NIPS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wimalawarne%2C%20K.%20Sugiyama%2C%20M.%20Tomioka%2C%20R.%20Multitask%20learning%20meets%20tensor%20factorization%3A%20task%20imputation%20via%20convex%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wimalawarne%2C%20K.%20Sugiyama%2C%20M.%20Tomioka%2C%20R.%20Multitask%20learning%20meets%20tensor%20factorization%3A%20task%20imputation%20via%20convex%20optimization%202014"
        },
        {
            "id": "42",
            "entry": "[42] Y. Xin and T. Jaakkola. Primal-dual methods for sparse constrained matrix completion. In AISTATS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xin%2C%20Y.%20Jaakkola%2C%20T.%20Primal-dual%20methods%20for%20sparse%20constrained%20matrix%20completion%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xin%2C%20Y.%20Jaakkola%2C%20T.%20Primal-dual%20methods%20for%20sparse%20constrained%20matrix%20completion%202012"
        },
        {
            "id": "43",
            "entry": "[43] H. Zhang, S. J. Reddi, and S. Sra. Riemannian svrg: Fast stochastic optimization on Riemannian manifolds. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20H.%20Reddi%2C%20S.J.%20Sra%2C%20S.%20Riemannian%20svrg%3A%20Fast%20stochastic%20optimization%20on%20Riemannian%20manifolds%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20H.%20Reddi%2C%20S.J.%20Sra%2C%20S.%20Riemannian%20svrg%3A%20Fast%20stochastic%20optimization%20on%20Riemannian%20manifolds%202016"
        },
        {
            "id": "44",
            "entry": "[44] Z. Zhang, G. Ely, S. Aeron, N. Hao, and M. E. Kilmer. Novel methods for multilinear data completion and de-noising based on tensor-svd. In CVPR, 2014. URL: http://www.ece.tufts.edu/shuchin/software.html.",
            "url": "http://www.ece.tufts.edu/shuchin/software.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Z.%20Ely%2C%20G.%20Aeron%2C%20S.%20Hao%2C%20N.%20Novel%20methods%20for%20multilinear%20data%20completion%20and%20de-noising%20based%202014"
        },
        {
            "id": "45",
            "entry": "[45] Q. Zhao, L. Zhang, and A. Cichocki. Bayesian CP factorization of incomplete tensors with automatic rank determination. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(9):1751\u20131763, 2015. URL: https://github.com/qbzhao/BCPF. ",
            "url": "https://github.com/qbzhao/BCPF",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Q.%20Zhang%2C%20L.%20Cichocki%2C%20A.%20Bayesian%20CP%20factorization%20of%20incomplete%20tensors%20with%20automatic%20rank%20determination%202015"
        }
    ]
}
