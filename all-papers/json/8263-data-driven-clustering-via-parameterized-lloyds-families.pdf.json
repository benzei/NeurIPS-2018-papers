{
    "filename": "8263-data-driven-clustering-via-parameterized-lloyds-families.pdf",
    "metadata": {
        "title": "Data-Driven Clustering via Parameterized Lloyd's Families",
        "author": "Maria-Florina F. Balcan, Travis Dick, Colin White",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8263-data-driven-clustering-via-parameterized-lloyds-families.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Algorithms for clustering points in metric spaces is a long-studied area of research. Clustering has seen a multitude of work both theoretically, in understanding the approximation guarantees possible for many objective functions such as k-median and k-means clustering, and experimentally, in finding the fastest algorithms and seeding procedures for Lloyd\u2019s algorithm. The performance of a given clustering algorithm depends on the specific application at hand, and this may not be known up front. For example, a \u201ctypical instance\u201d may vary depending on the application, and different clustering heuristics perform differently depending on the instance. In this paper, we define an infinite family of algorithms generalizing Lloyd\u2019s algorithm, with one parameter controlling the initialization procedure, and another parameter controlling the local search procedure. This family of algorithms includes the celebrated k-means++ algorithm, as well as the classic farthest-first traversal algorithm. We design efficient learning algorithms which receive samples from an application-specific distribution over clustering instances and learn a nearoptimal clustering algorithm from the class. We show the best parameters vary significantly across datasets such as MNIST, CIFAR, and mixtures of Gaussians. Our learned algorithms never perform worse than k-means++, and on some datasets we see significant improvements."
    },
    "keywords": [
        {
            "term": "social network",
            "url": "https://en.wikipedia.org/wiki/social_network"
        },
        {
            "term": "clustering algorithm",
            "url": "https://en.wikipedia.org/wiki/clustering_algorithm"
        },
        {
            "term": "text analysis",
            "url": "https://en.wikipedia.org/wiki/text_analysis"
        },
        {
            "term": "objective function",
            "url": "https://en.wikipedia.org/wiki/objective_function"
        },
        {
            "term": "lloyds algorithm",
            "url": "https://en.wikipedia.org/wiki/lloyds_algorithm"
        }
    ],
    "highlights": [
        "Clustering is a fundamental problem in machine learning with applications in many areas including text analysis, transportation networks, social networks, and so on",
        "We show positive theoretical and empirical results for learning the best initialization and local search procedures over a large family of algorithms",
        "We show the the optimal parameters transfer from one instance to the other",
        "We provide a sample efficient and computationally efficient algorithm to learn a near-optimal parameter over an unknown distribution of clustering instances, by developing techniques to bound the expected number of discontinuities in the cost as a function of the parameter",
        "We show the optimal parameters vary among different types of datasets, and the optimal parameters often significantly improves the error compared to existing algorithms such as k-means++ and farthest-first traversal"
    ],
    "key_statements": [
        "Clustering is a fundamental problem in machine learning with applications in many areas including text analysis, transportation networks, social networks, and so on",
        "We show positive theoretical and empirical results for learning the best initialization and local search procedures over a large family of algorithms",
        "We show the the optimal parameters transfer from one instance to the other",
        "We provide a sample efficient and computationally efficient algorithm to learn a near-optimal parameter over an unknown distribution of clustering instances, by developing techniques to bound the expected number of discontinuities in the cost as a function of the parameter",
        "We show the optimal parameters vary among different types of datasets, and the optimal parameters often significantly improves the error compared to existing algorithms such as k-means++ and farthest-first traversal"
    ],
    "summary": [
        "Clustering is a fundamental problem in machine learning with applications in many areas including text analysis, transportation networks, social networks, and so on.",
        "The seeding phase is a spectrum between random seeding (\u03b1 = 0), and farthest-first traversal (\u03b1 = \u221e), and the Lloyd\u2019s algorithm can optimize for common clustering objectives including k-median (\u03b2 = 1), k-means (\u03b2 = 2), and k-center (\u03b2 = \u221e).",
        "Our main structural result is to show that for a given clustering instance and value of \u03b2, with high probability over the randomness in Algorithm 1, the number of discontinuities of the cost function clus\u03b1,\u03b2 V, Z as we vary \u03b1 \u2208 [0, \u03b1h] is O\u03b1h).",
        "If we use a combinatorial approach as in prior algorithm configuration work, we would only achieve a bound of nO(k), which is the total number of sets of k centers.",
        "Our goal is to bound the total number of breakpoints over all k rounds in phase 1 of Algorithm 1, which bounds the number of discontinuities of the cost of the outputted clustering as a function of \u03b1 over [\u03b1 , \u03b1h].",
        "[\u03b1 , \u03b1 +1], we claim the expected number of new breakpoints #It, by choosing a center in round t is bounded by 4n log n(\u03b1 +1 \u2212 \u03b1 ).",
        "We define lloyds\u03b2(V, C, T ) as the cost of the outputted clustering from phase 2 of Algorithm 1 on instance V with initial centers C, and a maximum of T iterations.",
        "Given T \u2208 N, a clustering instance V, and a fixed set C of initial centers, the number of discontinuities of lloyds\u03b2(V, C, T ) as a function of \u03b2 on instance V is O).",
        "Given V and a set of initial centers C, we bound the number of discontinuities introduced in the Lloyd\u2019s step of Algorithm 1.",
        "By combining Theorem 4 with Theorem 5, and using standard learning theory results, we can bound the sample complexity needed to learn near-optimal parameters \u03b1, \u03b2 for an unknown distribution D over clustering instances.",
        "The high-level idea of our algorithm is to directly enumerate the set of centers that can possibly be output by d\u03b1-sampling for a given clustering instance V and pre-sampled randomness Z.",
        "We provide a sample efficient and computationally efficient algorithm to learn a near-optimal parameter over an unknown distribution of clustering instances, by developing techniques to bound the expected number of discontinuities in the cost as a function of the parameter.",
        "We show the optimal parameters vary among different types of datasets, and the optimal parameters often significantly improves the error compared to existing algorithms such as k-means++ and farthest-first traversal"
    ],
    "headline": "We show the best parameters vary significantly across datasets such as MNIST, CIFAR, and mixtures of Gaussians",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sara Ahmadian, Ashkan Norouzi-Fard, Ola Svensson, and Justin Ward. Better guarantees for k-means and euclidean k-median by primal-dual algorithms. In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahmadian%2C%20Sara%20Norouzi-Fard%2C%20Ashkan%20Svensson%2C%20Ola%20Ward%2C%20Justin%20Better%20guarantees%20for%20k-means%20and%20euclidean%20k-median%20by%20primal-dual%20algorithms%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahmadian%2C%20Sara%20Norouzi-Fard%2C%20Ashkan%20Svensson%2C%20Ola%20Ward%2C%20Justin%20Better%20guarantees%20for%20k-means%20and%20euclidean%20k-median%20by%20primal-dual%20algorithms%202017"
        },
        {
            "id": "2",
            "entry": "[2] Kohei Arai and Ali Ridho Barakbah. Hierarchical k-means: an algorithm for centroids initialization for k-means. Reports of the Faculty of Science and Engineering, 36(1):25\u201331, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arai%2C%20Kohei%20Barakbah%2C%20Ali%20Ridho%20Hierarchical%20k-means%3A%20an%20algorithm%20for%20centroids%20initialization%20for%20k-means%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arai%2C%20Kohei%20Barakbah%2C%20Ali%20Ridho%20Hierarchical%20k-means%3A%20an%20algorithm%20for%20centroids%20initialization%20for%20k-means%202007"
        },
        {
            "id": "3",
            "entry": "[3] David Arthur and Sergei Vassilvitskii. k-means++: The advantages of careful seeding. In Proceedings of the Annual Symposium on Discrete Algorithms (SODA), pages 1027\u20131035, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arthur%2C%20David%20Vassilvitskii%2C%20Sergei%20k-means%2B%2B%3A%20The%20advantages%20of%20careful%20seeding%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arthur%2C%20David%20Vassilvitskii%2C%20Sergei%20k-means%2B%2B%3A%20The%20advantages%20of%20careful%20seeding%202007"
        },
        {
            "id": "4",
            "entry": "[4] Vijay Arya, Naveen Garg, Rohit Khandekar, Adam Meyerson, Kamesh Munagala, and Vinayaka Pandit. Local search heuristics for k-median and facility location problems. SIAM Journal on Computing, 33(3):544\u2013562, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arya%2C%20Vijay%20Garg%2C%20Naveen%20Khandekar%2C%20Rohit%20Meyerson%2C%20Adam%20Local%20search%20heuristics%20for%20k-median%20and%20facility%20location%20problems%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arya%2C%20Vijay%20Garg%2C%20Naveen%20Khandekar%2C%20Rohit%20Meyerson%2C%20Adam%20Local%20search%20heuristics%20for%20k-median%20and%20facility%20location%20problems%202004"
        },
        {
            "id": "5",
            "entry": "[5] Hassan Ashtiani and Shai Ben-David. Representation learning for clustering: a statistical framework. In Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence, pages 82\u201391, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashtiani%2C%20Hassan%20Ben-David%2C%20Shai%20Representation%20learning%20for%20clustering%3A%20a%20statistical%20framework%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashtiani%2C%20Hassan%20Ben-David%2C%20Shai%20Representation%20learning%20for%20clustering%3A%20a%20statistical%20framework%202015"
        },
        {
            "id": "6",
            "entry": "[6] Maria-Florina Balcan, Vaishnavh Nagarajan, Ellen Vitercik, and Colin White. Learning-theoretic foundations of algorithm configuration for combinatorial partitioning problems. In Proceedings of the Annual Conference on Learning Theory (COLT), pages 213\u2013274, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20Maria-Florina%20Nagarajan%2C%20Vaishnavh%20Vitercik%2C%20Ellen%20White%2C%20Colin%20Learning-theoretic%20foundations%20of%20algorithm%20configuration%20for%20combinatorial%20partitioning%20problems%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20Maria-Florina%20Nagarajan%2C%20Vaishnavh%20Vitercik%2C%20Ellen%20White%2C%20Colin%20Learning-theoretic%20foundations%20of%20algorithm%20configuration%20for%20combinatorial%20partitioning%20problems%202017"
        },
        {
            "id": "7",
            "entry": "[7] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. Journal of Machine Learning Research, 3(Nov):463\u2013482, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20Peter%20L.%20Mendelson%2C%20Shahar%20Rademacher%20and%20gaussian%20complexities%3A%20Risk%20bounds%20and%20structural%20results%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20Peter%20L.%20Mendelson%2C%20Shahar%20Rademacher%20and%20gaussian%20complexities%3A%20Risk%20bounds%20and%20structural%20results%202002"
        },
        {
            "id": "8",
            "entry": "[8] Jonathan Baxter. A bayesian/information theoretic model of learning to learn via multiple task sampling. Machine learning, 28(1):7\u201339, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baxter%2C%20Jonathan%20A%20bayesian/information%20theoretic%20model%20of%20learning%20to%20learn%20via%20multiple%20task%20sampling%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baxter%2C%20Jonathan%20A%20bayesian/information%20theoretic%20model%20of%20learning%20to%20learn%20via%20multiple%20task%20sampling%201997"
        },
        {
            "id": "9",
            "entry": "[9] Jaros\u0142aw Byrka, Thomas Pensyl, Bartosz Rybicki, Aravind Srinivasan, and Khoa Trinh. An improved approximation for k-median, and positive correlation in budgeted optimization. In Proceedings of the Annual Symposium on Discrete Algorithms (SODA), pages 737\u2013756, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Byrka%2C%20Jaros%C5%82aw%20Pensyl%2C%20Thomas%20Rybicki%2C%20Bartosz%20Srinivasan%2C%20Aravind%20An%20improved%20approximation%20for%20k-median%2C%20and%20positive%20correlation%20in%20budgeted%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Byrka%2C%20Jaros%C5%82aw%20Pensyl%2C%20Thomas%20Rybicki%2C%20Bartosz%20Srinivasan%2C%20Aravind%20An%20improved%20approximation%20for%20k-median%2C%20and%20positive%20correlation%20in%20budgeted%20optimization%202015"
        },
        {
            "id": "10",
            "entry": "[10] Moses Charikar, Sudipto Guha, \u00c9va Tardos, and David B Shmoys. A constant-factor approximation algorithm for the k-median problem. In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 1\u201310, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charikar%2C%20Moses%20Guha%2C%20Sudipto%20Tardos%2C%20%C3%89va%20Shmoys%2C%20David%20B.%20A%20constant-factor%20approximation%20algorithm%20for%20the%20k-median%20problem%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charikar%2C%20Moses%20Guha%2C%20Sudipto%20Tardos%2C%20%C3%89va%20Shmoys%2C%20David%20B.%20A%20constant-factor%20approximation%20algorithm%20for%20the%20k-median%20problem%201999"
        },
        {
            "id": "11",
            "entry": "[11] Michael B Cohen, Yin Tat Lee, Gary Miller, Jakub Pachocki, and Aaron Sidford. Geometric median in nearly linear time. In Proceedings of the Annual Symposium on Theory of Computing (STOC), pages 9\u201321. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20Michael%20B.%20Lee%2C%20Yin%20Tat%20Miller%2C%20Gary%20Pachocki%2C%20Jakub%20Geometric%20median%20in%20nearly%20linear%20time%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20Michael%20B.%20Lee%2C%20Yin%20Tat%20Miller%2C%20Gary%20Pachocki%2C%20Jakub%20Geometric%20median%20in%20nearly%20linear%20time%202016"
        },
        {
            "id": "12",
            "entry": "[12] Sanjoy Dasgupta and Philip M Long. Performance guarantees for hierarchical clustering. Journal of Computer and System Sciences, 70(4):555\u2013569, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dasgupta%2C%20Sanjoy%20Long%2C%20Philip%20M.%20Performance%20guarantees%20for%20hierarchical%20clustering%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dasgupta%2C%20Sanjoy%20Long%2C%20Philip%20M.%20Performance%20guarantees%20for%20hierarchical%20clustering%202005"
        },
        {
            "id": "13",
            "entry": "[13] Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society, pages 1\u201338, 1977.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dempster%2C%20Arthur%20P.%20Laird%2C%20Nan%20M.%20Rubin%2C%20Donald%20B.%20Maximum%20likelihood%20from%20incomplete%20data%20via%20the%20em%20algorithm%201977",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dempster%2C%20Arthur%20P.%20Laird%2C%20Nan%20M.%20Rubin%2C%20Donald%20B.%20Maximum%20likelihood%20from%20incomplete%20data%20via%20the%20em%20algorithm%201977"
        },
        {
            "id": "14",
            "entry": "[14] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning, volume 1. Springer series in statistics New York, NY, USA:, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Friedman%2C%20Jerome%20Hastie%2C%20Trevor%20Tibshirani%2C%20Robert%20The%20elements%20of%20statistical%20learning%2C%20volume%201.%20Springer%20series%20in%20statistics%20New%20York%202001"
        },
        {
            "id": "15",
            "entry": "[15] Teofilo F Gonzalez. Clustering to minimize the maximum intercluster distance. Theoretical Computer Science, 38:293\u2013306, 1985.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gonzalez%2C%20Teofilo%20F.%20Clustering%20to%20minimize%20the%20maximum%20intercluster%20distance%201985",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gonzalez%2C%20Teofilo%20F.%20Clustering%20to%20minimize%20the%20maximum%20intercluster%20distance%201985"
        },
        {
            "id": "16",
            "entry": "[16] Richard E Higgs, Kerry G Bemis, Ian A Watson, and James H Wikel. Experimental designs for selecting molecules from large chemical databases. Journal of chemical information and computer sciences, 37(5):861\u2013870, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgs%2C%20Richard%20E.%20Bemis%2C%20Kerry%20G.%20Watson%2C%20Ian%20A.%20Wikel%2C%20James%20H.%20Experimental%20designs%20for%20selecting%20molecules%20from%20large%20chemical%20databases%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgs%2C%20Richard%20E.%20Bemis%2C%20Kerry%20G.%20Watson%2C%20Ian%20A.%20Wikel%2C%20James%20H.%20Experimental%20designs%20for%20selecting%20molecules%20from%20large%20chemical%20databases%201997"
        },
        {
            "id": "17",
            "entry": "[17] Wenhao Jiang and Fu-lai Chung. Transfer spectral clustering. In Proceedings of the Annual Conference on Knowledge Discovery and Data Mining (KDD), pages 789\u2013803, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jiang%2C%20Wenhao%20Chung%2C%20Fu-lai%20Transfer%20spectral%20clustering%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jiang%2C%20Wenhao%20Chung%2C%20Fu-lai%20Transfer%20spectral%20clustering%202012"
        },
        {
            "id": "18",
            "entry": "[18] Tapas Kanungo, David M Mount, Nathan S Netanyahu, Christine D Piatko, Ruth Silverman, and Angela Y Wu. An efficient k-means clustering algorithm: Analysis and implementation. transactions on pattern analysis and machine intelligence, 24(7):881\u2013892, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kanungo%2C%20Tapas%20Mount%2C%20David%20M.%20Netanyahu%2C%20Nathan%20S.%20Piatko%2C%20Christine%20D.%20An%20efficient%20k-means%20clustering%20algorithm%3A%20Analysis%20and%20implementation.%20transactions%20on%20pattern%20analysis%20and%20machine%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kanungo%2C%20Tapas%20Mount%2C%20David%20M.%20Netanyahu%2C%20Nathan%20S.%20Piatko%2C%20Christine%20D.%20An%20efficient%20k-means%20clustering%20algorithm%3A%20Analysis%20and%20implementation.%20transactions%20on%20pattern%20analysis%20and%20machine%202002"
        },
        {
            "id": "19",
            "entry": "[19] Leonard Kaufman and Peter J Rousseeuw. Finding groups in data: an introduction to cluster analysis, volume 344. John Wiley & Sons, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kaufman%2C%20Leonard%20Rousseeuw%2C%20Peter%20J.%20Finding%20groups%20in%20data%3A%20an%20introduction%20to%20cluster%20analysis%2C%20volume%20344%202009"
        },
        {
            "id": "20",
            "entry": "[20] Ari Kobren, Nicholas Monath, Akshay Krishnamurthy, and Andrew McCallum. An online hierarchical algorithm for extreme clustering. In Proceedings of the Annual Conference on Knowledge Discovery and Data Mining (KDD), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kobren%2C%20Ari%20Monath%2C%20Nicholas%20Krishnamurthy%2C%20Akshay%20McCallum%2C%20Andrew%20An%20online%20hierarchical%20algorithm%20for%20extreme%20clustering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kobren%2C%20Ari%20Monath%2C%20Nicholas%20Krishnamurthy%2C%20Akshay%20McCallum%2C%20Andrew%20An%20online%20hierarchical%20algorithm%20for%20extreme%20clustering%202017"
        },
        {
            "id": "21",
            "entry": "[21] Vladimir Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Transactions on Information Theory, 47(5):1902\u20131914, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koltchinskii%2C%20Vladimir%20Rademacher%20penalties%20and%20structural%20risk%20minimization%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koltchinskii%2C%20Vladimir%20Rademacher%20penalties%20and%20structural%20risk%20minimization%202001"
        },
        {
            "id": "22",
            "entry": "[22] Stuart Lloyd. Least squares quantization in pcm. transactions on information theory, 28(2):129\u2013 137, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lloyd%2C%20Stuart%20Least%20squares%20quantization%20in%20pcm%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lloyd%2C%20Stuart%20Least%20squares%20quantization%20in%20pcm%201982"
        },
        {
            "id": "23",
            "entry": "[23] James MacQueen et al. Some methods for classification and analysis of multivariate observations. In symposium on mathematical statistics and probability, volume 1, pages 281\u2013297. Oakland, CA, USA, 1967.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=MacQueen%2C%20James%20Some%20methods%20for%20classification%20and%20analysis%20of%20multivariate%20observations%201967",
            "oa_query": "https://api.scholarcy.com/oa_version?query=MacQueen%2C%20James%20Some%20methods%20for%20classification%20and%20analysis%20of%20multivariate%20observations%201967"
        },
        {
            "id": "24",
            "entry": "[24] Joel Max. Quantizing for minimum distortion. IRE Transactions on Information Theory, 6(1):7\u201312, 1960.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Max%2C%20Joel%20Quantizing%20for%20minimum%20distortion%201960",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Max%2C%20Joel%20Quantizing%20for%20minimum%20distortion%201960"
        },
        {
            "id": "25",
            "entry": "[25] Rafail Ostrovsky, Yuval Rabani, Leonard J Schulman, and Chaitanya Swamy. The effectiveness of lloyd-type methods for the k-means problem. Journal of the ACM (JACM), 59(6):28, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ostrovsky%2C%20Rafail%20Rabani%2C%20Yuval%20Schulman%2C%20Leonard%20J.%20Swamy%2C%20Chaitanya%20The%20effectiveness%20of%20lloyd-type%20methods%20for%20the%20k-means%20problem%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ostrovsky%2C%20Rafail%20Rabani%2C%20Yuval%20Schulman%2C%20Leonard%20J.%20Swamy%2C%20Chaitanya%20The%20effectiveness%20of%20lloyd-type%20methods%20for%20the%20k-means%20problem%202012"
        },
        {
            "id": "26",
            "entry": "[26] Dan Pelleg and Andrew Moore. Accelerating exact k-means algorithms with geometric reasoning. In Proceedings of the Annual Conference on Knowledge Discovery and Data Mining (KDD), pages 277\u2013281, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pelleg%2C%20Dan%20Moore%2C%20Andrew%20Accelerating%20exact%20k-means%20algorithms%20with%20geometric%20reasoning%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pelleg%2C%20Dan%20Moore%2C%20Andrew%20Accelerating%20exact%20k-means%20algorithms%20with%20geometric%20reasoning%201999"
        },
        {
            "id": "27",
            "entry": "[27] Jos\u00e9 M Pena, Jose Antonio Lozano, and Pedro Larranaga. An empirical comparison of four initialization methods for the k-means algorithm. Pattern recognition letters, 20(10):1027\u20131040, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pena%2C%20Jos%C3%A9%20M.%20Lozano%2C%20Jose%20Antonio%20Larranaga%2C%20Pedro%20An%20empirical%20comparison%20of%20four%20initialization%20methods%20for%20the%20k-means%20algorithm%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pena%2C%20Jos%C3%A9%20M.%20Lozano%2C%20Jose%20Antonio%20Larranaga%2C%20Pedro%20An%20empirical%20comparison%20of%20four%20initialization%20methods%20for%20the%20k-means%20algorithm%201999"
        },
        {
            "id": "28",
            "entry": "[28] Kim D Pruitt, Tatiana Tatusova, Garth R Brown, and Donna R Maglott. Ncbi reference sequences (refseq): current status, new features and genome annotation policy. Nucleic acids research, 40(D1):D130\u2013D135, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pruitt%2C%20Kim%20D.%20Tatusova%2C%20Tatiana%20Brown%2C%20Garth%20R.%20Maglott%2C%20Donna%20R.%20Ncbi%20reference%20sequences%20%28refseq%29%3A%20current%20status%2C%20new%20features%20and%20genome%20annotation%20policy%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pruitt%2C%20Kim%20D.%20Tatusova%2C%20Tatiana%20Brown%2C%20Garth%20R.%20Maglott%2C%20Donna%20R.%20Ncbi%20reference%20sequences%20%28refseq%29%3A%20current%20status%2C%20new%20features%20and%20genome%20annotation%20policy%202011"
        },
        {
            "id": "29",
            "entry": "[29] Rajat Raina, Alexis Battle, Honglak Lee, Benjamin Packer, and Andrew Y Ng. Self-taught learning: transfer learning from unlabeled data. In Proceedings of the International Conference on Machine Learning (ICML), pages 759\u2013766, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raina%2C%20Rajat%20Battle%2C%20Alexis%20Lee%2C%20Honglak%20Packer%2C%20Benjamin%20and%20Andrew%20Y%20Ng.%20Self-taught%20learning%3A%20transfer%20learning%20from%20unlabeled%20data%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raina%2C%20Rajat%20Battle%2C%20Alexis%20Lee%2C%20Honglak%20Packer%2C%20Benjamin%20and%20Andrew%20Y%20Ng.%20Self-taught%20learning%3A%20transfer%20learning%20from%20unlabeled%20data%202007"
        },
        {
            "id": "30",
            "entry": "[30] Qiang Yang, Yuqiang Chen, Gui-Rong Xue, Wenyuan Dai, and Yong Yu. Heterogeneous transfer learning for image clustering via the social web. In Proceedings of the Conference on Natural Language Processing, pages 1\u20139, 2009. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Qiang%20Chen%2C%20Yuqiang%20Xue%2C%20Gui-Rong%20Dai%2C%20Wenyuan%20Heterogeneous%20transfer%20learning%20for%20image%20clustering%20via%20the%20social%20web%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Qiang%20Chen%2C%20Yuqiang%20Xue%2C%20Gui-Rong%20Dai%2C%20Wenyuan%20Heterogeneous%20transfer%20learning%20for%20image%20clustering%20via%20the%20social%20web%202009"
        }
    ]
}
