{
    "filename": "8258-regret-bounds-for-online-portfolio-selection-with-a-cardinality-constraint.pdf",
    "metadata": {
        "title": "Regret Bounds for Online Portfolio Selection with a Cardinality Constraint",
        "author": "Shinji Ito, Daisuke Hatano, Sumita Hanna, Akihiro Yabe, Takuro Fukunaga, Naonori Kakimura, Ken-Ichi Kawarabayashi",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8258-regret-bounds-for-online-portfolio-selection-with-a-cardinality-constraint.pdf"
        },
        "abstract": "Online portfolio selection is a sequential decision-making problem in which a learner repetitively selects a portfolio over a set of assets, aiming to maximize long-term return. In this paper, we study the problem with the cardinality constraint that the number of assets in a portfolio is restricted to be at most k, and consider two scenarios: (i) in the full-feedback setting, the learner can observe price relatives (rates of return to cost) for all assets, and (ii) in the bandit-feedback setting, the learner can observe price relatives only for invested assets. We propose efficient algorithms for these scenarios, which achieve sublinear regrets. We also provide regret (statistical) lower bounds for both scenarios which nearly match the upper bounds when k is a constant. In addition, we give a computational lower bound, which implies that no algorithm maintains both computational efficiency, as well as a small regret upper bound."
    },
    "keywords": [
        {
            "term": "multi-armed bandit problem",
            "url": "https://en.wikipedia.org/wiki/multi-armed_bandit_problem"
        },
        {
            "term": "multi armed bandit",
            "url": "https://en.wikipedia.org/wiki/multi_armed_bandit"
        },
        {
            "term": "online convex optimization",
            "url": "https://en.wikipedia.org/wiki/online_convex_optimization"
        },
        {
            "term": "bandit problem",
            "url": "https://en.wikipedia.org/wiki/bandit_problem"
        }
    ],
    "highlights": [
        "Online portfolio selection [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>] is a fundamental problem in financial engineering, in which a learner sequentially selects a portfolio over a set of assets, aiming to maximize cumulative wealth",
        "To prove the regret lower bounds, we use three different techniques: for the statistical lower bound for the full-feedback setting, we consider a completely random market and evaluate how well the \u201cbest\u201d strategy worked after observing the market behavior, in a similar way to that for the lower bound for MWU [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]; for the bandit-feedback setting, we construct a \u201cgood\u201d combination S\u2217 \u2208 S of assets so that it is hard to distinguish it from the others, and bound the number of choosing this \u201cgood\u201d combination via a technique similar to that used in the proof of the regret lower bound for multi-armed bandit problem [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>]; to prove the computational lower bound, we reduce the 3-dimensional matching problem (3DM), one of Karp\u2019s 21 NP-complete problems [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], to our problem.\n2 Related work",
        "Online portfolio selection has been studied in many research areas, including finance, statistics, machine learning, and optimization [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>, <a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] since Cover [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] formulated the problem setting and proposed a universal portfolio algorithm that achieves regret of O(d log T ) with exponential computation cost",
        "We propose an algorithm for the full-feedback setting, created by combining the multiplicative weight update method (MWU) [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] and the follow-the-approximate-leader method (FTAL) [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]",
        "For the full-feedback setting of the online portfolio selection problem with S ="
    ],
    "key_statements": [
        "Online portfolio selection [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>] is a fundamental problem in financial engineering, in which a learner sequentially selects a portfolio over a set of assets, aiming to maximize cumulative wealth",
        "We show regret lower bounds for both the full-feedback setting and the bandit-feedback setting where S = Sk, which give insight into the tightness of regret upper bounds achieved with our algorithms",
        "To prove the regret lower bounds, we use three different techniques: for the statistical lower bound for the full-feedback setting, we consider a completely random market and evaluate how well the \u201cbest\u201d strategy worked after observing the market behavior, in a similar way to that for the lower bound for MWU [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]; for the bandit-feedback setting, we construct a \u201cgood\u201d combination S\u2217 \u2208 S of assets so that it is hard to distinguish it from the others, and bound the number of choosing this \u201cgood\u201d combination via a technique similar to that used in the proof of the regret lower bound for multi-armed bandit problem [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>]; to prove the computational lower bound, we reduce the 3-dimensional matching problem (3DM), one of Karp\u2019s 21 NP-complete problems [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], to our problem.\n2 Related work",
        "Online portfolio selection has been studied in many research areas, including finance, statistics, machine learning, and optimization [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>, <a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] since Cover [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] formulated the problem setting and proposed a universal portfolio algorithm that achieves regret of O(d log T ) with exponential computation cost",
        "We propose an algorithm for the full-feedback setting, created by combining the multiplicative weight update method (MWU) [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] and the follow-the-approximate-leader method (FTAL) [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]",
        "For the full-feedback setting of the online portfolio selection problem with S ="
    ],
    "summary": [
        "Online portfolio selection [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>] is a fundamental problem in financial engineering, in which a learner sequentially selects a portfolio over a set of assets, aiming to maximize cumulative wealth.",
        "Algorithm 1 for the full-feedback setting, achieving regret of O( T log |S|).",
        "Algorithm 2 for the bandit-feedback setting, achieving regret of O( T k|S| log T ), where k denotes the largest cardinality among elements in S, i.e., k = maxS\u2208S |S|.",
        "With the st\u221aandard online portfolio selection problem, and there exist algorithms achieving RT = O( T log d)\u221a.",
        "Online portfolio selection has been studied in many research areas, including finance, statistics, machine learning, and optimization [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>, <a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] since Cover [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] formulated the problem setting and proposed a universal portfolio algorithm that achieves regret of O(d log T ) with exponential computation cost.",
        "Their problem setting differs from ours in that they did not put constraints about sparsity but, rather, defined regret containing regularizer inducing group sparsity, and that they supposed that a learner can observe price relatives for all assets after determining portfolios.",
        "For the special case of the single asset selection setting, i.e., if S = S1 = {{i} | i \u2208 [d]}, Algorithm 1 runs in O(d)-time per round since each x{t i} can be updated in constant time.",
        "We present lower bounds on regrets achievable by algorithms for the online portfolio selection problem.",
        "T-time algorithm A for the full-feedback online portfolio selection problem with S = Sk+1 that achieves regret RT \u2264 p2(d)T 1\u2212\u03b4 with a probability of at least 2/3.",
        "Let d \u2265 17k, and consider the online portfolio selection problem with d assets and available combinations S = Sk. There is a probability distribution of input sequences {rt}tT=1 such that the regret of any algorithm for the full-feedback setting is bounded as E[RT ] = \u03a9",
        "We consider the bandit-feedback setting of the online portfolio selection problem with S = Sk. We show that every algorithm for this setting suffers from regret of \u03a9",
        "Let d \u2265 k \u2212 1, and consider the online portfolio selection problem with d assets and available combinations S = Sk. There is a probability distribution of input sequences {rt}Tt=1 such that the regret of any algorithm for the bandit-feedback setting is bounded as",
        "Exp3 cont Set a parameter B \u2208 N, and consider an MAB problem instance with d(B + 1) arms in which the rewards for the d(B + 1) arms in the t-th round are given by)1\u2264i\u2264d,0\u2264b\u2264B."
    ],
    "headline": "We study the problem with the cardinality constraint that the number of assets in a portfolio is restricted to be at most k, and consider two scenarios:  in the full-feedback setting, the learner can observe price relatives  for all assets, and  in the bandit-feedback setting, the learner can observe price relatives only for invested assets",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] A. Agarwal, E. Hazan, S. Kale, and R. E. Schapire. Algorithms for portfolio management based on the Newton method. Proceedings of the 23rd International Conference on Machine Learning - ICML \u201906, pages 9\u201316, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20A.%20Hazan%2C%20E.%20Kale%2C%20S.%20Schapire%2C%20R.E.%20Algorithms%20for%20portfolio%20management%20based%20on%20the%20Newton%20method%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20A.%20Hazan%2C%20E.%20Kale%2C%20S.%20Schapire%2C%20R.E.%20Algorithms%20for%20portfolio%20management%20based%20on%20the%20Newton%20method%202006"
        },
        {
            "id": "2",
            "entry": "[2] N. Alon and J. H. Spencer. The Probabilistic Method. John Wiley & Sons, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alon%2C%20N.%20Spencer%2C%20J.H.%20The%20Probabilistic%20Method%202004"
        },
        {
            "id": "3",
            "entry": "[3] S. Arora, E. Hazan, and S. Kale. The multiplicative weights update method: a meta-algorithm and applications. Theory of Computing, 8(1):121\u2013164, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20S.%20Hazan%2C%20E.%20Kale%2C%20S.%20The%20multiplicative%20weights%20update%20method%3A%20a%20meta-algorithm%20and%20applications%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20S.%20Hazan%2C%20E.%20Kale%2C%20S.%20The%20multiplicative%20weights%20update%20method%3A%20a%20meta-algorithm%20and%20applications%202012"
        },
        {
            "id": "4",
            "entry": "[4] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235\u2013256, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Auer%2C%20P.%20Cesa-Bianchi%2C%20N.%20Fischer%2C%20P.%20Finite-time%20analysis%20of%20the%20multiarmed%20bandit%20problem%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Auer%2C%20P.%20Cesa-Bianchi%2C%20N.%20Fischer%2C%20P.%20Finite-time%20analysis%20of%20the%20multiarmed%20bandit%20problem%202002"
        },
        {
            "id": "5",
            "entry": "[5] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit problem. SIAM Journal on Computing, 32(1):48\u201377, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Auer%2C%20P.%20Cesa-Bianchi%2C%20N.%20Freund%2C%20Y.%20Schapire%2C%20R.E.%20The%20nonstochastic%20multiarmed%20bandit%20problem%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Auer%2C%20P.%20Cesa-Bianchi%2C%20N.%20Freund%2C%20Y.%20Schapire%2C%20R.E.%20The%20nonstochastic%20multiarmed%20bandit%20problem%202002"
        },
        {
            "id": "6",
            "entry": "[6] S. Bubeck, N. Cesa-Bianchi, et al. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends R in Machine Learning, 5(1):1\u2013122, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bubeck%2C%20S.%20Cesa-Bianchi%2C%20N.%20Regret%20analysis%20of%20stochastic%20and%20nonstochastic%20multi-armed%20bandit%20problems%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bubeck%2C%20S.%20Cesa-Bianchi%2C%20N.%20Regret%20analysis%20of%20stochastic%20and%20nonstochastic%20multi-armed%20bandit%20problems%202012"
        },
        {
            "id": "7",
            "entry": "[7] N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. Journal of Computer and System Sciences, 78(5):1404\u20131422, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cesa-Bianchi%2C%20N.%20Lugosi%2C%20G.%20Combinatorial%20bandits%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cesa-Bianchi%2C%20N.%20Lugosi%2C%20G.%20Combinatorial%20bandits%202012"
        },
        {
            "id": "8",
            "entry": "[8] W. Chen, Y. Wang, and Y. Yuan. Combinatorial multi-armed bandit: General framework and applications. In International Conference on Machine Learning, pages 151\u2013159, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20W.%20Wang%2C%20Y.%20Yuan%2C%20Y.%20Combinatorial%20multi-armed%20bandit%3A%20General%20framework%20and%20applications%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20W.%20Wang%2C%20Y.%20Yuan%2C%20Y.%20Combinatorial%20multi-armed%20bandit%3A%20General%20framework%20and%20applications%202013"
        },
        {
            "id": "9",
            "entry": "[9] R. Combes, M. S. T. M. Shahi, A. Proutiere, et al. Combinatorial bandits revisited. In Advances in Neural Information Processing Systems, pages 2116\u20132124, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Combes%2C%20R.%20Shahi%2C%20M.S.T.M.%20Proutiere%2C%20A.%20Combinatorial%20bandits%20revisited%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Combes%2C%20R.%20Shahi%2C%20M.S.T.M.%20Proutiere%2C%20A.%20Combinatorial%20bandits%20revisited%202015"
        },
        {
            "id": "10",
            "entry": "[10] T. M. Cover. Universal portfolios. Mathematical Finance, 1(1):1\u201329, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20T.M.%20Universal%20portfolios%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cover%2C%20T.M.%20Universal%20portfolios%201991"
        },
        {
            "id": "11",
            "entry": "[11] T. M. Cover and J. A. Thomas. Elements of Information Theory. John Wiley & Sons, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20T.M.%20Thomas%2C%20J.A.%20Elements%20of%20Information%20Theory%202012"
        },
        {
            "id": "12",
            "entry": "[12] P. Das, N. Johnson, and A. Banerjee. Online portfolio selection with group sparsity. In TwentyEighth AAAI Conference on Artificial Intelligence, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Das%2C%20P.%20Johnson%2C%20N.%20Banerjee%2C%20A.%20Online%20portfolio%20selection%20with%20group%20sparsity%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Das%2C%20P.%20Johnson%2C%20N.%20Banerjee%2C%20A.%20Online%20portfolio%20selection%20with%20group%20sparsity%202014"
        },
        {
            "id": "13",
            "entry": "[13] P. M. Fenwick. A new data structure for cumulative frequency tables. Software: Practice and Experience, 24(3):327\u2013336, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fenwick%2C%20P.M.%20A%20new%20data%20structure%20for%20cumulative%20frequency%20tables%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fenwick%2C%20P.M.%20A%20new%20data%20structure%20for%20cumulative%20frequency%20tables%201994"
        },
        {
            "id": "14",
            "entry": "[14] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119\u2013139, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freund%2C%20Y.%20Schapire%2C%20R.E.%20A%20decision-theoretic%20generalization%20of%20on-line%20learning%20and%20an%20application%20to%20boosting%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freund%2C%20Y.%20Schapire%2C%20R.E.%20A%20decision-theoretic%20generalization%20of%20on-line%20learning%20and%20an%20application%20to%20boosting%201997"
        },
        {
            "id": "15",
            "entry": "[15] J. E. Gentle. Computational Statistics. Springer Science & Business Media, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=J%20E%20Gentle%20Computational%20Statistics%20Springer%20Science%20%20Business%20Media%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=J%20E%20Gentle%20Computational%20Statistics%20Springer%20Science%20%20Business%20Media%202009"
        },
        {
            "id": "16",
            "entry": "[16] N. H. Hakansson and W. T. Ziemba. Capital growth theory. Handbooks in Operations Research and Management Science, 9:65\u201386, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hakansson%2C%20N.H.%20Ziemba%2C%20W.T.%20Capital%20growth%20theory%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hakansson%2C%20N.H.%20Ziemba%2C%20W.T.%20Capital%20growth%20theory%201995"
        },
        {
            "id": "17",
            "entry": "[17] E. Hazan. Introduction to online convex optimization. Foundations and Trends R in Optimization, 2(3-4):157\u2013325, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20E.%20Introduction%20to%20online%20convex%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20E.%20Introduction%20to%20online%20convex%20optimization%202016"
        },
        {
            "id": "18",
            "entry": "[18] E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169\u2013192, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20E.%20Agarwal%2C%20A.%20Kale%2C%20S.%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20E.%20Agarwal%2C%20A.%20Kale%2C%20S.%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007"
        },
        {
            "id": "19",
            "entry": "[19] A. Kalai and S. Vempala. Efficient algorithms for universal portfolios. Journal of Machine Learning Research, 3(Nov):423\u2013440, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kalai%2C%20A.%20Vempala%2C%20S.%20Efficient%20algorithms%20for%20universal%20portfolios%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kalai%2C%20A.%20Vempala%2C%20S.%20Efficient%20algorithms%20for%20universal%20portfolios%202002"
        },
        {
            "id": "21",
            "entry": "[21] J. Kelly. A new interpretation of information rate. Bell Sys. Tech. Journal, 35:917\u2013926, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kelly%2C%20J.%20A%20new%20interpretation%20of%20information%20rate%201956",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kelly%2C%20J.%20A%20new%20interpretation%20of%20information%20rate%201956"
        },
        {
            "id": "22",
            "entry": "[22] B. Li and S. C. Hoi. Online portfolio selection: A survey. ACM Computing Surveys (CSUR), 46(3):35, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20B.%20Hoi%2C%20S.C.%20Online%20portfolio%20selection%3A%20A%20survey%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20B.%20Hoi%2C%20S.C.%20Online%20portfolio%20selection%3A%20A%20survey%202014"
        },
        {
            "id": "23",
            "entry": "[23] B. Li and S. C. H. Hoi. On-Line Portfolio Selection with Moving Average Reversion. Proceedings of the 29th International Conference on Machine Learning (ICML-12), pages 273\u2013280, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20B.%20Hoi%2C%20S.C.H.%20On-Line%20Portfolio%20Selection%20with%20Moving%20Average%20Reversion%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20B.%20Hoi%2C%20S.C.H.%20On-Line%20Portfolio%20Selection%20with%20Moving%20Average%20Reversion%202012"
        },
        {
            "id": "24",
            "entry": "[24] M. S. Lobo, L. Vandenberghe, S. Boyd, and H. Lebret. Applications of second-order cone programming. Linear Algebra and Its Applications, 284(1-3):193\u2013228, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lobo%2C%20M.S.%20Vandenberghe%2C%20L.%20Boyd%2C%20S.%20Lebret%2C%20H.%20Applications%20of%20second-order%20cone%20programming%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lobo%2C%20M.S.%20Vandenberghe%2C%20L.%20Boyd%2C%20S.%20Lebret%2C%20H.%20Applications%20of%20second-order%20cone%20programming%201998"
        },
        {
            "id": "25",
            "entry": "[25] J. Matousek and J. Vondrak. The probabilistic method. Lecture Notes, Department of Applied Mathematics, Charles University, Prague, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matousek%2C%20J.%20Vondrak%2C%20J.%20The%20probabilistic%20method%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matousek%2C%20J.%20Vondrak%2C%20J.%20The%20probabilistic%20method%202001"
        },
        {
            "id": "26",
            "entry": "[26] E. Ordentlich and T. M. Cover. The cost of achieving the best portfolio in hindsight. Mathematics of Operations Research, 23(4):960\u2013982, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ordentlich%2C%20E.%20Cover%2C%20T.M.%20The%20cost%20of%20achieving%20the%20best%20portfolio%20in%20hindsight%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ordentlich%2C%20E.%20Cover%2C%20T.M.%20The%20cost%20of%20achieving%20the%20best%20portfolio%20in%20hindsight%201998"
        },
        {
            "id": "27",
            "entry": "[27] S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends R in Machine Learning, 4(2):107\u2013194, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shalev-Shwartz%2C%20S.%20Online%20learning%20and%20online%20convex%20optimization%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shalev-Shwartz%2C%20S.%20Online%20learning%20and%20online%20convex%20optimization%202012"
        },
        {
            "id": "28",
            "entry": "[28] Y. Ye, L. Lei, and C. Ju. Hones: A fast and tuning-free homotopy method for online newton step. In Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics (AISTATS-18), pages 2008\u20132017, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ye%2C%20Y.%20Lei%2C%20L.%20Ju%2C%20C.%20Hones%3A%20A%20fast%20and%20tuning-free%20homotopy%20method%20for%20online%20newton%20step%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ye%2C%20Y.%20Lei%2C%20L.%20Ju%2C%20C.%20Hones%3A%20A%20fast%20and%20tuning-free%20homotopy%20method%20for%20online%20newton%20step%202008"
        },
        {
            "id": "29",
            "entry": "[29] M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th International Conference on Machine Learning (ICML-03), pages 928\u2013936, 2003. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zinkevich%2C%20M.%20Online%20convex%20programming%20and%20generalized%20infinitesimal%20gradient%20ascent%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zinkevich%2C%20M.%20Online%20convex%20programming%20and%20generalized%20infinitesimal%20gradient%20ascent%202003"
        }
    ]
}
