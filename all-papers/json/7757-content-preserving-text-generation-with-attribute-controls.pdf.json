{
    "filename": "7757-content-preserving-text-generation-with-attribute-controls.pdf",
    "metadata": {
        "title": "Content preserving text generation with attribute controls",
        "author": "Lajanugen Logeswaran, Honglak Lee, Samy Bengio",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7757-content-preserving-text-generation-with-attribute-controls.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In this work, we address the problem of modifying textual attributes of sentences. Given an input sentence and a set of attribute labels, we attempt to generate sentences that are compatible with the conditioning information. To ensure that the model generates content compatible sentences, we introduce a reconstruction loss which interpolates between auto-encoding and back-translation loss components. We propose an adversarial loss to enforce generated samples to be attribute compatible and realistic. Through quantitative, qualitative and human evaluations we demonstrate that our model is capable of generating fluent sentences that better reflect the conditioning information compared to prior methods. We further demonstrate that the model is capable of simultaneously controlling multiple attributes."
    },
    "keywords": [
        {
            "term": "word vector",
            "url": "https://en.wikipedia.org/wiki/word_vector"
        },
        {
            "term": "neural machine translation",
            "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
        },
        {
            "term": "time step",
            "url": "https://en.wikipedia.org/wiki/time_step"
        },
        {
            "term": "text generation",
            "url": "https://en.wikipedia.org/wiki/text_generation"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        }
    ],
    "highlights": [
        "Generative modeling of images and text has seen increasing progress over the last few years",
        "In this work we consider a generative model for sentences that is capable of expressing a given sentence in a form that is compatible with a given set of conditioning attributes",
        "Given a set of sentences annotated with multiple attributes, our goal is to be able to plug this data into the learning algorithm and obtain a model capable of tweaking these properties of a sentence",
        "In this work we considered the problem of modifying textual attributes in sentences",
        "We proposed a model that explicitly encourages content preservation, attribute compatibility and generating realistic sequences through carefully designed reconstruction and adversarial losses",
        "We demonstrate that our model effectively reflects the conditioning information through various experiments and metrics"
    ],
    "key_statements": [
        "Generative modeling of images and text has seen increasing progress over the last few years",
        "In this work we consider a generative model for sentences that is capable of expressing a given sentence in a form that is compatible with a given set of conditioning attributes",
        "Hu et al [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] propose a generative model of sentences which can be conditioned on a sentence and attribute labels",
        "Our proposed adversarial loss involves learning a single discriminator which determines whether a sentence is both realistic and is compatible with a given set of attribute values",
        "We demonstrate that the model can handle multiple attributes simultaneously, while prior work has mostly focused on one or two attributes, which limits their practical applicability",
        "Soft-sampling and hard-sampling A challenging aspect of text generation models is dealing with the discrete nature of language, which makes it difficult to generate a sequence and obtain a learning signal based on it",
        "Given a set of sentences annotated with multiple attributes, our goal is to be able to plug this data into the learning algorithm and obtain a model capable of tweaking these properties of a sentence",
        "In this work we considered the problem of modifying textual attributes in sentences",
        "We proposed a model that explicitly encourages content preservation, attribute compatibility and generating realistic sequences through carefully designed reconstruction and adversarial losses",
        "We demonstrate that our model effectively reflects the conditioning information through various experiments and metrics"
    ],
    "summary": [
        "Generative modeling of images and text has seen increasing progress over the last few years.",
        "In this work we consider a generative model for sentences that is capable of expressing a given sentence in a form that is compatible with a given set of conditioning attributes.",
        "In addition to evaluating attribute compatibility, we consider new metrics for content preservation and generation fluency, and evaluate models using these metrics.",
        "Evaluating the model on parallel data assesses it in terms of all properties of interest: generating content and attribute compatible, realistic sentences.",
        "Hu et al [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] propose a generative model of sentences which can be conditioned on a sentence and attribute labels.",
        "Our proposed adversarial loss involves learning a single discriminator which determines whether a sentence is both realistic and is compatible with a given set of attribute values.",
        "Assuming a well-trained model, Let the y \u201e pGp|zx, l1q be sampled sentence y a generated sentence conditioned on will preserve the content of x.",
        "We consider an adversarial loss which encourages generating realistic and attribute compatible sentences.",
        "The autoencoding loss Lae is used to measure how well the model generates content compatible sentences.",
        "Attribute accuracy To quantitatively evaluate how well the generated samples match the conditioning labels we adopt a protocol similar to [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>].",
        "We generate samples from the model and measure label accuracy using a pre-trained sentiment classifier.",
        "Fluency We use a pre-trained language model to measure the fluency of generated sentences.",
        "The interpolation loss can be thought of as data augmentation in the feature space, taking into account the noisy nature of parallel text produced by the model, and encourages content preservation when modifying attribute properties.",
        "Qualitative evaluation Table 4 shows samples generated from the models for given conditioning sentence and sentiment label.",
        "Human judges on MTurk were asked to rate the three aspects of generated sentences we are interested in - attribute compatibility, content preservation and fluency.",
        "Attribute compatibility is assessed by asking judges to label generated sentences and comparing the opinions with the actual conditioning sentiment label.",
        "The attribute compatibility of the proposed model Lint Ladv drops more gracefully compared to the other settings as the content preservation improves.",
        "Given a set of sentences annotated with multiple attributes, our goal is to be able to plug this data into the learning algorithm and obtain a model capable of tweaking these properties of a sentence.",
        "We proposed a model that explicitly encourages content preservation, attribute compatibility and generating realistic sequences through carefully designed reconstruction and adversarial losses.",
        "It would be interesting future work to consider attributes with continuous values in this framework and a much larger set of semantic and syntactic attributes"
    ],
    "headline": "We address the problem of modifying textual attributes of sentences",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "2",
            "entry": "[2] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "3",
            "entry": "[3] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks. arXiv preprint arXiv:1601.06759, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1601.06759"
        },
        {
            "id": "4",
            "entry": "[4] Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. Attribute2image: Conditional image generation from visual attributes. In European Conference on Computer Vision, pages 776\u2013791.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yan%2C%20Xinchen%20Yang%2C%20Jimei%20Sohn%2C%20Kihyuk%20Lee%2C%20Honglak%20Attribute2image%3A%20Conditional%20image%20generation%20from%20visual%20attributes",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yan%2C%20Xinchen%20Yang%2C%20Jimei%20Sohn%2C%20Kihyuk%20Lee%2C%20Honglak%20Attribute2image%3A%20Conditional%20image%20generation%20from%20visual%20attributes"
        },
        {
            "id": "5",
            "entry": "[5] Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. Generative adversarial text to image synthesis. arXiv preprint arXiv:1605.05396, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.05396"
        },
        {
            "id": "6",
            "entry": "[6] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. A neural algorithm of artistic style. arXiv preprint arXiv:1508.06576, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1508.06576"
        },
        {
            "id": "7",
            "entry": "[7] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint arXiv:1611.07004, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.07004"
        },
        {
            "id": "8",
            "entry": "[8] Jiwei Li, Michel Galley, Chris Brockett, Georgios P Spithourakis, Jianfeng Gao, and Bill Dolan. A persona-based neural conversation model. arXiv preprint arXiv:1603.06155, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.06155"
        },
        {
            "id": "9",
            "entry": "[9] Wei Xu, Alan Ritter, William B Dolan, Ralph Grishman, and Colin Cherry. Paraphrasing for style. In 24th International Conference on Computational Linguistics, COLING 2012, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Wei%20Ritter%2C%20Alan%20Dolan%2C%20William%20B.%20Grishman%2C%20Ralph%20Paraphrasing%20for%20style%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Wei%20Ritter%2C%20Alan%20Dolan%2C%20William%20B.%20Grishman%2C%20Ralph%20Paraphrasing%20for%20style%202012"
        },
        {
            "id": "10",
            "entry": "[10] Rico Sennrich, Barry Haddow, and Alexandra Birch. Controlling politeness in neural machine translation via side constraints. In Proceedings of NAACL-HLT, pages 35\u201340, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sennrich%2C%20Rico%20Haddow%2C%20Barry%20Birch%2C%20Alexandra%20Controlling%20politeness%20in%20neural%20machine%20translation%20via%20side%20constraints%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sennrich%2C%20Rico%20Haddow%2C%20Barry%20Birch%2C%20Alexandra%20Controlling%20politeness%20in%20neural%20machine%20translation%20via%20side%20constraints%202016"
        },
        {
            "id": "11",
            "entry": "[11] Rakshith Shetty, Bernt Schiele, and Mario Fritz. Author attribute anonymity by adversarial training of neural machine translation. arXiv preprint arXiv:1711.01921, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.01921"
        },
        {
            "id": "12",
            "entry": "[12] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014"
        },
        {
            "id": "13",
            "entry": "[13] Yuta Kikuchi, Graham Neubig, Ryohei Sasano, Hiroya Takamura, and Manabu Okumura. Controlling output length in neural encoder-decoders. arXiv preprint arXiv:1609.09552, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.09552"
        },
        {
            "id": "14",
            "entry": "[14] Hayahide Yamagishi, Shin Kanouchi, Takayuki Sato, and Mamoru Komachi. Controlling the voice of a sentence in japanese-to-english neural machine translation. In Proceedings of the 3rd Workshop on Asian Translation (WAT2016), pages 203\u2013210, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yamagishi%2C%20Hayahide%20Kanouchi%2C%20Shin%20Sato%2C%20Takayuki%20Komachi%2C%20Mamoru%20Controlling%20the%20voice%20of%20a%20sentence%20in%20japanese-to-english%20neural%20machine%20translation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yamagishi%2C%20Hayahide%20Kanouchi%2C%20Shin%20Sato%2C%20Takayuki%20Komachi%2C%20Mamoru%20Controlling%20the%20voice%20of%20a%20sentence%20in%20japanese-to-english%20neural%20machine%20translation%202016"
        },
        {
            "id": "15",
            "entry": "[15] Ryan Kiros, Richard Zemel, and Ruslan R Salakhutdinov. A multiplicative model for learning distributed text-based attribute representations. In Advances in neural information processing systems, pages 2348\u20132356, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kiros%2C%20Ryan%20Zemel%2C%20Richard%20Salakhutdinov%2C%20Ruslan%20R.%20A%20multiplicative%20model%20for%20learning%20distributed%20text-based%20attribute%20representations%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kiros%2C%20Ryan%20Zemel%2C%20Richard%20Salakhutdinov%2C%20Ruslan%20R.%20A%20multiplicative%20model%20for%20learning%20distributed%20text-based%20attribute%20representations%202014"
        },
        {
            "id": "16",
            "entry": "[16] Alec Radford, Rafal Jozefowicz, and Ilya Sutskever. Learning to generate reviews and discovering sentiment. arXiv preprint arXiv:1704.01444, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.01444"
        },
        {
            "id": "17",
            "entry": "[17] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "18",
            "entry": "[18] Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. Controllable text generation. arXiv preprint arXiv:1703.00955, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00955"
        },
        {
            "id": "19",
            "entry": "[19] Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06349"
        },
        {
            "id": "20",
            "entry": "[20] Xi Chen, Diederik P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder. arXiv preprint arXiv:1611.02731, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02731"
        },
        {
            "id": "21",
            "entry": "[21] Juncen Li, Robin Jia, He He, and Percy Liang. Delete, retrieve, generate: A simple approach to sentiment and style transfer. arXiv preprint arXiv:1804.06437, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.06437"
        },
        {
            "id": "22",
            "entry": "[22] Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi Jaakkola. Style transfer from non-parallel text by cross-alignment. arXiv preprint arXiv:1705.09655, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.09655"
        },
        {
            "id": "23",
            "entry": "[23] Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, and Alan W Black. Style transfer through back-translation. arXiv preprint arXiv:1804.09000, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.09000"
        },
        {
            "id": "24",
            "entry": "[24] Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tieyan Liu, and Wei-Ying Ma. Dual learning for machine translation. In Advances in Neural Information Processing Systems, pages 820\u2013828, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Di%20Xia%2C%20Yingce%20Qin%2C%20Tao%20Wang%2C%20Liwei%20and%20Wei-Ying%20Ma.%20Dual%20learning%20for%20machine%20translation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Di%20Xia%2C%20Yingce%20Qin%2C%20Tao%20Wang%2C%20Liwei%20and%20Wei-Ying%20Ma.%20Dual%20learning%20for%20machine%20translation%202016"
        },
        {
            "id": "25",
            "entry": "[25] Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. Unsupervised neural machine translation. arXiv preprint arXiv:1710.11041, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.11041"
        },
        {
            "id": "26",
            "entry": "[26] Guillaume Lample, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. Unsupervised machine translation using monolingual corpora only. arXiv preprint arXiv:1711.00043, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.00043"
        },
        {
            "id": "27",
            "entry": "[27] Takeru Miyato and Masanori Koyama. cgans with projection discriminator. arXiv preprint arXiv:1802.05637, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05637"
        },
        {
            "id": "28",
            "entry": "[28] Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Gated feedback recurrent neural networks. In International Conference on Machine Learning, pages 2067\u20132075, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Junyoung%20Gulcehre%2C%20Caglar%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Gated%20feedback%20recurrent%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chung%2C%20Junyoung%20Gulcehre%2C%20Caglar%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Gated%20feedback%20recurrent%20neural%20networks%202015"
        },
        {
            "id": "29",
            "entry": "[29] Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word representation. In EMNLP, volume 14, pages 1532\u20131543, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014"
        },
        {
            "id": "30",
            "entry": "[30] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142\u2013 150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/P11-1015.",
            "url": "http://www.aclweb.org/anthology/P11-1015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maas%2C%20Andrew%20L.%20Daly%2C%20Raymond%20E.%20Pham%2C%20Peter%20T.%20Huang%2C%20Dan%20Learning%20word%20vectors%20for%20sentiment%20analysis%202011-06"
        },
        {
            "id": "31",
            "entry": "[31] Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, and Rui Yan. Style transfer in text: Exploration and evaluation. arXiv preprint arXiv:1711.06861, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.06861"
        },
        {
            "id": "32",
            "entry": "[32] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.02410"
        },
        {
            "id": "33",
            "entry": "[33] Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexander J Smola, Jing Jiang, and Chong Wang. Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars). In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 193\u2013202. ACM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diao%2C%20Qiming%20Qiu%2C%20Minghui%20Wu%2C%20Chao-Yuan%20Smola%2C%20Alexander%20J.%20Jointly%20modeling%20aspects%2C%20ratings%20and%20sentiments%20for%20movie%20recommendation%20%28jmars%29%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diao%2C%20Qiming%20Qiu%2C%20Minghui%20Wu%2C%20Chao-Yuan%20Smola%2C%20Alexander%20J.%20Jointly%20modeling%20aspects%2C%20ratings%20and%20sentiments%20for%20movie%20recommendation%20%28jmars%29%202014"
        },
        {
            "id": "34",
            "entry": "[34] Anita Ramm, Sharid Lo\u00e1iciga, Annemarie Friedrich, and Alexander Fraser. Annotating tense, mood and voice for english, french and german. Proceedings of ACL 2017, System Demonstrations, pages 1\u20136, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramm%2C%20Anita%20Lo%C3%A1iciga%2C%20Sharid%20Friedrich%2C%20Annemarie%20Fraser%2C%20Alexander%20Annotating%20tense%2C%20mood%20and%20voice%20for%20english%2C%20french%20and%20german%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ramm%2C%20Anita%20Lo%C3%A1iciga%2C%20Sharid%20Friedrich%2C%20Annemarie%20Fraser%2C%20Alexander%20Annotating%20tense%2C%20mood%20and%20voice%20for%20english%2C%20french%20and%20german%202017"
        }
    ]
}
