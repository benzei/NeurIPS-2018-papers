{
    "filename": "8027-neural-arithmetic-logic-units.pdf",
    "metadata": {
        "title": "Neural Arithmetic Logic Units",
        "author": "Andrew Trask, Felix Hill, Scott E. Reed, Jack Rae, Chris Dyer, Phil Blunsom",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8027-neural-arithmetic-logic-units.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Neural networks can learn to represent and manipulate numerical information, but they seldom generalize well outside of the range of numerical values encountered during training. To encourage more systematic numerical extrapolation, we propose an architecture that represents numerical quantities as linear activations which are manipulated using primitive arithmetic operators, controlled by learned gates. We call this module a neural arithmetic logic unit (NALU), by analogy to the arithmetic logic unit in traditional processors. Experiments show that NALU-enhanced neural networks can learn to track time, perform arithmetic over images of numbers, translate numerical language into real-valued scalars, execute computer code, and count objects in images. In contrast to conventional architectures, we obtain substantially better generalization both inside and outside of the range of numerical values encountered during training, often extrapolating orders of magnitude beyond trained numerical ranges."
    },
    "keywords": [
        {
            "term": "design strategy",
            "url": "https://en.wikipedia.org/wiki/design_strategy"
        },
        {
            "term": "numerical value",
            "url": "https://en.wikipedia.org/wiki/numerical_value"
        },
        {
            "term": "numerical range",
            "url": "https://en.wikipedia.org/wiki/numerical_range"
        },
        {
            "term": "NALU",
            "url": "https://en.wikipedia.org/wiki/NALU"
        },
        {
            "term": "arithmetic logic unit",
            "url": "https://en.wikipedia.org/wiki/arithmetic_logic_unit"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "The ability to represent and manipulate numerical quantities is apparent in the behavior of many species, from insects to mammals to humans, suggesting that basic quantitative reasoning is a general component of intelligence [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>].<br/><br/>While neural networks can successfully represent and manipulate numerical quantities given an appropriate learning signal, the behavior that they learn does not generally exhibit systematic generalization [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>]",
        "In both interpolation and extrapolation, the Neural Accumulator succeeds at modeling addition and subtraction, whereas the more flexible neural arithmetic logic unit succeeds at multiplicative operations as well.\n4.2",
        "Current approaches to modeling numeracy in neural networks fall short because numerical representations fail to generalize outside of the range observed during training",
        "We have shown how the Neural Accumulator and neural arithmetic logic unit can be applied to rectify these two shortcomings across a wide variety of domains, facilitating both numerical representations and functions on numerical representations that generalize outside of the range observed during training",
        "It is unlikely that Neural Accumulator or neural arithmetic logic unit will be the perfect solution for every task",
        "This design strategy is enabled by the single-neuron number representation we propose, which allows arbitrary numerical functions to be added to the module and controlled via learned gates, as the neural arithmetic logic unit has exemplified between addition/subtraction and multiplication/division"
    ],
    "key_statements": [
        "The ability to represent and manipulate numerical quantities is apparent in the behavior of many species, from insects to mammals to humans, suggesting that basic quantitative reasoning is a general component of intelligence [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>].<br/><br/>While neural networks can successfully represent and manipulate numerical quantities given an appropriate learning signal, the behavior that they learn does not generally exhibit systematic generalization [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>]",
        "In both interpolation and extrapolation, the Neural Accumulator succeeds at modeling addition and subtraction, whereas the more flexible neural arithmetic logic unit succeeds at multiplicative operations as well.\n4.2",
        "We discover whether backpropagation can learn the representation of non-numeric inputs to Neural Accumulator/neural arithmetic logic unit",
        "We compare to three popular RNNs (UGRNN, LSTM and DNC) and observe in both addition (Supplementary Figure 6) and program evaluation (Figure 4) that all models are able to solve the task at a fixed input domain, only the neural arithmetic logic unit is able to extrapolate to larger numbers",
        "Current approaches to modeling numeracy in neural networks fall short because numerical representations fail to generalize outside of the range observed during training",
        "We have shown how the Neural Accumulator and neural arithmetic logic unit can be applied to rectify these two shortcomings across a wide variety of domains, facilitating both numerical representations and functions on numerical representations that generalize outside of the range observed during training",
        "It is unlikely that Neural Accumulator or neural arithmetic logic unit will be the perfect solution for every task",
        "They exemplify a general design strategy for creating models that have biases intended for a target class of functions",
        "This design strategy is enabled by the single-neuron number representation we propose, which allows arbitrary numerical functions to be added to the module and controlled via learned gates, as the neural arithmetic logic unit has exemplified between addition/subtraction and multiplication/division"
    ],
    "summary": [
        "The ability to represent and manipulate numerical quantities is apparent in the behavior of many species, from insects to mammals to humans, suggesting that basic quantitative reasoning is a general component of intelligence [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>].<br/><br/>While neural networks can successfully represent and manipulate numerical quantities given an appropriate learning signal, the behavior that they learn does not generally exhibit systematic generalization [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>].",
        "We see that even over a basic task using a simple architecture, all nonlinear functions fail to learn to represent numbers outside of the range seen during training.",
        "This cell can learn arithmetic functions consisting of multiplication, addition, subtraction, division, and power functions in a way that extrapolates to numbers outside of the range observed during training.",
        "This is a strong trend in recent neural network literature concerning the systematic representation of concepts within recurrent memory, allowing for functions over these concepts to extrapolate to sequences longer than observed during training.",
        "In both interpolation and extrapolation, the NAC succeeds at modeling addition and subtraction, whereas the more flexible NALU succeeds at multiplicative operations as well.",
        "We discover whether backpropagation can learn the representation of non-numeric inputs to NACs/NALUs. In these tasks, a recurrent network is fed a series of 10 randomly chosen MNIST digits and at the end of the series it must output a numerical value about the series it observed.3 In the MNIST Digit Counting task, the model must learn to count how many images of each type it has seen (a 10-way regression), and in the MNIST Digit Addition task, it must learn to compute the sum of the digits it observed (a linear regression).",
        "We compare to three popular RNNs (UGRNN, LSTM and DNC) and observe in both addition (Supplementary Figure 6) and program evaluation (Figure 4) that all models are able to solve the task at a fixed input domain, only the NALU is able to extrapolate to larger numbers.",
        "We test whether a NAC can be used \u201cinternally\u201d by an RL-trained agent to develop more systematic generalization to quancommand: 13 r=m titative changes in its environment.",
        "Current approaches to modeling numeracy in neural networks fall short because numerical representations fail to generalize outside of the range observed during training.",
        "We have shown how the NAC and NALU can be applied to rectify these two shortcomings across a wide variety of domains, facilitating both numerical representations and functions on numerical representations that generalize outside of the range observed during training.",
        "This design strategy is enabled by the single-neuron number representation we propose, which allows arbitrary numerical functions to be added to the module and controlled via learned gates, as the NALU has exemplified between addition/subtraction and multiplication/division."
    ],
    "headline": "To encourage more systematic numerical extrapolation, we propose an architecture that represents numerical quantities as linear activations which are manipulated using primitive arithmetic operators, controlled by learned gates",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. VQA: Visual question answering. In Proceedings of the IEEE International Conference on Computer Vision, pages 2425\u20132433, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Antol%2C%20Stanislaw%20Agrawal%2C%20Aishwarya%20Lu%2C%20Jiasen%20Mitchell%2C%20Margaret%20VQA%3A%20Visual%20question%20answering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Antol%2C%20Stanislaw%20Agrawal%2C%20Aishwarya%20Lu%2C%20Jiasen%20Mitchell%2C%20Margaret%20VQA%3A%20Visual%20question%20answering%202015"
        },
        {
            "id": "2",
            "entry": "[2] Carlos Arteta, Victor Lempitsky, J Alison Noble, and Andrew Zisserman. Interactive object counting. In European Conference on Computer Vision, pages 504\u2013518, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arteta%2C%20Carlos%20Victor%20Lempitsky%2C%20J.Alison%20Noble%20Zisserman%2C%20Andrew%20Interactive%20object%20counting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arteta%2C%20Carlos%20Victor%20Lempitsky%2C%20J.Alison%20Noble%20Zisserman%2C%20Andrew%20Interactive%20object%20counting%202014"
        },
        {
            "id": "3",
            "entry": "[3] Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proceedings of the National Academy of Sciences, 113(15):3932\u20133937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brunton%2C%20Steven%20L.%20Proctor%2C%20Joshua%20L.%20Kutz%2C%20J.Nathan%20Discovering%20governing%20equations%20from%20data%20by%20sparse%20identification%20of%20nonlinear%20dynamical%20systems%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brunton%2C%20Steven%20L.%20Proctor%2C%20Joshua%20L.%20Kutz%2C%20J.Nathan%20Discovering%20governing%20equations%20from%20data%20by%20sparse%20identification%20of%20nonlinear%20dynamical%20systems%202016"
        },
        {
            "id": "4",
            "entry": "[4] Antoni B Chan, Zhang-Sheng John Liang, and Nuno Vasconcelos. Privacy preserving crowd monitoring: Counting people without people models or tracking. In Proc. CVPR, pages 1\u20137. IEEE, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chan%2C%20Antoni%20B.%20Liang%2C%20Zhang-Sheng%20John%20Vasconcelos%2C%20Nuno%20Privacy%20preserving%20crowd%20monitoring%3A%20Counting%20people%20without%20people%20models%20or%20tracking%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chan%2C%20Antoni%20B.%20Liang%2C%20Zhang-Sheng%20John%20Vasconcelos%2C%20Nuno%20Privacy%20preserving%20crowd%20monitoring%3A%20Counting%20people%20without%20people%20models%20or%20tracking%202008"
        },
        {
            "id": "5",
            "entry": "[5] Stanislas Dehaene. The Number Sense: How the Mind Creates Mathematics. Oxford University Press, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dehaene%2C%20Stanislas%20The%20Number%20Sense%3A%20How%20the%20Mind%20Creates%20Mathematics%202011"
        },
        {
            "id": "6",
            "entry": "[6] Jerry A. Fodor and Zenon W. Pylyshyn. Connectionism and cognitive architecture: a critical analysis. Cognition, 28(1\u20132):3\u201371, 1988.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fodor%2C%20Jerry%20A.%20Pylyshyn%2C%20Zenon%20W.%20Connectionism%20and%20cognitive%20architecture%3A%20a%20critical%20analysis%201988",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fodor%2C%20Jerry%20A.%20Pylyshyn%2C%20Zenon%20W.%20Connectionism%20and%20cognitive%20architecture%3A%20a%20critical%20analysis%201988"
        },
        {
            "id": "7",
            "entry": "[7] C. Randy Gallistel. Finding numbers in the brain. Philosophical Transactions of the Royal Society B, 373, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gallistel%2C%20C.Randy%20Finding%20numbers%20in%20the%20brain%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gallistel%2C%20C.Randy%20Finding%20numbers%20in%20the%20brain%202017"
        },
        {
            "id": "8",
            "entry": "[8] Rochel Gelman and C. Randy Gallistel. The child\u2019s understanding of number. Harvard, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gelman%2C%20Rochel%20Gallistel%2C%20C.Randy%20The%20child%E2%80%99s%20understanding%20of%20number%201978"
        },
        {
            "id": "9",
            "entry": "[9] Felix A Gers and E Schmidhuber. LSTM recurrent networks learn simple context-free and context-sensitive languages. IEEE Transactions on Neural Networks, 12(6):1333\u20131340, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gers%2C%20Felix%20A.%20Schmidhuber%2C%20E.%20LSTM%20recurrent%20networks%20learn%20simple%20context-free%20and%20context-sensitive%20languages%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gers%2C%20Felix%20A.%20Schmidhuber%2C%20E.%20LSTM%20recurrent%20networks%20learn%20simple%20context-free%20and%20context-sensitive%20languages%202001"
        },
        {
            "id": "10",
            "entry": "[10] Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recurrent neural networks. In Acoustics, speech and signal processing (icassp), 2013 ieee international conference on, pages 6645\u20136649. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Mohamed%2C%20Abdel-rahman%20Hinton%2C%20Geoffrey%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Mohamed%2C%20Abdel-rahman%20Hinton%2C%20Geoffrey%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks%202013"
        },
        {
            "id": "11",
            "entry": "[11] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. CoRR, abs/1410.5401, 2014. URL http://arxiv.org/abs/1410.5401.",
            "url": "http://arxiv.org/abs/1410.5401",
            "arxiv_url": "https://arxiv.org/pdf/1410.5401"
        },
        {
            "id": "12",
            "entry": "[12] Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka GrabskaBarwinska, Sergio G\u00f3mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al. Hybrid computing using a neural network with dynamic external memory. Nature, 538 (7626):471, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Wayne%2C%20Greg%20Reynolds%2C%20Malcolm%20Harley%2C%20Tim%20Hybrid%20computing%20using%20a%20neural%20network%20with%20dynamic%20external%20memory%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Wayne%2C%20Greg%20Reynolds%2C%20Malcolm%20Harley%2C%20Tim%20Hybrid%20computing%20using%20a%20neural%20network%20with%20dynamic%20external%20memory%202016"
        },
        {
            "id": "13",
            "entry": "[13] Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, and Phil Blunsom. Learning to transduce with unbounded memory. In Proc. NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grefenstette%2C%20Edward%20Hermann%2C%20Karl%20Moritz%20Suleyman%2C%20Mustafa%20Blunsom%2C%20Phil%20Learning%20to%20transduce%20with%20unbounded%20memory%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grefenstette%2C%20Edward%20Hermann%2C%20Karl%20Moritz%20Suleyman%2C%20Mustafa%20Blunsom%2C%20Phil%20Learning%20to%20transduce%20with%20unbounded%20memory%202015"
        },
        {
            "id": "14",
            "entry": "[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. CoRR, abs/1603.05027, 2016. URL http://arxiv.org/abs/1603.05027.",
            "url": "http://arxiv.org/abs/1603.05027",
            "arxiv_url": "https://arxiv.org/pdf/1603.05027"
        },
        {
            "id": "15",
            "entry": "[15] Gao Huang, Zhuang Liu, and Kilian Q. Weinberger. Densely connected convolutional networks. CoRR, abs/1608.06993, 2016. URL http://arxiv.org/abs/1608.06993.",
            "url": "http://arxiv.org/abs/1608.06993",
            "arxiv_url": "https://arxiv.org/pdf/1608.06993"
        },
        {
            "id": "16",
            "entry": "[16] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.02410"
        },
        {
            "id": "17",
            "entry": "[17] Alex Krizhevsky and Geoff Hinton. Convolutional deep belief networks on CIFAR-10. Unpublished manuscript, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoff%20Convolutional%20deep%20belief%20networks%20on%20CIFAR-10%202010"
        },
        {
            "id": "18",
            "entry": "[18] Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, and Richard Socher. Ask me anything: Dynamic memory networks for natural language processing. In Proc. ICML, pages 1378\u20131387, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20Ankit%20Irsoy%2C%20Ozan%20Ondruska%2C%20Peter%20Iyyer%2C%20Mohit%20Ask%20me%20anything%3A%20Dynamic%20memory%20networks%20for%20natural%20language%20processing%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20Ankit%20Irsoy%2C%20Ozan%20Ondruska%2C%20Peter%20Iyyer%2C%20Mohit%20Ask%20me%20anything%3A%20Dynamic%20memory%20networks%20for%20natural%20language%20processing%202016"
        },
        {
            "id": "19",
            "entry": "[19] Brendan Lake and Marco Baroni. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In Proc. ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brendan%20Baroni%2C%20Marco%20Generalization%20without%20systematicity%3A%20On%20the%20compositional%20skills%20of%20sequence-to-sequence%20recurrent%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brendan%20Baroni%2C%20Marco%20Generalization%20without%20systematicity%3A%20On%20the%20compositional%20skills%20of%20sequence-to-sequence%20recurrent%20networks%202018"
        },
        {
            "id": "20",
            "entry": "[20] Gary F. Marcus. The Algebraic Mind: Integrating Connectionism and Cognitive Science. MIT Press, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcus%2C%20Gary%20F.%20The%20Algebraic%20Mind%3A%20Integrating%20Connectionism%20and%20Cognitive%20Science%202003"
        },
        {
            "id": "21",
            "entry": "[21] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In Proc. ICML, pages 1928\u20131937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "22",
            "entry": "[22] Manuela Piazza, V\u00e9ronique Izard, Philippe Pinel, Denis Le Bihan, and Stanislas Dehaene. Tuning curves for approximate numerosity in the human intraparietal sulcus. Neuron, 44: 547\u2013555, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Piazza%2C%20Manuela%20Izard%2C%20V%C3%A9ronique%20Pinel%2C%20Philippe%20Bihan%2C%20Denis%20Le%20Tuning%20curves%20for%20approximate%20numerosity%20in%20the%20human%20intraparietal%20sulcus%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Piazza%2C%20Manuela%20Izard%2C%20V%C3%A9ronique%20Pinel%2C%20Philippe%20Bihan%2C%20Denis%20Le%20Tuning%20curves%20for%20approximate%20numerosity%20in%20the%20human%20intraparietal%20sulcus%202004"
        },
        {
            "id": "23",
            "entry": "[23] Scott E. Reed and Nando de Freitas. Neural programmer-interpreters. In Proc. ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Reed%2C%20Scott%20E.%20de%20Freitas%2C%20Nando%20Neural%20programmer-interpreters%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Reed%2C%20Scott%20E.%20de%20Freitas%2C%20Nando%20Neural%20programmer-interpreters%202016"
        },
        {
            "id": "24",
            "entry": "[24] David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. Learning representations by back-propagating errors. Nature, 323(6088):533, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rumelhart%2C%20David%20E.%20Hinton%2C%20Geoffrey%20E.%20Williams%2C%20Ronald%20J.%20Learning%20representations%20by%20back-propagating%20errors%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rumelhart%2C%20David%20E.%20Hinton%2C%20Geoffrey%20E.%20Williams%2C%20Ronald%20J.%20Learning%20representations%20by%20back-propagating%20errors%201986"
        },
        {
            "id": "25",
            "entry": "[25] Santi Segu\u00ed, Oriol Pujol, and Jordi Vitri\u00e0. Learning to count with deep object features. CoRR, abs/1505.08082, 2015. URL http://arxiv.org/abs/1505.08082.",
            "url": "http://arxiv.org/abs/1505.08082",
            "arxiv_url": "https://arxiv.org/pdf/1505.08082"
        },
        {
            "id": "26",
            "entry": "[26] Rupesh Kumar Srivastava, Klaus Greff, and J\u00fcrgen Schmidhuber. Highway networks. CoRR, abs/1505.00387, 2015. URL http://arxiv.org/abs/1505.00387.",
            "url": "http://arxiv.org/abs/1505.00387",
            "arxiv_url": "https://arxiv.org/pdf/1505.00387"
        },
        {
            "id": "27",
            "entry": "[27] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014"
        },
        {
            "id": "28",
            "entry": "[28] Gail Weiss, Yoav Goldberg, and Eran Yahav. On the practical computational power of finite precision RNNs for language recognition. In Proc. ACL, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Weiss%2C%20Gail%20Goldberg%2C%20Yoav%20Yahav%2C%20Eran%20On%20the%20practical%20computational%20power%20of%20finite%20precision%20RNNs%20for%20language%20recognition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Weiss%2C%20Gail%20Goldberg%2C%20Yoav%20Yahav%2C%20Eran%20On%20the%20practical%20computational%20power%20of%20finite%20precision%20RNNs%20for%20language%20recognition%202018"
        },
        {
            "id": "29",
            "entry": "[29] Jason Weston, Antoine Bordes, Sumit Chopra, and Tomas Mikolov. Towards AI-complete question answering: A set of prerequisite toy tasks. CoRR, abs/1502.05698, 2015. URL http://arxiv.org/abs/1502.05698.",
            "url": "http://arxiv.org/abs/1502.05698",
            "arxiv_url": "https://arxiv.org/pdf/1502.05698"
        },
        {
            "id": "30",
            "entry": "[30] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. In Proc. ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Weston%2C%20Jason%20Chopra%2C%20Sumit%20Bordes%2C%20Antoine%20Memory%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Weston%2C%20Jason%20Chopra%2C%20Sumit%20Bordes%2C%20Antoine%20Memory%20networks%202015"
        },
        {
            "id": "31",
            "entry": "[31] Weidi Xie, J Alison Noble, and Andrew Zisserman. Microscopy cell counting and detection with fully convolutional regression networks. Computer methods in biomechanics and biomedical engineering: Imaging & Visualization, 6(3):283\u2013292, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Weidi%20Xie%2C%20J.Alison%20Noble%20Zisserman%2C%20Andrew%20Microscopy%20cell%20counting%20and%20detection%20with%20fully%20convolutional%20regression%20networks.%20Computer%20methods%20in%20biomechanics%20and%20biomedical%20engineering%3A%20Imaging%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Weidi%20Xie%2C%20J.Alison%20Noble%20Zisserman%2C%20Andrew%20Microscopy%20cell%20counting%20and%20detection%20with%20fully%20convolutional%20regression%20networks.%20Computer%20methods%20in%20biomechanics%20and%20biomedical%20engineering%3A%20Imaging%202018"
        },
        {
            "id": "32",
            "entry": "[32] Wojciech Zaremba and Ilya Sutskever. Learning to execute. CoRR, abs/1410.4615, 2014. URL http://arxiv.org/abs/1410.4615.",
            "url": "http://arxiv.org/abs/1410.4615",
            "arxiv_url": "https://arxiv.org/pdf/1410.4615"
        },
        {
            "id": "33",
            "entry": "[33] Cong Zhang, Hongsheng Li, Xiaogang Wang, and Xiaokang Yang. Cross-scene crowd counting via deep convolutional neural networks. In Proc. CVPR, pages 833\u2013841. IEEE, 2015. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Cong%20Li%2C%20Hongsheng%20Xiaogang%20Wang%2C%20and%20Xiaokang%20Yang.%20Cross-scene%20crowd%20counting%20via%20deep%20convolutional%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Cong%20Li%2C%20Hongsheng%20Xiaogang%20Wang%2C%20and%20Xiaokang%20Yang.%20Cross-scene%20crowd%20counting%20via%20deep%20convolutional%20neural%20networks%202015"
        }
    ]
}
