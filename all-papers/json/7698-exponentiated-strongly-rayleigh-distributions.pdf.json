{
    "filename": "7698-exponentiated-strongly-rayleigh-distributions.pdf",
    "metadata": {
        "date": 2018,
        "title": "Exponentiated Strongly Rayleigh Distributions",
        "author": "Zelda Mariet",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7698-exponentiated-strongly-rayleigh-distributions.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Strongly Rayleigh (SR) measures are discrete probability distributions over the subsets of a ground set. They enjoy strong negative dependence properties, as a result of which they assign higher probability to subsets of diverse elements. We introduce in this paper Exponentiated Strongly Rayleigh (ESR) measures, which sharpen (or smoothen) the negative dependence property of SR measures via a single parameter (the exponent) that can be intuitively understood as an inverse temperature. We develop efficient MCMC procedures for approximate sampling from ESRs, and obtain explicit mixing time bounds for two concrete instances: exponentiated versions of Determinantal Point Processes and Dual Volume Sampling. We illustrate some of the potential of ESRs, by applying them to a few machine learning problems; empirical results confirm that beyond their theoretical appeal, ESR-based models hold significant promise for these tasks."
    },
    "keywords": [
        {
            "term": "markov chain",
            "url": "https://en.wikipedia.org/wiki/markov_chain"
        },
        {
            "term": "recommender system",
            "url": "https://en.wikipedia.org/wiki/recommender_system"
        },
        {
            "term": "MCMC",
            "url": "https://en.wikipedia.org/wiki/MCMC"
        },
        {
            "term": "experimental design",
            "url": "https://en.wikipedia.org/wiki/experimental_design"
        },
        {
            "term": "Local Outlier Factor",
            "url": "https://en.wikipedia.org/wiki/Local_Outlier_Factor"
        }
    ],
    "highlights": [
        "The careful selection of a few items from a large ground set is a crucial component of many machine learning problems",
        "In order to calibrate the relative influence of the diversity and quality of a set S on the probability an Strongly Rayleigh measure assigns to S, we introduce the family of Exponentiated Strongly Rayleigh measures",
        "We report the performance of a selection of standard outlier detection algorithms whose reported performance in [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>] is competitive with other outlier detection algorithms: Local Outlier Factor (LOF) [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], k-Nearest Neighbor [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], Histogram-based Outlier Score (HBOS) [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>], Local Outlier Probability (LoOP) [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>] and unweighted Cluster-Based Local Outlier Factor [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>]",
        "Many machine learning problems have been shown to benefit from the negative dependence properties of Strongly Rayleigh measures: measures based on elementary symmetric polynomials \u2013 including volume sampling \u2013 have been applied to experimental design; Determinantal Point Processes have been applied\n2http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html successfully to fields ranging from automatic summarization to minibatch selection and neural network pruning",
        "We introduced Exponentiated Strongly Rayleigh measures, an extension of Strongly Rayleigh measures which augment standard Strongly Rayleigh measures with an exponent p, allowing for straightforward tuning of the the quality-diversity trade-off of Strongly Rayleigh distributions",
        "We show that Exponentiated Strongly Rayleigh measures do not necessarily remain Strongly Rayleigh, but certain distributions lie at the intersection of both classes"
    ],
    "key_statements": [
        "The careful selection of a few items from a large ground set is a crucial component of many machine learning problems",
        "We evaluate the proposed sampling procedures on outlier detection and kernel reconstruction, and show how a class of machine learning problems can benefit from the modeling power of Exponentiated Strongly Rayleigh measures",
        "We show that the mixing time of the Exponentiated Strongly Rayleigh samplers is upper bounded in terms of r-closeness; we provide concrete bounds for popular Strongly Rayleigh measures",
        "We address this need by passing to the broader class of Exponentiated Strongly Rayleigh measures, whose diversity/quality preference is parametrized by a single exponent",
        "In order to calibrate the relative influence of the diversity and quality of a set S on the probability an Strongly Rayleigh measure assigns to S, we introduce the family of Exponentiated Strongly Rayleigh measures",
        "We propose instead two MCMC sampling algorithms whose key idea lies in exploiting the explicit relation Exponentiated Strongly Rayleigh measures have to Strongly Rayleigh measures",
        "The following result establishes that for any Exponentiated Strongly Rayleigh measure \u03bd, there exists an Strongly Rayleigh measure \u03bc which is r-close to \u03bd with r < \u221e. This result is the cornerstone of the sampling algorithms we derive, as we show that we can use an r-close Strongly Rayleigh measure as proposal to efficiently sample from an Exponentiated Strongly Rayleigh measure",
        "In order to sample from an Exponentiated Strongly Rayleigh distribution \u03bd, we generalize existing MCMC algorithms for Strongly Rayleigh measures; we bound the distance to stationarity of the the chain\u2019s current state by comparing it to the distance to stationarity of a similar chain sampling from an Strongly Rayleigh measure \u03bc, and leveraging the r-closeness r(\u03bc, \u03bd).\n3.1",
        "Writing \u03bdt\u2032,S the distribution generated by a Markov chain sampler after t iterations and initialization set S, the mixing time \u03c4S(\u03b5) measures the number of required iterations of the Markov chain so that \u03bdt\u2032,S is close enough to the true Exponentiated Strongly Rayleigh measure \u03bd: \u03c4S(\u03b5) \u225c min{t : \u2225\u03bdt\u2032,S \u2212 \u03bd\u2225TV \u2264 \u03b5}",
        "We show this explicitly for the two algorithms derived above, obtaining bounds on \u03c4S that directly depend on the r-closeness of the target Exponentiated Strongly Rayleigh measure \u03bd and an Strongly Rayleigh measure \u03bc",
        "We derive explicit mixing time bounds for Exponentiated Strongly Rayleigh measures \u03bd generated by two popular classes of Strongly Rayleigh measures: Determinantal Point Processes, in their usual form as well as their k-homogeneous form (k-Determinantal Point Processes), and Dual Volume Sampling (DVS)",
        "Let \u03bc be the distribution induced by a k-Determinantal Point Processes with kernel Lp, and \u03bd be the corresponding Exponentiated Strongly Rayleigh measure such that \u03bd(S) \u221d det(L[S])p",
        "To evaluate the empirical applications of Exponentiated Strongly Rayleigh measures, we evaluate E-Determinantal Point Processes (DPPs are by far the most popular Strongly Rayleigh measure in machine learning) on a variety of machine learning task",
        "We report the performance of a selection of standard outlier detection algorithms whose reported performance in [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>] is competitive with other outlier detection algorithms: Local Outlier Factor (LOF) [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], k-Nearest Neighbor [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], Histogram-based Outlier Score (HBOS) [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>], Local Outlier Probability (LoOP) [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>] and unweighted Cluster-Based Local Outlier Factor [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>]",
        "Determinantal Point Processes have successfully been applied to the landmark selection for the Nystr\u00f6m approach [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>]",
        "We show here that E-Determinantal Point Processes further improve upon the recent results of [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] for kernel reconstruction",
        "Many machine learning problems have been shown to benefit from the negative dependence properties of Strongly Rayleigh measures: measures based on elementary symmetric polynomials \u2013 including volume sampling \u2013 have been applied to experimental design; Determinantal Point Processes have been applied\n2http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html successfully to fields ranging from automatic summarization to minibatch selection and neural network pruning",
        "We introduced Exponentiated Strongly Rayleigh measures, an extension of Strongly Rayleigh measures which augment standard Strongly Rayleigh measures with an exponent p, allowing for straightforward tuning of the the quality-diversity trade-off of Strongly Rayleigh distributions",
        "P controls how much priority should be given to diversity requirements",
        "We show that Exponentiated Strongly Rayleigh measures do not necessarily remain Strongly Rayleigh, but certain distributions lie at the intersection of both classes",
        "We derive general-purpose mixing bounds based on the distance from the target distribution \u03bd to an Strongly Rayleigh distribution \u03bc; we show that these bounds can be further improved by specifying a carefully calibrated Strongly Rayleigh proposal distribution \u03bc, as is the case for Exponentiated Determinantal Point Processes"
    ],
    "summary": [
        "The careful selection of a few items from a large ground set is a crucial component of many machine learning problems.",
        "We evaluate the proposed sampling procedures on outlier detection and kernel reconstruction, and show how a class of machine learning problems can benefit from the modeling power of ESR measures.",
        "We show that ESRs have a fundamental advantage over standard log-submodular functions: the intractability of their partition function precludes exact sampling algorithms, their closed form as the exponentiation of an SR measure can be leveraged to take advantage of the recent result [<a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>] on fast-mixing Markov chains for SR measures.",
        "In order to sample from an ESR distribution \u03bd, we generalize existing MCMC algorithms for SR measures; we bound the distance to stationarity of the the chain\u2019s current state by comparing it to the distance to stationarity of a similar chain sampling from an SR measure \u03bc, and leveraging the r-closeness r(\u03bc, \u03bd).",
        "Writing \u03bdt\u2032,S the distribution generated by a Markov chain sampler after t iterations and initialization set S, the mixing time \u03c4S(\u03b5) measures the number of required iterations of the Markov chain so that \u03bdt\u2032,S is close enough to the true ESR measure \u03bd: \u03c4S(\u03b5) \u225c min{t : \u2225\u03bdt\u2032,S \u2212 \u03bd\u2225TV \u2264 \u03b5}",
        "For the swapchain algorithm (Alg. 2), we derive a bound on the mixing time by comparing to a result by [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>] which shows fast sampling for SR distributions over subsets of a fixed size.",
        "As a Markov chain\u2019s applicability closely depends on its mixing time, a crucial task in sampling from ESR measures lies in finding an r-close SR distribution with small r.",
        "We derive explicit mixing time bounds for ESR measures \u03bd generated by two popular classes of SR measures: DPPs, in their usual form as well as their k-homogeneous form (k-DPPs), and Dual Volume Sampling (DVS).",
        "Let \u03bc be the distribution induced by a k-DPP with kernel Lp, and \u03bd be the corresponding ESR measure such that \u03bd(S) \u221d det(L[S])p.",
        "Despite their intractable partition function, ESR measures can leverage existing fast-mixing Markov chains for SR measures, enabling finer bounds than those obtained for the broader class of logsubmodular models.",
        "We derive general-purpose mixing bounds based on the distance from the target distribution \u03bd to an SR distribution \u03bc; we show that these bounds can be further improved by specifying a carefully calibrated SR proposal distribution \u03bc, as is the case for Exponentiated DPPs. We verified empirically that ESR measures and the algorithms we derive are valuable modeling tools for machine learning tasks, such as outlier detection and kernel reconstruction.",
        "We show that ESR measures do not necessarily remain SR, but certain distributions lie at the intersection of both classes"
    ],
    "headline": "We introduce in this paper Exponentiated Strongly Rayleigh  measures, which sharpen  the negative dependence property of Strongly Rayleigh measures via a single parameter  that can be intuitively understood as an inverse temperature",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] R. Affandi, E. Fox, R. Adams, and B. Taskar. Learning the parameters of Determinantal Point Process kernels. In ICML, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Affandi%2C%20R.%20Fox%2C%20E.%20Adams%2C%20R.%20Taskar%2C%20B.%20Learning%20the%20parameters%20of%20Determinantal%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Affandi%2C%20R.%20Fox%2C%20E.%20Adams%2C%20R.%20Taskar%2C%20B.%20Learning%20the%20parameters%20of%20Determinantal%202014"
        },
        {
            "id": "2",
            "entry": "[2] R. H. Affandi, A. Kulesza, E. B. Fox, and B. Taskar. Nystr\u00f6m approximation for large-scale determinantal processes. In Proc. Int. Conference on Artificial Intelligence and Statistics (AISTATS), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Affandi%2C%20R.H.%20Kulesza%2C%20A.%20Fox%2C%20E.B.%20Taskar%2C%20B.%20Nystr%C3%B6m%20approximation%20for%20large-scale%20determinantal%20processes%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Affandi%2C%20R.H.%20Kulesza%2C%20A.%20Fox%2C%20E.B.%20Taskar%2C%20B.%20Nystr%C3%B6m%20approximation%20for%20large-scale%20determinantal%20processes%202013"
        },
        {
            "id": "3",
            "entry": "[3] M. Amer and M. Goldstein. Nearest-neighbor and clustering based anomaly detection algorithms for rapidminer. In Proceedings of the 3rd RapidMiner Community Meeting and Conferernce (RCOMM 2012), pages 1\u201312. Shaker Verlag GmbH, 8 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amer%2C%20M.%20Goldstein%2C%20M.%20Nearest-neighbor%20and%20clustering%20based%20anomaly%20detection%20algorithms%20for%20rapidminer%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Amer%2C%20M.%20Goldstein%2C%20M.%20Nearest-neighbor%20and%20clustering%20based%20anomaly%20detection%20algorithms%20for%20rapidminer%202012"
        },
        {
            "id": "4",
            "entry": "[4] N. Anari and S. Oveis Gharan. A generalization of permanent inequalities and applications in counting and optimization. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing (STOC). ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anari%2C%20N.%20Gharan%2C%20S.Oveis%20A%20generalization%20of%20permanent%20inequalities%20and%20applications%20in%20counting%20and%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anari%2C%20N.%20Gharan%2C%20S.Oveis%20A%20generalization%20of%20permanent%20inequalities%20and%20applications%20in%20counting%20and%20optimization%202017"
        },
        {
            "id": "5",
            "entry": "[5] N. Anari, S. O. Gharan, and A. Rezaei. Monte Carlo Markov Chain algorithms for sampling strongly Rayleigh distributions and Determinantal Point Processes. In Conference on Learning Theory (COLT), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anari%2C%20N.%20Gharan%2C%20S.O.%20Rezaei%2C%20A.%20Monte%20Carlo%20Markov%20Chain%20algorithms%20for%20sampling%20strongly%20Rayleigh%20distributions%20and%20Determinantal%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anari%2C%20N.%20Gharan%2C%20S.O.%20Rezaei%2C%20A.%20Monte%20Carlo%20Markov%20Chain%20algorithms%20for%20sampling%20strongly%20Rayleigh%20distributions%20and%20Determinantal%202016"
        },
        {
            "id": "6",
            "entry": "[6] C. Andrieu, N. D. Freitas, and et al. An introduction to MCMC for machine learning, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=C.%20Andrieu%2C%20N.%20D.%20Freitas%2C%20and%20An%20introduction%20to%20MCMC%202003"
        },
        {
            "id": "7",
            "entry": "[7] F. Angiulli and C. Pizzuti. Fast outlier detection in high dimensional spaces. In Proceedings of the 6th European Conference on Principles of Data Mining and Knowledge Discovery, PKDD \u201902, pages 15\u201326, London, UK, UK, 2002. Springer-Verlag.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Angiulli%2C%20F.%20Pizzuti%2C%20C.%20Fast%20outlier%20detection%20in%20high%20dimensional%20spaces%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Angiulli%2C%20F.%20Pizzuti%2C%20C.%20Fast%20outlier%20detection%20in%20high%20dimensional%20spaces%202002"
        },
        {
            "id": "8",
            "entry": "[8] H. Avron and C. Boutsidis. Faster subset selection for matrices and applications. SIAM J. Matrix Analysis Applications, 34(4):1464\u20131499, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Avron%2C%20H.%20Boutsidis%2C%20C.%20Faster%20subset%20selection%20for%20matrices%20and%20applications%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Avron%2C%20H.%20Boutsidis%2C%20C.%20Faster%20subset%20selection%20for%20matrices%20and%20applications%202013"
        },
        {
            "id": "9",
            "entry": "[9] J. Borcea and P. Br\u00e4nd\u00e9n. Applications of stable polynomials to mixed determinants: Johnson\u2019s conjectures, unimodality and mixed fischer products. Duke Math. J., pages 205\u2013223, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borcea%2C%20J.%20Br%C3%A4nd%C3%A9n%2C%20P.%20Applications%20of%20stable%20polynomials%20to%20mixed%20determinants%3A%20Johnson%E2%80%99s%20conjectures%2C%20unimodality%20and%20mixed%20fischer%20products%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borcea%2C%20J.%20Br%C3%A4nd%C3%A9n%2C%20P.%20Applications%20of%20stable%20polynomials%20to%20mixed%20determinants%3A%20Johnson%E2%80%99s%20conjectures%2C%20unimodality%20and%20mixed%20fischer%20products%202008"
        },
        {
            "id": "10",
            "entry": "[10] J. Borcea and P. Br\u00e4nd\u00e9n. P\u00f3lya-schur master theorems for circular domains and their boundaries. Annals of Mathematics, 170(1):465\u2013492, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borcea%2C%20J.%20Br%C3%A4nd%C3%A9n%2C%20P.%20P%C3%B3lya-schur%20master%20theorems%20for%20circular%20domains%20and%20their%20boundaries%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borcea%2C%20J.%20Br%C3%A4nd%C3%A9n%2C%20P.%20P%C3%B3lya-schur%20master%20theorems%20for%20circular%20domains%20and%20their%20boundaries%202009"
        },
        {
            "id": "11",
            "entry": "[11] J. Borcea, P. Br\u00e4nden, and T. Liggett. Negative dependence and the geometry of polynomials. Journal of American Mathematical Society, 22:521\u2013567, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borcea%2C%20J.%20Br%C3%A4nden%2C%20P.%20Liggett%2C%20T.%20Negative%20dependence%20and%20the%20geometry%20of%20polynomials%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borcea%2C%20J.%20Br%C3%A4nden%2C%20P.%20Liggett%2C%20T.%20Negative%20dependence%20and%20the%20geometry%20of%20polynomials%202009"
        },
        {
            "id": "12",
            "entry": "[12] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. LOF: Identifying density-based local outliers. SIGMOD Rec., 29(2):93\u2013104, May 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Breunig%2C%20M.M.%20Kriegel%2C%20H.-P.%20Ng%2C%20R.T.%20Sander%2C%20J.%20LOF%3A%20Identifying%20density-based%20local%20outliers%202000-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Breunig%2C%20M.M.%20Kriegel%2C%20H.-P.%20Ng%2C%20R.T.%20Sander%2C%20J.%20LOF%3A%20Identifying%20density-based%20local%20outliers%202000-05"
        },
        {
            "id": "13",
            "entry": "[13] S. P. Brooks and A. Gelman. General methods for monitoring convergence of iterative simulations. Journal of Computational and Graphical Statistics, 7:434\u2013455, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brooks%2C%20S.P.%20Gelman%2C%20A.%20General%20methods%20for%20monitoring%20convergence%20of%20iterative%20simulations%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brooks%2C%20S.P.%20Gelman%2C%20A.%20General%20methods%20for%20monitoring%20convergence%20of%20iterative%20simulations%201998"
        },
        {
            "id": "14",
            "entry": "[14] H. Cai. Exact bound for the convergence of metropolis chains. Stochastic Analysis and Applications, 18(1):63\u201371, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cai%2C%20H.%20Exact%20bound%20for%20the%20convergence%20of%20metropolis%20chains%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cai%2C%20H.%20Exact%20bound%20for%20the%20convergence%20of%20metropolis%20chains%202000"
        },
        {
            "id": "15",
            "entry": "[15] W. Chao, B. Gong, K. Grauman, and F. Sha. Large-margin Determinantal Point Processes. In Uncertainty in Artificial Intelligence (UAI), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=W%20Chao%20B%20Gong%20K%20Grauman%20and%20F%20Sha%20Largemargin%20Determinantal%20Point%20Processes%20In%20Uncertainty%20in%20Artificial%20Intelligence%20UAI%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=W%20Chao%20B%20Gong%20K%20Grauman%20and%20F%20Sha%20Largemargin%20Determinantal%20Point%20Processes%20In%20Uncertainty%20in%20Artificial%20Intelligence%20UAI%202015"
        },
        {
            "id": "16",
            "entry": "[16] M. Derezinski and M. K. Warmuth. Unbiased estimates for linear regression via volume sampling. In Advances in Neural Information Processing Systems 30, pages 3084\u20133093. Curran Associates, Inc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Derezinski%2C%20M.%20Warmuth%2C%20M.K.%20Unbiased%20estimates%20for%20linear%20regression%20via%20volume%20sampling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Derezinski%2C%20M.%20Warmuth%2C%20M.K.%20Unbiased%20estimates%20for%20linear%20regression%20via%20volume%20sampling%202017"
        },
        {
            "id": "17",
            "entry": "[17] P. Diaconis and L. Saloff-Coste. Comparison theorems for reversible Markov chains. The Annals of Applied Probability, 3(3):696\u2013730, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diaconis%2C%20P.%20Saloff-Coste%2C%20L.%20Comparison%20theorems%20for%20reversible%20Markov%20chains%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diaconis%2C%20P.%20Saloff-Coste%2C%20L.%20Comparison%20theorems%20for%20reversible%20Markov%20chains%201993"
        },
        {
            "id": "18",
            "entry": "[18] P. Diaconis and D. Stroock. Geometric bounds for eingenvalues of Markov Chains. Annals of Applied Probability, pages 36\u201361, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diaconis%2C%20P.%20Stroock%2C%20D.%20Geometric%20bounds%20for%20eingenvalues%20of%20Markov%20Chains%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diaconis%2C%20P.%20Stroock%2C%20D.%20Geometric%20bounds%20for%20eingenvalues%20of%20Markov%20Chains%201991"
        },
        {
            "id": "19",
            "entry": "[19] J. Djolonga and A. Krause. From MAP to marginals: Variational inference in bayesian submodular models. In Advances in Neural Information Processing Systems 27, pages 244\u2013252. Curran Associates, Inc., 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Djolonga%2C%20J.%20Krause%2C%20A.%20From%20MAP%20to%20marginals%3A%20Variational%20inference%20in%20bayesian%20submodular%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Djolonga%2C%20J.%20Krause%2C%20A.%20From%20MAP%20to%20marginals%3A%20Variational%20inference%20in%20bayesian%20submodular%20models%202014"
        },
        {
            "id": "20",
            "entry": "[20] J. Djolonga, S. Tschiatschek, and A. Krause. Variational inference in mixed probabilistic submodular models. In Neural Information Processing Systems (NIPS), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Djolonga%2C%20J.%20Tschiatschek%2C%20S.%20Krause%2C%20A.%20Variational%20inference%20in%20mixed%20probabilistic%20submodular%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Djolonga%2C%20J.%20Tschiatschek%2C%20S.%20Krause%2C%20A.%20Variational%20inference%20in%20mixed%20probabilistic%20submodular%20models%202016"
        },
        {
            "id": "21",
            "entry": "[21] M. Gartrell, U. Paquet, and N. Koenigstein. Low-rank factorization of Determinantal Point Processes. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA., pages 1912\u20131918, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gartrell%2C%20M.%20Paquet%2C%20U.%20Koenigstein%2C%20N.%20Low-rank%20factorization%20of%20Determinantal%20Point%20Processes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gartrell%2C%20M.%20Paquet%2C%20U.%20Koenigstein%2C%20N.%20Low-rank%20factorization%20of%20Determinantal%20Point%20Processes%202017"
        },
        {
            "id": "22",
            "entry": "[22] J. Gillenwater. Approximate Inference for Determinantal Point Processes. PhD thesis, University of Pennsylvania, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gillenwater%2C%20J.%20Approximate%20Inference%20for%20Determinantal%20Point%20Processes%202014"
        },
        {
            "id": "23",
            "entry": "[23] M. Goldstein and A. Dengel. Histogram-based outlier score (HBOS): A fast unsupervised anomaly detection algorithm. In KI-2012: Poster and Demo Track. German Conference on Artificial Intelligence (KI-2012), 35th, September 24-27, Saarbr\u00fccken, Germany, pages 59\u201363, 9 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldstein%2C%20M.%20Dengel%2C%20A.%20Histogram-based%20outlier%20score%20%28HBOS%29%3A%20A%20fast%20unsupervised%20anomaly%20detection%20algorithm%202012-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldstein%2C%20M.%20Dengel%2C%20A.%20Histogram-based%20outlier%20score%20%28HBOS%29%3A%20A%20fast%20unsupervised%20anomaly%20detection%20algorithm%202012-09"
        },
        {
            "id": "24",
            "entry": "[24] M. Goldstein and S. Uchida. A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data. PLOS ONE, 11(4):1\u201331, 04 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldstein%2C%20M.%20Uchida%2C%20S.%20A%20comparative%20evaluation%20of%20unsupervised%20anomaly%20detection%20algorithms%20for%20multivariate%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldstein%2C%20M.%20Uchida%2C%20S.%20A%20comparative%20evaluation%20of%20unsupervised%20anomaly%20detection%20algorithms%20for%20multivariate%20data%202016"
        },
        {
            "id": "25",
            "entry": "[25] A. Gotovos, S. Hassani, and A. Krause. Sampling from probabilistic submodular models. In Advances in Neural Information Processing Systems (NIPS), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gotovos%2C%20A.%20Hassani%2C%20S.%20Krause%2C%20A.%20Sampling%20from%20probabilistic%20submodular%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gotovos%2C%20A.%20Hassani%2C%20S.%20Krause%2C%20A.%20Sampling%20from%20probabilistic%20submodular%20models%202015"
        },
        {
            "id": "26",
            "entry": "[26] W. K. Hastings. Monte carlo sampling methods using markov chains and their applications. Biometrika, 57(1):97\u2013109, 1970.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hastings%2C%20W.K.%20Monte%20carlo%20sampling%20methods%20using%20markov%20chains%20and%20their%20applications%201970",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hastings%2C%20W.K.%20Monte%20carlo%20sampling%20methods%20using%20markov%20chains%20and%20their%20applications%201970"
        },
        {
            "id": "27",
            "entry": "[27] A. Krause, A. Singh, and C. Guestrin. Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies. Journal of Machine Learning Research, 9: 235\u2013284, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krause%2C%20A.%20Singh%2C%20A.%20Guestrin%2C%20C.%20Near-optimal%20sensor%20placements%20in%20gaussian%20processes%3A%20Theory%2C%20efficient%20algorithms%20and%20empirical%20studies%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krause%2C%20A.%20Singh%2C%20A.%20Guestrin%2C%20C.%20Near-optimal%20sensor%20placements%20in%20gaussian%20processes%3A%20Theory%2C%20efficient%20algorithms%20and%20empirical%20studies%202008"
        },
        {
            "id": "28",
            "entry": "[28] H.-P. Kriegel, P. Kr\u00f6ger, E. Schubert, and A. Zimek. LoOP: Local outlier probabilities. In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM \u201909, pages 1649\u20131652, New York, NY, USA, 2009. ACM.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kriegel%2C%20H.-P.%20Kr%C3%B6ger%2C%20P.%20Schubert%2C%20E.%20Zimek%2C%20A.%20LoOP%3A%20Local%20outlier%20probabilities%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kriegel%2C%20H.-P.%20Kr%C3%B6ger%2C%20P.%20Schubert%2C%20E.%20Zimek%2C%20A.%20LoOP%3A%20Local%20outlier%20probabilities%202009"
        },
        {
            "id": "29",
            "entry": "[29] A. Kulesza and B. Taskar. Determinantal Point Processes for machine learning, volume 5. Foundations and Trends in Machine Learning, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulesza%2C%20A.%20Taskar%2C%20B.%20Determinantal%20Point%20Processes%20for%20machine%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulesza%2C%20A.%20Taskar%2C%20B.%20Determinantal%20Point%20Processes%20for%20machine%202012"
        },
        {
            "id": "30",
            "entry": "[30] C. Li, S. Jegelka, and S. Sra. Fast DPP sampling for Nystr\u00f6m with appication to kernel methods. In Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48, ICML\u201916, pages 2061\u20132070. JMLR.org, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Fast%20DPP%20sampling%20for%20Nystr%C3%B6m%20with%20appication%20to%20kernel%20methods%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Fast%20DPP%20sampling%20for%20Nystr%C3%B6m%20with%20appication%20to%20kernel%20methods%202016"
        },
        {
            "id": "31",
            "entry": "[31] C. Li, S. Jegelka, and S. Sra. Fast mixing Markov chains for strongly Rayleigh measures, DPPs, and constrained sampling. In Advances in Neural Information Processing Systems (NIPS), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Fast%20mixing%20Markov%20chains%20for%20strongly%20Rayleigh%20measures%2C%20DPPs%2C%20and%20constrained%20sampling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Fast%20mixing%20Markov%20chains%20for%20strongly%20Rayleigh%20measures%2C%20DPPs%2C%20and%20constrained%20sampling%202016"
        },
        {
            "id": "32",
            "entry": "[32] C. Li, S. Jegelka, and S. Sra. Fast DPP sampling for Nystr\u00f6m with application to kernel methods. In Int. Conference on Machine Learning (ICML), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Fast%20DPP%20sampling%20for%20Nystr%C3%B6m%20with%20application%20to%20kernel%20methods%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Fast%20DPP%20sampling%20for%20Nystr%C3%B6m%20with%20application%20to%20kernel%20methods%202016"
        },
        {
            "id": "33",
            "entry": "[33] C. Li, S. Jegelka, and S. Sra. Polynomial time algorithms for dual volume sampling. In Advances in Neural Information Processing Systems 30, pages 5038\u20135047. Curran Associates, Inc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Polynomial%20time%20algorithms%20for%20dual%20volume%20sampling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20C.%20Jegelka%2C%20S.%20Sra%2C%20S.%20Polynomial%20time%20algorithms%20for%20dual%20volume%20sampling%202017"
        },
        {
            "id": "34",
            "entry": "[34] H. Lin and J. Bilmes. Learning mixtures of submodular shells with application to document summarization. In Uncertainty in Artificial Intelligence (UAI), 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20H.%20Bilmes%2C%20J.%20Learning%20mixtures%20of%20submodular%20shells%20with%20application%20to%20document%20summarization%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20H.%20Bilmes%2C%20J.%20Learning%20mixtures%20of%20submodular%20shells%20with%20application%20to%20document%20summarization%202012"
        },
        {
            "id": "35",
            "entry": "[35] A. W. Marcus, D. A. Spielman, and N. Srivastava. Interlacing families II: Mixed characteristic polynomials and the Kadison-Singer problem. Annals of Mathematics, 182(1):327\u2013350, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcus%2C%20A.W.%20Spielman%2C%20D.A.%20Srivastava%2C%20N.%20Interlacing%20families%20II%3A%20Mixed%20characteristic%20polynomials%20and%20the%20Kadison-Singer%20problem%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcus%2C%20A.W.%20Spielman%2C%20D.A.%20Srivastava%2C%20N.%20Interlacing%20families%20II%3A%20Mixed%20characteristic%20polynomials%20and%20the%20Kadison-Singer%20problem%202015"
        },
        {
            "id": "36",
            "entry": "[36] Z. Mariet and S. Sra. Diversity networks. In International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Z%20Mariet%20and%20S%20Sra%20Diversity%20networks%20In%20International%20Conference%20on%20Learning%20Representations%20ICLR%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Z%20Mariet%20and%20S%20Sra%20Diversity%20networks%20In%20International%20Conference%20on%20Learning%20Representations%20ICLR%202016"
        },
        {
            "id": "37",
            "entry": "[37] Z. Mariet and S. Sra. Elementary symmetric polynomials for optimal experimental design. In Advances in Neural Information Processing Systems 30, pages 2136\u20132145. Curran Associates, Inc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mariet%2C%20Z.%20Sra%2C%20S.%20Elementary%20symmetric%20polynomials%20for%20optimal%20experimental%20design%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mariet%2C%20Z.%20Sra%2C%20S.%20Elementary%20symmetric%20polynomials%20for%20optimal%20experimental%20design%202017"
        },
        {
            "id": "38",
            "entry": "[38] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller. Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6): 1087\u20131092, 1953.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Metropolis%2C%20N.%20Rosenbluth%2C%20A.W.%20Rosenbluth%2C%20M.N.%20Teller%2C%20A.H.%20Equation%20of%20state%20calculations%20by%20fast%20computing%20machines%201953",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Metropolis%2C%20N.%20Rosenbluth%2C%20A.W.%20Rosenbluth%2C%20M.N.%20Teller%2C%20A.H.%20Equation%20of%20state%20calculations%20by%20fast%20computing%20machines%201953"
        },
        {
            "id": "39",
            "entry": "[39] B. Micenkov\u00e1, B. McWilliams, and I. Assent. Learning outlier ensembles: The best of both worlds \u2013 supervised and unsupervised. In Proceedings of the ACM SIGKDD 2014 Workshop on outlier Detection and Description under Data Diversity, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Micenkov%C3%A1%2C%20B.%20McWilliams%2C%20B.%20Assent%2C%20I.%20Learning%20outlier%20ensembles%3A%20The%20best%20of%20both%20worlds%20%E2%80%93%20supervised%20and%20unsupervised%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Micenkov%C3%A1%2C%20B.%20McWilliams%2C%20B.%20Assent%2C%20I.%20Learning%20outlier%20ensembles%3A%20The%20best%20of%20both%20worlds%20%E2%80%93%20supervised%20and%20unsupervised%202014"
        },
        {
            "id": "40",
            "entry": "[40] E. Nystr\u00f6m. \u00dcber die praktische Aufl\u00f6sung von Integralgleichungen mit Anwendungen auf Randwertaufgaben. Acta Mathematica, 54(1):185\u2013204, 1930.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nystr%C3%B6m%2C%20E.%20%C3%9Cber%20die%20praktische%20Aufl%C3%B6sung%20von%20Integralgleichungen%20mit%20Anwendungen%20auf%20Randwertaufgaben%201930",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nystr%C3%B6m%2C%20E.%20%C3%9Cber%20die%20praktische%20Aufl%C3%B6sung%20von%20Integralgleichungen%20mit%20Anwendungen%20auf%20Randwertaufgaben%201930"
        },
        {
            "id": "41",
            "entry": "[41] R. Pemantle. Towards a theory of negative dependence. Journal of Mathematical Physics, 41: 1371\u20131390, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pemantle%2C%20R.%20Towards%20a%20theory%20of%20negative%20dependence%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pemantle%2C%20R.%20Towards%20a%20theory%20of%20negative%20dependence%202000"
        },
        {
            "id": "42",
            "entry": "[42] R. Pemantle and Y. Peres. Concentration of Lipschitz functionals of determinantal and other strong Rayleigh measures. Combinatorics, Probability and Computing, 23(1):140160, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pemantle%2C%20R.%20Peres%2C%20Y.%20Concentration%20of%20Lipschitz%20functionals%20of%20determinantal%20and%20other%20strong%20Rayleigh%20measures%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pemantle%2C%20R.%20Peres%2C%20Y.%20Concentration%20of%20Lipschitz%20functionals%20of%20determinantal%20and%20other%20strong%20Rayleigh%20measures%202014"
        },
        {
            "id": "43",
            "entry": "[43] P. Rebeschini and A. Karbasi. Fast mixing for discrete point processes. In Conference on Learning Theory (COLT), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rebeschini%2C%20P.%20Karbasi%2C%20A.%20Fast%20mixing%20for%20discrete%20point%20processes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rebeschini%2C%20P.%20Karbasi%2C%20A.%20Fast%20mixing%20for%20discrete%20point%20processes%202015"
        },
        {
            "id": "44",
            "entry": "[44] T. Shirai and Y. Takahashi. Random point fields associated with certain Fredholm determinants I: fermion, Poisson and boson point processes. Journal of Functional Analysis, 205(2):414\u2013 463, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shirai%2C%20T.%20Takahashi%2C%20Y.%20Random%20point%20fields%20associated%20with%20certain%20Fredholm%20determinants%20I%3A%20fermion%2C%20Poisson%20and%20boson%20point%20processes%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shirai%2C%20T.%20Takahashi%2C%20Y.%20Random%20point%20fields%20associated%20with%20certain%20Fredholm%20determinants%20I%3A%20fermion%2C%20Poisson%20and%20boson%20point%20processes%202003"
        },
        {
            "id": "45",
            "entry": "[45] W. Specht. Zur Theorie der elementaren Mittel. Math. Zeitschr., 74:91\u201398, 1960.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Specht%2C%20W.%20Zur%20Theorie%20der%20elementaren%20Mittel%201960",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Specht%2C%20W.%20Zur%20Theorie%20der%20elementaren%20Mittel%201960"
        },
        {
            "id": "46",
            "entry": "[46] N. Street, W. H. Wolberg, and O. L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Street%2C%20N.%20Wolberg%2C%20W.H.%20Mangasarian%2C%20O.L.%20Nuclear%20feature%20extraction%20for%20breast%20tumor%20diagnosis%201993"
        },
        {
            "id": "47",
            "entry": "[47] C. K. I. Williams and M. Seeger. Using the Nystr\u00f6m method to speed up kernel machines. In Advances in Neural Information Processing Systems 13, pages 682\u2013688. MIT Press, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20C.K.I.%20Seeger%2C%20M.%20Using%20the%20Nystr%C3%B6m%20method%20to%20speed%20up%20kernel%20machines%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20C.K.I.%20Seeger%2C%20M.%20Using%20the%20Nystr%C3%B6m%20method%20to%20speed%20up%20kernel%20machines%202001"
        },
        {
            "id": "48",
            "entry": "[48] T. Zhou, Z. Kuscsik, J.-G. Liu, M. Medo, J. R. Wakeling, and Y.-C. Zhang. Solving the apparent diversity-accuracy dilemma of recommender systems. PNAS, 107(10):4511\u20134515, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20T.%20Kuscsik%2C%20Z.%20Liu%2C%20J.-G.%20Medo%2C%20M.%20Solving%20the%20apparent%20diversity-accuracy%20dilemma%20of%20recommender%20systems%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20T.%20Kuscsik%2C%20Z.%20Liu%2C%20J.-G.%20Medo%2C%20M.%20Solving%20the%20apparent%20diversity-accuracy%20dilemma%20of%20recommender%20systems%202010"
        },
        {
            "id": "49",
            "entry": "[49] J. Y. Zou and R. Adams. Priors for diversity in generative latent variable models. In Advances in Neural Information Processing Systems (NIPS), 2012. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zou%2C%20J.Y.%20Adams%2C%20R.%20Priors%20for%20diversity%20in%20generative%20latent%20variable%20models%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zou%2C%20J.Y.%20Adams%2C%20R.%20Priors%20for%20diversity%20in%20generative%20latent%20variable%20models%202012"
        }
    ]
}
