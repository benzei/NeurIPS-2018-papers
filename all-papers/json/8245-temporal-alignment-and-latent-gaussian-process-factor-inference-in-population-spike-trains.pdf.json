{
    "filename": "8245-temporal-alignment-and-latent-gaussian-process-factor-inference-in-population-spike-trains.pdf",
    "metadata": {
        "title": "Temporal alignment and latent Gaussian process factor inference in population spike trains",
        "author": "Lea Duncker, Maneesh Sahani",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8245-temporal-alignment-and-latent-gaussian-process-factor-inference-in-population-spike-trains.pdf",
            "doi": "10.1101/331751"
        },
        "abstract": "We introduce a novel scalable approach to identifying common latent structure in neural population spike-trains, which allows for variability both in the trajectory and in the rate of progression of the underlying computation. Our approach is based on shared latent Gaussian processes (GPs) which are combined linearly, as in the Gaussian Process Factor Analysis (GPFA) algorithm. We extend GPFA to handle unbinned spike-train data by incorporating a continuous time point-process likelihood model, achieving scalability with a sparse variational approximation. Shared variability is separated into terms that express condition dependence, as well as trial-to-trial variation in trajectories. Finally, we introduce a nested GP formulation to capture variability in the rate of evolution along the trajectory. We show that the new method learns to recover latent trajectories in synthetic data, and can accurately identify the trial-to-trial timing of movement-related parameters from motor cortical data without any supervision."
    },
    "keywords": [
        {
            "term": "point process",
            "url": "https://en.wikipedia.org/wiki/point_process"
        },
        {
            "term": "neural population",
            "url": "https://en.wikipedia.org/wiki/neural_population"
        },
        {
            "term": "Gaussian processes",
            "url": "https://en.wikipedia.org/wiki/Gaussian_processes"
        },
        {
            "term": "spike train",
            "url": "https://en.wikipedia.org/wiki/spike_train"
        },
        {
            "term": "latent variable",
            "url": "https://en.wikipedia.org/wiki/latent_variable"
        },
        {
            "term": "Gaussian process",
            "url": "https://en.wikipedia.org/wiki/Gaussian_process"
        },
        {
            "term": "factor analysis",
            "url": "https://en.wikipedia.org/wiki/factor_analysis"
        },
        {
            "term": "dynamic time warping",
            "url": "https://en.wikipedia.org/wiki/dynamic_time_warping"
        }
    ],
    "highlights": [
        "Many computations in the brain are thought to be implemented by the dynamical evolution of activity distributed across large neural populations",
        "We extend Gaussian Process Factor Analysis (GPFA) [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], an algorithm that has been successfully applied in the context of extracting time-varying low-dimensional latent structure from binned neural population activity on single trials, to directly model the point-process structure of spiking activity",
        "The svGPFA model with point-process likelihood already fully addresses the two major limitations of the classic Gaussian Process Factor Analysis approach outlined in section 2: Firstly, it improves the scalability of the algorithm via the use of inducing points, scaling cubically only in the number of inducing points per latent and linearly in the total number of spiking events",
        "We explicitly model latent structure that is shared across trials or subsets of trials, as well as structure that is specific to each trial, and make use of a nested Gaussian processes architecture with time-warping functions",
        "We have introduced a scalable sparse variational extension of Gaussian Process Factor Analysis, allowing one to extract latent structure directly from the unbinned spike-time observations of simultaneously recorded neurons",
        "We further extended Gaussian Process Factor Analysis using an explicit separation of shared variability into condition-dependent and trial-specific components within a nested Gaussian processes architecture"
    ],
    "key_statements": [
        "Many computations in the brain are thought to be implemented by the dynamical evolution of activity distributed across large neural populations",
        "We develop a novel method to jointly infer shared latent structure directly from the spiking activity of neural populations, allowing for trial-to-trial variations in the timing of the latent processes",
        "We extend Gaussian Process Factor Analysis (GPFA) [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], an algorithm that has been successfully applied in the context of extracting time-varying low-dimensional latent structure from binned neural population activity on single trials, to directly model the point-process structure of spiking activity",
        "The svGPFA model with point-process likelihood already fully addresses the two major limitations of the classic Gaussian Process Factor Analysis approach outlined in section 2: Firstly, it improves the scalability of the algorithm via the use of inducing points, scaling cubically only in the number of inducing points per latent and linearly in the total number of spiking events",
        "The svGPFA model we have developed in section 3 aims to extract different latent trajectories on each trial",
        "We explicitly model latent structure that is shared across trials or subsets of trials, as well as structure that is specific to each trial, and make use of a nested Gaussian processes architecture with time-warping functions",
        "We have introduced a scalable sparse variational extension of Gaussian Process Factor Analysis, allowing one to extract latent structure directly from the unbinned spike-time observations of simultaneously recorded neurons",
        "We further extended Gaussian Process Factor Analysis using an explicit separation of shared variability into condition-dependent and trial-specific components within a nested Gaussian processes architecture",
        "We showed that our svGPFA methods can more accurately recover firing rate estimates than related methods"
    ],
    "summary": [
        "Many computations in the brain are thought to be implemented by the dynamical evolution of activity distributed across large neural populations.",
        "Simultaneous inference and temporal alignment of latent trajectories from multivariate point process observations \u2013 such as a set of spike-times of simultaneously recorded neurons \u2013 is a relatively unexplored area of research.",
        "We develop a novel method to jointly infer shared latent structure directly from the spiking activity of neural populations, allowing for trial-to-trial variations in the timing of the latent processes.",
        "We extend Gaussian Process Factor Analysis (GPFA) [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], an algorithm that has been successfully applied in the context of extracting time-varying low-dimensional latent structure from binned neural population activity on single trials, to directly model the point-process structure of spiking activity.",
        "This extension allows us to infer latent time-warping functions that align trials in a purely unsupervised manner \u2013 that is, using population spiking activity alone with no behavioural covariates.",
        "Inter-trial variability in neural firing that is shared across the population is modelled via the evolution of the latent processes on a given trial.",
        "The form of the variational lower bound in (4) makes it clear that including different observation models only requires taking a Gaussian expectation of the respective log-likelihood.",
        "The svGPFA model with point-process likelihood already fully addresses the two major limitations of the classic GPFA approach outlined in section 2: Firstly, it improves the scalability of the algorithm via the use of inducing points, scaling cubically only in the number of inducing points per latent and linearly in the total number of spiking events.",
        "We can relate hn(\u00b7) to the neuron\u2019s firing rate via a static non-linearity g(\u00b7), and use a point-process observation model for spike times.",
        "While the decomposition into shared, condition-specific and trial-specific latents and the addition of the time-warping layer increases the total number of inducing points that require optimisation, the impact on the time-complexity of the algorithm is minimal: it remains linear in the total number of spikes across trials and neurons, and only cubic in the number of inducing points per individual latent process.",
        "We have introduced a scalable sparse variational extension of GPFA, allowing one to extract latent structure directly from the unbinned spike-time observations of simultaneously recorded neurons.",
        "The problem of latent input alignment in the context of the GP-LVM has recently been considered in [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>], where maximum a posteriori inference in a Gaussian model is used to recover a single true underlying input sequence from multiple observations that are generated from different time-warping functions.",
        "We arrived at a scalable algorithm for posterior inference using inducing points"
    ],
    "headline": "We introduce a novel scalable approach to identifying common latent structure in neural population spike-trains, which allows for variability both in the trajectory and in the rate of progression of the underlying computation",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] MM Churchland, BM Yu, M Sahani, and KV Shenoy. Techniques for extracting single-trial activity patterns from large-scale neural recordings. Current Opinion in Neurobiology, 17(5):609\u2013618, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Churchland%2C%20M.M.%20Yu%2C%20B.M.%20Sahani%2C%20M.%20Shenoy%2C%20K.V.%20Techniques%20for%20extracting%20single-trial%20activity%20patterns%20from%20large-scale%20neural%20recordings%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Churchland%2C%20M.M.%20Yu%2C%20B.M.%20Sahani%2C%20M.%20Shenoy%2C%20K.V.%20Techniques%20for%20extracting%20single-trial%20activity%20patterns%20from%20large-scale%20neural%20recordings%202007"
        },
        {
            "id": "2",
            "entry": "[2] BM Yu, JP Cunningham, G Santhanam, SI Ryu, KV Shenoy, and M Sahani. Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity. Journal of Neurophysiology, 102(1):614\u2013635, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20B.M.%20Cunningham%2C%20J.P.%20Santhanam%2C%20G.%20Ryu%2C%20S.I.%20Gaussian-process%20factor%20analysis%20for%20low-dimensional%20single-trial%20analysis%20of%20neural%20population%20activity%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20B.M.%20Cunningham%2C%20J.P.%20Santhanam%2C%20G.%20Ryu%2C%20S.I.%20Gaussian-process%20factor%20analysis%20for%20low-dimensional%20single-trial%20analysis%20of%20neural%20population%20activity%202009"
        },
        {
            "id": "3",
            "entry": "[3] Y Gao, EW Archer, L Paninski, and JP Cunningham. Linear dynamical neural population models through nonlinear embeddings. In Advances in Neural Information Processing Systems, pp. 163\u2013171, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gao%2C%20Y.%20Archer%2C%20E.W.%20Paninski%2C%20L.%20Cunningham%2C%20J.P.%20Linear%20dynamical%20neural%20population%20models%20through%20nonlinear%20embeddings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gao%2C%20Y.%20Archer%2C%20E.W.%20Paninski%2C%20L.%20Cunningham%2C%20J.P.%20Linear%20dynamical%20neural%20population%20models%20through%20nonlinear%20embeddings%202016"
        },
        {
            "id": "4",
            "entry": "[4] C Pandarinath, DJ O\u2019Shea, J Collins, R Jozefowicz, SD Stavisky, JC Kao, EM Trautmann, MT Kaufman, SI Ryu, LR Hochberg, JM Henderson, KV Shenoy, LF Abbott, and D Sussillo. Inferring single-trial neural population dynamics using sequential auto-encoders. Nature Methods, 15(10):805\u2013815, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pandarinath%2C%20C.%20O%E2%80%99Shea%2C%20D.J.%20Collins%2C%20J.%20Jozefowicz%2C%20R.%20Inferring%20single-trial%20neural%20population%20dynamics%20using%20sequential%20auto-encoders%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pandarinath%2C%20C.%20O%E2%80%99Shea%2C%20D.J.%20Collins%2C%20J.%20Jozefowicz%2C%20R.%20Inferring%20single-trial%20neural%20population%20dynamics%20using%20sequential%20auto-encoders%202018"
        },
        {
            "id": "5",
            "entry": "[5] JH Macke, L Buesing, and M Sahani. Estimating state and parameters in state space models of spike trains. Advanced State Space Methods for Neural and Clinical Data, p. 137, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Macke%2C%20J.H.%20Buesing%2C%20L.%20Sahani%2C%20M.%20Estimating%20state%20and%20parameters%20in%20state%20space%20models%20of%20spike%20trains.%20Advanced%20State%20Space%20Methods%20for%20Neural%20and%20Clinical%20Data%202015"
        },
        {
            "id": "6",
            "entry": "[6] JP Cunningham and BM Yu. Dimensionality reduction for large-scale neural recordings. Nature Neuroscience, 17(11):1500\u20131509, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cunningham%2C%20J.P.%20Yu%2C%20B.M.%20Dimensionality%20reduction%20for%20large-scale%20neural%20recordings%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cunningham%2C%20J.P.%20Yu%2C%20B.M.%20Dimensionality%20reduction%20for%20large-scale%20neural%20recordings%202014"
        },
        {
            "id": "7",
            "entry": "[7] A Afshar, G Santhanam, BM Yu, SI Ryu, M Sahani, and KV Shenoy. Single-trial neural correlates of arm movement preparation. Neuron, 71(3):555\u2013564, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Afshar%2C%20A.%20Santhanam%2C%20G.%20Yu%2C%20B.M.%20Ryu%2C%20S.I.%20Single-trial%20neural%20correlates%20of%20arm%20movement%20preparation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Afshar%2C%20A.%20Santhanam%2C%20G.%20Yu%2C%20B.M.%20Ryu%2C%20S.I.%20Single-trial%20neural%20correlates%20of%20arm%20movement%20preparation%202011"
        },
        {
            "id": "8",
            "entry": "[8] S Kollmorgen and RH Hahnloser. Dynamic alignment models for neural coding. PLoS computational biology, 10(3):e1003508, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kollmorgen%2C%20S.%20Hahnloser%2C%20R.H.%20Dynamic%20alignment%20models%20for%20neural%20coding%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kollmorgen%2C%20S.%20Hahnloser%2C%20R.H.%20Dynamic%20alignment%20models%20for%20neural%20coding%202014"
        },
        {
            "id": "9",
            "entry": "[9] PN Lawlor, MG Perich, LE Miller, and KP Kording. Linear-nonlinear-time-warp-poisson models of neural activity. Journal of Computational Neuroscience, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lawlor%2C%20P.N.%20Perich%2C%20M.G.%20Miller%2C%20L.E.%20Kording%2C%20K.P.%20Linear-nonlinear-time-warp-poisson%20models%20of%20neural%20activity%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lawlor%2C%20P.N.%20Perich%2C%20M.G.%20Miller%2C%20L.E.%20Kording%2C%20K.P.%20Linear-nonlinear-time-warp-poisson%20models%20of%20neural%20activity%202018"
        },
        {
            "id": "10",
            "entry": "[10] B Poole, A Williams, N Maheswaranathan, BM Yu, G Santhanam, S Ryu, SA Baccus, K Shenoy, and S Ganguli. Time-warped PCA: simultaneous alignment and dimensionality reduction of neural data. In Frontiers in Neuroscience. Computational and Systems Neuroscience (COSYNE), Salt Lake City, UT, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Poole%2C%20B.%20Williams%2C%20A.%20Maheswaranathan%2C%20N.%20Yu%2C%20B.M.%20Time-warped%20PCA%3A%20simultaneous%20alignment%20and%20dimensionality%20reduction%20of%20neural%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Poole%2C%20B.%20Williams%2C%20A.%20Maheswaranathan%2C%20N.%20Yu%2C%20B.M.%20Time-warped%20PCA%3A%20simultaneous%20alignment%20and%20dimensionality%20reduction%20of%20neural%20data%202017"
        },
        {
            "id": "11",
            "entry": "[11] H Sakoe and S Chiba. Dynamic programming algorithm optimization for spoken word recognition. IEEE Transactions on Acoustics, Speech, and Signal Processing, 26(1):43\u201349, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sakoe%2C%20H.%20Chiba%2C%20S.%20Dynamic%20programming%20algorithm%20optimization%20for%20spoken%20word%20recognition%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sakoe%2C%20H.%20Chiba%2C%20S.%20Dynamic%20programming%20algorithm%20optimization%20for%20spoken%20word%20recognition%201978"
        },
        {
            "id": "12",
            "entry": "[12] EJ Keogh and MJ Pazzani. Derivative dynamic time warping. In Proceedings of the 2001 SIAM International Conference on Data Mining, pp. 1\u201311. SIAM, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Keogh%2C%20E.J.%20Pazzani%2C%20M.J.%20Derivative%20dynamic%20time%20warping%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Keogh%2C%20E.J.%20Pazzani%2C%20M.J.%20Derivative%20dynamic%20time%20warping%202001"
        },
        {
            "id": "13",
            "entry": "[13] E Hsu, K Pulli, and J Popovic. Style translation for human motion. In ACM Transactions on Graphics (TOG), vol. 24, pp. 1082\u20131089. ACM, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hsu%2C%20E.%20Pulli%2C%20K.%20Popovic%2C%20J.%20Style%20translation%20for%20human%20motion%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hsu%2C%20E.%20Pulli%2C%20K.%20Popovic%2C%20J.%20Style%20translation%20for%20human%20motion%202005"
        },
        {
            "id": "14",
            "entry": "[14] M Cuturi and M Blondel. Soft-DTW: a differentiable loss function for time-series. In Proceedings of the 34th International Conference on Machine Learning, pp. 894\u2013903, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cuturi%2C%20M.%20Blondel%2C%20M.%20Soft-DTW%3A%20a%20differentiable%20loss%20function%20for%20time-series%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cuturi%2C%20M.%20Blondel%2C%20M.%20Soft-DTW%3A%20a%20differentiable%20loss%20function%20for%20time-series%202017"
        },
        {
            "id": "15",
            "entry": "[15] F Zhou and F De la Torre. Generalized canonical time warping. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(2):279\u2013294, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20F.%20la%20Torre%2C%20F.De%20Generalized%20canonical%20time%20warping%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20F.%20la%20Torre%2C%20F.De%20Generalized%20canonical%20time%20warping%202016"
        },
        {
            "id": "16",
            "entry": "[16] M L\u00e1zaro-Gredilla. Bayesian warped Gaussian processes. In F Pereira, CJC Burges, L Bottou, and KQ Weinberger, eds., Advances in Neural Information Processing Systems 25, pp. 1619\u20131627. Curran Associates, Inc., 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=L%C3%A1zaro-Gredilla%2C%20M.%20Bayesian%20warped%20Gaussian%20processes%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=L%C3%A1zaro-Gredilla%2C%20M.%20Bayesian%20warped%20Gaussian%20processes%202012"
        },
        {
            "id": "17",
            "entry": "[17] J Snoek, K Swersky, R Zemel, and R Adams. Input warping for Bayesian optimization of non-stationary functions. In Proceedings of the 31st International Conference on Machine Learning, pp. 1674\u20131682, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Snoek%2C%20J.%20Swersky%2C%20K.%20Zemel%2C%20R.%20Adams%2C%20R.%20Input%20warping%20for%20Bayesian%20optimization%20of%20non-stationary%20functions%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Snoek%2C%20J.%20Swersky%2C%20K.%20Zemel%2C%20R.%20Adams%2C%20R.%20Input%20warping%20for%20Bayesian%20optimization%20of%20non-stationary%20functions%202014"
        },
        {
            "id": "18",
            "entry": "[18] M Kaiser, C Otte, T Runkler, and CH Ek. Bayesian alignments of warped multi-output Gaussian processes. arXiv preprint arXiv:1710.02766, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.02766"
        },
        {
            "id": "19",
            "entry": "[19] A Arribas-Gil and HG M\u00fcller. Pairwise dynamic time warping for event data. Computational Statistics & Data Analysis, 69:255\u2013268, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20A%20Arribas-Gil%20and%20HG%20M%C3%BCller.%20Pairwise%20dynamic%20time%20warping%20for%20event%20data%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20A%20Arribas-Gil%20and%20HG%20M%C3%BCller.%20Pairwise%20dynamic%20time%20warping%20for%20event%20data%202014"
        },
        {
            "id": "20",
            "entry": "[20] VM Panaretos, Y Zemel, et al. Amplitude and phase variation of point processes. The Annals of Statistics, 44(2):771\u2013812, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Panaretos%2C%20V.M.%20Zemel%2C%20Y.%20Amplitude%20and%20phase%20variation%20of%20point%20processes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Panaretos%2C%20V.M.%20Zemel%2C%20Y.%20Amplitude%20and%20phase%20variation%20of%20point%20processes%202016"
        },
        {
            "id": "21",
            "entry": "[21] W Wu and A Srivastava. Estimating summary statistics in the spike-train space. Journal of Computational Neuroscience, 34(3):391\u2013410, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20W.%20Srivastava%2C%20A.%20Estimating%20summary%20statistics%20in%20the%20spike-train%20space%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20W.%20Srivastava%2C%20A.%20Estimating%20summary%20statistics%20in%20the%20spike-train%20space%202013"
        },
        {
            "id": "22",
            "entry": "[22] Y Zemel and VM Panaretos. Fr\u00e9chet means and procrustes analysis in wasserstein space. arXiv preprint arXiv:1701.06876, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.06876"
        },
        {
            "id": "23",
            "entry": "[23] Y Zhao and IM Park. Variational latent Gaussian process for recovering single-trial dynamics from population spike trains. Neural Computation, 29(5):1293\u20131316, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Y.%20Park%2C%20I.M.%20Variational%20latent%20Gaussian%20process%20for%20recovering%20single-trial%20dynamics%20from%20population%20spike%20trains%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Y.%20Park%2C%20I.M.%20Variational%20latent%20Gaussian%20process%20for%20recovering%20single-trial%20dynamics%20from%20population%20spike%20trains%202017"
        },
        {
            "id": "24",
            "entry": "[24] M Opper and C Archambeau. The variational Gaussian approximation revisited. Neural Computation, 21(3):786\u2013792, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Opper%2C%20M.%20Archambeau%2C%20C.%20The%20variational%20Gaussian%20approximation%20revisited%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Opper%2C%20M.%20Archambeau%2C%20C.%20The%20variational%20Gaussian%20approximation%20revisited%202009"
        },
        {
            "id": "25",
            "entry": "[25] MK Titsias. Variational learning of inducing variables in sparse Gaussian processes. In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics, pp. 567\u2013574, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Titsias%2C%20M.K.%20Variational%20learning%20of%20inducing%20variables%20in%20sparse%20Gaussian%20processes%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Titsias%2C%20M.K.%20Variational%20learning%20of%20inducing%20variables%20in%20sparse%20Gaussian%20processes%202009"
        },
        {
            "id": "26",
            "entry": "[26] V Adam, J Hensman, and M Sahani. Scalable transformed additive signal decomposition by non-conjugate Gaussian process inference. In Proceedings of the 26th International Workshop on Machine Learning for Signal Processing (MLSP), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Adam%2C%20V.%20Hensman%2C%20J.%20Sahani%2C%20M.%20Scalable%20transformed%20additive%20signal%20decomposition%20by%20non-conjugate%20Gaussian%20process%20inference%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Adam%2C%20V.%20Hensman%2C%20J.%20Sahani%2C%20M.%20Scalable%20transformed%20additive%20signal%20decomposition%20by%20non-conjugate%20Gaussian%20process%20inference%202016"
        },
        {
            "id": "27",
            "entry": "[27] C Lloyd, T Gunter, MA Osborne, and SJ Roberts. Variational inference for Gaussian process modulated Poisson processes. In Proceedings of the 32nd International Conference on Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lloyd%2C%20C.%20Gunter%2C%20T.%20Osborne%2C%20M.A.%20Roberts%2C%20S.J.%20Variational%20inference%20for%20Gaussian%20process%20modulated%20Poisson%20processes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lloyd%2C%20C.%20Gunter%2C%20T.%20Osborne%2C%20M.A.%20Roberts%2C%20S.J.%20Variational%20inference%20for%20Gaussian%20process%20modulated%20Poisson%20processes%202015"
        },
        {
            "id": "28",
            "entry": "[28] J Hensman, N Fusi, and ND Lawrence. Gaussian processes for big data. In Conference on Uncertainty in Artificial Intellegence, pp. 282\u2013290. auai.org, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hensman%2C%20J.%20Fusi%2C%20N.%20Lawrence%2C%20N.D.%20Gaussian%20processes%20for%20big%20data%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hensman%2C%20J.%20Fusi%2C%20N.%20Lawrence%2C%20N.D.%20Gaussian%20processes%20for%20big%20data%202013"
        },
        {
            "id": "29",
            "entry": "[29] J Hensman, AGdG Matthews, and Z Ghahramani. Scalable variational Gaussian process classification. In Proceedings of the 18th International Conference on Artificial Intelligence and Statistics, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hensman%2C%20J.%20Matthews%2C%20AGdG%20Ghahramani%2C%20Z.%20Scalable%20variational%20Gaussian%20process%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hensman%2C%20J.%20Matthews%2C%20AGdG%20Ghahramani%2C%20Z.%20Scalable%20variational%20Gaussian%20process%20classification%202015"
        },
        {
            "id": "30",
            "entry": "[30] AD Saul, J Hensman, A Vehtari, and ND Lawrence. Chained Gaussian processes. In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, pp. 1431\u20131440, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saul%2C%20A.D.%20Hensman%2C%20J.%20Vehtari%2C%20A.%20Lawrence%2C%20N.D.%20Chained%20Gaussian%20processes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saul%2C%20A.D.%20Hensman%2C%20J.%20Vehtari%2C%20A.%20Lawrence%2C%20N.D.%20Chained%20Gaussian%20processes%202016"
        },
        {
            "id": "31",
            "entry": "[31] G Mena and L Paninski. On quadrature methods for refractory point process likelihoods. Neural Computation, 26(12):2790\u20132797, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mena%2C%20G.%20Paninski%2C%20L.%20On%20quadrature%20methods%20for%20refractory%20point%20process%20likelihoods%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mena%2C%20G.%20Paninski%2C%20L.%20On%20quadrature%20methods%20for%20refractory%20point%20process%20likelihoods%202014"
        },
        {
            "id": "32",
            "entry": "[32] P Abbott. Tricks of the trade: Legendre-gauss quadrature. Mathematica Journal, 9(4):689\u2013691, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbott%2C%20P.%20Tricks%20of%20the%20trade%3A%20Legendre-gauss%20quadrature%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abbott%2C%20P.%20Tricks%20of%20the%20trade%3A%20Legendre-gauss%20quadrature%202005"
        },
        {
            "id": "33",
            "entry": "[33] A Damianou and N Lawrence. Deep Gaussian processes. In Proceedings of the 16th International Conference on Artificial Intelligence and Statistics, pp. 207\u2013215, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20A%20Damianou%20and%20N%20Lawrence.%20Deep%20Gaussian%20processes%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20A%20Damianou%20and%20N%20Lawrence.%20Deep%20Gaussian%20processes%202013"
        },
        {
            "id": "34",
            "entry": "[34] H Salimbeni and M Deisenroth. Doubly stochastic variational inference for deep Gaussian processes. In Advances in Neural Information Processing Systems, pp. 4591\u20134602, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimbeni%2C%20H.%20Deisenroth%2C%20M.%20Doubly%20stochastic%20variational%20inference%20for%20deep%20Gaussian%20processes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimbeni%2C%20H.%20Deisenroth%2C%20M.%20Doubly%20stochastic%20variational%20inference%20for%20deep%20Gaussian%20processes%202017"
        },
        {
            "id": "35",
            "entry": "[35] MK Titsias and ND Lawrence. Bayesian Gaussian process latent variable model. In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics, pp. 844\u2013851, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Titsias%2C%20M.K.%20Lawrence%2C%20N.D.%20Bayesian%20Gaussian%20process%20latent%20variable%20model%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Titsias%2C%20M.K.%20Lawrence%2C%20N.D.%20Bayesian%20Gaussian%20process%20latent%20variable%20model%202010"
        },
        {
            "id": "36",
            "entry": "[36] B Petreska, BM Yu, JP Cunningham, G Santhanam, SI Ryu, KV Shenoy, and M Sahani. Dynamical segmentation of single trials from population neural data. In Advances in Neural Information Processing Systems, pp. 756\u2013764, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Petreska%2C%20B.%20Yu%2C%20B.M.%20Cunningham%2C%20J.P.%20Santhanam%2C%20G.%20Dynamical%20segmentation%20of%20single%20trials%20from%20population%20neural%20data%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Petreska%2C%20B.%20Yu%2C%20B.M.%20Cunningham%2C%20J.P.%20Santhanam%2C%20G.%20Dynamical%20segmentation%20of%20single%20trials%20from%20population%20neural%20data%202011"
        },
        {
            "id": "37",
            "entry": "[37] MM Churchland, JP Cunningham, MT Kaufman, JD Foster, P Nuyujukian, SI Ryu, and KV Shenoy. Neural population dynamics during reaching. Nature, 487(7405):51, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Churchland%2C%20M.M.%20Cunningham%2C%20J.P.%20Kaufman%2C%20M.T.%20Foster%2C%20J.D.%20Neural%20population%20dynamics%20during%20reaching%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Churchland%2C%20M.M.%20Cunningham%2C%20J.P.%20Kaufman%2C%20M.T.%20Foster%2C%20J.D.%20Neural%20population%20dynamics%20during%20reaching%202012"
        },
        {
            "id": "38",
            "entry": "[38] A Wu, NG Roy, S Keeley, and JW Pillow. Gaussian process based nonlinear latent structure discovery in multivariate spike train data. In Advances in Neural Information Processing Systems, pp. 3499\u20133508, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20A.%20Roy%2C%20N.G.%20Keeley%2C%20S.%20Pillow%2C%20J.W.%20Gaussian%20process%20based%20nonlinear%20latent%20structure%20discovery%20in%20multivariate%20spike%20train%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20A.%20Roy%2C%20N.G.%20Keeley%2C%20S.%20Pillow%2C%20J.W.%20Gaussian%20process%20based%20nonlinear%20latent%20structure%20discovery%20in%20multivariate%20spike%20train%20data%202017"
        },
        {
            "id": "39",
            "entry": "[39] I Kazlauskaite, CH Ek, and ND Campbell. Gaussian process latent variable alignment learning. arXiv preprint arXiv:1803.02603, 2018. ",
            "arxiv_url": "https://arxiv.org/pdf/1803.02603"
        }
    ]
}
