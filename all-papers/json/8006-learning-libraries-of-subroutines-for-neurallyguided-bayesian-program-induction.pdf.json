{
    "filename": "8006-learning-libraries-of-subroutines-for-neurallyguided-bayesian-program-induction.pdf",
    "metadata": {
        "title": "Learning Libraries of Subroutines for Neurally\u2013Guided Bayesian Program Induction",
        "author": "Kevin Ellis, Lucas Morales, Mathias Sabl\u00e9-Meyer, Armando Solar-Lezama, Josh Tenenbaum",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8006-learning-libraries-of-subroutines-for-neurallyguided-bayesian-program-induction.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Successful approaches to program induction require a hand-engineered domainspecific language (DSL), constraining the space of allowed programs and imparting prior knowledge of the domain. We contribute a program induction algorithm called EC2 that learns a DSL while jointly training a neural network to efficiently search for programs in the learned DSL. We use our model to synthesize functions on lists, edit text, and solve symbolic regression problems, showing how the model learns a domain-specific library of program components for expressing solutions to problems in the domain."
    },
    "keywords": [
        {
            "term": "program synthesis",
            "url": "https://en.wikipedia.org/wiki/program_synthesis"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "Domain Specific Language",
            "url": "https://en.wikipedia.org/wiki/Domain_Specific_Language"
        },
        {
            "term": "text editing",
            "url": "https://en.wikipedia.org/wiki/text_editing"
        },
        {
            "term": "maximum a posteriori",
            "url": "https://en.wikipedia.org/wiki/maximum_a_posteriori"
        }
    ],
    "highlights": [
        "Much of everyday human thinking and learning can be understood in terms of program induction: constructing a procedure that maps inputs to desired outputs, based on observing example inputoutput pairs",
        "The neural network functions as a recognition model supporting a form of approximate Bayesian program induction, jointly trained with a generative model for programs encoded in the Domain Specific Language, in the spirit of the Helmholtz machine [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>])",
        "The purpose of this ablation study is both to examine the role of each component of EC2, as well as to compare with prior approaches in the literature: a head-to-head comparison of program synthesizers is complicated by the fact that each system, including ours, makes idiosyncratic assumptions about the space of programs and the statement of tasks",
        "NPS, which does not learn the Domain Specific Language, instead learning the recognition model from samples drawn from the fixed Domain Specific Language",
        "EC2, that learns to program by bootstrapping a Domain Specific Language with new domainspecific primitives that the algorithm itself discovers, together with a neural recognition model that learns how to efficiently deploy the Domain Specific Language on new tasks",
        "If program induction is to become a standard part of the AI toolkit, in the long-term, we need to build agents that autonomously acquire the knowledge needed to navigate a new domain"
    ],
    "key_statements": [
        "Much of everyday human thinking and learning can be understood in terms of program induction: constructing a procedure that maps inputs to desired outputs, based on observing example inputoutput pairs",
        "The neural network functions as a recognition model supporting a form of approximate Bayesian program induction, jointly trained with a generative model for programs encoded in the Domain Specific Language, in the spirit of the Helmholtz machine [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>])",
        "The purpose of this ablation study is both to examine the role of each component of EC2, as well as to compare with prior approaches in the literature: a head-to-head comparison of program synthesizers is complicated by the fact that each system, including ours, makes idiosyncratic assumptions about the space of programs and the statement of tasks",
        "NPS, which does not learn the Domain Specific Language, instead learning the recognition model from samples drawn from the fixed Domain Specific Language",
        "EC2, that learns to program by bootstrapping a Domain Specific Language with new domainspecific primitives that the algorithm itself discovers, together with a neural recognition model that learns how to efficiently deploy the Domain Specific Language on new tasks",
        "If program induction is to become a standard part of the AI toolkit, in the long-term, we need to build agents that autonomously acquire the knowledge needed to navigate a new domain"
    ],
    "summary": [
        "Much of everyday human thinking and learning can be understood in terms of program induction: constructing a procedure that maps inputs to desired outputs, based on observing example inputoutput pairs.",
        "The neural network functions as a recognition model supporting a form of approximate Bayesian program induction, jointly trained with a generative model for programs encoded in the DSL, in the spirit of the Helmholtz machine [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>]).",
        "We find EC motivating, and go beyond it and other prior work through the following contributions: (1) We show how to learn-to-learn programs in an expressive Lisp-like programming language, including conditionals, variables, and higher-order recursive functions; (2) We give an algorithm for learning DSLs, built on a formalism known as Fragment Grammars [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]; and (3) We give a hierarchical Bayesian framing of the problem that allows joint inference of the DSL and neural recognition model.",
        "We have two reasons: (1) A key point of our work is that learning the DSL, along with a neural recognition model, can make program induction tractable, even if the search algorithm is very simple.",
        "SyGuS comes with a different hand-engineered DSL for each text editing problem.1 Here we learned a single DSL that applied generically to all of the tasks, and perform comparably to the best prior work.",
        "We con-% solved 94% 79% 71% 35% 62% 37% sistently improve on the baselines, and Solve time 88s 39s 11s 35s 44s 20s find that lesioning the recognition model impairs the convergence of the algorithm, % solved 74% 43% 30% 33% 0% 4% causing it to hit a lower \u2018plateau\u2019 after Solve time 29s 49s 38s 80s \u2013 235s which it stops solving new tasks, following an initial spurt of learning (Fig. 4) \u2013 without the neural network, search becomes in-",
        "Our work considers a weaklysupervised regime where ground truth programs are not provided and the agent must learn from at most a few hundred tasks, which is facilitated by our \u201cHelmholtz machine\u201d style recognition model.",
        "EC2, that learns to program by bootstrapping a DSL with new domainspecific primitives that the algorithm itself discovers, together with a neural recognition model that learns how to efficiently deploy the DSL on new tasks.",
        "Two immediate goals are to integrate more sophisticated neural recognition models [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>] and program synthesizers [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], which may improve performance in some domains over the generic methods used here: while our focus in this work was learning to quickly write small programs, we believe more sophisticated neural models, coupled with more powerful program search algorithms, could extend our approach to synthesize larger bodies of code."
    ],
    "headline": "For each of these we initially provide a generic set of programming primitives",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sumit Gulwani. Automating string processing in spreadsheets using input-output examples. In ACM SIGPLAN Notices, volume 46, pages 317\u2013330. ACM, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulwani%2C%20Sumit%20Automating%20string%20processing%20in%20spreadsheets%20using%20input-output%20examples%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulwani%2C%20Sumit%20Automating%20string%20processing%20in%20spreadsheets%20using%20input-output%20examples%202011"
        },
        {
            "id": "2",
            "entry": "[2] Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning through probabilistic program induction. Science, 350(6266):1332\u20131338, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brenden%20M.%20Salakhutdinov%2C%20Ruslan%20Tenenbaum%2C%20Joshua%20B.%20Human-level%20concept%20learning%20through%20probabilistic%20program%20induction%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brenden%20M.%20Salakhutdinov%2C%20Ruslan%20Tenenbaum%2C%20Joshua%20B.%20Human-level%20concept%20learning%20through%20probabilistic%20program%20induction%202015"
        },
        {
            "id": "3",
            "entry": "[3] Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Joshua B Tenenbaum. Learning to infer graphics programs from hand-drawn images. NIPS, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20Kevin%20Ritchie%2C%20Daniel%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Joshua%20B.%20Learning%20to%20infer%20graphics%20programs%20from%20hand-drawn%20images%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ellis%2C%20Kevin%20Ritchie%2C%20Daniel%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Joshua%20B.%20Learning%20to%20infer%20graphics%20programs%20from%20hand-drawn%20images%202018"
        },
        {
            "id": "4",
            "entry": "[4] Ute Schmid and Emanuel Kitzelmann. Inductive rule learning on the knowledge level. Cognitive Systems Research, 12(3-4):237\u2013248, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmid%2C%20Ute%20Kitzelmann%2C%20Emanuel%20Inductive%20rule%20learning%20on%20the%20knowledge%20level%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmid%2C%20Ute%20Kitzelmann%2C%20Emanuel%20Inductive%20rule%20learning%20on%20the%20knowledge%20level%202011"
        },
        {
            "id": "5",
            "entry": "[5] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In CVPR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning.%20In%20CVPR"
        },
        {
            "id": "6",
            "entry": "[6] Jacob Devlin, Rudy R Bunel, Rishabh Singh, Matthew Hausknecht, and Pushmeet Kohli. Neural program meta-induction. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jacob%20Devlin%20Rudy%20R%20Bunel%20Rishabh%20Singh%20Matthew%20Hausknecht%20and%20Pushmeet%20Kohli%20Neural%20program%20metainduction%20In%20NIPS%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jacob%20Devlin%20Rudy%20R%20Bunel%20Rishabh%20Singh%20Matthew%20Hausknecht%20and%20Pushmeet%20Kohli%20Neural%20program%20metainduction%20In%20NIPS%202017"
        },
        {
            "id": "7",
            "entry": "[7] Armando Solar Lezama. Program Synthesis By Sketching. PhD thesis, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lezama%2C%20Armando%20Solar%20Program%20Synthesis%20By%20Sketching%202008"
        },
        {
            "id": "8",
            "entry": "[8] John R. Koza. Genetic programming - on the programming of computers by means of natural selection. MIT Press, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koza%2C%20John%20R.%20Genetic%20programming%20-%20on%20the%20programming%20of%20computers%20by%20means%20of%20natural%20selection%201993"
        },
        {
            "id": "9",
            "entry": "[9] Tuan Anh Le, At\u0131l\u0131m G\u00fcnes Baydin, and Frank Wood. Inference Compilation and Universal Probabilistic Programming. In AISTATS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tuan%20Anh%20Le%20At%C4%B1l%C4%B1m%20G%C3%BCnes%20Baydin%20and%20Frank%20Wood%20Inference%20Compilation%20and%20Universal%20Probabilistic%20Programming%20In%20AISTATS%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tuan%20Anh%20Le%20At%C4%B1l%C4%B1m%20G%C3%BCnes%20Baydin%20and%20Frank%20Wood%20Inference%20Compilation%20and%20Universal%20Probabilistic%20Programming%20In%20AISTATS%202017"
        },
        {
            "id": "10",
            "entry": "[10] Andreas Stuhlm\u00fcller, Jacob Taylor, and Noah Goodman. Learning stochastic inverses. NIPS, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stuhlm%C3%BCller%2C%20Andreas%20Taylor%2C%20Jacob%20Goodman%2C%20Noah%20Learning%20stochastic%20inverses%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stuhlm%C3%BCller%2C%20Andreas%20Taylor%2C%20Jacob%20Goodman%2C%20Noah%20Learning%20stochastic%20inverses%202013"
        },
        {
            "id": "11",
            "entry": "[11] Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. The \"wake-sleep\" algorithm for unsupervised neural networks. Science, 268(5214):1158\u20131161, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20E.%20Dayan%2C%20Peter%20Frey%2C%20Brendan%20J.%20Neal%2C%20Radford%20M.%20The%20%22wake-sleep%22%20algorithm%20for%20unsupervised%20neural%20networks%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20Geoffrey%20E.%20Dayan%2C%20Peter%20Frey%2C%20Brendan%20J.%20Neal%2C%20Radford%20M.%20The%20%22wake-sleep%22%20algorithm%20for%20unsupervised%20neural%20networks%201995"
        },
        {
            "id": "12",
            "entry": "[12] Stephen H Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of higher-order dyadic datalog: Predicate invention revisited. Machine Learning, 100(1):49\u201373, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Muggleton%2C%20Stephen%20H.%20Lin%2C%20Dianhuan%20Tamaddoni-Nezhad%2C%20Alireza%20Meta-interpretive%20learning%20of%20higher-order%20dyadic%20datalog%3A%20Predicate%20invention%20revisited%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muggleton%2C%20Stephen%20H.%20Lin%2C%20Dianhuan%20Tamaddoni-Nezhad%2C%20Alireza%20Meta-interpretive%20learning%20of%20higher-order%20dyadic%20datalog%3A%20Predicate%20invention%20revisited%202015"
        },
        {
            "id": "13",
            "entry": "[13] Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and Pushmeet Kohli. Robustfill: Neural program learning under noisy i/o. ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Devlin%2C%20Jacob%20Uesato%2C%20Jonathan%20Bhupatiraju%2C%20Surya%20Singh%2C%20Rishabh%20Robustfill%3A%20Neural%20program%20learning%20under%20noisy%20i/o%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Devlin%2C%20Jacob%20Uesato%2C%20Jonathan%20Bhupatiraju%2C%20Surya%20Singh%2C%20Rishabh%20Robustfill%3A%20Neural%20program%20learning%20under%20noisy%20i/o%202017"
        },
        {
            "id": "14",
            "entry": "[14] Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra, Prateek Jain, and Sumit Gulwani. Neural-guided deductive search for real-time program synthesis from examples. ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kalyan%2C%20Ashwin%20Mohta%2C%20Abhishek%20Polozov%2C%20Oleksandr%20Batra%2C%20Dhruv%20Neural-guided%20deductive%20search%20for%20real-time%20program%20synthesis%20from%20examples%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kalyan%2C%20Ashwin%20Mohta%2C%20Abhishek%20Polozov%2C%20Oleksandr%20Batra%2C%20Dhruv%20Neural-guided%20deductive%20search%20for%20real-time%20program%20synthesis%20from%20examples%202018"
        },
        {
            "id": "15",
            "entry": "[15] Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. Deepcoder: Learning to write programs. ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balog%2C%20Matej%20Gaunt%2C%20Alexander%20L.%20Brockschmidt%2C%20Marc%20Nowozin%2C%20Sebastian%20Deepcoder%3A%20Learning%20to%20write%20programs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balog%2C%20Matej%20Gaunt%2C%20Alexander%20L.%20Brockschmidt%2C%20Marc%20Nowozin%2C%20Sebastian%20Deepcoder%3A%20Learning%20to%20write%20programs%202016"
        },
        {
            "id": "16",
            "entry": "[16] Eyal Dechter, Jon Malmaud, Ryan P. Adams, and Joshua B. Tenenbaum. Bootstrap learning via modular concept discovery. In IJCAI, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dechter%2C%20Eyal%20Malmaud%2C%20Jon%20Adams%2C%20Ryan%20P.%20Tenenbaum%2C%20Joshua%20B.%20Bootstrap%20learning%20via%20modular%20concept%20discovery%202013"
        },
        {
            "id": "17",
            "entry": "[17] Timothy J. O\u2019Donnell. Productivity and Reuse in Language: A Theory of Linguistic Computation and Storage. The MIT Press, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=O%E2%80%99Donnell%2C%20Timothy%20J.%20Productivity%20and%20Reuse%20in%20Language%3A%20A%20Theory%20of%20Linguistic%20Computation%20and%20Storage%202015"
        },
        {
            "id": "18",
            "entry": "[18] Benjamin C. Pierce. Types and programming languages. MIT Press, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pierce%2C%20Benjamin%20C.%20Types%20and%20programming%20languages%202002"
        },
        {
            "id": "19",
            "entry": "[19] Eric Schkufza, Rahul Sharma, and Alex Aiken. Stochastic superoptimization. In ACM SIGARCH Computer Architecture News, volume 41, pages 305\u2013316. ACM, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schkufza%2C%20Eric%20Sharma%2C%20Rahul%20Aiken%2C%20Alex%20Stochastic%20superoptimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schkufza%2C%20Eric%20Sharma%2C%20Rahul%20Aiken%2C%20Alex%20Stochastic%20superoptimization%202013"
        },
        {
            "id": "20",
            "entry": "[20] John K Feser, Swarat Chaudhuri, and Isil Dillig. Synthesizing data structure transformations from inputoutput examples. In PLDI, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feser%2C%20John%20K.%20Chaudhuri%2C%20Swarat%20Dillig%2C%20Isil%20Synthesizing%20data%20structure%20transformations%20from%20inputoutput%20examples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feser%2C%20John%20K.%20Chaudhuri%2C%20Swarat%20Dillig%2C%20Isil%20Synthesizing%20data%20structure%20transformations%20from%20inputoutput%20examples%202015"
        },
        {
            "id": "21",
            "entry": "[21] Peter-Michael Osera and Steve Zdancewic. Type-and-example-directed program synthesis. In ACM SIGPLAN Notices, volume 50, pages 619\u2013630. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Osera%2C%20Peter-Michael%20Zdancewic%2C%20Steve%20Type-and-example-directed%20program%20synthesis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Osera%2C%20Peter-Michael%20Zdancewic%2C%20Steve%20Type-and-example-directed%20program%20synthesis%202015"
        },
        {
            "id": "22",
            "entry": "[22] Oleksandr Polozov and Sumit Gulwani. Flashmeta: A framework for inductive program synthesis. ACM SIGPLAN Notices, 50(10):107\u2013126, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Polozov%2C%20Oleksandr%20Gulwani%2C%20Sumit%20Flashmeta%3A%20A%20framework%20for%20inductive%20program%20synthesis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Polozov%2C%20Oleksandr%20Gulwani%2C%20Sumit%20Flashmeta%3A%20A%20framework%20for%20inductive%20program%20synthesis%202015"
        },
        {
            "id": "23",
            "entry": "[23] Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama. Program synthesis from polymorphic refinement types. ACM SIGPLAN Notices, 51(6):522\u2013538, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Polikarpova%2C%20Nadia%20Kuraj%2C%20Ivan%20Solar-Lezama%2C%20Armando%20Program%20synthesis%20from%20polymorphic%20refinement%20types%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Polikarpova%2C%20Nadia%20Kuraj%2C%20Ivan%20Solar-Lezama%2C%20Armando%20Program%20synthesis%20from%20polymorphic%20refinement%20types%202016"
        },
        {
            "id": "24",
            "entry": "[24] Aditya Menon, Omer Tamuz, Sumit Gulwani, Butler Lampson, and Adam Kalai. A machine learning framework for programming by example. In ICML, pages 187\u2013195, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Menon%2C%20Aditya%20Tamuz%2C%20Omer%20Gulwani%2C%20Sumit%20Lampson%2C%20Butler%20A%20machine%20learning%20framework%20for%20programming%20by%20example%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Menon%2C%20Aditya%20Tamuz%2C%20Omer%20Gulwani%2C%20Sumit%20Lampson%2C%20Butler%20A%20machine%20learning%20framework%20for%20programming%20by%20example%202013"
        },
        {
            "id": "25",
            "entry": "[25] Peter Dayan, Geoffrey E Hinton, Radford M Neal, and Richard S Zemel. The helmholtz machine. Neural computation, 7(5):889\u2013904, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dayan%2C%20Peter%20Hinton%2C%20Geoffrey%20E.%20Neal%2C%20Radford%20M.%20Zemel%2C%20Richard%20S.%20The%20helmholtz%20machine%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dayan%2C%20Peter%20Hinton%2C%20Geoffrey%20E.%20Neal%2C%20Radford%20M.%20Zemel%2C%20Richard%20S.%20The%20helmholtz%20machine%201995"
        },
        {
            "id": "26",
            "entry": "[26] Dianhuan Lin, Eyal Dechter, Kevin Ellis, Joshua B. Tenenbaum, and Stephen Muggleton. Bias reformulation for one-shot function induction. In ECAI 2014, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Dianhuan%20Dechter%2C%20Eyal%20Ellis%2C%20Kevin%20Tenenbaum%2C%20Joshua%20B.%20Bias%20reformulation%20for%20one-shot%20function%20induction%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Dianhuan%20Dechter%2C%20Eyal%20Ellis%2C%20Kevin%20Tenenbaum%2C%20Joshua%20B.%20Bias%20reformulation%20for%20one-shot%20function%20induction%202014"
        },
        {
            "id": "27",
            "entry": "[27] Trevor Cohn, Phil Blunsom, and Sharon Goldwater. Inducing tree-substitution grammars. JMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohn%2C%20Trevor%20Blunsom%2C%20Phil%20Goldwater%2C%20Sharon%20Inducing%20tree-substitution%20grammars",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohn%2C%20Trevor%20Blunsom%2C%20Phil%20Goldwater%2C%20Sharon%20Inducing%20tree-substitution%20grammars"
        },
        {
            "id": "28",
            "entry": "[28] Robert John Henderson. Cumulative learning in the lambda calculus. PhD thesis, Imperial College London, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henderson%2C%20Robert%20John%20Cumulative%20learning%20in%20the%20lambda%20calculus%202013"
        },
        {
            "id": "29",
            "entry": "[29] Irvin Hwang, Andreas Stuhlm\u00fcller, and Noah D Goodman. Inducing probabilistic programs by bayesian program merging. arXiv preprint arXiv:1110.5667, 2011.",
            "arxiv_url": "https://arxiv.org/pdf/1110.5667"
        },
        {
            "id": "30",
            "entry": "[30] Kyunghyun Cho, Bart Van Merri\u00ebnboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1406.1078"
        },
        {
            "id": "31",
            "entry": "[31] Tessa Lau. Programming by demonstration: a machine learning approach. PhD thesis, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lau%2C%20Tessa%20Programming%20by%20demonstration%3A%20a%20machine%20learning%20approach%202001"
        },
        {
            "id": "32",
            "entry": "[32] Rajeev Alur, Dana Fisman, Rishabh Singh, and Armando Solar-Lezama. Sygus-comp 2016: results and analysis. arXiv preprint arXiv:1611.07627, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.07627"
        },
        {
            "id": "33",
            "entry": "[33] Christopher M. Bishop. Pattern Recognition and Machine Learning. 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bishop%2C%20Christopher%20M.%20Pattern%20Recognition%20and%20Machine%20Learning%202006"
        },
        {
            "id": "34",
            "entry": "[34] Percy Liang, Michael I. Jordan, and Dan Klein. Learning programs: A hierarchical bayesian approach. In",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20Percy%20Jordan%2C%20Michael%20I.%20Klein%2C%20Dan%20Learning%20programs%3A%20A%20hierarchical%20bayesian%20approach",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20Percy%20Jordan%2C%20Michael%20I.%20Klein%2C%20Dan%20Learning%20programs%3A%20A%20hierarchical%20bayesian%20approach"
        },
        {
            "id": "35",
            "entry": "[35] Ray J Solomonoff. A system for incremental learning based on algorithmic probability. Sixth Israeli Conference on Artificial Intelligence, Computer Vision and Pattern Recognition, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Solomonoff%2C%20Ray%20J.%20A%20system%20for%20incremental%20learning%20based%20on%20algorithmic%20probability%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Solomonoff%2C%20Ray%20J.%20A%20system%20for%20incremental%20learning%20based%20on%20algorithmic%20probability%201989"
        },
        {
            "id": "36",
            "entry": "[36] J\u00fcrgen Schmidhuber. Optimal ordered problem solver. Machine Learning, 54(3):211\u2013254, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidhuber%2C%20J%C3%BCrgen%20Optimal%20ordered%20problem%20solver%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmidhuber%2C%20J%C3%BCrgen%20Optimal%20ordered%20problem%20solver%202004"
        },
        {
            "id": "37",
            "entry": "[37] Susumu Katayama. Towards human-level inductive functional programming. In International Conference on Artificial General Intelligence, pages 111\u2013120.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Katayama%2C%20Susumu%20Towards%20human-level%20inductive%20functional%20programming",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Katayama%2C%20Susumu%20Towards%20human-level%20inductive%20functional%20programming"
        },
        {
            "id": "38",
            "entry": "[38] Miltiadis Allamanis and Charles Sutton. Mining idioms from source code. In Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE 2014, pages 472\u2013483, New York, NY, USA, 2014. ACM.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allamanis%2C%20Miltiadis%20Sutton%2C%20Charles%20Mining%20idioms%20from%20source%20code%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allamanis%2C%20Miltiadis%20Sutton%2C%20Charles%20Mining%20idioms%20from%20source%20code%202014"
        },
        {
            "id": "39",
            "entry": "[39] Richard Shin, Marc Brockschmidt, Miltiadis Allamanis, and Oleksandr Polozov. Program synthesis with learned code idioms. Under review, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shin%2C%20Richard%20Brockschmidt%2C%20Marc%20Allamanis%2C%20Miltiadis%20Polozov%2C%20Oleksandr%20Program%20synthesis%20with%20learned%20code%20idioms%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shin%2C%20Richard%20Brockschmidt%2C%20Marc%20Allamanis%2C%20Miltiadis%20Polozov%2C%20Oleksandr%20Program%20synthesis%20with%20learned%20code%20idioms%202018"
        },
        {
            "id": "40",
            "entry": "[40] Kevin Ellis, Armando Solar-Lezama, and Josh Tenenbaum. Sampling for bayesian program learning. In Advances in Neural Information Processing Systems, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20Kevin%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Josh%20Sampling%20for%20bayesian%20program%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ellis%2C%20Kevin%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Josh%20Sampling%20for%20bayesian%20program%20learning%202016"
        },
        {
            "id": "41",
            "entry": "[41] Kevin Ellis, Armando Solar-Lezama, and Josh Tenenbaum. Unsupervised learning by program synthesis. In NIPS. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20Kevin%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Josh%20Unsupervised%20learning%20by%20program%20synthesis.%20In%20NIPS"
        }
    ]
}
