{
    "filename": "8100-group-equivariant-capsule-networks.pdf",
    "metadata": {
        "title": "Group Equivariant Capsule Networks",
        "author": "Jan Eric Lenssen, Matthias Fey, Pascal Libuschewski",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8100-group-equivariant-capsule-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We present group equivariant capsule networks, a framework to introduce guaranteed equivariance and invariance properties to the capsule network idea. Our work can be divided into two contributions. First, we present a generic routing by agreement algorithm defined on elements of a group and prove that equivariance of output pose vectors, as well as invariance of output activations, hold under certain conditions. Second, we connect the resulting equivariant capsule networks with work from the field of group convolutional networks. Through this connection, we provide intuitions of how both methods relate and are able to combine the strengths of both approaches in one deep neural network architecture. The resulting framework allows sparse evaluation of the group convolution operator, provides control over specific equivariance and invariance properties, and can use routing by agreement instead of pooling operations. In addition, it is able to provide interpretable and equivariant representation vectors as output capsules, which disentangle evidence of object existence from its pose."
    },
    "keywords": [
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "Deutsche Forschungsgemeinschaft",
            "url": "https://en.wikipedia.org/wiki/Deutsche_Forschungsgemeinschaft"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "convolution operator",
            "url": "https://en.wikipedia.org/wiki/convolution_operator"
        }
    ],
    "highlights": [
        "Convolutional neural networks heavily rely on equivariance of the convolution operator under translation",
        "We show that we can build sparse group convolutional networks that inherit invariance of activations under the group law from the capsule part of the network",
        "We show that when using the pose vector outputs to evaluate a Group convolutions layer for group element g we inherit the invariance property from the capsule activations, by proving the following theorem: Theorem 3",
        "We proposed group equivariant capsule networks that provide provable equivariance and invariance properties",
        "We proved the relevant properties and confirmed them through proof of concept experiments while showing that our architecture provides disentangled pose vectors"
    ],
    "key_statements": [
        "Convolutional neural networks heavily rely on equivariance of the convolution operator under translation",
        "Our work focuses on obtaining a formalized version of capsule networks that guarantees those properties as well as bringing them together with group equivariant convolutions by <a class=\"ref-link\" id=\"cCohen_2016_a\" href=\"#rCohen_2016_a\">Cohen and Welling [2016</a>], which provide provable equivariance properties under transformations within a group",
        "We present group equivariant capsule layers, a specialized kind of capsule layer whose pose vectors are elements of a group (G, \u25e6) (cf",
        "We provide a general scheme for dynamic routing by agreement algorithms and show that, under certain conditions, equivariance and invariance properties under transformations from G are mathematically guaranteed",
        "The mean poses of transformed and non-transformed inputs differ by the transformation g: p = g \u25e6 q. This follows from equivariance of M, invariance of M under permutation, and from the equivariance property of previous layers, meaning that the rotation applied to the input directly translates to the pose vectors in deeper layers",
        "We show that we can build sparse group convolutional networks that inherit invariance of activations under the group law from the capsule part of the network",
        "We shortly introduce group convolutions before presenting the combined architecture",
        "We show that when using the pose vector outputs to evaluate a Group convolutions layer for group element g we inherit the invariance property from the capsule activations, by proving the following theorem: Theorem 3",
        "We can go one step further: given a group convolution layer for a product group, we can use the capsule output poses as an index for one group and densely evaluate the convolution for the other, leading to equivariance in the dense dimension and invariance in the capsule-indexed dimension",
        "We pair each capsule with a pose-indexed convolution as described in Section 4 with ReLU non-linearities after each layer, leading to a CNN architecture that is guided by pose vectors to become a sparse group CNN",
        "To verify the disentanglement of rotation, we provide reconstructions of the images after we applied \u03c0/4 rotations to the output pose vectors",
        "We proposed group equivariant capsule networks that provide provable equivariance and invariance properties",
        "We proved the relevant properties and confirmed them through proof of concept experiments while showing that our architecture provides disentangled pose vectors"
    ],
    "summary": [
        "Convolutional neural networks heavily rely on equivariance of the convolution operator under translation.",
        "The function computing the output pose vectors of one layer is left-equivariant regarding applications of the group law if",
        "We define the group capsule layer functions as the output of an iterative routing by agreement, similar to the approach proposed by Sabour et al [2017].",
        "We are able to build a deep group capsule network, by a composition of those layers, that guarantees global invariance in output activations and equivariance in pose vectors.",
        "This follows from equivariance of M, invariance of M under permutation, and from the equivariance property of previous layers, meaning that the rotation applied to the input directly translates to the pose vectors in deeper layers.",
        "The newly won properties of pose vectors and activations allow us to combine our group equivariant capsule networks with methods from the field of group equivariant convolutional networks.",
        "We show that when using the pose vector outputs to evaluate a G-conv layer for group element g we inherit the invariance property from the capsule activations, by proving the following theorem: Theorem 3.",
        "Given pose vector outputs Lp(p, a) of a group capsule layer for group G, input signal f : G \u2192 R, and filter \u03c8 : G \u2192 R.",
        "The group convolution [f \u03c8] is invariant under joint left-applications of g \u2208 G on capsule input pose vectors P \u2208 Gn and signal f :",
        "We can go one step further: given a group convolution layer for a product group, we can use the capsule output poses as an index for one group and densely evaluate the convolution for the other, leading to equivariance in the dense dimension and invariance in the capsule-indexed dimension.",
        "We pair each capsule with a pose-indexed convolution as described in Section 4 with ReLU non-linearities after each layer, leading to a CNN architecture that is guided by pose vectors to become a sparse group CNN.",
        "The results of our capsule networks with and without a reconstruction loss are compared to the naive approach of hierarchically averaging local pose vectors.",
        "Reconstruction For further verification of disentanglement, we replicated the autoencoder experiment of Sabour et al [2017] by appending a three-layer MLP to convolution outputs, agreement outputs, and poses and train it to reconstruct the input image.",
        "Future work will include applying the proposed framework to other, higher-dimensional groups, to come closer to the expressiveness of original capsule networks while preserving the guarantees."
    ],
    "headline": "We present group equivariant capsule networks, a framework to introduce guaranteed equivariance and invariance properties to the capsule network idea",
    "reference_links": [
        {
            "id": "Cohen_2016_a",
            "entry": "T. S. Cohen and M. Welling. Group equivariant convolutional networks. In Proceedings of the 33rd International Conference on International Conference on Machine Learning (ICML), pages 2990\u20132999, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20T.S.%20Welling%2C%20M.%20Group%20equivariant%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20T.S.%20Welling%2C%20M.%20Group%20equivariant%20convolutional%20networks%202016"
        },
        {
            "id": "Cohen_2017_a",
            "entry": "T. S. Cohen and M. Welling. Steerable CNNs. In International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20T.S.%20Welling%2C%20M.%20Steerable%20CNNs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20T.S.%20Welling%2C%20M.%20Steerable%20CNNs%202017"
        },
        {
            "id": "Cohen_et+al_2018_a",
            "entry": "T. S. Cohen, M. Geiger, J. K\u00f6hler, and M. Welling. Spherical CNNs. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20T.S.%20Geiger%2C%20M.%20K%C3%B6hler%2C%20J.%20Welling%2C%20M.%20Spherical%20CNNs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20T.S.%20Geiger%2C%20M.%20K%C3%B6hler%2C%20J.%20Welling%2C%20M.%20Spherical%20CNNs%202018"
        },
        {
            "id": "Cohen_et+al_2018_b",
            "entry": "T. S. Cohen, M. Geiger, and M. Weiler. Intertwiners between Induced Representations (with Applications to the Theory of Equivariant Neural Networks). ArXiv e-prints, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20T.S.%20Geiger%2C%20M.%20Weiler%2C%20M.%20Intertwiners%20between%20Induced%20Representations%20%28with%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20T.S.%20Geiger%2C%20M.%20Weiler%2C%20M.%20Intertwiners%20between%20Induced%20Representations%20%28with%202018"
        },
        {
            "id": "Dieleman_et+al_2016_a",
            "entry": "S. Dieleman, J. De Fauw, and K. Kavukcuoglu. Exploiting cyclic symmetry in convolutional neural networks. In Proceedings of the 33rd International Conference on International Conference on Machine Learning (ICML), pages 1889\u20131898, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dieleman%2C%20S.%20Fauw%2C%20J.De%20Kavukcuoglu%2C%20K.%20Exploiting%20cyclic%20symmetry%20in%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dieleman%2C%20S.%20Fauw%2C%20J.De%20Kavukcuoglu%2C%20K.%20Exploiting%20cyclic%20symmetry%20in%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "Fey_et+al_2018_a",
            "entry": "M. Fey, J. E. Lenssen, F. Weichert, and H. M\u00fcller. SplineCNN: Fast geometric deep learning with continuous B-spline kernels. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fey%2C%20M.%20Lenssen%2C%20J.E.%20Weichert%2C%20F.%20M%C3%BCller%2C%20H.%20SplineCNN%3A%20Fast%20geometric%20deep%20learning%20with%20continuous%20B-spline%20kernels%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fey%2C%20M.%20Lenssen%2C%20J.E.%20Weichert%2C%20F.%20M%C3%BCller%2C%20H.%20SplineCNN%3A%20Fast%20geometric%20deep%20learning%20with%20continuous%20B-spline%20kernels%202018"
        },
        {
            "id": "Gilmer_et+al_2017_a",
            "entry": "J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning (ICML), pages 1263\u20131272, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilmer%2C%20J.%20Schoenholz%2C%20S.S.%20Riley%2C%20P.F.%20Vinyals%2C%20O.%20Neural%20message%20passing%20for%20quantum%20chemistry%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilmer%2C%20J.%20Schoenholz%2C%20S.S.%20Riley%2C%20P.F.%20Vinyals%2C%20O.%20Neural%20message%20passing%20for%20quantum%20chemistry%202017"
        },
        {
            "id": "Henriques_2017_a",
            "entry": "J. F. Henriques and A. Vedaldi. Warped convolutions: Efficient invariance to spatial transformations. In Proceedings of the 34th International Conference on Machine Learning (ICML), pages 1461\u20131469, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henriques%2C%20J.F.%20Vedaldi%2C%20A.%20Warped%20convolutions%3A%20Efficient%20invariance%20to%20spatial%20transformations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Henriques%2C%20J.F.%20Vedaldi%2C%20A.%20Warped%20convolutions%3A%20Efficient%20invariance%20to%20spatial%20transformations%202017"
        },
        {
            "id": "Hinton_et+al_2011_a",
            "entry": "G. E. Hinton, A. Krizhevsky, and S. D. Wang. Transforming auto-encoders. In Artificial Neural Networks and Machine Learning - 21st International Conference on Artificial Neural Networks (ICANN), pages 44\u201351, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20G.E.%20Krizhevsky%2C%20A.%20Wang%2C%20S.D.%20Transforming%20auto-encoders%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20G.E.%20Krizhevsky%2C%20A.%20Wang%2C%20S.D.%20Transforming%20auto-encoders%202011"
        },
        {
            "id": "Hinton_et+al_2018_a",
            "entry": "G. E. Hinton, S. Sabour, and N. Frosst. Matrix capsules with EM routing. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20G.E.%20Sabour%2C%20S.%20Frosst%2C%20N.%20Matrix%20capsules%20with%20EM%20routing%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20G.E.%20Sabour%2C%20S.%20Frosst%2C%20N.%20Matrix%20capsules%20with%20EM%20routing%202018"
        },
        {
            "id": "Larochelle_et+al_2007_a",
            "entry": "H. Larochelle, D. Erhan, A. Courville, J. Bergstra, and Y. Bengio. An empirical evaluation of deep architectures on problems with many factors of variation. In Proceedings of the 24th International Conference on Machine Learning, pages 473\u2013480, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Larochelle%2C%20H.%20Erhan%2C%20D.%20Courville%2C%20A.%20Bergstra%2C%20J.%20An%20empirical%20evaluation%20of%20deep%20architectures%20on%20problems%20with%20many%20factors%20of%20variation%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Larochelle%2C%20H.%20Erhan%2C%20D.%20Courville%2C%20A.%20Bergstra%2C%20J.%20An%20empirical%20evaluation%20of%20deep%20architectures%20on%20problems%20with%20many%20factors%20of%20variation%202007"
        },
        {
            "id": "Lecun_et+al_1998_a",
            "entry": "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. In Proceedings of the IEEE, pages 2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "Marcos_et+al_2017_a",
            "entry": "D. Marcos, M. Volpi, N. Komodakis, and D. Tuia. Rotation equivariant vector field networks. In IEEE International Conference on Computer Vision (ICCV), pages 5058\u20135067, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcos%2C%20D.%20Volpi%2C%20M.%20Komodakis%2C%20N.%20Tuia%2C%20D.%20Rotation%20equivariant%20vector%20field%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcos%2C%20D.%20Volpi%2C%20M.%20Komodakis%2C%20N.%20Tuia%2C%20D.%20Rotation%20equivariant%20vector%20field%20networks%202017"
        },
        {
            "id": "Nielsen_2012_a",
            "entry": "F. Nielsen and R. Bhatia. Matrix Information Geometry. Springer Publishing Company, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=F%20Nielsen%20and%20R%20Bhatia%20Matrix%20Information%20Geometry%20Springer%20Publishing%20Company%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=F%20Nielsen%20and%20R%20Bhatia%20Matrix%20Information%20Geometry%20Springer%20Publishing%20Company%202012"
        },
        {
            "id": "Processing_2017_a",
            "entry": "Processing Systems (NIPS), pages 3859\u20133869, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Processing%20Systems%20NIPS%20pages%2038593869%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Processing%20Systems%20NIPS%20pages%2038593869%202017"
        },
        {
            "id": "Conference_2018_a",
            "entry": "Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202018"
        },
        {
            "id": "Worrall_et+al_2017_a",
            "entry": "D. E. Worrall, S. J. Garbin, D. Turmukhambetov, and G. J. Brostow. Harmonic networks: Deep translation and rotation equivariance. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Worrall%2C%20D.E.%20Garbin%2C%20S.J.%20Turmukhambetov%2C%20D.%20Brostow%2C%20G.J.%20Harmonic%20networks%3A%20Deep%20translation%20and%20rotation%20equivariance%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Worrall%2C%20D.E.%20Garbin%2C%20S.J.%20Turmukhambetov%2C%20D.%20Brostow%2C%20G.J.%20Harmonic%20networks%3A%20Deep%20translation%20and%20rotation%20equivariance%202017"
        },
        {
            "id": "Vision_2017_b",
            "entry": "Vision and Pattern Recognition (CVPR), pages 4961\u20134970, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Vision%20and%20Pattern%20Recognition%20%28CVPR%29%202017"
        }
    ]
}
