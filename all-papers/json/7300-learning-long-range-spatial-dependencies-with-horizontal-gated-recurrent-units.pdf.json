{
    "filename": "7300-learning-long-range-spatial-dependencies-with-horizontal-gated-recurrent-units.pdf",
    "metadata": {
        "title": "Learning long-range spatial dependencies with horizontal gated recurrent units",
        "author": "Drew Linsley, Junkyung Kim, Vijay Veerabadran, Charles Windolf, Thomas Serre",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7300-learning-long-range-spatial-dependencies-with-horizontal-gated-recurrent-units.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching \u2013 and sometimes even surpassing \u2013 human accuracy on a variety of visual recognition tasks. Here, however, we show that these neural networks and their recent extensions struggle in recognition tasks where co-dependent visual features must be detected over long spatial ranges. We introduce a visual challenge, Pathfinder, and describe a novel recurrent neural network architecture called the horizontal gated recurrent unit (hGRU) to learn intrinsic horizontal connections \u2013 both within and across feature columns. We demonstrate that a single hGRU layer matches or outperforms all tested feedforward hierarchical baselines including state-of-the-art architectures with orders of magnitude more parameters."
    },
    "keywords": [
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "Conditional Random Fields",
            "url": "https://en.wikipedia.org/wiki/Conditional_Random_Field"
        },
        {
            "term": "primary visual cortex",
            "url": "https://en.wikipedia.org/wiki/primary_visual_cortex"
        },
        {
            "term": "receptive fields",
            "url": "https://en.wikipedia.org/wiki/receptive_fields"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        }
    ],
    "highlights": [
        "Consider Fig. 1a which shows a sample image from a representative segmentation dataset [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] and the corresponding contour map produced by a state-of-the-art deep convolutional neural network (CNN) [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "Unlike convolutional neural network, which exhibit a sharp decrease in accuracy for increasingly long paths, we show that the horizontal gated recurrent unit is highly effective at solving the Pathfinder challenge with just one layer and a fraction of the number of parameters and training samples needed by convolutional neural network",
        "The horizontal gated recurrent unit extends the derivation from Eq 2 with three modifications that improve the training of the model with gradient descent and its expressiveness2. (i) We introduce learnable gates, borrowed from the gated recurrent unit (GRU) framework (see Supp",
        "The present study demonstrates that long-range spatial dependencies generally strain convolutional neural network, with only very deep and state-of-the-art networks overcoming the visual variability introduced by long paths in the Pathfinder challenge",
        "We find that the horizontal gated recurrent unit can reliably detect paths of any tested length or form using just a single layer",
        "Theoretical models suggest that patterns of horizontal connections reflect the statistics of natural scenes, and here too we find that horizontal kernels in the horizontal gated recurrent unit learned from natural scenes resemble cortical patterns of horizontal connectivity, including association fields and the paired near-excitatory / far-inhibitory surrounds that may be responsible for many contextual illusions [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c56\" href=\"#r56\">56</a>]"
    ],
    "key_statements": [
        "Consider Fig. 1a which shows a sample image from a representative segmentation dataset [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] and the corresponding contour map produced by a state-of-the-art deep convolutional neural network (CNN) [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "We describe an extension of the popular gated recurrent unit (GRU) [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], which we call the horizontal gated recurrent unit",
        "Unlike convolutional neural network, which exhibit a sharp decrease in accuracy for increasingly long paths, we show that the horizontal gated recurrent unit is highly effective at solving the Pathfinder challenge with just one layer and a fraction of the number of parameters and training samples needed by convolutional neural network",
        "When trained on natural scenes, the horizontal gated recurrent unit learns connection patterns that coarsely resemble anatomical patterns of horizontal connectivity found in the visual cortex, and exhibits a detection profile that strongly correlates with human behavior on a classic contour detection task [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>]",
        "The horizontal gated recurrent unit extends the derivation from Eq 2 with three modifications that improve the training of the model with gradient descent and its expressiveness2. (i) We introduce learnable gates, borrowed from the gated recurrent unit (GRU) framework (see Supp",
        "The present study demonstrates that long-range spatial dependencies generally strain convolutional neural network, with only very deep and state-of-the-art networks overcoming the visual variability introduced by long paths in the Pathfinder challenge",
        "This study adds to a body of work highlighting examples of routine visual tasks where convolutional neural network fall short of human performance [<a class=\"ref-link\" id=\"c58\" href=\"#r58\">58</a>\u2013<a class=\"ref-link\" id=\"c62\" href=\"#r62\">62</a>]",
        "We demonstrate a solution to the Pathfinder challenge inspired by neuroscience",
        "We find that the horizontal gated recurrent unit can reliably detect paths of any tested length or form using just a single layer",
        "We found that horizontal gated recurrent unit performance on the Pathfinder challenge is a function of the amount of time it was given for processing",
        "The performance of the horizontal gated recurrent unit on the Pathfinder challenge captures the iterative nature of computations used by our visual system during similar tasks [<a class=\"ref-link\" id=\"c63\" href=\"#r63\">63</a>] \u2013 exhibiting a comparable tradeoff between performance and processing-time [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>]",
        "Theoretical models suggest that patterns of horizontal connections reflect the statistics of natural scenes, and here too we find that horizontal kernels in the horizontal gated recurrent unit learned from natural scenes resemble cortical patterns of horizontal connectivity, including association fields and the paired near-excitatory / far-inhibitory surrounds that may be responsible for many contextual illusions [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c56\" href=\"#r56\">56</a>]"
    ],
    "summary": [
        "Consider Fig. 1a which shows a sample image from a representative segmentation dataset [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] and the corresponding contour map produced by a state-of-the-art deep convolutional neural network (CNN) [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>].",
        "Unlike CNNs, which exhibit a sharp decrease in accuracy for increasingly long paths, we show that the hGRU is highly effective at solving the Pathfinder challenge with just one layer and a fraction of the number of parameters and training samples needed by CNNs. We further find that, when trained on natural scenes, the hGRU learns connection patterns that coarsely resemble anatomical patterns of horizontal connectivity found in the visual cortex, and exhibits a detection profile that strongly correlates with human behavior on a classic contour detection task [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>].",
        "HGRU formulation We build on Eq 2 to introduce the hGRU \u2013 a model with the ability to learn complex interactions between units via horizontal connections within a single processing layer (Fig. 2).",
        "Model implementation We performed a large-scale analysis of the effectiveness of feedforward and recurrent computations on the Pathfinder challenge.",
        "Recurrent models We tested 6 different recurrent layers in the feature extraction stage of the standard architecture: hGRUs with 8, 6, and 4-timesteps of processing; a GRU; and hGRUs with lesions applied to parameters controlling linear or quadratic horizontal interactions.",
        "The 152-layer ResNet was less efficient at learning the 14-length dataset than the hGRU (Fig. 3b), and achieved its performance with nearly 1000\u00d7 as many parameters (Fig. 3c; see Supp.",
        "We tested three representative per-pixel prediction models: the fully-convolutional network (FCN), the skip-connection U-Net, and the unpooling SegNet. These models used an encoder/decoder style architecture, which was followed by the readout processing stage of the standard architecture described above to make them suitable for Pathfinder classification.",
        "When trained on the the Pathfinder challenge, hGRU kernels resembled the dominant patterns of horizontal connectivity in visual cortex.",
        "The present study demonstrates that long-range spatial dependencies generally strain CNNs, with only very deep and state-of-the-art networks overcoming the visual variability introduced by long paths in the Pathfinder challenge.",
        "Feedforward networks are generally effective at learning and detecting relatively rigid objects shown in well-defined poses, these models tend towards a brute-force solution when tasked with the recognition of less constrained structures, such as a path connecting two distant locations.",
        "The performance of the hGRU on the Pathfinder challenge captures the iterative nature of computations used by our visual system during similar tasks [<a class=\"ref-link\" id=\"c63\" href=\"#r63\">63</a>] \u2013 exhibiting a comparable tradeoff between performance and processing-time [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>].",
        "Theoretical models suggest that patterns of horizontal connections reflect the statistics of natural scenes, and here too we find that horizontal kernels in the hGRU learned from natural scenes resemble cortical patterns of horizontal connectivity, including association fields and the paired near-excitatory / far-inhibitory surrounds that may be responsible for many contextual illusions [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c56\" href=\"#r56\">56</a>]."
    ],
    "headline": "We show that these neural networks and their recent extensions struggle in recognition tasks where co-dependent visual features must be detected over long spatial ranges",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. IEEE transactions on pattern analysis and machine intelligence, 33(5):898\u2013916, May 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arbelaez%2C%20P.%20Maire%2C%20M.%20Fowlkes%2C%20C.%20Malik%2C%20J.%20Contour%20detection%20and%20hierarchical%20image%20segmentation%202011-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arbelaez%2C%20P.%20Maire%2C%20M.%20Fowlkes%2C%20C.%20Malik%2C%20J.%20Contour%20detection%20and%20hierarchical%20image%20segmentation%202011-05"
        },
        {
            "id": "2",
            "entry": "[2] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu. Deeply-Supervised nets. In Artificial Intelligence and Statistics, pages 562\u2013570, February 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CY%20Lee%20S%20Xie%20P%20Gallagher%20Z%20Zhang%20and%20Z%20Tu%20DeeplySupervised%20nets%20In%20Artificial%20Intelligence%20and%20Statistics%20pages%20562570%20February%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=CY%20Lee%20S%20Xie%20P%20Gallagher%20Z%20Zhang%20and%20Z%20Tu%20DeeplySupervised%20nets%20In%20Artificial%20Intelligence%20and%20Statistics%20pages%20562570%20February%202015"
        },
        {
            "id": "3",
            "entry": "[3] S. Xie and Z. Tu. Holistically-Nested edge detection. International journal of computer vision, 125(1):3\u201318, December 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20S.%20Tu%2C%20Z.%20Holistically-Nested%20edge%20detection%202017-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20S.%20Tu%2C%20Z.%20Holistically-Nested%20edge%20detection%202017-12"
        },
        {
            "id": "4",
            "entry": "[4] Y. Liu, M. M. Cheng, X. Hu, K. Wang, and X. Bai. Richer convolutional features for edge detection. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5872\u20135881, July 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Cheng%2C%20M.M.%20Hu%2C%20X.%20Wang%2C%20K.%20Richer%20convolutional%20features%20for%20edge%20detection%202017-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Cheng%2C%20M.M.%20Hu%2C%20X.%20Wang%2C%20K.%20Richer%20convolutional%20features%20for%20edge%20detection%202017-07"
        },
        {
            "id": "5",
            "entry": "[5] K.-K. Maninis, J. Pont-Tuset, P. Arbelaez, and L. Van Gool. Convolutional oriented boundaries: From image segmentation to High-Level tasks. IEEE transactions on pattern analysis and machine intelligence, 40(4):819\u2013833, April 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maninis%2C%20K.-K.%20Pont-Tuset%2C%20J.%20Arbelaez%2C%20P.%20Gool%2C%20L.Van%20Convolutional%20oriented%20boundaries%3A%20From%20image%20segmentation%20to%20High-Level%20tasks%202018-04",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maninis%2C%20K.-K.%20Pont-Tuset%2C%20J.%20Arbelaez%2C%20P.%20Gool%2C%20L.Van%20Convolutional%20oriented%20boundaries%3A%20From%20image%20segmentation%20to%20High-Level%20tasks%202018-04"
        },
        {
            "id": "6",
            "entry": "[6] Y. Wang, X. Zhao, and K. Huang. Deep crisp boundaries. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3892\u20133900, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Y.%20Zhao%2C%20X.%20Huang%2C%20K.%20Deep%20crisp%20boundaries%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Y.%20Zhao%2C%20X.%20Huang%2C%20K.%20Deep%20crisp%20boundaries%202017"
        },
        {
            "id": "7",
            "entry": "[7] R. Houtkamp and P. R. Roelfsema. Parallel and serial grouping of image elements in visual perception. Journal of experimental psychology. Human perception and performance, 36(6): 1443\u20131459, December 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Houtkamp%2C%20R.%20Roelfsema%2C%20P.R.%20Parallel%20and%20serial%20grouping%20of%20image%20elements%20in%20visual%20perception%202010-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Houtkamp%2C%20R.%20Roelfsema%2C%20P.R.%20Parallel%20and%20serial%20grouping%20of%20image%20elements%20in%20visual%20perception%202010-12"
        },
        {
            "id": "8",
            "entry": "[8] D. D. Stettler, A. Das, J. Bennett, and C. D. Gilbert. Lateral connectivity and contextual interactions in macaque primary visual cortex. Neuron, 36(4):739\u2013750, November 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stettler%2C%20D.D.%20Das%2C%20A.%20Bennett%2C%20J.%20Gilbert%2C%20C.D.%20Lateral%20connectivity%20and%20contextual%20interactions%20in%20macaque%20primary%20visual%20cortex%202002-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stettler%2C%20D.D.%20Das%2C%20A.%20Bennett%2C%20J.%20Gilbert%2C%20C.D.%20Lateral%20connectivity%20and%20contextual%20interactions%20in%20macaque%20primary%20visual%20cortex%202002-11"
        },
        {
            "id": "9",
            "entry": "[9] K. S. Rockland and J. S. Lund. Intrinsic laminar lattice connections in primate visual cortex. The Journal of comparative neurology, 216(3):303\u2013318, May 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rockland%2C%20K.S.%20Lund%2C%20J.S.%20Intrinsic%20laminar%20lattice%20connections%20in%20primate%20visual%20cortex%201983-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rockland%2C%20K.S.%20Lund%2C%20J.S.%20Intrinsic%20laminar%20lattice%20connections%20in%20primate%20visual%20cortex%201983-05"
        },
        {
            "id": "10",
            "entry": "[10] S. Grossberg and E. Mingolla. Neural dynamics of perceptual grouping: textures, boundaries, and emergent segmentations. Perception & psychophysics, 38(2):141\u2013171, August 1985.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grossberg%2C%20S.%20Mingolla%2C%20E.%20Neural%20dynamics%20of%20perceptual%20grouping%3A%20textures%2C%20boundaries%2C%20and%20emergent%20segmentations%201985-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grossberg%2C%20S.%20Mingolla%2C%20E.%20Neural%20dynamics%20of%20perceptual%20grouping%3A%20textures%2C%20boundaries%2C%20and%20emergent%20segmentations%201985-08"
        },
        {
            "id": "11",
            "entry": "[11] D. J. Field, A. Hayes, and R. F. Hess. Contour integration by the human visual system: Evidence for a local \u201cassociation field\u201d. Vision research, 33(2):173\u2013193, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Field%2C%20D.J.%20Hayes%2C%20A.%20Hess%2C%20R.F.%20Contour%20integration%20by%20the%20human%20visual%20system%3A%20Evidence%20for%20a%20local%20%E2%80%9Cassociation%20field%E2%80%9D%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Field%2C%20D.J.%20Hayes%2C%20A.%20Hess%2C%20R.F.%20Contour%20integration%20by%20the%20human%20visual%20system%3A%20Evidence%20for%20a%20local%20%E2%80%9Cassociation%20field%E2%80%9D%201993"
        },
        {
            "id": "12",
            "entry": "[12] G. W. Lesher and E. Mingolla. The role of edges and line-ends in illusory contour formation. Vision research, 33(16):2253\u20132270, November 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lesher%2C%20G.W.%20Mingolla%2C%20E.%20The%20role%20of%20edges%20and%20line-ends%20in%20illusory%20contour%20formation%201993-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lesher%2C%20G.W.%20Mingolla%2C%20E.%20The%20role%20of%20edges%20and%20line-ends%20in%20illusory%20contour%20formation%201993-11"
        },
        {
            "id": "13",
            "entry": "[13] W. Li, V. Pi\u00ebch, and C. D. Gilbert. Contour saliency in primary visual cortex. Neuron, 50(6): 951\u2013962, June 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20W.%20Pi%C3%ABch%2C%20V.%20Gilbert%2C%20C.D.%20Contour%20saliency%20in%20primary%20visual%20cortex%202006-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20W.%20Pi%C3%ABch%2C%20V.%20Gilbert%2C%20C.D.%20Contour%20saliency%20in%20primary%20visual%20cortex%202006-06"
        },
        {
            "id": "14",
            "entry": "[14] W. Li, V. Pi\u00ebch, and C. D. Gilbert. Learning to link visual contours. Neuron, 57(3):442\u2013451, February 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20W.%20Pi%C3%ABch%2C%20V.%20Gilbert%2C%20C.D.%20Learning%20to%20link%20visual%20contours%202008-02",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20W.%20Pi%C3%ABch%2C%20V.%20Gilbert%2C%20C.D.%20Learning%20to%20link%20visual%20contours%202008-02"
        },
        {
            "id": "15",
            "entry": "[15] S. W. Zucker. Stereo, shading, and surfaces: Curvature constraints couple neural computations. Proceedings of the IEEE, 102(5):812\u2013829, May 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stereo%2C%20S.W.Zucker%20shading%2C%20and%20surfaces%3A%20Curvature%20constraints%20couple%20neural%20computations%202014-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stereo%2C%20S.W.Zucker%20shading%2C%20and%20surfaces%3A%20Curvature%20constraints%20couple%20neural%20computations%202014-05"
        },
        {
            "id": "16",
            "entry": "[16] P. Series, J. Lorenceau, and Y. Fr\u00e9gnac. The \u201csilent\u201d surround of V1 receptive fields: theory and experiments. Journal of physiology-Paris, 97:453\u2013474, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Series%2C%20P.%20Lorenceau%2C%20J.%20Fr%C3%A9gnac%2C%20Y.%20The%20%E2%80%9Csilent%E2%80%9D%20surround%20of%20V1%20receptive%20fields%3A%20theory%20and%20experiments%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Series%2C%20P.%20Lorenceau%2C%20J.%20Fr%C3%A9gnac%2C%20Y.%20The%20%E2%80%9Csilent%E2%80%9D%20surround%20of%20V1%20receptive%20fields%3A%20theory%20and%20experiments%202003"
        },
        {
            "id": "17",
            "entry": "[17] L. Zhaoping. Neural circuit models for computations in early visual cortex. Current opinion in neurobiology, 21(5):808\u2013815, October 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhaoping%2C%20L.%20Neural%20circuit%20models%20for%20computations%20in%20early%20visual%20cortex%202011-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhaoping%2C%20L.%20Neural%20circuit%20models%20for%20computations%20in%20early%20visual%20cortex%202011-10"
        },
        {
            "id": "18",
            "entry": "[18] S. Shushruth, P. Mangapathy, J. M. Ichida, P. C. Bressloff, L. Schwabe, and A. Angelucci. Strong recurrent networks compute the orientation tuning of surround modulation in the primate primary visual cortex. Journal of Neuroscience, 32(1):308\u2013321, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shushruth%2C%20S.%20Mangapathy%2C%20P.%20Ichida%2C%20J.M.%20Bressloff%2C%20P.C.%20Strong%20recurrent%20networks%20compute%20the%20orientation%20tuning%20of%20surround%20modulation%20in%20the%20primate%20primary%20visual%20cortex%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shushruth%2C%20S.%20Mangapathy%2C%20P.%20Ichida%2C%20J.M.%20Bressloff%2C%20P.C.%20Strong%20recurrent%20networks%20compute%20the%20orientation%20tuning%20of%20surround%20modulation%20in%20the%20primate%20primary%20visual%20cortex%202012"
        },
        {
            "id": "19",
            "entry": "[19] D. B. Rubin, S. D. Van Hooser, and K. D. Miller. The stabilized supralinear network: a unifying circuit motif underlying multi-input integration in sensory cortex. Neuron, 85(2):402\u2013417, January 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rubin%2C%20D.B.%20Hooser%2C%20S.D.Van%20Miller%2C%20K.D.%20The%20stabilized%20supralinear%20network%3A%20a%20unifying%20circuit%20motif%20underlying%20multi-input%20integration%20in%20sensory%20cortex%202015-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rubin%2C%20D.B.%20Hooser%2C%20S.D.Van%20Miller%2C%20K.D.%20The%20stabilized%20supralinear%20network%3A%20a%20unifying%20circuit%20motif%20underlying%20multi-input%20integration%20in%20sensory%20cortex%202015-01"
        },
        {
            "id": "20",
            "entry": "[20] D. A. M\u00e9ly, D. Linsley, and T. Serre. Complementary surrounds explain diverse contextual phenomena across visual modalities. Psychological review, 125(5):769\u2013784, October 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%C3%A9ly%2C%20D.A.%20Linsley%2C%20D.%20Serre%2C%20T.%20Complementary%20surrounds%20explain%20diverse%20contextual%20phenomena%20across%20visual%20modalities%202018-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%C3%A9ly%2C%20D.A.%20Linsley%2C%20D.%20Serre%2C%20T.%20Complementary%20surrounds%20explain%20diverse%20contextual%20phenomena%20across%20visual%20modalities%202018-10"
        },
        {
            "id": "21",
            "entry": "[21] K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using RNN Encoder\u2013Decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724\u20131734, Stroudsburg, PA, USA, 2014. Association for Computational Linguistics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20K.%20van%20Merrienboer%2C%20B.%20Gulcehre%2C%20C.%20Bahdanau%2C%20D.%20Learning%20phrase%20representations%20using%20RNN%20Encoder%E2%80%93Decoder%20for%20statistical%20machine%20translation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cho%2C%20K.%20van%20Merrienboer%2C%20B.%20Gulcehre%2C%20C.%20Bahdanau%2C%20D.%20Learning%20phrase%20representations%20using%20RNN%20Encoder%E2%80%93Decoder%20for%20statistical%20machine%20translation%202014"
        },
        {
            "id": "22",
            "entry": "[22] W. Li and C. D. Gilbert. Global contour saliency and local colinear interactions. Journal of neurophysiology, 88(5):2846\u20132856, November 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20W.%20Gilbert%2C%20C.D.%20Global%20contour%20saliency%20and%20local%20colinear%20interactions%202002-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20W.%20Gilbert%2C%20C.D.%20Global%20contour%20saliency%20and%20local%20colinear%20interactions%202002-11"
        },
        {
            "id": "23",
            "entry": "[23] S. Xie and Z. Tu. Holistically-Nested edge detection. International journal of computer vision, 125(1-3):3\u201318, December 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20S.%20Tu%2C%20Z.%20Holistically-Nested%20edge%20detection%202017-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20S.%20Tu%2C%20Z.%20Holistically-Nested%20edge%20detection%202017-12"
        },
        {
            "id": "24",
            "entry": "[24] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, November 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20short-term%20memory%201997-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20short-term%20memory%201997-11"
        },
        {
            "id": "25",
            "entry": "[25] A. Graves, S. Fern\u00e1ndez, and J. Schmidhuber. Multi-dimensional recurrent neural networks. In Proceedings of the 17th International Conference on Artificial Neural Networks, ICANN\u201907, pages 549\u2013558, Berlin, Heidelberg, 2007. Springer-Verlag.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A.%20Graves%2C%20S.%20Fern%C3%A1ndez%20Schmidhuber%2C%20J.%20Multi-dimensional%20recurrent%20neural%20networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A.%20Graves%2C%20S.%20Fern%C3%A1ndez%20Schmidhuber%2C%20J.%20Multi-dimensional%20recurrent%20neural%20networks"
        },
        {
            "id": "26",
            "entry": "[26] A. Graves and J. Schmidhuber. Offline handwriting recognition with multidimensional recurrent neural networks. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems 21, pages 545\u2013552. Curran Associates, Inc., 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Schmidhuber%2C%20J.%20Offline%20handwriting%20recognition%20with%20multidimensional%20recurrent%20neural%20networks%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20A.%20Schmidhuber%2C%20J.%20Offline%20handwriting%20recognition%20with%20multidimensional%20recurrent%20neural%20networks%202009"
        },
        {
            "id": "27",
            "entry": "[27] S. Bell, C. Lawrence Zitnick, K. Bala, and R. Girshick. Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2874\u20132883, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bell%2C%20S.%20Zitnick%2C%20C.Lawrence%20Bala%2C%20K.%20Girshick%2C%20R.%20Inside-outside%20net%3A%20Detecting%20objects%20in%20context%20with%20skip%20pooling%20and%20recurrent%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bell%2C%20S.%20Zitnick%2C%20C.Lawrence%20Bala%2C%20K.%20Girshick%2C%20R.%20Inside-outside%20net%3A%20Detecting%20objects%20in%20context%20with%20skip%20pooling%20and%20recurrent%20neural%20networks%202016"
        },
        {
            "id": "28",
            "entry": "[28] L. Theis and M. Bethge. Generative image modeling using spatial LSTMs. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 1927\u20131935. Curran Associates, Inc., 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Theis%2C%20L.%20Bethge%2C%20M.%20Generative%20image%20modeling%20using%20spatial%20LSTMs%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Theis%2C%20L.%20Bethge%2C%20M.%20Generative%20image%20modeling%20using%20spatial%20LSTMs%202015"
        },
        {
            "id": "29",
            "entry": "[29] A. Van Den Oord, N. Kalchbrenner, and K. Kavukcuoglu. Pixel recurrent neural networks. In Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48, ICML\u201916, pages 1747\u20131756, New York, NY, USA, 2016. JMLR.org.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oord%2C%20A.Van%20Den%20Kalchbrenner%2C%20N.%20Kavukcuoglu%2C%20K.%20Pixel%20recurrent%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oord%2C%20A.Van%20Den%20Kalchbrenner%2C%20N.%20Kavukcuoglu%2C%20K.%20Pixel%20recurrent%20neural%20networks%202016"
        },
        {
            "id": "30",
            "entry": "[30] M. Liang and X. Hu. Recurrent convolutional neural network for object recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3367\u20133375, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20M.%20Hu%2C%20X.%20Recurrent%20convolutional%20neural%20network%20for%20object%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20M.%20Hu%2C%20X.%20Recurrent%20convolutional%20neural%20network%20for%20object%20recognition%202015"
        },
        {
            "id": "31",
            "entry": "[31] Q. Liao and T. Poggio. Bridging the gaps between residual learning, recurrent neural networks and visual cortex. arXiv preprint arXiv:1604.03640, April 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1604.03640"
        },
        {
            "id": "32",
            "entry": "[32] J. Kim, J. K. Lee, and K. M. Lee. Deeply-Recursive convolutional network for image SuperResolution. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1637\u20131645. IEEE, June 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20J.%20Lee%2C%20J.K.%20Lee%2C%20K.M.%20Deeply-Recursive%20convolutional%20network%20for%20image%20SuperResolution%202016-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20J.%20Lee%2C%20J.K.%20Lee%2C%20K.M.%20Deeply-Recursive%20convolutional%20network%20for%20image%20SuperResolution%202016-06"
        },
        {
            "id": "33",
            "entry": "[33] C. J. Spoerer, P. McClure, and N. Kriegeskorte. Recurrent convolutional neural networks: A better model of biological object recognition. Frontiers in psychology, 8:1551, September 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spoerer%2C%20C.J.%20McClure%2C%20P.%20Kriegeskorte%2C%20N.%20Recurrent%20convolutional%20neural%20networks%3A%20A%20better%20model%20of%20biological%20object%20recognition%201551-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Spoerer%2C%20C.J.%20McClure%2C%20P.%20Kriegeskorte%2C%20N.%20Recurrent%20convolutional%20neural%20networks%3A%20A%20better%20model%20of%20biological%20object%20recognition%201551-09"
        },
        {
            "id": "34",
            "entry": "[34] W. Lotter, G. Kreiman, and D. Cox. Deep predictive coding networks for video prediction and unsupervised learning. In International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lotter%2C%20W.%20Kreiman%2C%20G.%20Cox%2C%20D.%20Deep%20predictive%20coding%20networks%20for%20video%20prediction%20and%20unsupervised%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lotter%2C%20W.%20Kreiman%2C%20G.%20Cox%2C%20D.%20Deep%20predictive%20coding%20networks%20for%20video%20prediction%20and%20unsupervised%20learning%202017"
        },
        {
            "id": "35",
            "entry": "[35] A. R. Zamir, T.-L. Wu, L. Sun, W. Shen, B. E. Shi, J. Malik, and S. Savarese. Feedback Networks. arXiv preprint arxiv: 1612.09508, December 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.09508"
        },
        {
            "id": "36",
            "entry": "[36] A. Nayebi, D. Bear, J. Kubilius, K. Kar, S. Ganguli, D. Sussillo, J. J. DiCarlo, and D. L. K. Yamins. Task-Driven convolutional recurrent models of the visual system. arXiv preprint arXiv:1807.00053, June 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.00053"
        },
        {
            "id": "37",
            "entry": "[37] I. Kokkinos. Pushing the boundaries of boundary detection using deep learning. In International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kokkinos%2C%20I.%20Pushing%20the%20boundaries%20of%20boundary%20detection%20using%20deep%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kokkinos%2C%20I.%20Pushing%20the%20boundaries%20of%20boundary%20detection%20using%20deep%20learning%202016"
        },
        {
            "id": "38",
            "entry": "[38] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. IEEE transactions on pattern analysis and machine intelligence, 40(4):834\u2013848, April 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20L.-C.%20Papandreou%2C%20G.%20Kokkinos%2C%20I.%20Murphy%2C%20K.%20DeepLab%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%2C%20atrous%20convolution%2C%20and%20fully%20connected%20CRFs%202018-04",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20L.-C.%20Papandreou%2C%20G.%20Kokkinos%2C%20I.%20Murphy%2C%20K.%20DeepLab%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%2C%20atrous%20convolution%2C%20and%20fully%20connected%20CRFs%202018-04"
        },
        {
            "id": "39",
            "entry": "[39] D. George, W. Lehrach, K. Kansky, M. L\u00e1zaro-Gredilla, C. Laan, B. Marthi, X. Lou, Z. Meng, Y. Liu, H. Wang, A. Lavin, and D. S. Phoenix. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. Science, 358(6368), December 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=George%2C%20D.%20Lehrach%2C%20W.%20Kansky%2C%20K.%20L%C3%A1zaro-Gredilla%2C%20M.%20A%20generative%20vision%20model%20that%20trains%20with%20high%20data%20efficiency%20and%20breaks%20text-based%20CAPTCHAs%202017-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=George%2C%20D.%20Lehrach%2C%20W.%20Kansky%2C%20K.%20L%C3%A1zaro-Gredilla%2C%20M.%20A%20generative%20vision%20model%20that%20trains%20with%20high%20data%20efficiency%20and%20breaks%20text-based%20CAPTCHAs%202017-12"
        },
        {
            "id": "40",
            "entry": "[40] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. H. S. Torr. Conditional random fields as recurrent neural networks. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), pages 1529\u20131537. IEEE, December 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20S.%20Jayasumana%2C%20S.%20Romera-Paredes%2C%20B.%20Vineet%2C%20V.%20Conditional%20random%20fields%20as%20recurrent%20neural%20networks%202015-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20S.%20Jayasumana%2C%20S.%20Romera-Paredes%2C%20B.%20Vineet%2C%20V.%20Conditional%20random%20fields%20as%20recurrent%20neural%20networks%202015-12"
        },
        {
            "id": "41",
            "entry": "[41] T. Cooijmans, N. Ballas, C. Laurent, \u00c7. G\u00fcl\u00e7ehre, and A. Courville. Recurrent batch normalization. In International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cooijmans%2C%20T.%20Ballas%2C%20N.%20Laurent%2C%20C.%20G%C3%BCl%C3%A7ehre%2C%20%C3%87.%20Recurrent%20batch%20normalization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cooijmans%2C%20T.%20Ballas%2C%20N.%20Laurent%2C%20C.%20G%C3%BCl%C3%A7ehre%2C%20%C3%87.%20Recurrent%20batch%20normalization%202017"
        },
        {
            "id": "42",
            "entry": "[42] D. R. Martin, C. C. Fowlkes, and J. Malik. Learning to detect natural image boundaries using local brightness, color, and texture cues. IEEE transactions on pattern analysis and machine intelligence, 26(5):530\u2013549, May 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martin%2C%20D.R.%20Fowlkes%2C%20C.C.%20Malik%2C%20J.%20Learning%20to%20detect%20natural%20image%20boundaries%20using%20local%20brightness%2C%20color%2C%20and%20texture%20cues%202004-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martin%2C%20D.R.%20Fowlkes%2C%20C.C.%20Malik%2C%20J.%20Learning%20to%20detect%20natural%20image%20boundaries%20using%20local%20brightness%2C%20color%2C%20and%20texture%20cues%202004-05"
        },
        {
            "id": "43",
            "entry": "[43] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part IV, pages 630\u2013645, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=K%20He%20X%20Zhang%20S%20Ren%20and%20J%20Sun%20Identity%20mappings%20in%20deep%20residual%20networks%20In%20Computer%20Vision%20%20ECCV%202016%20%2014th%20European%20Conference%20Amsterdam%20The%20Netherlands%20October%201114%202016%20Proceedings%20Part%20IV%20pages%20630645%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=K%20He%20X%20Zhang%20S%20Ren%20and%20J%20Sun%20Identity%20mappings%20in%20deep%20residual%20networks%20In%20Computer%20Vision%20%20ECCV%202016%20%2014th%20European%20Conference%20Amsterdam%20The%20Netherlands%20October%201114%202016%20Proceedings%20Part%20IV%20pages%20630645%202016"
        },
        {
            "id": "44",
            "entry": "[44] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20J.%20Shelhamer%2C%20E.%20Darrell%2C%20T.%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20J.%20Shelhamer%2C%20E.%20Darrell%2C%20T.%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015"
        },
        {
            "id": "45",
            "entry": "[45] F. Yu and V. Koltun. Multi-Scale context aggregation by dilated convolutions. In International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20F.%20Koltun%2C%20V.%20Multi-Scale%20context%20aggregation%20by%20dilated%20convolutions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20F.%20Koltun%2C%20V.%20Multi-Scale%20context%20aggregation%20by%20dilated%20convolutions%202016"
        },
        {
            "id": "46",
            "entry": "[46] T. Wang, M. Sun, and K. Hu. Dilated deep residual network for image denoising. In 29th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2017, Boston, MA, USA, November 6-8, 2017, pages 1272\u20131279, 2017. doi: 10.1109/ICTAI.2017.00192.",
            "crossref": "https://dx.doi.org/10.1109/ICTAI.2017.00192",
            "arxiv_url": "https://arxiv.org/pdf/2017.00192"
        },
        {
            "id": "47",
            "entry": "[47] R. Hamaguchi, A. Fujita, K. Nemoto, T. Imaizumi, and S. Hikosaka. Effective use of dilated convolutions for segmenting small object instances in remote sensing imagery. CoRR, abs/1709.00179, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.00179"
        },
        {
            "id": "48",
            "entry": "[48] X. Wang, R. Girshick, A. Gupta, and K. He. Non-Local Neural Networks. In 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=X%20Wang%20R%20Girshick%20A%20Gupta%20and%20K%20He%20NonLocal%20Neural%20Networks%20In%202018%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=X%20Wang%20R%20Girshick%20A%20Gupta%20and%20K%20He%20NonLocal%20Neural%20Networks%20In%202018%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202018"
        },
        {
            "id": "49",
            "entry": "[49] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV \u201915, pages 1026\u20131034, Washington, DC, USA, 2015. IEEE Computer Society. ISBN 978-1-4673-8391-2. doi: 10.1109/ICCV.2015.123. URL http://dx.doi.org/10.1109/ICCV.2015.123.",
            "crossref": "https://dx.doi.org/10.1109/ICCV.2015.123",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/ICCV.2015.123"
        },
        {
            "id": "50",
            "entry": "[50] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "51",
            "entry": "[51] G. Papandreou, I. Kokkinos, and P.-A. Savalle. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 390\u2013399. IEEE, June 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Papandreou%2C%20G.%20Kokkinos%2C%20I.%20Savalle%2C%20P.-A.%20Modeling%20local%20and%20global%20deformations%20in%20deep%20learning%3A%20Epitomic%20convolution%2C%20multiple%20instance%20learning%2C%20and%20sliding%20window%20detection%202015-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Papandreou%2C%20G.%20Kokkinos%2C%20I.%20Savalle%2C%20P.-A.%20Modeling%20local%20and%20global%20deformations%20in%20deep%20learning%3A%20Epitomic%20convolution%2C%20multiple%20instance%20learning%2C%20and%20sliding%20window%20detection%202015-06"
        },
        {
            "id": "52",
            "entry": "[52] K.-K. Maninis, J. Pont-Tuset, P. Arbelaez, and L. Van Gool. Convolutional oriented boundaries: From image segmentation to High-Level tasks. IEEE transactions on pattern analysis and machine intelligence, May 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maninis%2C%20K.-K.%20Pont-Tuset%2C%20J.%20Arbelaez%2C%20P.%20Gool%2C%20L.Van%20Convolutional%20oriented%20boundaries%3A%20From%20image%20segmentation%20to%20High-Level%20tasks.%20IEEE%20transactions%20on%20pattern%20analysis%20and%20machine%20intelligence%202017-05"
        },
        {
            "id": "53",
            "entry": "[53] O. Ronneberger, P. Fischer, and T. Brox. U-Net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2015, pages 234\u2013241. Springer International Publishing, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ronneberger%2C%20O.%20Fischer%2C%20P.%20Brox%2C%20T.%20U-Net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ronneberger%2C%20O.%20Fischer%2C%20P.%20Brox%2C%20T.%20U-Net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation%202015"
        },
        {
            "id": "54",
            "entry": "[54] V. Badrinarayanan, A. Kendall, and R. Cipolla. SegNet: A deep convolutional Encoder-Decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481\u20132495, December 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Badrinarayanan%2C%20V.%20Kendall%2C%20A.%20Cipolla%2C%20R.%20SegNet%3A%20A%20deep%20convolutional%20Encoder-Decoder%20architecture%20for%20image%20segmentation%202017-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Badrinarayanan%2C%20V.%20Kendall%2C%20A.%20Cipolla%2C%20R.%20SegNet%3A%20A%20deep%20convolutional%20Encoder-Decoder%20architecture%20for%20image%20segmentation%202017-12"
        },
        {
            "id": "55",
            "entry": "[55] O. Ben-Shahar and S. Zucker. Geometrical computations explain projection patterns of longrange horizontal connections in visual cortex. Neural computation, 16(3):445\u2013476, March 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-Shahar%2C%20O.%20Zucker%2C%20S.%20Geometrical%20computations%20explain%20projection%20patterns%20of%20longrange%20horizontal%20connections%20in%20visual%20cortex%202004-03",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-Shahar%2C%20O.%20Zucker%2C%20S.%20Geometrical%20computations%20explain%20projection%20patterns%20of%20longrange%20horizontal%20connections%20in%20visual%20cortex%202004-03"
        },
        {
            "id": "56",
            "entry": "[56] S. Shushruth, L. Nurminen, M. Bijanzadeh, J. M. Ichida, S. Vanni, and A. Angelucci. Different orientation tuning of nearand far-surround suppression in macaque primary visual cortex mirrors their tuning in human perception. The Journal of neuroscience: the official journal of the Society for Neuroscience, 33(1):106\u2013119, January 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shushruth%2C%20S.%20Nurminen%2C%20L.%20Bijanzadeh%2C%20M.%20Ichida%2C%20J.M.%20Different%20orientation%20tuning%20of%20nearand%20far-surround%20suppression%20in%20macaque%20primary%20visual%20cortex%20mirrors%20their%20tuning%20in%20human%20perception%202013-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shushruth%2C%20S.%20Nurminen%2C%20L.%20Bijanzadeh%2C%20M.%20Ichida%2C%20J.M.%20Different%20orientation%20tuning%20of%20nearand%20far-surround%20suppression%20in%20macaque%20primary%20visual%20cortex%20mirrors%20their%20tuning%20in%20human%20perception%202013-01"
        },
        {
            "id": "57",
            "entry": "[57] H. Tanaka and I. Ohzawa. Surround suppression of V1 neurons mediates orientation-based representation of high-order visual features. Journal of neurophysiology, 101(3):1444\u20131462, March 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tanaka%2C%20H.%20Ohzawa%2C%20I.%20Surround%20suppression%20of%20V1%20neurons%20mediates%20orientation-based%20representation%20of%20high-order%20visual%20features%202009-03",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tanaka%2C%20H.%20Ohzawa%2C%20I.%20Surround%20suppression%20of%20V1%20neurons%20mediates%20orientation-based%20representation%20of%20high-order%20visual%20features%202009-03"
        },
        {
            "id": "58",
            "entry": "[58] J. Kim, M. Ricci, and T. Serre. Not-So-CLEVR: learning same-different relations strains feedforward neural networks. Interface focus, 8(4):20180011, August 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20J.%20Ricci%2C%20M.%20Serre%2C%20T.%20Not-So-CLEVR%3A%20learning%20same-different%20relations%20strains%20feedforward%20neural%20networks%202018-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20J.%20Ricci%2C%20M.%20Serre%2C%20T.%20Not-So-CLEVR%3A%20learning%20same-different%20relations%20strains%20feedforward%20neural%20networks%202018-08"
        },
        {
            "id": "59",
            "entry": "[59] C. Szegedy, Google Inc, W. Zaremba, I. Sutskever, Google Inc, J. Bruna, D. Erhan, Google Inc, I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. In International Conference on Learning Representations (ICLR), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Google%20Inc%2C%20W.Zaremba%20Sutskever%2C%20I.%20Google%20Inc%2C%20J.Bruna%20Intriguing%20properties%20of%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20C.%20Google%20Inc%2C%20W.Zaremba%20Sutskever%2C%20I.%20Google%20Inc%2C%20J.Bruna%20Intriguing%20properties%20of%20neural%20networks%202014"
        },
        {
            "id": "60",
            "entry": "[60] A. Nguyen, J. Yosinski, and J. Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 427\u2013436, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20A.%20Yosinski%2C%20J.%20Clune%2C%20J.%20Deep%20neural%20networks%20are%20easily%20fooled%3A%20High%20confidence%20predictions%20for%20unrecognizable%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20A.%20Yosinski%2C%20J.%20Clune%2C%20J.%20Deep%20neural%20networks%20are%20easily%20fooled%3A%20High%20confidence%20predictions%20for%20unrecognizable%20images%202015"
        },
        {
            "id": "61",
            "entry": "[61] A. Volokitin, G. Roig, and T. A. Poggio. Do deep neural networks suffer from crowding? In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5628\u20135638. Curran Associates, Inc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Volokitin%2C%20A.%20Roig%2C%20G.%20Poggio%2C%20T.A.%20Do%20deep%20neural%20networks%20suffer%20from%20crowding%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Volokitin%2C%20A.%20Roig%2C%20G.%20Poggio%2C%20T.A.%20Do%20deep%20neural%20networks%20suffer%20from%20crowding%3F%202017"
        },
        {
            "id": "62",
            "entry": "[62] K. Ellis, A. Solar-Lezama, and J. Tenenbaum. Unsupervised learning by program synthesis. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 973\u2013981. Curran Associates, Inc., 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20K.%20Solar-Lezama%2C%20A.%20Tenenbaum%2C%20J.%20Unsupervised%20learning%20by%20program%20synthesis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ellis%2C%20K.%20Solar-Lezama%2C%20A.%20Tenenbaum%2C%20J.%20Unsupervised%20learning%20by%20program%20synthesis%202015"
        },
        {
            "id": "63",
            "entry": "[63] P. R. Roelfsema and R. Houtkamp. Incremental grouping of image elements in vision. Attention, perception & psychophysics, 73(8):2542\u20132572, November 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roelfsema%2C%20P.R.%20Houtkamp%2C%20R.%20Incremental%20grouping%20of%20image%20elements%20in%20vision.%20Attention%2C%20perception%20%26%20psychophysics%2C%2073%288%29%202011-11"
        },
        {
            "id": "64",
            "entry": "[64] C. D. Gilbert and W. Li. Top-down influences on visual processing. Nature reviews. Neuroscience, 14(5):350\u2013363, May 2013. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilbert%2C%20C.D.%20Li%2C%20W.%20Top-down%20influences%20on%20visual%20processing%202013-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilbert%2C%20C.D.%20Li%2C%20W.%20Top-down%20influences%20on%20visual%20processing%202013-05"
        }
    ]
}
