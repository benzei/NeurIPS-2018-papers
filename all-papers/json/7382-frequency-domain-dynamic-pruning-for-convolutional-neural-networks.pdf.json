{
    "filename": "7382-frequency-domain-dynamic-pruning-for-convolutional-neural-networks.pdf",
    "metadata": {
        "title": "Frequency-Domain Dynamic Pruning for Convolutional Neural Networks",
        "author": "Zhenhua Liu, Jizheng Xu, Xiulian Peng, Ruiqin Xiong",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7382-frequency-domain-dynamic-pruning-for-convolutional-neural-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Deep convolutional neural networks have demonstrated their powerfulness in a variety of applications. However, the storage and computational requirements have largely restricted their further extensions on mobile devices. Recently, pruning of unimportant parameters has been used for both network compression and acceleration. Considering that there are spatial redundancy within most filters in a CNN, we propose a frequency-domain dynamic pruning scheme to exploit the spatial correlations. The frequency-domain coefficients are pruned dynamically in each iteration and different frequency bands are pruned discriminatively, given their different importance on accuracy. Experimental results demonstrate that the proposed scheme can outperform previous spatial-domain counterparts by a large margin. Specifically, it can achieve a compression ratio of 8.4\u00d7 and a theoretical inference speed-up of 9.2\u00d7 for ResNet-110, while the accuracy is even better than the reference model on CIFAR-10."
    },
    "keywords": [
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "mobile device",
            "url": "https://en.wikipedia.org/wiki/mobile_device"
        },
        {
            "term": "deep convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/deep_convolutional_neural_network"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        }
    ],
    "highlights": [
        "Convolutional neural networks have been performing well in a variety of artificial tasks including image classification, face recognition, natural language processing and speech recognition",
        "The compared results of LeNet and AlexNet are directly acquired from the paper and we train the compressed model of ResNet ourselves as the paper introduced since they didn\u2019t report the results of ResNet",
        "As we mentioned in section 2.1, Frequency-Domain Dynamic Network Pruning and BA-Frequency-Domain Dynamic Network Pruning are appplied to the convolutional layers as well as the first fully-connected layer whose input is the output feature map of convolutional layer and the other fully-connected layers are pruned in spatial domain using the method in [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]",
        "Our Frequency-Domain Dynamic Network Pruning and BA-Frequency-Domain Dynamic Network Pruning methods achieve 20.9\u00d7 and 22.6\u00d7 compression ratios which are better than the spatial-domain pruning methods",
        "We propose a novel approach to compress the convolutional neural networks by dynamically pruning the unimportant weight coefficients in frequency domain",
        "Our BA-Frequency-Domain Dynamic Network Pruning scheme achieves a 8.4\u00d7 of compression and a 9.2\u00d7 of acceleration for ResNet-110 respectively without any loss of accuracy, which outperforms the previous pruning methods by a considerable margins"
    ],
    "key_statements": [
        "Convolutional neural networks have been performing well in a variety of artificial tasks including image classification, face recognition, natural language processing and speech recognition",
        "The compared results of LeNet and AlexNet are directly acquired from the paper and we train the compressed model of ResNet ourselves as the paper introduced since they didn\u2019t report the results of ResNet",
        "As we mentioned in section 2.1, Frequency-Domain Dynamic Network Pruning and BA-Frequency-Domain Dynamic Network Pruning are appplied to the convolutional layers as well as the first fully-connected layer whose input is the output feature map of convolutional layer and the other fully-connected layers are pruned in spatial domain using the method in [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]",
        "Our Frequency-Domain Dynamic Network Pruning and BA-Frequency-Domain Dynamic Network Pruning methods achieve 20.9\u00d7 and 22.6\u00d7 compression ratios which are better than the spatial-domain pruning methods",
        "We propose a novel approach to compress the convolutional neural networks by dynamically pruning the unimportant weight coefficients in frequency domain",
        "Our BA-Frequency-Domain Dynamic Network Pruning scheme achieves a 8.4\u00d7 of compression and a 9.2\u00d7 of acceleration for ResNet-110 respectively without any loss of accuracy, which outperforms the previous pruning methods by a considerable margins"
    ],
    "summary": [
        "Convolutional neural networks have been performing well in a variety of artificial tasks including image classification, face recognition, natural language processing and speech recognition.",
        "We try to fully exploit this spatial correlation and propose a frequency-domain network pruning approach.",
        "Further we apply a dynamic pruning to the DCT coefficients of network filters, since the dynamic method achieves a pretty good performance among the spatial pruning approaches.",
        "In Section 2, we introduce the proposed band-adaptive frequency-domain dynamic pruning scheme.",
        "The proposed frequency-domain dynamic pruning method is introduced.",
        "The same scheme of convolutional layers can be directly applied to implement an inner product in frequency domain.",
        "We show how the proposed frequency-domain dynamic network pruning approach works.",
        "The key point of training pruning networks in frequency domain is the updating scheme of weight coefficients matrix Y .",
        "In the feed-forward phase, the input and weight filters are transformed into frequency domain to complete the computation as shown in Section 2.1.",
        "Suppose \u03be is the ratio of non-zero elements in the compressed weights of spatial-domain pruning method.",
        "Compared to the spatial-domain pruning method, our scheme has an additional computation cost of transformation, a larger compression ratio can be acquired, i.e. less non-zero elements left in compressed parameters, due to the sparser representation of the weight filters.",
        "As we mentioned in section 2.1, FDNP and BA-FDNP are appplied to the convolutional layers as well as the first fully-connected layer whose input is the output feature map of convolutional layer and the other fully-connected layers are pruned in spatial domain using the method in [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>].",
        "Table 3 shows the comparison of our schemes with [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>] and [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] on AlexNet. Our FDNP and BA-FDNP methods achieve 20.9\u00d7 and 22.6\u00d7 compression ratios which are better than the spatial-domain pruning methods.",
        "While applying FDNP and BA-FDNP, we employ the spatial-domain dynamic pruning method in [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] to compress the convolutional layers whose kernel sizes are 1 \u00d7 1.",
        "We consider that it owe to our schemes pruning more coefficients of layers who own larger size of output feature map.",
        "We propose a novel approach to compress the convolutional neural networks by dynamically pruning the unimportant weight coefficients in frequency domain.",
        "The coefficients can be efficiently pruned since they are sparser after 2-D DCT transformation and many spatial-domain pruning methods can be applied.",
        "Our BA-FDNP scheme achieves a 8.4\u00d7 of compression and a 9.2\u00d7 of acceleration for ResNet-110 respectively without any loss of accuracy, which outperforms the previous pruning methods by a considerable margins.",
        "The quantization and Huffman-coding can be applied to the coefficients in frequency domain"
    ],
    "headline": "Considering that there are spatial redundancy within most filters in a CNN, we propose a frequency-domain dynamic pruning scheme to exploit the spatial correlations",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Jaderberg, A. Vedaldi, and A. Zisserman, \u201cSpeeding up convolutional neural networks with low rank expansions,\u201d british machine vision conference, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaderberg%2C%20M.%20Vedaldi%2C%20A.%20Zisserman%2C%20A.%20Speeding%20up%20convolutional%20neural%20networks%20with%20low%20rank%20expansions%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20M.%20Vedaldi%2C%20A.%20Zisserman%2C%20A.%20Speeding%20up%20convolutional%20neural%20networks%20with%20low%20rank%20expansions%2C%202014"
        },
        {
            "id": "2",
            "entry": "[2] X. Zhang, J. Zou, X. Ming, K. He, and J. Sun, \u201cEfficient and accurate approximations of nonlinear convolutional networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1984\u20131992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20X.%20Zou%2C%20J.%20Ming%2C%20X.%20He%2C%20K.%20Efficient%20and%20accurate%20approximations%20of%20nonlinear%20convolutional%20networks%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20X.%20Zou%2C%20J.%20Ming%2C%20X.%20He%2C%20K.%20Efficient%20and%20accurate%20approximations%20of%20nonlinear%20convolutional%20networks%2C%202015"
        },
        {
            "id": "3",
            "entry": "[3] C. Tai, T. Xiao, Y. Zhang, X. Wang, and E. Weinan, \u201cConvolutional neural networks with low-rank regularization,\u201d international conference on learning representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tai%2C%20C.%20Xiao%2C%20T.%20Zhang%2C%20Y.%20Wang%2C%20X.%20Convolutional%20neural%20networks%20with%20low-rank%20regularization%2C%202016"
        },
        {
            "id": "4",
            "entry": "[4] Y. Kim, E. Park, S. Yoo, T. Choi, L. Yang, and D. Shin, \u201cCompression of deep convolutional neural networks for fast and low power mobile applications,\u201d international conference on learning representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Y.%20Park%2C%20E.%20Yoo%2C%20S.%20Choi%2C%20T.%20Compression%20of%20deep%20convolutional%20neural%20networks%20for%20fast%20and%20low%20power%20mobile%20applications%2C%202016"
        },
        {
            "id": "5",
            "entry": "[5] M. Courbariaux, I. Hubara, D. Soudry, R. El-Yaniv, and Y. Bengio, \u201cBinarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1,\u201d arXiv preprint arXiv:1602.02830, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.02830"
        },
        {
            "id": "6",
            "entry": "[6] M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi, \u201cXnor-net: Imagenet classification using binary convolutional neural networks,\u201d in European Conference on Computer Vision. Springer, 2016, pp. 525\u2013542.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rastegari%2C%20M.%20Ordonez%2C%20V.%20Redmon%2C%20J.%20Farhadi%2C%20A.%20%E2%80%9CXnor-net%3A%20Imagenet%20classification%20using%20binary%20convolutional%20neural%20networks%2C%E2%80%9D%20in%20European%20Conference%20on%20Computer%20Vision%202016"
        },
        {
            "id": "7",
            "entry": "[7] Z. Li, B. Ni, W. Zhang, X. Yang, and W. Gao, \u201cPerformance guaranteed network acceleration via high-order residual quantization,\u201d in IEEE International Conference on Computer Vision, 2017, pp. 2603\u20132611.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Z.%20Ni%2C%20B.%20Zhang%2C%20W.%20Yang%2C%20X.%20Performance%20guaranteed%20network%20acceleration%20via%20high-order%20residual%20quantization%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Z.%20Ni%2C%20B.%20Zhang%2C%20W.%20Yang%2C%20X.%20Performance%20guaranteed%20network%20acceleration%20via%20high-order%20residual%20quantization%2C%202017"
        },
        {
            "id": "8",
            "entry": "[8] P. Wang and J. Cheng, \u201cFixed-point factorized networks,\u201d computer vision and pattern recognition, pp. 4012\u20134020, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20P.%20Cheng%2C%20J.%20Fixed-point%20factorized%20networks%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20P.%20Cheng%2C%20J.%20Fixed-point%20factorized%20networks%2C%202016"
        },
        {
            "id": "9",
            "entry": "[9] C. Zhu, S. Han, H. Mao, and W. J. Dally, \u201cTrained ternary quantization,\u201d international conference on learning representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20C.%20Han%2C%20S.%20Mao%2C%20H.%20Dally%2C%20W.J.%20Trained%20ternary%20quantization%2C%202016"
        },
        {
            "id": "10",
            "entry": "[10] N. Mellempudi, A. Kundu, D. Mudigere, D. Das, B. Kaul, and P. Dubey, \u201cTernary neural networks with fine-grained quantization,\u201d arXiv preprint arXiv:1705.01462, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.01462"
        },
        {
            "id": "11",
            "entry": "[11] A. Zhou, A. Yao, Y. Guo, L. Xu, and Y. Chen, \u201cIncremental network quantization: Towards lossless cnns with low-precision weights,\u201d arXiv preprint arXiv:1702.03044, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.03044"
        },
        {
            "id": "12",
            "entry": "[12] S. Han, H. Mao, and W. J. Dally, \u201cDeep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding,\u201d international conference on learning representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Mao%2C%20H.%20Dally%2C%20W.J.%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%2C%202016"
        },
        {
            "id": "13",
            "entry": "[13] J. Wu, C. Leng, Y. Wang, Q. Hu, and J. Cheng, \u201cQuantized convolutional neural networks for mobile devices,\u201d computer vision and pattern recognition, pp. 4820\u20134828, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20J.%20Leng%2C%20C.%20Wang%2C%20Y.%20Hu%2C%20Q.%20Quantized%20convolutional%20neural%20networks%20for%20mobile%20devices%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20J.%20Leng%2C%20C.%20Wang%2C%20Y.%20Hu%2C%20Q.%20Quantized%20convolutional%20neural%20networks%20for%20mobile%20devices%2C%202016"
        },
        {
            "id": "14",
            "entry": "[14] W. Chen, J. T. Wilson, S. Tyree, K. Q. Weinberger, and Y. Chen, \u201cCompressing convolutional neural networks in the frequency domain.,\u201d in KDD, 2016, pp. 1475\u20131484.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20W.%20Wilson%2C%20J.T.%20Tyree%2C%20S.%20Weinberger%2C%20K.Q.%20%E2%80%9CCompressing%20convolutional%20neural%20networks%20in%20the%20frequency%20domain.%2C%E2%80%9D%20in%20KDD%202016"
        },
        {
            "id": "15",
            "entry": "[15] Y. Wang, C. Xu, S. You, D. Tao, and C. Xu, \u201cCnnpack: packing convolutional neural networks in the frequency domain,\u201d in Advances in Neural Information Processing Systems, 2016, pp. 253\u2013261.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Y.%20Xu%2C%20C.%20You%2C%20S.%20Tao%2C%20D.%20Cnnpack%3A%20packing%20convolutional%20neural%20networks%20in%20the%20frequency%20domain%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Y.%20Xu%2C%20C.%20You%2C%20S.%20Tao%2C%20D.%20Cnnpack%3A%20packing%20convolutional%20neural%20networks%20in%20the%20frequency%20domain%2C%202016"
        },
        {
            "id": "16",
            "entry": "[16] Karen Ullrich, Edward Meeds, and Max Welling, \u201cSoft weight-sharing for neural network compression,\u201d arXiv preprint arXiv:1702.04008, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.04008"
        },
        {
            "id": "17",
            "entry": "[17] S. Han, J. Pool, J. Tran, and W. J. Dally, \u201cLearning both weights and connections for efficient neural networks,\u201d neural information processing systems, pp. 1135\u20131143, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Pool%2C%20J.%20Tran%2C%20J.%20Dally%2C%20W.J.%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20networks%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20S.%20Pool%2C%20J.%20Tran%2C%20J.%20Dally%2C%20W.J.%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20networks%2C%202015"
        },
        {
            "id": "18",
            "entry": "[18] Y. Guo, A. Yao, and Y. Chen, \u201cDynamic network surgery for efficient dnns,\u201d in Advances In Neural Information Processing Systems, 2016, pp. 1379\u20131387.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Y.%20Yao%2C%20A.%20Chen%2C%20Y.%20Dynamic%20network%20surgery%20for%20efficient%20dnns%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Y.%20Yao%2C%20A.%20Chen%2C%20Y.%20Dynamic%20network%20surgery%20for%20efficient%20dnns%2C%202016"
        },
        {
            "id": "19",
            "entry": "[19] Y. He, X. Zhang, and J. Sun, \u201cChannel pruning for accelerating very deep neural networks,\u201d in International Conference on Computer Vision (ICCV), 2017, vol. 2, p. 6.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Y.%20Zhang%2C%20X.%20Sun%2C%20J.%20Channel%20pruning%20for%20accelerating%20very%20deep%20neural%20networks%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Y.%20Zhang%2C%20X.%20Sun%2C%20J.%20Channel%20pruning%20for%20accelerating%20very%20deep%20neural%20networks%2C%202017"
        },
        {
            "id": "20",
            "entry": "[20] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov, \u201cVariational dropout sparsifies deep neural networks,\u201d arXiv preprint arXiv:1701.05369, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.05369"
        },
        {
            "id": "21",
            "entry": "[21] Christos Louizos, Karen Ullrich, and Max Welling, \u201cBayesian compression for deep learning,\u201d in Advances in Neural Information Processing Systems, 2017, pp. 3288\u20133298.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Louizos%2C%20Christos%20Ullrich%2C%20Karen%20Welling%2C%20Max%20Bayesian%20compression%20for%20deep%20learning%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Louizos%2C%20Christos%20Ullrich%2C%20Karen%20Welling%2C%20Max%20Bayesian%20compression%20for%20deep%20learning%2C%202017"
        },
        {
            "id": "22",
            "entry": "[22] Christos Louizos, Max Welling, and Diederik P Kingma, \u201cLearning sparse neural networks through l_0 regularization,\u201d arXiv preprint arXiv:1712.01312, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.01312"
        },
        {
            "id": "23",
            "entry": "[23] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry P Vetrov, \u201cStructured bayesian pruning via log-normal multiplicative noise,\u201d in Advances in Neural Information Processing Systems, 2017, pp. 6775\u20136784.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neklyudov%2C%20Kirill%20Molchanov%2C%20Dmitry%20Ashukha%2C%20Arsenii%20Vetrov%2C%20Dmitry%20P.%20Structured%20bayesian%20pruning%20via%20log-normal%20multiplicative%20noise%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neklyudov%2C%20Kirill%20Molchanov%2C%20Dmitry%20Ashukha%2C%20Arsenii%20Vetrov%2C%20Dmitry%20P.%20Structured%20bayesian%20pruning%20via%20log-normal%20multiplicative%20noise%2C%202017"
        },
        {
            "id": "24",
            "entry": "[24] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell, \u201cCaffe: Convolutional architecture for fast feature embedding,\u201d in Proceedings of the 22nd ACM international conference on Multimedia. ACM, 2014, pp. 675\u2013678.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jia%2C%20Yangqing%20Shelhamer%2C%20Evan%20Donahue%2C%20Jeff%20Karayev%2C%20Sergey%20Caffe%3A%20Convolutional%20architecture%20for%20fast%20feature%20embedding%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Yangqing%20Shelhamer%2C%20Evan%20Donahue%2C%20Jeff%20Karayev%2C%20Sergey%20Caffe%3A%20Convolutional%20architecture%20for%20fast%20feature%20embedding%2C%202014"
        },
        {
            "id": "25",
            "entry": "[25] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \u201cGradient-based learning applied to document recognition,\u201d Proceedings of the IEEE, vol. 86, no. 11, pp. 2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%2C%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%2C%201998"
        },
        {
            "id": "26",
            "entry": "[26] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770\u2013778.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%2C%202016"
        },
        {
            "id": "27",
            "entry": "[27] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, \u201cIdentity mappings in deep residual networks,\u201d in European conference on computer vision. Springer, 2016, pp. 630\u2013645. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20%E2%80%9CIdentity%20mappings%20in%20deep%20residual%20networks%2C%E2%80%9D%20in%20European%20conference%20on%20computer%20vision%202016"
        }
    ]
}
