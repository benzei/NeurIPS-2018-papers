{
    "filename": "7865-privacy-amplification-by-subsampling-tight-analyses-via-couplings-and-divergences.pdf",
    "metadata": {
        "title": "Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences",
        "author": "Borja Balle, Gilles Barthe, Marco Gaboardi",
        "date": 2014,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7865-privacy-amplification-by-subsampling-tight-analyses-via-couplings-and-divergences.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Differential privacy comes equipped with multiple analytical tools for the design of private data analyses. One important tool is the so-called \u201cprivacy amplification by subsampling\u201d principle, which ensures that a differentially private mechanism run on a random subsample of a population provides higher privacy guarantees than when run on the entire population. Several instances of this principle have been studied for different random subsampling methods, each with an ad-hoc analysis. In this paper we present a general method that recovers and improves prior analyses, yields lower bounds and derives new instances of privacy amplification by subsampling. Our method leverages a characterization of differential privacy as a divergence which emerged in the program verification community. Furthermore, it introduces new tools, including advanced joint convexity and privacy profiles, which might be of independent interest."
    },
    "keywords": [
        {
            "term": "program verification",
            "url": "https://en.wikipedia.org/wiki/program_verification"
        },
        {
            "term": "privacy amplification",
            "url": "https://en.wikipedia.org/wiki/privacy_amplification"
        },
        {
            "term": "differential privacy",
            "url": "https://en.wikipedia.org/wiki/differential_privacy"
        },
        {
            "term": "analytical tool",
            "url": "https://en.wikipedia.org/wiki/analytical_tool"
        }
    ],
    "highlights": [
        "Subsampling is a fundamental tool in the design and analysis of differentially private mechanisms",
        "The intuition behind the \u201cprivacy amplification by subsampling\u201d principle is that the privacy guarantees of a differentially private mechanism can be amplified by applying it to a small random subsample of records from a given dataset",
        "Our results provide a first step in this direction by showing how privacy amplification resulting from different sampling techniques can be analyzed by means of single set of tools, and by showing how these tools can be used for proving lower bounds",
        "In order to emphasize the relevant properties of M from a privacy amplification point of view, we introduce the concepts of privacy profile and group-privacy profiles",
        "We have developed a general method for reasoning about privacy amplification by subsampling",
        "It would be interesting to study whether our tools can be extended to give concrete bounds on privacy amplification for other privacy notions such as concentrated DP [<a class=\"ref-link\" id=\"cDwork_2016_a\" href=\"#rDwork_2016_a\">Dwork and Rothblum, 2016</a>], zero-concentrated DP [<a class=\"ref-link\" id=\"cBun_2016_a\" href=\"#rBun_2016_a\">Bun and Steinke, 2016</a>], R\u00e9nyi DP [<a class=\"ref-link\" id=\"cMironov_2017_a\" href=\"#rMironov_2017_a\">Mironov, 2017</a>], and truncated concentrated DP [<a class=\"ref-link\" id=\"cBun_et+al_2018_a\" href=\"#rBun_et+al_2018_a\">Bun et al, 2018</a>]"
    ],
    "key_statements": [
        "Subsampling is a fundamental tool in the design and analysis of differentially private mechanisms",
        "The intuition behind the \u201cprivacy amplification by subsampling\u201d principle is that the privacy guarantees of a differentially private mechanism can be amplified by applying it to a small random subsample of records from a given dataset",
        "Many classes of algorithms involve sampling operations, e.g. stochastic optimization methods and Bayesian inference algorithms, and it is not surprising that results quantifying the privacy amplification obtained via subsampling play a key role in designing differentially private versions of these learning algorithms [<a class=\"ref-link\" id=\"cBassily_et+al_2014_a\" href=\"#rBassily_et+al_2014_a\">Bassily et al, 2014</a>, Wang et al, 2015, <a class=\"ref-link\" id=\"cAbadi_et+al_2016_a\" href=\"#rAbadi_et+al_2016_a\">Abadi et al, 2016</a>, J\u00e4lk\u00f6 et al, 2017, Park et al, 2016b,a]",
        "In this type of settings, if the default privacy parameters are not satisfactory one could achieve a stronger privacy guarantee by devising a strategy that only submits to the mechanism a random sample of the data",
        "Despite the practical importance of subsampling, existing tools to bound privacy amplification only work for specific forms of subsampling and typically come with cumbersome proofs providing no information about the tightness of the resulting bounds",
        "Our results provide a first step in this direction by showing how privacy amplification resulting from different sampling techniques can be analyzed by means of single set of tools, and by showing how these tools can be used for proving lower bounds",
        "In order to emphasize the relevant properties of M from a privacy amplification point of view, we introduce the concepts of privacy profile and group-privacy profiles",
        "Distance-compatible Coupling The last tool we need to prove general privacy amplification bounds based on \u03b1-divergences is the existence of a certain type of couplings between two distributions like the ones occurring in the right hand side of (4)",
        "We provide explicit privacy amplification bounds for the most common subsampling methods and neighbouring relations found in the literature on differential privacy, and provide pointers to existing bounds and other related work",
        "One cannot hope to get a meaningful result about the privacy profile of the subsampled mechanism across all inputs sets in 2U ; instead the privacy guarantee will depend on the size of the input dataset as shown in the following result",
        "S -compatible, and \u03c91 and \u03c91 are not. This argument shows that the method we used to analyze the previous settings cannot be extended to analyze Poisson subsampling under the substitution relation, regardless of whether the privacy profile of the base mechanism is given in terms of the replacement/addition or the substitution relation",
        "We have developed a general method for reasoning about privacy amplification by subsampling",
        "It would be interesting to study whether our tools can be extended to give concrete bounds on privacy amplification for other privacy notions such as concentrated DP [<a class=\"ref-link\" id=\"cDwork_2016_a\" href=\"#rDwork_2016_a\">Dwork and Rothblum, 2016</a>], zero-concentrated DP [<a class=\"ref-link\" id=\"cBun_2016_a\" href=\"#rBun_2016_a\">Bun and Steinke, 2016</a>], R\u00e9nyi DP [<a class=\"ref-link\" id=\"cMironov_2017_a\" href=\"#rMironov_2017_a\">Mironov, 2017</a>], and truncated concentrated DP [<a class=\"ref-link\" id=\"cBun_et+al_2018_a\" href=\"#rBun_et+al_2018_a\">Bun et al, 2018</a>]"
    ],
    "summary": [
        "Subsampling is a fundamental tool in the design and analysis of differentially private mechanisms.",
        "Regardless of the specific setting being considered, the main challenge in the analysis of privacy amplification by subsampling resides in the fact that the output distribution of the mechanism \u03bc = MS (x) \u2208 P(Z) is a mixture distribution.",
        "The proof of Theorem 4 implicitly provides a characterization of privacy profiles in terms of privacy loss random variables that holds for any mechanism.",
        "Distance-compatible Coupling The last tool we need to prove general privacy amplification bounds based on \u03b1-divergences is the existence of a certain type of couplings between two distributions like the ones occurring in the right hand side of (4).",
        "In this case the subsampling mechanism S\u03b3po : 2U \u2192 P(2U ) takes a set x and outputs a sample y from the distribution \u03c9ind=epSen\u03b3podtlysuapdpdoirntegdtoonyalwl isteht y \u2286 x given by \u03c9(y) = \u03b3|y|(1 \u2212 probability \u03b3 each element from \u03b3 )|x|\u2212|y| .",
        "In the context of the moments accountant technique based on the moment generating function of the privacy loss random variable, [<a class=\"ref-link\" id=\"cAbadi_et+al_2016_a\" href=\"#rAbadi_et+al_2016_a\">Abadi et al, 2016</a>] provide an amplification result for Gaussian output perturbation mechanisms under Poisson subsampling.",
        "\u2192 P(Z) is in bounding defined on multisets and the privacy profile of the has privacy subsampled mechanism MSm wr : 2nU \u2192 P(Z) with respect to s.",
        "One cannot hope to get a meaningful result about the privacy profile of the subsampled mechanism across all inputs sets in 2U ; instead the privacy guarantee will depend on the size of the input dataset as shown in the following result.",
        "This argument shows that the method we used to analyze the previous settings cannot be extended to analyze Poisson subsampling under the substitution relation, regardless of whether the privacy profile of the base mechanism is given in terms of the replacement/addition or the substitution relation.",
        "Even without distance-compatible couplings it is possible to provide privacy amplification bounds for Poisson subsampling with respect to the substitution relation, the resulting bound is quite cumbersome.",
        "We prove a general lemma that can be used to obtain tightness results for any subsampling mechanism and any neighbouring relation satisfying two natural assumptions.",
        "An alternative approach is to extend the recent results for R\u00e9nyi DP amplification by subsampling without replacement given in [Wang et al, 2018] to more general notions of subsampling and neighbouring relations."
    ],
    "headline": "In this paper we present a general method that recovers and improves prior analyses, yields lower bounds and derives new instances of privacy amplification by subsampling",
    "reference_links": [
        {
            "id": "Abadi_et+al_2016_a",
            "entry": "Mart\u00edn Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 308\u2013318. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20Mart%C3%ADn%20Chu%2C%20Andy%20Ian%20Goodfellow%2C%20H.Brendan%20McMahan%20Mironov%2C%20Ilya%20Deep%20learning%20with%20differential%20privacy%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20Mart%C3%ADn%20Chu%2C%20Andy%20Ian%20Goodfellow%2C%20H.Brendan%20McMahan%20Mironov%2C%20Ilya%20Deep%20learning%20with%20differential%20privacy%202016"
        },
        {
            "id": "Balle_2018_a",
            "entry": "Borja Balle and Yu-Xiang Wang. Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising. In Proceedings of the 35th International Conference on Machine Learning, ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balle%2C%20Borja%20Wang%2C%20Yu-Xiang%20Improving%20the%20gaussian%20mechanism%20for%20differential%20privacy%3A%20Analytical%20calibration%20and%20optimal%20denoising%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balle%2C%20Borja%20Wang%2C%20Yu-Xiang%20Improving%20the%20gaussian%20mechanism%20for%20differential%20privacy%3A%20Analytical%20calibration%20and%20optimal%20denoising%202018"
        },
        {
            "id": "Gilles_2012_a",
            "entry": "Gilles Barthe, Boris K\u00f6pf, Federico Olmedo, and Santiago Zanella B\u00e9guelin. Probabilistic relational reasoning for differential privacy. In Symposium on Principles of Programming Languages (POPL), pages 97\u2013110, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilles%20Barthe%2C%20Boris%20K%C3%B6pf%2C%20Federico%20Olmedo%20B%C3%A9guelin%2C%20Santiago%20Zanella%20Probabilistic%20relational%20reasoning%20for%20differential%20privacy%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilles%20Barthe%2C%20Boris%20K%C3%B6pf%2C%20Federico%20Olmedo%20B%C3%A9guelin%2C%20Santiago%20Zanella%20Probabilistic%20relational%20reasoning%20for%20differential%20privacy%202012"
        },
        {
            "id": "Barthe_et+al_2016_a",
            "entry": "Gilles Barthe, Marco Gaboardi, Benjamin Gr\u00e9goire, Justin Hsu, and Pierre-Yves Strub. Proving differential privacy via probabilistic couplings. In Symposium on Logic in Computer Science (LICS), pages 749\u2013758, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barthe%2C%20Gilles%20Gaboardi%2C%20Marco%20Gr%C3%A9goire%2C%20Benjamin%20Hsu%2C%20Justin%20Proving%20differential%20privacy%20via%20probabilistic%20couplings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barthe%2C%20Gilles%20Gaboardi%2C%20Marco%20Gr%C3%A9goire%2C%20Benjamin%20Hsu%2C%20Justin%20Proving%20differential%20privacy%20via%20probabilistic%20couplings%202016"
        },
        {
            "id": "Bassily_et+al_2014_a",
            "entry": "Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on, pages 464\u2013473. IEEE, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bassily%2C%20Raef%20Smith%2C%20Adam%20Thakurta%2C%20Abhradeep%20Private%20empirical%20risk%20minimization%3A%20Efficient%20algorithms%20and%20tight%20error%20bounds%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bassily%2C%20Raef%20Smith%2C%20Adam%20Thakurta%2C%20Abhradeep%20Private%20empirical%20risk%20minimization%3A%20Efficient%20algorithms%20and%20tight%20error%20bounds%202014"
        },
        {
            "id": "Beimel_et+al_2013_a",
            "entry": "Amos Beimel, Kobbi Nissim, and Uri Stemmer. Characterizing the sample complexity of private learners. In Proceedings of the 4th conference on Innovations in Theoretical Computer Science, pages 97\u2013110. ACM, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beimel%2C%20Amos%20Nissim%2C%20Kobbi%20Stemmer%2C%20Uri%20Characterizing%20the%20sample%20complexity%20of%20private%20learners%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beimel%2C%20Amos%20Nissim%2C%20Kobbi%20Stemmer%2C%20Uri%20Characterizing%20the%20sample%20complexity%20of%20private%20learners%202013"
        },
        {
            "id": "Beimel_et+al_2014_a",
            "entry": "Amos Beimel, Hai Brenner, Shiva Prasad Kasiviswanathan, and Kobbi Nissim. Bounds on the sample complexity for private learning and private data release. Machine learning, 94(3):401\u2013437, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beimel%2C%20Amos%20Brenner%2C%20Hai%20Kasiviswanathan%2C%20Shiva%20Prasad%20Nissim%2C%20Kobbi%20Bounds%20on%20the%20sample%20complexity%20for%20private%20learning%20and%20private%20data%20release%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beimel%2C%20Amos%20Brenner%2C%20Hai%20Kasiviswanathan%2C%20Shiva%20Prasad%20Nissim%2C%20Kobbi%20Bounds%20on%20the%20sample%20complexity%20for%20private%20learning%20and%20private%20data%20release%202014"
        },
        {
            "id": "Bun_2016_a",
            "entry": "Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. In Theory of Cryptography - 14th International Conference, TCC 2016-B, Beijing, China, October 31 - November 3, 2016, Proceedings, Part I, pages 635\u2013658, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bun%2C%20Mark%20Steinke%2C%20Thomas%20Concentrated%20differential%20privacy%3A%20Simplifications%2C%20extensions%2C%20and%20lower%20bounds%202016-10-31",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bun%2C%20Mark%20Steinke%2C%20Thomas%20Concentrated%20differential%20privacy%3A%20Simplifications%2C%20extensions%2C%20and%20lower%20bounds%202016-10-31"
        },
        {
            "id": "Bun_et+al_2015_a",
            "entry": "Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. In Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on, pages 634\u2013649. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bun%2C%20Mark%20Nissim%2C%20Kobbi%20Stemmer%2C%20Uri%20Vadhan%2C%20Salil%20Differentially%20private%20release%20and%20learning%20of%20threshold%20functions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bun%2C%20Mark%20Nissim%2C%20Kobbi%20Stemmer%2C%20Uri%20Vadhan%2C%20Salil%20Differentially%20private%20release%20and%20learning%20of%20threshold%20functions%202015"
        },
        {
            "id": "Bun_et+al_2018_a",
            "entry": "Mark Bun, Cynthia Dwork, Guy Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated cdp. In Symposium on Theory of Computing, STOC, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bun%2C%20Mark%20Dwork%2C%20Cynthia%20Rothblum%2C%20Guy%20Steinke%2C%20Thomas%20Composable%20and%20versatile%20privacy%20via%20truncated%20cdp%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bun%2C%20Mark%20Dwork%2C%20Cynthia%20Rothblum%2C%20Guy%20Steinke%2C%20Thomas%20Composable%20and%20versatile%20privacy%20via%20truncated%20cdp%202018"
        },
        {
            "id": "Dwork_2014_a",
            "entry": "Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science, 9(3-4):211\u2013407, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Roth%2C%20Aaron%20The%20algorithmic%20foundations%20of%20differential%20privacy%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Roth%2C%20Aaron%20The%20algorithmic%20foundations%20of%20differential%20privacy%202014"
        },
        {
            "id": "Dwork_2016_a",
            "entry": "Cynthia Dwork and Guy N Rothblum. Concentrated differential privacy. arXiv preprint arXiv:1603.01887, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.01887"
        },
        {
            "id": "Dwork_et+al_2010_a",
            "entry": "Cynthia Dwork, Guy N Rothblum, and Salil Vadhan. Boosting and differential privacy. In Foundations of Computer Science (FOCS), 2010 51st Annual IEEE Symposium on, pages 51\u201360. IEEE, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Rothblum%2C%20Guy%20N.%20Vadhan%2C%20Salil%20Boosting%20and%20differential%20privacy%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Rothblum%2C%20Guy%20N.%20Vadhan%2C%20Salil%20Boosting%20and%20differential%20privacy%202010"
        },
        {
            "id": "Jaelkoe_et+al_2017_a",
            "entry": "Joonas J\u00e4lk\u00f6, Antti Honkela, and Onur Dikmen. Differentially private variational inference for non-conjugate models. In Proceedings of the Thirty-Third Conference on Uncertainty in Artificial Intelligence, UAI 2017, Sydney, Australia, August 11-15, 2017, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=J%C3%A4lk%C3%B6%2C%20Joonas%20Honkela%2C%20Antti%20Dikmen%2C%20Onur%20Differentially%20private%20variational%20inference%20for%20non-conjugate%20models%202017-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=J%C3%A4lk%C3%B6%2C%20Joonas%20Honkela%2C%20Antti%20Dikmen%2C%20Onur%20Differentially%20private%20variational%20inference%20for%20non-conjugate%20models%202017-08"
        },
        {
            "id": "Kairouz_et+al_2017_a",
            "entry": "Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. IEEE Transactions on Information Theory, 63(6):4037\u20134049, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kairouz%2C%20Peter%20Oh%2C%20Sewoong%20Viswanath%2C%20Pramod%20The%20composition%20theorem%20for%20differential%20privacy%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kairouz%2C%20Peter%20Oh%2C%20Sewoong%20Viswanath%2C%20Pramod%20The%20composition%20theorem%20for%20differential%20privacy%202017"
        },
        {
            "id": "Kasiviswanathan_et+al_2011_a",
            "entry": "Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. What can we learn privately? SIAM Journal on Computing, 40(3):793\u2013826, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kasiviswanathan%2C%20Shiva%20Prasad%20Lee%2C%20Homin%20K.%20Nissim%2C%20Kobbi%20Raskhodnikova%2C%20Sofya%20What%20can%20we%20learn%20privately%3F%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kasiviswanathan%2C%20Shiva%20Prasad%20Lee%2C%20Homin%20K.%20Nissim%2C%20Kobbi%20Raskhodnikova%2C%20Sofya%20What%20can%20we%20learn%20privately%3F%202011"
        },
        {
            "id": "Li_et+al_2012_a",
            "entry": "Ninghui Li, Wahbeh Qardaji, and Dong Su. On sampling, anonymization, and differential privacy or, k-anonymization meets differential privacy. In Proceedings of the 7th ACM Symposium on Information, Computer and Communications Security, pages 32\u201333. ACM, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Ninghui%20Qardaji%2C%20Wahbeh%20Su%2C%20Dong%20On%20sampling%2C%20anonymization%2C%20and%20differential%20privacy%20or%2C%20k-anonymization%20meets%20differential%20privacy%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Ninghui%20Qardaji%2C%20Wahbeh%20Su%2C%20Dong%20On%20sampling%2C%20anonymization%2C%20and%20differential%20privacy%20or%2C%20k-anonymization%20meets%20differential%20privacy%202012"
        },
        {
            "id": "Mironov_2017_a",
            "entry": "Ilya Mironov. R\u00e9nyi differential privacy. In 30th IEEE Computer Security Foundations Symposium, CSF 2017, Santa Barbara, CA, USA, August 21-25, 2017, pages 263\u2013275, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mironov%2C%20Ilya%20R%C3%A9nyi%20differential%20privacy%202017-08-21",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mironov%2C%20Ilya%20R%C3%A9nyi%20differential%20privacy%202017-08-21"
        },
        {
            "id": "Oesterreicher_2002_a",
            "entry": "Ferdinand \u00d6sterreicher. Csisz\u00e1r\u2019s f-divergences-basic properties. RGMIA Res. Rep. Coll, 2002. Mijung Park, James R. Foulds, Kamalika Chaudhuri, and Max Welling. Private topic modeling.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=%C3%96sterreicher%2C%20Ferdinand%20Csisz%C3%A1r%E2%80%99s%20f-divergences-basic%20properties.%20RGMIA%20Res%202002-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=%C3%96sterreicher%2C%20Ferdinand%20Csisz%C3%A1r%E2%80%99s%20f-divergences-basic%20properties.%20RGMIA%20Res%202002-06"
        },
        {
            "id": "Corr_2016_a",
            "entry": "CoRR, abs/1609.04120, 2016a. Mijung Park, James R. Foulds, Kamalika Chaudhuri, and Max Welling. Variational bayes in private settings (VIPS). CoRR, abs/1611.00340, 2016b. Igal Sason and Sergio Verd\u00fa. f -divergence inequalities. IEEE Transactions on Information Theory, 62(11):5973\u20136006, 2016. Jonathan Ullman. Cs7880: Rigorous approaches to data privacy. http://www.ccs.neu.edu/",
            "url": "http://www.ccs.neu.edu/",
            "arxiv_url": "https://arxiv.org/pdf/1609.04120"
        },
        {
            "id": "Home_2017_a",
            "entry": "home/jullman/PrivacyS17/HW1sol.pdf, 2017. Salil P. Vadhan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography., pages 347\u2013450. 2017. Yu-Xiang Wang, Stephen Fienberg, and Alex Smola. Privacy for free: Posterior sampling and stochastic gradient monte carlo. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 2493\u20132502, 2015. Yu-Xiang Wang, Jing Lei, and Stephen E. Fienberg. Learning with differential privacy: Stability, learnability and the sufficiency and necessity of erm principle. Journal of Machine Learning Research, 17(183):1\u201340, 2016. Yu-Xiang Wang, Borja Balle, and Shiva Kasiviswanathan. Subsampled r\u00e9nyi differential privacy and analytical moments accountant. ArXiv e-prints, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=home/jullman/PrivacyS17/HW1sol.pdf%2C%202017.%20Salil%20P.%20Vadhan%20The%20complexity%20of%20differential%20privacy%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=home/jullman/PrivacyS17/HW1sol.pdf%2C%202017.%20Salil%20P.%20Vadhan%20The%20complexity%20of%20differential%20privacy%202017"
        }
    ]
}
