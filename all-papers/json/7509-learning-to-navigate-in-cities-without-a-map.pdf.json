{
    "filename": "7509-learning-to-navigate-in-cities-without-a-map.pdf",
    "metadata": {
        "title": "Learning to Navigate in Cities Without a Map",
        "author": "Piotr Mirowski, Matt Grimes, Mateusz Malinowski, Karl Moritz Hermann, Keith Anderson, Denis Teplyashin, Karen Simonyan, koray kavukcuoglu, Andrew Zisserman, Raia Hadsell",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7509-learning-to-navigate-in-cities-without-a-map.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Navigating through unstructured environments is a basic capability of intelligent creatures, and thus is of fundamental interest in the study and development of artificial intelligence. Long-range navigation is a complex cognitive task that relies on developing an internal representation of space, grounded by recognisable landmarks and robust visual processing, that can simultaneously support continuous self-localisation (\u201cI am here\u201d) and a representation of the goal (\u201cI am going there\u201d). Building upon recent research that applies deep reinforcement learning to maze navigation problems, we present an end-to-end deep reinforcement learning approach that can be applied on a city scale. Recognising that successful navigation relies on integration of general policies with localespecific knowledge, we propose a dual pathway architecture that allows localespecific features to be encapsulated, while still enabling transfer to multiple cities. A key contribution of this paper is an interactive navigation environment that uses Google Street View for its photographic content and worldwide coverage. Our baselines demonstrate that deep reinforcement learning agents can learn to navigate in multiple cities and to traverse to target destinations that may be kilometres away. A video summarizing our research and showing the trained agent in diverse city environments as well as on the transfer task is available at: https://sites.google.com/view/learn-navigate-cities-nips18."
    },
    "keywords": [
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "world environment",
            "url": "https://en.wikipedia.org/wiki/World_Environment"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "agent architecture",
            "url": "https://en.wikipedia.org/wiki/agent_architecture"
        },
        {
            "term": "google street view",
            "url": "https://en.wikipedia.org/wiki/google_street_view"
        },
        {
            "term": "convolutional neural networks",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_networks"
        },
        {
            "term": "street view",
            "url": "https://en.wikipedia.org/wiki/street_view"
        }
    ],
    "highlights": [
        "The primary contributions of this paper are (a) to present a new reinforcement learning challenge that features real world visual navigation through city-scale environments, and (b) to propose a modular, goal-conditional deep reinforcement learning algorithm that can solve this task, providing a strong baseline for future research",
        "Just as humans can learn to navigate a city without relying on maps, GPS localisation, or other aids, it is our aim to show that a neural network agent can learn to traverse entire cities using only visual observations",
        "In order to realise this aim, we designed an interactive environment that uses the images and underlying connectivity information from Google Street View, and propose a dual pathway agent architecture that can navigate within the environment",
        "Navigation is an important cognitive task that enables humans and animals to traverse a complex world without maps",
        "We have presented a city-scale real-world environment for training reinforcement learning navigation agents, introduced and analysed a new courier task, demonstrated that deep reinforcement learning algorithms can be applied to problems involving large-scale real-world data, and presented a multi-city neural network agent architecture that demonstrates transfer to new environments",
        "A multi-city version of the Street View based reinforcement learning environment, with carefully processed images provided by Google Street View, as well as code for building and training an agent, will be released before the 2018 conference and accessible from https://sites.google.com/view/learn-navigate-cities-nips18"
    ],
    "key_statements": [
        "The primary contributions of this paper are (a) to present a new reinforcement learning challenge that features real world visual navigation through city-scale environments, and (b) to propose a modular, goal-conditional deep reinforcement learning algorithm that can solve this task, providing a strong baseline for future research",
        "Just as humans can learn to navigate a city without relying on maps, GPS localisation, or other aids, it is our aim to show that a neural network agent can learn to traverse entire cities using only visual observations",
        "In order to realise this aim, we designed an interactive environment that uses the images and underlying connectivity information from Google Street View, and propose a dual pathway agent architecture that can navigate within the environment",
        "Navigation is an important cognitive task that enables humans and animals to traverse a complex world without maps",
        "We have presented a city-scale real-world environment for training reinforcement learning navigation agents, introduced and analysed a new courier task, demonstrated that deep reinforcement learning algorithms can be applied to problems involving large-scale real-world data, and presented a multi-city neural network agent architecture that demonstrates transfer to new environments",
        "A multi-city version of the Street View based reinforcement learning environment, with carefully processed images provided by Google Street View, as well as code for building and training an agent, will be released before the 2018 conference and accessible from https://sites.google.com/view/learn-navigate-cities-nips18"
    ],
    "summary": [
        "The primary contributions of this paper are (a) to present a new RL challenge that features real world visual navigation through city-scale environments, and (b) to propose a modular, goal-conditional deep RL algorithm that can solve this task, providing a strong baseline for future research.",
        "Within this environment we have developed a traversal task that requires that the agent navigates from goal to goal within London, Paris and New York City.",
        "Rather than using a map, or an external memory, we propose an architecture with two recurrent pathways that can effectively address a challenging navigation task in a single city as well as transfer to new cities or regions by training only a new locale-specific pathway.",
        "To support sparse reward signals in these environments, recent navigational agents use auxiliary tasks in training [<a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>, <a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>].",
        "We prefer curriculum learning to reward shaping on large areas because the former approach keeps agent training consistent with its experience at test time and reduces the risk of learning degenerate strategies such as ascending the gradient of increasing rewards to reach the goal, rather than learn to read the goal specification gt.",
        "We choose a curriculum that starts by sampling the goal within a radius of 500m from the agent\u2019s location, and progressively grows that disc until it reaches the maximum distance an agent could travel within the environment (e.g., 3.5km, and 5km in the NYU and London environments respectively) by the end of the training.",
        "While the nature of our courier task precludes zero-shot navigation in a new city without retraining, we test the CityNav agent\u2019s ability to exploit local linearities of the goal representation to handle unseen goal locations.",
        "While the transfer learning performance of the agent is lower than the stronger agent trained jointly on all the areas, the agent significantly outperforms the baselines and demonstrates goal-dependent navigation.",
        "We have presented a city-scale real-world environment for training RL navigation agents, introduced and analysed a new courier task, demonstrated that deep RL algorithms can be applied to problems involving large-scale real-world data, and presented a multi-city neural network agent architecture that demonstrates transfer to new environments.",
        "A multi-city version of the Street View based RL environment, with carefully processed images provided by Google Street View, as well as code for building and training an agent, will be released before the 2018 conference and accessible from https://sites.google.com/view/learn-navigate-cities-nips18.",
        "Future work will involve learning landmarks from images and scaling up the navigation and path-planning thanks to hierarchical RL approaches"
    ],
    "headline": "Building upon recent research that applies deep reinforcement learning to maze navigation problems, we present an end-to-end deep reinforcement learning approach that can be applied on a city scale",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko S\u00fcnderhauf, Ian Reid, Stephen Gould, and Anton van den Hengel. Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments. arXiv preprint arXiv:1711.07280, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.07280"
        },
        {
            "id": "2",
            "entry": "[2] Andrea Banino, Caswell Barry, Benigno Uria, Charles Blundell, Timothy Lillicrap, Piotr Mirowski, Alexander Pritzel, Martin J Chadwick, Thomas Degris, Joseph Modayil, et al. Vector-based navigation using grid-like representations in artificial agents. Nature, page 1, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Banino%2C%20Andrea%20Barry%2C%20Caswell%20Uria%2C%20Benigno%20Blundell%2C%20Charles%20Vector-based%20navigation%20using%20grid-like%20representations%20in%20artificial%20agents%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Banino%2C%20Andrea%20Barry%2C%20Caswell%20Uria%2C%20Benigno%20Blundell%2C%20Charles%20Vector-based%20navigation%20using%20grid-like%20representations%20in%20artificial%20agents%202018"
        },
        {
            "id": "3",
            "entry": "[3] Charles Beattie, Joel Z Leibo, Denis Teplyashin, Tom Ward, Marcus Wainwright, Heinrich K\u00fcttler, Andrew Lefrancq, Simon Green, V\u00edctor Vald\u00e9s, Amir Sadik, et al. Deepmind lab. arXiv preprint arXiv:1612.03801, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.03801"
        },
        {
            "id": "4",
            "entry": "[4] Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In Proceedings of the 26th annual international conference on machine learning, pages 41\u201348. ACM, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Yoshua%20Louradour%2C%20J%C3%A9r%C3%B4me%20Collobert%2C%20Ronan%20Weston%2C%20Jason%20Curriculum%20learning%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Yoshua%20Louradour%2C%20J%C3%A9r%C3%B4me%20Collobert%2C%20Ronan%20Weston%2C%20Jason%20Curriculum%20learning%202009"
        },
        {
            "id": "5",
            "entry": "[5] Rodrigo F Berriel, Lucas Tabelini Torres, Vinicius B Cardoso, R\u00e2nik Guidolini, Claudine Badue, Alberto F De Souza, and Thiago Oliveira-Santos. Heading direction estimation using deep learning with automatic large-scale data acquisition. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berriel%2C%20Rodrigo%20F.%20Torres%2C%20Lucas%20Tabelini%20Cardoso%2C%20Vinicius%20B.%20Guidolini%2C%20R%C3%A2nik%20and%20Thiago%20Oliveira-Santos.%20Heading%20direction%20estimation%20using%20deep%20learning%20with%20automatic%20large-scale%20data%20acquisition%202018"
        },
        {
            "id": "6",
            "entry": "[6] Samarth Brahmbhatt and James Hays. Deepnav: Learning to navigate large cities. arXiv preprint arXiv:1701.09135, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.09135"
        },
        {
            "id": "7",
            "entry": "[7] Jake Bruce, Niko S\u00fcnderhauf, Piotr Mirowski, Raia Hadsell, and Michael Milford. One-shot reinforcement learning for robot navigation with interactive replay. arXiv preprint arXiv:1711.10137, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.10137"
        },
        {
            "id": "8",
            "entry": "[8] Gino Brunner, Oliver Richter, Yuyi Wang, and Roger Wattenhofer. Teaching a machine to read maps with deep reinforcement learning. arXiv preprint arXiv:1711.07479, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.07479"
        },
        {
            "id": "9",
            "entry": "[9] Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Nie\u00dfner, Manolis Savva, Shuran Song, Andy Zeng, and Yinda Zhang. Matterport3d: Learning from rgb-d data in indoor environments. arXiv preprint arXiv:1709.06158, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.06158"
        },
        {
            "id": "10",
            "entry": "[10] Devendra Singh Chaplot, Emilio Parisotto, and Ruslan Salakhutdinov. Active neural localization. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaplot%2C%20Devendra%20Singh%20Parisotto%2C%20Emilio%20Salakhutdinov%2C%20Ruslan%20Active%20neural%20localization%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaplot%2C%20Devendra%20Singh%20Parisotto%2C%20Emilio%20Salakhutdinov%2C%20Ruslan%20Active%20neural%20localization%202018"
        },
        {
            "id": "11",
            "entry": "[11] Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, and Ruslan Salakhutdinov. Gated-attention architectures for task-oriented language grounding. arXiv preprint arXiv:1706.07230, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.07230"
        },
        {
            "id": "12",
            "entry": "[12] Christopher J Cueva and Xue-Xin Wei. Emergence of grid-like representations by training recurrent neural networks to perform spatial localization. arXiv preprint arXiv:1803.07770, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.07770"
        },
        {
            "id": "13",
            "entry": "[13] Coline Devin, Abhishek Gupta, Trevor Darrell, Pieter Abbeel, and Sergey Levine. Learning modular neural network policies for multi-task and multi-robot transfer. In Robotics and Automation (ICRA), 2017 IEEE International Conference on, pages 2169\u20132176. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Devin%2C%20Coline%20Gupta%2C%20Abhishek%20Darrell%2C%20Trevor%20Abbeel%2C%20Pieter%20Learning%20modular%20neural%20network%20policies%20for%20multi-task%20and%20multi-robot%20transfer%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Devin%2C%20Coline%20Gupta%2C%20Abhishek%20Darrell%2C%20Trevor%20Abbeel%2C%20Pieter%20Learning%20modular%20neural%20network%20policies%20for%20multi-task%20and%20multi-robot%20transfer%202017"
        },
        {
            "id": "14",
            "entry": "[14] Vikas Dhiman, Shurjo Banerjee, Brent Griffin, Jeffrey M Siskind, and Jason J Corso. A critical investigation of deep reinforcement learning for navigation. arXiv preprint arXiv:1802.02274, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.02274"
        },
        {
            "id": "15",
            "entry": "[15] Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. Long-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2625\u20132634, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20Jeffrey%20Hendricks%2C%20Lisa%20Anne%20Guadarrama%2C%20Sergio%20Rohrbach%2C%20Marcus%20Long-term%20recurrent%20convolutional%20networks%20for%20visual%20recognition%20and%20description%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20Jeffrey%20Hendricks%2C%20Lisa%20Anne%20Guadarrama%2C%20Sergio%20Rohrbach%2C%20Marcus%20Long-term%20recurrent%20convolutional%20networks%20for%20visual%20recognition%20and%20description%202015"
        },
        {
            "id": "16",
            "entry": "[16] Alexey Dosovitskiy and Vladlen Koltun. Learning to act by predicting the future. arXiv preprint arXiv:1611.01779, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01779"
        },
        {
            "id": "17",
            "entry": "[17] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio L\u00f3pez, and Vladlen Koltun. Carla: An open urban driving simulator. arXiv preprint arXiv:1711.03938, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.03938"
        },
        {
            "id": "18",
            "entry": "[18] Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane Legg, and Koray Kavukcuoglu. Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures. arXiv preprint arXiv:1802.01561, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.01561"
        },
        {
            "id": "19",
            "entry": "[19] Alex Graves, Marc G Bellemare, Jacob Menick, Remi Munos, and Koray Kavukcuoglu. Automated curriculum learning for neural networks. arXiv preprint arXiv:1704.03003, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.03003"
        },
        {
            "id": "20",
            "entry": "[20] Saurabh Gupta, James Davidson, Sergey Levine, Rahul Sukthankar, and Jitendra Malik. Cognitive mapping and planning for visual navigation. arXiv preprint arXiv:1702.03920, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.03920"
        },
        {
            "id": "21",
            "entry": "[21] Saurabh Gupta, David Fouhey, Sergey Levine, and Jitendra Malik. Unifying map and landmark based representations for visual navigation. arXiv preprint arXiv:1712.08125, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.08125"
        },
        {
            "id": "22",
            "entry": "[22] Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan Faulkner, Hubert Soyer, David Szepesvari, Wojtek Czarnecki, Max Jaderberg, Denis Teplyashin, et al. Grounded language learning in a simulated 3d world. arXiv preprint arXiv:1706.06551, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.06551"
        },
        {
            "id": "23",
            "entry": "[23] Felix Hill, Karl Moritz Hermann, Phil Blunsom, and Stephen Clark. Understanding grounded language learning agents. arXiv preprint arXiv:1710.09867, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.09867"
        },
        {
            "id": "24",
            "entry": "[24] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "25",
            "entry": "[25] Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, and Koray Kavukcuoglu. Reinforcement learning with unsupervised auxiliary tasks. arXiv preprint arXiv:1611.05397, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.05397"
        },
        {
            "id": "26",
            "entry": "[26] Micha\u0142 Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek, and Wojciech Jaskowski. Vizdoom: A doom-based ai research platform for visual reinforcement learning. In Computational Intelligence and Games (CIG), 2016 IEEE Conference on, pages 1\u20138. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kempka%2C%20Micha%C5%82%20Wydmuch%2C%20Marek%20Runc%2C%20Grzegorz%20Toczek%2C%20Jakub%20Vizdoom%3A%20A%20doom-based%20ai%20research%20platform%20for%20visual%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kempka%2C%20Micha%C5%82%20Wydmuch%2C%20Marek%20Runc%2C%20Grzegorz%20Toczek%2C%20Jakub%20Vizdoom%3A%20A%20doom-based%20ai%20research%20platform%20for%20visual%20reinforcement%20learning%202016"
        },
        {
            "id": "27",
            "entry": "[27] Arbaaz Khan, Clark Zhang, Nikolay Atanasov, Konstantinos Karydis, Vijay Kumar, and Daniel D Lee. Memory augmented control networks. arXiv preprint arXiv:1709.05706, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.05706"
        },
        {
            "id": "28",
            "entry": "[28] Aditya Khosla, Byoungkwon An An, Joseph J Lim, and Antonio Torralba. Looking beyond the visible scene. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3710\u20133717, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khosla%2C%20Aditya%20An%2C%20Byoungkwon%20An%20Lim%2C%20Joseph%20J.%20Torralba%2C%20Antonio%20Looking%20beyond%20the%20visible%20scene%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khosla%2C%20Aditya%20An%2C%20Byoungkwon%20An%20Lim%2C%20Joseph%20J.%20Torralba%2C%20Antonio%20Looking%20beyond%20the%20visible%20scene%202014"
        },
        {
            "id": "29",
            "entry": "[29] Eric Kolve, Roozbeh Mottaghi, Daniel Gordon, Yuke Zhu, Abhinav Gupta, and Ali Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.05474, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.05474"
        },
        {
            "id": "30",
            "entry": "[30] Guillaume Lample and Devendra Singh Chaplot. Playing FPS games with deep reinforcement learning. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20Guillaume%20Chaplot%2C%20Devendra%20Singh%20Playing%20FPS%20games%20with%20deep%20reinforcement%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lample%2C%20Guillaume%20Chaplot%2C%20Devendra%20Singh%20Playing%20FPS%20games%20with%20deep%20reinforcement%20learning%202017"
        },
        {
            "id": "31",
            "entry": "[31] Mateusz Malinowski, Marcus Rohrbach, and Mario Fritz. Ask your neurons: A deep learning approach to visual question answering. International Journal of Computer Vision, 125(1-3):110\u2013 135, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Malinowski%2C%20Mateusz%20Rohrbach%2C%20Marcus%20Fritz%2C%20Mario%20Ask%20your%20neurons%3A%20A%20deep%20learning%20approach%20to%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Malinowski%2C%20Mateusz%20Rohrbach%2C%20Marcus%20Fritz%2C%20Mario%20Ask%20your%20neurons%3A%20A%20deep%20learning%20approach%20to%20visual%20question%20answering%202017"
        },
        {
            "id": "32",
            "entry": "[32] Michael J Milford, Gordon F Wyeth, and David Prasser. Ratslam: a hippocampal model for simultaneous localization and mapping. In Robotics and Automation, 2004. Proceedings. ICRA\u201904. 2004 IEEE International Conference on, volume 1, pages 403\u2013408. IEEE, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Milford%2C%20Michael%20J.%20Wyeth%2C%20Gordon%20F.%20Prasser%2C%20David%20Ratslam%3A%20a%20hippocampal%20model%20for%20simultaneous%20localization%20and%20mapping%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Milford%2C%20Michael%20J.%20Wyeth%2C%20Gordon%20F.%20Prasser%2C%20David%20Ratslam%3A%20a%20hippocampal%20model%20for%20simultaneous%20localization%20and%20mapping%202004"
        },
        {
            "id": "33",
            "entry": "[33] Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran, and Raia Hadsell. Learning to navigate in complex environments. arXiv preprint arXiv:1611.03673, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.03673"
        },
        {
            "id": "34",
            "entry": "[34] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning, pages 1928\u20131937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "35",
            "entry": "[35] Kaichun Mo, Haoxiang Li, Zhe Lin, and Joon-Young Lee. The adobeindoornav dataset: Towards deep reinforcement learning based real-world indoor robot visual navigation. arXiv preprint arXiv:1802.08824, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.08824"
        },
        {
            "id": "36",
            "entry": "[36] Emilio Parisotto and Ruslan Salakhutdinov. Neural map: Structured memory for deep reinforcement learning. arXiv preprint arXiv:1702.08360, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.08360"
        },
        {
            "id": "37",
            "entry": "[37] Nikolay Savinov, Alexey Dosovitskiy, and Vladlen Koltun. Semi-parametric topological memory for navigation. arXiv preprint arXiv:1803.00653, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.00653"
        },
        {
            "id": "38",
            "entry": "[38] Shital Shah, Debadeepta Dey, Chris Lovett, and Ashish Kapoor. Airsim: High-fidelity visual and physical simulation for autonomous vehicles. In Field and Service Robotics, pages 621\u2013635.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shah%2C%20Shital%20Dey%2C%20Debadeepta%20Lovett%2C%20Chris%20Kapoor%2C%20Ashish%20Airsim%3A%20High-fidelity%20visual%20and%20physical%20simulation%20for%20autonomous%20vehicles",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shah%2C%20Shital%20Dey%2C%20Debadeepta%20Lovett%2C%20Chris%20Kapoor%2C%20Ashish%20Airsim%3A%20High-fidelity%20visual%20and%20physical%20simulation%20for%20autonomous%20vehicles"
        },
        {
            "id": "39",
            "entry": "[39] Chen Tessler, Shahar Givony, Tom Zahavy, Daniel J. Mankowitz, and Shie Mannor. A deep hierarchical approach to lifelong learning in minecraft. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tessler%2C%20Chen%20Givony%2C%20Shahar%20Zahavy%2C%20Tom%20Mankowitz%2C%20Daniel%20J.%20A%20deep%20hierarchical%20approach%20to%20lifelong%20learning%20in%20minecraft%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tessler%2C%20Chen%20Givony%2C%20Shahar%20Zahavy%2C%20Tom%20Mankowitz%2C%20Daniel%20J.%20A%20deep%20hierarchical%20approach%20to%20lifelong%20learning%20in%20minecraft%202017"
        },
        {
            "id": "40",
            "entry": "[40] Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja, Agnieszka GrabskaBarwinska, Jack Rae, Piotr Mirowski, Joel Z Leibo, Adam Santoro, et al. Unsupervised predictive memory in a goal-directed agent. arXiv preprint arXiv:1803.10760, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.10760"
        },
        {
            "id": "41",
            "entry": "[41] Tobias Weyand, Ilya Kostrikov, and James Philbin. Planet-photo geolocation with convolutional neural networks. In European Conference on Computer Vision, pages 37\u201355.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Weyand%2C%20Tobias%20Kostrikov%2C%20Ilya%20Philbin%2C%20James%20Planet-photo%20geolocation%20with%20convolutional%20neural%20networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Weyand%2C%20Tobias%20Kostrikov%2C%20Ilya%20Philbin%2C%20James%20Planet-photo%20geolocation%20with%20convolutional%20neural%20networks"
        },
        {
            "id": "42",
            "entry": "[42] Yi Wu, Yuxin Wu, Georgia Gkioxari, and Yuandong Tian. Building generalizable agents with a realistic and rich 3d environment. arXiv preprint arXiv:1801.02209, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.02209"
        },
        {
            "id": "43",
            "entry": "[43] Wojciech Zaremba and Ilya Sutskever. Learning to execute. arXiv preprint arXiv:1410.4615, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1410.4615"
        },
        {
            "id": "44",
            "entry": "[44] Jingwei Zhang, Lei Tai, Joschka Boedecker, Wolfram Burgard, and Ming Liu. Neural slam: Learning to explore with external memory. arXiv preprint arXiv:1706.09520, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.09520"
        },
        {
            "id": "45",
            "entry": "[45] Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J. Lim, Abhinav Gupta, Li Fei-Fei, and Ali Farhadi. Target-driven visual navigation in indoor scenes using deep reinforcement learning. In 2017 IEEE International Conference on Robotics and Automation, ICRA, pages 3357\u20133364, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Yuke%20Mottaghi%2C%20Roozbeh%20Kolve%2C%20Eric%20Lim%2C%20Joseph%20J.%20Target-driven%20visual%20navigation%20in%20indoor%20scenes%20using%20deep%20reinforcement%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Yuke%20Mottaghi%2C%20Roozbeh%20Kolve%2C%20Eric%20Lim%2C%20Joseph%20J.%20Target-driven%20visual%20navigation%20in%20indoor%20scenes%20using%20deep%20reinforcement%20learning%202017"
        }
    ]
}
