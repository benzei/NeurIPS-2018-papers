{
    "filename": "7604-derivative-estimation-in-random-design.pdf",
    "metadata": {
        "title": "Derivative Estimation in Random Design",
        "author": "Yu Liu, Kris De Brabanter",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7604-derivative-estimation-in-random-design.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We propose a nonparametric derivative estimation method for random design without having to estimate the regression function. The method is based on a variance-reducing linear combination of symmetric difference quotients. First, we discuss the special case of uniform random design and establish the estimator\u2019s asymptotic properties. Secondly, we generalize these results for any distribution of the dependent variable and compare the proposed estimator with popular estimators for derivative estimation such as local polynomial regression and smoothing splines."
    },
    "keywords": [
        {
            "term": "linear combination",
            "url": "https://en.wikipedia.org/wiki/linear_combination"
        },
        {
            "term": "residual sum of squares",
            "url": "https://en.wikipedia.org/wiki/residual_sum_of_squares"
        },
        {
            "term": "smoothing spline",
            "url": "https://en.wikipedia.org/wiki/smoothing_spline"
        },
        {
            "term": "regression function",
            "url": "https://en.wikipedia.org/wiki/regression_function"
        },
        {
            "term": "nonparametric regression",
            "url": "https://en.wikipedia.org/wiki/nonparametric_regression"
        },
        {
            "term": "mean integrated squared error",
            "url": "https://en.wikipedia.org/wiki/mean_integrated_squared_error"
        },
        {
            "term": "local polynomial regression",
            "url": "https://en.wikipedia.org/wiki/local_polynomial_regression"
        },
        {
            "term": "confidence interval",
            "url": "https://en.wikipedia.org/wiki/confidence_interval"
        }
    ],
    "highlights": [
        "In the area of statistics, nonparametric regression is often of great interest due to its flexibility and different regression methods have been fully explored [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]",
        "We show that the new estimator has similar performance compared to local polynomial regression and penalized smoothing splines",
        "In order to discuss the asymptotic properties of this different quotient, we need to obtain an asymptotic expression for the difference Xi \u2212 Xi\u22121 which is not trivial in the random design setting",
        "In this paper we proposed a theoretical framework for first order derivative estimation based on a variance-reducing linear combination of symmetric quotients for random design",
        "This is a popular estimator for the equispaced design case, we showed that for the random design some difficulties occur and extra estimation of unknown quantities are needed",
        "It is possible to extend these type of estimators to higher order derivatives and similar theoretical results can be established"
    ],
    "key_statements": [
        "In the area of statistics, nonparametric regression is often of great interest due to its flexibility and different regression methods have been fully explored [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]",
        "Other applications include exploring the structure of curves [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], analyzing significant trends [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], comparing regression curves [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], characterization of nanoparticles [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>], neural network pruning [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], estimating the leading bias term in the construction of confidence intervals [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>] and bandwidth selection methods [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "We show that the extension from equispaced to random design for higher order derivatives is not trivial",
        "We show that the new estimator has similar performance compared to local polynomial regression and penalized smoothing splines",
        "In order to discuss the asymptotic properties of this different quotient, we need to obtain an asymptotic expression for the difference Xi \u2212 Xi\u22121 which is not trivial in the random design setting",
        "In this paper we proposed a theoretical framework for first order derivative estimation based on a variance-reducing linear combination of symmetric quotients for random design",
        "This is a popular estimator for the equispaced design case, we showed that for the random design some difficulties occur and extra estimation of unknown quantities are needed",
        "It is possible to extend these type of estimators to higher order derivatives and similar theoretical results can be established"
    ],
    "summary": [
        "In the area of statistics, nonparametric regression is often of great interest due to its flexibility and different regression methods have been fully explored [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>].",
        "The derivative estimators discussed in [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>, <a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>, <a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>] use the symmetric property xi+j \u2212 xi = xi \u2212 xi\u2212j since they assume equispaced design.",
        "Which is a noise corrupted version of the first order derivative in Xi. this estimator is quasi unbiased, two problems immediately emerge: (i) no simple expression for the difference Xi \u2212 Xi\u22121 is available to study its asymptotic properties; the variance is proportional to n2.",
        "In order to discuss the asymptotic properties of this different quotient, we need to obtain an asymptotic expression for the difference Xi \u2212 Xi\u22121 which is not trivial in the random design setting.",
        "It is immediately clear that the first order difference quotient proposed by [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>] is an asymptotic unbiased estimator of r(U(i)).",
        "The following theorems establish the asymptotic bias and variance of our proposed estimator (5) for interior points i.e., k + 1 \u2264 i \u2264 n \u2212 k.",
        "Using Lemma 1, assume k \u2192 \u221e as n \u2192 \u221e, and for the weights in Proposition 1 we obtain the asymptotic order of the exact conditional bias for different values of q bias Yi(1)|U =",
        "Due to page limitations we will not elaborate further on higher order derivative estimation, but more information and theoretical results can be obtained by contacting the first author.",
        "From Section 2.4, assume r(\u00b7) is three times continuously differentiable on [0, 1], at the boundary, the asymptotic order of the bias is Op max",
        "In order to evaluate the derivative in an arbitrary point we propose smoothing the newly generated data set.",
        "Under mild assumptions on the correlation function, which is unknown, [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] showed that, by using a bimodal type of kernel K such that K(0) = 0, the residual sum of squares (RSS) approximates the asymptotic squared error uniformly over a set of bandwidths.",
        "It is possible to find a closed form expression for the distribution of the differences X(i+j) \u2212 X(i\u2212j) with X i.\u223ci.d F where F is unknown and continuous [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>] such that the density function f (x) = F (x).",
        "We compare the proposed methodology to several popular methods for nonparametric derivative estimation, i.e. the local slope of the local polynomial regression estimator with p = 2 and penalized cubic smoothing splines [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>].",
        "In this paper we proposed a theoretical framework for first order derivative estimation based on a variance-reducing linear combination of symmetric quotients for random design.",
        "It is possible to extend these type of estimators to higher order derivatives and similar theoretical results can be established"
    ],
    "headline": "We propose a nonparametric derivative estimation method for random design without having to estimate the regression function",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] J. Fan and I. Gijbels. Local polynomial modelling and its applications: monographs on statistics and applied probability. Chapman & Hall/CRC Press, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fan%2C%20J.%20Gijbels%2C%20I.%20Local%20polynomial%20modelling%20and%20its%20applications%3A%20monographs%20on%20statistics%20and%20applied%20probability%201996"
        },
        {
            "id": "2",
            "entry": "[2] L. Gy\u00f6rfi, M. Kohler, A. Krzyzak, and H. Walk. A distribution-free theory of nonparametric regression. Springer Science & Business Media, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gy%C3%B6rfi%2C%20L.%20Kohler%2C%20M.%20Krzyzak%2C%20A.%20Walk%2C%20H.%20A%20distribution-free%20theory%20of%20nonparametric%20regression%202006"
        },
        {
            "id": "3",
            "entry": "[3] A. Tsybakov. Introduction to Nonparametric Estimation. Springer Publishing Company, Incorporated, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsybakov%2C%20A.%20Introduction%20to%20Nonparametric%20Estimation%202008"
        },
        {
            "id": "4",
            "entry": "[4] G. Wahba and Y. Wang. When is the optimal regularization parameter insensitive to the choice of the loss function? Communications in Statistics-Theory and Methods, 19(5):1685\u20131700, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wahba%2C%20G.%20Wang%2C%20Y.%20When%20is%20the%20optimal%20regularization%20parameter%20insensitive%20to%20the%20choice%20of%20the%20loss%20function%3F%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wahba%2C%20G.%20Wang%2C%20Y.%20When%20is%20the%20optimal%20regularization%20parameter%20insensitive%20to%20the%20choice%20of%20the%20loss%20function%3F%201990"
        },
        {
            "id": "5",
            "entry": "[5] H-G. M\u00fcller. Nonparametric regression analysis of longitudinal data, volume 46. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%C3%BCller%2C%20H.-G.%20Nonparametric%20regression%20analysis%20of%20longitudinal%20data%2C%20volume%2046%202012"
        },
        {
            "id": "6",
            "entry": "[6] J. Ramsay and B. Silverman. Applied functional data analysis: methods and case studies. Springer, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramsay%2C%20J.%20Silverman%2C%20B.%20Applied%20functional%20data%20analysis%3A%20methods%20and%20case%20studies%202007"
        },
        {
            "id": "7",
            "entry": "[7] I. Gijbels and A-C. Goderniaux. Data-driven discontinuity detection in derivatives of a regression function. Communications in Statistics-Theory and Methods, 33(4):851\u2013871, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gijbels%2C%20I.%20Goderniaux%2C%20A.-C.%20Data-driven%20discontinuity%20detection%20in%20derivatives%20of%20a%20regression%20function%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gijbels%2C%20I.%20Goderniaux%2C%20A.-C.%20Data-driven%20discontinuity%20detection%20in%20derivatives%20of%20a%20regression%20function%202005"
        },
        {
            "id": "8",
            "entry": "[8] P. Chaudhuri and J. Marron. Sizer for exploration of structures in curves. Journal of the American Statistical Association, 94(447):807\u2013823, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaudhuri%2C%20P.%20Marron%2C%20J.%20Sizer%20for%20exploration%20of%20structures%20in%20curves%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaudhuri%2C%20P.%20Marron%2C%20J.%20Sizer%20for%20exploration%20of%20structures%20in%20curves%201999"
        },
        {
            "id": "9",
            "entry": "[9] V. Rondonotti, J. Marron, and C. Park. Sizer for time series: a new approach to the analysis of trends. Electronic Journal of Statistics, 1:268\u2013289, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rondonotti%2C%20V.%20Marron%2C%20J.%20Park%2C%20C.%20Sizer%20for%20time%20series%3A%20a%20new%20approach%20to%20the%20analysis%20of%20trends%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rondonotti%2C%20V.%20Marron%2C%20J.%20Park%2C%20C.%20Sizer%20for%20time%20series%3A%20a%20new%20approach%20to%20the%20analysis%20of%20trends%202007"
        },
        {
            "id": "10",
            "entry": "[10] C. Park and K-H. Kang. Sizer analysis for the comparison of regression curves. Computational Statistics & Data Analysis, 52(8):3954\u20133970, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20C.%20Kang%2C%20K.-H.%20Sizer%20analysis%20for%20the%20comparison%20of%20regression%20curves%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20C.%20Kang%2C%20K.-H.%20Sizer%20analysis%20for%20the%20comparison%20of%20regression%20curves%202008"
        },
        {
            "id": "11",
            "entry": "[11] R. Charnigo, M. Francoeur, M. Pinar Meng\u00fc\u00e7, A. Brock, M. Leichter, and C. Srinivasan. Derivatives of scattering profiles: tools for nanoparticle characterization. Journal of the Optical Society of America A, 24(9):2578\u20132589, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charnigo%2C%20R.%20Francoeur%2C%20M.%20Meng%C3%BC%C3%A7%2C%20M.Pinar%20Brock%2C%20A.%20Derivatives%20of%20scattering%20profiles%3A%20tools%20for%20nanoparticle%20characterization%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charnigo%2C%20R.%20Francoeur%2C%20M.%20Meng%C3%BC%C3%A7%2C%20M.Pinar%20Brock%2C%20A.%20Derivatives%20of%20scattering%20profiles%3A%20tools%20for%20nanoparticle%20characterization%202007"
        },
        {
            "id": "12",
            "entry": "[12] B. Hassibi and D. Stork. Second order derivatives for network pruning: Optimal brain surgeon. In Advances in neural information processing systems, pages 164\u2013171, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hassibi%2C%20B.%20Stork%2C%20D.%20Second%20order%20derivatives%20for%20network%20pruning%3A%20Optimal%20brain%20surgeon%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hassibi%2C%20B.%20Stork%2C%20D.%20Second%20order%20derivatives%20for%20network%20pruning%3A%20Optimal%20brain%20surgeon%201993"
        },
        {
            "id": "13",
            "entry": "[13] R. Eubank and P. Speckman. Confidence bands in nonparametric regression. Journal of the American Statistical Association, 88(424):1287\u20131301, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eubank%2C%20R.%20Speckman%2C%20P.%20Confidence%20bands%20in%20nonparametric%20regression%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eubank%2C%20R.%20Speckman%2C%20P.%20Confidence%20bands%20in%20nonparametric%20regression%201993"
        },
        {
            "id": "14",
            "entry": "[14] Y. Xia. Bias-corrected confidence bands in nonparametric regression. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 60(4):797\u2013811, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xia%2C%20Y.%20Bias-corrected%20confidence%20bands%20in%20nonparametric%20regression%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xia%2C%20Y.%20Bias-corrected%20confidence%20bands%20in%20nonparametric%20regression%201998"
        },
        {
            "id": "15",
            "entry": "[15] D. Ruppert and M. Wand. Multivariate locally weighted least squares regression. The Annals of Statistics, pages 1346\u20131370, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ruppert%2C%20D.%20Wand%2C%20M.%20Multivariate%20locally%20weighted%20least%20squares%20regression%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ruppert%2C%20D.%20Wand%2C%20M.%20Multivariate%20locally%20weighted%20least%20squares%20regression%201994"
        },
        {
            "id": "16",
            "entry": "[16] H-G. M\u00fcller, U. Stadtm\u00fcller, and T. Schmitt. Bandwidth choice and confidence intervals for derivatives of noisy data. Biometrika, 74(4):743\u2013749, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%C3%BCller%2C%20H.-G.%20Stadtm%C3%BCller%2C%20U.%20Schmitt%2C%20T.%20Bandwidth%20choice%20and%20confidence%20intervals%20for%20derivatives%20of%20noisy%20data%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%C3%BCller%2C%20H.-G.%20Stadtm%C3%BCller%2C%20U.%20Schmitt%2C%20T.%20Bandwidth%20choice%20and%20confidence%20intervals%20for%20derivatives%20of%20noisy%20data%201987"
        },
        {
            "id": "17",
            "entry": "[17] N. Heckman and J. Ramsay. Penalized regression with model-based penalties. Canadian Journal of Statistics, 28(2):241\u2013258, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heckman%2C%20N.%20Ramsay%2C%20J.%20Penalized%20regression%20with%20model-based%20penalties%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heckman%2C%20N.%20Ramsay%2C%20J.%20Penalized%20regression%20with%20model-based%20penalties%202000"
        },
        {
            "id": "18",
            "entry": "[18] C. Stone. Additive regression and other nonparametric models. The annals of Statistics, pages 689\u2013705, 1985.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stone%2C%20C.%20Additive%20regression%20and%20other%20nonparametric%20models.%20The%20annals%20of%201985",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stone%2C%20C.%20Additive%20regression%20and%20other%20nonparametric%20models.%20The%20annals%20of%201985"
        },
        {
            "id": "19",
            "entry": "[19] S. Zhou and D. Wolfe. On derivative estimation in spline regression. Statistica Sinica, pages 93\u2013108, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20S.%20Wolfe%2C%20D.%20On%20derivative%20estimation%20in%20spline%20regression%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20S.%20Wolfe%2C%20D.%20On%20derivative%20estimation%20in%20spline%20regression%202000"
        },
        {
            "id": "20",
            "entry": "[20] W. H\u00e4rdle. Applied nonparametric regression. Cambridge university press, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%A4rdle%2C%20W.%20Applied%20nonparametric%20regression%201990"
        },
        {
            "id": "21",
            "entry": "[21] R. Charnigo, B. Hall, and C. Srinivasan. A generalized c p criterion for derivative estimation. Technometrics, 53(3):238\u2013253, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charnigo%2C%20R.%20Hall%2C%20B.%20Srinivasan%2C%20C.%20A%20generalized%20c%20p%20criterion%20for%20derivative%20estimation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charnigo%2C%20R.%20Hall%2C%20B.%20Srinivasan%2C%20C.%20A%20generalized%20c%20p%20criterion%20for%20derivative%20estimation%202011"
        },
        {
            "id": "22",
            "entry": "[22] K. De Brabanter, J. De Brabanter, B. De Moor, and I. Gijbels. Derivative estimation with local polynomial fitting. Journal of Machine Learning Research, 14(1):281\u2013301, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brabanter%2C%20K.De%20Brabanter%2C%20J.De%20Moor%2C%20B.De%20Gijbels%2C%20I.%20Derivative%20estimation%20with%20local%20polynomial%20fitting%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brabanter%2C%20K.De%20Brabanter%2C%20J.De%20Moor%2C%20B.De%20Gijbels%2C%20I.%20Derivative%20estimation%20with%20local%20polynomial%20fitting%202013"
        },
        {
            "id": "23",
            "entry": "[23] W. Wang and L. Lin. Derivative estimation based on difference sequence via locally weighted least squares regression. Journal of Machine Learning Research, 16:2617\u20132641, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20W.%20Lin%2C%20L.%20Derivative%20estimation%20based%20on%20difference%20sequence%20via%20locally%20weighted%20least%20squares%20regression%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20W.%20Lin%2C%20L.%20Derivative%20estimation%20based%20on%20difference%20sequence%20via%20locally%20weighted%20least%20squares%20regression%202015"
        },
        {
            "id": "24",
            "entry": "[24] W. Dai, T. Tong, and M.G. Genton. Optimal estimation of derivatives in nonparametric regression. Journal of Machine Learning Research, 117:1\u201325, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20W.%20Tong%2C%20T.%20Genton%2C%20M.G.%20Optimal%20estimation%20of%20derivatives%20in%20nonparametric%20regression%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20W.%20Tong%2C%20T.%20Genton%2C%20M.G.%20Optimal%20estimation%20of%20derivatives%20in%20nonparametric%20regression%202016"
        },
        {
            "id": "25",
            "entry": "[25] H.A. David and H.N. Nagaraja. Order Statistics, Third Edn. John Wiley & Sons, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=David%2C%20H.A.%20Nagaraja%2C%20H.N.%20Order%20Statistics%2C%20Third%20Edn%202003"
        },
        {
            "id": "26",
            "entry": "[26] P. Hall, J. Kay, and D. Titterington. Asymptotically optimal difference-based estimation of variance in nonparametric regression. Biometrika, 77(3):521\u2013528, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hall%2C%20P.%20Kay%2C%20J.%20Titterington%2C%20D.%20Asymptotically%20optimal%20difference-based%20estimation%20of%20variance%20in%20nonparametric%20regression%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hall%2C%20P.%20Kay%2C%20J.%20Titterington%2C%20D.%20Asymptotically%20optimal%20difference-based%20estimation%20of%20variance%20in%20nonparametric%20regression%201990"
        },
        {
            "id": "27",
            "entry": "[27] K. De Brabanter, F. Cao, I. Gijbels, and J. Opsomer. Local polynomial regression with correlated errors in random design and unknown correlation structure, in press. Biometrika, 2018. Mathematical Statistics, pages 832\u2013837, 1956.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brabanter%2C%20K.De%20Cao%2C%20F.%20Gijbels%2C%20I.%20Opsomer%2C%20J.%20Local%20polynomial%20regression%20with%20correlated%20errors%20in%20random%20design%20and%20unknown%20correlation%20structure%2C%20in%20press%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brabanter%2C%20K.De%20Cao%2C%20F.%20Gijbels%2C%20I.%20Opsomer%2C%20J.%20Local%20polynomial%20regression%20with%20correlated%20errors%20in%20random%20design%20and%20unknown%20correlation%20structure%2C%20in%20press%202018"
        },
        {
            "id": "29",
            "entry": "[29] E. Parzen. On estimation of a probability density function and mode. The annals of mathematical statistics, 33(3):1065\u20131076, 1962.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parzen%2C%20E.%20On%20estimation%20of%20a%20probability%20density%20function%20and%20mode%201962",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parzen%2C%20E.%20On%20estimation%20of%20a%20probability%20density%20function%20and%20mode%201962"
        },
        {
            "id": "30",
            "entry": "[30] T. Duong. ks: Kernel smoothing v1.11.1, https://cran.r-project.org/web/packages/ks/index.html, 2018.",
            "url": "https://cran.r-project.org/web/packages/ks/index.html"
        },
        {
            "id": "31",
            "entry": "[31] J.L. Ojeda Cabrera. locpol: Kernel local polynomial regression v0.6, https://cran.r-project.org/web/packages/locpol/index.html, 2012.",
            "url": "https://cran.r-project.org/web/packages/locpol/index.html"
        },
        {
            "id": "32",
            "entry": "[32] B. Ripley. pspline: Penalized smoothing splines v1.0-18, https://cran.r-project.org/web/packages/pspline/index.html, 2017. ",
            "url": "https://cran.r-project.org/web/packages/pspline/index.html"
        }
    ]
}
