{
    "filename": "7666-tetris-tile-matching-the-tremendous-irregular-sparsity.pdf",
    "metadata": {
        "title": "TETRIS: TilE-matching the TRemendous Irregular Sparsity",
        "author": "Yu Ji, Ling Liang, Lei Deng, Youyang Zhang, Youhui Zhang, Yuan Xie",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7666-tetris-tile-matching-the-tremendous-irregular-sparsity.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Compressing neural networks by pruning weights with small magnitudes can significantly reduce the computation and storage cost. Although pruning makes the model smaller, it is difficult to get a practical speedup in modern computing platforms such as CPU and GPU due to the irregularity. Structural pruning has attracted a lot of research interest to make sparsity hardware-friendly. Increasing the sparsity granularity can lead to better hardware utilization, but it will compromise the sparsity for maintaining accuracy. In this work, we propose a novel method, TETRIS, to achieve both better hardware utilization and higher sparsity. Just like a tile-matching game2, we cluster the irregularly distributed weights with small value into structured groups by reordering the input/output dimension and structurally prune them. Results show that it can achieve comparable sparsity with the irregular element-wise pruning and demonstrate negligible accuracy loss. The experiments also show ideal speedup, which is proportional to the sparsity, on GPU platforms. Our proposed method provides a new solution toward algorithm and architecture co-optimization for accuracy-efficiency trade-off."
    },
    "keywords": [
        {
            "term": "expectation maximization",
            "url": "https://en.wikipedia.org/wiki/expectation_maximization"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "National Science Foundations",
            "url": "https://en.wikipedia.org/wiki/National_Science_Foundation"
        }
    ],
    "highlights": [
        "Deep neural networks (DNNs) have achieved great success in a wide spectrum of applications, such as computer vision [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], speech recognition [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and language translation [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "We use VGG16 as an example to test the relationship between accuracy and sparsity under different block size",
        "Instead of struggling to achieve a good trade-off among the sparsity, hardware utilization, and the accuracy, and selecting a proper grouping granularity, we propose an orthogonal approach that clusters unimportant elements together to form regular structures",
        "As shown in Figure 2, we can leverage the flexibility of permutation and properly reorder the indices for each dimension to cluster elements according to the value magnitude, which enables a better sparsity for structured pruning algorithms.\n4.1",
        "Compared to the baseline without reordering that the accuracy significantly dropped, our approach can make the curve of block-wise pruning close to the element-wise case (1 \u00d7 1 case).\n5.3",
        "We present a method to reorder irregular fine-grained sparsity to structured coarse-grained sparsity to bridge the gap between the large sparsity we can gain from models and the poor practical speedup"
    ],
    "key_statements": [
        "Deep neural networks (DNNs) have achieved great success in a wide spectrum of applications, such as computer vision [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], speech recognition [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and language translation [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "We use VGG16 as an example to test the relationship between accuracy and sparsity under different block size",
        "Instead of struggling to achieve a good trade-off among the sparsity, hardware utilization, and the accuracy, and selecting a proper grouping granularity, we propose an orthogonal approach that clusters unimportant elements together to form regular structures",
        "As shown in Figure 2, we can leverage the flexibility of permutation and properly reorder the indices for each dimension to cluster elements according to the value magnitude, which enables a better sparsity for structured pruning algorithms.\n4.1",
        "Compared to the baseline without reordering that the accuracy significantly dropped, our approach can make the curve of block-wise pruning close to the element-wise case (1 \u00d7 1 case).\n5.3",
        "Figure 7 shows the speedup of different convolutional layers in VGG16 under different block sizes; and the pruning rate configuration is set to the same as that of Deep Compression",
        "We present a method to reorder irregular fine-grained sparsity to structured coarse-grained sparsity to bridge the gap between the large sparsity we can gain from models and the poor practical speedup"
    ],
    "summary": [
        "Deep neural networks (DNNs) have achieved great success in a wide spectrum of applications, such as computer vision [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], speech recognition [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and language translation [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>].",
        "The key idea is to cluster elements with small magnitude closer by reordering the input and output dimensions before pruning at a coarse granularity.",
        "Our method achieves comparable sparsity with irregular fine-grained pruning and maintains the model accuracy to a great extent.",
        "By reordering the input and output dimensions, we can always increase the sparsity of pruned networks generated by those pruning methods.",
        "The sparsity generated by these coarse-grained pruning methods is usually compromised because of the accuracy maintaining.",
        "We use VGG16 as an example to test the relationship between accuracy and sparsity under different block size.",
        "Instead of struggling to achieve a good trade-off among the sparsity, hardware utilization, and the accuracy, and selecting a proper grouping granularity, we propose an orthogonal approach that clusters unimportant elements together to form regular structures.",
        "As shown in Figure 2, we can leverage the flexibility of permutation and properly reorder the indices for each dimension to cluster elements according to the value magnitude, which enables a better sparsity for structured pruning algorithms.",
        "Input: Pruning Method P , d-order weight tensor W , reordering dimension set \u03a9 Output: Permutations \u03b1i",
        "The introduced overhead in the inference phase is that we have to reorder the input and output of all layers according to the generated permutations.",
        "We use one typical structural pruning algorithm, block sparsity, as a case study to show how our algorithm can improve its sparsity and granularity.",
        "We reorder the mask according to the reverse permutations to generate a permuted mask and use it to filter the elements of the original weights so that we do not need to reorder the inputs and outputs for retraining.",
        "Compared to the baseline without reordering that the accuracy significantly dropped, our approach can make the curve of block-wise pruning close to the element-wise case (1 \u00d7 1 case).",
        "We have to decrease the block size that leads to smaller sparsity and less speedup.",
        "As shown in Figure 6, we plot the relationship between accuracy and speedup under different block sizes for VGG16.",
        "Figure 7 shows the speedup of different convolutional layers in VGG16 under different block sizes; and the pruning rate configuration is set to the same as that of Deep Compression.",
        "We present a method to reorder irregular fine-grained sparsity to structured coarse-grained sparsity to bridge the gap between the large sparsity we can gain from models and the poor practical speedup.",
        "It can help the fine-grained pruning methods to achieve the ideal execution acceleration"
    ],
    "headline": "We propose a novel method, TETRIS, to achieve both better hardware utilization and higher sparsity",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] K. Simonyan and A. Zisserman, \u201cVery deep convolutional networks for large-scale image recognition,\u201d arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "2",
            "entry": "[2] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%2C%202016"
        },
        {
            "id": "3",
            "entry": "[3] J. Redmon and A. Farhadi, \u201cYolo9000: better, faster, stronger,\u201d arXiv preprint, vol. 1612, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Redmon%2C%20J.%20Farhadi%2C%20A.%20Yolo9000%3A%20better%2C%20faster%2C%20stronger%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Redmon%2C%20J.%20Farhadi%2C%20A.%20Yolo9000%3A%20better%2C%20faster%2C%20stronger%2C%202016"
        },
        {
            "id": "4",
            "entry": "[4] O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, L. Deng, G. Penn, and D. Yu, \u201cConvolutional neural networks for speech recognition,\u201d IEEE/ACM Transactions on audio, speech, and language processing, vol. 22, no. 10, pp. 1533\u20131545, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abdel-Hamid%2C%20O.%20Mohamed%2C%20A.-r%20Jiang%2C%20H.%20Deng%2C%20L.%20Convolutional%20neural%20networks%20for%20speech%20recognition%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abdel-Hamid%2C%20O.%20Mohamed%2C%20A.-r%20Jiang%2C%20H.%20Deng%2C%20L.%20Convolutional%20neural%20networks%20for%20speech%20recognition%2C%202014"
        },
        {
            "id": "5",
            "entry": "[5] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen, et al., \u201cDeep speech 2: End-to-end speech recognition in english and mandarin,\u201d in International Conference on Machine Learning, pp. 173\u2013182, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amodei%2C%20D.%20Ananthanarayanan%2C%20S.%20Anubhai%2C%20R.%20Bai%2C%20J.%20Deep%20speech%202%3A%20End-to-end%20speech%20recognition%20in%20english%20and%20mandarin%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Amodei%2C%20D.%20Ananthanarayanan%2C%20S.%20Anubhai%2C%20R.%20Bai%2C%20J.%20Deep%20speech%202%3A%20End-to-end%20speech%20recognition%20in%20english%20and%20mandarin%2C%202016"
        },
        {
            "id": "6",
            "entry": "[6] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey, M. Krikun, Y. Cao, Q. Gao, K. Macherey, et al., \u201cGoogle\u2019s neural machine translation system: Bridging the gap between human and machine translation,\u201d arXiv preprint arXiv:1609.08144, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.08144"
        },
        {
            "id": "7",
            "entry": "[7] A. Ardakani, C. Condo, and W. J. Gross, \u201cSparsely-connected neural networks: towards efficient vlsi implementation of deep neural networks,\u201d arXiv preprint arXiv:1611.01427, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01427"
        },
        {
            "id": "8",
            "entry": "[8] S. Han, J. Pool, J. Tran, and W. Dally, \u201cLearning both weights and connections for efficient neural network,\u201d in Advances in neural information processing systems, pp. 1135\u20131143, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Pool%2C%20J.%20Tran%2C%20J.%20Dally%2C%20W.%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20network%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20S.%20Pool%2C%20J.%20Tran%2C%20J.%20Dally%2C%20W.%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20network%2C%202015"
        },
        {
            "id": "9",
            "entry": "[9] S. Han, H. Mao, and W. J. Dally, \u201cDeep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding,\u201d arXiv preprint arXiv:1510.00149, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1510.00149"
        },
        {
            "id": "10",
            "entry": "[10] Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang, \u201cLearning efficient convolutional networks through network slimming,\u201d in 2017 IEEE International Conference on Computer Vision (ICCV), pp. 2755\u20132763, IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Li%2C%20J.%20Shen%2C%20Z.%20Huang%2C%20G.%20Learning%20efficient%20convolutional%20networks%20through%20network%20slimming%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Z.%20Li%2C%20J.%20Shen%2C%20Z.%20Huang%2C%20G.%20Learning%20efficient%20convolutional%20networks%20through%20network%20slimming%2C%202017"
        },
        {
            "id": "11",
            "entry": "[11] H. Li, A. Kadav, I. Durdanovic, H. Samet, and H. P. Graf, \u201cPruning filters for efficient convnets,\u201d arXiv preprint arXiv:1608.08710, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.08710"
        },
        {
            "id": "12",
            "entry": "[12] B. Liu, M. Wang, H. Foroosh, M. Tappen, and M. Pensky, \u201cSparse convolutional neural networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 806\u2013814, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20B.%20Wang%2C%20M.%20Foroosh%2C%20H.%20Tappen%2C%20M.%20Sparse%20convolutional%20neural%20networks%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20B.%20Wang%2C%20M.%20Foroosh%2C%20H.%20Tappen%2C%20M.%20Sparse%20convolutional%20neural%20networks%2C%202015"
        },
        {
            "id": "13",
            "entry": "[13] S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, and W. J. Dally, \u201cEie: efficient inference engine on compressed deep neural network,\u201d in Computer Architecture (ISCA), 2016 ACM/IEEE 43rd Annual International Symposium on, pp. 243\u2013254, IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Liu%2C%20X.%20Mao%2C%20H.%20Pu%2C%20J.%20Eie%3A%20efficient%20inference%20engine%20on%20compressed%20deep%20neural%20network%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20S.%20Liu%2C%20X.%20Mao%2C%20H.%20Pu%2C%20J.%20Eie%3A%20efficient%20inference%20engine%20on%20compressed%20deep%20neural%20network%2C%202016"
        },
        {
            "id": "14",
            "entry": "[14] S. Han, J. Kang, H. Mao, Y. Hu, X. Li, Y. Li, D. Xie, H. Luo, S. Yao, Y. Wang, et al., \u201cEse: Efficient speech recognition engine with sparse lstm on fpga,\u201d in Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 75\u201384, ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Kang%2C%20J.%20Mao%2C%20H.%20Hu%2C%20Y.%20Ese%3A%20Efficient%20speech%20recognition%20engine%20with%20sparse%20lstm%20on%20fpga%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20S.%20Kang%2C%20J.%20Mao%2C%20H.%20Hu%2C%20Y.%20Ese%3A%20Efficient%20speech%20recognition%20engine%20with%20sparse%20lstm%20on%20fpga%2C%202017"
        },
        {
            "id": "15",
            "entry": "[15] Y. Lu, L. Gong, C. Xu, F. Sun, Y. Zhang, C. Wang, and X. Zhou, \u201cA high-performance fpga accelerator for sparse neural networks: work-in-progress,\u201d in Proceedings of the 2017 International Conference on Compilers, Architectures and Synthesis for Embedded Systems Companion, p. 12, ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lu%2C%20Y.%20Gong%2C%20L.%20Xu%2C%20C.%20Sun%2C%20F.%20A%20high-performance%20fpga%20accelerator%20for%20sparse%20neural%20networks%3A%20work-in-progress%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lu%2C%20Y.%20Gong%2C%20L.%20Xu%2C%20C.%20Sun%2C%20F.%20A%20high-performance%20fpga%20accelerator%20for%20sparse%20neural%20networks%3A%20work-in-progress%2C%202017"
        },
        {
            "id": "16",
            "entry": "[16] A. Page, A. Jafari, C. Shea, and T. Mohsenin, \u201cSparcnet: A hardware accelerator for efficient deployment of sparse convolutional networks,\u201d ACM Journal on Emerging Technologies in Computing Systems (JETC), vol. 13, no. 3, p. 31, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Page%2C%20A.%20Jafari%2C%20A.%20Shea%2C%20C.%20Mohsenin%2C%20T.%20Sparcnet%3A%20A%20hardware%20accelerator%20for%20efficient%20deployment%20of%20sparse%20convolutional%20networks%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Page%2C%20A.%20Jafari%2C%20A.%20Shea%2C%20C.%20Mohsenin%2C%20T.%20Sparcnet%3A%20A%20hardware%20accelerator%20for%20efficient%20deployment%20of%20sparse%20convolutional%20networks%2C%202017"
        },
        {
            "id": "17",
            "entry": "[17] A. Parashar, M. Rhu, A. Mukkara, A. Puglielli, R. Venkatesan, B. Khailany, J. Emer, S. W. Keckler, and W. J. Dally, \u201cScnn: An accelerator for compressed-sparse convolutional neural networks,\u201d in Proceedings of the 44th Annual International Symposium on Computer Architecture, pp. 27\u201340, ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parashar%2C%20A.%20Rhu%2C%20M.%20Mukkara%2C%20A.%20Puglielli%2C%20A.%20Scnn%3A%20An%20accelerator%20for%20compressed-sparse%20convolutional%20neural%20networks%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parashar%2C%20A.%20Rhu%2C%20M.%20Mukkara%2C%20A.%20Puglielli%2C%20A.%20Scnn%3A%20An%20accelerator%20for%20compressed-sparse%20convolutional%20neural%20networks%2C%202017"
        },
        {
            "id": "18",
            "entry": "[18] C.-Y. Lin and B.-C. Lai, \u201cSupporting compressed-sparse activations and weights on simdlike accelerator for sparse convolutional neural networks,\u201d in Design Automation Conference (ASP-DAC), 2018 23rd Asia and South Pacific, pp. 105\u2013110, IEEE, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20C.-Y.%20Lai%2C%20B.-C.%20Supporting%20compressed-sparse%20activations%20and%20weights%20on%20simdlike%20accelerator%20for%20sparse%20convolutional%20neural%20networks%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20C.-Y.%20Lai%2C%20B.-C.%20Supporting%20compressed-sparse%20activations%20and%20weights%20on%20simdlike%20accelerator%20for%20sparse%20convolutional%20neural%20networks%2C%202018"
        },
        {
            "id": "19",
            "entry": "[19] W. Wen, C. Wu, Y. Wang, Y. Chen, and H. Li, \u201cLearning structured sparsity in deep neural networks,\u201d in Advances in Neural Information Processing Systems, pp. 2074\u20132082, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wen%2C%20W.%20Wu%2C%20C.%20Wang%2C%20Y.%20Chen%2C%20Y.%20Learning%20structured%20sparsity%20in%20deep%20neural%20networks%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wen%2C%20W.%20Wu%2C%20C.%20Wang%2C%20Y.%20Chen%2C%20Y.%20Learning%20structured%20sparsity%20in%20deep%20neural%20networks%2C%202016"
        },
        {
            "id": "20",
            "entry": "[20] J. Yu, A. Lukefahr, D. Palframan, G. Dasika, R. Das, and S. Mahlke, \u201cScalpel: Customizing dnn pruning to the underlying hardware parallelism,\u201d in Proceedings of the 44th Annual International Symposium on Computer Architecture, pp. 548\u2013560, ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20J.%20Lukefahr%2C%20A.%20Palframan%2C%20D.%20Dasika%2C%20G.%20Scalpel%3A%20Customizing%20dnn%20pruning%20to%20the%20underlying%20hardware%20parallelism%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20J.%20Lukefahr%2C%20A.%20Palframan%2C%20D.%20Dasika%2C%20G.%20Scalpel%3A%20Customizing%20dnn%20pruning%20to%20the%20underlying%20hardware%20parallelism%2C%202017"
        },
        {
            "id": "21",
            "entry": "[21] J.-H. Luo, J. Wu, and W. Lin, \u201cThinet: A filter level pruning method for deep neural network compression,\u201d arXiv preprint arXiv:1707.06342, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06342"
        },
        {
            "id": "22",
            "entry": "[22] W. Wen, C. Xu, C. Wu, Y. Wang, Y. Chen, and H. Li, \u201cCoordinating filters for faster deep neural networks,\u201d CoRR, abs/1703.09746, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.09746"
        },
        {
            "id": "23",
            "entry": "[23] X. Sun, X. Ren, S. Ma, and H. Wang, \u201cmeprop: Sparsified back propagation for accelerated deep learning with reduced overfitting,\u201d arXiv preprint arXiv:1706.06197, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.06197"
        },
        {
            "id": "24",
            "entry": "[24] S. Narang, E. Undersander, and G. Diamos, \u201cBlock-sparse recurrent neural networks,\u201d arXiv preprint arXiv:1711.02782, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.02782"
        },
        {
            "id": "25",
            "entry": "[25] G. Scott, R. Alec, and P. K. Diederik, \u201cGpu kernel for block-sparse weights,\u201d 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scott%2C%20G.%20Alec%2C%20R.%20Diederik%2C%20P.K.%20Gpu%20kernel%20for%20block-sparse%20weights%2C%202016"
        },
        {
            "id": "26",
            "entry": "[26] W. Wen, Y. He, S. Rajbhandari, W. Wang, F. Liu, B. Hu, Y. Chen, and H. Li, \u201cLearning intrinsic sparse structures within long short-term memory,\u201d arXiv preprint arXiv:1709.05027, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.05027"
        },
        {
            "id": "27",
            "entry": "[27] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, \u201cImageNet: A Large-Scale Hierarchical Image Database,\u201d in CVPR09, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20ImageNet%3A%20A%20Large-Scale%20Hierarchical%20Image%20Database%2C%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20ImageNet%3A%20A%20Large-Scale%20Hierarchical%20Image%20Database%2C%202009"
        },
        {
            "id": "28",
            "entry": "[28] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer, \u201cAutomatic differentiation in pytorch,\u201d 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20A.%20Gross%2C%20S.%20Chintala%2C%20S.%20Chanan%2C%20G.%20Automatic%20differentiation%20in%20pytorch%2C%202017"
        },
        {
            "id": "29",
            "entry": "[29] S. Marcel and Y. Rodriguez, \u201cTorchvision the machine-vision package of torch,\u201d in Proceedings of the 18th ACM international conference on Multimedia, pp. 1485\u20131488, ACM, 2010. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcel%2C%20S.%20Rodriguez%2C%20Y.%20%E2%80%9CTorchvision%20the%20machine-vision%20package%20of%20torch%2C%E2%80%9D%20in%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcel%2C%20S.%20Rodriguez%2C%20Y.%20%E2%80%9CTorchvision%20the%20machine-vision%20package%20of%20torch%2C%E2%80%9D%20in%202010"
        }
    ]
}
