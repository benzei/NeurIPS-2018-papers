{
    "filename": "7913-extracting-relationships-by-multi-domain-matching.pdf",
    "metadata": {
        "title": "Extracting Relationships by Multi-Domain Matching",
        "author": "Yitong Li, michael Murias, geraldine Dawson, David E. Carlson",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7913-extracting-relationships-by-multi-domain-matching.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In many biological and medical contexts, we construct a large labeled corpus by aggregating many sources to use in target prediction tasks. Unfortunately, many of the sources may be irrelevant to our target task, so ignoring the structure of the dataset is detrimental. This work proposes a novel approach, the Multiple Domain Matching Network (MDMN), to exploit this structure. MDMN embeds all data into a shared feature space while learning which domains share strong statistical relationships. These relationships are often insightful in their own right, and they allow domains to share strength without interference from irrelevant data. This methodology builds on existing distribution-matching approaches by assuming that source domains are varied and outcomes multi-factorial. Therefore, each domain should only match a relevant subset. Theoretical analysis shows that the proposed approach can have a tighter generalization bound than existing multiple-domain adaptation approaches. Empirically, we show that the proposed methodology handles higher numbers of source domains (up to 21 empirically), and provides state-of-the-art performance on image, text, and multi-channel time series classification, including clinical outcome data in an open label trial evaluating a novel treatment for Autism Spectrum Disorder."
    },
    "keywords": [
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "Autism Spectrum Disorder",
            "url": "https://en.wikipedia.org/wiki/Autism_Spectrum_Disorder"
        }
    ],
    "highlights": [
        "Deep learning methods have shown unparalleled performance when trained on vast amounts of diverse labeled training data [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], often collected at great cost",
        "By sharing strength within source domains, Multiple Domain Matching Network can better deal with the overfitting problem within each domain, a common problem in scientific domains",
        "Our proposed algorithm Multiple Domain Matching Network overcomes this problem by computing domain similarity in feature space while performing feature mapping, and a domain relationship graph by subject is given in Figure 2",
        "We propose the Multiple Domain Matching Network (MDMN) that uses feature matching across different source domains",
        "Multiple Domain Matching Network is able to use pairwise domain feature similarity to give a weight to each training domain, which is of key importance when the number of source domains increases, especially in many neuroscience and biological applications",
        "Our proposed adversarial training framework further applies this idea on different domain adaptation tasks and shows state-of-the-art performance"
    ],
    "key_statements": [
        "Deep learning methods have shown unparalleled performance when trained on vast amounts of diverse labeled training data [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], often collected at great cost",
        "By sharing strength within source domains, Multiple Domain Matching Network can better deal with the overfitting problem within each domain, a common problem in scientific domains",
        "Our proposed algorithm Multiple Domain Matching Network overcomes this problem by computing domain similarity in feature space while performing feature mapping, and a domain relationship graph by subject is given in Figure 2",
        "We propose the Multiple Domain Matching Network (MDMN) that uses feature matching across different source domains",
        "Multiple Domain Matching Network is able to use pairwise domain feature similarity to give a weight to each training domain, which is of key importance when the number of source domains increases, especially in many neuroscience and biological applications",
        "Our proposed adversarial training framework further applies this idea on different domain adaptation tasks and shows state-of-the-art performance"
    ],
    "summary": [
        "Deep learning methods have shown unparalleled performance when trained on vast amounts of diverse labeled training data [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], often collected at great cost.",
        "Recent approaches to multiple-domain adaptation involve learning a mapping from each domain into a common feature space, in which observations from the target and source domains have similar distributions [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>].",
        "The proposed algorithm computes pairwise domain distance, the computational cost in practice is similar compared to standard DANN model.",
        "The quantity \u21e4 given in (27) is defined in the appendix and addresses the fundamental mismatch in true labeling functions, which is uncontrollable by domain adaptation.",
        "Matching (KMM) is widely used in the assumption that target data can be represented by a weighted combination of samples in the source domain [<a class=\"ref-link\" id=\"c37\" href=\"#r37\">37</a>, <a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>].",
        "With the increasing use of neural networks, weight sharing and transfer has emerged as an effective strategy for domain adaptation [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>].",
        "The Domain Adversarial Neural Network (DANN) is a newly proposed model for feature adaptation rather than simple network weight sharing [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>].",
        "In the multiple domain case, a weighted combination of source domains is used for adaptation.",
        "The baseline method is the concatenation of feature extractor and label predictor as a standard CNN but it has no access to any target domain data during training process.",
        "This model is trained on the source domains, and features are extracted for all domains to use as inputs into TCA and SA.",
        "The top row shows the baseline result on the target domain with the classifier trained on the three other datasets.",
        "Algorithms like TCA, SA and DANN weight all source domain datasets, making the result worse than MDMN.",
        "The baseline model in Figure 4(a) shows no adaptation for the target domain, i.e. the digit \u20180\u2019 from USPS and MNIST datasets",
        "For TCA, SA and ITL methods, the baseline model was trained as before without a domain adapter on the source domain data.",
        "Our proposed algorithm MDMN overcomes this problem by computing domain similarity in feature space while performing feature mapping, and a domain relationship graph by subject is given in Figure 2.",
        "We propose the Multiple Domain Matching Network (MDMN) that uses feature matching across different source domains.",
        "MDMN is able to use pairwise domain feature similarity to give a weight to each training domain, which is of key importance when the number of source domains increases, especially in many neuroscience and biological applications.",
        "Our proposed adversarial training framework further applies this idea on different domain adaptation tasks and shows state-of-the-art performance."
    ],
    "headline": "We show that the proposed methodology handles higher numbers of source domains , and provides state-of-the-art performance on image, text, and multi-channel time series classification, including clinical outcome data in an open label trial evaluating a novel treatment for Autism Spectrum Disorder",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] S. Ao, X. Li, and C. X. Ling. Fast generalized distillation for semi-supervised domain adaptation. In AAAI, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ao%2C%20S.%20Li%2C%20X.%20Ling%2C%20C.X.%20Fast%20generalized%20distillation%20for%20semi-supervised%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ao%2C%20S.%20Li%2C%20X.%20Ling%2C%20C.X.%20Fast%20generalized%20distillation%20for%20semi-supervised%20domain%20adaptation%202017"
        },
        {
            "id": "2",
            "entry": "[2] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gan. arXiv preprint arXiv:1701.07875, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.07875"
        },
        {
            "id": "3",
            "entry": "[3] J. T. Ash, R. E. Schapire, and B. E. Engelhardt. Unsupervised domain adaptation using approximate label matching. arXiv preprint arXiv:1602.04889, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.04889"
        },
        {
            "id": "4",
            "entry": "[4] S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. W. Vaughan. A theory of learning from different domains. Machine Learning, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20S.%20Blitzer%2C%20J.%20Crammer%2C%20K.%20Kulesza%2C%20A.%20A%20theory%20of%20learning%20from%20different%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20S.%20Blitzer%2C%20J.%20Crammer%2C%20K.%20Kulesza%2C%20A.%20A%20theory%20of%20learning%20from%20different%20domains%202010"
        },
        {
            "id": "5",
            "entry": "[5] S. Ben-David and R. Urner. Domain adaptation\u2013can quantity compensate for quality? Annals of Mathematics and Artificial Intelligence, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20S.%20Urner%2C%20R.%20Domain%20adaptation%E2%80%93can%20quantity%20compensate%20for%20quality%3F%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20S.%20Urner%2C%20R.%20Domain%20adaptation%E2%80%93can%20quantity%20compensate%20for%20quality%3F%202014"
        },
        {
            "id": "6",
            "entry": "[6] M. Chen, Z. Xu, K. Q. Weinberger, and F. Sha. Marginalized stacked denoising autoencoders. In Proceedings of the Learning Workshop, Utah, UT, USA, volume 36, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20M.%20Xu%2C%20Z.%20Weinberger%2C%20K.Q.%20Sha%2C%20F.%20Marginalized%20stacked%20denoising%20autoencoders%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20M.%20Xu%2C%20Z.%20Weinberger%2C%20K.Q.%20Sha%2C%20F.%20Marginalized%20stacked%20denoising%20autoencoders%202012"
        },
        {
            "id": "7",
            "entry": "[7] N. Courty, R. Flamary, A. Habrard, and A. Rakotomamonjy. Joint distribution optimal transportation for domain adaptation. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Courty%2C%20N.%20Flamary%2C%20R.%20Habrard%2C%20A.%20Rakotomamonjy%2C%20A.%20Joint%20distribution%20optimal%20transportation%20for%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Courty%2C%20N.%20Flamary%2C%20R.%20Habrard%2C%20A.%20Rakotomamonjy%2C%20A.%20Joint%20distribution%20optimal%20transportation%20for%20domain%20adaptation%202017"
        },
        {
            "id": "8",
            "entry": "[8] N. Courty, R. Flamary, D. Tuia, and A. Rakotomamonjy. Optimal transport for domain adaptation. IEEE PAMI, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Courty%2C%20N.%20Flamary%2C%20R.%20Tuia%2C%20D.%20Rakotomamonjy%2C%20A.%20Optimal%20transport%20for%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Courty%2C%20N.%20Flamary%2C%20R.%20Tuia%2C%20D.%20Rakotomamonjy%2C%20A.%20Optimal%20transport%20for%20domain%20adaptation%202017"
        },
        {
            "id": "9",
            "entry": "[9] K. Crammer, M. Kearns, and J. Wortman. Learning from multiple sources. JMLR, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crammer%2C%20K.%20Kearns%2C%20M.%20Wortman%2C%20J.%20Learning%20from%20multiple%20sources%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Crammer%2C%20K.%20Kearns%2C%20M.%20Wortman%2C%20J.%20Learning%20from%20multiple%20sources%202008"
        },
        {
            "id": "10",
            "entry": "[10] H. Daum\u00e9 III. Frustratingly easy domain adaptation. arXiv preprint arXiv:0907.1815, 2009.",
            "arxiv_url": "https://arxiv.org/pdf/0907.1815"
        },
        {
            "id": "11",
            "entry": "[11] G. Dawson, J. M. Sun, K. S. Davlantis, M. Murias, L. Franz, J. Troy, R. Simmons, M. SabatosDeVito, R. Durham, and J. Kurtzberg. Autologous cord blood infusions are safe and feasible in young children with autism spectrum disorder: Results of a single-center phase i open-label trial. Stem Cells Translational Medicine, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dawson%2C%20G.%20Sun%2C%20J.M.%20Davlantis%2C%20K.S.%20Murias%2C%20M.%20Autologous%20cord%20blood%20infusions%20are%20safe%20and%20feasible%20in%20young%20children%20with%20autism%20spectrum%20disorder%3A%20Results%20of%20a%20single-center%20phase%20i%20open-label%20trial%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dawson%2C%20G.%20Sun%2C%20J.M.%20Davlantis%2C%20K.S.%20Murias%2C%20M.%20Autologous%20cord%20blood%20infusions%20are%20safe%20and%20feasible%20in%20young%20children%20with%20autism%20spectrum%20disorder%3A%20Results%20of%20a%20single-center%20phase%20i%20open-label%20trial%202017"
        },
        {
            "id": "12",
            "entry": "[12] L. Duan, I. W. Tsang, D. Xu, and T.-S. Chua. Domain adaptation from multiple sources via auxiliary classifiers. In ICML. ACM, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duan%2C%20L.%20Tsang%2C%20I.W.%20Xu%2C%20D.%20Chua%2C%20T.-S.%20Domain%20adaptation%20from%20multiple%20sources%20via%20auxiliary%20classifiers.%20In%20ICML%202009"
        },
        {
            "id": "13",
            "entry": "[13] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. In ICCV, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fernando%2C%20B.%20Habrard%2C%20A.%20Sebban%2C%20M.%20Tuytelaars%2C%20T.%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013"
        },
        {
            "id": "14",
            "entry": "[14] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. Lempitsky. Domain-adversarial training of neural networks. JMLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Y.%20Ustinova%2C%20E.%20Ajakan%2C%20H.%20Germain%2C%20P.%20Domain-adversarial%20training%20of%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Y.%20Ustinova%2C%20E.%20Ajakan%2C%20H.%20Germain%2C%20P.%20Domain-adversarial%20training%20of%20neural%20networks%202016"
        },
        {
            "id": "15",
            "entry": "[15] T. Gebru, J. Hoffman, and L. Fei-Fei. Fine-grained recognition in the wild: A multi-task domain adaptation approach. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gebru%2C%20T.%20Hoffman%2C%20J.%20Fei-Fei%2C%20L.%20Fine-grained%20recognition%20in%20the%20wild%3A%20A%20multi-task%20domain%20adaptation%20approach%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gebru%2C%20T.%20Hoffman%2C%20J.%20Fei-Fei%2C%20L.%20Fine-grained%20recognition%20in%20the%20wild%3A%20A%20multi-task%20domain%20adaptation%20approach%202017"
        },
        {
            "id": "16",
            "entry": "[16] X. Glorot, A. Bordes, and Y. Bengio. Domain adaptation for large-scale sentiment classification: A deep learning approach. In ICML, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20X.%20Bordes%2C%20A.%20Bengio%2C%20Y.%20Domain%20adaptation%20for%20large-scale%20sentiment%20classification%3A%20A%20deep%20learning%20approach%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20X.%20Bordes%2C%20A.%20Bengio%2C%20Y.%20Domain%20adaptation%20for%20large-scale%20sentiment%20classification%3A%20A%20deep%20learning%20approach%202011"
        },
        {
            "id": "17",
            "entry": "[17] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=I%20Goodfellow%20J%20PougetAbadie%20M%20Mirza%20B%20Xu%20D%20WardeFarley%20S%20Ozair%20A%20Courville%20and%20Y%20Bengio%20Generative%20adversarial%20nets%20In%20NIPS%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=I%20Goodfellow%20J%20PougetAbadie%20M%20Mirza%20B%20Xu%20D%20WardeFarley%20S%20Ozair%20A%20Courville%20and%20Y%20Bengio%20Generative%20adversarial%20nets%20In%20NIPS%202014"
        },
        {
            "id": "18",
            "entry": "[18] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville. Improved training of wasserstein gans. arXiv preprint arXiv:1704.00028, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.00028"
        },
        {
            "id": "19",
            "entry": "[19] C.-A. Hou, Y.-H. H. Tsai, Y.-R. Yeh, and Y.-C. F. Wang. Unsupervised domain adaptation with label and structural consistency. IEEE Transactions on Image Processing, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hou%2C%20C.-A.%20Tsai%2C%20Y.-H.H.%20Yeh%2C%20Y.-R.%20Wang%2C%20Y.-C.F.%20Unsupervised%20domain%20adaptation%20with%20label%20and%20structural%20consistency%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hou%2C%20C.-A.%20Tsai%2C%20Y.-H.H.%20Yeh%2C%20Y.-R.%20Wang%2C%20Y.-C.F.%20Unsupervised%20domain%20adaptation%20with%20label%20and%20structural%20consistency%202016"
        },
        {
            "id": "20",
            "entry": "[20] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014"
        },
        {
            "id": "21",
            "entry": "[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "22",
            "entry": "[22] C. Li, D. Alvarez-Melis, K. Xu, S. Jegelka, and S. Sra. Distributional adversarial networks. arXiv preprint arXiv:1706.09549, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.09549"
        },
        {
            "id": "23",
            "entry": "[23] Y. Li, M. Murias, S. Major, G. Dawson, K. Dzirasa, L. Carin, and D. E. Carlson. Targeting eeg/lfp synchrony with neural nets. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Y.%20Murias%2C%20M.%20Major%2C%20S.%20Dawson%2C%20G.%20Targeting%20eeg/lfp%20synchrony%20with%20neural%20nets%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Y.%20Murias%2C%20M.%20Major%2C%20S.%20Dawson%2C%20G.%20Targeting%20eeg/lfp%20synchrony%20with%20neural%20nets%202017"
        },
        {
            "id": "24",
            "entry": "[24] Y.-P. Lin and T.-P. Jung. Improving eeg-based emotion classification using conditional transfer learning. Frontiers in human neuroscience, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Y.-P.%20Jung%2C%20T.-P.%20Improving%20eeg-based%20emotion%20classification%20using%20conditional%20transfer%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Y.-P.%20Jung%2C%20T.-P.%20Improving%20eeg-based%20emotion%20classification%20using%20conditional%20transfer%20learning%202017"
        },
        {
            "id": "25",
            "entry": "[25] H. Liu, M. Shao, and Y. Fu. Structure-preserved multi-source domain adaptation. In ICDM. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20H.%20Shao%2C%20M.%20Fu%2C%20Y.%20Structure-preserved%20multi-source%20domain%20adaptation.%20In%20ICDM%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20H.%20Shao%2C%20M.%20Fu%2C%20Y.%20Structure-preserved%20multi-source%20domain%20adaptation.%20In%20ICDM%202016"
        },
        {
            "id": "26",
            "entry": "[26] M.-Y. Liu, T. Breuel, and J. Kautz. Unsupervised image-to-image translation networks. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "27",
            "entry": "[27] M.-Y. Liu and O. Tuzel. Coupled generative adversarial networks. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Tuzel%2C%20O.%20Coupled%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Tuzel%2C%20O.%20Coupled%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "28",
            "entry": "[28] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation networks. In ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Cao%2C%20Y.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Cao%2C%20Y.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202016"
        },
        {
            "id": "29",
            "entry": "[29] M. Long, H. Zhu, J. Wang, and M. I. Jordan. Unsupervised domain adaptation with residual transfer networks. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Unsupervised%20domain%20adaptation%20with%20residual%20transfer%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Unsupervised%20domain%20adaptation%20with%20residual%20transfer%20networks%202016"
        },
        {
            "id": "30",
            "entry": "[30] M. Long, H. Zhu, J. Wang, and M. I. Jordan. Deep transfer learning with joint adaptation networks. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Deep%20transfer%20learning%20with%20joint%20adaptation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.I.%20Deep%20transfer%20learning%20with%20joint%20adaptation%20networks%202017"
        },
        {
            "id": "31",
            "entry": "[31] L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. JMLR, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=v.%20d.%20Maaten%2C%20L.%20Hinton%2C%20G.%20Visualizing%20data%20using%20t-sne%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=v.%20d.%20Maaten%2C%20L.%20Hinton%2C%20G.%20Visualizing%20data%20using%20t-sne%202008"
        },
        {
            "id": "32",
            "entry": "[32] Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain adaptation with multiple sources. In NIPS, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%20with%20multiple%20sources%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Y.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Domain%20adaptation%20with%20multiple%20sources%202009"
        },
        {
            "id": "33",
            "entry": "[33] S. Motiian, Q. Jones, S. Iranmanesh, and G. Doretto. Few-shot adversarial domain adaptation. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Motiian%2C%20S.%20Jones%2C%20Q.%20Iranmanesh%2C%20S.%20Doretto%2C%20G.%20Few-shot%20adversarial%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Motiian%2C%20S.%20Jones%2C%20Q.%20Iranmanesh%2C%20S.%20Doretto%2C%20G.%20Few-shot%20adversarial%20domain%20adaptation%202017"
        },
        {
            "id": "34",
            "entry": "[34] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. IEEE Transactions on Neural Networks, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.J.%20Tsang%2C%20I.W.%20Kwok%2C%20J.T.%20Yang%2C%20Q.%20Domain%20adaptation%20via%20transfer%20component%20analysis%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.J.%20Tsang%2C%20I.W.%20Kwok%2C%20J.T.%20Yang%2C%20Q.%20Domain%20adaptation%20via%20transfer%20component%20analysis%202011"
        },
        {
            "id": "35",
            "entry": "[35] P. Russo, F. M. Carlucci, T. Tommasi, and B. Caputo. From source to target and back: symmetric bi-directional adaptive gan. arXiv preprint arXiv:1705.08824, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.08824"
        },
        {
            "id": "36",
            "entry": "[36] Y. Shi and F. Sha. Information-theoretical learning of discriminative clusters for unsupervised domain adaptation. In ICML, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shi%2C%20Y.%20Sha%2C%20F.%20Information-theoretical%20learning%20of%20discriminative%20clusters%20for%20unsupervised%20domain%20adaptation%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shi%2C%20Y.%20Sha%2C%20F.%20Information-theoretical%20learning%20of%20discriminative%20clusters%20for%20unsupervised%20domain%20adaptation%202012"
        },
        {
            "id": "37",
            "entry": "[37] Q. Sun, R. Chattopadhyay, S. Panchanathan, and J. Ye. A two-stage weighting framework for multi-source domain adaptation. In NIPS, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Q.%20Chattopadhyay%2C%20R.%20Panchanathan%2C%20S.%20Ye%2C%20J.%20A%20two-stage%20weighting%20framework%20for%20multi-source%20domain%20adaptation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Q.%20Chattopadhyay%2C%20R.%20Panchanathan%2C%20S.%20Ye%2C%20J.%20A%20two-stage%20weighting%20framework%20for%20multi-source%20domain%20adaptation%202011"
        },
        {
            "id": "38",
            "entry": "[38] W. Tu and S. Sun. A subject transfer framework for eeg classification. Neurocomputing, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tu%2C%20W.%20Sun%2C%20S.%20A%20subject%20transfer%20framework%20for%20eeg%20classification%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tu%2C%20W.%20Sun%2C%20S.%20A%20subject%20transfer%20framework%20for%20eeg%20classification%202012"
        },
        {
            "id": "39",
            "entry": "[39] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017"
        },
        {
            "id": "40",
            "entry": "[40] H. Venkateswara, J. Eusebio, S. Chakraborty, and S. Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Venkateswara%2C%20H.%20Eusebio%2C%20J.%20Chakraborty%2C%20S.%20Panchanathan%2C%20S.%20Deep%20hashing%20network%20for%20unsupervised%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Venkateswara%2C%20H.%20Eusebio%2C%20J.%20Chakraborty%2C%20S.%20Panchanathan%2C%20S.%20Deep%20hashing%20network%20for%20unsupervised%20domain%20adaptation%202017"
        },
        {
            "id": "41",
            "entry": "[41] C. Villani. Optimal transport: old and new. Springer Science & Business Media, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Villani%2C%20C.%20Optimal%20transport%3A%20old%20and%20new%202008"
        },
        {
            "id": "42",
            "entry": "[42] M.-A. T. Vu, T. Adali, D. Ba, G. Buzsaki, D. Carlson, K. Heller, C. Liston, C. Rudin, V. Sohal, A. S. Widge, et al. A shared vision for machine learning in neuroscience. Journal of Neuroscience, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vu%2C%20M.-A.T.%20Adali%2C%20T.%20Ba%2C%20D.%20Buzsaki%2C%20G.%20A%20shared%20vision%20for%20machine%20learning%20in%20neuroscience%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vu%2C%20M.-A.T.%20Adali%2C%20T.%20Ba%2C%20D.%20Buzsaki%2C%20G.%20A%20shared%20vision%20for%20machine%20learning%20in%20neuroscience%202018"
        },
        {
            "id": "43",
            "entry": "[43] Q. Xie, Z. Dai, Y. Du, E. Hovy, and G. Neubig. Adversarial invariant feature learning. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20Q.%20Dai%2C%20Z.%20Du%2C%20Y.%20Hovy%2C%20E.%20Adversarial%20invariant%20feature%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20Q.%20Dai%2C%20Z.%20Du%2C%20Y.%20Hovy%2C%20E.%20Adversarial%20invariant%20feature%20learning%202017"
        },
        {
            "id": "44",
            "entry": "[44] H. Xu, A. Lorbert, P. J. Ramadge, J. S. Guntupalli, and J. V. Haxby. Regularized hyperalignment of multi-set fmri data. In Statistical Signal Processing Workshop (SSP). IEEE, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20H.%20Lorbert%2C%20A.%20Ramadge%2C%20P.J.%20Guntupalli%2C%20J.S.%20Regularized%20hyperalignment%20of%20multi-set%20fmri%20data%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20H.%20Lorbert%2C%20A.%20Ramadge%2C%20P.J.%20Guntupalli%2C%20J.S.%20Regularized%20hyperalignment%20of%20multi-set%20fmri%20data%202012"
        },
        {
            "id": "45",
            "entry": "[45] H. Zhao, S. Zhang, G. Wu, J. P. Costeira, J. M. Moura, and G. J. Gordon. Multiple source domain adaptation with adversarial training of neural networks. arXiv preprint arXiv:1705.09684, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.09684"
        },
        {
            "id": "46",
            "entry": "[46] W.-L. Zheng and B.-L. Lu. Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks. IEEE Transactions on Autonomous Mental Development, 2015. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20W.-L.%20Lu%2C%20B.-L.%20Investigating%20critical%20frequency%20bands%20and%20channels%20for%20eeg-based%20emotion%20recognition%20with%20deep%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20W.-L.%20Lu%2C%20B.-L.%20Investigating%20critical%20frequency%20bands%20and%20channels%20for%20eeg-based%20emotion%20recognition%20with%20deep%20neural%20networks%202015"
        }
    ]
}
