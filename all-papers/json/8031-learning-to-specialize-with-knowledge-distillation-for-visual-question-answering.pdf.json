{
    "filename": "8031-learning-to-specialize-with-knowledge-distillation-for-visual-question-answering.pdf",
    "metadata": {
        "title": "Learning to Specialize with Knowledge Distillation for Visual Question Answering",
        "author": "Jonghwan Mun, Kimin Lee, Jinwoo Shin, Bohyung Han",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8031-learning-to-specialize-with-knowledge-distillation-for-visual-question-answering.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Visual Question Answering (VQA) is a notoriously challenging problem because it involves various heterogeneous tasks defined by questions within a unified framework. Learning specialized models for individual types of tasks is intuitively attracting but surprisingly difficult; it is not straightforward to outperform na\u00efve independent ensemble approach. We present a principled algorithm to learn specialized models with knowledge distillation under a multiple choice learning (MCL) framework, where training examples are assigned dynamically to a subset of models for updating network parameters. The assigned and non-assigned models are learned to predict ground-truth answers and imitate their own base models before specialization, respectively. Our approach alleviates the limitation of data deficiency in existing MCL frameworks, and allows each model to learn its own specialized expertise without forgetting general knowledge. The proposed framework is model-agnostic and applicable to any tasks including VQA and image classification with a large number of labels but few per-class examples, which is known to be difficult under existing MCL schemes. Our experimental results indeed demonstrate that our method outperforms other baselines for VQA and image classification."
    },
    "keywords": [
        {
            "term": "question answering",
            "url": "https://en.wikipedia.org/wiki/question_answering"
        },
        {
            "term": "image classification",
            "url": "https://en.wikipedia.org/wiki/image_classification"
        },
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "multiple choice",
            "url": "https://en.wikipedia.org/wiki/multiple_choice"
        },
        {
            "term": "ground truth",
            "url": "https://en.wikipedia.org/wiki/ground_truth"
        }
    ],
    "highlights": [
        "Learning<br/><br/>This section introduces the main idea of multiple choice learning, and compares its two variants, original and confident multiple choice learning. 2.1",
        "We propose a novel model-agnostic ensemble learning algorithm, referred to as Multiple Choice Learning with Knowledge Distillation (MCL-KD), which learns models to be specialized to a subset of tasks",
        "Results We compare our algorithm denoted by Multiple Choice Learning-KD with three baselines\u2014independent ensemble, Multiple Choice Learning and Confident Multiple Choice Learning",
        "Confident Multiple Choice Learning is substantially better than Multiple Choice Learning, but still not sufficient to achieve clear accuracy improvement with respect to independent ensemble",
        "We presented a novel and principled framework to learn specialized models for visual question answering",
        "We showed that our algorithm consistently outperforms all other methods including independent ensemble, Multiple Choice Learning, Confident Multiple Choice Learning in Visual Question Answering and image classification"
    ],
    "key_statements": [
        "Learning<br/><br/>This section introduces the main idea of multiple choice learning, and compares its two variants, original and confident multiple choice learning. 2.1",
        "We propose a novel model-agnostic ensemble learning algorithm, referred to as Multiple Choice Learning with Knowledge Distillation (MCL-KD), which learns models to be specialized to a subset of tasks",
        "The proposed algorithm is applied to existing Visual Question Answering models and consistently improves performance compared to independent ensembles and existing Multiple Choice Learning-based approaches",
        "In contrast to the prior works, our novelty lies in utilizing knowledge distillation for balancing generalization and specialization of ensemble models.\n2 Background on Multiple Choice Learning. This section introduces the main idea of multiple choice learning, and compares its two variants, original and confident multiple choice learning.\n2.1",
        "To tackle the limitations of the existing Multiple Choice Learning techniques, we present a more principled oracle loss .\n3 Multiple Choice Learning with Knowledge Distillation",
        "Multiple Choice Learning and Confident Multiple Choice Learning show potential to achieve competitive performance compared to independent ensembles, model specialization on a subset of training examples suffers from weak generalization power of each model, often resulting in degraded accuracy",
        "Given a training dataset D = {(x1, y1), (x2, y2), ...,} and M independently trained base models with fixed model parameters \u03c6m, we train M models parametrized by \u03b8m in the proposed Multiple Choice Learning-KD framework using the following oracle loss: LMCL-KD(D)",
        "Contrary to Confident Multiple Choice Learning, the knowledge distillation loss in our framework provides opportunity to learn from non-assigned training examples and makes non-specialized models as competitive as the corresponding base models for those examples",
        "The dataset is composed of 70,000 training images with 699,989 questions and 15,000 validation images with 149,991 questions, where each question is associated with a single unique answer",
        "Results We compare our algorithm denoted by Multiple Choice Learning-KD with three baselines\u2014independent ensemble, Multiple Choice Learning and Confident Multiple Choice Learning",
        "Confident Multiple Choice Learning is substantially better than Multiple Choice Learning, but still not sufficient to achieve clear accuracy improvement with respect to independent ensemble",
        "Since the non-specialized models in Confident Multiple Choice Learning are learned to generate uniform distribution and all models lose the opportunity to learn from a sufficient number of training examples, specialized model fails to predict the correct answer",
        "Both Multiple Choice Learning and Confident Multiple Choice Learning fail to achieve competitive accuracy compared to independent ensemble regardless of k",
        "It is surprising that their oracle accuracies are often worse than those of independent ensemble. This is because the number of training examples per class is only 500 in CIFAR-100, and the data deficiency problem drives Multiple Choice Learning and Confident Multiple Choice Learning to fail in specialization",
        "We presented a novel and principled framework to learn specialized models for visual question answering",
        "We showed that our algorithm consistently outperforms all other methods including independent ensemble, Multiple Choice Learning, Confident Multiple Choice Learning in Visual Question Answering and image classification"
    ],
    "summary": [
        "Learning<br/><br/>This section introduces the main idea of multiple choice learning, and compares its two variants, original and confident multiple choice learning. 2.1.",
        "In addition to such data deficiency issue, MCL loses the opportunity to learn general knowledge from the examples assigned to other models.",
        "We propose a novel model-agnostic ensemble learning algorithm, referred to as Multiple Choice Learning with Knowledge Distillation (MCL-KD), which learns models to be specialized to a subset of tasks.",
        "The proposed algorithm is applied to existing VQA models and consistently improves performance compared to independent ensembles and existing MCL-based approaches.",
        "The oracle loss in CMCL is well-designed to learn specialized models, its performance is not impressive particularly in complex tasks such as VQA because the loss function enforces individual models to disregard unassigned training examples completely.",
        "MCL and CMCL show potential to achieve competitive performance compared to independent ensembles, model specialization on a subset of training examples suffers from weak generalization power of each model, often resulting in degraded accuracy.",
        "Given a training dataset D = {(x1, y1), (x2, y2), ...,} and M independently trained base models with fixed model parameters \u03c6m, we train M models parametrized by \u03b8m in the proposed MCL-KD framework using the following oracle loss: LMCL-KD(D)",
        "Specialized models are learned to predict the ground-truth answers while nonspecialized ones are trained to preserve the representations of the corresponding base models.",
        "Contrary to CMCL, the knowledge distillation loss in our framework provides opportunity to learn from non-assigned training examples and makes non-specialized models as competitive as the corresponding base models for those examples.",
        "Specialized answering networks with knowledge distillation are trained with the loss function in Eq (4) with task replaced by VQA.",
        "Since the non-specialized models in CMCL are learned to generate uniform distribution and all models lose the opportunity to learn from a sufficient number of training examples, specialized model fails to predict the correct answer.",
        "This is because the number of training examples per class is only 500 in CIFAR-100, and the data deficiency problem drives MCL and CMCL to fail in specialization.",
        "We formulate the problem with an ensemble of models, where each model is specialized dynamically on a subset of training examples within a multiple choice learning framework.",
        "By exploiting the idea of knowledge distillation, we first learn base models with the whole data and specialize models to predict ground-truth labels on assigned examples while preserving the representations of the base models on non-assigned ones.",
        "We believe that adaptively determining the number of models for specialization of each example would be an interesting future direction"
    ],
    "headline": "We present a principled algorithm to learn specialized models with knowledge distillation under a multiple choice learning  framework, where training examples are assigned dynamically to a subset of models for updating network parameters",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang. Bottom-up and top-down attention for image captioning and visual question answering. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anderson%2C%20P.%20He%2C%20X.%20Buehler%2C%20C.%20Teney%2C%20D.%20Bottom-up%20and%20top-down%20attention%20for%20image%20captioning%20and%20visual%20question%20answering%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anderson%2C%20P.%20He%2C%20X.%20Buehler%2C%20C.%20Teney%2C%20D.%20Bottom-up%20and%20top-down%20attention%20for%20image%20captioning%20and%20visual%20question%20answering%202018"
        },
        {
            "id": "2",
            "entry": "[2] J. Andreas, M. Rohrbach, T. Darrell, and D. Klein. Learning to compose neural networks for question answering. In NAACL, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andreas%2C%20J.%20Rohrbach%2C%20M.%20Darrell%2C%20T.%20Klein%2C%20D.%20Learning%20to%20compose%20neural%20networks%20for%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andreas%2C%20J.%20Rohrbach%2C%20M.%20Darrell%2C%20T.%20Klein%2C%20D.%20Learning%20to%20compose%20neural%20networks%20for%20question%20answering%202016"
        },
        {
            "id": "3",
            "entry": "[3] J. Andreas, M. Rohrbach, T. Darrell, and D. Klein. Neural module networks. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=J%20Andreas%20M%20Rohrbach%20T%20Darrell%20and%20D%20Klein%20Neural%20module%20networks%20In%20CVPR%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=J%20Andreas%20M%20Rohrbach%20T%20Darrell%20and%20D%20Klein%20Neural%20module%20networks%20In%20CVPR%202016"
        },
        {
            "id": "4",
            "entry": "[4] H. Ben-younes, R. Cadene, M. Cord, and N. Thome. Mutan: Multimodal tucker fusion for visual question answering. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-younes%2C%20H.%20Cadene%2C%20R.%20Cord%2C%20M.%20N.%20Thome.%20Mutan%3A%20Multimodal%20tucker%20fusion%20for%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-younes%2C%20H.%20Cadene%2C%20R.%20Cord%2C%20M.%20N.%20Thome.%20Mutan%3A%20Multimodal%20tucker%20fusion%20for%20visual%20question%20answering%202017"
        },
        {
            "id": "5",
            "entry": "[5] G. Chen, W. Choi, X. Chen, T. X. Han, and M. K. Chandraker. Learning efficient object detection models with knowledge distillation. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20G.%20Choi%2C%20W.%20Chen%2C%20X.%20Han%2C%20T.X.%20Learning%20efficient%20object%20detection%20models%20with%20knowledge%20distillation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20G.%20Choi%2C%20W.%20Chen%2C%20X.%20Han%2C%20T.X.%20Learning%20efficient%20object%20detection%20models%20with%20knowledge%20distillation%202017"
        },
        {
            "id": "6",
            "entry": "[6] T. Chen, I. J. Goodfellow, and J. Shlens. Net2net: Accelerating learning via knowledge transfer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20T.%20Goodfellow%2C%20I.J.%20Shlens%2C%20J.%20Net2net%3A%20Accelerating%20learning%20via%20knowledge%20transfer"
        },
        {
            "id": "7",
            "entry": "[7] D. Ciregan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In CVPR, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ciregan%2C%20D.%20Meier%2C%20U.%20Schmidhuber%2C%20J.%20Multi-column%20deep%20neural%20networks%20for%20image%20classification%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ciregan%2C%20D.%20Meier%2C%20U.%20Schmidhuber%2C%20J.%20Multi-column%20deep%20neural%20networks%20for%20image%20classification%202012"
        },
        {
            "id": "8",
            "entry": "[8] A. Fukui, D. H. Park, D. Yang, A. Rohrbach, T. Darrell, and M. Rohrbach. Multimodal compact bilinear pooling for visual question answering and visual grounding. In EMNLP, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fukui%2C%20A.%20Park%2C%20D.H.%20Yang%2C%20D.%20Rohrbach%2C%20A.%20Multimodal%20compact%20bilinear%20pooling%20for%20visual%20question%20answering%20and%20visual%20grounding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fukui%2C%20A.%20Park%2C%20D.H.%20Yang%2C%20D.%20Rohrbach%2C%20A.%20Multimodal%20compact%20bilinear%20pooling%20for%20visual%20question%20answering%20and%20visual%20grounding%202016"
        },
        {
            "id": "9",
            "entry": "[9] Y. Goyal, T. Khot, D. Summers-Stay, D. Batra, and D. Parikh. Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goyal%2C%20Y.%20Khot%2C%20T.%20Summers-Stay%2C%20D.%20Batra%2C%20D.%20Making%20the%20V%20in%20VQA%20matter%3A%20Elevating%20the%20role%20of%20image%20understanding%20in%20Visual%20Question%20Answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goyal%2C%20Y.%20Khot%2C%20T.%20Summers-Stay%2C%20D.%20Batra%2C%20D.%20Making%20the%20V%20in%20VQA%20matter%3A%20Elevating%20the%20role%20of%20image%20understanding%20in%20Visual%20Question%20Answering%202017"
        },
        {
            "id": "10",
            "entry": "[10] A. Guzman-Rivera, D. Batra, and P. Kohli. Multiple choice learning: Learning to produce multiple structured outputs. In NIPS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guzman-Rivera%2C%20A.%20Batra%2C%20D.%20Kohli%2C%20P.%20Multiple%20choice%20learning%3A%20Learning%20to%20produce%20multiple%20structured%20outputs%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guzman-Rivera%2C%20A.%20Batra%2C%20D.%20Kohli%2C%20P.%20Multiple%20choice%20learning%3A%20Learning%20to%20produce%20multiple%20structured%20outputs%202012"
        },
        {
            "id": "11",
            "entry": "[11] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "12",
            "entry": "[12] G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network. In NIPS Deep Learning and Representation Learning Workshop, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20G.%20Vinyals%2C%20O.%20Dean%2C%20J.%20Distilling%20the%20knowledge%20in%20a%20neural%20network.%20In%20NIPS%20Deep%20Learning%20and%20Representation%20Learning%20Workshop%202015"
        },
        {
            "id": "13",
            "entry": "[13] R. Hu, J. Andreas, M. Rohrbach, T. Darrell, and K. Saenko. Learning to reason: End-to-end module networks for visual question answering. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20R.%20Andreas%2C%20J.%20Rohrbach%2C%20M.%20Darrell%2C%20T.%20Learning%20to%20reason%3A%20End-to-end%20module%20networks%20for%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20R.%20Andreas%2C%20J.%20Rohrbach%2C%20M.%20Darrell%2C%20T.%20Learning%20to%20reason%3A%20End-to-end%20module%20networks%20for%20visual%20question%20answering%202017"
        },
        {
            "id": "14",
            "entry": "[14] J. Johnson, B. Hariharan, L. van der Maaten, L. Fei-Fei, C. L. Zitnick, and R. Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20J.%20Hariharan%2C%20B.%20van%20der%20Maaten%2C%20L.%20Fei-Fei%2C%20L.%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20J.%20Hariharan%2C%20B.%20van%20der%20Maaten%2C%20L.%20Fei-Fei%2C%20L.%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017"
        },
        {
            "id": "15",
            "entry": "[15] V. Kazemi and A. Elqursh. Show, ask, attend, and answer: A strong baseline for visual question answering. arXiv preprint arXiv:1704.03162, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.03162"
        },
        {
            "id": "16",
            "entry": "[16] J.-H. Kim, K.-W. On, W. Lim, J. Kim, J.-W. Ha, and B.-T. Zhang. Hadamard product for low-rank bilinear pooling. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20J.-H.%20On%2C%20K.-W.%20Lim%2C%20W.%20Kim%2C%20J.%20Hadamard%20product%20for%20low-rank%20bilinear%20pooling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20J.-H.%20On%2C%20K.-W.%20Lim%2C%20W.%20Kim%2C%20J.%20Hadamard%20product%20for%20low-rank%20bilinear%20pooling%202017"
        },
        {
            "id": "17",
            "entry": "[17] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "18",
            "entry": "[18] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Hinton%2C%20G.%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "19",
            "entry": "[19] K. Lee, C. Hwang, K. Park, and J. Shin. Confident multiple choice learning. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20K.%20Hwang%2C%20C.%20Park%2C%20K.%20Shin%2C%20J.%20Confident%20multiple%20choice%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20K.%20Hwang%2C%20C.%20Park%2C%20K.%20Shin%2C%20J.%20Confident%20multiple%20choice%20learning%202017"
        },
        {
            "id": "20",
            "entry": "[20] K. Lee, H. Lee, K. Lee, and J. Shin. Training confidence-calibrated classifiers for detecting out-of-distribution samples. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20K.%20Lee%2C%20H.%20Lee%2C%20K.%20Shin%2C%20J.%20Training%20confidence-calibrated%20classifiers%20for%20detecting%20out-of-distribution%20samples%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20K.%20Lee%2C%20H.%20Lee%2C%20K.%20Shin%2C%20J.%20Training%20confidence-calibrated%20classifiers%20for%20detecting%20out-of-distribution%20samples%202018"
        },
        {
            "id": "21",
            "entry": "[21] S. Lee, S. P. S. Prakash, M. Cogswell, V. Ranjan, D. Crandall, and D. Batra. Stochastic multiple choice learning for training diverse deep ensembles. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20S.%20Prakash%2C%20S.P.S.%20Cogswell%2C%20M.%20Ranjan%2C%20V.%20Stochastic%20multiple%20choice%20learning%20for%20training%20diverse%20deep%20ensembles%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20S.%20Prakash%2C%20S.P.S.%20Cogswell%2C%20M.%20Ranjan%2C%20V.%20Stochastic%20multiple%20choice%20learning%20for%20training%20diverse%20deep%20ensembles%202016"
        },
        {
            "id": "22",
            "entry": "[22] Q. Li, S. Jin, and J. Yan. Mimicking very efficient network for object detection. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Q.%20Jin%2C%20S.%20Yan%2C%20J.%20Mimicking%20very%20efficient%20network%20for%20object%20detection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Q.%20Jin%2C%20S.%20Yan%2C%20J.%20Mimicking%20very%20efficient%20network%20for%20object%20detection%202017"
        },
        {
            "id": "23",
            "entry": "[23] Z. Li and D. Hoiem. Learning without forgetting. In ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Z.%20Hoiem%2C%20D.%20Learning%20without%20forgetting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Z.%20Hoiem%2C%20D.%20Learning%20without%20forgetting%202016"
        },
        {
            "id": "24",
            "entry": "[24] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In ECCV, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=TY%20Lin%20M%20Maire%20S%20Belongie%20J%20Hays%20P%20Perona%20D%20Ramanan%20P%20Doll%C3%A1r%20and%20C%20L%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20ECCV%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=TY%20Lin%20M%20Maire%20S%20Belongie%20J%20Hays%20P%20Perona%20D%20Ramanan%20P%20Doll%C3%A1r%20and%20C%20L%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20ECCV%202014"
        },
        {
            "id": "25",
            "entry": "[25] P. Luo, Z. Zhu, Z. Liu, X. Wang, and X. Tang. Face model compression by distilling knowledge from neurons. In AAAI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20P.%20Zhu%2C%20Z.%20Liu%2C%20Z.%20Wang%2C%20X.%20Face%20model%20compression%20by%20distilling%20knowledge%20from%20neurons%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20P.%20Zhu%2C%20Z.%20Liu%2C%20Z.%20Wang%2C%20X.%20Face%20model%20compression%20by%20distilling%20knowledge%20from%20neurons%202016"
        },
        {
            "id": "26",
            "entry": "[26] H. Nam, J.-W. Ha, and J. Kim. Dual attention networks for multimodal reasoning and matching. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nam%2C%20H.%20Ha%2C%20J.-W.%20Kim%2C%20J.%20Dual%20attention%20networks%20for%20multimodal%20reasoning%20and%20matching%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nam%2C%20H.%20Ha%2C%20J.-W.%20Kim%2C%20J.%20Dual%20attention%20networks%20for%20multimodal%20reasoning%20and%20matching%202017"
        },
        {
            "id": "27",
            "entry": "[27] H. Noh and B. Han. Training recurrent answering units with joint loss minimization for vqa. arXiv preprint arXiv:1606.03647, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.03647"
        },
        {
            "id": "28",
            "entry": "[28] H. Noh, P. H. Seo, and B. Han. Image question answering using convolutional neural network with dynamic parameter prediction. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Noh%2C%20H.%20Seo%2C%20P.H.%20Han%2C%20B.%20Image%20question%20answering%20using%20convolutional%20neural%20network%20with%20dynamic%20parameter%20prediction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Noh%2C%20H.%20Seo%2C%20P.H.%20Han%2C%20B.%20Image%20question%20answering%20using%20convolutional%20neural%20network%20with%20dynamic%20parameter%20prediction%202016"
        },
        {
            "id": "29",
            "entry": "[29] M. Noroozi, A. Vinjimoor, P. Favaro, and H. Pirsiavash. Boosting self-supervised learning via knowledge transfer. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Noroozi%2C%20M.%20Vinjimoor%2C%20A.%20Favaro%2C%20P.%20Pirsiavash%2C%20H.%20Boosting%20self-supervised%20learning%20via%20knowledge%20transfer%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Noroozi%2C%20M.%20Vinjimoor%2C%20A.%20Favaro%2C%20P.%20Pirsiavash%2C%20H.%20Boosting%20self-supervised%20learning%20via%20knowledge%20transfer%202018"
        },
        {
            "id": "30",
            "entry": "[30] A. Romero, N. Ballas, S. E. Kahou, A. Chassang, C. Gatta, and Y. Bengio. Fitnets: Hints for thin deep nets. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Romero%2C%20A.%20Ballas%2C%20N.%20Kahou%2C%20S.E.%20Chassang%2C%20A.%20Fitnets%3A%20Hints%20for%20thin%20deep%20nets%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Romero%2C%20A.%20Ballas%2C%20N.%20Kahou%2C%20S.E.%20Chassang%2C%20A.%20Fitnets%3A%20Hints%20for%20thin%20deep%20nets%202015"
        },
        {
            "id": "31",
            "entry": "[31] K. J. Shih, S. Singh, and D. Hoiem. Where to look: Focus regions for visual question answering. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shih%2C%20K.J.%20Singh%2C%20S.%20Hoiem%2C%20D.%20Where%20to%20look%3A%20Focus%20regions%20for%20visual%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shih%2C%20K.J.%20Singh%2C%20S.%20Hoiem%2C%20D.%20Where%20to%20look%3A%20Focus%20regions%20for%20visual%20question%20answering%202016"
        },
        {
            "id": "32",
            "entry": "[32] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "33",
            "entry": "[33] H. Xu and K. Saenko. Ask, attend and answer: Exploring question-guided spatial attention for visual question answering. In ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20H.%20Ask%2C%20K.Saenko%20attend%20and%20answer%3A%20Exploring%20question-guided%20spatial%20attention%20for%20visual%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20H.%20Ask%2C%20K.Saenko%20attend%20and%20answer%3A%20Exploring%20question-guided%20spatial%20attention%20for%20visual%20question%20answering%202016"
        },
        {
            "id": "34",
            "entry": "[34] Z. Yang, X. He, J. Gao, L. Deng, and A. Smola. Stacked attention networks for image question answering. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Z.%20He%2C%20X.%20Gao%2C%20J.%20Deng%2C%20L.%20Stacked%20attention%20networks%20for%20image%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Z.%20He%2C%20X.%20Gao%2C%20J.%20Deng%2C%20L.%20Stacked%20attention%20networks%20for%20image%20question%20answering%202016"
        },
        {
            "id": "35",
            "entry": "[35] J. Yim, D. Joo, J. Bae, and J. Kim. A gift from knowledge distillation: Fast optimization, network minimization and transfer learning. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yim%2C%20J.%20Joo%2C%20D.%20Bae%2C%20J.%20Kim%2C%20J.%20A%20gift%20from%20knowledge%20distillation%3A%20Fast%20optimization%2C%20network%20minimization%20and%20transfer%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yim%2C%20J.%20Joo%2C%20D.%20Bae%2C%20J.%20Kim%2C%20J.%20A%20gift%20from%20knowledge%20distillation%3A%20Fast%20optimization%2C%20network%20minimization%20and%20transfer%20learning%202017"
        },
        {
            "id": "36",
            "entry": "[36] S. Zagoruyko and N. Komodakis. Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. In ICLR, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zagoruyko%2C%20S.%20Komodakis%2C%20N.%20Paying%20more%20attention%20to%20attention%3A%20Improving%20the%20performance%20of%20convolutional%20neural%20networks%20via%20attention%20transfer%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zagoruyko%2C%20S.%20Komodakis%2C%20N.%20Paying%20more%20attention%20to%20attention%3A%20Improving%20the%20performance%20of%20convolutional%20neural%20networks%20via%20attention%20transfer%202017"
        }
    ]
}
