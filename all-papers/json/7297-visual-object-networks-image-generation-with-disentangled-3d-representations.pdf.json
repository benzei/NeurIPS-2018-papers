{
    "filename": "7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf",
    "metadata": {
        "title": "Visual Object Networks: Image Generation with Disentangled 3D Representations",
        "author": "Jun-Yan Zhu, Zhoutong Zhang, Chengkai Zhang, Jiajun Wu, Antonio Torralba, Josh Tenenbaum, Bill Freeman",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Recent progress in deep generative models has led to tremendous breakthroughs in image generation. While being able to synthesize photorealistic images, existing models lack an understanding of our underlying 3D world. Different from previous works built on 2D datasets and models, we present a new generative model, Visual Object Networks (VON), synthesizing natural images of objects with a disentangled 3D representation. Inspired by classic graphics rendering pipelines, we unravel the image formation process into three conditionally independent factors\u2014viewpoint, shape, and texture\u2014and present an end-to-end adversarial learning framework that jointly models 3D shape and 2D texture. Our model first learns to synthesize 3D shapes that are indistinguishable from real shapes. It then renders the object\u2019s 2.5D sketches (i.e. silhouette and depth map) from its shape under a sampled viewpoint. Finally, it learns to add realistic textures to these 2.5D sketches to generate realistic images. The VON not only generates images that are more realistic than the stateof-the-art 2D image synthesis methods but also enables many 3D operations such as changing the viewpoint of a generated image, shape and texture editing, and linear interpolation in texture and shape space."
    },
    "keywords": [
        {
            "term": "image synthesis",
            "url": "https://en.wikipedia.org/wiki/image_synthesis"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        }
    ],
    "highlights": [
        "Modern deep generative models learn to synthesize realistic images",
        "Figure 1a shows a car generated by a recent deep generative model (WGAN-GP) [<a class=\"ref-link\" id=\"cGulrajani_et+al_2017_a\" href=\"#rGulrajani_et+al_2017_a\">Gulrajani et al, 2017</a>]",
        "We show that visual object networks produce more realistic image samples compared with recent 2D deep generative models",
        "We apply our visual object networks to several 3D manipulation applications, none of which can be achieved by existing 2D generative models [<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>, <a class=\"ref-link\" id=\"cKingma_2014_a\" href=\"#rKingma_2014_a\">Kingma and Welling, 2014</a>]",
        "We present visual object networks (VON), a fully differentiable 3D-aware generative model for image and shape synthesis",
        "Our model synthesizes more photorealistic images compared to existing 2D generative models; it allows various 3D manipulations that are not possible with prior 2D methods"
    ],
    "key_statements": [
        "Modern deep generative models learn to synthesize realistic images",
        "Figure 1a shows a car generated by a recent deep generative model (WGAN-GP) [<a class=\"ref-link\" id=\"cGulrajani_et+al_2017_a\" href=\"#rGulrajani_et+al_2017_a\">Gulrajani et al, 2017</a>]",
        "We show that visual object networks produce more realistic image samples compared with recent 2D deep generative models",
        "Table 1 shows that our results have the smallest Fr\u00e9chet Inception Distance; in Table 2, 74% \u2212 85% of the responses preferred our results",
        "This performance gain shows that the learned 3D prior helps our model synthesize more realistic images",
        "We apply our visual object networks to several 3D manipulation applications, none of which can be achieved by existing 2D generative models [<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>, <a class=\"ref-link\" id=\"cKingma_2014_a\" href=\"#rKingma_2014_a\">Kingma and Welling, 2014</a>]",
        "We present visual object networks (VON), a fully differentiable 3D-aware generative model for image and shape synthesis",
        "Our model synthesizes more photorealistic images compared to existing 2D generative models; it allows various 3D manipulations that are not possible with prior 2D methods"
    ],
    "summary": [
        "Modern deep generative models learn to synthesize realistic images.",
        "We present an end-to-end generative model that jointly synthesizes 3D shapes and 2D images via a disentangled object representation.",
        "We decompose our image generation model into three conditionally independent factors: shape, viewpoint, and texture, borrowing ideas from classic graphics rendering engines.",
        "We show that VON produce more realistic image samples compared with recent 2D deep generative models.",
        "While they focus on 3D reconstruction, we aim to learn an unconditional generative model of shapes and images with disentangled representations of object texture, shape and pose.",
        "Our goal is to learn an generative model that can sample an image x \u2208 RH\u00d7W\u00d73 from three factors: a shape code zshape, a viewpoint code zview, and a texture code ztexture.",
        "We learn a 3D shape generation network that produces realistic voxels v = Gshape given a shape code zshape (Section 3.1).",
        "We learn to produce a final image given the 2.5D sketches v2.5D and a randomly sampled texture code ztexture, using our texture synthesis network x = Gtexture(v2.5D, ztexture) in Section 3.3.",
        "Consider a voxelized 3D object collection {vi}iN , where vi \u2208 RW\u00d7W\u00d7W , we learn a generator Gshape to map a shape code zshape, randomly sampled from a Gaussian distribution, to a W \u00d7 W \u00d7 W voxel grid.",
        "Given the projected 2.5D sketches, which encode both the viewpoint and the object shape, we learn to synthesize realistic 2D images.",
        "Randomly sampled texture code ztexture and the projected 2.5D sketches v2.5D as input, and produces a 2D image x = Gtexture(v2.5D, ztexture).",
        "We introduce a latent space cycle-consistency loss to encourage Gtexture to use the texture code ztexture.",
        "We sample 200 pairs of generated images from the VON and the state-of-the-art models (DCGAN, LSGAN, and WGAN-GP), and show each pair to five subjects on Amazon MTurk.",
        "Shape Generation For shape generation, we compare our method against prior work 3D-GAN [<a class=\"ref-link\" id=\"cWu_et+al_2016_a\" href=\"#rWu_et+al_2016_a\">Wu et al, 2016</a>] on both voxel grids and distance function representation.",
        "We apply our visual object networks to several 3D manipulation applications, none of which can be achieved by existing 2D generative models [<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>, <a class=\"ref-link\" id=\"cKingma_2014_a\" href=\"#rKingma_2014_a\">Kingma and Welling, 2014</a>].",
        "We present visual object networks (VON), a fully differentiable 3D-aware generative model for image and shape synthesis.",
        "Our key idea is to disentangle the image generation process into three factors: shape, viewpoint, and texture."
    ],
    "headline": "Different from previous works built on 2D datasets and models, we present a new generative model, Visual Object Networks , synthesizing natural images of objects with a disentangled 3D representation",
    "reference_links": [
        {
            "id": "Achlioptas_et+al_2018_a",
            "entry": "Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas. Learning representations and generative models for 3d point clouds. In ICLR Workshop, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Achlioptas%2C%20Panos%20Diamanti%2C%20Olga%20Mitliagkas%2C%20Ioannis%20Guibas%2C%20Leonidas%20Learning%20representations%20and%20generative%20models%20for%203d%20point%20clouds%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Achlioptas%2C%20Panos%20Diamanti%2C%20Olga%20Mitliagkas%2C%20Ioannis%20Guibas%2C%20Leonidas%20Learning%20representations%20and%20generative%20models%20for%203d%20point%20clouds%202018"
        },
        {
            "id": "Almahairi_et+al_2018_a",
            "entry": "Amjad Almahairi, Sai Rajeswar, Alessandro Sordoni, Philip Bachman, and Aaron Courville. Augmented cyclegan: Learning many-to-many mappings from unpaired data. In ICML, 2018. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Almahairi%2C%20Amjad%20Rajeswar%2C%20Sai%20Sordoni%2C%20Alessandro%20Bachman%2C%20Philip%20Augmented%20cyclegan%3A%20Learning%20many-to-many%20mappings%20from%20unpaired%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Almahairi%2C%20Amjad%20Rajeswar%2C%20Sai%20Sordoni%2C%20Alessandro%20Bachman%2C%20Philip%20Augmented%20cyclegan%3A%20Learning%20many-to-many%20mappings%20from%20unpaired%20data%202018"
        },
        {
            "id": "Mart_2017_a",
            "entry": "Mart\u00edn Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In ICML, 2017. 2, 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mart%C3%ADn%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mart%C3%ADn%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Barrow_0000_a",
            "entry": "Harry G Barrow and Jay M Tenenbaum. Recovering intrinsic scene characteristics from images. Computer Vision Systems, 1978. 1, 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barrow%2C%20Harry%20G.%20Tenenbaum%2C%20Jay%20M.%20Recovering%20intrinsic%20scene%20characteristics%20from%20images",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barrow%2C%20Harry%20G.%20Tenenbaum%2C%20Jay%20M.%20Recovering%20intrinsic%20scene%20characteristics%20from%20images"
        },
        {
            "id": "Bever_2010_a",
            "entry": "Thomas G Bever and David Poeppel. Analysis by synthesis: a (re-) emerging program of research for language and vision. Biolinguistics, 4(2-3):174\u2013200, 2010. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bever%2C%20Thomas%20G.%20Poeppel%2C%20David%20Analysis%20by%20synthesis%3A%20a%20%28re-%29%20emerging%20program%20of%20research%20for%20language%20and%20vision%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bever%2C%20Thomas%20G.%20Poeppel%2C%20David%20Analysis%20by%20synthesis%3A%20a%20%28re-%29%20emerging%20program%20of%20research%20for%20language%20and%20vision%202010"
        },
        {
            "id": "Blanz_1999_a",
            "entry": "Volker Blanz and Thomas Vetter. A morphable model for the synthesis of 3d faces. In SIGGRAPH, 1999. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blanz%2C%20Volker%20Vetter%2C%20Thomas%20A%20morphable%20model%20for%20the%20synthesis%20of%203d%20faces%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blanz%2C%20Volker%20Vetter%2C%20Thomas%20A%20morphable%20model%20for%20the%20synthesis%20of%203d%20faces%201999"
        },
        {
            "id": "Chang_et+al_2015_a",
            "entry": "Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao, Li Yi, and Fisher Yu. Shapenet: An information-rich 3d model repository. arXiv:1512.03012, 2015. 2, 3, 6",
            "arxiv_url": "https://arxiv.org/pdf/1512.03012"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In NIPS, 2016. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "Curless_1996_a",
            "entry": "Brian Curless and Marc Levoy. A volumetric method for building complex models from range images. In SIGGRAPH, 1996. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Curless%2C%20Brian%20Levoy%2C%20Marc%20A%20volumetric%20method%20for%20building%20complex%20models%20from%20range%20images%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Curless%2C%20Brian%20Levoy%2C%20Marc%20A%20volumetric%20method%20for%20building%20complex%20models%20from%20range%20images%201996"
        },
        {
            "id": "Dai_et+al_2017_a",
            "entry": "Angela Dai, Charles Ruizhongtai Qi, and Matthias Nie\u00dfner. Shape completion using 3d-encoder-predictor cnns and shape synthesis. In CVPR, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20Angela%20Qi%2C%20Charles%20Ruizhongtai%20Nie%C3%9Fner%2C%20Matthias%20Shape%20completion%20using%203d-encoder-predictor%20cnns%20and%20shape%20synthesis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20Angela%20Qi%2C%20Charles%20Ruizhongtai%20Nie%C3%9Fner%2C%20Matthias%20Shape%20completion%20using%203d-encoder-predictor%20cnns%20and%20shape%20synthesis%202017"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009. 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "Dosovitskiy_et+al_2015_a",
            "entry": "Alexey Dosovitskiy, Jost Tobias Springenberg, and Thomas Brox. Learning to generate chairs with convolutional neural networks. In CVPR, 2015. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dosovitskiy%2C%20Alexey%20Springenberg%2C%20Jost%20Tobias%20Brox%2C%20Thomas%20Learning%20to%20generate%20chairs%20with%20convolutional%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dosovitskiy%2C%20Alexey%20Springenberg%2C%20Jost%20Tobias%20Brox%2C%20Thomas%20Learning%20to%20generate%20chairs%20with%20convolutional%20neural%20networks%202015"
        },
        {
            "id": "Gadelha_et+al_2017_a",
            "entry": "Matheus Gadelha, Subhransu Maji, and Rui Wang. 3d shape induction from 2d views of multiple objects. In 3D Vision (3DV), pages 402\u2013411. IEEE, 2017a. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gadelha%2C%20Matheus%20Maji%2C%20Subhransu%20Wang%2C%20Rui%203d%20shape%20induction%20from%202d%20views%20of%20multiple%20objects%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gadelha%2C%20Matheus%20Maji%2C%20Subhransu%20Wang%2C%20Rui%203d%20shape%20induction%20from%202d%20views%20of%20multiple%20objects%202017"
        },
        {
            "id": "Gadelha_et+al_2017_b",
            "entry": "Matheus Gadelha, Subhransu Maji, and Rui Wang. Shape generation using spatially partitioned point clouds. In BMVC, 2017b. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gadelha%2C%20Matheus%20Maji%2C%20Subhransu%20Wang%2C%20Rui%20Shape%20generation%20using%20spatially%20partitioned%20point%20clouds%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gadelha%2C%20Matheus%20Maji%2C%20Subhransu%20Wang%2C%20Rui%20Shape%20generation%20using%20spatially%20partitioned%20point%20clouds%202017"
        },
        {
            "id": "Goodfellow_2016_a",
            "entry": "Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint arXiv:1701.00160, 2016. 4",
            "arxiv_url": "https://arxiv.org/pdf/1701.00160"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014. 2, 5, 6, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Improved training of wasserstein gans. In NIPS, 2017. 1, 2, 4, 6, 7, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2015. 6, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015"
        },
        {
            "id": "Heusel_et+al_1706_a",
            "entry": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, G\u00fcnter Klambauer, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a nash equilibrium. NIPS1706.08500, 2017. 7, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20Gans%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20nash%20equilibrium%201706"
        },
        {
            "id": "Huang_2017_a",
            "entry": "Xun Huang and Serge J Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. In ICCV, 2017. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Xun%20Belongie%2C%20Serge%20J.%20Arbitrary%20style%20transfer%20in%20real-time%20with%20adaptive%20instance%20normalization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Xun%20Belongie%2C%20Serge%20J.%20Arbitrary%20style%20transfer%20in%20real-time%20with%20adaptive%20instance%20normalization%202017"
        },
        {
            "id": "Huang_et+al_2018_a",
            "entry": "Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz. Multimodal unsupervised image-to-image translation. ECCV1804.04732, 2018. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Xun%20Liu%2C%20Ming-Yu%20Belongie%2C%20Serge%20Kautz%2C%20Jan%20Multimodal%20unsupervised%20image-to-image%20translation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Xun%20Liu%2C%20Ming-Yu%20Belongie%2C%20Serge%20Kautz%2C%20Jan%20Multimodal%20unsupervised%20image-to-image%20translation%202018"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "Isola_et+al_2016_a",
            "entry": "Phillip Isola, Daniel Zoran, Dilip Krishnan, and Edward H Adelson. Learning visual groups from co-occurrences in space and time. In ICLR Workshop, 2016. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zoran%2C%20Daniel%20Krishnan%2C%20Dilip%20Adelson%2C%20Edward%20H.%20Learning%20visual%20groups%20from%20co-occurrences%20in%20space%20and%20time%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zoran%2C%20Daniel%20Krishnan%2C%20Dilip%20Adelson%2C%20Edward%20H.%20Learning%20visual%20groups%20from%20co-occurrences%20in%20space%20and%20time%202016"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In CVPR, 2017. 2, 4, 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "Jaderberg_et+al_2015_a",
            "entry": "Max Jaderberg, Karen Simonyan, and Andrew Zisserman. Spatial transformer networks. In NIPS, 2015. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202015"
        },
        {
            "id": "Kajiya_1986_a",
            "entry": "James T Kajiya. The rendering equation. In SIGGRAPH, 1986. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kajiya%2C%20James%20T.%20The%20rendering%20equation%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kajiya%2C%20James%20T.%20The%20rendering%20equation%201986"
        },
        {
            "id": "Kanazawa_et+al_2018_a",
            "entry": "Angjoo Kanazawa, Shubham Tulsiani, Alexei A Efros, and Jitendra Malik. Learning category-specific mesh reconstruction from image collections. ECCV1803.07549, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kanazawa%2C%20Angjoo%20Tulsiani%2C%20Shubham%20Efros%2C%20Alexei%20A.%20Malik%2C%20Jitendra%20Learning%20category-specific%20mesh%20reconstruction%20from%20image%20collections%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kanazawa%2C%20Angjoo%20Tulsiani%2C%20Shubham%20Efros%2C%20Alexei%20A.%20Malik%2C%20Jitendra%20Learning%20category-specific%20mesh%20reconstruction%20from%20image%20collections%202018"
        },
        {
            "id": "Karras_et+al_2017_a",
            "entry": "Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. In ICLR, 2017. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20gans%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20gans%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202017"
        },
        {
            "id": "Karras_et+al_2018_a",
            "entry": "Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. ICLR, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20gans%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20gans%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "Kulkarni_et+al_2015_a",
            "entry": "Tejas D Kulkarni, Pushmeet Kohli, Joshua B Tenenbaum, and Vikash Mansinghka. Picture: A probabilistic programming language for scene perception. In CVPR, 2015a. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Mansinghka%2C%20Vikash%20Picture%3A%20A%20probabilistic%20programming%20language%20for%20scene%20perception%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Mansinghka%2C%20Vikash%20Picture%3A%20A%20probabilistic%20programming%20language%20for%20scene%20perception%202015"
        },
        {
            "id": "Kulkarni_et+al_2015_b",
            "entry": "Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Josh Tenenbaum. Deep convolutional inverse graphics network. In NIPS, 2015b. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015"
        },
        {
            "id": "Ledig_et+al_2017_a",
            "entry": "Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. Photo-realistic single image superresolution using a generative adversarial network. In CVPR, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20superresolution%20using%20a%20generative%20adversarial%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20superresolution%20using%20a%20generative%20adversarial%20network%202017"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised image-to-image translation networks. In NIPS, 2017. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "Lucic_et+al_2018_a",
            "entry": "Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier Bousquet. Are gans created equal? a large-scale study. NIPS, 2018. 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lucic%2C%20Mario%20Kurach%2C%20Karol%20Michalski%2C%20Marcin%20Gelly%2C%20Sylvain%20Are%20gans%20created%20equal%3F%20a%20large-scale%20study%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lucic%2C%20Mario%20Kurach%2C%20Karol%20Michalski%2C%20Marcin%20Gelly%2C%20Sylvain%20Are%20gans%20created%20equal%3F%20a%20large-scale%20study%202018"
        },
        {
            "id": "Mao_et+al_2017_a",
            "entry": "Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley. Least squares generative adversarial networks. In ICCV, 2017. 6, 7, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mao%2C%20Xudong%20Li%2C%20Qing%20Xie%2C%20Haoran%20Lau%2C%20Raymond%20Y.K.%20Least%20squares%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mao%2C%20Xudong%20Li%2C%20Qing%20Xie%2C%20Haoran%20Lau%2C%20Raymond%20Y.K.%20Least%20squares%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Marr_1982_a",
            "entry": "David Marr. Vision: A computational investigation into the human representation and processing of visual information, volume 2. W. H. Freeman and Company, 1982. 1, 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marr%2C%20David%20Vision%3A%20A%20computational%20investigation%20into%20the%20human%20representation%20and%20processing%20of%20visual%20information%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marr%2C%20David%20Vision%3A%20A%20computational%20investigation%20into%20the%20human%20representation%20and%20processing%20of%20visual%20information%201982"
        },
        {
            "id": "Mathieu_et+al_2016_a",
            "entry": "Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction beyond mean square error. In ICLR, 2016. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mathieu%2C%20Michael%20Couprie%2C%20Camille%20LeCun%2C%20Yann%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mathieu%2C%20Michael%20Couprie%2C%20Camille%20LeCun%2C%20Yann%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%202016"
        },
        {
            "id": "Pathak_et+al_2016_a",
            "entry": "Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Context encoders: Feature learning by inpainting. In CVPR, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016"
        },
        {
            "id": "Radford_et+al_2016_a",
            "entry": "Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. In ICLR, 2016. 2, 6, 7, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "Reed_et+al_2016_a",
            "entry": "Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. Generative adversarial text-to-image synthesis. In ICML, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Reed%2C%20Scott%20Akata%2C%20Zeynep%20Yan%2C%20Xinchen%20Logeswaran%2C%20Lajanugen%20Generative%20adversarial%20text-to-image%20synthesis%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Reed%2C%20Scott%20Akata%2C%20Zeynep%20Yan%2C%20Xinchen%20Logeswaran%2C%20Lajanugen%20Generative%20adversarial%20text-to-image%20synthesis%202016"
        },
        {
            "id": "Danilo_et+al_2016_a",
            "entry": "Danilo Jimenez Rezende, SM Eslami, Shakir Mohamed, Peter Battaglia, Max Jaderberg, and Nicolas Heess. Unsupervised learning of 3d structure from images. In NIPS, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Danilo%20Jimenez%20Rezende%2C%20S.M.Eslami%20Mohamed%2C%20Shakir%20Battaglia%2C%20Peter%20Jaderberg%2C%20Max%20Unsupervised%20learning%20of%203d%20structure%20from%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Danilo%20Jimenez%20Rezende%2C%20S.M.Eslami%20Mohamed%2C%20Shakir%20Battaglia%2C%20Peter%20Jaderberg%2C%20Max%20Unsupervised%20learning%20of%203d%20structure%20from%20images%202016"
        },
        {
            "id": "Shu_et+al_2017_a",
            "entry": "Zhixin Shu, Ersin Yumer, Sunil Hadap, Kalyan Sunkavalli, Eli Shechtman, and Dimitris Samaras. Neural face editing with intrinsic image disentangling. In CVPR, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shu%2C%20Zhixin%20Yumer%2C%20Ersin%20Hadap%2C%20Sunil%20Sunkavalli%2C%20Kalyan%20Neural%20face%20editing%20with%20intrinsic%20image%20disentangling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shu%2C%20Zhixin%20Yumer%2C%20Ersin%20Hadap%2C%20Sunil%20Sunkavalli%2C%20Kalyan%20Neural%20face%20editing%20with%20intrinsic%20image%20disentangling%202017"
        },
        {
            "id": "Sun_et+al_2018_a",
            "entry": "Xingyuan Sun, Jiajun Wu, Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Tianfan Xue, Joshua B Tenenbaum, and William T Freeman. Pix3d: Dataset and methods for single-image 3d shape modeling. In CVPR, 2018a. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Xingyuan%20Wu%2C%20Jiajun%20Zhang%2C%20Xiuming%20Zhang%2C%20Zhoutong%20Pix3d%3A%20Dataset%20and%20methods%20for%20single-image%203d%20shape%20modeling%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Xingyuan%20Wu%2C%20Jiajun%20Zhang%2C%20Xiuming%20Zhang%2C%20Zhoutong%20Pix3d%3A%20Dataset%20and%20methods%20for%20single-image%203d%20shape%20modeling%202018"
        },
        {
            "id": "Sun_et+al_2018_b",
            "entry": "Yongbin Sun, Ziwei Liu, Yue Wang, and Sanjay E Sarma. Im2avatar: Colorful 3d reconstruction from a single image. arXiv:1804.06375, 2018b. 2",
            "arxiv_url": "https://arxiv.org/pdf/1804.06375"
        },
        {
            "id": "Szegedy_et+al_2015_a",
            "entry": "Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In CVPR, 2015. 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "Tatarchenko_et+al_2016_a",
            "entry": "Maxim Tatarchenko, Alexey Dosovitskiy, and Thomas Brox. Multi-view 3d models from single images with a convolutional network. In ECCV, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tatarchenko%2C%20Maxim%20Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Multi-view%203d%20models%20from%20single%20images%20with%20a%20convolutional%20network%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tatarchenko%2C%20Maxim%20Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Multi-view%203d%20models%20from%20single%20images%20with%20a%20convolutional%20network%202016"
        },
        {
            "id": "Tatarchenko_et+al_2017_a",
            "entry": "Maxim Tatarchenko, Alexey Dosovitskiy, and Thomas Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3d outputs. In ICCV, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tatarchenko%2C%20Maxim%20Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Octree%20generating%20networks%3A%20Efficient%20convolutional%20architectures%20for%20high-resolution%203d%20outputs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tatarchenko%2C%20Maxim%20Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Octree%20generating%20networks%3A%20Efficient%20convolutional%20architectures%20for%20high-resolution%203d%20outputs%202017"
        },
        {
            "id": "Tulsiani_et+al_2017_a",
            "entry": "Shubham Tulsiani, Hao Su, Leonidas J Guibas, Alexei A Efros, and Jitendra Malik. Learning shape abstractions by assembling volumetric primitives. In CVPR, 2017. 2, 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20Shubham%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20J.%20Efros%2C%20Alexei%20A.%20Learning%20shape%20abstractions%20by%20assembling%20volumetric%20primitives%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20Shubham%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20J.%20Efros%2C%20Alexei%20A.%20Learning%20shape%20abstractions%20by%20assembling%20volumetric%20primitives%202017"
        },
        {
            "id": "Tung_et+al_2017_a",
            "entry": "Hsiao-Yu Fish Tung, Adam W Harley, William Seto, and Katerina Fragkiadaki. Adversarial inverse graphics networks: Learning 2d-to-3d lifting and image-to-image translation from unpaired supervision. In ICCV, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tung%2C%20Hsiao-Yu%20Fish%20Harley%2C%20Adam%20W.%20Seto%2C%20William%20Fragkiadaki%2C%20Katerina%20Adversarial%20inverse%20graphics%20networks%3A%20Learning%202d-to-3d%20lifting%20and%20image-to-image%20translation%20from%20unpaired%20supervision%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tung%2C%20Hsiao-Yu%20Fish%20Harley%2C%20Adam%20W.%20Seto%2C%20William%20Fragkiadaki%2C%20Katerina%20Adversarial%20inverse%20graphics%20networks%3A%20Learning%202d-to-3d%20lifting%20and%20image-to-image%20translation%20from%20unpaired%20supervision%202017"
        },
        {
            "id": "Ulyanov_et+al_2016_a",
            "entry": "Dmitry Ulyanov, Andrea Vedaldi, and Victor S. Lempitsky. Instance normalization: The missing ingredient for fast stylization. arXiv:1607.08022, 2016. 7",
            "arxiv_url": "https://arxiv.org/pdf/1607.08022"
        },
        {
            "id": "Wang_et+al_2018_a",
            "entry": "Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-resolution image synthesis and semantic manipulation with conditional gans. In CVPR, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Ting-Chun%20Liu%2C%20Ming-Yu%20Zhu%2C%20Jun-Yan%20Tao%2C%20Andrew%20High-resolution%20image%20synthesis%20and%20semantic%20manipulation%20with%20conditional%20gans%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Ting-Chun%20Liu%2C%20Ming-Yu%20Zhu%2C%20Jun-Yan%20Tao%2C%20Andrew%20High-resolution%20image%20synthesis%20and%20semantic%20manipulation%20with%20conditional%20gans%202018"
        },
        {
            "id": "Wang_et+al_2017_a",
            "entry": "Weiyue Wang, Qiangui Huang, Suya You, Chao Yang, and Ulrich Neumann. Shape inpainting using 3d generative adversarial network and recurrent convolutional networks. In ICCV, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Weiyue%20Huang%2C%20Qiangui%20You%2C%20Suya%20Yang%2C%20Chao%20Shape%20inpainting%20using%203d%20generative%20adversarial%20network%20and%20recurrent%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Weiyue%20Huang%2C%20Qiangui%20You%2C%20Suya%20Yang%2C%20Chao%20Shape%20inpainting%20using%203d%20generative%20adversarial%20network%20and%20recurrent%20convolutional%20networks%202017"
        },
        {
            "id": "Wu_et+al_2016_a",
            "entry": "Jiajun Wu, Chengkai Zhang, Tianfan Xue, William T Freeman, and Joshua B Tenenbaum. Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling. In NIPS, 2016. 2, 4, 6, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20William%20T.%20Learning%20a%20Probabilistic%20Latent%20Space%20of%20Object%20Shapes%20via%203D%20Generative-Adversarial%20Modeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20William%20T.%20Learning%20a%20Probabilistic%20Latent%20Space%20of%20Object%20Shapes%20via%203D%20Generative-Adversarial%20Modeling%202016"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, William T Freeman, and Joshua B Tenenbaum. MarrNet: 3D Shape Reconstruction via 2.5D Sketches. In NIPS, 2017. 3, 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Wang%2C%20Yifan%20Xue%2C%20Tianfan%20Sun%2C%20Xingyuan%20MarrNet%3A%203D%20Shape%20Reconstruction%20via%202.5D%20Sketches%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Wang%2C%20Yifan%20Xue%2C%20Tianfan%20Sun%2C%20Xingyuan%20MarrNet%3A%203D%20Shape%20Reconstruction%20via%202.5D%20Sketches%202017"
        },
        {
            "id": "Wu_et+al_2018_a",
            "entry": "Jiajun Wu, Chengkai Zhang, Xiuming Zhang, Zhoutong Zhang, William T Freeman, and Joshua B Tenenbaum. Learning 3d shape priors for shape completion and reconstruction. In ECCV, 2018. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Zhang%2C%20Xiuming%20Zhang%2C%20Zhoutong%20Learning%203d%20shape%20priors%20for%20shape%20completion%20and%20reconstruction%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Zhang%2C%20Xiuming%20Zhang%2C%20Zhoutong%20Learning%203d%20shape%20priors%20for%20shape%20completion%20and%20reconstruction%202018"
        },
        {
            "id": "Yang_et+al_2015_a",
            "entry": "Jimei Yang, Scott E Reed, Ming-Hsuan Yang, and Honglak Lee. Weakly-supervised disentangling with recurrent transformations for 3d view synthesis. In NIPS, 2015. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jimei%20Reed%2C%20Scott%20E.%20Yang%2C%20Ming-Hsuan%20Lee%2C%20Honglak%20Weakly-supervised%20disentangling%20with%20recurrent%20transformations%20for%203d%20view%20synthesis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jimei%20Reed%2C%20Scott%20E.%20Yang%2C%20Ming-Hsuan%20Lee%2C%20Honglak%20Weakly-supervised%20disentangling%20with%20recurrent%20transformations%20for%203d%20view%20synthesis%202015"
        },
        {
            "id": "Zili_2017_a",
            "entry": "Zili Yi, Hao (Richard) Zhang, Ping Tan, and Minglun Gong. Dualgan: Unsupervised dual learning for image-toimage translation. In ICCV, 2017. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zili%20Yi%2C%20Hao%20%28Richard%29%20Zhang%2C%20Ping%20Tan%20Gong%2C%20Minglun%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-toimage%20translation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zili%20Yi%2C%20Hao%20%28Richard%29%20Zhang%2C%20Ping%20Tan%20Gong%2C%20Minglun%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-toimage%20translation%202017"
        },
        {
            "id": "Yuille_2006_a",
            "entry": "Alan Yuille and Daniel Kersten. Vision as bayesian inference: analysis by synthesis? TiCS, 10(7):301\u2013308, 2006. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yuille%2C%20Alan%20Kersten%2C%20Daniel%20Vision%20as%20bayesian%20inference%3A%20analysis%20by%20synthesis%3F%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yuille%2C%20Alan%20Kersten%2C%20Daniel%20Vision%20as%20bayesian%20inference%3A%20analysis%20by%20synthesis%3F%202006"
        },
        {
            "id": "Zhang_et+al_2017_a",
            "entry": "Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In ICCV, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Han%20Xu%2C%20Tao%20Li%2C%20Hongsheng%20Shaoting%20Zhang%2C%20Xiaogang%20Wang%2C%20Xiaolei%20Huang%2C%20and%20Dimitris%20Metaxas.%20Stackgan%3A%20Text%20to%20photo-realistic%20image%20synthesis%20with%20stacked%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Han%20Xu%2C%20Tao%20Li%2C%20Hongsheng%20Shaoting%20Zhang%2C%20Xiaogang%20Wang%2C%20Xiaolei%20Huang%2C%20and%20Dimitris%20Metaxas.%20Stackgan%3A%20Text%20to%20photo-realistic%20image%20synthesis%20with%20stacked%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Zhang_et+al_2018_a",
            "entry": "Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Joshua B Tenenbaum, William T Freeman, and Jiajun Wu. Learning to reconstruct shapes from unseen categories. In NIPS, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Xiuming%20Zhang%2C%20Zhoutong%20Zhang%2C%20Chengkai%20Tenenbaum%2C%20Joshua%20B.%20Learning%20to%20reconstruct%20shapes%20from%20unseen%20categories%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Xiuming%20Zhang%2C%20Zhoutong%20Zhang%2C%20Chengkai%20Tenenbaum%2C%20Joshua%20B.%20Learning%20to%20reconstruct%20shapes%20from%20unseen%20categories%202018"
        },
        {
            "id": "Zhu_et+al_2016_a",
            "entry": "Jun-Yan Zhu, Philipp Kr\u00e4henb\u00fchl, Eli Shechtman, and Alexei A Efros. Generative visual manipulation on the natural image manifold. In ECCV, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Shechtman%2C%20Eli%20and%20Alexei%20A%20Efros.%20Generative%20visual%20manipulation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Shechtman%2C%20Eli%20and%20Alexei%20A%20Efros.%20Generative%20visual%20manipulation%202016"
        },
        {
            "id": "Zhu_et+al_2017_a",
            "entry": "Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In ICCV, 2017a. 2, 4, 5, 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20and%20Alexei%20A%20Efros.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20and%20Alexei%20A%20Efros.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017"
        },
        {
            "id": "Zhu_et+al_2017_b",
            "entry": "Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang, and Eli Shechtman. Toward multimodal image-to-image translation. In NIPS, 2017b. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Zhang%2C%20Richard%20Pathak%2C%20Deepak%20Darrell%2C%20Trevor%20Alexei%20A%20Efros%2C%20Oliver%20Wang%2C%20and%20Eli%20Shechtman.%20Toward%20multimodal%20image-to-image%20translation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Zhang%2C%20Richard%20Pathak%2C%20Deepak%20Darrell%2C%20Trevor%20Alexei%20A%20Efros%2C%20Oliver%20Wang%2C%20and%20Eli%20Shechtman.%20Toward%20multimodal%20image-to-image%20translation%202017"
        }
    ]
}
