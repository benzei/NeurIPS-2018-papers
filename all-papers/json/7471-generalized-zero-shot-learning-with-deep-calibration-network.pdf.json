{
    "filename": "7471-generalized-zero-shot-learning-with-deep-calibration-network.pdf",
    "metadata": {
        "title": "Generalized Zero-Shot Learning with Deep Calibration Network",
        "author": "Shichen Liu, Mingsheng Long, Jianmin Wang, Michael I. Jordan",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7471-generalized-zero-shot-learning-with-deep-calibration-network.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "A technical challenge of deep learning is recognizing target classes without seen data. Zero-shot learning leverages semantic representations such as attributes or class prototypes to bridge source and target classes. Existing standard zero-shot learning methods may be prone to overfitting the seen data of source classes as they are blind to the semantic representations of target classes. In this paper, we study generalized zero-shot learning that assumes accessible to target classes for unseen data during training, and prediction on unseen data is made by searching on both source and target classes. We propose a novel Deep Calibration Network (DCN) approach towards this generalized zero-shot learning paradigm, which enables simultaneous calibration of deep networks on the confidence of source classes and uncertainty of target classes. Our approach maps visual features of images and semantic representations of class prototypes to a common embedding space such that the compatibility of seen data to both source and target classes are maximized. We show superior accuracy of our approach over the state of the art on benchmark datasets for generalized zero-shot learning, including AwA, CUB, SUN, and aPY."
    },
    "keywords": [
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "deep network",
            "url": "https://en.wikipedia.org/wiki/deep_network"
        },
        {
            "term": "object recognition",
            "url": "https://en.wikipedia.org/wiki/object_recognition"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "nearest prototype classifier",
            "url": "https://en.wikipedia.org/wiki/nearest_prototype_classifier"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        }
    ],
    "highlights": [
        "Remarkable advances in object recognition has been achieved in recent years with the prosperity of deep convolutional neural networks [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c46\" href=\"#r46\">46</a>, <a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>]",
        "Towards the above technical difficulty of generalized zero-shot learning, we propose a novel Deep Calibration Network (DCN) approach that enables simultaneous calibration of deep networks on the confidence of source classes and the uncertainty of target classes",
        "We use the same models trained on zero-shot learning setting on the Proposed Splits (PS) [<a class=\"ref-link\" id=\"c53\" href=\"#r53\">53</a>]",
        "We evaluate our models on the generalized zero-shot learning setting, by evaluating performance on both source and target classes",
        "This paper proposed a deep calibration network towards generalized zero-shot learning",
        "Experiments show that our approach yield state of the art performance for generalized zero-shot learning tasks on four benchmark datasets"
    ],
    "key_statements": [
        "Remarkable advances in object recognition has been achieved in recent years with the prosperity of deep convolutional neural networks [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c46\" href=\"#r46\">46</a>, <a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>]",
        "Towards the above technical difficulty of generalized zero-shot learning, we propose a novel Deep Calibration Network (DCN) approach that enables simultaneous calibration of deep networks on the confidence of source classes and the uncertainty of target classes",
        "We propose an end-to-end deep architecture comprised of deep convolutional neural networks (CNN) and multilayer perceptrons (MLP) with new loss functions to enable end-to-end training by back-propagation, with which we map visual features of images and semantic representations of class prototypes to a common embedding space such that the compatibility of seen data to the target classes are maximized",
        "We enable generalized zero-shot learning by making our model unblind to target classes",
        "Model variants We further study two variants of the proposed deep calibration network approach to justify the efficacy of the entropy and temperature calibration strategies respectively: (i) deep calibration network w/o E is the variant of deep calibration network without entropy calibration, i.e. setting \u03bb = 0 in Equation (9). deep calibration network w/o ET is the variant of deep calibration network without entropy and temperature calibrations, i.e. setting \u03bb = 0 and \u03c4 = 1 in Equation (9)",
        "We report the average per-image classification accuracy based on five random experiments, where the accuracy is computed over the images in target classes",
        "A new Rigorous Protocol is proposed for three reasons: (a) The image features are ImageNet pretrained ResNet-101 features, which have higher accuracy than GoogLeNet features, yielding more stable comparison across different methods; (b) The Proposed Split (PS) guarantee that no target classes are from ImageNet-1K since it is used to pre-train the base network, otherwise unfairness would be introduced; (c) The zero-shot performance is evaluated based on per-class classification accuracy Eq (10), which accounts for the imbalances in the target classes",
        "Whether an image is from a source or target class is unknown in advance",
        "We use the same models trained on zero-shot learning setting on the Proposed Splits (PS) [<a class=\"ref-link\" id=\"c53\" href=\"#r53\">53</a>]",
        "We evaluate our models on the generalized zero-shot learning setting, by evaluating performance on both source and target classes",
        "This paper proposed a deep calibration network towards generalized zero-shot learning",
        "Experiments show that our approach yield state of the art performance for generalized zero-shot learning tasks on four benchmark datasets"
    ],
    "summary": [
        "Remarkable advances in object recognition has been achieved in recent years with the prosperity of deep convolutional neural networks [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c46\" href=\"#r46\">46</a>, <a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>].",
        "Generalized zero-shot learning where prediction on unseen data is made over both source and target classes, has drawn attention very recently [<a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>, <a class=\"ref-link\" id=\"c53\" href=\"#r53\">53</a>].",
        "Existing standard zero-shot learning methods may be prone to overfitting the seen data of source classes as they are blind to the semantic representations of target classes.",
        "Where prediction is made over both source and target classes as c \u2208 S \u222a T in generalized zero-shot learning.",
        "Despite the higher accuracy of high-capacity deep models on many tasks, overfitting to the seen data of source classes may hurt transfer to target classes for generalized zero-shot learning.",
        "As common practice of standard zero-shot learning, we can apply the trained model fc in Eq (3) to classify the unseen data over only target classes T .",
        "In generalized zero-shot learning, things become more difficult as we have to make predictions over both source and target classes S \u222a T .",
        "A new Rigorous Protocol is proposed for three reasons: (a) The image features are ImageNet pretrained ResNet-101 features, which have higher accuracy than GoogLeNet features, yielding more stable comparison across different methods; (b) The Proposed Split (PS) guarantee that no target classes are from ImageNet-1K since it is used to pre-train the base network, otherwise unfairness would be introduced; (c) The zero-shot performance is evaluated based on per-class classification accuracy Eq (10), which accounts for the imbalances in the target classes.",
        "At the test phase of generalized zero-shot learning, the search space includes both source and target classes C = S \u2229 T , a more practical but challenging setting.",
        "This validates the effectiveness of temperature calibration for mitigating the deep networks from overfitting the seen data of source classes and improving the zero-shot generalization capability.",
        "Result Analysis We show in Figure 3 the histograms of probabilities output by our deep models with (\u03c4 = 0.3) or without (\u03c4 = 1) temperature calibration on AwA test data from the 10 target classes.",
        "We evaluate our models on the generalized zero-shot learning setting, by evaluating performance on both source and target classes.",
        "The approach enables simultaneous calibration of deep networks on the confidence of source classes and uncertainty of target classes, and as a consequence, bridges the source and target classes through both semantic representations of classes and visual embeddings of seen images.",
        "Experiments show that our approach yield state of the art performance for generalized zero-shot learning tasks on four benchmark datasets"
    ],
    "headline": "We study generalized zero-shot learning that assumes accessible to target classes for unseen data during training, and prediction on unseen data is made by searching on both source and target classes",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Z. Akata, F. Perronnin, Z. Harchaoui, and C. Schmid. Label-embedding for attribute-based classification. In CVPR, pages 819\u2013826, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Akata%2C%20Z.%20Perronnin%2C%20F.%20Harchaoui%2C%20Z.%20Schmid%2C%20C.%20Label-embedding%20for%20attribute-based%20classification%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Akata%2C%20Z.%20Perronnin%2C%20F.%20Harchaoui%2C%20Z.%20Schmid%2C%20C.%20Label-embedding%20for%20attribute-based%20classification%202013"
        },
        {
            "id": "2",
            "entry": "[2] Z. Akata, F. Perronnin, Z. Harchaoui, and C. Schmid. Label-embedding for image classification. IEEE TPAMI, 38(7):1425\u20131438, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Akata%2C%20Z.%20Perronnin%2C%20F.%20Harchaoui%2C%20Z.%20Schmid%2C%20C.%20Label-embedding%20for%20image%20classification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Akata%2C%20Z.%20Perronnin%2C%20F.%20Harchaoui%2C%20Z.%20Schmid%2C%20C.%20Label-embedding%20for%20image%20classification%202016"
        },
        {
            "id": "3",
            "entry": "[3] Z. Akata, S. Reed, D. Walter, H. Lee, and B. Schiele. Evaluation of output embeddings for fine-grained image classification. In CVPR, pages 2927\u20132936, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Akata%2C%20Z.%20Reed%2C%20S.%20Walter%2C%20D.%20Lee%2C%20H.%20Evaluation%20of%20output%20embeddings%20for%20fine-grained%20image%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Akata%2C%20Z.%20Reed%2C%20S.%20Walter%2C%20D.%20Lee%2C%20H.%20Evaluation%20of%20output%20embeddings%20for%20fine-grained%20image%20classification%202015"
        },
        {
            "id": "4",
            "entry": "[4] Z. Al-Halah and R. Stiefelhagen. How to transfer? zero-shot object recognition via hierarchical transfer of semantic attributes. In WACV, pages 837\u2013843, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Al-Halah%2C%20Z.%20Stiefelhagen%2C%20R.%20How%20to%20transfer%3F%20zero-shot%20object%20recognition%20via%20hierarchical%20transfer%20of%20semantic%20attributes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Al-Halah%2C%20Z.%20Stiefelhagen%2C%20R.%20How%20to%20transfer%3F%20zero-shot%20object%20recognition%20via%20hierarchical%20transfer%20of%20semantic%20attributes%202015"
        },
        {
            "id": "5",
            "entry": "[5] Y. Atzmon and G. Chechik. Probabilistic AND-OR attribute grouping for zero-shot learning. In UAI, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Atzmon%2C%20Y.%20Chechik%2C%20G.%20Probabilistic%20AND-OR%20attribute%20grouping%20for%20zero-shot%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Atzmon%2C%20Y.%20Chechik%2C%20G.%20Probabilistic%20AND-OR%20attribute%20grouping%20for%20zero-shot%20learning%202018"
        },
        {
            "id": "6",
            "entry": "[6] L. J. Ba, K. Swersky, S. Fidler, and R. Salakhutdinov. Predicting deep zero-shot convolutional neural networks using textual descriptions. In ICCV, pages 4247\u20134255, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ba%2C%20L.J.%20Swersky%2C%20K.%20Fidler%2C%20S.%20Salakhutdinov%2C%20R.%20Predicting%20deep%20zero-shot%20convolutional%20neural%20networks%20using%20textual%20descriptions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ba%2C%20L.J.%20Swersky%2C%20K.%20Fidler%2C%20S.%20Salakhutdinov%2C%20R.%20Predicting%20deep%20zero-shot%20convolutional%20neural%20networks%20using%20textual%20descriptions%202015"
        },
        {
            "id": "7",
            "entry": "[7] Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE TPAMI, 35(8):1798\u20131828, Aug 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Y.%20Courville%2C%20A.%20Vincent%2C%20P.%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Y.%20Courville%2C%20A.%20Vincent%2C%20P.%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013-08"
        },
        {
            "id": "8",
            "entry": "[8] S. Changpinyo, W.-L. Chao, B. Gong, and F. Sha. Synthesized classifiers for zero-shot learning. In CVPR, pages 5327\u20135336, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Changpinyo%2C%20S.%20Chao%2C%20W.-L.%20Gong%2C%20B.%20Sha%2C%20F.%20Synthesized%20classifiers%20for%20zero-shot%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Changpinyo%2C%20S.%20Chao%2C%20W.-L.%20Gong%2C%20B.%20Sha%2C%20F.%20Synthesized%20classifiers%20for%20zero-shot%20learning%202016"
        },
        {
            "id": "9",
            "entry": "[9] S. Changpinyo, W.-L. Chao, and F. Sha. Predicting visual exemplars of unseen classes for zero-shot learning. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Changpinyo%2C%20S.%20Chao%2C%20W.-L.%20Sha%2C%20F.%20Predicting%20visual%20exemplars%20of%20unseen%20classes%20for%20zero-shot%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Changpinyo%2C%20S.%20Chao%2C%20W.-L.%20Sha%2C%20F.%20Predicting%20visual%20exemplars%20of%20unseen%20classes%20for%20zero-shot%20learning%202017"
        },
        {
            "id": "10",
            "entry": "[10] W.-L. Chao, S. Changpinyo, B. Gong, and F. Sha. An empirical study and analysis of generalized zero-shot learning for object recognition in the wild. In ECCV, pages 52\u201368, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chao%2C%20W.-L.%20Changpinyo%2C%20S.%20Gong%2C%20B.%20Sha%2C%20F.%20An%20empirical%20study%20and%20analysis%20of%20generalized%20zero-shot%20learning%20for%20object%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chao%2C%20W.-L.%20Changpinyo%2C%20S.%20Gong%2C%20B.%20Sha%2C%20F.%20An%20empirical%20study%20and%20analysis%20of%20generalized%20zero-shot%20learning%20for%20object%20recognition%202016"
        },
        {
            "id": "11",
            "entry": "[11] M. Elhoseiny, B. Saleh, and A. Elgammal. Write a classifier: Zero-shot learning using purely textual descriptions. In ICCV, pages 2584\u20132591, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Elhoseiny%2C%20M.%20Saleh%2C%20B.%20Elgammal%2C%20A.%20Write%20a%20classifier%3A%20Zero-shot%20learning%20using%20purely%20textual%20descriptions%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Elhoseiny%2C%20M.%20Saleh%2C%20B.%20Elgammal%2C%20A.%20Write%20a%20classifier%3A%20Zero-shot%20learning%20using%20purely%20textual%20descriptions%202013"
        },
        {
            "id": "12",
            "entry": "[12] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, pages 1778\u20131785, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Farhadi%2C%20A.%20Endres%2C%20I.%20Hoiem%2C%20D.%20Forsyth%2C%20D.%20Describing%20objects%20by%20their%20attributes%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Farhadi%2C%20A.%20Endres%2C%20I.%20Hoiem%2C%20D.%20Forsyth%2C%20D.%20Describing%20objects%20by%20their%20attributes%202009"
        },
        {
            "id": "13",
            "entry": "[13] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, pages",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Farhadi%2C%20A.%20Endres%2C%20I.%20Hoiem%2C%20D.%20Forsyth%2C%20D.%20Describing%20objects%20by%20their%20attributes",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Farhadi%2C%20A.%20Endres%2C%20I.%20Hoiem%2C%20D.%20Forsyth%2C%20D.%20Describing%20objects%20by%20their%20attributes"
        },
        {
            "id": "14",
            "entry": "[14] L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. IEEE TPAMI, 28(4):594\u2013611, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fei-Fei%2C%20L.%20Fergus%2C%20R.%20Perona%2C%20P.%20One-shot%20learning%20of%20object%20categories%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fei-Fei%2C%20L.%20Fergus%2C%20R.%20Perona%2C%20P.%20One-shot%20learning%20of%20object%20categories%202006"
        },
        {
            "id": "15",
            "entry": "[15] A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, and T. Mikolov. Devise: A deep visual-semantic embedding model. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, NIPS, pages 2121\u20132129. 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Frome%2C%20A.%20Corrado%2C%20G.S.%20Shlens%2C%20J.%20Bengio%2C%20S.%20Devise%3A%20A%20deep%20visual-semantic%20embedding%20model%202013"
        },
        {
            "id": "16",
            "entry": "[16] Y. Fu, T. M. Hospedales, T. Xiang, and S. Gong. Learning multimodal latent attributes. IEEE TPAMI, 36(2):303\u2013316, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fu%2C%20Y.%20Hospedales%2C%20T.M.%20Xiang%2C%20T.%20Gong%2C%20S.%20Learning%20multimodal%20latent%20attributes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fu%2C%20Y.%20Hospedales%2C%20T.M.%20Xiang%2C%20T.%20Gong%2C%20S.%20Learning%20multimodal%20latent%20attributes%202014"
        },
        {
            "id": "17",
            "entry": "[17] Y. Fu, T. M. Hospedales, T. Xiang, and S. Gong. Transductive multi-view zero-shot learning. IEEE TPAMI, 37(11):2332\u20132345, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fu%2C%20Y.%20Hospedales%2C%20T.M.%20Xiang%2C%20T.%20Gong%2C%20S.%20Transductive%20multi-view%20zero-shot%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fu%2C%20Y.%20Hospedales%2C%20T.M.%20Xiang%2C%20T.%20Gong%2C%20S.%20Transductive%20multi-view%20zero-shot%20learning%202015"
        },
        {
            "id": "18",
            "entry": "[18] Y. Fu, T. M. Hospedales, T. Xiang, and S. Gong. Transductive multi-view zero-shot learning. IEEE TPAMI, 37(11):2332\u20132345, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fu%2C%20Y.%20Hospedales%2C%20T.M.%20Xiang%2C%20T.%20Gong%2C%20S.%20Transductive%20multi-view%20zero-shot%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fu%2C%20Y.%20Hospedales%2C%20T.M.%20Xiang%2C%20T.%20Gong%2C%20S.%20Transductive%20multi-view%20zero-shot%20learning%202015"
        },
        {
            "id": "19",
            "entry": "[19] Y. Fu and L. Sigal. Semi-supervised vocabulary-informed learning. In CVPR, pages 5337\u20135346, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fu%2C%20Y.%20Sigal%2C%20L.%20Semi-supervised%20vocabulary-informed%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fu%2C%20Y.%20Sigal%2C%20L.%20Semi-supervised%20vocabulary-informed%20learning%202016"
        },
        {
            "id": "20",
            "entry": "[20] Z. Fu, T. Xiang, E. Kodirov, and S. Gong. Zero-shot object recognition by semantic manifold distance. In CVPR, pages 2635\u20132644, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fu%2C%20Z.%20Xiang%2C%20T.%20Kodirov%2C%20E.%20Gong%2C%20S.%20Zero-shot%20object%20recognition%20by%20semantic%20manifold%20distance%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fu%2C%20Z.%20Xiang%2C%20T.%20Kodirov%2C%20E.%20Gong%2C%20S.%20Zero-shot%20object%20recognition%20by%20semantic%20manifold%20distance%202015"
        },
        {
            "id": "21",
            "entry": "[21] E. Gavves, T. Mensink, T. Tommasi, C. G. Snoek, and T. Tuytelaars. Active transfer learning with zero-shot priors: Reusing past datasets for future tasks. In ICCV, pages 2731\u20132739, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gavves%2C%20E.%20Mensink%2C%20T.%20Tommasi%2C%20T.%20Snoek%2C%20C.G.%20Active%20transfer%20learning%20with%20zero-shot%20priors%3A%20Reusing%20past%20datasets%20for%20future%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gavves%2C%20E.%20Mensink%2C%20T.%20Tommasi%2C%20T.%20Snoek%2C%20C.G.%20Active%20transfer%20learning%20with%20zero-shot%20priors%3A%20Reusing%20past%20datasets%20for%20future%20tasks%202015"
        },
        {
            "id": "22",
            "entry": "[22] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "23",
            "entry": "[23] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20C.%20Pleiss%2C%20G.%20Sun%2C%20Y.%20Weinberger%2C%20K.Q.%20On%20calibration%20of%20modern%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20C.%20Pleiss%2C%20G.%20Sun%2C%20Y.%20Weinberger%2C%20K.Q.%20On%20calibration%20of%20modern%20neural%20networks%202017"
        },
        {
            "id": "24",
            "entry": "[24] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "25",
            "entry": "[25] G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.02531"
        },
        {
            "id": "26",
            "entry": "[26] D. P. Kingma and M. Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "27",
            "entry": "[27] E. Kodirov, T. Xiang, Z. Fu, and S. Gong. Unsupervised domain adaptation for zero-shot learning. In ICCV, pages 2452\u20132460, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kodirov%2C%20E.%20Xiang%2C%20T.%20Fu%2C%20Z.%20Gong%2C%20S.%20Unsupervised%20domain%20adaptation%20for%20zero-shot%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kodirov%2C%20E.%20Xiang%2C%20T.%20Fu%2C%20Z.%20Gong%2C%20S.%20Unsupervised%20domain%20adaptation%20for%20zero-shot%20learning%202015"
        },
        {
            "id": "28",
            "entry": "[28] E. Kodirov, T. Xiang, and S. Gong. Semantic autoencoder for zero-shot learning. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kodirov%2C%20E.%20Xiang%2C%20T.%20Gong%2C%20S.%20Semantic%20autoencoder%20for%20zero-shot%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kodirov%2C%20E.%20Xiang%2C%20T.%20Gong%2C%20S.%20Semantic%20autoencoder%20for%20zero-shot%20learning%202017"
        },
        {
            "id": "29",
            "entry": "[29] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "30",
            "entry": "[30] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Attribute and simile classifiers for face verification. In ICCV, pages 365\u2013372, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20N.%20Berg%2C%20A.C.%20Belhumeur%2C%20P.N.%20Nayar%2C%20S.K.%20Attribute%20and%20simile%20classifiers%20for%20face%20verification%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20N.%20Berg%2C%20A.C.%20Belhumeur%2C%20P.N.%20Nayar%2C%20S.K.%20Attribute%20and%20simile%20classifiers%20for%20face%20verification%202009"
        },
        {
            "id": "31",
            "entry": "[31] V. Kumar Verma, G. Arora, A. Mishra, and P. Rai. Generalized zero-shot learning via synthesized examples. In CVPR, June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Verma%2C%20V.Kumar%20Arora%2C%20G.%20Mishra%2C%20A.%20Rai%2C%20P.%20Generalized%20zero-shot%20learning%20via%20synthesized%20examples%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Verma%2C%20V.Kumar%20Arora%2C%20G.%20Mishra%2C%20A.%20Rai%2C%20P.%20Generalized%20zero-shot%20learning%20via%20synthesized%20examples%202018-06"
        },
        {
            "id": "32",
            "entry": "[32] C. H. Lampert, H. Nickisch, and S. Harmeling. Attribute-based classification for zero-shot visual object categorization. IEEE TPAMI, 36(3):453\u2013465, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lampert%2C%20C.H.%20Nickisch%2C%20H.%20Harmeling%2C%20S.%20Attribute-based%20classification%20for%20zero-shot%20visual%20object%20categorization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lampert%2C%20C.H.%20Nickisch%2C%20H.%20Harmeling%2C%20S.%20Attribute-based%20classification%20for%20zero-shot%20visual%20object%20categorization%202014"
        },
        {
            "id": "33",
            "entry": "[33] Z. Li, E. Gavves, T. Mensink, and C. G. Snoek. Attributes make sense on segmented objects. In ECCV, pages 350\u2013365, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Z.%20Gavves%2C%20E.%20Mensink%2C%20T.%20Snoek%2C%20C.G.%20Attributes%20make%20sense%20on%20segmented%20objects%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Z.%20Gavves%2C%20E.%20Mensink%2C%20T.%20Snoek%2C%20C.G.%20Attributes%20make%20sense%20on%20segmented%20objects%202014"
        },
        {
            "id": "34",
            "entry": "[34] T. Mensink, E. Gavves, and C. G. Snoek. Costa: Co-occurrence statistics for zero-shot classification. In CVPR, pages 2441\u20132448, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mensink%2C%20T.%20Gavves%2C%20E.%20Snoek%2C%20C.G.%20Costa%3A%20Co-occurrence%20statistics%20for%20zero-shot%20classification%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mensink%2C%20T.%20Gavves%2C%20E.%20Snoek%2C%20C.G.%20Costa%3A%20Co-occurrence%20statistics%20for%20zero-shot%20classification%202014"
        },
        {
            "id": "35",
            "entry": "[35] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word representations in vector space. CoRR, abs/1301.3781, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1301.3781"
        },
        {
            "id": "36",
            "entry": "[36] M. Norouzi, T. Mikolov, S. Bengio, Y. Singer, J. Shlens, A. Frome, G. S. Corrado, and J. Dean. Zero-shot learning by convex combination of semantic embeddings. arXiv preprint arXiv:1312.5650, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.5650"
        },
        {
            "id": "37",
            "entry": "[37] M. Palatucci, D. Pomerleau, G. E. Hinton, and T. M. Mitchell. Zero-shot learning with semantic output codes. In NIPS, pages 1410\u20131418, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Palatucci%2C%20M.%20Pomerleau%2C%20D.%20Hinton%2C%20G.E.%20Mitchell%2C%20T.M.%20Zero-shot%20learning%20with%20semantic%20output%20codes%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Palatucci%2C%20M.%20Pomerleau%2C%20D.%20Hinton%2C%20G.E.%20Mitchell%2C%20T.M.%20Zero-shot%20learning%20with%20semantic%20output%20codes%202009"
        },
        {
            "id": "38",
            "entry": "[38] D. Parikh and K. Grauman. Relative attributes. In ICCV, pages 503\u2013510, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parikh%2C%20D.%20Grauman%2C%20K.%20Relative%20attributes%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parikh%2C%20D.%20Grauman%2C%20K.%20Relative%20attributes%202011"
        },
        {
            "id": "39",
            "entry": "[39] G. Patterson and J. Hays. Sun attribute database: Discovering, annotating, and recognizing scene attributes. In CVPR, pages 2751\u20132758, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Patterson%2C%20G.%20Hays%2C%20J.%20Sun%20attribute%20database%3A%20Discovering%2C%20annotating%2C%20and%20recognizing%20scene%20attributes%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Patterson%2C%20G.%20Hays%2C%20J.%20Sun%20attribute%20database%3A%20Discovering%2C%20annotating%2C%20and%20recognizing%20scene%20attributes%202012"
        },
        {
            "id": "40",
            "entry": "[40] M. Rohrbach, M. Stark, and B. Schiele. Evaluating knowledge transfer and zero-shot learning in a large-scale setting. In CVPR, pages 1641\u20131648, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rohrbach%2C%20M.%20Stark%2C%20M.%20Schiele%2C%20B.%20Evaluating%20knowledge%20transfer%20and%20zero-shot%20learning%20in%20a%20large-scale%20setting%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rohrbach%2C%20M.%20Stark%2C%20M.%20Schiele%2C%20B.%20Evaluating%20knowledge%20transfer%20and%20zero-shot%20learning%20in%20a%20large-scale%20setting%202011"
        },
        {
            "id": "41",
            "entry": "[41] M. Rohrbach, M. Stark, G. Szarvas, I. Gurevych, and B. Schiele. What helps where\u2013and why? semantic relatedness for knowledge transfer. In CVPR, pages 910\u2013917, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rohrbach%2C%20M.%20Stark%2C%20M.%20Szarvas%2C%20G.%20Gurevych%2C%20I.%20What%20helps%20where%E2%80%93and%20why%3F%20semantic%20relatedness%20for%20knowledge%20transfer%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rohrbach%2C%20M.%20Stark%2C%20M.%20Szarvas%2C%20G.%20Gurevych%2C%20I.%20What%20helps%20where%E2%80%93and%20why%3F%20semantic%20relatedness%20for%20knowledge%20transfer%202010"
        },
        {
            "id": "42",
            "entry": "[42] B. Romera-Paredes and P. H. Torr. An embarrassingly simple approach to zero-shot learning. In ICML, pages 2152\u20132161, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Romera-Paredes%2C%20B.%20Torr%2C%20P.H.%20An%20embarrassingly%20simple%20approach%20to%20zero-shot%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Romera-Paredes%2C%20B.%20Torr%2C%20P.H.%20An%20embarrassingly%20simple%20approach%20to%20zero-shot%20learning%202015"
        },
        {
            "id": "43",
            "entry": "[43] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1. chapter Learning Internal Representations by Error Propagation. MIT Press, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rumelhart%2C%20D.E.%20Hinton%2C%20G.E.%20Williams%2C%20R.J.%20Parallel%20distributed%20processing%3A%20Explorations%20in%20the%20microstructure%20of%20cognition%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rumelhart%2C%20D.E.%20Hinton%2C%20G.E.%20Williams%2C%20R.J.%20Parallel%20distributed%20processing%3A%20Explorations%20in%20the%20microstructure%20of%20cognition%201986"
        },
        {
            "id": "44",
            "entry": "[44] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. IJCV, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20ImageNet%20Large%20Scale%20Visual%20Recognition%20Challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20ImageNet%20Large%20Scale%20Visual%20Recognition%20Challenge%202015"
        },
        {
            "id": "45",
            "entry": "[45] W. J. Scheirer, A. de Rezende Rocha, A. Sapkota, and T. E. Boult. Toward open set recognition. IEEE TPAMI, 35(7):1757\u20131772, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scheirer%2C%20W.J.%20de%20Rezende%20Rocha%2C%20A.%20Sapkota%2C%20A.%20Boult%2C%20T.E.%20Toward%20open%20set%20recognition%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scheirer%2C%20W.J.%20de%20Rezende%20Rocha%2C%20A.%20Sapkota%2C%20A.%20Boult%2C%20T.E.%20Toward%20open%20set%20recognition%202013"
        },
        {
            "id": "46",
            "entry": "[46] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "47",
            "entry": "[47] R. Socher, M. Ganjoo, C. D. Manning, and A. Ng. Zero-shot learning through cross-modal transfer. In NIPS, pages 935\u2013943, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Socher%2C%20R.%20Ganjoo%2C%20M.%20Manning%2C%20C.D.%20Ng%2C%20A.%20Zero-shot%20learning%20through%20cross-modal%20transfer%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Socher%2C%20R.%20Ganjoo%2C%20M.%20Manning%2C%20C.D.%20Ng%2C%20A.%20Zero-shot%20learning%20through%20cross-modal%20transfer%202013"
        },
        {
            "id": "48",
            "entry": "[48] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Liu%2C%20W.%20Jia%2C%20Y.%20Sermanet%2C%20P.%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20C.%20Liu%2C%20W.%20Jia%2C%20Y.%20Sermanet%2C%20P.%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "49",
            "entry": "[49] Y. H. Tsai, L. Huang, and R. Salakhutdinov. Learning robust visual-semantic embeddings. In ICCV, pages 3591\u20133600, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsai%2C%20Y.H.%20Huang%2C%20L.%20Salakhutdinov%2C%20R.%20Learning%20robust%20visual-semantic%20embeddings%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsai%2C%20Y.H.%20Huang%2C%20L.%20Salakhutdinov%2C%20R.%20Learning%20robust%20visual-semantic%20embeddings%202017"
        },
        {
            "id": "50",
            "entry": "[50] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The caltech-ucsd birds-200-2011 dataset. 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wah%2C%20C.%20Branson%2C%20S.%20Welinder%2C%20P.%20Perona%2C%20P.%20The%20caltech-ucsd%20birds-200-2011%202011"
        },
        {
            "id": "51",
            "entry": "[51] X. Wang and Q. Ji. A unified probabilistic approach modeling relationships between attributes and objects. In ICCV, pages 2120\u20132127, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20X.%20Ji%2C%20Q.%20A%20unified%20probabilistic%20approach%20modeling%20relationships%20between%20attributes%20and%20objects%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20X.%20Ji%2C%20Q.%20A%20unified%20probabilistic%20approach%20modeling%20relationships%20between%20attributes%20and%20objects%202013"
        },
        {
            "id": "52",
            "entry": "[52] Z. Wu, Y. Fu, Y.-G. Jiang, and L. Sigal. Harnessing object and scene semantics for large-scale video understanding. In CVPR, pages 3112\u20133121, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Z.%20Fu%2C%20Y.%20Jiang%2C%20Y.-G.%20Sigal%2C%20L.%20Harnessing%20object%20and%20scene%20semantics%20for%20large-scale%20video%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Z.%20Fu%2C%20Y.%20Jiang%2C%20Y.-G.%20Sigal%2C%20L.%20Harnessing%20object%20and%20scene%20semantics%20for%20large-scale%20video%20understanding%202016"
        },
        {
            "id": "53",
            "entry": "[53] Y. Xian, B. Schiele, and Z. Akata. Zero-shot learning - the good, the bad and the ugly. In CVPR, July 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xian%2C%20Y.%20Schiele%2C%20B.%20Akata%2C%20Z.%20Zero-shot%20learning%20-%20the%20good%2C%20the%20bad%20and%20the%20ugly%202017-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xian%2C%20Y.%20Schiele%2C%20B.%20Akata%2C%20Z.%20Zero-shot%20learning%20-%20the%20good%2C%20the%20bad%20and%20the%20ugly%202017-07"
        },
        {
            "id": "54",
            "entry": "[54] Y. Yang and T. M. Hospedales. A unified perspective on multi-domain and multi-task learning. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Y.%20Hospedales%2C%20T.M.%20A%20unified%20perspective%20on%20multi-domain%20and%20multi-task%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Y.%20Hospedales%2C%20T.M.%20A%20unified%20perspective%20on%20multi-domain%20and%20multi-task%20learning%202015"
        },
        {
            "id": "55",
            "entry": "[55] F. X. Yu, L. Cao, R. S. Feris, J. R. Smith, and S.-F. Chang. Designing category-level attributes for discriminative visual recognition. In CVPR, pages 771\u2013778, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20F.X.%20Cao%2C%20L.%20Feris%2C%20R.S.%20Smith%2C%20J.R.%20Designing%20category-level%20attributes%20for%20discriminative%20visual%20recognition%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20F.X.%20Cao%2C%20L.%20Feris%2C%20R.S.%20Smith%2C%20J.R.%20Designing%20category-level%20attributes%20for%20discriminative%20visual%20recognition%202013"
        },
        {
            "id": "56",
            "entry": "[56] H. Zhang and P. Koniusz. Zero-shot kernel learning. In CVPR, June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20H.%20Koniusz%2C%20P.%20Zero-shot%20kernel%20learning%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20H.%20Koniusz%2C%20P.%20Zero-shot%20kernel%20learning%202018-06"
        },
        {
            "id": "57",
            "entry": "[57] L. Zhang, T. Xiang, and S. Gong. Learning a deep embedding model for zero-shot learning. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20L.%20Xiang%2C%20T.%20Gong%2C%20S.%20Learning%20a%20deep%20embedding%20model%20for%20zero-shot%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20L.%20Xiang%2C%20T.%20Gong%2C%20S.%20Learning%20a%20deep%20embedding%20model%20for%20zero-shot%20learning%202017"
        },
        {
            "id": "58",
            "entry": "[58] Z. Zhang and V. Saligrama. Classifying unseen instances by learning class-independent similarity functions. arXiv preprint arXiv: 1511.04512, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.04512"
        },
        {
            "id": "59",
            "entry": "[59] Z. Zhang and V. Saligrama. Zero-shot learning via semantic similarity embedding. In ICCV, pages 4166\u20134174, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Z.%20Saligrama%2C%20V.%20Zero-shot%20learning%20via%20semantic%20similarity%20embedding%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Z.%20Saligrama%2C%20V.%20Zero-shot%20learning%20via%20semantic%20similarity%20embedding%202015"
        },
        {
            "id": "60",
            "entry": "[60] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. Learning deep features for scene recognition using places database. In NIPS, pages 487\u2013495, 2014. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20B.%20Lapedriza%2C%20A.%20Xiao%2C%20J.%20Torralba%2C%20A.%20Learning%20deep%20features%20for%20scene%20recognition%20using%20places%20database%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20B.%20Lapedriza%2C%20A.%20Xiao%2C%20J.%20Torralba%2C%20A.%20Learning%20deep%20features%20for%20scene%20recognition%20using%20places%20database%202014"
        }
    ]
}
