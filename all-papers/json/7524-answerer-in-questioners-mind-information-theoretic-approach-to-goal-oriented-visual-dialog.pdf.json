{
    "filename": "7524-answerer-in-questioners-mind-information-theoretic-approach-to-goal-oriented-visual-dialog.pdf",
    "metadata": {
        "title": "Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog",
        "author": "Sang-Woo Lee, Yu-Jung Heo, Byoung-Tak Zhang",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7524-answerer-in-questioners-mind-information-theoretic-approach-to-goal-oriented-visual-dialog.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Goal-oriented dialog has been given attention due to its numerous applications in artificial intelligence. Goal-oriented dialogue tasks occur when a questioner asks an action-oriented question and an answerer responds with the intent of letting the questioner know a correct action to take. To ask the adequate question, deep learning and reinforcement learning have been recently applied. However, these approaches struggle to find a competent recurrent neural questioner, owing to the complexity of learning a series of sentences. Motivated by theory of mind, we propose \u201cAnswerer in Questioner\u2019s Mind\u201d (AQM), a novel information theoretic algorithm for goal-oriented dialog. With AQM, a questioner asks and infers based on an approximated probabilistic model of the answerer. The questioner figures out the answerer\u2019s intention via selecting a plausible question by explicitly calculating the information gain of the candidate intentions and possible answers to each question. We test our framework on two goal-oriented visual dialog tasks: \u201cMNIST Counting Dialog\u201d and \u201cGuessWhat?!\u201d. In our experiments, AQM outperforms comparative algorithms by a large margin."
    },
    "keywords": [
        {
            "term": "dialogue system",
            "url": "https://en.wikipedia.org/wiki/dialogue_system"
        },
        {
            "term": "correct action",
            "url": "https://en.wikipedia.org/wiki/correct_action"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "artificial intelligence",
            "url": "https://en.wikipedia.org/wiki/artificial_intelligence"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        }
    ],
    "highlights": [
        "Goal-oriented dialog is a classical artificial intelligence problem that needs to be addressed for digital personal assistants, order-by-phone tools, and online customer service centers",
        "We extend Answerer in Questioner\u2019s Mind to generate questions, in which case Answerer in Questioner\u2019s Mind can be understood as a way to boost the existing deep learning method in Section 5.2.\n2 Previous Works",
        "The compared deep supervised learning method used the question-generator with the hierarchical recurrent encoder-decoder [<a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>], achieving an accuracy of 46.8% in five turns [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "Random-randQ-depA achieved 46.36% in five turns, which is a competitive result to the deep supervised learning model. \u201cRandom\u201d denotes random question generation from the randQ set",
        "We extended Answerer in Questioner\u2019s Mind to generate question by applying a previously proposed deep supervised learning method",
        "Answerer in Questioner\u2019s Mind can be understood as a way to boost the existing deep learning method"
    ],
    "key_statements": [
        "Goal-oriented dialog is a classical artificial intelligence problem that needs to be addressed for digital personal assistants, order-by-phone tools, and online customer service centers",
        "We propose an \u201cAnswerer in Questioner\u2019s Mind\u201d (AQM) algorithm for goal-oriented dialog (Figure 1 (Left))",
        "Though we demonstrate the performance of our models in visual dialog tasks, our approach can be directly applied to general goal-oriented dialog where there is a non-visual context",
        "We propose the Answerer in Questioner\u2019s Mind, a practical goal-oriented dialog system motivated by theory of mind",
        "We extend Answerer in Questioner\u2019s Mind to generate questions, in which case Answerer in Questioner\u2019s Mind can be understood as a way to boost the existing deep learning method in Section 5.2.\n2 Previous Works",
        "To clearly explain the mechanism of Answerer in Questioner\u2019s Mind, we introduce the MNIST Counting Dialog task, which is a toy goal-oriented visual dialog problem, illustrated in Figure 4 (Left)",
        "The compared deep supervised learning method used the question-generator with the hierarchical recurrent encoder-decoder [<a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>], achieving an accuracy of 46.8% in five turns [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "Random-randQ-depA achieved 46.36% in five turns, which is a competitive result to the deep supervised learning model. \u201cRandom\u201d denotes random question generation from the randQ set",
        "The deep reinforcement learning has a module to decide whether the dialog is stopped or not. 4.1 is the number of the averaged turns.\n5.1",
        "In deep supervised learning and RL methods, hidden neurons in RNN are expected to track the context of history",
        "Answerer in Questioner\u2019s Mind can be implemented in various manners, not relying on a specific model representation nor a learning method",
        "We extended Answerer in Questioner\u2019s Mind to generate question by applying a previously proposed deep supervised learning method",
        "Answerer in Questioner\u2019s Mind can be understood as a way to boost the existing deep learning method"
    ],
    "summary": [
        "Goal-oriented dialog is a classical artificial intelligence problem that needs to be addressed for digital personal assistants, order-by-phone tools, and online customer service centers.",
        "Two machine agents are trained to make a dialog to achieve the goal of the task in a cooperative way [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>\u2013<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>].",
        "The questioner utilizes the approximated model to calculate the information gain of the candidate answerer\u2019s intentions and answers for each question.",
        "We test AQM mainly on goal-oriented visual dialog tasks in the self-play environment.",
        "We test our AQM on two goal-oriented visual dialog tasks, showing that our method outperforms comparative methods.",
        "We use AQM as a tool to understand existing deep learning methods in goal-oriented dialog studies.",
        "We extend AQM to generate questions, in which case AQM can be understood as a way to boost the existing deep learning method in Section 5.2.",
        "AQM uses real images, creates multi-turn dialog, and can be used for general goal-oriented dialog tasks.",
        "In deep SL and RL methods [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], the questioner has two RNN-based models, one is the questiongenerator to generate a question and the other is the guesser to classify a class.",
        "To calculate the information gain I, the question-generator module uses the likelihood pand the posterior p.",
        "If Q-sampler uses a RNN-based model, AQM can generate the question.",
        "In the existing deep learning framework, SL and RL are used to train two RNN-based models of the questioner.",
        "The goal of the MNIST Counting Dialog task is to inform the questioner to pick the correct image among 10K candidate images via questioning and answering.",
        "For the MNIST Counting Dialog task, we do not model the questioner and the answerer using neural networks.",
        "In Appendix D, we leverage AQM as a tool for analyzing the deep RL approach on goal-oriented dialog tasks from the perspective of theory of mind.",
        "We prove that AQM and RL have a similar objective function, implying that RL-based training for the questioner can be seen as implicit approximation on the answer distribution of the answerer.",
        "AQM can generate questions by using rule-based program [<a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>] or a seq2seq models previously used in goal-oriented dialog studies.",
        "If the Q-sampler generates questions through the seq2seq model using the history of dialog at every turn, the performance would be improved further.",
        "We proposed \u201cAnswerer in Questioner\u2019s Mind\u201d (AQM), a practical goal-oriented dialog framework using information-theoretic approach.",
        "We extended AQM to generate question by applying a previously proposed deep SL method.",
        "We argued that considering the collaborator\u2019s mind in implementing an agent is useful and fundamental"
    ],
    "headline": "We propose an \u201cAnswerer in Questioner\u2019s Mind\u201d  algorithm for goal-oriented dialog )",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Oliver Lemon, Kallirroi Georgila, James Henderson, and Matthew Stuttle. An isu dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the talk in-car system. In Proceedings of the Eleventh Conference of the European Chapter of the Association for Computational Linguistics: Posters & Demonstrations, pages 119\u2013122. Association for Computational Linguistics, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lemon%2C%20Oliver%20Georgila%2C%20Kallirroi%20Henderson%2C%20James%20Stuttle%2C%20Matthew%20An%20isu%20dialogue%20system%20exhibiting%20reinforcement%20learning%20of%20dialogue%20policies%3A%20generic%20slot-filling%20in%20the%20talk%20in-car%20system%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lemon%2C%20Oliver%20Georgila%2C%20Kallirroi%20Henderson%2C%20James%20Stuttle%2C%20Matthew%20An%20isu%20dialogue%20system%20exhibiting%20reinforcement%20learning%20of%20dialogue%20policies%3A%20generic%20slot-filling%20in%20the%20talk%20in-car%20system%202006"
        },
        {
            "id": "2",
            "entry": "[2] Jason D Williams and Steve Young. Partially observable markov decision processes for spoken dialog systems. Computer Speech & Language, 21(2):393\u2013422, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Jason%20D.%20Young%2C%20Steve%20Partially%20observable%20markov%20decision%20processes%20for%20spoken%20dialog%20systems%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Jason%20D.%20Young%2C%20Steve%20Partially%20observable%20markov%20decision%20processes%20for%20spoken%20dialog%20systems%202007"
        },
        {
            "id": "3",
            "entry": "[3] Antoine Bordes and Jason Weston. Learning end-to-end goal-oriented dialog. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bordes%2C%20Antoine%20Weston%2C%20Jason%20Learning%20end-to-end%20goal-oriented%20dialog%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bordes%2C%20Antoine%20Weston%2C%20Jason%20Learning%20end-to-end%20goal-oriented%20dialog%202017"
        },
        {
            "id": "4",
            "entry": "[4] Oriol Vinyals and Quoc Le. A neural conversational model. In ICML Deep Learning Workshop, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20Oriol%20Le%2C%20Quoc%20A%20neural%20conversational%20model%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20Oriol%20Le%2C%20Quoc%20A%20neural%20conversational%20model%202015"
        },
        {
            "id": "5",
            "entry": "[5] Angeliki Lazaridou, Karl Moritz Hermann Hermann, Karl Tuyls, and Stephen Clark. Emergence of linguistic communication from referential games with symbolic and pixel input. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lazaridou%2C%20Angeliki%20Hermann%2C%20Karl%20Moritz%20Hermann%20Tuyls%2C%20Karl%20Clark%2C%20Stephen%20Emergence%20of%20linguistic%20communication%20from%20referential%20games%20with%20symbolic%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lazaridou%2C%20Angeliki%20Hermann%2C%20Karl%20Moritz%20Hermann%20Tuyls%2C%20Karl%20Clark%2C%20Stephen%20Emergence%20of%20linguistic%20communication%20from%20referential%20games%20with%20symbolic%202018"
        },
        {
            "id": "6",
            "entry": "[6] Harm de Vries, Florian Strub, Sarath Chandar, Olivier Pietquin, Hugo Larochelle, and Aaron Courville. Guesswhat?! visual object discovery through multi-modal dialogue. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=de%20Vries%2C%20Harm%20Strub%2C%20Florian%20Chandar%2C%20Sarath%20Pietquin%2C%20Olivier%20Guesswhat%3F%21%20visual%20object%20discovery%20through%20multi-modal%20dialogue%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=de%20Vries%2C%20Harm%20Strub%2C%20Florian%20Chandar%2C%20Sarath%20Pietquin%2C%20Olivier%20Guesswhat%3F%21%20visual%20object%20discovery%20through%20multi-modal%20dialogue%202017"
        },
        {
            "id": "7",
            "entry": "[7] Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, Jos\u00e9 MF Moura, Devi Parikh, and Dhruv Batra. Visual dialog. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Das%2C%20Abhishek%20Kottur%2C%20Satwik%20Gupta%2C%20Khushi%20Singh%2C%20Avi%20Visual%20dialog%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Das%2C%20Abhishek%20Kottur%2C%20Satwik%20Gupta%2C%20Khushi%20Singh%2C%20Avi%20Visual%20dialog%202017"
        },
        {
            "id": "8",
            "entry": "[8] Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su, Stefan Ultes, and Steve Young. A network-based end-to-end trainable task-oriented dialogue system. arXiv preprint arXiv:1604.04562, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1604.04562"
        },
        {
            "id": "9",
            "entry": "[9] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724\u20131734, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20Kyunghyun%20van%20Merrienboer%2C%20Bart%20Gulcehre%2C%20Caglar%20Bahdanau%2C%20Dzmitry%20Learning%20phrase%20representations%20using%20rnn%20encoder%E2%80%93decoder%20for%20statistical%20machine%20translation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cho%2C%20Kyunghyun%20van%20Merrienboer%2C%20Bart%20Gulcehre%2C%20Caglar%20Bahdanau%2C%20Dzmitry%20Learning%20phrase%20representations%20using%20rnn%20encoder%E2%80%93decoder%20for%20statistical%20machine%20translation%202014"
        },
        {
            "id": "10",
            "entry": "[10] Tiancheng Zhao and Maxine Eskenazi. Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning. arXiv preprint arXiv:1606.02560, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.02560"
        },
        {
            "id": "11",
            "entry": "[11] Xuijun Li, Yun-Nung Chen, Lihong Li, and Jianfeng Gao. End-to-end task-completion neural dialogue systems. arXiv preprint arXiv:1703.01008, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.01008"
        },
        {
            "id": "12",
            "entry": "[12] Jin-Hwa Kim, Devi Parikh, Dhruv Batra, Byoung-Tak Zhang, and Yuandong Tian. Codraw: Visual dialog for collaborative drawing. arXiv preprint arXiv:1712.05558, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.05558"
        },
        {
            "id": "13",
            "entry": "[13] Abhishek Das, Satwik Kottur, Jos\u00e9 MF Moura, Stefan Lee, and Dhruv Batra. Learning cooperative visual dialog agents with deep reinforcement learning. arXiv preprint arXiv:1703.06585, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.06585"
        },
        {
            "id": "14",
            "entry": "[14] David Premack and Guy Woodruff. Does the chimpanzee have a theory of mind? Behavioral and Brain Sciences, 1(4):515\u2013526, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Premack%2C%20David%20Woodruff%2C%20Guy%20Does%20the%20chimpanzee%20have%20a%20theory%20of%20mind%3F%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Premack%2C%20David%20Woodruff%2C%20Guy%20Does%20the%20chimpanzee%20have%20a%20theory%20of%20mind%3F%201978"
        },
        {
            "id": "15",
            "entry": "[15] Jerome S Bruner. Intention in the structure of action and interaction. Advances in infancy research, 1981.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bruner%2C%20Jerome%20S.%20Intention%20in%20the%20structure%20of%20action%20and%20interaction%201981",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bruner%2C%20Jerome%20S.%20Intention%20in%20the%20structure%20of%20action%20and%20interaction%201981"
        },
        {
            "id": "16",
            "entry": "[16] David JC MacKay. Information theory, inference and learning algorithms. Cambridge university press, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=MacKay%2C%20David%20J.C.%20Information%20theory%2C%20inference%20and%20learning%20algorithms%202003"
        },
        {
            "id": "17",
            "entry": "[17] Byoung-Tak Zhang. Information-theoretic objective functions for lifelong learning. In AAAI Spring Symposium: Lifelong Machine Learning, pages 62\u201369, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Byoung-Tak%20Information-theoretic%20objective%20functions%20for%20lifelong%20learning.%20In%20AAAI%20Spring%20Symposium%3A%20Lifelong%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Byoung-Tak%20Information-theoretic%20objective%20functions%20for%20lifelong%20learning.%20In%20AAAI%20Spring%20Symposium%3A%20Lifelong%202013"
        },
        {
            "id": "18",
            "entry": "[18] Florian Strub, Harm de Vries, Jeremie Mary, Bilal Piot, Aaron Courville, and Olivier Pietquin. End-to-end optimization of goal-driven and visually grounded dialogue systems. arXiv preprint arXiv:1703.05423, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.05423"
        },
        {
            "id": "19",
            "entry": "[19] Katrina Evtimova, Andrew Drozdov, Douwe Kiela, and Kyunghyun Cho. Emergent language in a multimodal, multi-step referential game. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Evtimova%2C%20Katrina%20Drozdov%2C%20Andrew%20Kiela%2C%20Douwe%20Cho%2C%20Kyunghyun%20Emergent%20language%20in%20a%20multimodal%2C%20multi-step%20referential%20game%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Evtimova%2C%20Katrina%20Drozdov%2C%20Andrew%20Kiela%2C%20Douwe%20Cho%2C%20Kyunghyun%20Emergent%20language%20in%20a%20multimodal%2C%20multi-step%20referential%20game%202018"
        },
        {
            "id": "20",
            "entry": "[20] Arjun Chandrasekaran, Deshraj Yadav, Prithvijit Chattopadhyay, Viraj Prabhu, and Devi Parikh. It takes two to tango: Towards theory of ai\u2019s mind. arXiv preprint arXiv:1704.00717, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.00717"
        },
        {
            "id": "21",
            "entry": "[21] John Batali. Computational simulations of the emergence of grammar. Approaches to the Evolution of Language: Social and Cognitive Bases, 405:426, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Batali%2C%20John%20Computational%20simulations%20of%20the%20emergence%20of%20grammar.%20Approaches%20to%20the%20Evolution%20of%20Language%3A%20Social%20and%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Batali%2C%20John%20Computational%20simulations%20of%20the%20emergence%20of%20grammar.%20Approaches%20to%20the%20Evolution%20of%20Language%3A%20Social%20and%201998"
        },
        {
            "id": "22",
            "entry": "[22] Edward Choi, Angeliki Lazaridou, and Nando de Freitas. Multi-agent compositional communication learning from raw visual input. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Edward%20Lazaridou%2C%20Angeliki%20de%20Freitas%2C%20Nando%20Multi-agent%20compositional%20communication%20learning%20from%20raw%20visual%20input%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Edward%20Lazaridou%2C%20Angeliki%20de%20Freitas%2C%20Nando%20Multi-agent%20compositional%20communication%20learning%20from%20raw%20visual%20input%202018"
        },
        {
            "id": "23",
            "entry": "[23] Pablo Hernandez-Leal and Michael Kaisers. Learning against sequential opponents in repeated stochastic games. In The 3rd Multi-disciplinary Conference on Reinforcement Learning and Decision Making, Ann Arbor, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hernandez-Leal%2C%20Pablo%20Kaisers%2C%20Michael%20Learning%20against%20sequential%20opponents%20in%20repeated%20stochastic%20games.%20In%20The%203rd%20Multi-disciplinary%20Conference%20on%20Reinforcement%20Learning%20and%20Decision%20Making%202017"
        },
        {
            "id": "24",
            "entry": "[24] Junhua Mao, Jonathan Huang, Alexander Toshev, Oana Camburu, Alan L Yuille, and Kevin Murphy. Generation and comprehension of unambiguous object descriptions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 11\u201320, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mao%2C%20Junhua%20Huang%2C%20Jonathan%20Toshev%2C%20Alexander%20Camburu%2C%20Oana%20Generation%20and%20comprehension%20of%20unambiguous%20object%20descriptions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mao%2C%20Junhua%20Huang%2C%20Jonathan%20Toshev%2C%20Alexander%20Camburu%2C%20Oana%20Generation%20and%20comprehension%20of%20unambiguous%20object%20descriptions%202016"
        },
        {
            "id": "25",
            "entry": "[25] Daniel Fried, Jacob Andreas, and Dan Klein. Unified pragmatic models for generating and following instructions. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), volume 1, pages 1951\u20131963, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fried%2C%20Daniel%20Andreas%2C%20Jacob%20Klein%2C%20Dan%20Unified%20pragmatic%20models%20for%20generating%20and%20following%20instructions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fried%2C%20Daniel%20Andreas%2C%20Jacob%20Klein%2C%20Dan%20Unified%20pragmatic%20models%20for%20generating%20and%20following%20instructions%202018"
        },
        {
            "id": "26",
            "entry": "[26] Jacob Andreas and Dan Klein. Reasoning about pragmatics with neural listeners and speakers. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1173\u20131182, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andreas%2C%20Jacob%20Klein%2C%20Dan%20Reasoning%20about%20pragmatics%20with%20neural%20listeners%20and%20speakers%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andreas%2C%20Jacob%20Klein%2C%20Dan%20Reasoning%20about%20pragmatics%20with%20neural%20listeners%20and%20speakers%202016"
        },
        {
            "id": "27",
            "entry": "[27] Licheng Yu, Hao Tan, Mohit Bansal, and Tamara L Berg. A joint speakerlistener-reinforcer model for referring expressions. In Computer Vision and Pattern Recognition (CVPR), volume 2, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20Licheng%20Tan%2C%20Hao%20Bansal%2C%20Mohit%20Berg%2C%20Tamara%20L.%20A%20joint%20speakerlistener-reinforcer%20model%20for%20referring%20expressions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20Licheng%20Tan%2C%20Hao%20Bansal%2C%20Mohit%20Berg%2C%20Tamara%20L.%20A%20joint%20speakerlistener-reinforcer%20model%20for%20referring%20expressions%202017"
        },
        {
            "id": "28",
            "entry": "[28] Will Monroe, Robert XD Hawkins, Noah D Goodman, and Christopher Potts. Colors in context: A pragmatic neural model for grounded language understanding. Transactions of the Association for Computational Linguistics, 5:325\u2013338, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Monroe%2C%20Will%20Hawkins%2C%20Robert%20X.D.%20Goodman%2C%20Noah%20D.%20Potts%2C%20Christopher%20Colors%20in%20context%3A%20A%20pragmatic%20neural%20model%20for%20grounded%20language%20understanding%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Monroe%2C%20Will%20Hawkins%2C%20Robert%20X.D.%20Goodman%2C%20Noah%20D.%20Potts%2C%20Christopher%20Colors%20in%20context%3A%20A%20pragmatic%20neural%20model%20for%20grounded%20language%20understanding%202017"
        },
        {
            "id": "29",
            "entry": "[29] Jakob N Foerster, Richard Y Chen, Maruan Al-Shedivat, Shimon Whiteson, Pieter Abbeel, and Igor Mordatch. Learning with opponent-learning awareness. arXiv preprint arXiv:1709.04326, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.04326"
        },
        {
            "id": "30",
            "entry": "[30] Joseph Polifroni and Marilyn Walker. Learning database content for spoken dialogue system design. In 5th International Conference on Language Resources and Evaluation (LREC), 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Polifroni%2C%20Joseph%20Walker%2C%20Marilyn%20Learning%20database%20content%20for%20spoken%20dialogue%20system%20design%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Polifroni%2C%20Joseph%20Walker%2C%20Marilyn%20Learning%20database%20content%20for%20spoken%20dialogue%20system%20design%202006"
        },
        {
            "id": "31",
            "entry": "[31] Anselm Rothe, Brenden M Lake, and Todd Gureckis. Question asking as program generation. In Advances in Neural Information Processing Systems, pages 1046\u20131055, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rothe%2C%20Anselm%20Lake%2C%20Brenden%20M.%20Gureckis%2C%20Todd%20Question%20asking%20as%20program%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rothe%2C%20Anselm%20Lake%2C%20Brenden%20M.%20Gureckis%2C%20Todd%20Question%20asking%20as%20program%20generation%202017"
        },
        {
            "id": "32",
            "entry": "[32] Satwik Kottur, Jos\u00e9 Moura, Stefan Lee, and Dhruv Batra. Natural language does not emerge \u2018naturally\u2019in multi-agent dialog. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2962\u20132967, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kottur%2C%20Satwik%20Moura%2C%20Jos%C3%A9%20Lee%2C%20Stefan%20Batra%2C%20Dhruv%20Natural%20language%20does%20not%20emerge%20%E2%80%98naturally%E2%80%99in%20multi-agent%20dialog%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kottur%2C%20Satwik%20Moura%2C%20Jos%C3%A9%20Lee%2C%20Stefan%20Batra%2C%20Dhruv%20Natural%20language%20does%20not%20emerge%20%E2%80%98naturally%E2%80%99in%20multi-agent%20dialog%202017"
        },
        {
            "id": "33",
            "entry": "[33] Paul Hongsuck Seo, Andreas Lehrmann, Bohyung Han, and Leonid Sigal. Visual reference resolution using attention memory for visual dialog. In Advances in Neural Information Processing Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seo%2C%20Paul%20Hongsuck%20Lehrmann%2C%20Andreas%20Han%2C%20Bohyung%20Sigal%2C%20Leonid%20Visual%20reference%20resolution%20using%20attention%20memory%20for%20visual%20dialog%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Seo%2C%20Paul%20Hongsuck%20Lehrmann%2C%20Andreas%20Han%2C%20Bohyung%20Sigal%2C%20Leonid%20Visual%20reference%20resolution%20using%20attention%20memory%20for%20visual%20dialog%202017"
        },
        {
            "id": "34",
            "entry": "[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European Conference on Computer Vision, pages 740\u2013755.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=TsungYi%20Lin%20Michael%20Maire%20Serge%20Belongie%20James%20Hays%20Pietro%20Perona%20Deva%20Ramanan%20Piotr%20Doll%C3%A1r%20and%20C%20Lawrence%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20European%20Conference%20on%20Computer%20Vision%20pages%20740755",
            "oa_query": "https://api.scholarcy.com/oa_version?query=TsungYi%20Lin%20Michael%20Maire%20Serge%20Belongie%20James%20Hays%20Pietro%20Perona%20Deva%20Ramanan%20Piotr%20Doll%C3%A1r%20and%20C%20Lawrence%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20European%20Conference%20on%20Computer%20Vision%20pages%20740755"
        },
        {
            "id": "35",
            "entry": "[35] Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. arXiv preprint arXiv:1612.08242, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.08242"
        },
        {
            "id": "36",
            "entry": "[36] Iulian V Serban, Alessandro Sordoni, Yoshua Bengio, Aaron Courville, and Joelle Pineau. Hierarchical neural network generative models for movie dialogues. arXiv preprint arXiv:1507.04808, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.04808"
        },
        {
            "id": "37",
            "entry": "[37] Igor Mordatch and Pieter Abbeel. Emergence of grounded compositional language in multi-agent populations. arXiv preprint arXiv:1703.04908, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.04908"
        },
        {
            "id": "38",
            "entry": "[38] Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. Show and tell: A neural image caption generator. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3156\u20133164, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20Oriol%20Toshev%2C%20Alexander%20Bengio%2C%20Samy%20Erhan%2C%20Dumitru%20Show%20and%20tell%3A%20A%20neural%20image%20caption%20generator%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20Oriol%20Toshev%2C%20Alexander%20Bengio%2C%20Samy%20Erhan%2C%20Dumitru%20Show%20and%20tell%3A%20A%20neural%20image%20caption%20generator%202015"
        },
        {
            "id": "39",
            "entry": "[39] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. Vqa: Visual question answering. In Proceedings of the IEEE International Conference on Computer Vision, pages 2425\u20132433, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Antol%2C%20Stanislaw%20Agrawal%2C%20Aishwarya%20Lu%2C%20Jiasen%20Mitchell%2C%20Margaret%20Vqa%3A%20Visual%20question%20answering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Antol%2C%20Stanislaw%20Agrawal%2C%20Aishwarya%20Lu%2C%20Jiasen%20Mitchell%2C%20Margaret%20Vqa%3A%20Visual%20question%20answering%202015"
        },
        {
            "id": "40",
            "entry": "[40] Cheolho Han, Sang-Woo Lee, Yujung Heo, Wooyoung Kang, Jaehyun Jun, and Byoung-Tak Zhang. Criteria for human-compatible ai in two-player vision-language tasks. In 2017 IJCAI Workshop on Linguistic and Cognitive Approaches to Dialogue Agents, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20Cheolho%20Lee%2C%20Sang-Woo%20Heo%2C%20Yujung%20Kang%2C%20Wooyoung%20Criteria%20for%20human-compatible%20ai%20in%20two-player%20vision-language%20tasks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20Cheolho%20Lee%2C%20Sang-Woo%20Heo%2C%20Yujung%20Kang%2C%20Wooyoung%20Criteria%20for%20human-compatible%20ai%20in%20two-player%20vision-language%20tasks%202017"
        },
        {
            "id": "41",
            "entry": "[41] Prithvijit Chattopadhyay, Deshraj Yadav, Viraj Prabhu, Arjun Chandrasekaran, Abhishek Das, Stefan Lee, Dhruv Batra, and Devi Parikh. Evaluating visual conversational agents via cooperative human-ai games. arXiv preprint arXiv:1708.05122, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.05122"
        },
        {
            "id": "42",
            "entry": "[42] R\u00e9mi Coulom. Efficient selectivity and backup operators in monte-carlo tree search. In International Conference on Computers and Games, pages 72\u201383.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Coulom%2C%20R%C3%A9mi%20Efficient%20selectivity%20and%20backup%20operators%20in%20monte-carlo%20tree%20search",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Coulom%2C%20R%C3%A9mi%20Efficient%20selectivity%20and%20backup%20operators%20in%20monte-carlo%20tree%20search"
        },
        {
            "id": "43",
            "entry": "[43] Andrew Y Ng and Michael I Jordan. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. In Advances in Neural Information Processing Systems, pages 841\u2013848, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Andrew%20Y%20Ng%20and%20Michael%20I%20Jordan.%20On%20discriminative%20vs.%20generative%20classifiers%3A%20A%20comparison%20of%20logistic%20regression%20and%20naive%20bayes%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Andrew%20Y%20Ng%20and%20Michael%20I%20Jordan.%20On%20discriminative%20vs.%20generative%20classifiers%3A%20A%20comparison%20of%20logistic%20regression%20and%20naive%20bayes%202002"
        },
        {
            "id": "44",
            "entry": "[44] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go without human knowledge. Nature, 550(7676):354, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silver%2C%20David%20Schrittwieser%2C%20Julian%20Simonyan%2C%20Karen%20Antonoglou%2C%20Ioannis%20Mastering%20the%20game%20of%20go%20without%20human%20knowledge%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silver%2C%20David%20Schrittwieser%2C%20Julian%20Simonyan%2C%20Karen%20Antonoglou%2C%20Ioannis%20Mastering%20the%20game%20of%20go%20without%20human%20knowledge%202017"
        },
        {
            "id": "45",
            "entry": "[45] Alex Kendall and Yarin Gal. What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? In Advances in Neural Information Processing Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kendall%2C%20Alex%20Gal%2C%20Yarin%20What%20Uncertainties%20Do%20We%20Need%20in%20Bayesian%20Deep%20Learning%20for%20Computer%20Vision%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kendall%2C%20Alex%20Gal%2C%20Yarin%20What%20Uncertainties%20Do%20We%20Need%20in%20Bayesian%20Deep%20Learning%20for%20Computer%20Vision%3F%202017"
        },
        {
            "id": "46",
            "entry": "[46] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, pages 1126\u20131135, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finn%2C%20Chelsea%20Abbeel%2C%20Pieter%20Levine%2C%20Sergey%20Model-agnostic%20meta-learning%20for%20fast%20adaptation%20of%20deep%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20Chelsea%20Abbeel%2C%20Pieter%20Levine%2C%20Sergey%20Model-agnostic%20meta-learning%20for%20fast%20adaptation%20of%20deep%20networks%202017"
        }
    ]
}
