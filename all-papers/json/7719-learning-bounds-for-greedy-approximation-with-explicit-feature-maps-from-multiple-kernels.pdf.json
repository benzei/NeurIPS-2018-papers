{
    "filename": "7719-learning-bounds-for-greedy-approximation-with-explicit-feature-maps-from-multiple-kernels.pdf",
    "metadata": {
        "title": "Learning Bounds for Greedy Approximation with Explicit Feature Maps from Multiple Kernels",
        "author": "Shahin Shahrampour, Vahid Tarokh",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7719-learning-bounds-for-greedy-approximation-with-explicit-feature-maps-from-multiple-kernels.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Nonlinear kernels can be approximated using finite-dimensional feature maps for efficient risk minimization. Due to the inherent trade-off between the dimension of the (mapped) feature space and the approximation accuracy, the key problem is to identify promising (explicit) features leading to a satisfactory out-of-sample performance. In this work, we tackle this problem by efficiently choosing such features from multiple kernels in a greedy fashion. Our method sequentially selects these explicit features from a set of candidate features using a correlation metric. We establish an out-of-sample error bound capturing the trade-off between the error in terms of explicit features (approximation error) and the error due to spectral properties of the best model in the Hilbert space associated to the combined kernel (spectral error). The result verifies that when the (best) underlying data model is sparse enough, i.e., the spectral error is negligible, one can control the test error with a small number of explicit features, that can scale poly-logarithmically with data. Our empirical results show that given a fixed number of explicit features, the method can achieve a lower test error with a smaller time cost, compared to the state-of-the-art in data-dependent random features."
    },
    "keywords": [
        {
            "term": "kernel method",
            "url": "https://en.wikipedia.org/wiki/kernel_method"
        },
        {
            "term": "kernel machine",
            "url": "https://en.wikipedia.org/wiki/kernel_machine"
        },
        {
            "term": "hilbert space",
            "url": "https://en.wikipedia.org/wiki/hilbert_space"
        },
        {
            "term": "finite dimensional",
            "url": "https://en.wikipedia.org/wiki/finite_dimensional"
        }
    ],
    "highlights": [
        "Kernel methods are powerful tools in describing the nonlinear representation of data",
        "We provide non-asymptotic guarantees for Multi Feature Greedy Approximation, characterizing its out-of-sample performance via three types of errors, one of which relates to spectral properties of the best model in the Hilbert space associated to the combined kernel",
        "We face two important questions: (i) can we reduce the computation time using a suitable approximation of the kernel? how does the choice of kernel affect the prediction of unseen data? There is a large body of literature addressing these two questions",
        "Our work is related to several strands of literature reviewed below: Kernel approximation: Since the kernel matrix is N \u21e5 N , the computational cost of kernel methods scales at least quadratically with respect to data",
        "The distinction of our work with this literature is that our method is greedy rather than randomized, and our focus is on explicit feature maps",
        "Unlike most of the prior art, our focus is on explicit feature maps rather than kernels to save significant computational costs"
    ],
    "key_statements": [
        "Kernel methods are powerful tools in describing the nonlinear representation of data",
        "We provide non-asymptotic guarantees for Multi Feature Greedy Approximation, characterizing its out-of-sample performance via three types of errors, one of which relates to spectral properties of the best model in the Hilbert space associated to the combined kernel",
        "We further provide empirical evidence (Section 5) that explicit feature maps can be efficient tools for sparse representation",
        "We face two important questions: (i) can we reduce the computation time using a suitable approximation of the kernel? how does the choice of kernel affect the prediction of unseen data? There is a large body of literature addressing these two questions",
        "Our work is related to several strands of literature reviewed below: Kernel approximation: Since the kernel matrix is N \u21e5 N , the computational cost of kernel methods scales at least quadratically with respect to data",
        "The distinction of our work with this literature is that our method is greedy rather than randomized, and our focus is on explicit feature maps",
        "Unlike most of the prior art, our focus is on explicit feature maps rather than kernels to save significant computational costs",
        "Comparison with random features: For datasets in Table 1, we report our empirical findings in Figure 1"
    ],
    "summary": [
        "Kernel methods are powerful tools in describing the nonlinear representation of data.",
        "Our work is related to several strands of literature reviewed below: Kernel approximation: Since the kernel matrix is N \u21e5 N , the computational cost of kernel methods scales at least quadratically with respect to data.",
        "Shifting focus to explicit feature maps, in [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], the authors have proposed low-dimensional Taylor expansions of Gaussian kernel for speeding up learning.",
        "Vedaldi et al [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>] provide explicit feature maps for additive homogeneous kernels and quantify the approximation error using this approach.",
        "Various methods have been developed to decrease the time and space complexity of kernel approximation using properties of dense Gaussian random matrices.",
        "Random features reduce the computatpional complexity of traditional kernel methods.pIt has been shown recently in [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>] that to achieve O(1/ N ) learning error, we require only M = O( N log N ) random features.",
        "The distinction of our work with this literature is that our method is greedy rather than randomized, and our focus is on explicit feature maps.",
        "Our algorithm can be thought as an extension of fully corrective greedy in [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>] to nonlinear features from multiple kernels where we optimize the risk over the class (2).",
        "2) LKRF [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>], with approximated Gaussian kernel: = cos(x>!m + bm) in (4), but instead of M , a larger number M0 random features are sampled and re-weighted by solving a kernel alignment optimization.",
        "3) EERF [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>], with approximated Gaussian kernel: = cos(x>!m + bm) in (4), and again M0 random features are sampled and re-weighted according to a score function.",
        "When approximating Gaussian kernel by a second order Taylor expansion, our method forms O(d2) features and incurs O(N d2) computations, which is less than the other two in case d \u2327 M0.",
        "On all data sets except \u201cYear prediction\u201d, observe that our method spends drastically smaller pre-processing time to achieve a competitive result after evaluating smaller number of candidate features.",
        "Looking at the sum of training and pre-processing time from Table 2a-2b, we observe that our algorithm can achieve competitive results by spending less time compared to data-dependent methods.",
        "The comparison of our method to LKRF and EERF is equivalent to the comparison of explicit-vs-randomized feature maps.",
        "In comparison of vanilla explicit-vs-randomized feature maps, as discussed in the experiments of [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] for Gaussian kernel, the performance of none clearly dominates the other."
    ],
    "headline": "Motivated by the success of greedy methods in sparse approximation , we propose a method to select promising features from multiple kernels in a greedy fashion",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Alex J Smola and Bernhard Sch\u00f6kopf. Sparse greedy matrix approximation for machine learning. In Proceedings of the Seventeenth International Conference on Machine Learning, pages 911\u2013918, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smola%2C%20Alex%20J.%20Sch%C3%B6kopf%2C%20Bernhard%20Sparse%20greedy%20matrix%20approximation%20for%20machine%20learning%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smola%2C%20Alex%20J.%20Sch%C3%B6kopf%2C%20Bernhard%20Sparse%20greedy%20matrix%20approximation%20for%20machine%20learning%202000"
        },
        {
            "id": "2",
            "entry": "[2] Shai Fine and Katya Scheinberg. Efficient SVM training using low-rank kernel representations. Journal of Machine Learning Research, 2(Dec):243\u2013264, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fine%2C%20Shai%20Scheinberg%2C%20Katya%20Efficient%20SVM%20training%20using%20low-rank%20kernel%20representations%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fine%2C%20Shai%20Scheinberg%2C%20Katya%20Efficient%20SVM%20training%20using%20low-rank%20kernel%20representations%202001"
        },
        {
            "id": "3",
            "entry": "[3] Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In Advances in Neural Information Processing Systems, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Random%20features%20for%20large-scale%20kernel%20machines%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Random%20features%20for%20large-scale%20kernel%20machines%202007"
        },
        {
            "id": "4",
            "entry": "[4] Thorsten Joachims. Training linear SVM\u2019s in linear time. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 217\u2013226, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Joachims%2C%20Thorsten%20Training%20linear%20SVM%E2%80%99s%20in%20linear%20time%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Joachims%2C%20Thorsten%20Training%20linear%20SVM%E2%80%99s%20in%20linear%20time%202006"
        },
        {
            "id": "5",
            "entry": "[5] Ha Quang Minh, Partha Niyogi, and Yuan Yao. Mercer\u2019s theorem, feature maps, and smoothing. In International Conference on Computational Learning Theory, pages 154\u2013168.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minh%2C%20Ha%20Quang%20Niyogi%2C%20Partha%20Yao%2C%20Yuan%20Mercer%E2%80%99s%20theorem%2C%20feature%20maps%2C%20and%20smoothing",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Minh%2C%20Ha%20Quang%20Niyogi%2C%20Partha%20Yao%2C%20Yuan%20Mercer%E2%80%99s%20theorem%2C%20feature%20maps%2C%20and%20smoothing"
        },
        {
            "id": "6",
            "entry": "[6] Andrew Cotter, Joseph Keshet, and Nathan Srebro. Explicit approximations of the gaussian kernel. arXiv preprint arXiv:1109.4603, 2011.",
            "arxiv_url": "https://arxiv.org/pdf/1109.4603"
        },
        {
            "id": "7",
            "entry": "[7] St\u00e9phane G Mallat and Zhifeng Zhang. Matching pursuits with time-frequency dictionaries. IEEE Transactions on Signal Processing, 41(12):3397\u20133415, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mallat%2C%20St%C3%A9phane%20G.%20Zhang%2C%20Zhifeng%20Matching%20pursuits%20with%20time-frequency%20dictionaries%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mallat%2C%20St%C3%A9phane%20G.%20Zhang%2C%20Zhifeng%20Matching%20pursuits%20with%20time-frequency%20dictionaries%201993"
        },
        {
            "id": "8",
            "entry": "[8] Joel A Tropp. Greed is good: Algorithmic results for sparse approximation. IEEE Transactions on Information Theory, 50(10):2231\u20132242, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tropp%2C%20Joel%20A.%20Greed%20is%20good%3A%20Algorithmic%20results%20for%20sparse%20approximation%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tropp%2C%20Joel%20A.%20Greed%20is%20good%3A%20Algorithmic%20results%20for%20sparse%20approximation%202004"
        },
        {
            "id": "9",
            "entry": "[9] Mikhail Belkin. Approximation beats concentration? an approximation view on inference with smooth radial kernels. arXiv preprint arXiv:1801.03437, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.03437"
        },
        {
            "id": "10",
            "entry": "[10] Mehmet G\u00f6nen and Ethem Alpayd\u0131n. Multiple kernel learning algorithms. Journal of Machine Learning Research, 12(Jul):2211\u20132268, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=G%C3%B6nen%2C%20Mehmet%20Alpayd%C4%B1n%2C%20Ethem%20Multiple%20kernel%20learning%20algorithms%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=G%C3%B6nen%2C%20Mehmet%20Alpayd%C4%B1n%2C%20Ethem%20Multiple%20kernel%20learning%20algorithms%202011"
        },
        {
            "id": "11",
            "entry": "[11] Alan V Oppenheim, Alan S Willsky, and S Hamid Nawab. Signals & Systems. Pearson Educaci\u00f3n, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oppenheim%2C%20Alan%20V.%20Willsky%2C%20Alan%20S.%20Nawab%2C%20S.Hamid%20Signals%20%26%20Systems%201998"
        },
        {
            "id": "12",
            "entry": "[12] Yagyensh Chandra Pati, Ramin Rezaiifar, and Perinkulam Sambamurthy Krishnaprasad. Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition. In 1993 Conference Record of The Twenty-Seventh Asilomar Conference on Signals, Systems and Computers, pages 40\u201344. IEEE, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pati%2C%20Yagyensh%20Chandra%20Rezaiifar%2C%20Ramin%20Krishnaprasad%2C%20Perinkulam%20Sambamurthy%20Orthogonal%20matching%20pursuit%3A%20Recursive%20function%20approximation%20with%20applications%20to%20wavelet%20decomposition%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pati%2C%20Yagyensh%20Chandra%20Rezaiifar%2C%20Ramin%20Krishnaprasad%2C%20Perinkulam%20Sambamurthy%20Orthogonal%20matching%20pursuit%3A%20Recursive%20function%20approximation%20with%20applications%20to%20wavelet%20decomposition%201993"
        },
        {
            "id": "13",
            "entry": "[13] Geoffrey M Davis, Stephane G Mallat, and Zhifeng Zhang. Adaptive time-frequency decompositions. Optical Engineering, 33(7):2183\u20132192, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Davis%2C%20Geoffrey%20M.%20Mallat%2C%20Stephane%20G.%20Zhang%2C%20Zhifeng%20Adaptive%20time-frequency%20decompositions%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Davis%2C%20Geoffrey%20M.%20Mallat%2C%20Stephane%20G.%20Zhang%2C%20Zhifeng%20Adaptive%20time-frequency%20decompositions%201994"
        },
        {
            "id": "14",
            "entry": "[14] Jian Wang, Seokbeop Kwon, and Byonghyo Shim. Generalized orthogonal matching pursuit. IEEE Transactions on Signal Processing, 60(12):6202\u20136216, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Jian%20Kwon%2C%20Seokbeop%20Shim%2C%20Byonghyo%20Generalized%20orthogonal%20matching%20pursuit%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Jian%20Kwon%2C%20Seokbeop%20Shim%2C%20Byonghyo%20Generalized%20orthogonal%20matching%20pursuit%202012"
        },
        {
            "id": "15",
            "entry": "[15] Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Generalization bounds for learning kernels. In International Conference on Machine Learning, pages 247\u2013254, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Generalization%20bounds%20for%20learning%20kernels%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Generalization%20bounds%20for%20learning%20kernels%202010"
        },
        {
            "id": "16",
            "entry": "[16] R\u00e9mi Gribonval and Pierre Vandergheynst. On the exponential convergence of matching pursuits in quasi-incoherent dictionaries. IEEE Transactions on Information Theory, 52(1):255\u2013261, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gribonval%2C%20R%C3%A9mi%20Vandergheynst%2C%20Pierre%20On%20the%20exponential%20convergence%20of%20matching%20pursuits%20in%20quasi-incoherent%20dictionaries%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gribonval%2C%20R%C3%A9mi%20Vandergheynst%2C%20Pierre%20On%20the%20exponential%20convergence%20of%20matching%20pursuits%20in%20quasi-incoherent%20dictionaries%202006"
        },
        {
            "id": "17",
            "entry": "[17] Shai Shalev-Shwartz, Nathan Srebro, and Tong Zhang. Trading accuracy for sparsity in optimization problems with sparsity constraints. SIAM Journal on Optimization, 20(6):2807\u20132832, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shalev-Shwartz%2C%20Shai%20Srebro%2C%20Nathan%20Zhang%2C%20Tong%20Trading%20accuracy%20for%20sparsity%20in%20optimization%20problems%20with%20sparsity%20constraints%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shalev-Shwartz%2C%20Shai%20Srebro%2C%20Nathan%20Zhang%2C%20Tong%20Trading%20accuracy%20for%20sparsity%20in%20optimization%20problems%20with%20sparsity%20constraints%202010"
        },
        {
            "id": "18",
            "entry": "[18] Christopher Williams and Matthias Seeger. Using the Nystr\u00f6m method to speed up kernel machines. In Advances in Neural Information Processing Systems, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Christopher%20Seeger%2C%20Matthias%20Using%20the%20Nystr%C3%B6m%20method%20to%20speed%20up%20kernel%20machines%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Christopher%20Seeger%2C%20Matthias%20Using%20the%20Nystr%C3%B6m%20method%20to%20speed%20up%20kernel%20machines%202001"
        },
        {
            "id": "19",
            "entry": "[19] Petros Drineas and Michael W Mahoney. On the Nystr\u00f6m method for approximating a gram matrix for improved kernel-based learning. Journal of Machine Learning Research, 6(Dec):2153\u20132175, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Drineas%2C%20Petros%20Mahoney%2C%20Michael%20W.%20On%20the%20Nystr%C3%B6m%20method%20for%20approximating%20a%20gram%20matrix%20for%20improved%20kernel-based%20learning%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Drineas%2C%20Petros%20Mahoney%2C%20Michael%20W.%20On%20the%20Nystr%C3%B6m%20method%20for%20approximating%20a%20gram%20matrix%20for%20improved%20kernel-based%20learning%202005"
        },
        {
            "id": "20",
            "entry": "[20] Changjiang Yang, Ramani Duraiswami, and Larry Davis. Efficient kernel machines using the improved fast gauss transform. In Proceedings of the 17th International Conference on Neural Information Processing Systems, pages 1561\u20131568, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Changjiang%20Duraiswami%2C%20Ramani%20Davis%2C%20Larry%20Efficient%20kernel%20machines%20using%20the%20improved%20fast%20gauss%20transform%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Changjiang%20Duraiswami%2C%20Ramani%20Davis%2C%20Larry%20Efficient%20kernel%20machines%20using%20the%20improved%20fast%20gauss%20transform%202004"
        },
        {
            "id": "21",
            "entry": "[21] Jian-Wu Xu, Puskal P Pokharel, Kyu-Hwa Jeong, and Jose C Principe. An explicit construction of a reproducing gaussian kernel Hilbert space. In IEEE International Conference on Acoustics, Speech and Signal Processing, volume 5, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Jian-Wu%20Pokharel%2C%20Puskal%20P.%20Jeong%2C%20Kyu-Hwa%20Principe%2C%20Jose%20C.%20An%20explicit%20construction%20of%20a%20reproducing%20gaussian%20kernel%20Hilbert%20space%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Jian-Wu%20Pokharel%2C%20Puskal%20P.%20Jeong%2C%20Kyu-Hwa%20Principe%2C%20Jose%20C.%20An%20explicit%20construction%20of%20a%20reproducing%20gaussian%20kernel%20Hilbert%20space%202006"
        },
        {
            "id": "22",
            "entry": "[22] Andrea Vedaldi and Andrew Zisserman. Efficient additive kernels via explicit feature maps. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(3):480\u2013492, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Efficient%20additive%20kernels%20via%20explicit%20feature%20maps%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Efficient%20additive%20kernels%20via%20explicit%20feature%20maps%202012"
        },
        {
            "id": "23",
            "entry": "[23] Ali Rahimi and Benjamin Recht. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. In Advances in Neural Information Processing Systems, pages 1313\u20131320, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Weighted%20sums%20of%20random%20kitchen%20sinks%3A%20Replacing%20minimization%20with%20randomization%20in%20learning%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rahimi%2C%20Ali%20Recht%2C%20Benjamin%20Weighted%20sums%20of%20random%20kitchen%20sinks%3A%20Replacing%20minimization%20with%20randomization%20in%20learning%202009"
        },
        {
            "id": "24",
            "entry": "[24] Jiyan Yang, Vikas Sindhwani, Haim Avron, and Michael Mahoney. Quasi-monte carlo feature maps for shift-invariant kernels. In International Conference on Machine Learning, pages 485\u2013493, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jiyan%20Sindhwani%2C%20Vikas%20Avron%2C%20Haim%20Mahoney%2C%20Michael%20Quasi-monte%20carlo%20feature%20maps%20for%20shift-invariant%20kernels%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jiyan%20Sindhwani%2C%20Vikas%20Avron%2C%20Haim%20Mahoney%2C%20Michael%20Quasi-monte%20carlo%20feature%20maps%20for%20shift-invariant%20kernels%202014"
        },
        {
            "id": "25",
            "entry": "[25] Purushottam Kar and Harish Karnick. Random feature maps for dot product kernels. In International conference on Artificial Intelligence and Statistics, pages 583\u2013591, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kar%2C%20Purushottam%20Karnick%2C%20Harish%20Random%20feature%20maps%20for%20dot%20product%20kernels%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kar%2C%20Purushottam%20Karnick%2C%20Harish%20Random%20feature%20maps%20for%20dot%20product%20kernels%202012"
        },
        {
            "id": "26",
            "entry": "[26] Quoc Le, Tam\u00e1s Sarl\u00f3s, and Alex Smola. Fastfood-approximating kernel expansions in loglinear time. In International Conference on Machine Learning, volume 85, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Le%2C%20Quoc%20Sarl%C3%B3s%2C%20Tam%C3%A1s%20Smola%2C%20Alex%20Fastfood-approximating%20kernel%20expansions%20in%20loglinear%20time%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Le%2C%20Quoc%20Sarl%C3%B3s%2C%20Tam%C3%A1s%20Smola%2C%20Alex%20Fastfood-approximating%20kernel%20expansions%20in%20loglinear%20time%202013"
        },
        {
            "id": "27",
            "entry": "[27] X Yu Felix, Ananda Theertha Suresh, Krzysztof M Choromanski, Daniel N Holtmann-Rice, and Sanjiv Kumar. Orthogonal random features. In Advances in Neural Information Processing Systems, pages 1975\u20131983, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Felix%2C%20X.Yu%20Suresh%2C%20Ananda%20Theertha%20Choromanski%2C%20Krzysztof%20M.%20Holtmann-Rice%2C%20Daniel%20N.%20Orthogonal%20random%20features%201975",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Felix%2C%20X.Yu%20Suresh%2C%20Ananda%20Theertha%20Choromanski%2C%20Krzysztof%20M.%20Holtmann-Rice%2C%20Daniel%20N.%20Orthogonal%20random%20features%201975"
        },
        {
            "id": "28",
            "entry": "[28] Alessandro Rudi and Lorenzo Rosasco. Generalization properties of learning with random features. In Advances in Neural Information Processing Systems, pages 3218\u20133228, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rudi%2C%20Alessandro%20Rosasco%2C%20Lorenzo%20Generalization%20properties%20of%20learning%20with%20random%20features%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rudi%2C%20Alessandro%20Rosasco%2C%20Lorenzo%20Generalization%20properties%20of%20learning%20with%20random%20features%202017"
        },
        {
            "id": "29",
            "entry": "[29] Ian En-Hsu Yen, Ting-Wei Lin, Shou-De Lin, Pradeep K Ravikumar, and Inderjit S Dhillon. Sparse random feature algorithm as coordinate descent in hilbert space. In Advances in Neural Information Processing Systems, pages 2456\u20132464, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yen%2C%20Ian%20En-Hsu%20Lin%2C%20Ting-Wei%20Lin%2C%20Shou-De%20Ravikumar%2C%20Pradeep%20K.%20Sparse%20random%20feature%20algorithm%20as%20coordinate%20descent%20in%20hilbert%20space%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yen%2C%20Ian%20En-Hsu%20Lin%2C%20Ting-Wei%20Lin%2C%20Shou-De%20Ravikumar%2C%20Pradeep%20K.%20Sparse%20random%20feature%20algorithm%20as%20coordinate%20descent%20in%20hilbert%20space%202014"
        },
        {
            "id": "30",
            "entry": "[30] Felix X Yu, Sanjiv Kumar, Henry Rowley, and Shih-Fu Chang. Compact nonlinear maps and circulant extensions. arXiv preprint arXiv:1503.03893, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.03893"
        },
        {
            "id": "31",
            "entry": "[31] Zichao Yang, Andrew Wilson, Alex Smola, and Le Song. A la carte\u2013learning fast kernels. In Artificial Intelligence and Statistics, pages 1098\u20131106, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Zichao%20Wilson%2C%20Andrew%20Smola%2C%20Alex%20Song%2C%20Le%20A%20la%20carte%E2%80%93learning%20fast%20kernels%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Zichao%20Wilson%2C%20Andrew%20Smola%2C%20Alex%20Song%2C%20Le%20A%20la%20carte%E2%80%93learning%20fast%20kernels%202015"
        },
        {
            "id": "32",
            "entry": "[32] Junier B Oliva, Avinava Dubey, Andrew G Wilson, Barnab\u00e1s P\u00f3czos, Jeff Schneider, and Eric P Xing. Bayesian nonparametric kernel-learning. In Artificial Intelligence and Statistics, pages 1078\u20131086, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oliva%2C%20Junier%20B.%20Dubey%2C%20Avinava%20Wilson%2C%20Andrew%20G.%20P%C3%B3czos%2C%20Barnab%C3%A1s%20and%20Eric%20P%20Xing.%20Bayesian%20nonparametric%20kernel-learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oliva%2C%20Junier%20B.%20Dubey%2C%20Avinava%20Wilson%2C%20Andrew%20G.%20P%C3%B3czos%2C%20Barnab%C3%A1s%20and%20Eric%20P%20Xing.%20Bayesian%20nonparametric%20kernel-learning%202016"
        },
        {
            "id": "33",
            "entry": "[33] Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, and Barnabas Poczos. Data-driven random fourier features using stein effect. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chang%2C%20Wei-Cheng%20Li%2C%20Chun-Liang%20Yang%2C%20Yiming%20Poczos%2C%20Barnabas%20Data-driven%20random%20fourier%20features%20using%20stein%20effect%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20Wei-Cheng%20Li%2C%20Chun-Liang%20Yang%2C%20Yiming%20Poczos%2C%20Barnabas%20Data-driven%20random%20fourier%20features%20using%20stein%20effect%202017"
        },
        {
            "id": "34",
            "entry": "[34] Aman Sinha and John C Duchi. Learning kernels with random features. In Advances In Neural Information Processing Systems, pages 1298\u20131306, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sinha%2C%20Aman%20Duchi%2C%20John%20C.%20Learning%20kernels%20with%20random%20features%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sinha%2C%20Aman%20Duchi%2C%20John%20C.%20Learning%20kernels%20with%20random%20features%202016"
        },
        {
            "id": "35",
            "entry": "[35] Shahin Shahrampour, Ahmad Beirami, and Vahid Tarokh. On data-dependent random features for improved generalization in supervised learning. In AAAI Conference on Artificial Intelligence, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shahrampour%2C%20Shahin%20Beirami%2C%20Ahmad%20Tarokh%2C%20Vahid%20On%20data-dependent%20random%20features%20for%20improved%20generalization%20in%20supervised%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shahrampour%2C%20Shahin%20Beirami%2C%20Ahmad%20Tarokh%2C%20Vahid%20On%20data-dependent%20random%20features%20for%20improved%20generalization%20in%20supervised%20learning%202018"
        },
        {
            "id": "36",
            "entry": "[36] Shahin Shahrampour, Ahmad Beirami, and Vahid Tarokh. Supervised learning using data-dependent random features with application to seizure detection. In IEEE Conference on Decision and Control, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shahrampour%2C%20Shahin%20Beirami%2C%20Ahmad%20Tarokh%2C%20Vahid%20Supervised%20learning%20using%20data-dependent%20random%20features%20with%20application%20to%20seizure%20detection%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shahrampour%2C%20Shahin%20Beirami%2C%20Ahmad%20Tarokh%2C%20Vahid%20Supervised%20learning%20using%20data-dependent%20random%20features%20with%20application%20to%20seizure%20detection%202018"
        },
        {
            "id": "37",
            "entry": "[37] Brian Bullins, Cyril Zhang, and Yi Zhang. Not-so-random features. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bullins%2C%20Brian%20Zhang%2C%20Cyril%20Zhang%2C%20Yi%20Not-so-random%20features%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bullins%2C%20Brian%20Zhang%2C%20Cyril%20Zhang%2C%20Yi%20Not-so-random%20features%202018"
        },
        {
            "id": "38",
            "entry": "[38] Jerome H Friedman and Werner Stuetzle. Projection pursuit regression. Journal of the American Statistical Association, 76(376):817\u2013823, 1981.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Friedman%2C%20Jerome%20H.%20Stuetzle%2C%20Werner%20Projection%20pursuit%20regression%201981",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Friedman%2C%20Jerome%20H.%20Stuetzle%2C%20Werner%20Projection%20pursuit%20regression%201981"
        },
        {
            "id": "39",
            "entry": "[39] Pascal Vincent and Yoshua Bengio. Kernel matching pursuit. Machine Learning, 48(1-3):165\u2013187, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vincent%2C%20Pascal%20Bengio%2C%20Yoshua%20Kernel%20matching%20pursuit%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vincent%2C%20Pascal%20Bengio%2C%20Yoshua%20Kernel%20matching%20pursuit%202002"
        },
        {
            "id": "40",
            "entry": "[40] Prasanth B Nair, Arindam Choudhury, and Andy J Keane. Some greedy learning algorithms for sparse regression and classification with mercer kernels. Journal of Machine Learning Research, 3(Dec):781\u2013801, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nair%2C%20Prasanth%20B.%20Choudhury%2C%20Arindam%20Keane%2C%20Andy%20J.%20Some%20greedy%20learning%20algorithms%20for%20sparse%20regression%20and%20classification%20with%20mercer%20kernels%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nair%2C%20Prasanth%20B.%20Choudhury%2C%20Arindam%20Keane%2C%20Andy%20J.%20Some%20greedy%20learning%20algorithms%20for%20sparse%20regression%20and%20classification%20with%20mercer%20kernels%202002"
        },
        {
            "id": "41",
            "entry": "[41] Vikas Sindhwani and Aur\u00e9lie C Lozano. Non-parametric group orthogonal matching pursuit for sparse learning with multiple kernels. In Advances in Neural Information Processing Systems, pages 2519\u20132527, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sindhwani%2C%20Vikas%20Lozano%2C%20Aur%C3%A9lie%20C.%20Non-parametric%20group%20orthogonal%20matching%20pursuit%20for%20sparse%20learning%20with%20multiple%20kernels%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sindhwani%2C%20Vikas%20Lozano%2C%20Aur%C3%A9lie%20C.%20Non-parametric%20group%20orthogonal%20matching%20pursuit%20for%20sparse%20learning%20with%20multiple%20kernels%202011"
        },
        {
            "id": "42",
            "entry": "[42] Aurelie Lozano, Grzegorz Swirszcz, and Naoki Abe. Group orthogonal matching pursuit for logistic regression. In Artificial Intelligence and Statistics, pages 452\u2013460, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lozano%2C%20Aurelie%20Swirszcz%2C%20Grzegorz%20Abe%2C%20Naoki%20Group%20orthogonal%20matching%20pursuit%20for%20logistic%20regression%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lozano%2C%20Aurelie%20Swirszcz%2C%20Grzegorz%20Abe%2C%20Naoki%20Group%20orthogonal%20matching%20pursuit%20for%20logistic%20regression%202011"
        },
        {
            "id": "43",
            "entry": "[43] Francesco Locatello, Rajiv Khanna, Michael Tschannen, and Martin Jaggi. A unified optimization view on generalized matching pursuit and frank-wolfe. In Artificial Intelligence and Statistics, pages 860\u2013868, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Locatello%2C%20Francesco%20Khanna%2C%20Rajiv%20Tschannen%2C%20Michael%20Jaggi%2C%20Martin%20A%20unified%20optimization%20view%20on%20generalized%20matching%20pursuit%20and%20frank-wolfe%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Locatello%2C%20Francesco%20Khanna%2C%20Rajiv%20Tschannen%2C%20Michael%20Jaggi%2C%20Martin%20A%20unified%20optimization%20view%20on%20generalized%20matching%20pursuit%20and%20frank-wolfe%202017"
        },
        {
            "id": "44",
            "entry": "[44] Dino Oglic and Thomas G\u00e4rtner. Greedy feature construction. In Advances in Neural Information Processing Systems, pages 3945\u20133953, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oglic%2C%20Dino%20G%C3%A4rtner%2C%20Thomas%20Greedy%20feature%20construction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oglic%2C%20Dino%20G%C3%A4rtner%2C%20Thomas%20Greedy%20feature%20construction%202016"
        },
        {
            "id": "45",
            "entry": "[45] Jaz Kandola, John Shawe-Taylor, and Nello Cristianini. Optimizing kernel alignment over combinations of kernel. 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kandola%2C%20Jaz%20Shawe-Taylor%2C%20John%20Cristianini%2C%20Nello%20Optimizing%20kernel%20alignment%20over%20combinations%20of%20kernel%202002"
        },
        {
            "id": "46",
            "entry": "[46] Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Learning non-linear combinations of kernels. In Advances in Neural Information Processing Systems, pages 396\u2013404, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Learning%20non-linear%20combinations%20of%20kernels%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Learning%20non-linear%20combinations%20of%20kernels%202009"
        },
        {
            "id": "47",
            "entry": "[47] Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Algorithms for learning kernels based on centered alignment. Journal of Machine Learning Research, 13(Mar):795\u2013828, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Algorithms%20for%20learning%20kernels%20based%20on%20centered%20alignment%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Algorithms%20for%20learning%20kernels%20based%20on%20centered%20alignment%202012"
        },
        {
            "id": "48",
            "entry": "[48] Marius Kloft, Ulf Brefeld, S\u00f6ren Sonnenburg, and Alexander Zien. Lp-norm multiple kernel learning. Journal of Machine Learning Research, 12(Mar):953\u2013997, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kloft%2C%20Marius%20Brefeld%2C%20Ulf%20Sonnenburg%2C%20S%C3%B6ren%20Zien%2C%20Alexander%20Lp-norm%20multiple%20kernel%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kloft%2C%20Marius%20Brefeld%2C%20Ulf%20Sonnenburg%2C%20S%C3%B6ren%20Zien%2C%20Alexander%20Lp-norm%20multiple%20kernel%20learning%202011"
        },
        {
            "id": "49",
            "entry": "[49] Gert RG Lanckriet, Nello Cristianini, Peter Bartlett, Laurent El Ghaoui, and Michael I Jordan. Learning the kernel matrix with semidefinite programming. Journal of Machine Learning Research, 5(Jan):27\u201372, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lanckriet%2C%20Gert%20R.G.%20Cristianini%2C%20Nello%20Bartlett%2C%20Peter%20Ghaoui%2C%20Laurent%20El%20Learning%20the%20kernel%20matrix%20with%20semidefinite%20programming%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lanckriet%2C%20Gert%20R.G.%20Cristianini%2C%20Nello%20Bartlett%2C%20Peter%20Ghaoui%2C%20Laurent%20El%20Learning%20the%20kernel%20matrix%20with%20semidefinite%20programming%202004"
        },
        {
            "id": "50",
            "entry": "[50] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. Journal of Machine Learning Research, 3(Nov):463\u2013482, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20Peter%20L.%20Mendelson%2C%20Shahar%20Rademacher%20and%20gaussian%20complexities%3A%20Risk%20bounds%20and%20structural%20results%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20Peter%20L.%20Mendelson%2C%20Shahar%20Rademacher%20and%20gaussian%20complexities%3A%20Risk%20bounds%20and%20structural%20results%202002"
        },
        {
            "id": "51",
            "entry": "[51] Corinna Cortes, Mehryar Mohri, and Umar Syed. Deep boosting. In International Conference on Machine Learning, pages 1179\u20131187, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Syed%2C%20Umar%20Deep%20boosting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20Corinna%20Mohri%2C%20Mehryar%20Syed%2C%20Umar%20Deep%20boosting%202014"
        },
        {
            "id": "52",
            "entry": "[52] Corinna Cortes, Xavier Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. Adanet: Adaptive structural learning of artificial neural networks. In International Conference on Machine Learning, pages 874\u2013883, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20Corinna%20Gonzalvo%2C%20Xavier%20Kuznetsov%2C%20Vitaly%20Mohri%2C%20Mehryar%20Adanet%3A%20Adaptive%20structural%20learning%20of%20artificial%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20Corinna%20Gonzalvo%2C%20Xavier%20Kuznetsov%2C%20Vitaly%20Mohri%2C%20Mehryar%20Adanet%3A%20Adaptive%20structural%20learning%20of%20artificial%20neural%20networks%202017"
        },
        {
            "id": "53",
            "entry": "[53] Furong Huang, Jordan Ash, John Langford, and Robert Schapire. Learning deep resnet blocks sequentially using boosting theory. In International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Furong%20Ash%2C%20Jordan%20Langford%2C%20John%20Schapire%2C%20Robert%20Learning%20deep%20resnet%20blocks%20sequentially%20using%20boosting%20theory%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Furong%20Ash%2C%20Jordan%20Langford%2C%20John%20Schapire%2C%20Robert%20Learning%20deep%20resnet%20blocks%20sequentially%20using%20boosting%20theory%202018"
        },
        {
            "id": "54",
            "entry": "[54] Ahmad Beirami, Meisam Razaviyayn, Shahin Shahrampour, and Vahid Tarokh. On optimal generalizability in parametric learning. In Advances in Neural Information Processing Systems, pages 3455\u20133465, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beirami%2C%20Ahmad%20Razaviyayn%2C%20Meisam%20Shahrampour%2C%20Shahin%20Tarokh%2C%20Vahid%20On%20optimal%20generalizability%20in%20parametric%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beirami%2C%20Ahmad%20Razaviyayn%2C%20Meisam%20Shahrampour%2C%20Shahin%20Tarokh%2C%20Vahid%20On%20optimal%20generalizability%20in%20parametric%20learning%202017"
        },
        {
            "id": "55",
            "entry": "[55] Shuaiwen Wang, Wenda Zhou, Haihao Lu, Arian Maleki, and Vahab Mirrokni. Approximate leave-one-out for fast parameter tuning in high dimensions. arXiv preprint arXiv:1807.02694, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.02694"
        },
        {
            "id": "56",
            "entry": "[56] Ryan Giordano, Will Stephenson, Runjing Liu, Michael I Jordan, and Tamara Broderick. Return of the infinitesimal jackknife. arXiv preprint arXiv:1806.00550, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.00550"
        },
        {
            "id": "57",
            "entry": "[57] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT press, 2012. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Talwalkar%2C%20Ameet%20Foundations%20of%20machine%20learning%202012"
        }
    ]
}
