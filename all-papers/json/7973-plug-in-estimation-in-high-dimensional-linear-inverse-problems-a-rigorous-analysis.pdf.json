{
    "filename": "7973-plug-in-estimation-in-high-dimensional-linear-inverse-problems-a-rigorous-analysis.pdf",
    "metadata": {
        "title": "Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis",
        "author": "Alyson K. Fletcher, Parthe Pandit, Sundeep Rangan, Subrata Sarkar, Philip Schniter",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7973-plug-in-estimation-in-high-dimensional-linear-inverse-problems-a-rigorous-analysis.pdf"
        },
        "abstract": "Estimating a vector x from noisy linear measurements Ax + w often requires use of prior knowledge or structural constraints on x for accurate reconstruction. Several recent works have considered combining linear least-squares estimation with a generic or \u201cplug-in\u201d denoiser function that can be designed in a modular manner based on the prior knowledge about x. While these methods have shown excellent performance, it has been difficult to obtain rigorous performance guarantees. This work considers plug-in denoising combined with the recentlydeveloped Vector Approximate Message Passing (VAMP) algorithm, which is itself derived via Expectation Propagation techniques. It shown that the mean squared error of this \u201cplug-and-play\" VAMP can be exactly predicted for highdimensional right-rotationally invariant random A and Lipschitz denoisers. The method is demonstrated on applications in image recovery and parametric bilinear estimation."
    },
    "keywords": [
        {
            "term": "high dimensional",
            "url": "https://en.wikipedia.org/wiki/high_dimensional"
        },
        {
            "term": "inverse problem",
            "url": "https://en.wikipedia.org/wiki/inverse_problem"
        },
        {
            "term": "VAMP",
            "url": "https://en.wikipedia.org/wiki/VAMP"
        },
        {
            "term": "compressed sensing",
            "url": "https://en.wikipedia.org/wiki/compressed_sensing"
        },
        {
            "term": "minimum mean-squared error",
            "url": "https://en.wikipedia.org/wiki/minimum_mean-squared_error"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        }
    ],
    "highlights": [
        "For large, i.i.d., sub-Gaussian random matrices A and Lipschitz denoisers g(\u00b7), the performance of Approximate message passing can be exactly predicted by a scalar state evolution (SE), which provides testable conditions for optimality [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>]",
        "Approximate message passing (AMP), originally proposed in [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>], refers to a powerful class of algorithms that can be applied to reconstruction of x0 from (1) that can incorporate a wide class of statistical priors",
        "For large, i.i.d., sub-Gaussian random matrices A and Lipschitz denoisers g(\u00b7), the performance of Approximate message passing can be exactly predicted by a scalar state evolution (SE), which provides testable conditions for optimality [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>]",
        "The main contribution of this work is to show that the state evolution analysis of vector Approximate message passing can be extended to a large class of non-separable denoisers that are Lipschitz continuous and satisfy a certain convergence property",
        "We show that the vector Approximate message passing algorithm with a non-separable denoiser follows the identical state evolution equations as the separable case given in [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>]",
        "The method provides a computational efficient method for reconstruction where structural information and constraints on the unknown vector can be incorporated in a modular manner"
    ],
    "key_statements": [
        "For large, i.i.d., sub-Gaussian random matrices A and Lipschitz denoisers g(\u00b7), the performance of Approximate message passing can be exactly predicted by a scalar state evolution (SE), which provides testable conditions for optimality [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>]",
        "Approximate message passing (AMP), originally proposed in [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>], refers to a powerful class of algorithms that can be applied to reconstruction of x0 from (1) that can incorporate a wide class of statistical priors",
        "For large, i.i.d., sub-Gaussian random matrices A and Lipschitz denoisers g(\u00b7), the performance of Approximate message passing can be exactly predicted by a scalar state evolution (SE), which provides testable conditions for optimality [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>]",
        "The main contribution of this work is to show that the state evolution analysis of vector Approximate message passing can be extended to a large class of non-separable denoisers that are Lipschitz continuous and satisfy a certain convergence property",
        "We show that the vector Approximate message passing algorithm with a non-separable denoiser follows the identical state evolution equations as the separable case given in [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>]",
        "The method provides a computational efficient method for reconstruction where structural information and constraints on the unknown vector can be incorporated in a modular manner"
    ],
    "summary": [
        "For large, i.i.d., sub-Gaussian random matrices A and Lipschitz denoisers g(\u00b7), the performance of AMP can be exactly predicted by a scalar state evolution (SE), which provides testable conditions for optimality [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>].",
        "The main contribution of this work is to show that the SE analysis of VAMP can be extended to a large class of non-separable denoisers that are Lipschitz continuous and satisfy a certain convergence property.",
        "The conditions are similar to those used in the analysis of AMP with non-separable denoisers in [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>].",
        "The main result of [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>] is that, under suitable conditions, VAMP admits a state evolution (SE) analysis that precisely describes the mean squared error (MSE) of the estimates x1k and x2k in a certain large system limit (LSL).",
        "The main contribution of the paper is to extend the state evolution analysis of VAMP to a class of denoisers that we call uniformly Lipschitz and convergent under Gaussian noise.",
        "The sequence of random vectors u and estimators g(\u00b7) are said to be convergent under Gaussian noise if the following condition holds: Let z1, z2 \u2208 RN be two sequences where (z1n, z2n) are i.i.d. with (z1n, z2n) = N (0, S) for some positive definite covariance S \u2208 R2\u00d72.",
        "The sequence of true vectors x0 and denoiser functions are convergent under Gaussian noise following Definition 2.",
        "Under a certain uniform Lipschitz condition, it is shown in the extended version of this paper [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] that the denoiser satisfies Assumption 1.",
        "Under suitable Lipschitz continuity conditions, the extended version of this paper [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] shows that groupwise separable denoiser satisfies Assumption 1.",
        "If we assume that h remains constant and N \u2192 \u221e, the extended version of this paper [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] shows that the sequence of random vectors x0 and convolutional denoisers g1(\u00b7) satisfies Assumption 1.",
        "We show that the VAMP algorithm with a non-separable denoiser follows the identical state evolution equations as the separable case given in [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>].",
        "Under the above assumptions and definitions, assume that the sequence of true random vectors x0 and denoisers g1(r1, \u03b31) satisfy Assumption 1.",
        "As an alternative to the sparsity-based approach, it was recently suggested in [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] to recover x0 directly using AMP (2) by choosing the estimation function g as a sophisticated image-denoising algorithm like BM3D [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] or DnCNN [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>].",
        "Figure 1a compares the LASSO-and DnCNN-based versions of AMP and VAMP for 128\u00d7128 image recovery under well-conditioned A and no noise.",
        "The method admits a rigorous analysis that can provide precise predictions on the performance in high-dimensional random settings"
    ],
    "headline": "We show that there are several interesting non-separable denoisers that satisfy these conditions, including group-structured and convolutional neural network based denoisers",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] D. L. Donoho, A. Maleki, and A. Montanari, \u201cMessage-passing algorithms for compressed sensing,\u201d Proc. Nat. Acad. Sci., vol. 106, no. 45, pp. 18 914\u201318 919, Nov. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donoho%2C%20D.L.%20Maleki%2C%20A.%20Montanari%2C%20A.%20Message-passing%20algorithms%20for%20compressed%20sensing%2C%202009-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donoho%2C%20D.L.%20Maleki%2C%20A.%20Montanari%2C%20A.%20Message-passing%20algorithms%20for%20compressed%20sensing%2C%202009-11"
        },
        {
            "id": "2",
            "entry": "[2] S. Rangan, \u201cGeneralized approximate message passing for estimation with random linear mixing,\u201d in Proc. IEEE ISIT, 2011, pp. 2174\u20132178.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangan%2C%20S.%20Generalized%20approximate%20message%20passing%20for%20estimation%20with%20random%20linear%20mixing%2C%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangan%2C%20S.%20Generalized%20approximate%20message%20passing%20for%20estimation%20with%20random%20linear%20mixing%2C%202011"
        },
        {
            "id": "3",
            "entry": "[3] S. Rangan, P. Schniter, E. Riegler, A. Fletcher, and V. Cevher, \u201cFixed points of generalized approximate message passing with arbitrary matrices,\u201d in Proc. IEEE ISIT, Jul. 2013, pp. 664\u2013668.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangan%2C%20S.%20Schniter%2C%20P.%20Riegler%2C%20E.%20Fletcher%2C%20A.%20Fixed%20points%20of%20generalized%20approximate%20message%20passing%20with%20arbitrary%20matrices%2C%202013-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangan%2C%20S.%20Schniter%2C%20P.%20Riegler%2C%20E.%20Fletcher%2C%20A.%20Fixed%20points%20of%20generalized%20approximate%20message%20passing%20with%20arbitrary%20matrices%2C%202013-07"
        },
        {
            "id": "4",
            "entry": "[4] S. Rangan, P. Schniter, and A. K. Fletcher, \u201cOn the convergence of approximate message passing with arbitrary matrices,\u201d in Proc. IEEE ISIT, Jul. 2014, pp. 236\u2013240.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangan%2C%20S.%20Schniter%2C%20P.%20Fletcher%2C%20A.K.%20On%20the%20convergence%20of%20approximate%20message%20passing%20with%20arbitrary%20matrices%2C%202014-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangan%2C%20S.%20Schniter%2C%20P.%20Fletcher%2C%20A.K.%20On%20the%20convergence%20of%20approximate%20message%20passing%20with%20arbitrary%20matrices%2C%202014-07"
        },
        {
            "id": "5",
            "entry": "[5] R. Tibshirani, \u201cRegression shrinkage and selection via the lasso,\u201d J. Royal Stat. Soc., Ser. B, vol. 58, no. 1, pp. 267\u2013288, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tibshirani%2C%20R.%20Regression%20shrinkage%20and%20selection%20via%20the%20lasso%2C%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tibshirani%2C%20R.%20Regression%20shrinkage%20and%20selection%20via%20the%20lasso%2C%201996"
        },
        {
            "id": "6",
            "entry": "[6] M. Bayati and A. Montanari, \u201cThe dynamics of message passing on dense graphs, with applications to compressed sensing,\u201d IEEE Trans. Inform. Theory, vol. 57, no. 2, pp. 764\u2013785, Feb. 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bayati%2C%20M.%20Montanari%2C%20A.%20The%20dynamics%20of%20message%20passing%20on%20dense%20graphs%2C%20with%20applications%20to%20compressed%20sensing%2C%202011-02",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bayati%2C%20M.%20Montanari%2C%20A.%20The%20dynamics%20of%20message%20passing%20on%20dense%20graphs%2C%20with%20applications%20to%20compressed%20sensing%2C%202011-02"
        },
        {
            "id": "7",
            "entry": "[7] A. Javanmard and A. Montanari, \u201cState evolution for general approximate message passing algorithms, with applications to spatial coupling,\u201d Information and Inference, vol. 2, no. 2, pp. 115\u2013144, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Javanmard%2C%20A.%20Montanari%2C%20A.%20State%20evolution%20for%20general%20approximate%20message%20passing%20algorithms%2C%20with%20applications%20to%20spatial%20coupling%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Javanmard%2C%20A.%20Montanari%2C%20A.%20State%20evolution%20for%20general%20approximate%20message%20passing%20algorithms%2C%20with%20applications%20to%20spatial%20coupling%2C%202013"
        },
        {
            "id": "8",
            "entry": "[8] R. Berthier, A. Montanari, and P.-M. Nguyen, \u201cState evolution for approximate message passing with non-separable functions,\u201d arXiv preprint arXiv:1708.03950, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.03950"
        },
        {
            "id": "9",
            "entry": "[9] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian, \u201cImage denoising by sparse 3-D transform-domain collaborative filtering,\u201d IEEE Trans. Image Process., vol. 16, no. 8, pp. 2080\u20132095, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dabov%2C%20K.%20Foi%2C%20A.%20Katkovnik%2C%20V.%20Egiazarian%2C%20K.%20Image%20denoising%20by%20sparse%203-D%20transform-domain%20collaborative%20filtering%2C%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dabov%2C%20K.%20Foi%2C%20A.%20Katkovnik%2C%20V.%20Egiazarian%2C%20K.%20Image%20denoising%20by%20sparse%203-D%20transform-domain%20collaborative%20filtering%2C%202007"
        },
        {
            "id": "10",
            "entry": "[10] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, \u201cBeyond a Gaussian denoiser: Residual learning of deep CNN for image denoising,\u201d IEEE Trans. Image Process., vol. 26, no. 7, pp. 3142\u20133155, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20K.%20Zuo%2C%20W.%20Chen%2C%20Y.%20Meng%2C%20D.%20Beyond%20a%20Gaussian%20denoiser%3A%20Residual%20learning%20of%20deep%20CNN%20for%20image%20denoising%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20K.%20Zuo%2C%20W.%20Chen%2C%20Y.%20Meng%2C%20D.%20Beyond%20a%20Gaussian%20denoiser%3A%20Residual%20learning%20of%20deep%20CNN%20for%20image%20denoising%2C%202017"
        },
        {
            "id": "11",
            "entry": "[11] C. A. Metzler, A. Maleki, and R. G. Baraniuk, \u201cFrom denoising to compressed sensing,\u201d IEEE Trans. Info. Thy., vol. 62, no. 9, pp. 5117\u20135144, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Metzler%2C%20C.A.%20Maleki%2C%20A.%20Baraniuk%2C%20R.G.%20From%20denoising%20to%20compressed%20sensing%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Metzler%2C%20C.A.%20Maleki%2C%20A.%20Baraniuk%2C%20R.G.%20From%20denoising%20to%20compressed%20sensing%2C%202016"
        },
        {
            "id": "12",
            "entry": "[12] D. Donoho, I. Johnstone, and A. Montanari, \u201cAccurate prediction of phase transitions in compressed sensing via a connection to minimax denoising,\u201d IEEE Trans. Info. Thy., vol. 59, no. 6, pp. 3396\u20133433, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donoho%2C%20D.%20Johnstone%2C%20I.%20Montanari%2C%20A.%20Accurate%20prediction%20of%20phase%20transitions%20in%20compressed%20sensing%20via%20a%20connection%20to%20minimax%20denoising%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donoho%2C%20D.%20Johnstone%2C%20I.%20Montanari%2C%20A.%20Accurate%20prediction%20of%20phase%20transitions%20in%20compressed%20sensing%20via%20a%20connection%20to%20minimax%20denoising%2C%202013"
        },
        {
            "id": "13",
            "entry": "[13] Y. Ma, C. Rush, and D. Baron, \u201cAnalysis of approximate message passing with a class of non-separable denoisers,\u201d in Proc. ISIT, 2017, pp. 231\u2013235.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Y.%20Rush%2C%20C.%20Baron%2C%20D.%20Analysis%20of%20approximate%20message%20passing%20with%20a%20class%20of%20non-separable%20denoisers%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Y.%20Rush%2C%20C.%20Baron%2C%20D.%20Analysis%20of%20approximate%20message%20passing%20with%20a%20class%20of%20non-separable%20denoisers%2C%202017"
        },
        {
            "id": "14",
            "entry": "[14] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg, \u201cPlug-and-play priors for model based reconstruction,\u201d in Proc. IEEE Global Conference on Signal and Information Processing (GlobalSIP), 2013, pp. 945\u2013948.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Venkatakrishnan%2C%20S.V.%20Bouman%2C%20C.A.%20Wohlberg%2C%20B.%20Plug-and-play%20priors%20for%20model%20based%20reconstruction%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Venkatakrishnan%2C%20S.V.%20Bouman%2C%20C.A.%20Wohlberg%2C%20B.%20Plug-and-play%20priors%20for%20model%20based%20reconstruction%2C%202013"
        },
        {
            "id": "15",
            "entry": "[15] S. Chen, C. Luo, B. Deng, Y. Qin, H. Wang, and Z. Zhuang, \u201cBM3D vector approximate message passing for radar coded-aperture imaging,\u201d in PIERS-FALL, 2017, pp. 2035\u20132038.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20S.%20Luo%2C%20C.%20Deng%2C%20B.%20Qin%2C%20Y.%20%E2%80%9CBM3D%20vector%20approximate%20message%20passing%20for%20radar%20coded-aperture%20imaging%2C%E2%80%9D%20in%20PIERS-FALL%202017"
        },
        {
            "id": "16",
            "entry": "[16] X. Wang and S. H. Chan, \u201cParameter-free plug-and-play ADMM for image restoration,\u201d in Proc. IEEE Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017, pp. 1323\u20131327.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20X.%20Chan%2C%20S.H.%20Parameter-free%20plug-and-play%20ADMM%20for%20image%20restoration%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20X.%20Chan%2C%20S.H.%20Parameter-free%20plug-and-play%20ADMM%20for%20image%20restoration%2C%202017"
        },
        {
            "id": "17",
            "entry": "[17] F. Caltagirone, L. Zdeborov\u00e1, and F. Krzakala, \u201cOn convergence of approximate message passing,\u201d in Proc. IEEE ISIT, Jul. 2014, pp. 1812\u20131816.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caltagirone%2C%20F.%20Zdeborov%C3%A1%2C%20L.%20Krzakala%2C%20F.%20On%20convergence%20of%20approximate%20message%20passing%2C%202014-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caltagirone%2C%20F.%20Zdeborov%C3%A1%2C%20L.%20Krzakala%2C%20F.%20On%20convergence%20of%20approximate%20message%20passing%2C%202014-07"
        },
        {
            "id": "18",
            "entry": "[18] J. Vila, P. Schniter, S. Rangan, F. Krzakala, and L. Zdeborov\u00e1, \u201cAdaptive damping and mean removal for the generalized approximate message passing algorithm,\u201d in Proc. IEEE ICASSP, 2015, pp. 2021\u20132025.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vila%2C%20J.%20Schniter%2C%20P.%20Rangan%2C%20S.%20Krzakala%2C%20F.%20Adaptive%20damping%20and%20mean%20removal%20for%20the%20generalized%20approximate%20message%20passing%20algorithm%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vila%2C%20J.%20Schniter%2C%20P.%20Rangan%2C%20S.%20Krzakala%2C%20F.%20Adaptive%20damping%20and%20mean%20removal%20for%20the%20generalized%20approximate%20message%20passing%20algorithm%2C%202015"
        },
        {
            "id": "19",
            "entry": "[19] S. Rangan, P. Schniter, and A. K. Fletcher, \u201cVector approximate message passing,\u201d in Proc. IEEE ISIT, 2017, pp. 1588\u20131592.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangan%2C%20S.%20Schniter%2C%20P.%20Fletcher%2C%20A.K.%20Vector%20approximate%20message%20passing%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangan%2C%20S.%20Schniter%2C%20P.%20Fletcher%2C%20A.K.%20Vector%20approximate%20message%20passing%2C%202017"
        },
        {
            "id": "20",
            "entry": "[20] M. Opper and O. Winther, \u201cExpectation consistent approximate inference,\u201d J. Mach. Learning Res., vol. 1, pp. 2177\u20132204, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Opper%2C%20M.%20Winther%2C%20O.%20Expectation%20consistent%20approximate%20inference%2C%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Opper%2C%20M.%20Winther%2C%20O.%20Expectation%20consistent%20approximate%20inference%2C%202005"
        },
        {
            "id": "21",
            "entry": "[21] A. K. Fletcher, M. Sahraee-Ardakan, S. Rangan, and P. Schniter, \u201cExpectation consistent approximate inference: Generalizations and convergence,\u201d in Proc. IEEE ISIT, 2016, pp. 190\u2013194.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fletcher%2C%20A.K.%20Sahraee-Ardakan%2C%20M.%20Rangan%2C%20S.%20Schniter%2C%20P.%20Expectation%20consistent%20approximate%20inference%3A%20Generalizations%20and%20convergence%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fletcher%2C%20A.K.%20Sahraee-Ardakan%2C%20M.%20Rangan%2C%20S.%20Schniter%2C%20P.%20Expectation%20consistent%20approximate%20inference%3A%20Generalizations%20and%20convergence%2C%202016"
        },
        {
            "id": "22",
            "entry": "[22] J. Ma and L. Ping, \u201cOrthogonal AMP,\u201d IEEE Access, vol. 5, pp. 2020\u20132033, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20J.%20Ping%2C%20L.%20Orthogonal%20AMP%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20J.%20Ping%2C%20L.%20Orthogonal%20AMP%2C%202017"
        },
        {
            "id": "23",
            "entry": "[23] K. Takeuchi, \u201cRigorous dynamics of expectation-propagation-based signal recovery from unitarily invariant measurements,\u201d in Proc. ISIT, 2017, pp. 501\u2013505.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Takeuchi%2C%20K.%20Rigorous%20dynamics%20of%20expectation-propagation-based%20signal%20recovery%20from%20unitarily%20invariant%20measurements%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Takeuchi%2C%20K.%20Rigorous%20dynamics%20of%20expectation-propagation-based%20signal%20recovery%20from%20unitarily%20invariant%20measurements%2C%202017"
        },
        {
            "id": "24",
            "entry": "[24] S. Rangan, P. Schniter, and A. K. Fletcher, \u201cVector approximate message passing,\u201d arXiv:1610.03082, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.03082"
        },
        {
            "id": "25",
            "entry": "[25] A. K. Fletcher, M. Sahraee-Ardakan, S. Rangan, and P. Schniter, \u201cRigorous dynamics and consistent estimation in arbitrarily conditioned linear systems,\u201d in Proc. NIPS, 2017, pp. 2542\u20132551.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fletcher%2C%20A.K.%20Sahraee-Ardakan%2C%20M.%20Rangan%2C%20S.%20Schniter%2C%20P.%20Rigorous%20dynamics%20and%20consistent%20estimation%20in%20arbitrarily%20conditioned%20linear%20systems%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fletcher%2C%20A.K.%20Sahraee-Ardakan%2C%20M.%20Rangan%2C%20S.%20Schniter%2C%20P.%20Rigorous%20dynamics%20and%20consistent%20estimation%20in%20arbitrarily%20conditioned%20linear%20systems%2C%202017"
        },
        {
            "id": "26",
            "entry": "[26] P. Schniter, A. K. Fletcher, and S. Rangan, \u201cDenoising-based vector AMP,\u201d in Proc. Intl. Biomedical and Astronomical Signal Process. (BASP) Workshop, 2017, p. 77.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schniter%2C%20P.%20Fletcher%2C%20A.K.%20Rangan%2C%20S.%20Denoising-based%20vector%20AMP%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schniter%2C%20P.%20Fletcher%2C%20A.K.%20Rangan%2C%20S.%20Denoising-based%20vector%20AMP%2C%202017"
        },
        {
            "id": "27",
            "entry": "[27] A. K. Fletcher, P. Pandit, S. Rangan, S. Sarkar, and P. Schniter, \u201cPlug-in estimation in high-dimensional linear inverse problems: A rigorous analysis,\u201d arxiv preprint 1806.10466, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.10466"
        },
        {
            "id": "28",
            "entry": "[28] U. S. Kamilov, S. Rangan, A. K. Fletcher, and M. Unser, \u201cApproximate message passing with consistent parameter estimation and applications to sparse learning,\u201d IEEE Trans. Info. Theory, vol. 60, no. 5, pp. 2969\u20132985, Apr. 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamilov%2C%20U.S.%20Rangan%2C%20S.%20Fletcher%2C%20A.K.%20Unser%2C%20M.%20Approximate%20message%20passing%20with%20consistent%20parameter%20estimation%20and%20applications%20to%20sparse%20learning%2C%202014-04",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamilov%2C%20U.S.%20Rangan%2C%20S.%20Fletcher%2C%20A.K.%20Unser%2C%20M.%20Approximate%20message%20passing%20with%20consistent%20parameter%20estimation%20and%20applications%20to%20sparse%20learning%2C%202014-04"
        },
        {
            "id": "29",
            "entry": "[29] A. Taeb, A. Maleki, C. Studer, and R. Baraniuk, \u201cMaximin analysis of message passing algorithms for recovering block sparse signals,\u201d arXiv preprint arXiv:1303.2389, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1303.2389"
        },
        {
            "id": "30",
            "entry": "[30] M. R. Andersen, O. Winther, and L. K. Hansen, \u201cBayesian inference for structured spike and slab priors,\u201d in Advances in Neural Information Processing Systems, 2014, pp. 1745\u20131753.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andersen%2C%20M.R.%20Winther%2C%20O.%20Hansen%2C%20L.K.%20Bayesian%20inference%20for%20structured%20spike%20and%20slab%20priors%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andersen%2C%20M.R.%20Winther%2C%20O.%20Hansen%2C%20L.K.%20Bayesian%20inference%20for%20structured%20spike%20and%20slab%20priors%2C%202014"
        },
        {
            "id": "31",
            "entry": "[31] S. Rangan, A. K. Fletcher, V. K. Goyal, E. Byrne, and P. Schniter, \u201cHybrid approximate message passing,\u201d IEEE Transactions on Signal Processing, vol. 65, no. 17, pp. 4577\u20134592, Sept 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangan%2C%20S.%20Fletcher%2C%20A.K.%20Goyal%2C%20V.K.%20Byrne%2C%20E.%20Hybrid%20approximate%20message%20passing%2C%202017-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangan%2C%20S.%20Fletcher%2C%20A.K.%20Goyal%2C%20V.K.%20Byrne%2C%20E.%20Hybrid%20approximate%20message%20passing%2C%202017-09"
        },
        {
            "id": "32",
            "entry": "[32] L. L. Scharf and C. Demeure, Statistical Signal Processing: Detection, Estimation, and Time Series Analysis. Addison-Wesley Reading, MA, 1991, vol. 63.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scharf%2C%20L.L.%20Demeure%2C%20C.%20Statistical%20Signal%20Processing%3A%20Detection%2C%20Estimation%2C%20and%20Time%20Series%20Analysis%201991"
        },
        {
            "id": "33",
            "entry": "[33] J. Xie, L. Xu, and E. Chen, \u201cImage denoising and inpainting with deep neural networks,\u201d in Advances in Neural Information Processing Systems, 2012, pp. 341\u2013349.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20J.%20Xu%2C%20L.%20Chen%2C%20E.%20Image%20denoising%20and%20inpainting%20with%20deep%20neural%20networks%2C%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20J.%20Xu%2C%20L.%20Chen%2C%20E.%20Image%20denoising%20and%20inpainting%20with%20deep%20neural%20networks%2C%202012"
        },
        {
            "id": "34",
            "entry": "[34] L. Xu, J. S. Ren, C. Liu, and J. Jia, \u201cDeep convolutional neural network for image deconvolution,\u201d in Advances in Neural Information Processing Systems, 2014, pp. 1790\u20131798.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20L.%20Ren%2C%20J.S.%20Liu%2C%20C.%20Jia%2C%20J.%20Deep%20convolutional%20neural%20network%20for%20image%20deconvolution%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20L.%20Ren%2C%20J.S.%20Liu%2C%20C.%20Jia%2C%20J.%20Deep%20convolutional%20neural%20network%20for%20image%20deconvolution%2C%202014"
        },
        {
            "id": "35",
            "entry": "[35] J.-F. Cai, E. J. Cand\u00e8s, and Z. Shen, \u201cA singular value thresholding algorithm for matrix completion,\u201d SIAM J. Optim., vol. 20, no. 4, pp. 1956\u20131982, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cai%2C%20J.-F.%20Cand%C3%A8s%2C%20E.J.%20Shen%2C%20Z.%20A%20singular%20value%20thresholding%20algorithm%20for%20matrix%20completion%2C%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cai%2C%20J.-F.%20Cand%C3%A8s%2C%20E.J.%20Shen%2C%20Z.%20A%20singular%20value%20thresholding%20algorithm%20for%20matrix%20completion%2C%202010"
        },
        {
            "id": "36",
            "entry": "[36] M. Borgerding, P. Schniter, and S. Rangan, \u201cAMP-inspired deep networks for sparse linear inverse problems,\u201d IEEE Trans. Signal Process., vol. 65, no. 16, pp. 4293\u20134308, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borgerding%2C%20M.%20Schniter%2C%20P.%20Rangan%2C%20S.%20AMP-inspired%20deep%20networks%20for%20sparse%20linear%20inverse%20problems%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borgerding%2C%20M.%20Schniter%2C%20P.%20Rangan%2C%20S.%20AMP-inspired%20deep%20networks%20for%20sparse%20linear%20inverse%20problems%2C%202017"
        },
        {
            "id": "37",
            "entry": "[37] E. J. Cand\u00e8s, T. Strohmer, and V. Voroninski, \u201cPhaseLift: Exact and stable signal recovery from magnitude measurements via convex programming,\u201d Commun. Pure Appl. Math., vol. 66, no. 8, pp. 1241\u20131274, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cand%C3%A8s%2C%20E.J.%20Strohmer%2C%20T.%20Voroninski%2C%20V.%20PhaseLift%3A%20Exact%20and%20stable%20signal%20recovery%20from%20magnitude%20measurements%20via%20convex%20programming%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cand%C3%A8s%2C%20E.J.%20Strohmer%2C%20T.%20Voroninski%2C%20V.%20PhaseLift%3A%20Exact%20and%20stable%20signal%20recovery%20from%20magnitude%20measurements%20via%20convex%20programming%2C%202013"
        },
        {
            "id": "38",
            "entry": "[38] A. Ahmed, B. Recht, and J. Romberg, \u201cBlind deconvolution using convex programming,\u201d IEEE Trans. Inform. Theory, vol. 60, no. 3, pp. 1711\u20131732, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahmed%2C%20A.%20Recht%2C%20B.%20Romberg%2C%20J.%20Blind%20deconvolution%20using%20convex%20programming%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahmed%2C%20A.%20Recht%2C%20B.%20Romberg%2C%20J.%20Blind%20deconvolution%20using%20convex%20programming%2C%202014"
        },
        {
            "id": "39",
            "entry": "[39] S. Ling and T. Strohmer, \u201cSelf-calibration and biconvex compressive sensing,\u201d Inverse Problems, vol. 31, no. 11, p. 115002, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ling%2C%20S.%20Strohmer%2C%20T.%20Self-calibration%20and%20biconvex%20compressive%20sensing%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ling%2C%20S.%20Strohmer%2C%20T.%20Self-calibration%20and%20biconvex%20compressive%20sensing%2C%202015"
        },
        {
            "id": "40",
            "entry": "[40] M. A. Davenport and J. Romberg, \u201cAn overview of low-rank matrix recovery from incomplete observations,\u201d IEEE J. Sel. Topics Signal Process., vol. 10, no. 4, pp. 608\u2013622, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Davenport%2C%20M.A.%20Romberg%2C%20J.%20An%20overview%20of%20low-rank%20matrix%20recovery%20from%20incomplete%20observations%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Davenport%2C%20M.A.%20Romberg%2C%20J.%20An%20overview%20of%20low-rank%20matrix%20recovery%20from%20incomplete%20observations%2C%202016"
        },
        {
            "id": "41",
            "entry": "[41] S. S. Haykin, Ed., Blind Deconvolution. Upper Saddle River, NJ: Prentice-Hall, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Blind%20Deconvolution.%20Upper%20Saddle%201994"
        },
        {
            "id": "42",
            "entry": "[42] H. Zhu, G. Leus, and G. B. Giannakis, \u201cSparsity-cognizant total least-squares for perturbed compressive sampling,\u201d IEEE Trans. Signal Process., vol. 59, no. 5, pp. 2002\u20132016, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20H.%20Leus%2C%20G.%20Giannakis%2C%20G.B.%20Sparsity-cognizant%20total%20least-squares%20for%20perturbed%20compressive%20sampling%2C%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20H.%20Leus%2C%20G.%20Giannakis%2C%20G.B.%20Sparsity-cognizant%20total%20least-squares%20for%20perturbed%20compressive%20sampling%2C%202002"
        },
        {
            "id": "43",
            "entry": "[43] P. Sun, Z. Wang, and P. Schniter, \u201cJoint channel-estimation and equalization of single-carrier systems via bilinear AMP,\u201d IEEE Trans. Signal Process., vol. 66, no. 10, pp. 2772\u20132785, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20P.%20Wang%2C%20Z.%20Schniter%2C%20P.%20Joint%20channel-estimation%20and%20equalization%20of%20single-carrier%20systems%20via%20bilinear%20AMP%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20P.%20Wang%2C%20Z.%20Schniter%2C%20P.%20Joint%20channel-estimation%20and%20equalization%20of%20single-carrier%20systems%20via%20bilinear%20AMP%2C%202018"
        },
        {
            "id": "44",
            "entry": "[44] S. Rangan and A. K. Fletcher, \u201cIterative estimation of constrained rank-one matrices in noise,\u201d in Proc. IEEE ISIT, Cambridge, MA, Jul. 2012, pp. 1246\u20131250.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangan%2C%20S.%20Fletcher%2C%20A.K.%20Iterative%20estimation%20of%20constrained%20rank-one%20matrices%20in%20noise%2C%202012-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangan%2C%20S.%20Fletcher%2C%20A.K.%20Iterative%20estimation%20of%20constrained%20rank-one%20matrices%20in%20noise%2C%202012-07"
        },
        {
            "id": "45",
            "entry": "[45] Y. Deshpande and A. Montanari, \u201cInformation-theoretically optimal sparse PCA,\u201d in Proc. ISIT, 2014, pp.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deshpande%2C%20Y.%20Montanari%2C%20A.%20Information-theoretically%20optimal%20sparse%20PCA%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deshpande%2C%20Y.%20Montanari%2C%20A.%20Information-theoretically%20optimal%20sparse%20PCA%2C%202014"
        },
        {
            "id": "46",
            "entry": "[46] R. Matsushita and T. Tanaka, \u201cLow-rank matrix reconstruction and clustering via approximate message passing,\u201d in Proc. NIPS, 2013, pp. 917\u2013925.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matsushita%2C%20R.%20Tanaka%2C%20T.%20Low-rank%20matrix%20reconstruction%20and%20clustering%20via%20approximate%20message%20passing%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matsushita%2C%20R.%20Tanaka%2C%20T.%20Low-rank%20matrix%20reconstruction%20and%20clustering%20via%20approximate%20message%20passing%2C%202013"
        },
        {
            "id": "47",
            "entry": "[47] T. Lesieur, F. Krzakala, and L. Zdeborova, \u201cPhase transitions in sparse PCA,\u201d in Proc. IEEE ISIT, 2015, pp.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lesieur%2C%20T.%20Krzakala%2C%20F.%20Zdeborova%2C%20L.%20Phase%20transitions%20in%20sparse%20PCA%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lesieur%2C%20T.%20Krzakala%2C%20F.%20Zdeborova%2C%20L.%20Phase%20transitions%20in%20sparse%20PCA%2C%202015"
        },
        {
            "id": "48",
            "entry": "[48] J. Parker and P. Schniter, \u201cParametric bilinear generalized approximate message passing,\u201d IEEE J. Sel. Topics Signal Proc., vol. 10, no. 4, pp. 795\u2013808, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parker%2C%20J.%20Schniter%2C%20P.%20Parametric%20bilinear%20generalized%20approximate%20message%20passing%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parker%2C%20J.%20Schniter%2C%20P.%20Parametric%20bilinear%20generalized%20approximate%20message%20passing%2C%202016"
        }
    ]
}
