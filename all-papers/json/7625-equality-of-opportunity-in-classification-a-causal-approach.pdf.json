{
    "filename": "7625-equality-of-opportunity-in-classification-a-causal-approach.pdf",
    "metadata": {
        "title": "Equality of Opportunity in Classification: A Causal Approach",
        "author": "Junzhe Zhang, Elias Bareinboim",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7625-equality-of-opportunity-in-classification-a-causal-approach.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "The Equalized Odds (for short, EO) is one of the most popular measures of discrimination used in the supervised learning setting. It ascertains fairness through the balance of the misclassification rates (false positive and negative) across the protected groups \u2013 e.g., in the context of law enforcement, an African-American defendant who would not commit a future crime will have an equal opportunity of being released, compared to a non-recidivating Caucasian defendant. Despite this noble goal, it has been acknowledged in the literature that statistical tests based on the EO are oblivious to the underlying causal mechanisms that generated the disparity in the first place (Hardt et al. 2016). This leads to a critical disconnect between statistical measures readable from the data and the meaning of discrimination in the legal system, where compelling evidence that the observed disparity is tied to a specific causal process deemed unfair by society is required to characterize discrimination. The goal of this paper is to develop a principled approach to connect the statistical disparities characterized by the EO and the underlying, elusive, and frequently unobserved, causal mechanisms that generated such inequality. We start by introducing a new family of counterfactual measures that allows one to explain the misclassification disparities in terms of the underlying mechanisms in an arbitrary, non-parametric structural causal model. This will, in turn, allow legal and data analysts to interpret currently deployed classifiers through causal lens, linking the statistical disparities found in the data to the corresponding causal processes. Leveraging the new family of counterfactual measures, we develop a learning procedure to construct a classifier that is statistically efficient, interpretable, and compatible with the basic human intuition of fairness. We demonstrate our results through experiments in both real (COMPAS) and synthetic datasets."
    },
    "keywords": [
        {
            "term": "false positive",
            "url": "https://en.wikipedia.org/wiki/false_positive"
        },
        {
            "term": "law enforcement",
            "url": "https://en.wikipedia.org/wiki/law_enforcement"
        },
        {
            "term": "supervised learning",
            "url": "https://en.wikipedia.org/wiki/supervised_learning"
        },
        {
            "term": "african american",
            "url": "https://en.wikipedia.org/wiki/african_american"
        },
        {
            "term": "causal model",
            "url": "https://en.wikipedia.org/wiki/causal_model"
        }
    ],
    "highlights": [
        "The goal of supervised learning is to provide a statistical basis upon which individuals with different group memberships can be reliably classified",
        "We develop a causal framework to link the disparities realized through the ER and the causal mechanisms by which the protected attribute X",
        "(1) we introduce a family of counterfactual measures capable of describing the ER in terms of the direct, indirect, and spurious paths from X to Yon an arbitrary structural causal model (Defs. 1-3) and we prove different qualitative and quantitative properties of these measures (Thms. 1-2); (2) we derive adjustment-like formulas to estimate the counterfactual ERs from observational data (Thms. 3-4), which are accompanied with an efficient algorithm (Alg. 1, Thm. 5) to find the corresponding admissible sets; (3) we operationalize the proposed counterfactual estimands through a novel procedure to learn a fair classifier subject to constraints over the effect along the underlying causal mechanisms (Algs. 2-3, Thm. 6).\n2 Preliminaries and Notations",
        "We introduced a new family of counterfactual measures capable of explaining disparities in the misclassification rates across different demographics in terms of the causal mechanisms underlying the specific prediction process",
        "We developed machinery based on these measures to allow data scientists (1) to diagnose whether a classifier is operating in a discriminatory fashion against specific groups, and (2) to learn a new classifier subject to fairness constraints in terms of fine-grained misclassification rates"
    ],
    "key_statements": [
        "The goal of supervised learning is to provide a statistical basis upon which individuals with different group memberships can be reliably classified",
        "We develop a causal framework to link the disparities realized through the ER and the causal mechanisms by which the protected attribute X",
        "(1) we introduce a family of counterfactual measures capable of describing the ER in terms of the direct, indirect, and spurious paths from X to Yon an arbitrary structural causal model (Defs. 1-3) and we prove different qualitative and quantitative properties of these measures (Thms. 1-2); (2) we derive adjustment-like formulas to estimate the counterfactual ERs from observational data (Thms. 3-4), which are accompanied with an efficient algorithm (Alg. 1, Thm. 5) to find the corresponding admissible sets; (3) we operationalize the proposed counterfactual estimands through a novel procedure to learn a fair classifier subject to constraints over the effect along the underlying causal mechanisms (Algs. 2-3, Thm. 6).\n2 Preliminaries and Notations",
        "We investigate the unequalized odds of misclassification observed in COMPAS by devising three simple thought experiments. These experiments could be generalized into a set of novel counterfactual measures, providing a fine-grained explanation of how the ER disparity of a classifier f is brought about",
        "We provide in Appendix B [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] a more detailed discussion about the relationships between our measures and the existing ones.\n1G|Y explicitly represents the change of information flow due to conditioning on the true outcome Y : the information via arrows pointing away from Y is intercepted; measuring the collider Y makes its common causes dependent, known as the \u201cexplaining away\u201d effect [16, pp. 339].\n4 Estimating Counterfactual Error Rates",
        "Given finite samples D = {Yi, Vi}in=1 drawn from P (y, v), the associated causal diagram G, and a set of candidate ctf-explainable classifiers F , the goal of the supervised learning is to obtain an optimal classifier f \u2217 from F such that a loss function L(D, f ) measuring the distance between the prediction Yand the true outcome Y is minimized",
        "We focus on the false positive rate ERx0,x1 (y1|y0) across demographics x0 = 0, x1 = 1, where y1 = 1, y0 = 0, and the corresponding components ERxd0,x1 (y1|x0, y0), ERxi 1,x0 (y1|x0, y0) and ERxs1,x0 (y1|y0) (following",
        "We introduced a new family of counterfactual measures capable of explaining disparities in the misclassification rates across different demographics in terms of the causal mechanisms underlying the specific prediction process",
        "We developed machinery based on these measures to allow data scientists (1) to diagnose whether a classifier is operating in a discriminatory fashion against specific groups, and (2) to learn a new classifier subject to fairness constraints in terms of fine-grained misclassification rates"
    ],
    "summary": [
        "The goal of supervised learning is to provide a statistical basis upon which individuals with different group memberships can be reliably classified.",
        "(1) we introduce a family of counterfactual measures capable of describing the ER in terms of the direct, indirect, and spurious paths from X to Yon an arbitrary structural causal model (Defs.",
        "These experiments could be generalized into a set of novel counterfactual measures, providing a fine-grained explanation of how the ER disparity of a classifier f is brought about.",
        "Given a SCM M, P (u) and a classifier f, the counterfactual direct error rate for a sub-population x, y is defined as: ERdx0,x1 (y|x, y) = Px0,y |x, y) \u2212 P",
        "We generalize this thought experiment and provide an estimand of the indirect paths for any SCM and classifier f , namely: Definition 2 (Counterfactual Indirect Error Rate).",
        "Given a SCM M, P (u) and a classifier f, the counterfactual spurious error rate for a sub-population x, y is defined as: ERxs0,x1 (y|y) = P \u2212 P",
        "In COMPAS, ERdx0,x1 (y1|x0, y) explains how much the direct racial discrimination accounts for the unequalized false positive rate ERx0,x1 (y1|y0) between non-recidivating African American (x1, y) and Caucasian (x0, y) defendants.",
        "Given finite samples D = {Yi, Vi}in=1 drawn from P (y, v), the associated causal diagram G, and a set of candidate ctf-explainable classifiers F , the goal of the supervised learning is to obtain an optimal classifier f \u2217 from F such that a loss function L(D, f ) measuring the distance between the prediction Yand the true outcome Y is minimized.",
        "This observation suggests a novel feature selection problem in the fairness-aware classification task: we would like to find a subset PA from the available features V such that each classifier in the candidate set F = {\u2200f : PA \u2192 Y } is ctf-explainable, without significant loss of prediction accuracy.",
        "We do not apply FindExpSet, since removing features from a ctf-explainable classifier does not violate the explanation criterion (Def. 4).",
        "The results (Fig. 7(a)) support the counterfactual approach: fctf (90.1%) reports ER comparable to fer (ERctf = \u22120.238), but a smaller significant direct, indirect and spurious ER disparities (ERdctf = 0.191, ERcdtf = \u22120.194, ERdctf = \u22120.236).",
        "Since classifiers with feature set {X, W, Z} are not ctf-explainable in the COMPAS model (Def.4), ERd of fer and fopt cannot be identified via Thm. 3.",
        "We introduced a new family of counterfactual measures capable of explaining disparities in the misclassification rates across different demographics in terms of the causal mechanisms underlying the specific prediction process.",
        "We hope the causal machinery put forwarded here will help data scientists to analyze already deployed systems as well as to construct new classifiers that are fair even when the training data comes from an unfair world"
    ],
    "headline": "Leveraging the new family of counterfactual measures, we develop a learning procedure to construct a classifier that is statistically efficient, interpretable, and compatible with the basic human intuition of fairness",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] J. Angwin, J. Larson, S. Mattu, and L. Kirchner. Machine bias: There\u2019s software used across the country to predict future criminals. and it\u2019s biased against blacks. ProPublica, 23, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Angwin%2C%20J.%20Larson%2C%20J.%20Mattu%2C%20S.%20Kirchner%2C%20L.%20Machine%20bias%3A%20There%E2%80%99s%20software%20used%20across%20the%20country%20to%20predict%20future%20criminals.%20and%20it%E2%80%99s%20biased%20against%20blacks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Angwin%2C%20J.%20Larson%2C%20J.%20Mattu%2C%20S.%20Kirchner%2C%20L.%20Machine%20bias%3A%20There%E2%80%99s%20software%20used%20across%20the%20country%20to%20predict%20future%20criminals.%20and%20it%E2%80%99s%20biased%20against%20blacks%202016"
        },
        {
            "id": "2",
            "entry": "[2] E. Bareinboim and J. Pearl. Causal inference and the data-fusion problem. Proceedings of the National Academy of Sciences, 113:7345\u20137352, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bareinboim%2C%20E.%20Pearl%2C%20J.%20Causal%20inference%20and%20the%20data-fusion%20problem%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bareinboim%2C%20E.%20Pearl%2C%20J.%20Causal%20inference%20and%20the%20data-fusion%20problem%202016"
        },
        {
            "id": "3",
            "entry": "[3] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20S.%20Vandenberghe%2C%20L.%20Convex%20optimization%202004"
        },
        {
            "id": "4",
            "entry": "[4] T. Brennan, W. Dieterich, and B. Ehret. Evaluating the predictive validity of the compas risk and needs assessment system. Criminal Justice and Behavior, 36(1):21\u201340, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brennan%2C%20T.%20Dieterich%2C%20W.%20Ehret%2C%20B.%20Evaluating%20the%20predictive%20validity%20of%20the%20compas%20risk%20and%20needs%20assessment%20system%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brennan%2C%20T.%20Dieterich%2C%20W.%20Ehret%2C%20B.%20Evaluating%20the%20predictive%20validity%20of%20the%20compas%20risk%20and%20needs%20assessment%20system%202009"
        },
        {
            "id": "5",
            "entry": "[5] A. Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data, 5(2):153\u2013163, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chouldechova%2C%20A.%20Fair%20prediction%20with%20disparate%20impact%3A%20A%20study%20of%20bias%20in%20recidivism%20prediction%20instruments%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chouldechova%2C%20A.%20Fair%20prediction%20with%20disparate%20impact%3A%20A%20study%20of%20bias%20in%20recidivism%20prediction%20instruments%202017"
        },
        {
            "id": "6",
            "entry": "[6] G. Goh, A. Cotter, M. Gupta, and M. P. Friedlander. Satisfying real-world goals with dataset constraints. In Advances in Neural Information Processing Systems, pages 2415\u20132423, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goh%2C%20G.%20Cotter%2C%20A.%20Gupta%2C%20M.%20Friedlander%2C%20M.P.%20Satisfying%20real-world%20goals%20with%20dataset%20constraints%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goh%2C%20G.%20Cotter%2C%20A.%20Gupta%2C%20M.%20Friedlander%2C%20M.P.%20Satisfying%20real-world%20goals%20with%20dataset%20constraints%202016"
        },
        {
            "id": "7",
            "entry": "[7] M. Hardt, E. Price, N. Srebro, et al. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems, pages 3315\u20133323, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20M.%20Price%2C%20E.%20Srebro%2C%20N.%20Equality%20of%20opportunity%20in%20supervised%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20M.%20Price%2C%20E.%20Srebro%2C%20N.%20Equality%20of%20opportunity%20in%20supervised%20learning%202016"
        },
        {
            "id": "8",
            "entry": "[8] A. E. Khandani, A. J. Kim, and A. W. Lo. Consumer credit-risk models via machine-learning algorithms. Journal of Banking & Finance, 34(11):2767\u20132787, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khandani%2C%20A.E.%20Kim%2C%20A.J.%20Lo%2C%20A.W.%20Consumer%20credit-risk%20models%20via%20machine-learning%20algorithms%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khandani%2C%20A.E.%20Kim%2C%20A.J.%20Lo%2C%20A.W.%20Consumer%20credit-risk%20models%20via%20machine-learning%20algorithms%202010"
        },
        {
            "id": "9",
            "entry": "[9] N. Kilbertus, M. R. Carulla, G. Parascandolo, M. Hardt, D. Janzing, and B. Sch\u00f6lkopf. Avoiding discrimination through causal reasoning. In Advances in Neural Information Processing Systems, pages 656\u2013666, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kilbertus%2C%20N.%20Carulla%2C%20M.R.%20Parascandolo%2C%20G.%20Hardt%2C%20M.%20Avoiding%20discrimination%20through%20causal%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kilbertus%2C%20N.%20Carulla%2C%20M.R.%20Parascandolo%2C%20G.%20Hardt%2C%20M.%20Avoiding%20discrimination%20through%20causal%20reasoning%202017"
        },
        {
            "id": "10",
            "entry": "[10] M. J. Kusner, J. Loftus, C. Russell, and R. Silva. Counterfactual fairness. In Advances in Neural Information Processing Systems, pages 4069\u20134079, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%20J%20Kusner%20J%20Loftus%20C%20Russell%20and%20R%20Silva%20Counterfactual%20fairness%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pages%2040694079%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%20J%20Kusner%20J%20Loftus%20C%20Russell%20and%20R%20Silva%20Counterfactual%20fairness%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pages%2040694079%202017"
        },
        {
            "id": "11",
            "entry": "[11] X. W. Lu Zhang, Yongkai Wu. A causal framework for discovering and removing direct and indirect discrimination. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, pages 3929\u20133935, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20X.W.Lu%20Wu%2C%20Yongkai%20A%20causal%20framework%20for%20discovering%20and%20removing%20direct%20and%20indirect%20discrimination%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20X.W.Lu%20Wu%2C%20Yongkai%20A%20causal%20framework%20for%20discovering%20and%20removing%20direct%20and%20indirect%20discrimination%202017"
        },
        {
            "id": "12",
            "entry": "[12] J. K. Lunceford and M. Davidian. Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study. Statistics in medicine, 23(19):2937\u2013 2960, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lunceford%2C%20J.K.%20Davidian%2C%20M.%20Stratification%20and%20weighting%20via%20the%20propensity%20score%20in%20estimation%20of%20causal%20treatment%20effects%3A%20a%20comparative%20study%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lunceford%2C%20J.K.%20Davidian%2C%20M.%20Stratification%20and%20weighting%20via%20the%20propensity%20score%20in%20estimation%20of%20causal%20treatment%20effects%3A%20a%20comparative%20study%202004"
        },
        {
            "id": "13",
            "entry": "[13] J. F. Mahoney and J. M. Mohen. Method and system for loan origination and underwriting, Oct. 23 2007. US Patent 7,287,008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mahoney%2C%20J.F.%20Mohen%2C%20J.M.%20Method%20and%20system%20for%20loan%20origination%20and%20underwriting%202007-10"
        },
        {
            "id": "14",
            "entry": "[14] K. Mancuhan and C. Clifton. Combating discrimination using bayesian networks. Artificial Intelligence and Law, 22(2):211\u2013238, Jun 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mancuhan%2C%20K.%20Clifton%2C%20C.%20Combating%20discrimination%20using%20bayesian%20networks%202014-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mancuhan%2C%20K.%20Clifton%2C%20C.%20Combating%20discrimination%20using%20bayesian%20networks%202014-06"
        },
        {
            "id": "15",
            "entry": "[15] R. Nabi and I. Shpitser. Fair inference on outcomes. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nabi%2C%20R.%20Shpitser%2C%20I.%20Fair%20inference%20on%20outcomes%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nabi%2C%20R.%20Shpitser%2C%20I.%20Fair%20inference%20on%20outcomes%202018"
        },
        {
            "id": "16",
            "entry": "[16] J. Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, 2000. 2nd edition, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pearl%2C%20J.%20Causality%3A%20Models%2C%20Reasoning%2C%20and%20Inference%202000"
        },
        {
            "id": "17",
            "entry": "[17] J. Pearl. Direct and indirect effects. In Proc. of the Seventeenth Conference on Uncertainty in Artificial Intelligence, pages 411\u2013420. Morgan Kaufmann, CA, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pearl%2C%20J.%20Direct%20and%20indirect%20effects%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pearl%2C%20J.%20Direct%20and%20indirect%20effects%202001"
        },
        {
            "id": "18",
            "entry": "[18] J. Pearl, M. Glymour, and N. P. Jewell. Causal inference in statistics: a primer. John Wiley & Sons, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pearl%2C%20J.%20Glymour%2C%20M.%20Jewell%2C%20N.P.%20Causal%20inference%20in%20statistics%3A%20a%20primer%202016"
        },
        {
            "id": "19",
            "entry": "[19] P. Pudil, J. Novovicov\u00e1, and J. Kittler. Floating search methods in feature selection. Pattern recognition letters, 15(11):1119\u20131125, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pudil%2C%20P.%20Novovicov%C3%A1%2C%20J.%20Kittler%2C%20J.%20Floating%20search%20methods%20in%20feature%20selection%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pudil%2C%20P.%20Novovicov%C3%A1%2C%20J.%20Kittler%2C%20J.%20Floating%20search%20methods%20in%20feature%20selection%201994"
        },
        {
            "id": "20",
            "entry": "[20] I. Shpitser, T. VanderWeele, and J. Robins. On the validity of covariate adjustment for estimating causal effects. In Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence, pages 527\u2013536. AUAI, Corvallis, OR, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shpitser%2C%20I.%20VanderWeele%2C%20T.%20Robins%2C%20J.%20On%20the%20validity%20of%20covariate%20adjustment%20for%20estimating%20causal%20effects%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shpitser%2C%20I.%20VanderWeele%2C%20T.%20Robins%2C%20J.%20On%20the%20validity%20of%20covariate%20adjustment%20for%20estimating%20causal%20effects%202010"
        },
        {
            "id": "21",
            "entry": "[21] L. Sweeney. Discrimination in online ad delivery. Queue, 11(3):10, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sweeney%2C%20L.%20Discrimination%20in%20online%20ad%20delivery%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sweeney%2C%20L.%20Discrimination%20in%20online%20ad%20delivery%202013"
        },
        {
            "id": "22",
            "entry": "[22] B. van der Zander, M. Liskiewicz, and J. Textor. Constructing separators and adjustment sets in ancestral graphs. In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence. AUAI, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20der%20Zander%2C%20B.%20Liskiewicz%2C%20M.%20Textor%2C%20J.%20Constructing%20separators%20and%20adjustment%20sets%20in%20ancestral%20graphs%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20der%20Zander%2C%20B.%20Liskiewicz%2C%20M.%20Textor%2C%20J.%20Constructing%20separators%20and%20adjustment%20sets%20in%20ancestral%20graphs%202014"
        },
        {
            "id": "23",
            "entry": "[23] B. Woodworth, S. Gunasekar, M. I. Ohannessian, and N. Srebro. Learning non-discriminatory predictors. In Conference on Learning Theory, pages 1920\u20131953, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Woodworth%2C%20B.%20Gunasekar%2C%20S.%20Ohannessian%2C%20M.I.%20Srebro%2C%20N.%20Learning%20non-discriminatory%20predictors%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Woodworth%2C%20B.%20Gunasekar%2C%20S.%20Ohannessian%2C%20M.I.%20Srebro%2C%20N.%20Learning%20non-discriminatory%20predictors%202017"
        },
        {
            "id": "24",
            "entry": "[24] S. Wright. The method of path coefficients. The annals of mathematical statistics, 5(3):161\u2013215, 1934.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wright%2C%20S.%20The%20method%20of%20path%20coefficients.%20The%20annals%20of%20mathematical%201934",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wright%2C%20S.%20The%20method%20of%20path%20coefficients.%20The%20annals%20of%20mathematical%201934"
        },
        {
            "id": "25",
            "entry": "[25] M. B. Zafar, I. Valera, M. Gomez Rodriguez, and K. P. Gummadi. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th International Conference on World Wide Web, pages 1171\u20131180. International World Wide Web Conferences Steering Committee, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20M.B.%20Valera%2C%20I.%20Rodriguez%2C%20M.Gomez%20Gummadi%2C%20K.P.%20Fairness%20beyond%20disparate%20treatment%20%26%20disparate%20impact%3A%20Learning%20classification%20without%20disparate%20mistreatment%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20M.B.%20Valera%2C%20I.%20Rodriguez%2C%20M.Gomez%20Gummadi%2C%20K.P.%20Fairness%20beyond%20disparate%20treatment%20%26%20disparate%20impact%3A%20Learning%20classification%20without%20disparate%20mistreatment%202017"
        },
        {
            "id": "26",
            "entry": "[26] M. B. Zafar, I. Valera, M. G. Rogriguez, and K. P. Gummadi. Fairness constraints: Mechanisms for fair classification. In Artificial Intelligence and Statistics, pages 962\u2013970, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20M.B.%20Valera%2C%20I.%20Rogriguez%2C%20M.G.%20Gummadi%2C%20K.P.%20Fairness%20constraints%3A%20Mechanisms%20for%20fair%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20M.B.%20Valera%2C%20I.%20Rogriguez%2C%20M.G.%20Gummadi%2C%20K.P.%20Fairness%20constraints%3A%20Mechanisms%20for%20fair%20classification%202017"
        },
        {
            "id": "27",
            "entry": "[27] J. Zhang and E. Bareinboim. Equality of opportunity in classification: A causal approach. Technical Report R-37, AI Lab, Purdue University., 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20J.%20Bareinboim%2C%20E.%20Equality%20of%20opportunity%20in%20classification%3A%20A%20causal%20approach%202018"
        },
        {
            "id": "28",
            "entry": "[28] J. Zhang and E. Bareinboim. Fairness in decision-making \u2014 the causal explanation formula. In Proceedings of AAAI Conference on Artificial Intelligence, pages 2037\u20132045, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20J.%20Bareinboim%2C%20E.%20Fairness%20in%20decision-making%20%E2%80%94%20the%20causal%20explanation%20formula%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20J.%20Bareinboim%2C%20E.%20Fairness%20in%20decision-making%20%E2%80%94%20the%20causal%20explanation%20formula%202018"
        },
        {
            "id": "29",
            "entry": "[29] J. Zhang and E. Bareinboim. Non-parametric path analysis in structural causal models. In Proceedings of the 34th Conference on Uncertainty in Artificial Intelligence, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20J.%20Bareinboim%2C%20E.%20Non-parametric%20path%20analysis%20in%20structural%20causal%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20J.%20Bareinboim%2C%20E.%20Non-parametric%20path%20analysis%20in%20structural%20causal%20models%202018"
        }
    ]
}
