{
    "filename": "8048-the-promises-and-pitfalls-of-stochastic-gradient-langevin-dynamics.pdf",
    "metadata": {
        "title": "The promises and pitfalls of Stochastic Gradient Langevin Dynamics",
        "author": "Nicolas Brosse, Alain Durmus, Eric Moulines",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8048-the-promises-and-pitfalls-of-stochastic-gradient-langevin-dynamics.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Stochastic Gradient Langevin Dynamics (SGLD) has emerged as a key MCMC algorithm for Bayesian learning from large scale datasets. While SGLD with decreasing step sizes converges weakly to the posterior distribution, the algorithm is often used with a constant step size in practice and has demonstrated successes in machine learning tasks. The current practice is to set the step size inversely proportional to N where N is the number of training samples. As N becomes large, we show that the SGLD algorithm has an invariant probability measure which significantly departs from the target posterior and behaves like Stochastic Gradient Descent (SGD). This difference is inherently due to the high variance of the stochastic gradients. Several strategies have been suggested to reduce this effect; among them, SGLD Fixed Point (SGLDFP) uses carefully designed control variates to reduce the variance of the stochastic gradients. We show that SGLDFP gives approximate samples from the posterior distribution, with an accuracy comparable to the Langevin Monte Carlo (LMC) algorithm for a computational cost sublinear in the number of data points. We provide a detailed analysis of the Wasserstein distances between LMC, SGLD, SGLDFP and SGD and explicit expressions of the means and covariance matrices of their invariant distributions. Our findings are supported by limited numerical experiments."
    },
    "keywords": [
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "posterior distribution",
            "url": "https://en.wikipedia.org/wiki/posterior_distribution"
        },
        {
            "term": "monte carlo",
            "url": "https://en.wikipedia.org/wiki/monte_carlo"
        },
        {
            "term": "MCMC",
            "url": "https://en.wikipedia.org/wiki/MCMC"
        },
        {
            "term": "computational cost",
            "url": "https://en.wikipedia.org/wiki/computational_cost"
        },
        {
            "term": "variance reduction",
            "url": "https://en.wikipedia.org/wiki/variance_reduction"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        }
    ],
    "highlights": [
        "Most MCMC algorithms have not been designed to process huge sample sizes, a typical setting in machine learning",
        "We provide further insights on the links between stochastic gradient langevin dynamics, SGLD Fixed Point, Langevin Monte Carlo and Stochastic Gradient Descent (Stochastic Gradient Descent)",
        "In Section 3.1, we give an upper bound in Wasserstein distance of order 2 between the marginal distribution of the iterates of Langevin Monte Carlo and the Langevin diffusion, SGLD Fixed Point and Langevin Monte Carlo, and stochastic gradient langevin dynamics and Stochastic Gradient Descent",
        "We provide a lower bound on the Wasserstein distance between the marginal distribution of the iterates of SGLD Fixed Point and stochastic gradient langevin dynamics",
        "The study in Wasserstein distance emphasizes the different behaviors of the Langevin Monte Carlo, SGLD Fixed Point, stochastic gradient langevin dynamics and Stochastic Gradient Descent algorithms",
        "Assuming that m is proportional to N and N \u2265 1/\u03b7, we show by combining Proposition 5 and Theorem 7 that the biases and covariance matrices of stochastic gradient langevin dynamics and Stochastic Gradient Descent are of order \u0398(\u03b7) with remainder terms of the form O(\u03b73/2) when \u03b7 \u2192 0"
    ],
    "key_statements": [
        "Most MCMC algorithms have not been designed to process huge sample sizes, a typical setting in machine learning",
        "Many classical MCMC methods fail in this context, because the mixing time becomes prohibitively long and the cost per iteration increases proportionally to the number of training samples N",
        "We provide further insights on the links between stochastic gradient langevin dynamics, SGLD Fixed Point, Langevin Monte Carlo and Stochastic Gradient Descent (Stochastic Gradient Descent)",
        "In Section 3.1, we give an upper bound in Wasserstein distance of order 2 between the marginal distribution of the iterates of Langevin Monte Carlo and the Langevin diffusion, SGLD Fixed Point and Langevin Monte Carlo, and stochastic gradient langevin dynamics and Stochastic Gradient Descent",
        "We provide a lower bound on the Wasserstein distance between the marginal distribution of the iterates of SGLD Fixed Point and stochastic gradient langevin dynamics",
        "The theoretical analysis and the bounds remain unchanged if, instead of considering SGLD Fixed Point centered w.r.t. \u03b8 , we study SGLD Fixed Point centered w.r.t. \u03b8satisfying E[ \u03b8 \u2212 \u03b8 2] = O(1/N )",
        "Theorem 2 implies that the number of iterations necessary to obtain a sample \u03b5-close from \u03c0 in Wasserstein distance is the same for Langevin Monte Carlo and SGLD Fixed Point",
        "The study in Wasserstein distance emphasizes the different behaviors of the Langevin Monte Carlo, SGLD Fixed Point, stochastic gradient langevin dynamics and Stochastic Gradient Descent algorithms",
        "The marginal distributions of the kth iterates of stochastic gradient langevin dynamics and Stochastic Gradient Descent are analogous and their invariant probability measures \u03c0SGLD and \u03c0SGD are very different from \u03c0 when N \u2192 +\u221e",
        "For Langevin Monte Carlo and SGLD Fixed Point, we assume that limN\u2192+\u221e m/N > 0, \u03b3 = \u03b7/N , for \u03b7 > 0, and we develop an asymptotic when N \u2192 +\u221e",
        "Assuming that m is proportional to N and N \u2265 1/\u03b7, we show by combining Proposition 5 and Theorem 7 that the biases and covariance matrices of stochastic gradient langevin dynamics and Stochastic Gradient Descent are of order \u0398(\u03b7) with remainder terms of the form O(\u03b73/2) when \u03b7 \u2192 0",
        "The step size \u03b3 is set equal to 1/N and the trajectories are started at \u03b8, an estimator of \u03b8 , computed using Stochastic Gradient Descent combined with the BFGS algorithm"
    ],
    "summary": [
        "Most MCMC algorithms have not been designed to process huge sample sizes, a typical setting in machine learning.",
        "We provide further insights on the links between SGLD, SGLDFP, LMC and SGD (Stochastic Gradient Descent).",
        "In Section 3.1, we give an upper bound in Wasserstein distance of order 2 between the marginal distribution of the iterates of LMC and the Langevin diffusion, SGLDFP and LMC, and SGLD and SGD.",
        "We provide a lower bound on the Wasserstein distance between the marginal distribution of the iterates of SGLDFP and SGLD.",
        "In Section 3.2, we give a comparison of the means and covariance matrices of the invariant distributions of LMC, SGLDFP and SGLD with those of the target distribution \u03c0.",
        "Theorem 2 implies that the number of iterations necessary to obtain a sample \u03b5-close from \u03c0 in Wasserstein distance is the same for LMC and SGLDFP.",
        "The following theorem shows that the Wasserstein distances between the marginal distribution of the iterates of SGLD and SGLDFP, and \u03c0SGLD and \u03c0, is of order \u03a9(1) when N \u2192 +\u221e.",
        "The study in Wasserstein distance emphasizes the different behaviors of the LMC, SGLDFP, SGLD and SGD algorithms.",
        "When N \u2192 \u221e and limN\u2192+\u221e m/N > 0, the marginal distributions of the kth iterates of the LMC and SGLDFP algorithm are very close to the Langevin diffusion and their invariant probability measures \u03c0LMC and \u03c0FP are similar to the posterior distribution of interest \u03c0.",
        "The marginal distributions of the kth iterates of SGLD and SGD are analogous and their invariant probability measures \u03c0SGLD and \u03c0SGD are very different from \u03c0 when N \u2192 +\u221e.",
        "Assuming that m is proportional to N and N \u2265 1/\u03b7, we show by combining Proposition 5 and Theorem 7 that the biases and covariance matrices of SGLD and SGD are of order \u0398(\u03b7) with remainder terms of the form O(\u03b73/2) when \u03b7 \u2192 0.",
        "For the LMC, SGLDFP, SGLD and SGD algorithms, the step size \u03b3 is set equal to (1 + \u03b4/4)\u22121 where \u03b4 is the largest eigenvalue of XTX.",
        "The step size \u03b3 is set equal to 1/N and the trajectories are started at \u03b8, an estimator of \u03b8 , computed using SGD combined with the BFGS algorithm.",
        "We empirically check that the variance of the stochastic gradients scale as N 2 for SGD and SGLD, and as N for SGLDFP."
    ],
    "headline": "As N becomes large, we show that the stochastic gradient langevin dynamics algorithm has an invariant probability measure which significantly departs from the target posterior and behaves like Stochastic Gradient Descent ",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] S. Ahn, A. K. Balan, and M. Welling. Bayesian posterior sampling via stochastic gradient Fisher scoring. In Proceedings of the 29th International Conference on Machine Learning, ICML 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahn%2C%20S.%20Balan%2C%20A.K.%20Welling%2C%20M.%20Bayesian%20posterior%20sampling%20via%20stochastic%20gradient%20Fisher%20scoring%202012-06-26",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahn%2C%20S.%20Balan%2C%20A.K.%20Welling%2C%20M.%20Bayesian%20posterior%20sampling%20via%20stochastic%20gradient%20Fisher%20scoring%202012-06-26"
        },
        {
            "id": "2",
            "entry": "[2] S. Ahn, B. Shahbaba, and M. Welling. Distributed stochastic gradient MCMC. In E. P. Xing and T. Jebara, editors, Proceedings of the 31st International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning Research, pages 1044\u20131052, Bejing, China, 22\u201324 Jun 2014. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahn%2C%20S.%20Shahbaba%2C%20B.%20Welling%2C%20M.%20Distributed%20stochastic%20gradient%20MCMC%202014-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahn%2C%20S.%20Shahbaba%2C%20B.%20Welling%2C%20M.%20Distributed%20stochastic%20gradient%20MCMC%202014-06"
        },
        {
            "id": "3",
            "entry": "[3] J. Baker, P. Fearnhead, E. B. Fox, and C. Nemeth. Control variates for stochastic gradient MCMC. ArXiv e-prints 1706.05439, June 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.05439"
        },
        {
            "id": "4",
            "entry": "[4] R. Bardenet, A. Doucet, and C. Holmes. On Markov chain Monte Carlo methods for tall data. Journal of Machine Learning Research, 18(47):1\u201343, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bardenet%2C%20R.%20Doucet%2C%20A.%20Holmes%2C%20C.%20On%20Markov%20chain%20Monte%20Carlo%20methods%20for%20tall%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bardenet%2C%20R.%20Doucet%2C%20A.%20Holmes%2C%20C.%20On%20Markov%20chain%20Monte%20Carlo%20methods%20for%20tall%20data%202017"
        },
        {
            "id": "5",
            "entry": "[5] N. S. Chatterji, N. Flammarion, Y.-A. Ma, P. L. Bartlett, and M. I. Jordan. On the theory of variance reduction for stochastic gradient Monte Carlo. ArXiv e-prints 1802.05431, Feb. 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05431"
        },
        {
            "id": "6",
            "entry": "[6] C. Chen, N. Ding, and L. Carin. On the convergence of Stochastic Gradient MCMC algorithms with high-order integrators. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2278\u20132286. Curran Associates, Inc., 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20C.%20Ding%2C%20N.%20Carin%2C%20L.%20On%20the%20convergence%20of%20Stochastic%20Gradient%20MCMC%20algorithms%20with%20high-order%20integrators%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20C.%20Ding%2C%20N.%20Carin%2C%20L.%20On%20the%20convergence%20of%20Stochastic%20Gradient%20MCMC%20algorithms%20with%20high-order%20integrators%202015"
        },
        {
            "id": "7",
            "entry": "[7] C. Chen, W. Wang, Y. Zhang, Q. Su, and L. Carin. A convergence analysis for a class of practical variance-reduction stochastic gradient MCMC. ArXiv e-prints 1709.01180, Sept. 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.01180"
        },
        {
            "id": "8",
            "entry": "[8] T. Chen, E. Fox, and C. Guestrin. Stochastic gradient hamiltonian Monte Carlo. In Proceedings of the 31st International Conference on Machine Learning, pages 1683\u20131691, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20T.%20Fox%2C%20E.%20Guestrin%2C%20C.%20Stochastic%20gradient%20hamiltonian%20Monte%20Carlo%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20T.%20Fox%2C%20E.%20Guestrin%2C%20C.%20Stochastic%20gradient%20hamiltonian%20Monte%20Carlo%202014"
        },
        {
            "id": "9",
            "entry": "[9] A. Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave densities. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79(3): 651\u2013676, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dalalyan%2C%20A.%20Theoretical%20guarantees%20for%20approximate%20sampling%20from%20smooth%20and%20log-concave%20densities%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dalalyan%2C%20A.%20Theoretical%20guarantees%20for%20approximate%20sampling%20from%20smooth%20and%20log-concave%20densities%202017"
        },
        {
            "id": "10",
            "entry": "[10] A. Dalalyan. Further and stronger analogy between sampling and optimization: Langevin Monte Carlo and gradient descent. In S. Kale and O. Shamir, editors, Proceedings of the 2017 Conference on Learning Theory, volume 65 of Proceedings of Machine Learning Research, pages 678\u2013689, Amsterdam, Netherlands, 07\u201310 Jul 2017. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dalalyan%2C%20A.%20Further%20and%20stronger%20analogy%20between%20sampling%20and%20optimization%3A%20Langevin%20Monte%20Carlo%20and%20gradient%20descent%202017-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dalalyan%2C%20A.%20Further%20and%20stronger%20analogy%20between%20sampling%20and%20optimization%3A%20Langevin%20Monte%20Carlo%20and%20gradient%20descent%202017-07"
        },
        {
            "id": "11",
            "entry": "[11] A. S. Dalalyan and A. G. Karagulyan. User-friendly guarantees for the Langevin Monte Carlo with inaccurate gradient. ArXiv e-prints 1710.00095, Sept. 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.00095"
        },
        {
            "id": "12",
            "entry": "[12] N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, and H. Neven. Bayesian sampling using stochastic gradient thermostats. In Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2, NIPS\u201914, pages 3203\u20133211, Cambridge, MA, USA, 2014. MIT Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ding%2C%20N.%20Fang%2C%20Y.%20Babbush%2C%20R.%20Chen%2C%20C.%20Bayesian%20sampling%20using%20stochastic%20gradient%20thermostats%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ding%2C%20N.%20Fang%2C%20Y.%20Babbush%2C%20R.%20Chen%2C%20C.%20Bayesian%20sampling%20using%20stochastic%20gradient%20thermostats%202014"
        },
        {
            "id": "13",
            "entry": "[13] K. A. Dubey, S. J. Reddi, S. A. Williamson, B. Poczos, A. J. Smola, and E. P. Xing. Variance reduction in stochastic gradient Langevin dynamics. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing Systems 29, pages 1154\u20131162. Curran Associates, Inc., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dubey%2C%20K.A.%20Reddi%2C%20S.J.%20Williamson%2C%20S.A.%20Poczos%2C%20B.%20Variance%20reduction%20in%20stochastic%20gradient%20Langevin%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dubey%2C%20K.A.%20Reddi%2C%20S.J.%20Williamson%2C%20S.A.%20Poczos%2C%20B.%20Variance%20reduction%20in%20stochastic%20gradient%20Langevin%20dynamics%202016"
        },
        {
            "id": "14",
            "entry": "[14] A. Durmus and E. Moulines. High-dimensional Bayesian inference via the unadjusted Langevin algorithm. ArXiv e-prints 1605.01559, May 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.01559"
        },
        {
            "id": "15",
            "entry": "[15] A. Durmus and E. Moulines. Nonasymptotic convergence analysis for the unadjusted Langevin algorithm. Ann. Appl. Probab., 27(3):1551\u20131587, 06 2017. doi: 10.1214/16-AAP1238.",
            "crossref": "https://dx.doi.org/10.1214/16-AAP1238",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1214/16-AAP1238"
        },
        {
            "id": "16",
            "entry": "[16] U. Grenander. Tutorial in pattern theory. Division of Applied Mathematics, Brown University, Providence, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grenander%2C%20U.%20Tutorial%20in%20pattern%20theory%201983",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grenander%2C%20U.%20Tutorial%20in%20pattern%20theory%201983"
        },
        {
            "id": "17",
            "entry": "[17] U. Grenander and M. I. Miller. Representations of knowledge in complex systems. J. Roy. Statist. Soc. Ser. B, 56(4):549\u2013603, 1994. ISSN 0035-9246. With discussion and a reply by the authors.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grenander%2C%20U.%20Miller%2C%20M.I.%20Representations%20of%20knowledge%20in%20complex%20systems%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grenander%2C%20U.%20Miller%2C%20M.I.%20Representations%20of%20knowledge%20in%20complex%20systems%201994"
        },
        {
            "id": "18",
            "entry": "[18] L. Hasenclever, S. Webb, T. Lienart, S. Vollmer, B. Lakshminarayanan, C. Blundell, and Y. W. Teh. Distributed Bayesian learning with stochastic natural gradient expectation propagation and the posterior server. Journal of Machine Learning Research, 18(106):1\u201337, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hasenclever%2C%20L.%20Webb%2C%20S.%20Lienart%2C%20T.%20Vollmer%2C%20S.%20Distributed%20Bayesian%20learning%20with%20stochastic%20natural%20gradient%20expectation%20propagation%20and%20the%20posterior%20server%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hasenclever%2C%20L.%20Webb%2C%20S.%20Lienart%2C%20T.%20Vollmer%2C%20S.%20Distributed%20Bayesian%20learning%20with%20stochastic%20natural%20gradient%20expectation%20propagation%20and%20the%20posterior%20server%202017"
        },
        {
            "id": "19",
            "entry": "[19] E. Jones, T. Oliphant, P. Peterson, et al. SciPy: Open source scientific tools for Python, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=E%20Jones%20T%20Oliphant%20P%20Peterson%20et%20al%20SciPy%20Open%20source%20scientific%20tools%20for%20Python%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=E%20Jones%20T%20Oliphant%20P%20Peterson%20et%20al%20SciPy%20Open%20source%20scientific%20tools%20for%20Python%202001"
        },
        {
            "id": "20",
            "entry": "[20] I. Karatzas and S. Shreve. Brownian motion and stochastic calculus. Graduate Texts in Mathematics. Springer New York, 1991. ISBN 9780387976556.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karatzas%2C%20I.%20Shreve%2C%20S.%20Brownian%20motion%20and%20stochastic%20calculus.%20Graduate%20Texts%20in%20Mathematics%201991"
        },
        {
            "id": "21",
            "entry": "[21] A. Korattikara, Y. Chen, and M. Welling. Austerity in MCMC land: cutting the Metropolishastings budget. In Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32, ICML\u201914, pages I\u2013181\u2013I\u2013189. JMLR.org, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Korattikara%2C%20A.%20Chen%2C%20Y.%20Welling%2C%20M.%20Austerity%20in%20MCMC%20land%3A%20cutting%20the%20Metropolishastings%20budget%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Korattikara%2C%20A.%20Chen%2C%20Y.%20Welling%2C%20M.%20Austerity%20in%20MCMC%20land%3A%20cutting%20the%20Metropolishastings%20budget%202014"
        },
        {
            "id": "22",
            "entry": "[22] C. Li, C. Chen, D. Carlson, and L. Carin. Preconditioned stochastic gradient Langevin dynamics for deep neural networks. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI\u201916, pages 1788\u20131794. AAAI Press, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20C.%20Chen%2C%20C.%20Carlson%2C%20D.%20Carin%2C%20L.%20Preconditioned%20stochastic%20gradient%20Langevin%20dynamics%20for%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20C.%20Chen%2C%20C.%20Carlson%2C%20D.%20Carin%2C%20L.%20Preconditioned%20stochastic%20gradient%20Langevin%20dynamics%20for%20deep%20neural%20networks%202016"
        },
        {
            "id": "23",
            "entry": "[23] W. Li, S. Ahn, and M. Welling. Scalable MCMC for mixed membership stochastic blockmodels. In Artificial Intelligence and Statistics, pages 723\u2013731, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20W.%20Ahn%2C%20S.%20Welling%2C%20M.%20Scalable%20MCMC%20for%20mixed%20membership%20stochastic%20blockmodels%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20W.%20Ahn%2C%20S.%20Welling%2C%20M.%20Scalable%20MCMC%20for%20mixed%20membership%20stochastic%20blockmodels%202016"
        },
        {
            "id": "24",
            "entry": "[24] Y.-A. Ma, T. Chen, and E. Fox. A complete recipe for stochastic gradient MCMC. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2917\u20132925. Curran Associates, Inc., 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Y.-A.%20Chen%2C%20T.%20Fox%2C%20E.%20A%20complete%20recipe%20for%20stochastic%20gradient%20MCMC%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Y.-A.%20Chen%2C%20T.%20Fox%2C%20E.%20A%20complete%20recipe%20for%20stochastic%20gradient%20MCMC%202015"
        },
        {
            "id": "25",
            "entry": "[25] T. Nagapetyan, A. B. Duncan, L. Hasenclever, S. J. Vollmer, L. Szpruch, and K. Zygalakis. The true cost of stochastic gradient Langevin dynamics. ArXiv e-prints 1706.02692, June 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.02692"
        },
        {
            "id": "26",
            "entry": "[26] A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574\u20131609, 2009. doi: 10.1137/070704277.",
            "crossref": "https://dx.doi.org/10.1137/070704277",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1137/070704277"
        },
        {
            "id": "27",
            "entry": "[27] S. Patterson and Y. W. Teh. Stochastic gradient riemannian Langevin dynamics on the probability simplex. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 3102\u20133110. Curran Associates, Inc., 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Patterson%2C%20S.%20Teh%2C%20Y.W.%20Stochastic%20gradient%20riemannian%20Langevin%20dynamics%20on%20the%20probability%20simplex%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Patterson%2C%20S.%20Teh%2C%20Y.W.%20Stochastic%20gradient%20riemannian%20Langevin%20dynamics%20on%20the%20probability%20simplex%202013"
        },
        {
            "id": "28",
            "entry": "[28] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pedregosa%2C%20F.%20Varoquaux%2C%20G.%20Gramfort%2C%20A.%20Michel%2C%20V.%20Scikit-learn%3A%20Machine%20learning%20in%20Python%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pedregosa%2C%20F.%20Varoquaux%2C%20G.%20Gramfort%2C%20A.%20Michel%2C%20V.%20Scikit-learn%3A%20Machine%20learning%20in%20Python%202011"
        },
        {
            "id": "29",
            "entry": "[29] G. O. Roberts and R. L. Tweedie. Exponential convergence of Langevin distributions and their discrete approximations. Bernoulli, 2(4):341\u2013363, 1996. ISSN 1350-7265. doi: 10.2307/ 3318418.",
            "crossref": "https://dx.doi.org/10.2307/3318418",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.2307/3318418"
        },
        {
            "id": "30",
            "entry": "[30] I. Sato and H. Nakagawa. Approximation analysis of stochastic gradient Langevin dynamics by using Fokker-Planck equation and Ito process. In E. P. Xing and T. Jebara, editors, Proceedings of the 31st International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning Research, pages 982\u2013990, Bejing, China, 22\u201324 Jun 2014. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sato%2C%20I.%20Nakagawa%2C%20H.%20Approximation%20analysis%20of%20stochastic%20gradient%20Langevin%20dynamics%20by%20using%20Fokker-Planck%20equation%20and%20Ito%20process%202014-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sato%2C%20I.%20Nakagawa%2C%20H.%20Approximation%20analysis%20of%20stochastic%20gradient%20Langevin%20dynamics%20by%20using%20Fokker-Planck%20equation%20and%20Ito%20process%202014-06"
        },
        {
            "id": "31",
            "entry": "[31] Y. W. Teh, A. H. Thiery, and S. J. Vollmer. Consistency and fluctuations for stochastic gradient Langevin dynamics. The Journal of Machine Learning Research, 17(1):193\u2013225, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Teh%2C%20Y.W.%20Thiery%2C%20A.H.%20Vollmer%2C%20S.J.%20Consistency%20and%20fluctuations%20for%20stochastic%20gradient%20Langevin%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Teh%2C%20Y.W.%20Thiery%2C%20A.H.%20Vollmer%2C%20S.J.%20Consistency%20and%20fluctuations%20for%20stochastic%20gradient%20Langevin%20dynamics%202016"
        },
        {
            "id": "32",
            "entry": "[32] S. J. Vollmer, K. C. Zygalakis, and Y. W. Teh. Exploration of the (non-)asymptotic bias and variance of stochastic gradient Langevin dynamics. Journal of Machine Learning Research, 17 (159):1\u201348, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vollmer%2C%20S.J.%20Zygalakis%2C%20K.C.%20Teh%2C%20Y.W.%20Exploration%20of%20the%20%28non-%29asymptotic%20bias%20and%20variance%20of%20stochastic%20gradient%20Langevin%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vollmer%2C%20S.J.%20Zygalakis%2C%20K.C.%20Teh%2C%20Y.W.%20Exploration%20of%20the%20%28non-%29asymptotic%20bias%20and%20variance%20of%20stochastic%20gradient%20Langevin%20dynamics%202016"
        },
        {
            "id": "33",
            "entry": "[33] M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML\u201911, pages 681\u2013688, USA, 2011. Omnipress. ISBN 978-1-4503-0619-5. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Welling%2C%20M.%20Teh%2C%20Y.W.%20Bayesian%20learning%20via%20stochastic%20gradient%20Langevin%20dynamics%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Welling%2C%20M.%20Teh%2C%20Y.W.%20Bayesian%20learning%20via%20stochastic%20gradient%20Langevin%20dynamics%202011"
        }
    ]
}
