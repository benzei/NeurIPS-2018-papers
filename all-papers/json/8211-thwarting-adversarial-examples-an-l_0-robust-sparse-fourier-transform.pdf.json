{
    "filename": "8211-thwarting-adversarial-examples-an-l_0-robust-sparse-fourier-transform.pdf",
    "metadata": {
        "title": "Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform",
        "author": "Mitali Bafna, Jack Murtagh, Nikhil Vyas",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8211-thwarting-adversarial-examples-an-l_0-robust-sparse-fourier-transform.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We give a new algorithm for approximating the Discrete Fourier transform of an approximately sparse signal that is robust to worst-case L0 corruptions, namely that a bounded number of coordinates of the signal can be corrupted arbitrarily. Our techniques generalize to a wide range of linear transformations that are used in data analysis such as the Discrete Cosine and Sine transforms, the Hadamard transform, and their high-dimensional analogs. We use our algorithm to successfully defend against worst-case L0 adversaries in the setting of image classification. We give experimental results on the Jacobian-based Saliency Map Attack (JSMA) and the Carlini Wagner (CW) L0 attack on the MNIST and Fashion-MNIST datasets as well as the Adversarial Patch on the ImageNet dataset."
    },
    "keywords": [
        {
            "term": "MNIST",
            "url": "https://en.wikipedia.org/wiki/MNIST"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "compressed sensing",
            "url": "https://en.wikipedia.org/wiki/compressed_sensing"
        },
        {
            "term": "image classification",
            "url": "https://en.wikipedia.org/wiki/image_classification"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "linear time",
            "url": "https://en.wikipedia.org/wiki/linear_time"
        },
        {
            "term": "Discrete Cosine transform",
            "url": "https://en.wikipedia.org/wiki/Discrete_Cosine_Transform"
        },
        {
            "term": "compressive sensing",
            "url": "https://en.wikipedia.org/wiki/compressive_sensing"
        },
        {
            "term": "Discrete Fourier transform",
            "url": "https://en.wikipedia.org/wiki/Discrete_Fourier_transform"
        }
    ],
    "highlights": [
        "In the last several years, neural networks have made unprecedented achievements on computational learning tasks like image classification",
        "Neural networks have been shown to be brittle in the presence of adversarial noise [SZS+13]",
        "As deep learning becomes more integrated into our everyday technology, the need for systems that are robust to adversarial noise grows, especially in applications to security",
        "In Section 4, we evaluate our framework on three leading L0 attacks in the literature: the Jacobian-based Saliency Map Attack attack of Papernot et al [PMJ+15], the L0 attack from Carlini and Wagner (CW) [CW16], and the adversarial patch from Brown et al [BMR+17]",
        "Our focus is on recovering xh(k) when some of the measurements might be corrupted and we show a tight tradeoff between the number of measurements corrupted versus the quality of recovery we can ensure",
        "We evaluated our framework on three leading L0 attacks in the literature: the Jacobian-based Saliency Map Attack Attack of Papernot et al [PMJ+15], the L0 attack from Carlini and Wagner (CW) [CW16], and the adversarial patch from Brown et al [BMR+17]"
    ],
    "key_statements": [
        "In the last several years, neural networks have made unprecedented achievements on computational learning tasks like image classification",
        "Neural networks have been shown to be brittle in the presence of adversarial noise [SZS+13]",
        "Many effective attacks have been proposed in the context of computer vision that reliably generate small perturbations to input images that drastically change the network\u2019s classification of the image [MFF15, GSS15, CW16]",
        "As deep learning becomes more integrated into our everyday technology, the need for systems that are robust to adversarial noise grows, especially in applications to security",
        "We provide a much more general framework for building L0-robust sparse transformations that applies to many transformations used in practice such as all discrete variants of the Fourier transform, the Sine and Cosine Transforms, the Hadamard transform, and their higher-dimensional generalizations",
        "In Section 4, we evaluate our framework on three leading L0 attacks in the literature: the Jacobian-based Saliency Map Attack attack of Papernot et al [PMJ+15], the L0 attack from Carlini and Wagner (CW) [CW16], and the adversarial patch from Brown et al [BMR+17]",
        "Our focus is on recovering xh(k) when some of the measurements might be corrupted and we show a tight tradeoff between the number of measurements corrupted versus the quality of recovery we can ensure",
        "Our Techniques: Our main result uses techniques from the field of compressed sensing (CS) [CRT06, BCDH10] and properties of Fourier matrices. Using these we prove that Algorithm 1 converges to a good solution to Problem 2.1, where by a good solution we mean that it is close to the true solution in the L\u221e norm",
        "We model images as approximately k-sparse vectors in the 2D-Discrete Cosine transform domain",
        "Our correction algorithm does not depend on the magnitude of the corruptions, only their number (t). Both the training of the neural network on compressed images and the correction algorithm are essential to our framework.\n2.3",
        "We evaluated our framework on three leading L0 attacks in the literature: the Jacobian-based Saliency Map Attack Attack of Papernot et al [PMJ+15], the L0 attack from Carlini and Wagner (CW) [CW16], and the adversarial patch from Brown et al [BMR+17]",
        "We evaluated Algorithm 1 on the Jacobian-based Saliency Map Attack and Carlini and Wagner attacks and present these results",
        "For example when the adversary corrupts 30 bits, it is able to drop the accuracy of our network on the Fashion-MNIST dataset from 88.5% to 24.8% but after running our recovery algorithm we get back up to 83.1%",
        "For images that are too large to be sparse in Fourier bases, the block-wise approach may fail in the case where most of the L0 noise resides in few blocks because in these blocks there will be too many corrupted coordinates to recover",
        "We are able to use the contiguity of the noise with the mild sparsity of large images by using Algorithm 2 to defend against the patch attack"
    ],
    "summary": [
        "In the last several years, neural networks have made unprecedented achievements on computational learning tasks like image classification.",
        "The guarantees of our algorithms hold for all adversaries that stay within the noise budget, given that the input signals are sparse in the Fourier or related domains.",
        "Our goal is to approximate the top-k Fourier coefficients of a vector x even after it has been corrupted with adversarial L0 noise.",
        "We model images as being approximately sparse in the Fourier domain and prove that in such approximately sparse signals, it is possible to recover from L0 budgeted adversaries.",
        "2. On adversarial input images we run our L0-robust DCT algorithm to recover the top-k coefficients.",
        "Needs our correction algorithm for L0-corrupted images, since a naive compression of an adversarial example will not get classified correctly by a neural network in general.",
        "Both the training of the neural network on compressed images and the correction algorithm are essential to our framework.",
        "Such an attack can be prevented by initializing the IHT algorithm with random vectors x[1], e[1] so that the resulting recovered image is not deterministic.",
        "Recall that in our main problem (Problem 2.1), we want to recover the top-k coefficients of x = F x, where xis approximately k-sparse, given a corrupted vector y = x + e.",
        "Model-Based CS was first introduced in [BCDH10], for general sparsity models, and they proved therein that Iterative Hard Thresholding (IHT) [BD08] converges to a good solution to Problem 3.1, given that the measurement matrix M satisfies RIP for the model.",
        "In [BCDH10], they proved that the IHT algorithm converges to an approximately correct solution, given that the measurement matrix M satisfies the RIP for the model at hand.",
        "For example when the adversary corrupts 30 bits, it is able to drop the accuracy of our network on the Fashion-MNIST dataset from 88.5% to 24.8% but after running our recovery algorithm we get back up to 83.1%.",
        "For images that are too large to be sparse in Fourier bases, the block-wise approach may fail in the case where most of the L0 noise resides in few blocks because in these blocks there will be too many corrupted coordinates to recover.",
        "We show that even in this extreme case our framework for L0-robust sparse transformations can be used to guard against contiguous noise attacks even in large images.",
        "We are able to use the contiguity of the noise with the mild sparsity of large images by using Algorithm 2 to defend against the patch attack."
    ],
    "headline": "We show how to recover top coefficients of an approximately sparse signal that has been corrupted by worst-case L0 noise",
    "reference_links": [
        {
            "id": "Baraniuk_et+al_1982_a",
            "entry": "[BCDH10] Richard G. Baraniuk, Volkan Cevher, Marco F. Duarte, and Chinmay Hegde. Modelbased compressive sensing. IEEE Trans. Information Theory, 56(4):1982\u20132001, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baraniuk%2C%20Richard%20G.%20Cevher%2C%20Volkan%20Duarte%2C%20Marco%20F.%20and%20Chinmay%20Hegde.%20Modelbased%20compressive%20sensing%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baraniuk%2C%20Richard%20G.%20Cevher%2C%20Volkan%20Duarte%2C%20Marco%20F.%20and%20Chinmay%20Hegde.%20Modelbased%20compressive%20sensing%201982"
        },
        {
            "id": "Blumensath_2008_a",
            "entry": "[BD08] Thomas Blumensath and Mike E. Davies. Iterative hard thresholding for compressed sensing. CoRR, abs/0805.0510, 2008.",
            "arxiv_url": "https://arxiv.org/pdf/0805.0510"
        },
        {
            "id": "Backurs_et+al_2017_a",
            "entry": "[BIS17] Arturs Backurs, Piotr Indyk, and Ludwig Schmidt. Better approximations for tree sparsity in nearly-linear time. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2017, Barcelona, Spain, Hotel Porta Fira, January 16-19, pages 2215\u20132229, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Backurs%2C%20Arturs%20Indyk%2C%20Piotr%20Schmidt%2C%20Ludwig%20Better%20approximations%20for%20tree%20sparsity%20in%20nearly-linear%20time%202017-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Backurs%2C%20Arturs%20Indyk%2C%20Piotr%20Schmidt%2C%20Ludwig%20Better%20approximations%20for%20tree%20sparsity%20in%20nearly-linear%20time%202017-01"
        },
        {
            "id": "Brown_et+al_2017_a",
            "entry": "[BMR+17] Tom B. Brown, Dandelion Man\u00e9, Aurko Roy, Mart\u00edn Abadi, and Justin Gilmer. Adversarial patch. CoRR, abs/1712.09665, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.09665"
        },
        {
            "id": "Cand_et+al_2011_a",
            "entry": "[CLMW11] Emmanuel J. Cand\u00e8s, Xiaodong Li, Yi Ma, and John Wright. Robust principal component analysis? J. ACM, 58(3):11:1\u201311:37, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cand%C3%A8s%2C%20Emmanuel%20J.%20Li%2C%20Xiaodong%20Ma%2C%20Yi%20Wright%2C%20John%20Robust%20principal%20component%20analysis%3F%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cand%C3%A8s%2C%20Emmanuel%20J.%20Li%2C%20Xiaodong%20Ma%2C%20Yi%20Wright%2C%20John%20Robust%20principal%20component%20analysis%3F%202011"
        },
        {
            "id": "Cand_et+al_2006_a",
            "entry": "[CRT06] Emmanuel J. Cand\u00e8s, Justin K. Romberg, and Terence Tao. Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information. IEEE Trans. Information Theory, 52(2):489\u2013509, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cand%C3%A8s%2C%20Emmanuel%20J.%20Romberg%2C%20Justin%20K.%20Tao%2C%20Terence%20Robust%20uncertainty%20principles%3A%20exact%20signal%20reconstruction%20from%20highly%20incomplete%20frequency%20information%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cand%C3%A8s%2C%20Emmanuel%20J.%20Romberg%2C%20Justin%20K.%20Tao%2C%20Terence%20Robust%20uncertainty%20principles%3A%20exact%20signal%20reconstruction%20from%20highly%20incomplete%20frequency%20information%202006"
        },
        {
            "id": "Carlini_2016_a",
            "entry": "[CW16] Nicholas Carlini and David A. Wagner. Towards evaluating the robustness of neural networks. CoRR, abs/1608.04644, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.04644"
        },
        {
            "id": "Evtimov_et+al_2017_a",
            "entry": "[EEF+17] Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo Li, Atul Prakash, Amir Rahmati, and Dawn Song. Robust physical-world attacks on machine learning models. CoRR, abs/1707.08945, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.08945"
        },
        {
            "id": "Goodfellow_et+al_2015_a",
            "entry": "[GSS15] Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In International Conference on Learning Representations, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015"
        },
        {
            "id": "Hassanieh_et+al_2012_a",
            "entry": "[HIKP12a] Haitham Hassanieh, Piotr Indyk, Dina Katabi, and Eric Price. Nearly optimal sparse fourier transform. In Proceedings of the 44th Symposium on Theory of Computing Conference, STOC 2012, New York, NY, USA, May 19 - 22, 2012, pages 563\u2013578, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hassanieh%2C%20Haitham%20Indyk%2C%20Piotr%20Katabi%2C%20Dina%20Price%2C%20Eric%20Nearly%20optimal%20sparse%20fourier%20transform%202012-05-19",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hassanieh%2C%20Haitham%20Indyk%2C%20Piotr%20Katabi%2C%20Dina%20Price%2C%20Eric%20Nearly%20optimal%20sparse%20fourier%20transform%202012-05-19"
        },
        {
            "id": "Hassanieh_et+al_2012_b",
            "entry": "[HIKP12b] Haitham Hassanieh, Piotr Indyk, Dina Katabi, and Eric Price. Simple and practical algorithm for sparse fourier transform. In Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2012, Kyoto, Japan, January 17-19, 2012, pages 1183\u20131194, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hassanieh%2C%20Haitham%20Indyk%2C%20Piotr%20Katabi%2C%20Dina%20Price%2C%20Eric%20Simple%20and%20practical%20algorithm%20for%20sparse%20fourier%20transform%202012-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hassanieh%2C%20Haitham%20Indyk%2C%20Piotr%20Katabi%2C%20Dina%20Price%2C%20Eric%20Simple%20and%20practical%20algorithm%20for%20sparse%20fourier%20transform%202012-01"
        },
        {
            "id": "Hegde_et+al_2014_a",
            "entry": "[HIS14] Chinmay Hegde, Piotr Indyk, and Ludwig Schmidt. Nearly linear-time model-based compressive sensing. In Automata, Languages, and Programming - 41st International Colloquium, ICALP 2014, Copenhagen, Denmark, July 8-11, 2014, Proceedings, Part I, pages 588\u2013599, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hegde%2C%20Chinmay%20Indyk%2C%20Piotr%20Schmidt%2C%20Ludwig%20Nearly%20linear-time%20model-based%20compressive%20sensing%202014-07-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hegde%2C%20Chinmay%20Indyk%2C%20Piotr%20Schmidt%2C%20Ludwig%20Nearly%20linear-time%20model-based%20compressive%20sensing%202014-07-08"
        },
        {
            "id": "Hegde_et+al_2015_a",
            "entry": "[HIS15] Chinmay Hegde, Piotr Indyk, and Ludwig Schmidt. Approximation algorithms for model-based compressive sensing. IEEE Trans. Information Theory, 61(9):5129\u20135147, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hegde%2C%20Chinmay%20Indyk%2C%20Piotr%20Schmidt%2C%20Ludwig%20Approximation%20algorithms%20for%20model-based%20compressive%20sensing%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hegde%2C%20Chinmay%20Indyk%2C%20Piotr%20Schmidt%2C%20Ludwig%20Approximation%20algorithms%20for%20model-based%20compressive%20sensing%202015"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "[HZRS15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.03385"
        },
        {
            "id": "Ilyas_et+al_2017_a",
            "entry": "[IJA+17] Andrew Ilyas, Ajil Jalal, Eirini Asteri, Constantinos Daskalakis, and Alexandros G. Dimakis. The robust manifold defense: Adversarial training using generative models. CoRR, abs/1712.09196, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.09196"
        },
        {
            "id": "Indyk_2014_a",
            "entry": "[IKP14] Piotr Indyk, Michael Kapralov, and Eric Price. (nearly) sample-optimal sparse fourier transform. In Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2014, Portland, Oregon, USA, January 5-7, 2014, pages 480\u2013499, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Indyk%2C%20Piotr%20Kapralov%2C%20Michael%20and%20Eric%20Price.%20%28nearly%29%20sample-optimal%20sparse%20fourier%20transform%202014-01-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Indyk%2C%20Piotr%20Kapralov%2C%20Michael%20and%20Eric%20Price.%20%28nearly%29%20sample-optimal%20sparse%20fourier%20transform%202014-01-05"
        },
        {
            "id": "Lecun_1998_a",
            "entry": "[LeC98] Yann LeCun. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998.",
            "url": "http://yann.lecun.com/exdb/mnist/"
        },
        {
            "id": "Moosavi-Dezfooli_et+al_2015_a",
            "entry": "[MFF15] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and accurate method to fool deep neural networks. CoRR, abs/1511.04599, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.04599"
        },
        {
            "id": "Madry_et+al_2017_a",
            "entry": "[MMS+17] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. CoRR, abs/1706.06083, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.06083"
        },
        {
            "id": "[NT08]_2008_a",
            "entry": "[NT08] Deanna Needell and Joel A Tropp. Cosamp: Iterative signal recovery from incomplete and inaccurate samples. arXiv preprint arXiv:0803.2392, 2008.",
            "arxiv_url": "https://arxiv.org/pdf/0803.2392"
        },
        {
            "id": "Papernot_et+al_2015_a",
            "entry": "[PMJ+15] Nicolas Papernot, Patrick D. McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial settings. CoRR, abs/1511.07528, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.07528"
        },
        {
            "id": "Papernot_et+al_2016_a",
            "entry": "[PMW+16] Nicolas Papernot, Patrick D. McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami. Distillation as a defense to adversarial perturbations against deep neural networks. In IEEE Symposium on Security and Privacy, SP 2016, San Jose, CA, USA, May 22-26, 2016, pages 582\u2013597, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Papernot%2C%20Nicolas%20McDaniel%2C%20Patrick%20D.%20Wu%2C%20Xi%20Jha%2C%20Somesh%20Distillation%20as%20a%20defense%20to%20adversarial%20perturbations%20against%20deep%20neural%20networks%202016-05-22",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Papernot%2C%20Nicolas%20McDaniel%2C%20Patrick%20D.%20Wu%2C%20Xi%20Jha%2C%20Somesh%20Distillation%20as%20a%20defense%20to%20adversarial%20perturbations%20against%20deep%20neural%20networks%202016-05-22"
        },
        {
            "id": "Sharif_et+al_2016_a",
            "entry": "[SBBR16] Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, and Michael K Reiter. Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 1528\u20131540. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sharif%2C%20Mahmood%20Bhagavatula%2C%20Sruti%20Bauer%2C%20Lujo%20Reiter%2C%20Michael%20K.%20Accessorize%20to%20a%20crime%3A%20Real%20and%20stealthy%20attacks%20on%20state-of-the-art%20face%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sharif%2C%20Mahmood%20Bhagavatula%2C%20Sruti%20Bauer%2C%20Lujo%20Reiter%2C%20Michael%20K.%20Accessorize%20to%20a%20crime%3A%20Real%20and%20stealthy%20attacks%20on%20state-of-the-art%20face%20recognition%202016"
        },
        {
            "id": "Samangouei_et+al_2018_a",
            "entry": "[SKC18] Pouya Samangouei, Maya Kabkab, and Rama Chellappa. Defense-gan: Protecting classifiers against adversarial attacks using generative models. CoRR, abs/1805.06605, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.06605"
        },
        {
            "id": "Szegedy_et+al_2013_a",
            "entry": "[SZS+13] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. CoRR, abs/1312.6199, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6199"
        },
        {
            "id": "Tram_et+al_2017_a",
            "entry": "[TKP+17] Florian Tram\u00e8r, Alexey Kurakin, Nicolas Papernot, Dan Boneh, and Patrick McDaniel. Ensemble adversarial training: Attacks and defenses. arXiv preprint arXiv:1705.07204, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.07204"
        },
        {
            "id": "Xiao_et+al_2017_a",
            "entry": "[XRV17] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. CoRR, abs/1708.07747, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.07747"
        }
    ]
}
