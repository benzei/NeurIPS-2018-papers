{
    "filename": "7883-multi-view-silhouette-and-depth-decomposition-for-high-resolution-3d-object-representation.pdf",
    "metadata": {
        "title": "Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation",
        "author": "Edward Smith, Scott Fujimoto, David Meger",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7883-multi-view-silhouette-and-depth-decomposition-for-high-resolution-3d-object-representation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We consider the problem of scaling deep generative shape models to high-resolution. Drawing motivation from the canonical view representation of objects, we introduce a novel method for the fast up-sampling of 3D objects in voxel space through networks that perform super-resolution on the six orthographic depth projections. This allows us to generate high-resolution objects with more efficient scaling than methods which work directly in 3D. We decompose the problem of 2D depth super-resolution into silhouette and depth prediction to capture both structure and fine detail. This allows our method to generate sharp edges more easily than an individual network. We evaluate our work on multiple experiments concerning high-resolution 3D objects, and show our system is capable of accurately predicting novel objects at resolutions as large as 512\u00d7512\u00d7512 \u2013 the highest resolution reported for this task. We achieve state-of-the-art performance on 3D object reconstruction from RGB images on the ShapeNet dataset, and further demonstrate the first effective 3D super-resolution method."
    },
    "keywords": [
        {
            "term": "super resolution",
            "url": "https://en.wikipedia.org/wiki/super_resolution"
        }
    ],
    "highlights": [
        "The 3D shape of an object is a combination of countless physical elements that range in scale from gross structure and topology to minute textures endowed by the material of each surface",
        "We propose a novel approach for deep shape interpretation which captures the structure of an object via modeling of its canonical views in 2D as depth maps, in a framework we refer to as MultiView Decomposition (MVD)",
        "While we find that the silhouette prediction contributes far more to the intersection over union metric score, the addition of the depth variation network further increases the intersection over union metric score",
        "This is due to the silhouette capturing the gross structure of the object from multiple viewpoints, while the depth variation captures the fine-grained details, which contributes less to the total intersection over union metric score",
        "Additional 5123 renderings as well as multiple objects from each class at 2563 resolution can be found in our supplementary material.\n4.2 3D Object Reconstruction from RGB Images",
        "In this paper we argue for the application of multi-view representations when predicting the structure of objects at high resolution"
    ],
    "key_statements": [
        "The 3D shape of an object is a combination of countless physical elements that range in scale from gross structure and topology to minute textures endowed by the material of each surface",
        "We propose a novel approach for deep shape interpretation which captures the structure of an object via modeling of its canonical views in 2D as depth maps, in a framework we refer to as MultiView Decomposition (MVD)",
        "Our algorithm is a novel approach which uses the six axis-aligned orthographic depth maps (ODM), to efficiently scale 3D objects to high resolution without directly interacting with the voxels",
        "Evaluation We evaluate our method quantitatively using the intersection over union metric (IoU) against a simple baseline and the prediction of the individual networks on the test set",
        "Results The super-resolution intersection over union metric scores are presented in table 1",
        "While we find that the silhouette prediction contributes far more to the intersection over union metric score, the addition of the depth variation network further increases the intersection over union metric score",
        "This is due to the silhouette capturing the gross structure of the object from multiple viewpoints, while the depth variation captures the fine-grained details, which contributes less to the total intersection over union metric score",
        "Additional 5123 renderings as well as multiple objects from each class at 2563 resolution can be found in our supplementary material.\n4.2 3D Object Reconstruction from RGB Images",
        "Results The results of our intersection over union metric evaluation compared to the octree methods [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] can be seen in table 2",
        "In this paper we argue for the application of multi-view representations when predicting the structure of objects at high resolution"
    ],
    "summary": [
        "The 3D shape of an object is a combination of countless physical elements that range in scale from gross structure and topology to minute textures endowed by the material of each surface.",
        "By utilizing many 2D orthographic projections to capture shape, a model represented in this fashion can be up-scaled to high resolution by performing semantic super-resolution in 2D space, which leverages efficient, well-studied network structures and training procedures.",
        "\u4c00\u6f00\u7700 \u5200\u6500\u7300\u6f00\u6c00\u7500\u7400\u6900\u6f00\u6e00 \u4f00\u6200\u6a00\u6500\u6300\u7400",
        "Our algorithm is a novel approach which uses the six axis-aligned orthographic depth maps (ODM), to efficiently scale 3D objects to high resolution without directly interacting with the voxels.",
        "A pair of networks is used for each view, decomposing the super-resolution task into predicting the silhouette and relative depth from the low resolution ODM.",
        "Our Multi-View Decomposition framework (MVD) uses a set of twin of deep convolutional models fSIL and f\u2206D, to separately predict silhouette and variations in depth of the higher resolution ODM.",
        "The deep convolutional network for predicting the high-resolution silhouette, fSIL with parameters \u03b8, is passed the low resolution ODM DL, extracted from the input 3D object.",
        "We train our network f\u2206D by minimizing the mean squared error between our prediction and the ground truth high-resolution depth map DH .",
        "The output of the constrained depth map and silhouette networks are combined to produce a complete prediction for the high-resolution ODM.",
        "We present our results for our method, Multi-View Decomposition Networks (MVD), for both 3D object super-resolution and 3D object reconstruction from single RGB images.",
        "Figure 6: 3D object reconstruction 2563 rendering results from our method, MVD, of the 13 classes from ShapeNet, by interpreting 2D image input.",
        "From each object 1372 RGB images are rendered at random viewpoints, and we again compute their 323 and 2563 resolution voxelized models and ODMs. The data is split into a training, validation and test set with a ratio of 70:10:20.",
        "To study the effectiveness of our super-resolution pipeline, we compute the IoU scores using the low resolution objects predicted by our autoencoder (AE) with nearest neighbor up-sampling to produce predictions at 2563 resolution.",
        "We outline our Multi-View Decomposition framework, a novel system for learning to represent 3D objects and demonstrate its affinity for capturing category-specific shape details at a high resolution by operating over the six orthographic projections of the object.",
        "When applied to the reconstruction of high-resolution 3D objects from single RGB images, we outperform several state of the art methods with a variety of representation types, across two evaluation metrics."
    ],
    "headline": "Drawing motivation from the canonical view representation of objects, we introduce a novel method for the fast up-sampling of 3D objects in voxel space through networks that perform super-resolution on the six orthographic depth projections",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.03012"
        },
        {
            "id": "2",
            "entry": "[2] Ding-Yun Chen, Xiao-Pei Tian, Yu-Te Shen, and Ming Ouhyoung. On visual similarity based 3d model retrieval. In Computer graphics forum, volume 22, pages 223\u2013232. Wiley Online Library, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Ding-Yun%20Tian%2C%20Xiao-Pei%20Shen%2C%20Yu-Te%20Ouhyoung%2C%20Ming%20On%20visual%20similarity%20based%203d%20model%20retrieval%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Ding-Yun%20Tian%2C%20Xiao-Pei%20Shen%2C%20Yu-Te%20Ouhyoung%2C%20Ming%20On%20visual%20similarity%20based%203d%20model%20retrieval%202003"
        },
        {
            "id": "3",
            "entry": "[3] Christopher B Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, and Silvio Savarese. 3d-r2n2: A unified approach for single and multi-view 3d object reconstruction. In European Conference on Computer Vision, pages 628\u2013644.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choy%2C%20Christopher%20B.%20Xu%2C%20Danfei%20Gwak%2C%20JunYoung%20Chen%2C%20Kevin%203d-r2n2%3A%20A%20unified%20approach%20for%20single%20and%20multi-view%203d%20object%20reconstruction",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choy%2C%20Christopher%20B.%20Xu%2C%20Danfei%20Gwak%2C%20JunYoung%20Chen%2C%20Kevin%203d-r2n2%3A%20A%20unified%20approach%20for%20single%20and%20multi-view%203d%20object%20reconstruction"
        },
        {
            "id": "4",
            "entry": "[4] Trip Denton, M Fatih Demirci, Jeff Abrahamson, Ali Shokoufandeh, and Sven Dickinson. Selecting canonical views for view-based 3-d object recognition. In Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on, volume 2, pages 273\u2013276. IEEE, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Trip%20Denton%2C%20M.Fatih%20Demirci%20Abrahamson%2C%20Jeff%20Shokoufandeh%2C%20Ali%20Dickinson%2C%20Sven%20Selecting%20canonical%20views%20for%20view-based%203-d%20object%20recognition%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Trip%20Denton%2C%20M.Fatih%20Demirci%20Abrahamson%2C%20Jeff%20Shokoufandeh%2C%20Ali%20Dickinson%2C%20Sven%20Selecting%20canonical%20views%20for%20view-based%203-d%20object%20recognition%202004"
        },
        {
            "id": "5",
            "entry": "[5] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2):295\u2013307, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Chao%20Loy%2C%20Chen%20Change%20He%2C%20Kaiming%20Tang%2C%20Xiaoou%20Image%20super-resolution%20using%20deep%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Chao%20Loy%2C%20Chen%20Change%20He%2C%20Kaiming%20Tang%2C%20Xiaoou%20Image%20super-resolution%20using%20deep%20convolutional%20networks%202016"
        },
        {
            "id": "6",
            "entry": "[6] Haoqiang Fan, Hao Su, and Leonidas Guibas. A point set generation network for 3d object reconstruction from a single image. In Conference on Computer Vision and Pattern Recognition (CVPR), volume 38, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fan%2C%20Haoqiang%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20A%20point%20set%20generation%20network%20for%203d%20object%20reconstruction%20from%20a%20single%20image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fan%2C%20Haoqiang%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20A%20point%20set%20generation%20network%20for%203d%20object%20reconstruction%20from%20a%20single%20image%202017"
        },
        {
            "id": "7",
            "entry": "[7] William T Freeman, Thouis R Jones, and Egon C Pasztor. Example-based super-resolution. IEEE Computer graphics and Applications, 22(2):56\u201365, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freeman%2C%20William%20T.%20Jones%2C%20Thouis%20R.%20Pasztor%2C%20Egon%20C.%20Example-based%20super-resolution%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freeman%2C%20William%20T.%20Jones%2C%20Thouis%20R.%20Pasztor%2C%20Egon%20C.%20Example-based%20super-resolution%202002"
        },
        {
            "id": "8",
            "entry": "[8] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680. 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "9",
            "entry": "[9] Christian H\u00e4ne, Shubham Tulsiani, and Jitendra Malik. Hierarchical surface prediction for 3d object reconstruction. arXiv preprint arXiv:1704.00710, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.00710"
        },
        {
            "id": "10",
            "entry": "[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "11",
            "entry": "[11] Tak-Wai Hui, Chen Change Loy, and Xiaoou Tang. Depth map super-resolution by deep multi-scale guidance. pages 353\u2013369, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hui%2C%20Tak-Wai%20Loy%2C%20Chen%20Change%20Tang%2C%20Xiaoou%20Depth%20map%20super-resolution%20by%20deep%20multi-scale%20guidance%202016"
        },
        {
            "id": "12",
            "entry": "[12] Abhishek Kar, Christian H\u00e4ne, and Jitendra Malik. Learning a multi-view stereo machine. In Advances in Neural Information Processing Systems, pages 364\u2013375, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kar%2C%20Abhishek%20H%C3%A4ne%2C%20Christian%20Malik%2C%20Jitendra%20Learning%20a%20multi-view%20stereo%20machine%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kar%2C%20Abhishek%20H%C3%A4ne%2C%20Christian%20Malik%2C%20Jitendra%20Learning%20a%20multi-view%20stereo%20machine%202017"
        },
        {
            "id": "13",
            "entry": "[13] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20gans%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20gans%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018"
        },
        {
            "id": "14",
            "entry": "[14] Hiroharu Kato, Yoshitaka Ushiku, and Tatsuya Harada. Neural 3d mesh renderer. arXiv preprint arXiv:1711.07566, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.07566"
        },
        {
            "id": "15",
            "entry": "[15] Michael Kazhdan, Thomas Funkhouser, and Szymon Rusinkiewicz. Rotation invariant spherical harmonic representation of 3 d shape descriptors. In Symposium on geometry processing, volume 6, pages 156\u2013164, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kazhdan%2C%20Michael%20Funkhouser%2C%20Thomas%20Rusinkiewicz%2C%20Szymon%20Rotation%20invariant%20spherical%20harmonic%20representation%20of%203%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kazhdan%2C%20Michael%20Funkhouser%2C%20Thomas%20Rusinkiewicz%2C%20Szymon%20Rotation%20invariant%20spherical%20harmonic%20representation%20of%203%202003"
        },
        {
            "id": "16",
            "entry": "[16] Jan Knopp, Mukta Prasad, Geert Willems, Radu Timofte, and Luc Van Gool. Hough transform and 3d surf for robust three dimensional classification. In European Conference on Computer Vision, pages 589\u2013602.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Knopp%2C%20Jan%20Prasad%2C%20Mukta%20Willems%2C%20Geert%20Timofte%2C%20Radu%20Hough%20transform%20and%203d%20surf%20for%20robust%20three%20dimensional%20classification",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Knopp%2C%20Jan%20Prasad%2C%20Mukta%20Willems%2C%20Geert%20Timofte%2C%20Radu%20Hough%20transform%20and%203d%20surf%20for%20robust%20three%20dimensional%20classification"
        },
        {
            "id": "17",
            "entry": "[17] Jan J Koenderink and Andrea J Van Doorn. The singularities of the visual mapping. Biological cybernetics, 24(1):51\u201359, 1976.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koenderink%2C%20Jan%20J.%20Doorn%2C%20Andrea%20J.Van%20The%20singularities%20of%20the%20visual%20mapping%201976",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koenderink%2C%20Jan%20J.%20Doorn%2C%20Andrea%20J.Van%20The%20singularities%20of%20the%20visual%20mapping%201976"
        },
        {
            "id": "18",
            "entry": "[18] Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photorealistic single image super-resolution using a generative adversarial network. arXiv preprint arXiv:1609.04802, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.04802"
        },
        {
            "id": "19",
            "entry": "[19] Yangyan Li, Soeren Pirk, Hao Su, Charles R Qi, and Leonidas J Guibas. Fpnn: Field probing neural networks for 3d data. In Advances in Neural Information Processing Systems, pages 307\u2013315, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Yangyan%20Pirk%2C%20Soeren%20Su%2C%20Hao%20Qi%2C%20Charles%20R.%20Fpnn%3A%20Field%20probing%20neural%20networks%20for%203d%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Yangyan%20Pirk%2C%20Soeren%20Su%2C%20Hao%20Qi%2C%20Charles%20R.%20Fpnn%3A%20Field%20probing%20neural%20networks%20for%203d%20data%202016"
        },
        {
            "id": "20",
            "entry": "[20] Jerry Liu, Fisher Yu, and Thomas Funkhouser. Interactive 3d modeling with a generative adversarial network. arXiv preprint arXiv:1706.05170, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.05170"
        },
        {
            "id": "21",
            "entry": "[21] Q-T Luong and Thierry Vi\u00e9ville. Canonical representations for the geometries of multiple projective views. Computer vision and image understanding, 64(2):193\u2013229, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luong%2C%20Q.-T.%20Vi%C3%A9ville%2C%20Thierry%20Canonical%20representations%20for%20the%20geometries%20of%20multiple%20projective%20views%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luong%2C%20Q.-T.%20Vi%C3%A9ville%2C%20Thierry%20Canonical%20representations%20for%20the%20geometries%20of%20multiple%20projective%20views%201996"
        },
        {
            "id": "22",
            "entry": "[22] Oisin Mac Aodha, Neill DF Campbell, Arun Nair, and Gabriel J Brostow. Patch based synthesis for single depth image super-resolution. In European Conference on Computer Vision, pages 71\u201384.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aodha%2C%20Oisin%20Mac%20Campbell%2C%20Neill%20D.F.%20Nair%2C%20Arun%20Brostow%2C%20Gabriel%20J.%20Patch%20based%20synthesis%20for%20single%20depth%20image%20super-resolution",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aodha%2C%20Oisin%20Mac%20Campbell%2C%20Neill%20D.F.%20Nair%2C%20Arun%20Brostow%2C%20Gabriel%20J.%20Patch%20based%20synthesis%20for%20single%20depth%20image%20super-resolution"
        },
        {
            "id": "23",
            "entry": "[23] Diego Macrini, Ali Shokoufandeh, Sven Dickinson, Kaleem Siddiqi, and Steven Zucker. Viewbased 3-d object recognition using shock graphs. In Pattern Recognition, 2002. Proceedings. 16th International Conference on, volume 3, pages 24\u201328. IEEE, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Macrini%2C%20Diego%20Shokoufandeh%2C%20Ali%20Dickinson%2C%20Sven%20Siddiqi%2C%20Kaleem%20Viewbased%203-d%20object%20recognition%20using%20shock%20graphs%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Macrini%2C%20Diego%20Shokoufandeh%2C%20Ali%20Dickinson%2C%20Sven%20Siddiqi%2C%20Kaleem%20Viewbased%203-d%20object%20recognition%20using%20shock%20graphs%202002"
        },
        {
            "id": "24",
            "entry": "[24] Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction beyond mean square error. arXiv preprint arXiv:1511.05440, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05440"
        },
        {
            "id": "25",
            "entry": "[25] Daniel Maturana and Sebastian Scherer. Voxnet: A 3d convolutional neural network for realtime object recognition. In Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International Conference on, pages 922\u2013928. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maturana%2C%20Daniel%20Scherer%2C%20Sebastian%20Voxnet%3A%20A%203d%20convolutional%20neural%20network%20for%20realtime%20object%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maturana%2C%20Daniel%20Scherer%2C%20Sebastian%20Voxnet%3A%20A%203d%20convolutional%20neural%20network%20for%20realtime%20object%20recognition%202015"
        },
        {
            "id": "26",
            "entry": "[26] Hiroshi Murase and Shree K Nayar. Visual learning and recognition of 3-d objects from appearance. International journal of computer vision, 14(1):5\u201324, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Murase%2C%20Hiroshi%20Nayar%2C%20Shree%20K.%20Visual%20learning%20and%20recognition%20of%203-d%20objects%20from%20appearance%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Murase%2C%20Hiroshi%20Nayar%2C%20Shree%20K.%20Visual%20learning%20and%20recognition%20of%203-d%20objects%20from%20appearance%201995"
        },
        {
            "id": "27",
            "entry": "[27] Christian Osendorfer, Hubert Soyer, and Patrick Van Der Smagt. Image super-resolution with fast approximate convolutional sparse coding. In International Conference on Neural Information Processing, pages 250\u2013257.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Osendorfer%2C%20Christian%20Soyer%2C%20Hubert%20Smagt%2C%20Patrick%20Van%20Der%20Image%20super-resolution%20with%20fast%20approximate%20convolutional%20sparse%20coding",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Osendorfer%2C%20Christian%20Soyer%2C%20Hubert%20Smagt%2C%20Patrick%20Van%20Der%20Image%20super-resolution%20with%20fast%20approximate%20convolutional%20sparse%20coding"
        },
        {
            "id": "28",
            "entry": "[28] Jaesik Park, Hyeongwoo Kim, Yu-Wing Tai, Michael S Brown, and Inso Kweon. High quality depth map upsampling for 3d-tof cameras. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 1623\u20131630. IEEE, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20Jaesik%20Kim%2C%20Hyeongwoo%20Tai%2C%20Yu-Wing%20Brown%2C%20Michael%20S.%20High%20quality%20depth%20map%20upsampling%20for%203d-tof%20cameras%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20Jaesik%20Kim%2C%20Hyeongwoo%20Tai%2C%20Yu-Wing%20Brown%2C%20Michael%20S.%20High%20quality%20depth%20map%20upsampling%20for%203d-tof%20cameras%202011"
        },
        {
            "id": "29",
            "entry": "[29] Sung Cheol Park, Min Kyu Park, and Moon Gi Kang. Super-resolution image reconstruction: a technical overview. IEEE signal processing magazine, 20(3):21\u201336, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20Sung%20Cheol%20Park%2C%20Min%20Kyu%20Kang%2C%20Moon%20Gi%20Super-resolution%20image%20reconstruction%3A%20a%20technical%20overview%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20Sung%20Cheol%20Park%2C%20Min%20Kyu%20Kang%2C%20Moon%20Gi%20Super-resolution%20image%20reconstruction%3A%20a%20technical%20overview%202003"
        },
        {
            "id": "30",
            "entry": "[30] Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Context encoders: Feature learning by inpainting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2536\u20132544, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016"
        },
        {
            "id": "31",
            "entry": "[31] Jhony K Pontes, Chen Kong, Sridha Sridharan, Simon Lucey, Anders Eriksson, and Clinton Fookes. Image2mesh: A learning framework for single image 3d reconstruction. arXiv preprint arXiv:1711.10669, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.10669"
        },
        {
            "id": "32",
            "entry": "[32] Charles R Qi, Hao Su, Matthias Nie\u00dfner, Angela Dai, Mengyuan Yan, and Leonidas J Guibas. Volumetric and multi-view cnns for object classification on 3d data. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5648\u20135656, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Qi%2C%20Charles%20R.%20Su%2C%20Hao%20Nie%C3%9Fner%2C%20Matthias%20Dai%2C%20Angela%20Volumetric%20and%20multi-view%20cnns%20for%20object%20classification%20on%203d%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Qi%2C%20Charles%20R.%20Su%2C%20Hao%20Nie%C3%9Fner%2C%20Matthias%20Dai%2C%20Angela%20Volumetric%20and%20multi-view%20cnns%20for%20object%20classification%20on%203d%20data%202016"
        },
        {
            "id": "33",
            "entry": "[33] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, 1(2):4, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Qi%2C%20Charles%20R.%20Su%2C%20Hao%20Mo%2C%20Kaichun%20Guibas%2C%20Leonidas%20J.%20Pointnet%3A%20Deep%20learning%20on%20point%20sets%20for%203d%20classification%20and%20segmentation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Qi%2C%20Charles%20R.%20Su%2C%20Hao%20Mo%2C%20Kaichun%20Guibas%2C%20Leonidas%20J.%20Pointnet%3A%20Deep%20learning%20on%20point%20sets%20for%203d%20classification%20and%20segmentation%202017"
        },
        {
            "id": "34",
            "entry": "[34] Gernot Riegler, Ali Osman Ulusoy, Horst Bischof, and Andreas Geiger. Octnetfusion: Learning depth fusion from data. In Proceedings of the International Conference on 3D Vision, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Riegler%2C%20Gernot%20Ulusoy%2C%20Ali%20Osman%20Bischof%2C%20Horst%20Geiger%2C%20Andreas%20Octnetfusion%3A%20Learning%20depth%20fusion%20from%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Riegler%2C%20Gernot%20Ulusoy%2C%20Ali%20Osman%20Bischof%2C%20Horst%20Geiger%2C%20Andreas%20Octnetfusion%3A%20Learning%20depth%20fusion%20from%20data%202017"
        },
        {
            "id": "35",
            "entry": "[35] Leonid I Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total variation based noise removal algorithms. Physica D: nonlinear phenomena, 60(1-4):259\u2013268, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rudin%2C%20Leonid%20I.%20Osher%2C%20Stanley%20Fatemi%2C%20Emad%20Nonlinear%20total%20variation%20based%20noise%20removal%20algorithms%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rudin%2C%20Leonid%20I.%20Osher%2C%20Stanley%20Fatemi%2C%20Emad%20Nonlinear%20total%20variation%20based%20noise%20removal%20algorithms%201992"
        },
        {
            "id": "36",
            "entry": "[36] Ashutosh Saxena, Min Sun, and Andrew Y Ng. Make3d: Learning 3d scene structure from a single still image. IEEE transactions on pattern analysis and machine intelligence, 31(5): 824\u2013840, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saxena%2C%20Ashutosh%20Sun%2C%20Min%20Ng%2C%20Andrew%20Y.%20Make3d%3A%20Learning%203d%20scene%20structure%20from%20a%20single%20still%20image%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saxena%2C%20Ashutosh%20Sun%2C%20Min%20Ng%2C%20Andrew%20Y.%20Make3d%3A%20Learning%203d%20scene%20structure%20from%20a%20single%20still%20image%202009"
        },
        {
            "id": "37",
            "entry": "[37] Abhishek Sharma, Oliver Grau, and Mario Fritz. Vconv-dae: Deep volumetric shape learning without object labels. In European Conference on Computer Vision, pages 236\u2013250.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sharma%2C%20Abhishek%20Grau%2C%20Oliver%20Fritz%2C%20Mario%20Vconv-dae%3A%20Deep%20volumetric%20shape%20learning%20without%20object%20labels",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sharma%2C%20Abhishek%20Grau%2C%20Oliver%20Fritz%2C%20Mario%20Vconv-dae%3A%20Deep%20volumetric%20shape%20learning%20without%20object%20labels"
        },
        {
            "id": "38",
            "entry": "[38] Baoguang Shi, Song Bai, Zhichao Zhou, and Xiang Bai. Deeppano: Deep panoramic representation for 3-d shape recognition. IEEE Signal Processing Letters, 22(12):2339\u20132343, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shi%2C%20Baoguang%20Bai%2C%20Song%20Zhou%2C%20Zhichao%20Bai%2C%20Xiang%20Deeppano%3A%20Deep%20panoramic%20representation%20for%203-d%20shape%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shi%2C%20Baoguang%20Bai%2C%20Song%20Zhou%2C%20Zhichao%20Bai%2C%20Xiang%20Deeppano%3A%20Deep%20panoramic%20representation%20for%203-d%20shape%20recognition%202015"
        },
        {
            "id": "39",
            "entry": "[39] Daeyun Shin, Charless Fowlkes, and Derek Hoiem. Pixels, voxels, and views: A study of shape representations for single view 3d object shape prediction. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shin%2C%20Daeyun%20Fowlkes%2C%20Charless%20Hoiem%2C%20Derek%20Pixels%2C%20voxels%2C%20and%20views%3A%20A%20study%20of%20shape%20representations%20for%20single%20view%203d%20object%20shape%20prediction%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shin%2C%20Daeyun%20Fowlkes%2C%20Charless%20Hoiem%2C%20Derek%20Pixels%2C%20voxels%2C%20and%20views%3A%20A%20study%20of%20shape%20representations%20for%20single%20view%203d%20object%20shape%20prediction%202018"
        },
        {
            "id": "40",
            "entry": "[40] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "41",
            "entry": "[41] Edward J Smith and David Meger. Improved adversarial systems for 3d object generation and reconstruction. In Conference on Robot Learning, pages 87\u201396, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20Edward%20J.%20Meger%2C%20David%20Improved%20adversarial%20systems%20for%203d%20object%20generation%20and%20reconstruction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smith%2C%20Edward%20J.%20Meger%2C%20David%20Improved%20adversarial%20systems%20for%203d%20object%20generation%20and%20reconstruction%202017"
        },
        {
            "id": "42",
            "entry": "[42] Amir Arsalan Soltani, Haibin Huang, Jiajun Wu, Tejas D Kulkarni, and Joshua B Tenenbaum. Synthesizing 3d shapes via modeling multi-view depth maps and silhouettes with deep generative networks.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Soltani%2C%20Amir%20Arsalan%20Huang%2C%20Haibin%20Wu%2C%20Jiajun%20Kulkarni%2C%20Tejas%20D.%20Synthesizing%203d%20shapes%20via%20modeling%20multi-view%20depth%20maps%20and%20silhouettes%20with%20deep%20generative%20networks"
        },
        {
            "id": "43",
            "entry": "[43] Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In Proceedings of the IEEE international conference on computer vision, pages 945\u2013953, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Su%2C%20Hang%20Maji%2C%20Subhransu%20Kalogerakis%2C%20Evangelos%20Learned-Miller%2C%20Erik%20Multi-view%20convolutional%20neural%20networks%20for%203d%20shape%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Su%2C%20Hang%20Maji%2C%20Subhransu%20Kalogerakis%2C%20Evangelos%20Learned-Miller%2C%20Erik%20Multi-view%20convolutional%20neural%20networks%20for%203d%20shape%20recognition%202015"
        },
        {
            "id": "44",
            "entry": "[44] Maxim Tatarchenko, Alexey Dosovitskiy, and Thomas Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3d outputs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2088\u20132096, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tatarchenko%2C%20Maxim%20Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Octree%20generating%20networks%3A%20Efficient%20convolutional%20architectures%20for%20high-resolution%203d%20outputs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tatarchenko%2C%20Maxim%20Dosovitskiy%2C%20Alexey%20Brox%2C%20Thomas%20Octree%20generating%20networks%3A%20Efficient%20convolutional%20architectures%20for%20high-resolution%203d%20outputs%202017"
        },
        {
            "id": "45",
            "entry": "[45] Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu-Gang Jiang. Pixel2mesh: Generating 3d mesh models from single rgb images. arXiv preprint arXiv:1804.01654, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.01654"
        },
        {
            "id": "46",
            "entry": "[46] Zhaowen Wang, Ding Liu, Jianchao Yang, Wei Han, and Thomas Huang. Deep networks for image super-resolution with sparse prior. In Proceedings of the IEEE International Conference on Computer Vision, pages 370\u2013378, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhaowen%20Liu%2C%20Ding%20Yang%2C%20Jianchao%20Han%2C%20Wei%20Deep%20networks%20for%20image%20super-resolution%20with%20sparse%20prior%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhaowen%20Liu%2C%20Ding%20Yang%2C%20Jianchao%20Han%2C%20Wei%20Deep%20networks%20for%20image%20super-resolution%20with%20sparse%20prior%202015"
        },
        {
            "id": "47",
            "entry": "[47] Jiajun Wu, Chengkai Zhang, Tianfan Xue, William T Freeman, and Joshua B Tenenbaum. Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling. In Advances in Neural Information Processing Systems, pages 82\u201390, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20William%20T.%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203d%20generative-adversarial%20modeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20William%20T.%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203d%20generative-adversarial%20modeling%202016"
        },
        {
            "id": "48",
            "entry": "[48] Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, Bill Freeman, and Josh Tenenbaum. Marrnet: 3d shape reconstruction via 2.5 d sketches. In Advances In Neural Information Processing Systems, pages 540\u2013550, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Wang%2C%20Yifan%20Xue%2C%20Tianfan%20Sun%2C%20Xingyuan%20Marrnet%3A%203d%20shape%20reconstruction%20via%202.5%20d%20sketches%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Wang%2C%20Yifan%20Xue%2C%20Tianfan%20Sun%2C%20Xingyuan%20Marrnet%3A%203d%20shape%20reconstruction%20via%202.5%20d%20sketches%202017"
        },
        {
            "id": "49",
            "entry": "[49] Jianchao Yang, John Wright, Thomas S Huang, and Yi Ma. Image super-resolution via sparse representation. IEEE transactions on image processing, 19(11):2861\u20132873, 2010. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jianchao%20Wright%2C%20John%20Huang%2C%20Thomas%20S.%20Ma%2C%20Yi%20Image%20super-resolution%20via%20sparse%20representation%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jianchao%20Wright%2C%20John%20Huang%2C%20Thomas%20S.%20Ma%2C%20Yi%20Image%20super-resolution%20via%20sparse%20representation%202010"
        }
    ]
}
