{
    "filename": "7381-neural-symbolic-vqa-disentangling-reasoning-from-vision-and-language-understanding.pdf",
    "metadata": {
        "title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding",
        "author": "Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, Josh Tenenbaum",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7381-neural-symbolic-vqa-disentangling-reasoning-from-vision-and-language-understanding.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering (NS-VQA) system first recovers a structural scene representation from the image and a program trace from the question. It then executes the program on the scene representation to obtain an answer. Incorporating symbolic structure as prior knowledge offers three unique advantages. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model is more dataand memory-efficient: it performs well after learning on a small number of training data; it can also encode an image into a compact representation, requiring less storage than existing methods for offline question answering. Third, symbolic program execution offers full transparency to the reasoning process; we are thus able to interpret and diagnose each execution step."
    },
    "keywords": [
        {
            "term": "question answering",
            "url": "https://en.wikipedia.org/wiki/question_answering"
        },
        {
            "term": "neural machine translation",
            "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
        },
        {
            "term": "visual reasoning",
            "url": "https://en.wikipedia.org/wiki/visual_reasoning"
        },
        {
            "term": "language understanding",
            "url": "https://en.wikipedia.org/wiki/language_understanding"
        }
    ],
    "highlights": [
        "Looking at the images and questions in Figure 1, we instantly recognize objects and their attributes, parse complicated questions, and leverage such knowledge to reason and answer the questions",
        "We only fine-tune the attribute recognition network with annotated images from split B, but no questions or programs; thanks to the disentangled pipeline and symbolic scene representation, our question parser and executor are not overfitting to particular splits",
        "With an image parser trained on the original condition, our question parser and executor generalize well across splits (NS-Visual question answering+Ori)",
        "Our NS-Visual question answering outperforms IEP on CLEVR-Humans by a considerable margin under small amount of annotated programs",
        "Figure 5a shows the results on three test images: our NS-Visual question answering finds the correct answer and recovers the correct program under the new scene context",
        "We have presented a neural-symbolic Visual question answering approach that disentangles reasoning from visual perception and language understanding"
    ],
    "key_statements": [
        "Looking at the images and questions in Figure 1, we instantly recognize objects and their attributes, parse complicated questions, and leverage such knowledge to reason and answer the questions",
        "We only fine-tune the attribute recognition network with annotated images from split B, but no questions or programs; thanks to the disentangled pipeline and symbolic scene representation, our question parser and executor are not overfitting to particular splits",
        "With an image parser trained on the original condition, our question parser and executor generalize well across splits (NS-Visual question answering+Ori)",
        "Our NS-Visual question answering outperforms IEP on CLEVR-Humans by a considerable margin under small amount of annotated programs",
        "Figure 5a shows the results on three test images: our NS-Visual question answering finds the correct answer and recovers the correct program under the new scene context",
        "We have presented a neural-symbolic Visual question answering approach that disentangles reasoning from visual perception and language understanding"
    ],
    "summary": [
        "Looking at the images and questions in Figure 1, we instantly recognize objects and their attributes, parse complicated questions, and leverage such knowledge to reason and answer the questions.",
        "Modeling, proposing a neural-symbolic approach for visual question answering (NS-VQA) that fully disentangles vision and language understanding from reasoning.",
        "We use neural networks as powerful tools for parsing\u2014 inferring structural, object-based scene representation from images, and generating programs from questions.",
        "Our scene parser recovers a structural and disentangled representation of the scene in the image (Figure 2a), based on which we can perform fully interpretable symbolic reasoning.",
        "The program executor takes the output sequence from the question parser, applies these functional modules on the abstract scene representation of the input image, and generates the final answer (Figure 2-III).",
        "Our structural scene representation for a CLEVR image characterizes the objects in it, each labeled with its shape, size, color, material, and 3D coordinates.",
        "We evaluate our model\u2019s performance on the validation set under various supervise signal for training, including the numbers of ground-truth programs used for pretraining and question-answer pairs for REINFORCE.",
        "The number of question-answer pairs can be further reduced by pretraining the model on a larger set of annotated programs.",
        "Recent neural reasoning models have achieved impressive performance on the original CLEVR QA task [<a class=\"ref-link\" id=\"cJohnson_et+al_2017_b\" href=\"#rJohnson_et+al_2017_b\">Johnson et al, 2017b</a>, <a class=\"ref-link\" id=\"cMascharka_et+al_2018_a\" href=\"#rMascharka_et+al_2018_a\">Mascharka et al, 2018</a>, <a class=\"ref-link\" id=\"cPerez_et+al_2018_a\" href=\"#rPerez_et+al_2018_a\">Perez et al, 2018</a>], but they generalize less well across biased dataset splits.",
        "We only fine-tune the attribute recognition network with annotated images from split B, but no questions or programs; thanks to the disentangled pipeline and symbolic scene representation, our question parser and executor are not overfitting to particular splits.",
        "We adopt a training paradigm for CLEVR-Humans similar to the original CLEVR dataset: we first pretrain the model with a limited number of programs from CLEVR, and fine-tune it on CLEVR-Humans with REINFORCE.",
        "This shows our structural scene representation and symbolic program executor helps to exploit the strong exploration power of REINFORCE, and demonstrates the model\u2019s generalizability across different question styles.",
        "Our dataset differs from CLEVR primarily in two ways: Minecraft hosts a larger set of 3D objects with richer image content and visual appearance; our questions and programs involve hierarchical attributes.",
        "Figure 5a shows the results on three test images: our NS-VQA finds the correct answer and recovers the correct program under the new scene context.",
        "Our model uses deep learning for inverse graphics and inverse language modeling\u2014recognizing and characterizing objects in the scene; it uses a symbolic program executor to reason and answer questions."
    ],
    "headline": "We demonstrate the following advantages of our disentangled structural scene representation and symbolic execution engine",
    "reference_links": [
        {
            "id": "Aditya_et+al_2018_a",
            "entry": "Somak Aditya, Yezhou Yang, and Chitta Baral. Explicit reasoning over end-to-end neural architectures for visual question answering. In AAAI, 2018. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aditya%2C%20Somak%20Yang%2C%20Yezhou%20Baral%2C%20Chitta%20Explicit%20reasoning%20over%20end-to-end%20neural%20architectures%20for%20visual%20question%20answering%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aditya%2C%20Somak%20Yang%2C%20Yezhou%20Baral%2C%20Chitta%20Explicit%20reasoning%20over%20end-to-end%20neural%20architectures%20for%20visual%20question%20answering%202018"
        },
        {
            "id": "Andreas_et+al_2016_a",
            "entry": "Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Learning to compose neural networks for question answering. In NAACL-HLT, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andreas%2C%20Jacob%20Rohrbach%2C%20Marcus%20Darrell%2C%20Trevor%20Klein%2C%20Dan%20Learning%20to%20compose%20neural%20networks%20for%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andreas%2C%20Jacob%20Rohrbach%2C%20Marcus%20Darrell%2C%20Trevor%20Klein%2C%20Dan%20Learning%20to%20compose%20neural%20networks%20for%20question%20answering%202016"
        },
        {
            "id": "Antol_et+al_2015_a",
            "entry": "Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. Vqa: Visual question answering. In ICCV, 2015. 1, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Antol%2C%20Stanislaw%20Agrawal%2C%20Aishwarya%20Lu%2C%20Jiasen%20Mitchell%2C%20Margaret%20Vqa%3A%20Visual%20question%20answering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Antol%2C%20Stanislaw%20Agrawal%2C%20Aishwarya%20Lu%2C%20Jiasen%20Mitchell%2C%20Margaret%20Vqa%3A%20Visual%20question%20answering%202015"
        },
        {
            "id": "Ba_et+al_2015_a",
            "entry": "Jimmy Ba, Volodymyr Mnih, and Koray Kavukcuoglu. Multiple object recognition with visual attention. In ICLR, 2015. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ba%2C%20Jimmy%20Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Multiple%20object%20recognition%20with%20visual%20attention%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ba%2C%20Jimmy%20Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Multiple%20object%20recognition%20with%20visual%20attention%202015"
        },
        {
            "id": "Bahdanau_et+al_0000_a",
            "entry": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bahdanau%2C%20Dzmitry%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Neural%20machine%20translation%20by%20jointly%20learning%20to%20align%20and%20translate",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bahdanau%2C%20Dzmitry%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Neural%20machine%20translation%20by%20jointly%20learning%20to%20align%20and%20translate"
        },
        {
            "id": "Balog_et+al_2017_a",
            "entry": "Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. Deepcoder: Learning to write programs. In ICLR, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balog%2C%20Matej%20Gaunt%2C%20Alexander%20L.%20Brockschmidt%2C%20Marc%20Nowozin%2C%20Sebastian%20Deepcoder%3A%20Learning%20to%20write%20programs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balog%2C%20Matej%20Gaunt%2C%20Alexander%20L.%20Brockschmidt%2C%20Marc%20Nowozin%2C%20Sebastian%20Deepcoder%3A%20Learning%20to%20write%20programs%202017"
        },
        {
            "id": "Berant_et+al_2013_a",
            "entry": "Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase from questionanswer pairs. In EMNLP, 2013. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berant%2C%20Jonathan%20Chou%2C%20Andrew%20Frostig%2C%20Roy%20Liang%2C%20Percy%20Semantic%20parsing%20on%20freebase%20from%20questionanswer%20pairs.%20In%20EMNLP%202013"
        },
        {
            "id": "Bisk_et+al_2018_a",
            "entry": "Yonatan Bisk, Kevin J Shih, Yejin Choi, and Daniel Marcu. Learning interpretable spatial operations in a rich 3d blocks world. In AAAI, 2018. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bisk%2C%20Yonatan%20Shih%2C%20Kevin%20J.%20Choi%2C%20Yejin%20Marcu%2C%20Daniel%20Learning%20interpretable%20spatial%20operations%20in%20a%20rich%203d%20blocks%20world%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bisk%2C%20Yonatan%20Shih%2C%20Kevin%20J.%20Choi%2C%20Yejin%20Marcu%2C%20Daniel%20Learning%20interpretable%20spatial%20operations%20in%20a%20rich%203d%20blocks%20world%202018"
        },
        {
            "id": "Cao_et+al_2018_a",
            "entry": "Qingxing Cao, Xiaodan Liang, Bailing Li, Guanbin Li, and Liang Lin. Visual question reasoning on general dependency tree. In CVPR, 2018. 3, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Qingxing%20Liang%2C%20Xiaodan%20Li%2C%20Bailing%20Li%2C%20Guanbin%20Visual%20question%20reasoning%20on%20general%20dependency%20tree%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Qingxing%20Liang%2C%20Xiaodan%20Li%2C%20Bailing%20Li%2C%20Guanbin%20Visual%20question%20reasoning%20on%20general%20dependency%20tree%202018"
        },
        {
            "id": "Eslami_et+al_2016_a",
            "entry": "SM Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, Koray Kavukcuoglu, and Geoffrey E Hinton. Attend, infer, repeat: Fast scene understanding with generative models. In NIPS, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eslami%2C%20S.M.%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eslami%2C%20S.M.%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016"
        },
        {
            "id": "Gan_et+al_2017_a",
            "entry": "Chuang Gan, Yandong Li, Haoxiang Li, Chen Sun, and Boqing Gong. Vqs: Linking segmentations to questions and answers for supervised attention in vqa and question-focused semantic segmentation. In ICCV, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gan%2C%20Chuang%20Li%2C%20Yandong%20Li%2C%20Haoxiang%20Sun%2C%20Chen%20Vqs%3A%20Linking%20segmentations%20to%20questions%20and%20answers%20for%20supervised%20attention%20in%20vqa%20and%20question-focused%20semantic%20segmentation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gan%2C%20Chuang%20Li%2C%20Yandong%20Li%2C%20Haoxiang%20Sun%2C%20Chen%20Vqs%3A%20Linking%20segmentations%20to%20questions%20and%20answers%20for%20supervised%20attention%20in%20vqa%20and%20question-focused%20semantic%20segmentation%202017"
        },
        {
            "id": "Girshick_et+al_2018_a",
            "entry": "Ross Girshick, Ilija Radosavovic, Georgia Gkioxari, Piotr Doll\u00e1r, and Kaiming He. Detectron. https://github.com/facebookresearch/detectron, 2018.5",
            "url": "https://github.com/facebookresearch/detectron"
        },
        {
            "id": "Goldman_et+al_2018_a",
            "entry": "Omer Goldman, Veronica Latcinnik, Udi Naveh, Amir Globerson, and Jonathan Berant. Weakly-supervised semantic parsing with abstract examples. In ACL, 2018. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldman%2C%20Omer%20Latcinnik%2C%20Veronica%20Naveh%2C%20Udi%20Globerson%2C%20Amir%20Weakly-supervised%20semantic%20parsing%20with%20abstract%20examples%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldman%2C%20Omer%20Latcinnik%2C%20Veronica%20Naveh%2C%20Udi%20Globerson%2C%20Amir%20Weakly-supervised%20semantic%20parsing%20with%20abstract%20examples%202018"
        },
        {
            "id": "Goyal_et+al_2017_a",
            "entry": "Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In CVPR, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goyal%2C%20Yash%20Khot%2C%20Tejas%20Summers-Stay%2C%20Douglas%20Batra%2C%20Dhruv%20Making%20the%20v%20in%20vqa%20matter%3A%20Elevating%20the%20role%20of%20image%20understanding%20in%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goyal%2C%20Yash%20Khot%2C%20Tejas%20Summers-Stay%2C%20Douglas%20Batra%2C%20Dhruv%20Making%20the%20v%20in%20vqa%20matter%3A%20Elevating%20the%20role%20of%20image%20understanding%20in%20visual%20question%20answering%202017"
        },
        {
            "id": "Guu_et+al_2017_a",
            "entry": "Kelvin Guu, Panupong Pasupat, Evan Zheran Liu, and Percy Liang. From language to programs: Bridging reinforcement learning and maximum marginal likelihood. In ACL, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guu%2C%20Kelvin%20Pasupat%2C%20Panupong%20Liu%2C%20Evan%20Zheran%20Liang%2C%20Percy%20From%20language%20to%20programs%3A%20Bridging%20reinforcement%20learning%20and%20maximum%20marginal%20likelihood%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guu%2C%20Kelvin%20Pasupat%2C%20Panupong%20Liu%2C%20Evan%20Zheran%20Liang%2C%20Percy%20From%20language%20to%20programs%3A%20Bridging%20reinforcement%20learning%20and%20maximum%20marginal%20likelihood%202017"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2015. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015"
        },
        {
            "id": "He_et+al_2017_a",
            "entry": "Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Girshick. Mask r-cnn. In ICCV, 2017. 4, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Doll%C3%A1r%20and%20Ross%20Girshick%20Mask%20rcnn%20In%20ICCV%202017%204%205",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Doll%C3%A1r%20and%20Ross%20Girshick%20Mask%20rcnn%20In%20ICCV%202017%204%205"
        },
        {
            "id": "Higgins_et+al_2018_a",
            "entry": "Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner. Scan: learning abstract hierarchical compositional visual concepts. In ICLR, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Sonnerat%2C%20Nicolas%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Scan%3A%20learning%20abstract%20hierarchical%20compositional%20visual%20concepts%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Sonnerat%2C%20Nicolas%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Scan%3A%20learning%20abstract%20hierarchical%20compositional%20visual%20concepts%202018"
        },
        {
            "id": "Hochreiter_1997_a",
            "entry": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural Comput., 9(8):1735\u20131780, 1997. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "Hu_et+al_2017_a",
            "entry": "Ronghang Hu, Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Kate Saenko. Learning to reason: End-to-end module networks for visual question answering. In CVPR, 2017. 3, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Ronghang%20Andreas%2C%20Jacob%20Rohrbach%2C%20Marcus%20Darrell%2C%20Trevor%20Learning%20to%20reason%3A%20End-to-end%20module%20networks%20for%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Ronghang%20Andreas%2C%20Jacob%20Rohrbach%2C%20Marcus%20Darrell%2C%20Trevor%20Learning%20to%20reason%3A%20End-to-end%20module%20networks%20for%20visual%20question%20answering%202017"
        },
        {
            "id": "Hudson_2018_a",
            "entry": "Drew A Hudson and Christopher D Manning. Compositional attention networks for machine reasoning. In ICLR, 2018. 3, 5, 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hudson%2C%20Drew%20A.%20Manning%2C%20Christopher%20D.%20Compositional%20attention%20networks%20for%20machine%20reasoning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hudson%2C%20Drew%20A.%20Manning%2C%20Christopher%20D.%20Compositional%20attention%20networks%20for%20machine%20reasoning%202018"
        },
        {
            "id": "Jabri_et+al_2016_a",
            "entry": "Allan Jabri, Armand Joulin, and Laurens van der Maaten. Revisiting visual question answering baselines. In ECCV, 2016. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jabri%2C%20Allan%20Joulin%2C%20Armand%20van%20der%20Maaten%2C%20Laurens%20Revisiting%20visual%20question%20answering%20baselines%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jabri%2C%20Allan%20Joulin%2C%20Armand%20van%20der%20Maaten%2C%20Laurens%20Revisiting%20visual%20question%20answering%20baselines%202016"
        },
        {
            "id": "Johnson_et+al_2017_a",
            "entry": "Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In CVPR, 2017a. 1, 3, 6, 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017"
        },
        {
            "id": "Johnson_et+al_2017_b",
            "entry": "Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Judy Hoffman, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. Inferring and executing programs for visual reasoning. In ICCV, 2017b. 1, 3, 4, 5, 6, 7, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Hoffman%2C%20Judy%20Inferring%20and%20executing%20programs%20for%20visual%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Hoffman%2C%20Judy%20Inferring%20and%20executing%20programs%20for%20visual%20reasoning%202017"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Matthew Johnson, Katja Hofmann, Tim Hutton, and David Bignell. The malmo platform for artificial intelligence experimentation. In IJCAI, 2016. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Matthew%20Hofmann%2C%20Katja%20Hutton%2C%20Tim%20Bignell%2C%20David%20The%20malmo%20platform%20for%20artificial%20intelligence%20experimentation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Matthew%20Hofmann%2C%20Katja%20Hutton%2C%20Tim%20Bignell%2C%20David%20The%20malmo%20platform%20for%20artificial%20intelligence%20experimentation%202016"
        },
        {
            "id": "Kulkarni_et+al_2015_a",
            "entry": "Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Joshua B Tenenbaum. Deep convolutional inverse graphics network. In NIPS, 2015. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Deep%20convolutional%20inverse%20graphics%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Deep%20convolutional%20inverse%20graphics%20network%202015"
        },
        {
            "id": "Liang_et+al_2013_a",
            "entry": "Percy Liang, Michael I Jordan, and Dan Klein. Learning dependency-based compositional semantics. Computational Linguistics, 39(2):389\u2013446, 2013. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20Percy%20Jordan%2C%20Michael%20I.%20Klein%2C%20Dan%20Learning%20dependency-based%20compositional%20semantics%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20Percy%20Jordan%2C%20Michael%20I.%20Klein%2C%20Dan%20Learning%20dependency-based%20compositional%20semantics%202013"
        },
        {
            "id": "Lin_et+al_2017_a",
            "entry": "Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In CVPR, 2017. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Tsung-Yi%20Doll%C3%A1r%2C%20Piotr%20Girshick%2C%20Ross%20He%2C%20Kaiming%20Feature%20pyramid%20networks%20for%20object%20detection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Tsung-Yi%20Doll%C3%A1r%2C%20Piotr%20Girshick%2C%20Ross%20He%2C%20Kaiming%20Feature%20pyramid%20networks%20for%20object%20detection%202017"
        },
        {
            "id": "Lu_et+al_2016_a",
            "entry": "Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. Hierarchical question-image co-attention for visual question answering. In NIPS, 2016. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lu%2C%20Jiasen%20Yang%2C%20Jianwei%20Batra%2C%20Dhruv%20Parikh%2C%20Devi%20Hierarchical%20question-image%20co-attention%20for%20visual%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lu%2C%20Jiasen%20Yang%2C%20Jianwei%20Batra%2C%20Dhruv%20Parikh%2C%20Devi%20Hierarchical%20question-image%20co-attention%20for%20visual%20question%20answering%202016"
        },
        {
            "id": "Luong_et+al_2015_a",
            "entry": "Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based neural machine translation. In EMNLP, 2015. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luong%2C%20Minh-Thang%20Pham%2C%20Hieu%20Manning%2C%20Christopher%20D.%20Effective%20approaches%20to%20attention-based%20neural%20machine%20translation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luong%2C%20Minh-Thang%20Pham%2C%20Hieu%20Manning%2C%20Christopher%20D.%20Effective%20approaches%20to%20attention-based%20neural%20machine%20translation%202015"
        },
        {
            "id": "Malinowski_2014_a",
            "entry": "M Malinowski and M Fritz. A multi-world approach to question answering about real-world scenes based on uncertain input. In NIPS, 2014. 1, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Malinowski%2C%20M.%20Fritz%2C%20M.%20A%20multi-world%20approach%20to%20question%20answering%20about%20real-world%20scenes%20based%20on%20uncertain%20input%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Malinowski%2C%20M.%20Fritz%2C%20M.%20A%20multi-world%20approach%20to%20question%20answering%20about%20real-world%20scenes%20based%20on%20uncertain%20input%202014"
        },
        {
            "id": "Mascharka_et+al_2018_a",
            "entry": "David Mascharka, Philip Tran, Ryan Soklaski, and Arjun Majumdar. Transparency by design: Closing the gap between performance and interpretability in visual reasoning. In CVPR, 2018. 3, 5, 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mascharka%2C%20David%20Tran%2C%20Philip%20Soklaski%2C%20Ryan%20Majumdar%2C%20Arjun%20Transparency%20by%20design%3A%20Closing%20the%20gap%20between%20performance%20and%20interpretability%20in%20visual%20reasoning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mascharka%2C%20David%20Tran%2C%20Philip%20Soklaski%2C%20Ryan%20Majumdar%2C%20Arjun%20Transparency%20by%20design%3A%20Closing%20the%20gap%20between%20performance%20and%20interpretability%20in%20visual%20reasoning%202018"
        },
        {
            "id": "Misra_et+al_2018_a",
            "entry": "Ishan Misra, Ross Girshick, Rob Fergus, Martial Hebert, Abhinav Gupta, and Laurens van der Maaten. Learning by asking questions. In CVPR, 2018. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Misra%2C%20Ishan%20Girshick%2C%20Ross%20Fergus%2C%20Rob%20Hebert%2C%20Martial%20Learning%20by%20asking%20questions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Misra%2C%20Ishan%20Girshick%2C%20Ross%20Fergus%2C%20Rob%20Hebert%2C%20Martial%20Learning%20by%20asking%20questions%202018"
        },
        {
            "id": "Neelakantan_et+al_2016_a",
            "entry": "Arvind Neelakantan, Quoc V Le, and Ilya Sutskever. Neural programmer: Inducing latent programs with gradient descent. In ICLR, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neelakantan%2C%20Arvind%20Le%2C%20Quoc%20V.%20Sutskever%2C%20Ilya%20Neural%20programmer%3A%20Inducing%20latent%20programs%20with%20gradient%20descent%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neelakantan%2C%20Arvind%20Le%2C%20Quoc%20V.%20Sutskever%2C%20Ilya%20Neural%20programmer%3A%20Inducing%20latent%20programs%20with%20gradient%20descent%202016"
        },
        {
            "id": "Parisotto_et+al_2017_a",
            "entry": "Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Pushmeet Kohli. Neuro-symbolic program synthesis. In ICLR, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parisotto%2C%20Emilio%20Mohamed%2C%20Abdel-rahman%20Singh%2C%20Rishabh%20Li%2C%20Lihong%20Neuro-symbolic%20program%20synthesis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parisotto%2C%20Emilio%20Mohamed%2C%20Abdel-rahman%20Singh%2C%20Rishabh%20Li%2C%20Lihong%20Neuro-symbolic%20program%20synthesis%202017"
        },
        {
            "id": "Pennington_et+al_2014_a",
            "entry": "Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word representation. In EMNLP, 2014. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014"
        },
        {
            "id": "Perez_et+al_2018_a",
            "entry": "Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with a general conditioning layer. In AAAI, 2018. 3, 5, 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perez%2C%20Ethan%20Strub%2C%20Florian%20Vries%2C%20Harm%20De%20Dumoulin%2C%20Vincent%20Film%3A%20Visual%20reasoning%20with%20a%20general%20conditioning%20layer%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Perez%2C%20Ethan%20Strub%2C%20Florian%20Vries%2C%20Harm%20De%20Dumoulin%2C%20Vincent%20Film%3A%20Visual%20reasoning%20with%20a%20general%20conditioning%20layer%202018"
        },
        {
            "id": "Rothe_et+al_2017_a",
            "entry": "Anselm Rothe, Brenden M Lake, and Todd Gureckis. Question asking as program generation. In NIPS, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rothe%2C%20Anselm%20Lake%2C%20Brenden%20M.%20Gureckis%2C%20Todd%20Question%20asking%20as%20program%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rothe%2C%20Anselm%20Lake%2C%20Brenden%20M.%20Gureckis%2C%20Todd%20Question%20asking%20as%20program%20generation%202017"
        },
        {
            "id": "Santoro_et+al_2017_a",
            "entry": "Adam Santoro, David Raposo, David GT Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. In NIPS, 2017. 3, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santoro%2C%20Adam%20Raposo%2C%20David%20Barrett%2C%20David%20G.T.%20Malinowski%2C%20Mateusz%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Santoro%2C%20Adam%20Raposo%2C%20David%20Barrett%2C%20David%20G.T.%20Malinowski%2C%20Mateusz%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017"
        },
        {
            "id": "Siddharth_et+al_2017_a",
            "entry": "N Siddharth, T. B. Paige, J.W. Meent, A. Desmaison, N. Goodman, P. Kohli, F. Wood, and P. Torr. Learning disentangled representations with semi-supervised deep generative models. In NIPS, 2017. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Siddharth%2C%20N.%20Paige%2C%20T.B.%20Meent%2C%20J.W.%20Desmaison%2C%20A.%20Learning%20disentangled%20representations%20with%20semi-supervised%20deep%20generative%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Siddharth%2C%20N.%20Paige%2C%20T.B.%20Meent%2C%20J.W.%20Desmaison%2C%20A.%20Learning%20disentangled%20representations%20with%20semi-supervised%20deep%20generative%20models%202017"
        },
        {
            "id": "Suarez_et+al_2018_a",
            "entry": "Joseph Suarez, Justin Johnson, and Fei-Fei Li. Ddrprog: A clevr differentiable dynamic reasoning programmer. arXiv:1803.11361, 2018. 3, 5",
            "arxiv_url": "https://arxiv.org/pdf/1803.11361"
        },
        {
            "id": "Vedantam_et+al_2018_a",
            "entry": "Ramakrishna Vedantam, Ian Fischer, Jonathan Huang, and Kevin Murphy. Generative models of visually grounded imagination. In ICLR, 2018. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vedantam%2C%20Ramakrishna%20Fischer%2C%20Ian%20Huang%2C%20Jonathan%20Murphy%2C%20Kevin%20Generative%20models%20of%20visually%20grounded%20imagination%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vedantam%2C%20Ramakrishna%20Fischer%2C%20Ian%20Huang%2C%20Jonathan%20Murphy%2C%20Kevin%20Generative%20models%20of%20visually%20grounded%20imagination%202018"
        },
        {
            "id": "Vinyals_et+al_2015_a",
            "entry": "Oriol Vinyals, \u0141ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. Grammar as a foreign language. In NIPS, 2015. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20Oriol%20Kaiser%2C%20%C5%81ukasz%20Koo%2C%20Terry%20Petrov%2C%20Slav%20Grammar%20as%20a%20foreign%20language%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20Oriol%20Kaiser%2C%20%C5%81ukasz%20Koo%2C%20Terry%20Petrov%2C%20Slav%20Grammar%20as%20a%20foreign%20language%202015"
        },
        {
            "id": "Wang_et+al_2017_a",
            "entry": "Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, and Anthony Dick. Explicit knowledge-based reasoning for visual question answering. In IJCAI, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Peng%20Wu%2C%20Qi%20Shen%2C%20Chunhua%20van%20den%20Hengel%2C%20Anton%20Explicit%20knowledge-based%20reasoning%20for%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Peng%20Wu%2C%20Qi%20Shen%2C%20Chunhua%20van%20den%20Hengel%2C%20Anton%20Explicit%20knowledge-based%20reasoning%20for%20visual%20question%20answering%202017"
        },
        {
            "id": "Williams_1992_a",
            "entry": "Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. MLJ, 8(3-4):229\u2013256, 1992. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Ronald%20J.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Ronald%20J.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "Jiajun Wu, Joshua B Tenenbaum, and Pushmeet Kohli. Neural scene de-rendering. In CVPR, 2017. 2, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20CVPR%202017%202%208",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20CVPR%202017%202%208"
        },
        {
            "id": "Yang_et+al_2015_a",
            "entry": "Jimei Yang, Scott E Reed, Ming-Hsuan Yang, and Honglak Lee. Weakly-supervised disentangling with recurrent transformations for 3d view synthesis. In NIPS, 2015. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jimei%20Reed%2C%20Scott%20E.%20Yang%2C%20Ming-Hsuan%20Lee%2C%20Honglak%20Weakly-supervised%20disentangling%20with%20recurrent%20transformations%20for%203d%20view%20synthesis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jimei%20Reed%2C%20Scott%20E.%20Yang%2C%20Ming-Hsuan%20Lee%2C%20Honglak%20Weakly-supervised%20disentangling%20with%20recurrent%20transformations%20for%203d%20view%20synthesis%202015"
        },
        {
            "id": "Yang_et+al_2016_a",
            "entry": "Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola. Stacked attention networks for image question answering. In CVPR, 2016. 1, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Zichao%20He%2C%20Xiaodong%20Gao%2C%20Jianfeng%20Deng%2C%20Li%20Stacked%20attention%20networks%20for%20image%20question%20answering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Zichao%20He%2C%20Xiaodong%20Gao%2C%20Jianfeng%20Deng%2C%20Li%20Stacked%20attention%20networks%20for%20image%20question%20answering%202016"
        },
        {
            "id": "Yuille_2006_a",
            "entry": "Alan Yuille and Daniel Kersten. Vision as bayesian inference: analysis by synthesis? Trends Cogn. Sci., 10(7): 301\u2013308, 2006. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yuille%2C%20Alan%20Kersten%2C%20Daniel%20Vision%20as%20bayesian%20inference%3A%20analysis%20by%20synthesis%3F%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yuille%2C%20Alan%20Kersten%2C%20Daniel%20Vision%20as%20bayesian%20inference%3A%20analysis%20by%20synthesis%3F%202006"
        },
        {
            "id": "Zhu_et+al_2017_a",
            "entry": "Chen Zhu, Yanpeng Zhao, Shuaiyi Huang, Kewei Tu, and Yi Ma. Structured attentions for visual question answering. In ICCV, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Chen%20Zhao%2C%20Yanpeng%20Huang%2C%20Shuaiyi%20Tu%2C%20Kewei%20Structured%20attentions%20for%20visual%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Chen%20Zhao%2C%20Yanpeng%20Huang%2C%20Shuaiyi%20Tu%2C%20Kewei%20Structured%20attentions%20for%20visual%20question%20answering%202017"
        }
    ]
}
