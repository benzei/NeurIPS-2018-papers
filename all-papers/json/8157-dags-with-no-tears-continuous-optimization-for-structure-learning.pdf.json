{
    "filename": "8157-dags-with-no-tears-continuous-optimization-for-structure-learning.pdf",
    "metadata": {
        "title": "DAGs with NO TEARS: Continuous Optimization for Structure Learning",
        "author": "Xun Zheng, Bryon Aragam, Pradeep K. Ravikumar, Eric P. Xing",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8157-dags-with-no-tears-continuous-optimization-for-structure-learning.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Estimating the structure of directed acyclic graphs (DAGs, also known as Bayesian networks) is a challenging problem since the search space of DAGs is combinatorial and scales superexponentially with the number of nodes. Existing approaches rely on various local heuristics for enforcing the acyclicity constraint. In this paper, we introduce a fundamentally different strategy: we formulate the structure learning problem as a purely continuous optimization problem over real matrices that avoids this combinatorial constraint entirely. This is achieved by a novel characterization of acyclicity that is not only smooth but also exact. The resulting problem can be efficiently solved by standard numerical algorithms, which also makes implementation effortless. The proposed method outperforms existing ones, without imposing any structural assumptions on the graph such as bounded treewidth or in-degree."
    },
    "keywords": [
        {
            "term": "generalized linear model",
            "url": "https://en.wikipedia.org/wiki/generalized_linear_model"
        },
        {
            "term": "bayesian networks",
            "url": "https://en.wikipedia.org/wiki/bayesian_networks"
        },
        {
            "term": "real matrix",
            "url": "https://en.wikipedia.org/wiki/real_matrix"
        },
        {
            "term": "continuous optimization",
            "url": "https://en.wikipedia.org/wiki/continuous_optimization"
        },
        {
            "term": "structure learning",
            "url": "https://en.wikipedia.org/wiki/Structure_Learning"
        },
        {
            "term": "graphical model",
            "url": "https://en.wikipedia.org/wiki/graphical_model"
        },
        {
            "term": "structural equation model",
            "url": "https://en.wikipedia.org/wiki/structural_equation_model"
        },
        {
            "term": "directed acyclic graphs",
            "url": "https://en.wikipedia.org/wiki/directed_acyclic_graphs"
        },
        {
            "term": "acyclic graph",
            "url": "https://en.wikipedia.org/wiki/acyclic_graph"
        },
        {
            "term": "False discovery rate",
            "url": "https://en.wikipedia.org/wiki/False_discovery_rate"
        }
    ],
    "highlights": [
        "Learning directed acyclic graphs (DAGs) from data is an NP-hard problem [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>], owing mainly to the combinatorial acyclicity constraint that is difficult to enforce efficiently",
        "The main thrust of this work is to re-formulate score-based learning of directed acyclic graphs so that standard smooth optimization schemes such as L-BFGS [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>] can be leveraged",
        "We have proposed a new method for learning directed acyclic graphs from data based on a continuous optimization program",
        "This represents a significant departure from existing approaches that search over the discrete space of directed acyclic graphs, resulting in a difficult optimization program",
        "We proposed two optimization schemes for solving the resulting program to stationarity, and illustrated its advantages over existing methods such as greedy equivalence search",
        "By performing global updates instead of local updates in each iteration, our method is able to avoid relying on assumptions about the local structure of the graph"
    ],
    "key_statements": [
        "Learning directed acyclic graphs (DAGs) from data is an NP-hard problem [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>], owing mainly to the combinatorial acyclicity constraint that is difficult to enforce efficiently",
        "We propose a new approach for score-based learning of directed acyclic graphs by converting the traditional combinatorial optimization problem into a continuous program: min F (W )",
        "The main thrust of this work is to re-formulate score-based learning of directed acyclic graphs so that standard smooth optimization schemes such as L-BFGS [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>] can be leveraged",
        "We develop an equality-constrained program for simultaneously estimating the structure and parameters of a sparse directed acyclic graphs from possibly high-dimensional data, and show how standard numerical solvers can be used to find stationary points",
        "We model X via a structural equation model (SEM)",
        "The directed acyclic graphs learning problem becomes equivalent to solving a numerical optimization problem, which is agnostic about the graph structure",
        "The connection between trace of matrix power and number of cycles in the graph is well-known [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>], to the best of our knowledge, this characterization of acyclicity has not appeared in the directed acyclic graphs learning literature previously",
        "As we describe in Appendix B, the precomputation time is only O(m2p + m3) where m p is the memory size of L-BFGS, and each coordinate update is O(m)",
        "Since the accuracy of PC and LiNGAM was significantly lower than either fast greedy search or NOTEARS, we only report the results against fast greedy search here",
        "We only report the numbers for the structural Hamming distance (SHD) here, but complete figures and tables for additional metrics can be found in the supplement",
        "NOTEARS shows significant improvements. This is consistent across each metric we evaluated, and the difference grows as the number of nodes d gets larger",
        "We have proposed a new method for learning directed acyclic graphs from data based on a continuous optimization program",
        "This represents a significant departure from existing approaches that search over the discrete space of directed acyclic graphs, resulting in a difficult optimization program",
        "We proposed two optimization schemes for solving the resulting program to stationarity, and illustrated its advantages over existing methods such as greedy equivalence search",
        "By performing global updates instead of local updates in each iteration, our method is able to avoid relying on assumptions about the local structure of the graph",
        "The main advantage of NOTEARS is smooth, global search, as opposed to combinatorial, local search; and the search is delegated to standard numerical solvers"
    ],
    "summary": [
        "Learning directed acyclic graphs (DAGs) from data is an NP-hard problem [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>], owing mainly to the combinatorial acyclicity constraint that is difficult to enforce efficiently.",
        "We propose a new approach for score-based learning of DAGs by converting the traditional combinatorial optimization problem into a continuous program: min F (W )",
        "The main thrust of this work is to re-formulate score-based learning of DAGs so that standard smooth optimization schemes such as L-BFGS [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>] can be leveraged.",
        "As a result of its simplicity and effortlessness in its implementation, we call the resulting method NOTEARS: Non-combinatorial Optimization via Trace Exponential and Augmented lagRangian for Structure learning.",
        "The basic DAG learning problem is formulated as follows: Let X \u2208 Rn\u00d7d be a data matrix consisting of n i.i.d. observations of the random vector X = (X1, .",
        "The DAG learning problem becomes equivalent to solving a numerical optimization problem, which is agnostic about the graph structure.",
        "The connection between trace of matrix power and number of cycles in the graph is well-known [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>], to the best of our knowledge, this characterization of acyclicity has not appeared in the DAG learning literature previously.",
        "We first performed a qualitative study of the solutions obtained by NOTEARS without thresholding by visualizing the weight matrix WECP obtained by solving (ECP) (i.e. \u03c9 = 0).",
        "Since this involves enumerating all possible parent sets for each node, these experiments are limited to small DAGs. these small-scale experiments yield valuable insight into how well NOTEARS performs in solving the original problem.",
        "Since the general structure learning problem is NP-hard, we suspect that the models we have tested (i.e. ER and SF) appear amenable to fast solution, in the worst-case there are graphs which will still take exponential time to run or get stuck in a local minimum.",
        "We have proposed a new method for learning DAGs from data based on a continuous optimization program.",
        "We proposed two optimization schemes for solving the resulting program to stationarity, and illustrated its advantages over existing methods such as greedy equivalence search.",
        "With the exception of exact methods, existing methods suffer from this drawback as well.2 The main advantage of NOTEARS is smooth, global search, as opposed to combinatorial, local search; and the search is delegated to standard numerical solvers.",
        "The current work relies on the smoothness of the score function, in order to make use of gradient-based numerical solvers to guide the graph search."
    ],
    "headline": "We introduce a fundamentally different strategy: we formulate the structure learning problem as a purely continuous optimization problem over real matrices that avoids this combinatorial constraint entirely",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Al-Mohy, Awad H., & Higham, Nicholas J. 2009. A New Scaling and Squaring Algorithm for the Matrix Exponential. SIAM Journal on Matrix Analysis and Applications.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Al-Mohy%2C%20Awad%20H.%20Higham%2C%20Nicholas%20J.%20A%20New%20Scaling%20and%20Squaring%20Algorithm%20for%20the%20Matrix%20Exponential%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Al-Mohy%2C%20Awad%20H.%20Higham%2C%20Nicholas%20J.%20A%20New%20Scaling%20and%20Squaring%20Algorithm%20for%20the%20Matrix%20Exponential%202009"
        },
        {
            "id": "2",
            "entry": "[2] Aragam, Bryon, & Zhou, Qing. 2015. Concave Penalized Estimation of Sparse Gaussian Bayesian Networks. Journal of Machine Learning Research, 16, 2273\u20132328.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aragam%2C%20Bryon%20Zhou%2C%20Qing%20Concave%20Penalized%20Estimation%20of%20Sparse%20Gaussian%20Bayesian%20Networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aragam%2C%20Bryon%20Zhou%2C%20Qing%20Concave%20Penalized%20Estimation%20of%20Sparse%20Gaussian%20Bayesian%20Networks%202015"
        },
        {
            "id": "3",
            "entry": "[3] Aragam, Bryon, Amini, Arash A., & Zhou, Qing. 2016. Learning directed acyclic graphs with penalized neighbourhood regression. Submitted, arXiv:1511.08963.",
            "arxiv_url": "https://arxiv.org/pdf/1511.08963"
        },
        {
            "id": "4",
            "entry": "[4] Banerjee, Onureena, El Ghaoui, Laurent, & d\u2019Aspremont, Alexandre. 2008. Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data. Journal of Machine Learning Research, 9, 485\u2013516.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Banerjee%2C%20Onureena%20Ghaoui%2C%20El%20Laurent%20d%E2%80%99Aspremont%2C%20Alexandre%20Model%20selection%20through%20sparse%20maximum%20likelihood%20estimation%20for%20multivariate%20Gaussian%20or%20binary%20data%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Banerjee%2C%20Onureena%20Ghaoui%2C%20El%20Laurent%20d%E2%80%99Aspremont%2C%20Alexandre%20Model%20selection%20through%20sparse%20maximum%20likelihood%20estimation%20for%20multivariate%20Gaussian%20or%20binary%20data%202008"
        },
        {
            "id": "5",
            "entry": "[5] Barab\u00e1si, Albert-L\u00e1szl\u00f3, & Albert, R\u00e9ka. 1999. Emergence of scaling in random networks. Science, 286(5439), 509\u2013512.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barab%C3%A1si%2C%20Albert-L%C3%A1szl%C3%B3%20Albert%2C%20R%C3%A9ka%20Emergence%20of%20scaling%20in%20random%20networks%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barab%C3%A1si%2C%20Albert-L%C3%A1szl%C3%B3%20Albert%2C%20R%C3%A9ka%20Emergence%20of%20scaling%20in%20random%20networks%201999"
        },
        {
            "id": "6",
            "entry": "[6] Bouckaert, Remco R. 1993. Probabilistic network construction using the minimum description length principle. In European conference on symbolic and quantitative approaches to reasoning and uncertainty. Springer, pp. 41\u201348.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bouckaert%2C%20Remco%20R.%20Probabilistic%20network%20construction%20using%20the%20minimum%20description%20length%20principle.%20In%20European%20conference%20on%20symbolic%20and%20quantitative%20approaches%20to%20reasoning%20and%20uncertainty%201993"
        },
        {
            "id": "7",
            "entry": "[7] Byrd, Richard H., Lu, Peihuang, Nocedal, Jorge, & Zhu, Ciyou. 1995. A limited memory algorithm for bound constrained optimization. SIAM Journal on Scientific Computing.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Byrd%2C%20Richard%20H.%20Lu%2C%20Peihuang%20Nocedal%2C%20Jorge%20Zhu%2C%20Ciyou%20A%20limited%20memory%20algorithm%20for%20bound%20constrained%20optimization%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Byrd%2C%20Richard%20H.%20Lu%2C%20Peihuang%20Nocedal%2C%20Jorge%20Zhu%2C%20Ciyou%20A%20limited%20memory%20algorithm%20for%20bound%20constrained%20optimization%201995"
        },
        {
            "id": "8",
            "entry": "[8] Chickering, David Maxwell. 1996. Learning Bayesian networks is NP-complete. In Learning from data. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20David%20Maxwell%20Learning%20Bayesian%20networks%20is%20NP-complete.%20In%20Learning%20from%20data%201996"
        },
        {
            "id": "9",
            "entry": "[9] Chickering, David Maxwell. 2003. Optimal structure identification with greedy search. Journal of Machine Learning Research, 3, 507\u2013554.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20David%20Maxwell%20Optimal%20structure%20identification%20with%20greedy%20search%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chickering%2C%20David%20Maxwell%20Optimal%20structure%20identification%20with%20greedy%20search%202003"
        },
        {
            "id": "10",
            "entry": "[10] Chickering, David Maxwell, & Heckerman, David. 1997. Efficient approximations for the marginal likelihood of Bayesian networks with hidden variables. Machine Learning, 29(2-3), 181\u2013212.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20David%20Maxwell%20Heckerman%2C%20David%20Efficient%20approximations%20for%20the%20marginal%20likelihood%20of%20Bayesian%20networks%20with%20hidden%20variables%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chickering%2C%20David%20Maxwell%20Heckerman%2C%20David%20Efficient%20approximations%20for%20the%20marginal%20likelihood%20of%20Bayesian%20networks%20with%20hidden%20variables%201997"
        },
        {
            "id": "11",
            "entry": "[11] Chickering, David Maxwell, Heckerman, David, & Meek, Christopher. 2004. Large-sample learning of Bayesian networks is NP-hard. Journal of Machine Learning Research, 5, 1287\u20131330.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20David%20Maxwell%20Heckerman%2C%20David%20Meek%2C%20Christopher%20Large-sample%20learning%20of%20Bayesian%20networks%20is%20NP-hard%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chickering%2C%20David%20Maxwell%20Heckerman%2C%20David%20Meek%2C%20Christopher%20Large-sample%20learning%20of%20Bayesian%20networks%20is%20NP-hard%202004"
        },
        {
            "id": "12",
            "entry": "[12] Cussens, James. 2012. Bayesian network learning with cutting planes. arXiv preprint arXiv:1202.3713.",
            "arxiv_url": "https://arxiv.org/pdf/1202.3713"
        },
        {
            "id": "13",
            "entry": "[13] Cussens, James, Haws, David, & Studeny, Milan. 2017. Polyhedral aspects of score equivalence in Bayesian network structure learning. Mathematical Programming, 164(1-2), 285\u2013324.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cussens%2C%20James%20Haws%2C%20David%20Studeny%2C%20Milan%20Polyhedral%20aspects%20of%20score%20equivalence%20in%20Bayesian%20network%20structure%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cussens%2C%20James%20Haws%2C%20David%20Studeny%2C%20Milan%20Polyhedral%20aspects%20of%20score%20equivalence%20in%20Bayesian%20network%20structure%20learning%202017"
        },
        {
            "id": "14",
            "entry": "[14] Ellis, Byron, & Wong, Wing Hung. 2008. Learning causal Bayesian network structures from experimental data. Journal of the American Statistical Association, 103(482).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20Byron%20Wong%2C%20Wing%20Hung%20Learning%20causal%20Bayesian%20network%20structures%20from%20experimental%20data%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ellis%2C%20Byron%20Wong%2C%20Wing%20Hung%20Learning%20causal%20Bayesian%20network%20structures%20from%20experimental%20data%202008"
        },
        {
            "id": "15",
            "entry": "[15] Friedman, Jerome, Hastie, Trevor, & Tibshirani, Robert. 2008. Sparse inverse covariance estimation with the Graphical Lasso. Biostatistics, 9(3), 432\u2013441.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Friedman%2C%20Jerome%20Hastie%2C%20Trevor%20Tibshirani%2C%20Robert%20Sparse%20inverse%20covariance%20estimation%20with%20the%20Graphical%20Lasso%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Friedman%2C%20Jerome%20Hastie%2C%20Trevor%20Tibshirani%2C%20Robert%20Sparse%20inverse%20covariance%20estimation%20with%20the%20Graphical%20Lasso%202008"
        },
        {
            "id": "16",
            "entry": "[16] Fu, Fei, & Zhou, Qing. 2013. Learning Sparse Causal Gaussian Networks With Experimental Intervention: Regularization and Coordinate Descent. Journal of the American Statistical Association, 108(501), 288\u2013300.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fu%2C%20Fei%20Zhou%2C%20Qing%20Learning%20Sparse%20Causal%20Gaussian%20Networks%20With%20Experimental%20Intervention%3A%20Regularization%20and%20Coordinate%20Descent%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fu%2C%20Fei%20Zhou%2C%20Qing%20Learning%20Sparse%20Causal%20Gaussian%20Networks%20With%20Experimental%20Intervention%3A%20Regularization%20and%20Coordinate%20Descent%202013"
        },
        {
            "id": "17",
            "entry": "[17] G\u00e1mez, Jos\u00e9 A, Mateo, Juan L, & Puerta, Jos\u00e9 M. 2011. Learning Bayesian networks by hill climbing: Efficient methods based on progressive restriction of the neighborhood. Data Mining and Knowledge Discovery, 22(1-2), 106\u2013148.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=G%C3%A1mez%2C%20Jos%C3%A9%20A.%20Mateo%2C%20Juan%20L.%20Puerta%2C%20Jos%C3%A9%20M.%20Learning%20Bayesian%20networks%20by%20hill%20climbing%3A%20Efficient%20methods%20based%20on%20progressive%20restriction%20of%20the%20neighborhood%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=G%C3%A1mez%2C%20Jos%C3%A9%20A.%20Mateo%2C%20Juan%20L.%20Puerta%2C%20Jos%C3%A9%20M.%20Learning%20Bayesian%20networks%20by%20hill%20climbing%3A%20Efficient%20methods%20based%20on%20progressive%20restriction%20of%20the%20neighborhood%202011"
        },
        {
            "id": "18",
            "entry": "[18] Gu, Jiayang, Fu, Fei, & Zhou, Qing. 2018. Penalized Estimation of Directed Acyclic Graphs From Discrete Data. Statistics and Computing, DOI: 10.1007/s11222-018-9801-y.",
            "crossref": "https://dx.doi.org/10.1007/s11222-018-9801-y",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/s11222-018-9801-y"
        },
        {
            "id": "19",
            "entry": "[19] Harary, Frank, & Manvel, Bennet. 1971. On the number of cycles in a graph. Matematickycasopis.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harary%2C%20Frank%20Manvel%2C%20Bennet%20On%20the%20number%20of%20cycles%20in%20a%20graph.%20Matematickycasopis%201971"
        },
        {
            "id": "20",
            "entry": "[20] Heckerman, David, Geiger, Dan, & Chickering, David M. 1995. Learning Bayesian networks: The combination of knowledge and statistical data. Machine learning, 20(3), 197\u2013243.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heckerman%2C%20David%20Geiger%2C%20Dan%20Chickering%2C%20David%20M.%20Learning%20Bayesian%20networks%3A%20The%20combination%20of%20knowledge%20and%20statistical%20data%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heckerman%2C%20David%20Geiger%2C%20Dan%20Chickering%2C%20David%20M.%20Learning%20Bayesian%20networks%3A%20The%20combination%20of%20knowledge%20and%20statistical%20data%201995"
        },
        {
            "id": "21",
            "entry": "[21] Hsieh, Cho-Jui, Sustik, M\u00e1ty\u00e1s A, Dhillon, Inderjit S, & Ravikumar, Pradeep. 2014. QUIC: quadratic approximation for sparse inverse covariance estimation. Journal of Machine Learning Research, 15(1), 2911\u20132947.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hsieh%2C%20Cho-Jui%20Sustik%2C%20M%C3%A1ty%C3%A1s%20A.%20Dhillon%2C%20Inderjit%20S.%20Ravikumar%2C%20Pradeep%20QUIC%3A%20quadratic%20approximation%20for%20sparse%20inverse%20covariance%20estimation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hsieh%2C%20Cho-Jui%20Sustik%2C%20M%C3%A1ty%C3%A1s%20A.%20Dhillon%2C%20Inderjit%20S.%20Ravikumar%2C%20Pradeep%20QUIC%3A%20quadratic%20approximation%20for%20sparse%20inverse%20covariance%20estimation%202014"
        },
        {
            "id": "22",
            "entry": "[22] Koller, Daphne, & Friedman, Nir. 2009. Probabilistic graphical models: principles and techniques. MIT press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koller%2C%20Daphne%20Friedman%2C%20Nir%20Probabilistic%20graphical%20models%3A%20principles%20and%20techniques%202009"
        },
        {
            "id": "23",
            "entry": "[23] Kuipers, Jack, Moffa, Giusi, & Heckerman, David. 2014. Addendum on the scoring of Gaussian directed acyclic graphical models. The Annals of Statistics, pp. 1689\u20131691.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuipers%2C%20Jack%20Moffa%2C%20Giusi%20Heckerman%2C%20David%20Addendum%20on%20the%20scoring%20of%20Gaussian%20directed%20acyclic%20graphical%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuipers%2C%20Jack%20Moffa%2C%20Giusi%20Heckerman%2C%20David%20Addendum%20on%20the%20scoring%20of%20Gaussian%20directed%20acyclic%20graphical%20models%202014"
        },
        {
            "id": "24",
            "entry": "[24] Loh, Po-Ling, & B\u00fchlmann, Peter. 2014. High-Dimensional Learning of Linear Causal Networks via Inverse Covariance Estimation. Journal of Machine Learning Research, 15, 3065\u20133105.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loh%2C%20Po-Ling%20B%C3%BChlmann%2C%20Peter%20High-Dimensional%20Learning%20of%20Linear%20Causal%20Networks%20via%20Inverse%20Covariance%20Estimation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Loh%2C%20Po-Ling%20B%C3%BChlmann%2C%20Peter%20High-Dimensional%20Learning%20of%20Linear%20Causal%20Networks%20via%20Inverse%20Covariance%20Estimation%202014"
        },
        {
            "id": "25",
            "entry": "[25] Nemirovski, Arkadi. 1999. Optimization II: Standard Numerical Methods for Nonlinear Continuous Optimization.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovski%2C%20Arkadi%20Optimization%20II%3A%20Standard%20Numerical%20Methods%20for%20Nonlinear%20Continuous%20Optimization%201999"
        },
        {
            "id": "26",
            "entry": "[26] Nesterov, Yurii. 2005. Smooth minimization of non-smooth functions. Mathematical Programming.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Smooth%20minimization%20of%20non-smooth%20functions.%20Mathematical%20Programming%202005"
        },
        {
            "id": "27",
            "entry": "[27] Niinim\u00e4ki, Teppo, Parviainen, Pekka, & Koivisto, Mikko. 2016. Structure discovery in Bayesian networks by sampling partial orders. Journal of Machine Learning Research, 17(1), 2002\u20132048.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Niinim%C3%A4ki%2C%20Teppo%20Parviainen%2C%20Pekka%20Koivisto%2C%20Mikko%20Structure%20discovery%20in%20Bayesian%20networks%20by%20sampling%20partial%20orders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Niinim%C3%A4ki%2C%20Teppo%20Parviainen%2C%20Pekka%20Koivisto%2C%20Mikko%20Structure%20discovery%20in%20Bayesian%20networks%20by%20sampling%20partial%20orders%202016"
        },
        {
            "id": "28",
            "entry": "[28] Nocedal, Jorge, & Wright, Stephen J. 2006. Numerical Optimization.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nocedal%20Jorge%20%20Wright%20Stephen%20J%202006%20Numerical%20Optimization",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nocedal%20Jorge%20%20Wright%20Stephen%20J%202006%20Numerical%20Optimization"
        },
        {
            "id": "29",
            "entry": "[29] Ott, Sascha, & Miyano, Satoru. 2003. Finding optimal gene networks using biological constraints. Genome Informatics, 14, 124\u2013133.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ott%2C%20Sascha%20Miyano%2C%20Satoru%20Finding%20optimal%20gene%20networks%20using%20biological%20constraints%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ott%2C%20Sascha%20Miyano%2C%20Satoru%20Finding%20optimal%20gene%20networks%20using%20biological%20constraints%202003"
        },
        {
            "id": "30",
            "entry": "[30] Ramsey, Joseph, Glymour, Madelyn, Sanchez-Romero, Ruben, & Glymour, Clark. 2016. A million variables and more: the Fast Greedy Equivalence Search algorithm for learning highdimensional graphical causal models, with an application to functional magnetic resonance images. International Journal of Data Science and Analytics, pp. 1\u20139.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramsey%2C%20Joseph%20Glymour%2C%20Madelyn%20Sanchez-Romero%2C%20Ruben%20Glymour%2C%20Clark%20A%20million%20variables%20and%20more%3A%20the%20Fast%20Greedy%20Equivalence%20Search%20algorithm%20for%20learning%20highdimensional%20graphical%20causal%20models%2C%20with%20an%20application%20to%20functional%20magnetic%20resonance%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ramsey%2C%20Joseph%20Glymour%2C%20Madelyn%20Sanchez-Romero%2C%20Ruben%20Glymour%2C%20Clark%20A%20million%20variables%20and%20more%3A%20the%20Fast%20Greedy%20Equivalence%20Search%20algorithm%20for%20learning%20highdimensional%20graphical%20causal%20models%2C%20with%20an%20application%20to%20functional%20magnetic%20resonance%20images%202016"
        },
        {
            "id": "31",
            "entry": "[31] Robinson, Robert W. 1977. Counting unlabeled acyclic digraphs. In Combinatorial mathematics V. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robinson%2C%20Robert%20W.%20Counting%20unlabeled%20acyclic%20digraphs.%20In%20Combinatorial%20mathematics%20V%201977"
        },
        {
            "id": "32",
            "entry": "[32] Sachs, Karen, Perez, Omar, Pe\u2019er, Dana, Lauffenburger, Douglas A, & Nolan, Garry P. 2005. Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308(5721), 523\u2013529.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sachs%2C%20Karen%20Perez%2C%20Omar%20Pe%E2%80%99er%2C%20Dana%20Lauffenburger%2C%20Douglas%20A.%20Causal%20protein-signaling%20networks%20derived%20from%20multiparameter%20single-cell%20data%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sachs%2C%20Karen%20Perez%2C%20Omar%20Pe%E2%80%99er%2C%20Dana%20Lauffenburger%2C%20Douglas%20A.%20Causal%20protein-signaling%20networks%20derived%20from%20multiparameter%20single-cell%20data%202005"
        },
        {
            "id": "33",
            "entry": "[33] Scanagatta, Mauro, de Campos, Cassio P, Corani, Giorgio, & Zaffalon, Marco. 2015. Learning Bayesian networks with thousands of variables. In Advances in Neural Information Processing Systems. pp. 1864\u20131872.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scanagatta%2C%20Mauro%20de%20Campos%20P%2C%20Cassio%20Corani%2C%20Giorgio%20Learning%20Bayesian%20networks%20with%20thousands%20of%20variables%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scanagatta%2C%20Mauro%20de%20Campos%20P%2C%20Cassio%20Corani%2C%20Giorgio%20Learning%20Bayesian%20networks%20with%20thousands%20of%20variables%202015"
        },
        {
            "id": "34",
            "entry": "[34] Scanagatta, Mauro, Corani, Giorgio, de Campos, Cassio P, & Zaffalon, Marco. 2016. Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables. In Advances in Neural Information Processing Systems. pp. 1462\u20131470.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scanagatta%2C%20Mauro%20Corani%2C%20Giorgio%20de%20Campos%20P%2C%20Cassio%20Learning%20Treewidth-Bounded%20Bayesian%20Networks%20with%20Thousands%20of%20Variables%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scanagatta%2C%20Mauro%20Corani%2C%20Giorgio%20de%20Campos%20P%2C%20Cassio%20Learning%20Treewidth-Bounded%20Bayesian%20Networks%20with%20Thousands%20of%20Variables%202016"
        },
        {
            "id": "35",
            "entry": "[35] Schmidt, Mark, Niculescu-Mizil, Alexandru, & Murphy, Kevin. 2007. Learning graphical model structure using L1-regularization paths. In AAAI, vol. 7. pp. 1278\u20131283.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidt%2C%20Mark%20Niculescu-Mizil%2C%20Alexandru%20Murphy%2C%20Kevin%20Learning%20graphical%20model%20structure%20using%20L1-regularization%20paths%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmidt%2C%20Mark%20Niculescu-Mizil%2C%20Alexandru%20Murphy%2C%20Kevin%20Learning%20graphical%20model%20structure%20using%20L1-regularization%20paths%202007"
        },
        {
            "id": "36",
            "entry": "[36] Schmidt, Mark, Berg, Ewout, Friedlander, Michael, & Murphy, Kevin. 2009. Optimizing costly functions with simple constraints: A limited-memory projected quasi-newton algorithm. In Artificial Intelligence and Statistics. pp. 456\u2013463.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidt%2C%20Mark%20Berg%2C%20Ewout%20Friedlander%2C%20Michael%20Murphy%2C%20Kevin%20Optimizing%20costly%20functions%20with%20simple%20constraints%3A%20A%20limited-memory%20projected%20quasi-newton%20algorithm%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmidt%2C%20Mark%20Berg%2C%20Ewout%20Friedlander%2C%20Michael%20Murphy%2C%20Kevin%20Optimizing%20costly%20functions%20with%20simple%20constraints%3A%20A%20limited-memory%20projected%20quasi-newton%20algorithm%202009"
        },
        {
            "id": "37",
            "entry": "[37] Shimizu, Shohei, Hoyer, Patrik O, Hyv\u00e4rinen, Aapo, & Kerminen, Antti. 2006. A linear non-Gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7, 2003\u20132030.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shimizu%2C%20Shohei%20Hoyer%2C%20Patrik%20O.%20Hyv%C3%A4rinen%2C%20Aapo%20Kerminen%2C%20Antti%20A%20linear%20non-Gaussian%20acyclic%20model%20for%20causal%20discovery%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shimizu%2C%20Shohei%20Hoyer%2C%20Patrik%20O.%20Hyv%C3%A4rinen%2C%20Aapo%20Kerminen%2C%20Antti%20A%20linear%20non-Gaussian%20acyclic%20model%20for%20causal%20discovery%202006"
        },
        {
            "id": "38",
            "entry": "[38] Silander, Tomi, & Myllymaki, Petri. 2006. A simple approach for finding the globally optimal Bayesian network structure. In Proceedings of the 22nd Conference on Uncertainty in Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silander%2C%20Tomi%20Myllymaki%2C%20Petri%20A%20simple%20approach%20for%20finding%20the%20globally%20optimal%20Bayesian%20network%20structure%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silander%2C%20Tomi%20Myllymaki%2C%20Petri%20A%20simple%20approach%20for%20finding%20the%20globally%20optimal%20Bayesian%20network%20structure%202006"
        },
        {
            "id": "39",
            "entry": "[39] Singh, Ajit P, & Moore, Andrew W. 2005. Finding optimal Bayesian networks by dynamic programming.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Singh%2C%20Ajit%20P.%20Moore%2C%20Andrew%20W.%20Finding%20optimal%20Bayesian%20networks%20by%20dynamic%20programming%202005"
        },
        {
            "id": "40",
            "entry": "[40] Spirtes, Peter, & Glymour, Clark. 1991. An algorithm for fast recovery of sparse causal graphs. Social Science Computer Review, 9(1), 62\u201372.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spirtes%2C%20Peter%20Glymour%2C%20Clark%20An%20algorithm%20for%20fast%20recovery%20of%20sparse%20causal%20graphs%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Spirtes%2C%20Peter%20Glymour%2C%20Clark%20An%20algorithm%20for%20fast%20recovery%20of%20sparse%20causal%20graphs%201991"
        },
        {
            "id": "41",
            "entry": "[41] Spirtes, Peter, Glymour, Clark, & Scheines, Richard. 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spirtes%20Peter%20Glymour%20Clark%20%20Scheines%20Richard%202000"
        },
        {
            "id": "42",
            "entry": "[42] Teyssier, Marc, & Koller, Daphne. 2005. Ordering-based search: A simple and effective algorithm for learning Bayesian networks. In Uncertainty in Artifical Intelligence (UAI).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Teyssier%2C%20Marc%20Koller%2C%20Daphne%20Ordering-based%20search%3A%20A%20simple%20and%20effective%20algorithm%20for%20learning%20Bayesian%20networks%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Teyssier%2C%20Marc%20Koller%2C%20Daphne%20Ordering-based%20search%3A%20A%20simple%20and%20effective%20algorithm%20for%20learning%20Bayesian%20networks%202005"
        },
        {
            "id": "43",
            "entry": "[43] Tsamardinos, Ioannis, Brown, Laura E, & Aliferis, Constantin F. 2006. The max-min hillclimbing Bayesian network structure learning algorithm. Machine Learning, 65(1), 31\u201378.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsamardinos%2C%20Ioannis%20Brown%2C%20Laura%20E.%20Aliferis%2C%20Constantin%20F.%20The%20max-min%20hillclimbing%20Bayesian%20network%20structure%20learning%20algorithm%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsamardinos%2C%20Ioannis%20Brown%2C%20Laura%20E.%20Aliferis%2C%20Constantin%20F.%20The%20max-min%20hillclimbing%20Bayesian%20network%20structure%20learning%20algorithm%202006"
        },
        {
            "id": "44",
            "entry": "[44] van de Geer, Sara, & B\u00fchlmann, Peter. 2013. 0-penalized maximum likelihood for sparse directed acyclic graphs. Annals of Statistics, 41(2), 536\u2013567.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20de%20Geer%20Sara%20B%C3%BChlmann%2C%20Peter%200-penalized%20maximum%20likelihood%20for%20sparse%20directed%20acyclic%20graphs%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20de%20Geer%20Sara%20B%C3%BChlmann%2C%20Peter%200-penalized%20maximum%20likelihood%20for%20sparse%20directed%20acyclic%20graphs%202013"
        },
        {
            "id": "45",
            "entry": "[45] Wang, Xiangyu, Dunson, David, & Leng, Chenlei. 2016. No penalty no tears: Least squares in high-dimensional linear models. In International Conference on Machine Learning. pp. 1814\u2013 1822.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Xiangyu%20Dunson%2C%20David%20Leng%2C%20Chenlei%20No%20penalty%20no%20tears%3A%20Least%20squares%20in%20high-dimensional%20linear%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Xiangyu%20Dunson%2C%20David%20Leng%2C%20Chenlei%20No%20penalty%20no%20tears%3A%20Least%20squares%20in%20high-dimensional%20linear%20models%202016"
        },
        {
            "id": "46",
            "entry": "[46] Xiang, Jing, & Kim, Seyoung. 2013. A* Lasso for Learning a Sparse Bayesian Network Structure for Continuous Variables. In Advances in Neural Information Processing Systems. pp. 2418\u20132426.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xiang%2C%20Jing%20Kim%2C%20Seyoung%20A%2A%20Lasso%20for%20Learning%20a%20Sparse%20Bayesian%20Network%20Structure%20for%20Continuous%20Variables%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xiang%2C%20Jing%20Kim%2C%20Seyoung%20A%2A%20Lasso%20for%20Learning%20a%20Sparse%20Bayesian%20Network%20Structure%20for%20Continuous%20Variables%202013"
        },
        {
            "id": "47",
            "entry": "[47] Yuan, Ming, & Lin, Yi. 2007. Model selection and estimation in the Gaussian graphical model. Biometrika, 94(1), 19\u201335.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yuan%2C%20Ming%20Lin%2C%20Yi%20Model%20selection%20and%20estimation%20in%20the%20Gaussian%20graphical%20model%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yuan%2C%20Ming%20Lin%2C%20Yi%20Model%20selection%20and%20estimation%20in%20the%20Gaussian%20graphical%20model%202007"
        },
        {
            "id": "48",
            "entry": "[48] Zhang, Bin, Gaiteri, Chris, Bodea, Liviu-Gabriel, Wang, Zhi, McElwee, Joshua, Podtelezhnikov, Alexei A, Zhang, Chunsheng, Xie, Tao, Tran, Linh, Dobrin, Radu, et al. 2013. Integrated systems approach identifies genetic nodes and networks in late-onset Alzheimer\u2019s disease. Cell, 153(3), 707\u2013720.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Bin%20Gaiteri%2C%20Chris%20Bodea%2C%20Liviu-Gabriel%20Wang%2C%20Zhi%20Integrated%20systems%20approach%20identifies%20genetic%20nodes%20and%20networks%20in%20late-onset%20Alzheimer%E2%80%99s%20disease%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Bin%20Gaiteri%2C%20Chris%20Bodea%2C%20Liviu-Gabriel%20Wang%2C%20Zhi%20Integrated%20systems%20approach%20identifies%20genetic%20nodes%20and%20networks%20in%20late-onset%20Alzheimer%E2%80%99s%20disease%202013"
        },
        {
            "id": "49",
            "entry": "[49] Zhong, Kai, Yen, Ian En-Hsu, Dhillon, Inderjit S, & Ravikumar, Pradeep K. 2014. Proximal quasi-Newton for computationally intensive l1-regularized m-estimators. In Advances in Neural Information Processing Systems. pp. 2375\u20132383.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhong%2C%20Kai%20Yen%2C%20Ian%20En-Hsu%20Dhillon%2C%20Inderjit%20S.%20Ravikumar%2C%20Pradeep%20K.%20Proximal%20quasi-Newton%20for%20computationally%20intensive%20l1-regularized%20m-estimators%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhong%2C%20Kai%20Yen%2C%20Ian%20En-Hsu%20Dhillon%2C%20Inderjit%20S.%20Ravikumar%2C%20Pradeep%20K.%20Proximal%20quasi-Newton%20for%20computationally%20intensive%20l1-regularized%20m-estimators%202014"
        },
        {
            "id": "50",
            "entry": "[50] Zhou, Qing. 2011. Multi-Domain Sampling With Applications to Structural Inference of Bayesian Networks. Journal of the American Statistical Association, 106(496), 1317\u20131330.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Qing%20Multi-Domain%20Sampling%20With%20Applications%20to%20Structural%20Inference%20of%20Bayesian%20Networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20Qing%20Multi-Domain%20Sampling%20With%20Applications%20to%20Structural%20Inference%20of%20Bayesian%20Networks%202011"
        },
        {
            "id": "51",
            "entry": "[51] Zhou, Shuheng. 2009. Thresholding procedures for high dimensional variable selection and statistical estimation. In Advances in Neural Information Processing Systems. pp. 2304\u20132312. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Shuheng%20Thresholding%20procedures%20for%20high%20dimensional%20variable%20selection%20and%20statistical%20estimation%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20Shuheng%20Thresholding%20procedures%20for%20high%20dimensional%20variable%20selection%20and%20statistical%20estimation%202009"
        }
    ]
}
