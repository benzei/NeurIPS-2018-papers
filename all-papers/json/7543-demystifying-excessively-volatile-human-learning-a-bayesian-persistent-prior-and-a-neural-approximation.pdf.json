{
    "filename": "7543-demystifying-excessively-volatile-human-learning-a-bayesian-persistent-prior-and-a-neural-approximation.pdf",
    "metadata": {
        "title": "Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation",
        "author": "Chaitanya Ryali, Gautam Reddy, Angela J. Yu",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7543-demystifying-excessively-volatile-human-learning-a-bayesian-persistent-prior-and-a-neural-approximation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Understanding how humans and animals learn about statistical regularities in stable and volatile environments, and utilize these regularities to make predictions and decisions, is an important problem in neuroscience and psychology. Using a Bayesian modeling framework, specifically the Dynamic Belief Model (DBM), it has previously been shown that humans tend to make the default assumption that environmental statistics undergo abrupt, unsignaled changes, even when environmental statistics are actually stable. Because exact Bayesian inference in this setting, an example of switching state space models, is computationally intensive, a number of approximately Bayesian and heuristic algorithms have been proposed to account for learning/prediction in the brain. Here, we examine a neurally plausible algorithm, a special case of leaky integration dynamics we denote as EXP (for exponential filtering), that is significantly simpler than all previously suggested algorithms except for the delta-learning rule, and which far outperforms the delta rule in approximating Bayesian prediction performance. We derive the theoretical relationship between DBM and EXP, and show that EXP gains computational efficiency by foregoing the representation of inferential uncertainty (as does the delta rule), but that it nevertheless achieves near-Bayesian performance due to its ability to incorporate a \"persistent prior\" influence unique to DBM and absent from the other algorithms. Furthermore, we show that EXP is comparable to DBM but better than all other models in reproducing human behavior in a visual search task, suggesting that human learning and prediction also incorporates an element of persistent prior. More broadly, our work demonstrates that when observations are information-poor, detecting changes or modulating the learning rate is both difficult and thus unnecessary for making Bayes-optimal predictions."
    },
    "keywords": [
        {
            "term": "state space",
            "url": "https://en.wikipedia.org/wiki/state_space"
        },
        {
            "term": "information poor",
            "url": "https://en.wikipedia.org/wiki/information_poor"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "human learning",
            "url": "https://en.wikipedia.org/wiki/human_learning"
        }
    ],
    "highlights": [
        "Understanding how humans and animals make future predictions based on changing environmental statistics is an important problem in both neuroscience and psychology [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "We have shown that the Dynamic Belief Model-like human learning/prediction found in previous studies can be implemented by appropriately tuned leaky integrating neuronal dynamics (EXP)",
        "We showed that Exponential Filtering approximates Dynamic Belief Model well in all but extremely stable environments, and does so via both exponential discounting of past observations, and a persistent influence of a prior bias that is injected on every trial",
        "Our work shows that when observations are information-poor, detecting changes or modulating the learning rate explicitly or implicitly is both difficult and () unnecessary for making Bayes-optimal predictions",
        "M-ary Dynamic Belief Model is typically implemented via discretization of the belief state space [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], which has a computational and representational complexity of O per observation, where k depends on fineness of the discretization, while the near exact-Bayes approximation Exponential Filtering is only O(m)",
        "This is broadly consonant with our related finding that Dynamic Belief Model not only provides a better trial-by-trial account of human-choices in a multi-arm bandit task, but is able to recover a systematic underestimation in human prior reward rate expectation \u2013 this \u201cpessimism bias\u201d is incompletely captured by reinforcement learning and Fixed Belief Model [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>]"
    ],
    "key_statements": [
        "Understanding how humans and animals make future predictions based on changing environmental statistics is an important problem in both neuroscience and psychology [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]",
        "Dynamic Belief Model and Exponential Filtering are biased to a similar extent",
        "We have shown that the Dynamic Belief Model-like human learning/prediction found in previous studies can be implemented by appropriately tuned leaky integrating neuronal dynamics (EXP)",
        "While we derived an analytical form for the appropriate Exponential Filtering parameters for volatile environments, we have shown that even for less volatile environments, where our analytical approximation does not hold, the empirically fitted Exponential Filtering still achieves near-Bayes performance",
        "We showed that Exponential Filtering approximates Dynamic Belief Model well in all but extremely stable environments, and does so via both exponential discounting of past observations, and a persistent influence of a prior bias that is injected on every trial",
        "Our work shows that when observations are information-poor, detecting changes or modulating the learning rate explicitly or implicitly is both difficult and () unnecessary for making Bayes-optimal predictions",
        "M-ary Dynamic Belief Model is typically implemented via discretization of the belief state space [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], which has a computational and representational complexity of O per observation, where k depends on fineness of the discretization, while the near exact-Bayes approximation Exponential Filtering is only O(m)",
        "This is broadly consonant with our related finding that Dynamic Belief Model not only provides a better trial-by-trial account of human-choices in a multi-arm bandit task, but is able to recover a systematic underestimation in human prior reward rate expectation \u2013 this \u201cpessimism bias\u201d is incompletely captured by reinforcement learning and Fixed Belief Model [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>]"
    ],
    "summary": [
        "Understanding how humans and animals make future predictions based on changing environmental statistics is an important problem in both neuroscience and psychology [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>].",
        "Eq (9) is reminiscent of the delta rule: Gt (0 \u2264 Gt \u2264 1, for any binary sequence x1:t) acts like an adaptive learning rate, governing the trade-off between new data xt and the previous predictive mean, Pt; an additional parameter \u03b1 governs the trade-off between this combined prediction and a constant bias P0, which inserts persistent prior influence due to the recurring probability of \u03b3 being re-sampled.",
        "In terms of the behaviorally more relevant predictive accuracy measure, EXP still approximates DBM well (Fig. 2b).",
        "Term in Gt hold for m > 2, the quality of the approximation will be the same as the binary case, so that in volatile environments, near-Bayesian prediction can be achieved by using m \u2212 1 separate linear-exponential filters with no recurrent or complex interactions among the alternatives.",
        "We have shown that the DBM-like human learning/prediction found in previous studies can be implemented by appropriately tuned leaky integrating neuronal dynamics (EXP).",
        "We showed that EXP approximates DBM well in all but extremely stable environments, and does so via both exponential discounting of past observations, and a persistent influence of a prior bias that is injected on every trial.",
        "Our work shows that when observations are information-poor, detecting changes or modulating the learning rate explicitly or implicitly is both difficult and unnecessary for making Bayes-optimal predictions.",
        "M-ary DBM is typically implemented via discretization of the belief state space [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], which has a computational and representational complexity of O per observation, where k depends on fineness of the discretization, while the near exact-Bayes approximation EXP is only O(m).",
        "We found that DBM & EXP both explain human choice behavior in a visual search task [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] better than RL, which has exponential discounting but no persistent prior influence, and FBM, which has neither.",
        "We have done separate simulations to show that, in comparison to binary or categorical data, when mutual information between hidden state and observations is high, Bayesian detection of change points can be highly accurate, and the corresponding \u201clearning rate\u201d of its equivalent leaky-integrating update equation significantly increases after detecting such a change.",
        "One might consider a model that assumes the underlying real-valued hidden variable to undergo persistent stochastic changes with constant noisy characteristics, such as a Gaussian process, which gives rise to noisy binary or categorical observations."
    ],
    "headline": "We examine a neurally plausible algorithm, a special case of leaky integration dynamics we denote as Exponential Filtering , that is significantly simpler than all previously suggested algorithms except for the delta-learning rule, and which far outperforms the delta rule in approximating Bayesian prediction performance",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Yu, A. J. & Dayan, P. Expected and unexpected uncertainty: ACh and NE in the neocortex. In Advances in Neural Information Processing Systems, 173\u2013180 (2003).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20A.J.%20Dayan%2C%20P.%20Expected%20and%20unexpected%20uncertainty%3A%20ACh%20and%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20A.J.%20Dayan%2C%20P.%20Expected%20and%20unexpected%20uncertainty%3A%20ACh%20and%202003"
        },
        {
            "id": "2",
            "entry": "[2] Sugrue, L. P., Corrado, G. S. & Newsome, W. T. Matching behavior and the representation of value in the parietal cortex. science 304, 1782\u20131787 (2004).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sugrue%2C%20L.P.%20Corrado%2C%20G.S.%20Newsome%2C%20W.T.%20Matching%20behavior%20and%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sugrue%2C%20L.P.%20Corrado%2C%20G.S.%20Newsome%2C%20W.T.%20Matching%20behavior%20and%202004"
        },
        {
            "id": "3",
            "entry": "[3] Yu, A. J. & Dayan, P. Uncertainty, neuromodulation, and attention. Neuron 46, 681\u2013692 (2005).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%20A%20J%20%20Dayan%20P%20Uncertainty%20neuromodulation%20and%20attention%20Neuron%2046%20681692%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%20A%20J%20%20Dayan%20P%20Uncertainty%20neuromodulation%20and%20attention%20Neuron%2046%20681692%202005"
        },
        {
            "id": "4",
            "entry": "[4] Daw, N. D., O\u2019doherty, J. P., Dayan, P., Seymour, B. & Dolan, R. J. Cortical substrates for exploratory decisions in humans. Nature 441, 876 (2006).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daw%2C%20N.D.%20O%E2%80%99doherty%2C%20J.P.%20Dayan%2C%20P.%20Seymour%2C%20B.%20Cortical%20substrates%20for%20exploratory%20decisions%20in%20humans%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daw%2C%20N.D.%20O%E2%80%99doherty%2C%20J.P.%20Dayan%2C%20P.%20Seymour%2C%20B.%20Cortical%20substrates%20for%20exploratory%20decisions%20in%20humans%202006"
        },
        {
            "id": "5",
            "entry": "[5] Behrens, T. E., Woolrich, M. W., Walton, M. E. & Rushworth, M. F. Learning the value of information in an uncertain world. Nature neuroscience 10, 1214 (2007).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Behrens%2C%20T.E.%20Woolrich%2C%20M.W.%20Walton%2C%20M.E.%20Rushworth%2C%20M.F.%20Learning%20the%20value%20of%20information%20in%20an%20uncertain%20world%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Behrens%2C%20T.E.%20Woolrich%2C%20M.W.%20Walton%2C%20M.E.%20Rushworth%2C%20M.F.%20Learning%20the%20value%20of%20information%20in%20an%20uncertain%20world%202007"
        },
        {
            "id": "6",
            "entry": "[6] Nassar, M. R. et al. Rational regulation of learning dynamics by pupil-linked arousal systems. Nature neuroscience 15, 1040 (2012).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nassar%2C%20M.R.%20Rational%20regulation%20of%20learning%20dynamics%20by%20pupil-linked%20arousal%20systems%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nassar%2C%20M.R.%20Rational%20regulation%20of%20learning%20dynamics%20by%20pupil-linked%20arousal%20systems%202012"
        },
        {
            "id": "7",
            "entry": "[7] Yu, A. J. & Cohen, J. D. Sequential effects: Superstition or rational behavior? In Advances in Neural Information Processing Systems, 1873\u20131880 (2009).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20A.J.%20Cohen%2C%20J.D.%20Sequential%20effects%3A%20Superstition%20or%20rational%20behavior%3F%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20A.J.%20Cohen%2C%20J.D.%20Sequential%20effects%3A%20Superstition%20or%20rational%20behavior%3F%202009"
        },
        {
            "id": "8",
            "entry": "[8] Wilder, M., Jones, M. & Mozer, M. C. Sequential effects reflect parallel learning of multiple environmental regularities. In Advances in Neural Information Processing Systems, 2053\u20132061 (2009).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wilder%2C%20M.%20Jones%2C%20M.%20Mozer%2C%20M.C.%20Sequential%20effects%20reflect%20parallel%20learning%20of%20multiple%20environmental%20regularities%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wilder%2C%20M.%20Jones%2C%20M.%20Mozer%2C%20M.C.%20Sequential%20effects%20reflect%20parallel%20learning%20of%20multiple%20environmental%20regularities%202009"
        },
        {
            "id": "9",
            "entry": "[9] Ma, N. & Yu, A. J. Statistical learning and adaptive decision-making underlie human response time variability in inhibitory control. Frontiers in psychology 6, 1046 (2015).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20N.%20Yu%2C%20A.J.%20Statistical%20learning%20and%20adaptive%20decision-making%20underlie%20human%20response%20time%20variability%20in%20inhibitory%20control%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20N.%20Yu%2C%20A.J.%20Statistical%20learning%20and%20adaptive%20decision-making%20underlie%20human%20response%20time%20variability%20in%20inhibitory%20control%202015"
        },
        {
            "id": "10",
            "entry": "[10] Ide, J. S., Shenoy, P., Yu, A. J. & Chiang-Shan, R. L. Bayesian prediction and evaluation in the anterior cingulate cortex. Journal of Neuroscience 33, 2039\u20132047 (2013).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ide%2C%20J.S.%20Shenoy%2C%20P.%20Yu%2C%20A.J.%20Chiang-Shan%2C%20R.L.%20Bayesian%20prediction%20and%20evaluation%20in%20the%20anterior%20cingulate%20cortex%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ide%2C%20J.S.%20Shenoy%2C%20P.%20Yu%2C%20A.J.%20Chiang-Shan%2C%20R.L.%20Bayesian%20prediction%20and%20evaluation%20in%20the%20anterior%20cingulate%20cortex%202013"
        },
        {
            "id": "11",
            "entry": "[11] Yu, A. J. & Huang, H. Maximizing masquerading as matching in human visual search choice behavior. Decision 1, 275\u2013287 (2014).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20A.J.%20Huang%2C%20H.%20Maximizing%20masquerading%20as%20matching%20in%20human%20visual%20search%20choice%20behavior%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20A.J.%20Huang%2C%20H.%20Maximizing%20masquerading%20as%20matching%20in%20human%20visual%20search%20choice%20behavior%202014"
        },
        {
            "id": "12",
            "entry": "[12] Zhang, S. & Yu, A. J. Forgetful Bayes and myopic planning: Human learning and decision-making in a bandit setting. In Advances in Neural Information Processing Systems, 2607\u20132615 (2013).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20S.%20Yu%2C%20A.J.%20Forgetful%20Bayes%20and%20myopic%20planning%3A%20Human%20learning%20and%20decision-making%20in%20a%20bandit%20setting%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20S.%20Yu%2C%20A.J.%20Forgetful%20Bayes%20and%20myopic%20planning%3A%20Human%20learning%20and%20decision-making%20in%20a%20bandit%20setting%202013"
        },
        {
            "id": "13",
            "entry": "[13] Bialek, W., Nemenman, I. & Tishby, N. Predictability, complexity, and learning. Neural computation 13, 2409\u20132463 (2001).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bialek%2C%20W.%20Nemenman%2C%20I.%20Tishby%2C%20N.%20Predictability%2C%20complexity%2C%20and%20learning%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bialek%2C%20W.%20Nemenman%2C%20I.%20Tishby%2C%20N.%20Predictability%2C%20complexity%2C%20and%20learning%202001"
        },
        {
            "id": "14",
            "entry": "[14] Guo, D. & Yu, A. J. Why so gloomy? A Bayesian explanation of human pessimism bias in the multi-armed bandit task. In Advances in Neural Information Processing Systems (2018).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20D.%20Yu%2C%20A.J.%20Why%20so%20gloomy%3F%20A%20Bayesian%20explanation%20of%20human%20pessimism%20bias%20in%20the%20multi-armed%20bandit%20task%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20D.%20Yu%2C%20A.J.%20Why%20so%20gloomy%3F%20A%20Bayesian%20explanation%20of%20human%20pessimism%20bias%20in%20the%20multi-armed%20bandit%20task%202018"
        },
        {
            "id": "15",
            "entry": "[15] Ghahramani, Z. & Hinton, G. E. Variational learning for switching state-space models. Neural computation 12, 831\u2013864 (2000).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghahramani%2C%20Z.%20Hinton%2C%20G.E.%20Variational%20learning%20for%20switching%20state-space%20models%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghahramani%2C%20Z.%20Hinton%2C%20G.E.%20Variational%20learning%20for%20switching%20state-space%20models%202000"
        },
        {
            "id": "16",
            "entry": "[16] Nassar, M. R., Wilson, R. C., Heasly, B. & Gold, J. I. An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment. Journal of Neuroscience 30, 12366\u201312378 (2010).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nassar%2C%20M.R.%20Wilson%2C%20R.C.%20Heasly%2C%20B.%20Gold%2C%20J.I.%20An%20approximately%20Bayesian%20delta-rule%20model%20explains%20the%20dynamics%20of%20belief%20updating%20in%20a%20changing%20environment%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nassar%2C%20M.R.%20Wilson%2C%20R.C.%20Heasly%2C%20B.%20Gold%2C%20J.I.%20An%20approximately%20Bayesian%20delta-rule%20model%20explains%20the%20dynamics%20of%20belief%20updating%20in%20a%20changing%20environment%202010"
        },
        {
            "id": "17",
            "entry": "[17] Wilson, R. C., Nassar, M. R. & Gold, J. I. A mixture of delta-rules approximation to Bayesian inference in change-point problems. PLoS computational biology 9, e1003150 (2013).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wilson%2C%20R.C.%20Nassar%2C%20M.R.%20Gold%2C%20J.I.%20A%20mixture%20of%20delta-rules%20approximation%20to%20Bayesian%20inference%20in%20change-point%20problems%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wilson%2C%20R.C.%20Nassar%2C%20M.R.%20Gold%2C%20J.I.%20A%20mixture%20of%20delta-rules%20approximation%20to%20Bayesian%20inference%20in%20change-point%20problems%202013"
        },
        {
            "id": "18",
            "entry": "[18] Rescorla, R. A. & Wagner, A. R. A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement. Classical conditioning II: Current research and theory 2, 64\u201399 (1972).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rescorla%2C%20R.A.%20Wagner%2C%20A.R.%20A%20theory%20of%20Pavlovian%20conditioning%3A%20Variations%20in%20the%20effectiveness%20of%20reinforcement%20and%20nonreinforcement.%20Classical%20conditioning%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rescorla%2C%20R.A.%20Wagner%2C%20A.R.%20A%20theory%20of%20Pavlovian%20conditioning%3A%20Variations%20in%20the%20effectiveness%20of%20reinforcement%20and%20nonreinforcement.%20Classical%20conditioning%201972"
        },
        {
            "id": "19",
            "entry": "[19] Sutton, R. S. & Barto, A. G. Reinforcement Learning: An Introduction (MIT press, 1998).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutton%2C%20R.S.%20Barto%2C%20A.G.%20Reinforcement%20Learning%3A%20An%20Introduction%201998"
        },
        {
            "id": "20",
            "entry": "[20] Ahmad, S., Huang, H. & Yu, A. J. Cost-sensitive Bayesian control policy in human active sensing. Frontiers in Human Neuroscience 8 (2014).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahmad%2C%20S.%20Huang%2C%20H.%20Yu%2C%20A.J.%20Cost-sensitive%20Bayesian%20control%20policy%20in%20human%20active%20sensing%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahmad%2C%20S.%20Huang%2C%20H.%20Yu%2C%20A.J.%20Cost-sensitive%20Bayesian%20control%20policy%20in%20human%20active%20sensing%202014"
        },
        {
            "id": "21",
            "entry": "[21] Herrnstein, R. J. Relative and absolute strength of response as a function of frequency of reinforcement 1, 2. Journal of the experimental analysis of behavior 4, 267\u2013272 (1961).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Herrnstein%2C%20R.J.%20Relative%20and%20absolute%20strength%20of%20response%20as%20a%20function%20of%20frequency%20of%20reinforcement%201%2C%202%201961",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Herrnstein%2C%20R.J.%20Relative%20and%20absolute%20strength%20of%20response%20as%20a%20function%20of%20frequency%20of%20reinforcement%201%2C%202%201961"
        },
        {
            "id": "22",
            "entry": "[22] Adams, R. P. & MacKay, D. J. C. Bayesian Online Changepoint Detection. arXiv:0710.3742 [stat] (2007).",
            "arxiv_url": "https://arxiv.org/pdf/0710.3742"
        },
        {
            "id": "23",
            "entry": "[23] Meyniel, F., Schlunegger, D. & Dehaene, S. The sense of confidence during probabilistic learning: A normative account. PLoS computational biology 11, e1004305 (2015).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meyniel%2C%20F.%20Schlunegger%2C%20D.%20Dehaene%2C%20S.%20The%20sense%20of%20confidence%20during%20probabilistic%20learning%3A%20A%20normative%20account%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Meyniel%2C%20F.%20Schlunegger%2C%20D.%20Dehaene%2C%20S.%20The%20sense%20of%20confidence%20during%20probabilistic%20learning%3A%20A%20normative%20account%202015"
        }
    ]
}
