{
    "filename": "7822-neural-interaction-transparency-nit-disentangling-learned-interactions-for-improved-interpretability.pdf",
    "metadata": {
        "title": "Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability",
        "author": "Michael Tsang, Hanpeng Liu, Sanjay Purushotham, Pavankumar Murali, Yan Liu",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7822-neural-interaction-transparency-nit-disentangling-learned-interactions-for-improved-interpretability.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Neural networks are known to model statistical interactions, but they entangle the interactions at intermediate hidden layers for shared representation learning. We propose a framework, Neural Interaction Transparency (NIT), that disentangles the shared learning across different interactions to obtain their intrinsic lower-order and interpretable structure. This is done through a novel regularizer that directly penalizes interaction order. We show that disentangling interactions reduces a feedforward neural network to a generalized additive model with interactions, which can lead to transparent models that perform comparably to the state-of-theart models. NIT is also flexible and efficient; it can learn generalized additive models with maximum K-order interactions by training only O(1) models."
    },
    "keywords": [
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "Random Forests",
            "url": "https://en.wikipedia.org/wiki/Random_Forest"
        },
        {
            "term": "Generalized Additive Models",
            "url": "https://en.wikipedia.org/wiki/Generalized_Additive_Model"
        },
        {
            "term": "statistical interaction",
            "url": "https://en.wikipedia.org/wiki/statistical_interaction"
        },
        {
            "term": "additive model",
            "url": "https://en.wikipedia.org/wiki/additive_model"
        },
        {
            "term": "feedforward neural network",
            "url": "https://en.wikipedia.org/wiki/feedforward_neural_network"
        },
        {
            "term": "Logistic Regression",
            "url": "https://en.wikipedia.org/wiki/Logistic_Regression"
        }
    ],
    "highlights": [
        "Feedforward neural networks are typically viewed as powerful predictive models possessing the ability to universally approximate any function [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>]",
        "We propose the Neural Interaction Transparency (NIT) framework to learn interpretable feedforward neural networks",
        "Constructing generalized additive models by disentangling interactions has important advantages, the main of which is that our Neural Interaction Transparency framework can learn the Generalized Additive Models in O(1) models, whereas previous methods either needed to learn a model for each interaction, or in the case of traditional univariate Generalized Additive Models [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], learn a model for each feature (Table 1)",
        "In Figure 1 we show that Neural Interaction Transparency disentangles the x1x2 and x3x4 pairwise interactions at all possible lower weight thresholds while maintaining a performance (RMSE = 1.3e \u2212 3) similar to that of Multilayer Perceptron",
        "We have investigated an interpretation of a feedforward neural network based on its entangling of interactions, and we proposed our framework, Neural Interaction Transparency, for disentangling the interactions to learn a more interpretable neural network"
    ],
    "key_statements": [
        "Feedforward neural networks are typically viewed as powerful predictive models possessing the ability to universally approximate any function [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>]",
        "An interaction is entangled in a neural network if any hidden unit learns an interaction out of separate true feature interactions",
        "The neural network entangles the interactions if any hidden unit learns an interaction between all four variables {1, 2, 3, 4}",
        "We propose the Neural Interaction Transparency (NIT) framework to learn interpretable feedforward neural networks",
        "Let S be the set of all true feature interactions {Ii}|iS=|1 in a dataset, and let h be any hidden unit in a feedforward neural network",
        "We desire a feedforward neural network that does not entangle interactions at any hidden layer so that each interaction is separated in additive form",
        "Constructing generalized additive models by disentangling interactions has important advantages, the main of which is that our Neural Interaction Transparency framework can learn the Generalized Additive Models in O(1) models, whereas previous methods either needed to learn a model for each interaction, or in the case of traditional univariate Generalized Additive Models [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], learn a model for each feature (Table 1)",
        "We study binary classification as opposed to multi-class classification to minimize learned interaction orders and accord with previous research on Generalized Additive Models [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>]",
        "We don\u2019t assume K, so we report the performances of Neural Interaction Transparency when varying K",
        "In Figure 1 we show that Neural Interaction Transparency disentangles the x1x2 and x3x4 pairwise interactions at all possible lower weight thresholds while maintaining a performance (RMSE = 1.3e \u2212 3) similar to that of Multilayer Perceptron",
        "On real-world datasets (Table 2), we evaluate the predictive performance of Neural Interaction Transparency at different levels of K, as shown in Table 3",
        "In Figure 4, we provide all visualizations of what Neural Interaction Transparency learns at K = 2 on one fold of the MIMIC-III dataset",
        "We have investigated an interpretation of a feedforward neural network based on its entangling of interactions, and we proposed our framework, Neural Interaction Transparency, for disentangling the interactions to learn a more interpretable neural network"
    ],
    "summary": [
        "Feedforward neural networks are typically viewed as powerful predictive models possessing the ability to universally approximate any function [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>].",
        "An interaction is entangled in a neural network if any hidden unit learns an interaction out of separate true feature interactions.",
        "The neural network entangles the interactions if any hidden unit learns an interaction between all four variables {1, 2, 3, 4}.",
        "We propose the Neural Interaction Transparency (NIT) framework to learn interpretable feedforward neural networks.",
        "NIT learns to separate feature interactions within the neural network by novel use of regularization.",
        "Our contributions are as follows: 1) we demonstrate that feedforward neural networks entangle interactions under sparsity regularization, 2) we develop a novel architecture and regularization framework, NIT, for disentangling the interactions to be order K at maximum, and 3) we construct a generalized additive model with interactions by training only O(1) models.",
        "Let S be the set of all true feature interactions {Ii}|iS=|1 in a dataset, and let h be any hidden unit in a feedforward neural network.",
        "We desire a feedforward neural network that does not entangle interactions at any hidden layer so that each interaction is separated in additive form.",
        "We explain our architecture and regularization framework, NIT, to disentangle interactions in a feedforward neural network.",
        "Constructing generalized additive models by disentangling interactions has important advantages, the main of which is that our NIT framework can learn the GAM in O(1) models, whereas previous methods either needed to learn a model for each interaction, or in the case of traditional univariate GAMs [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], learn a model for each feature (Table 1).",
        "Previous methods [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] have focused on advocating tree-based GAMs to interpret and visualize what the model learns, and there exist few works which have explored neural network based GAMs with interactions for interpretability.",
        "In all of our NIT models, we set B = 20 and use an equal number of hidden units per network block for any given hidden layer.",
        "NIT can learn a GAM with interactions in O(1) models, the disentangling phase in our training optimization can take longer with increasing p or B.",
        "We have investigated an interpretation of a feedforward neural network based on its entangling of interactions, and we proposed our framework, NIT, for disentangling the interactions to learn a more interpretable neural network.",
        "NIT corresponds to reducing a feedforward neural network to a generalized additive model (GAM) with interactions, allowing it to learn the GAM in O(1) models.",
        "We would like to study ways of making NIT perform at state-of-the-art levels for interaction detection in addition to obtaining high predictive performance under K-order constraints"
    ],
    "headline": "Neural Interaction Transparency , that disentangles the shared learning across different interactions to obtain their intrinsic lower-order and interpretable structure",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. Network dissection: Quantifying interpretability of deep visual representations. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 3319\u20133327. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bau%2C%20David%20Zhou%2C%20Bolei%20Khosla%2C%20Aditya%20Oliva%2C%20Aude%20Network%20dissection%3A%20Quantifying%20interpretability%20of%20deep%20visual%20representations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bau%2C%20David%20Zhou%2C%20Bolei%20Khosla%2C%20Aditya%20Oliva%2C%20Aude%20Network%20dissection%3A%20Quantifying%20interpretability%20of%20deep%20visual%20representations%202017"
        },
        {
            "id": "2",
            "entry": "[2] Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad. Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1721\u20131730. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caruana%2C%20Rich%20Lou%2C%20Yin%20Gehrke%2C%20Johannes%20Koch%2C%20Paul%20Intelligible%20models%20for%20healthcare%3A%20Predicting%20pneumonia%20risk%20and%20hospital%2030-day%20readmission%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caruana%2C%20Rich%20Lou%2C%20Yin%20Gehrke%2C%20Johannes%20Koch%2C%20Paul%20Intelligible%20models%20for%20healthcare%3A%20Predicting%20pneumonia%20risk%20and%20hospital%2030-day%20readmission%202015"
        },
        {
            "id": "3",
            "entry": "[3] Zhengping Che, Sanjay Purushotham, Robinder Khemani, and Yan Liu. Interpretable deep models for icu outcome prediction. In AMIA Annual Symposium Proceedings, volume 2016, page 371. American Medical Informatics Association, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Che%2C%20Zhengping%20Purushotham%2C%20Sanjay%20Khemani%2C%20Robinder%20Liu%2C%20Yan%20Interpretable%20deep%20models%20for%20icu%20outcome%20prediction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Che%2C%20Zhengping%20Purushotham%2C%20Sanjay%20Khemani%2C%20Robinder%20Liu%2C%20Yan%20Interpretable%20deep%20models%20for%20icu%20outcome%20prediction%202016"
        },
        {
            "id": "4",
            "entry": "[4] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "5",
            "entry": "[5] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 797\u2013806. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Corbett-Davies%2C%20Sam%20Pierson%2C%20Emma%20Feller%2C%20Avi%20Goel%2C%20Sharad%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Corbett-Davies%2C%20Sam%20Pierson%2C%20Emma%20Feller%2C%20Avi%20Goel%2C%20Sharad%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017"
        },
        {
            "id": "6",
            "entry": "[6] Hadi Fanaee-T and Joao Gama. Event labeling combining ensemble detectors and background knowledge. Progress in Artificial Intelligence, 2(2-3):113\u2013127, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fanaee-T%2C%20Hadi%20Gama%2C%20Joao%20Event%20labeling%20combining%20ensemble%20detectors%20and%20background%20knowledge%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fanaee-T%2C%20Hadi%20Gama%2C%20Joao%20Event%20labeling%20combining%20ensemble%20detectors%20and%20background%20knowledge%202014"
        },
        {
            "id": "7",
            "entry": "[7] G David Garson. Interpreting neural-network connection weights. AI expert, 6(4):46\u201351, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Garson%2C%20G.David%20Interpreting%20neural-network%20connection%20weights%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Garson%2C%20G.David%20Interpreting%20neural-network%20connection%20weights%201991"
        },
        {
            "id": "8",
            "entry": "[8] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier neural networks. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pages 315\u2013323, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20Xavier%20Bordes%2C%20Antoine%20Bengio%2C%20Yoshua%20Deep%20sparse%20rectifier%20neural%20networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20Xavier%20Bordes%2C%20Antoine%20Bengio%2C%20Yoshua%20Deep%20sparse%20rectifier%20neural%20networks%202011"
        },
        {
            "id": "9",
            "entry": "[9] Bryce Goodman and Seth Flaxman. European union regulations on algorithmic decision-making and a\" right to explanation\". arXiv preprint arXiv:1606.08813, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.08813"
        },
        {
            "id": "10",
            "entry": "[10] Trevor J Hastie. Generalized additive models. In Statistical models in S, pages 249\u2013307. Routledge, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hastie%2C%20Trevor%20J.%20Generalized%20additive%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hastie%2C%20Trevor%20J.%20Generalized%20additive%20models%202017"
        },
        {
            "id": "11",
            "entry": "[11] Yotam Hechtlinger. Interpretation of prediction models using the input gradient. arXiv preprint arXiv:1611.07634, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.07634"
        },
        {
            "id": "12",
            "entry": "[12] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017"
        },
        {
            "id": "13",
            "entry": "[13] Kurt Hornik. Approximation capabilities of multilayer feedforward networks. Neural networks, 4(2):251\u2013257, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hornik%2C%20Kurt%20Approximation%20capabilities%20of%20multilayer%20feedforward%20networks%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hornik%2C%20Kurt%20Approximation%20capabilities%20of%20multilayer%20feedforward%20networks%201991"
        },
        {
            "id": "14",
            "entry": "[14] Wei-Ning Hsu, Yu Zhang, and James Glass. Unsupervised learning of disentangled and interpretable representations from sequential data. In Advances in neural information processing systems, pages 1876\u20131887, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hsu%2C%20Wei-Ning%20Zhang%2C%20Yu%20Glass%2C%20James%20Unsupervised%20learning%20of%20disentangled%20and%20interpretable%20representations%20from%20sequential%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hsu%2C%20Wei-Ning%20Zhang%2C%20Yu%20Glass%2C%20James%20Unsupervised%20learning%20of%20disentangled%20and%20interpretable%20representations%20from%20sequential%20data%202017"
        },
        {
            "id": "15",
            "entry": "[15] Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3:160035, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Alistair%20E.W.%20Pollard%2C%20Tom%20J.%20Lu%20Shen%2C%20H.Lehman%20Li-wei%20Feng%2C%20Mengling%20a%20freely%20accessible%20critical%20care%20database%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Alistair%20E.W.%20Pollard%2C%20Tom%20J.%20Lu%20Shen%2C%20H.Lehman%20Li-wei%20Feng%2C%20Mengling%20a%20freely%20accessible%20critical%20care%20database%202016"
        },
        {
            "id": "16",
            "entry": "[16] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "17",
            "entry": "[17] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "18",
            "entry": "[18] Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Josh Tenenbaum. Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems, pages 2539\u20132547, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015"
        },
        {
            "id": "19",
            "entry": "[19] Yin Lou, Rich Caruana, and Johannes Gehrke. Intelligible models for classification and regression. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 150\u2013158. ACM, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lou%2C%20Yin%20Caruana%2C%20Rich%20Gehrke%2C%20Johannes%20Intelligible%20models%20for%20classification%20and%20regression%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lou%2C%20Yin%20Caruana%2C%20Rich%20Gehrke%2C%20Johannes%20Intelligible%20models%20for%20classification%20and%20regression%202012"
        },
        {
            "id": "20",
            "entry": "[20] Yin Lou, Rich Caruana, Johannes Gehrke, and Giles Hooker. Accurate intelligible models with pairwise interactions. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 623\u2013631. ACM, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lou%2C%20Yin%20Caruana%2C%20Rich%20Gehrke%2C%20Johannes%20Hooker%2C%20Giles%20Accurate%20intelligible%20models%20with%20pairwise%20interactions%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lou%2C%20Yin%20Caruana%2C%20Rich%20Gehrke%2C%20Johannes%20Hooker%2C%20Giles%20Accurate%20intelligible%20models%20with%20pairwise%20interactions%202013"
        },
        {
            "id": "21",
            "entry": "[21] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l0 regularization. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Louizos%2C%20Christos%20Welling%2C%20Max%20Kingma%2C%20Diederik%20P.%20Learning%20sparse%20neural%20networks%20through%20l0%20regularization%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Louizos%2C%20Christos%20Welling%2C%20Max%20Kingma%2C%20Diederik%20P.%20Learning%20sparse%20neural%20networks%20through%20l0%20regularization%202018"
        },
        {
            "id": "22",
            "entry": "[22] Francisco Louzada, Anderson Ara, and Guilherme B Fernandes. Classification methods applied to credit scoring: Systematic review and overall comparison. Surveys in Operations Research and Management Science, 21(2):117\u2013134, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Louzada%2C%20Francisco%20Ara%2C%20Anderson%20Fernandes%2C%20Guilherme%20B.%20Classification%20methods%20applied%20to%20credit%20scoring%3A%20Systematic%20review%20and%20overall%20comparison%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Louzada%2C%20Francisco%20Ara%2C%20Anderson%20Fernandes%2C%20Guilherme%20B.%20Classification%20methods%20applied%20to%20credit%20scoring%3A%20Systematic%20review%20and%20overall%20comparison%202016"
        },
        {
            "id": "23",
            "entry": "[23] Julian D Olden and Donald A Jackson. Illuminating the \u201cblack box\u201d: a randomization approach for understanding variable contributions in artificial neural networks. Ecological modelling, 154(1-2):135\u2013150, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Olden%2C%20Julian%20D.%20Jackson%2C%20Donald%20A.%20Illuminating%20the%20%E2%80%9Cblack%20box%E2%80%9D%3A%20a%20randomization%20approach%20for%20understanding%20variable%20contributions%20in%20artificial%20neural%20networks%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Olden%2C%20Julian%20D.%20Jackson%2C%20Donald%20A.%20Illuminating%20the%20%E2%80%9Cblack%20box%E2%80%9D%3A%20a%20randomization%20approach%20for%20understanding%20variable%20contributions%20in%20artificial%20neural%20networks%202002"
        },
        {
            "id": "24",
            "entry": "[24] R Kelley Pace and Ronald Barry. Sparse spatial autoregressions. Statistics & Probability Letters, 33(3):291\u2013297, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pace%2C%20R.Kelley%20Barry%2C%20Ronald%20Sparse%20spatial%20autoregressions%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pace%2C%20R.Kelley%20Barry%2C%20Ronald%20Sparse%20spatial%20autoregressions%201997"
        },
        {
            "id": "25",
            "entry": "[25] William JE Potts. Generalized additive neural networks. In Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 194\u2013200. ACM, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Potts%2C%20William%20J.E.%20Generalized%20additive%20neural%20networks%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Potts%2C%20William%20J.E.%20Generalized%20additive%20neural%20networks%201999"
        },
        {
            "id": "26",
            "entry": "[26] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "27",
            "entry": "[27] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1135\u20131144. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ribeiro%2C%20Marco%20Tulio%20Singh%2C%20Sameer%20Guestrin%2C%20Carlos%20Why%20should%20i%20trust%20you%3F%3A%20Explaining%20the%20predictions%20of%20any%20classifier%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ribeiro%2C%20Marco%20Tulio%20Singh%2C%20Sameer%20Guestrin%2C%20Carlos%20Why%20should%20i%20trust%20you%3F%3A%20Explaining%20the%20predictions%20of%20any%20classifier%202016"
        },
        {
            "id": "28",
            "entry": "[28] Daria Sorokina, Rich Caruana, Mirek Riedewald, and Daniel Fink. Detecting statistical interactions with additive groves of trees. In Proceedings of the 25th international conference on Machine learning, pages 1000\u20131007. ACM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sorokina%2C%20Daria%20Caruana%2C%20Rich%20Riedewald%2C%20Mirek%20Fink%2C%20Daniel%20Detecting%20statistical%20interactions%20with%20additive%20groves%20of%20trees%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sorokina%2C%20Daria%20Caruana%2C%20Rich%20Riedewald%2C%20Mirek%20Fink%2C%20Daniel%20Detecting%20statistical%20interactions%20with%20additive%20groves%20of%20trees%202008"
        },
        {
            "id": "29",
            "entry": "[29] Sarah Tan, Rich Caruana, Giles Hooker, and Albert Gordo. Transparent model distillation. arXiv preprint arXiv:1801.08640, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.08640"
        },
        {
            "id": "30",
            "entry": "[30] Sarah Tan, Rich Caruana, Giles Hooker, and Yin Lou. Detecting bias in black-box models using transparent model distillation. AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tan%2C%20Sarah%20Caruana%2C%20Rich%20Hooker%2C%20Giles%20Lou%2C%20Yin%20Detecting%20bias%20in%20black-box%20models%20using%20transparent%20model%20distillation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tan%2C%20Sarah%20Caruana%2C%20Rich%20Hooker%2C%20Giles%20Lou%2C%20Yin%20Detecting%20bias%20in%20black-box%20models%20using%20transparent%20model%20distillation%202017"
        },
        {
            "id": "31",
            "entry": "[31] Michael Tsang, Dehua Cheng, and Yan Liu. Detecting statistical interactions from neural network weights. International Conference on Learning Representations, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsang%2C%20Michael%20Cheng%2C%20Dehua%20Liu%2C%20Yan%20Detecting%20statistical%20interactions%20from%20neural%20network%20weights%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsang%2C%20Michael%20Cheng%2C%20Dehua%20Liu%2C%20Yan%20Detecting%20statistical%20interactions%20from%20neural%20network%20weights%202018"
        }
    ]
}
