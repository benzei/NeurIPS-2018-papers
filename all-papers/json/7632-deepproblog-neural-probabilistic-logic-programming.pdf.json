{
    "filename": "7632-deepproblog-neural-probabilistic-logic-programming.pdf",
    "metadata": {
        "title": "DeepProbLog:  Neural Probabilistic Logic Programming",
        "author": "Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7632-deepproblog-neural-probabilistic-logic-programming.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples."
    },
    "keywords": [
        {
            "term": "probabilistic reasoning",
            "url": "https://en.wikipedia.org/wiki/probabilistic_reasoning"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        }
    ],
    "highlights": [
        "The integration of low-level perception with high-level reasoning is one of the oldest, and yet most current open challenges in the field of artificial intelligence",
        "Low-level perception is typically handled by neural networks and deep learning, whereas high-level reasoning is typically addressed using logical and probabilistic representations and inference",
        "The input data consists of feature vectors at the input of the neural network components together with other probabilistic facts and clauses in the logic program, whereas targets are only given at the output side of the probabilistic reasoner",
        "We introduce DeepProbLog which has a unique set of features: (i) it is a programming language that supports neural networks and machine learning, and it has a well-defined semantics; it integrates logical reasoning with neural networks; so both symbolic and subsymbolic representations and inference; it integrates probabilistic modeling, programming and reasoning with neural networks; it can be used to learn a wide range of probabilistic logical neural models from examples, including inductive programming",
        "We introduce our approach to jointly train the parameters of probabilistic facts and neural networks in DeepProbLog programs",
        "In contrast to the earlier approach for ProbLog parameter learning in this setting by Gutmann et al [2008], we use gradient descent rather than EM, as this allows for seamless integration with neural network training"
    ],
    "key_statements": [
        "The integration of low-level perception with high-level reasoning is one of the oldest, and yet most current open challenges in the field of artificial intelligence",
        "Low-level perception is typically handled by neural networks and deep learning, whereas high-level reasoning is typically addressed using logical and probabilistic representations and inference",
        "The input data consists of feature vectors at the input of the neural network components together with other probabilistic facts and clauses in the logic program, whereas targets are only given at the output side of the probabilistic reasoner",
        "We introduce DeepProbLog which has a unique set of features: (i) it is a programming language that supports neural networks and machine learning, and it has a well-defined semantics; it integrates logical reasoning with neural networks; so both symbolic and subsymbolic representations and inference; it integrates probabilistic modeling, programming and reasoning with neural networks; it can be used to learn a wide range of probabilistic logical neural models from examples, including inductive programming",
        "We introduce our approach to jointly train the parameters of probabilistic facts and neural networks in DeepProbLog programs",
        "In contrast to the earlier approach for ProbLog parameter learning in this setting by Gutmann et al [2008], we use gradient descent rather than EM, as this allows for seamless integration with neural network training",
        "Given a DeepProbLog program, its neural network models, and a query used as training example, we first ground the program with respect to the query, getting the current parameters of nADs from the external models, use the ProbLog machinery to compute the loss and its gradient, and use these to update the parameters in the neural networks and the probabilistic program",
        "We follow the program sketch setting of differentiable Forth [<a class=\"ref-link\" id=\"cBosnjak_et+al_2017_a\" href=\"#rBosnjak_et+al_2017_a\">Bosnjak et al, 2017</a>], where holes in given programs need to be filled by neural networks trained on input-output examples for the entire program"
    ],
    "summary": [
        "The integration of low-level perception with high-level reasoning is one of the oldest, and yet most current open challenges in the field of artificial intelligence.",
        "The input data consists of feature vectors at the input of the neural network components together with other probabilistic facts and clauses in the logic program, whereas targets are only given at the output side of the probabilistic reasoner.",
        "The SDD for our example is shown in Figure 1b, where rounded grey rectangles depict variables corresponding to probabilistic facts, and the rounded red rectangle denotes the query atom defined by the formula.",
        "We introduce our approach to jointly train the parameters of probabilistic facts and neural networks in DeepProbLog programs.",
        "We use the learning from entailment setting [De Raedt et al, 2016] , that is, given a DeepProbLog program with parameters X , a set Q of pairs (q, p) with q a query and p its desired success probability, and a loss function L, compute: arg min x",
        "In contrast to the earlier approach for ProbLog parameter learning in this setting by Gutmann et al [2008], we use gradient descent rather than EM, as this allows for seamless integration with neural network training.",
        "Given a DeepProbLog program, its neural network models, and a query used as training example, we first ground the program with respect to the query, getting the current parameters of nADs from the external models, use the ProbLog machinery to compute the loss and its gradient, and use these to update the parameters in the neural networks and the probabilistic program.",
        "We provide the necessary background on aProbLog, discuss how to use it to compute gradients with respect to ProbLog parameters and extend the approach to DeepProbLog. aProbLog and the gradient semiring ProbLog annotates each probabilistic fact f with the probability that f is true, which implicitly defines the probability that f is false, and its negation \u00acf is true.",
        "We follow the program sketch setting of differentiable Forth [<a class=\"ref-link\" id=\"cBosnjak_et+al_2017_a\" href=\"#rBosnjak_et+al_2017_a\">Bosnjak et al, 2017</a>], where holes in given programs need to be filled by neural networks trained on input-output examples for the entire program.",
        "We use a warm-up of the learning rate of the logic parameters for the coin-ball experiments, starting at 0.0001 and raising it linearly to 0.01 over four epochs.",
        "DeepProbLog takes a different approach and integrates neural networks into a probabilistic logic framework, retaining the full power of both logical and probabilistic reasoning and deep learning."
    ],
    "headline": "We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates",
    "reference_links": [
        {
            "id": "Andreas_et+al_2016_a",
            "entry": "Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural module networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 39\u201348, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andreas%2C%20Jacob%20Rohrbach%2C%20Marcus%20Darrell%2C%20Trevor%20Klein%2C%20Dan%20Neural%20module%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andreas%2C%20Jacob%20Rohrbach%2C%20Marcus%20Darrell%2C%20Trevor%20Klein%2C%20Dan%20Neural%20module%20networks%202016"
        },
        {
            "id": "Bosnjak_et+al_2017_a",
            "entry": "Matko Bosnjak, Tim Rocktaschel, and Sebastian Riedel. Programming with a differentiable forth interpreter. In Proceedings of the 34th International Conference on Machine Learning, volume 70, pages 547\u2013556, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bosnjak%2C%20Matko%20Rocktaschel%2C%20Tim%20Riedel%2C%20Sebastian%20Programming%20with%20a%20differentiable%20forth%20interpreter%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bosnjak%2C%20Matko%20Rocktaschel%2C%20Tim%20Riedel%2C%20Sebastian%20Programming%20with%20a%20differentiable%20forth%20interpreter%202017"
        },
        {
            "id": "Cohen_et+al_2018_a",
            "entry": "William W Cohen, Fan Yang, and Kathryn Rivard Mazaitis. Tensorlog: Deep learning meets probabilistic databases. Journal of Artificial Intelligence Research, 1:1\u201315, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20William%20W.%20Yang%2C%20Fan%20Mazaitis%2C%20Kathryn%20Rivard%20Tensorlog%3A%20Deep%20learning%20meets%20probabilistic%20databases%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20William%20W.%20Yang%2C%20Fan%20Mazaitis%2C%20Kathryn%20Rivard%20Tensorlog%3A%20Deep%20learning%20meets%20probabilistic%20databases%202018"
        },
        {
            "id": "Dai_et+al_2018_a",
            "entry": "Wang-Zhou Dai, Qiu-Ling Xu, Yang Yu, and Zhi-Hua Zhou. Tunneling neural perception and logic reasoning through abductive learning. arXiv preprint arXiv:1802.01173, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.01173"
        },
        {
            "id": "Adnan_2011_a",
            "entry": "Adnan Darwiche. SDD: A new canonical representation of propositional knowledge bases. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, IJCAI11, pages 819\u2013826, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Adnan%20Darwiche.%20SDD%3A%20A%20new%20canonical%20representation%20of%20propositional%20knowledge%20bases%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Adnan%20Darwiche.%20SDD%3A%20A%20new%20canonical%20representation%20of%20propositional%20knowledge%20bases%202011"
        },
        {
            "id": "Darwiche_2002_a",
            "entry": "Adnan Darwiche and Pierre Marquis. A knowledge compilation map. Journal of Artificial Intelligence Research, 17:229\u2013264, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Darwiche%2C%20Adnan%20Marquis%2C%20Pierre%20A%20knowledge%20compilation%20map%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Darwiche%2C%20Adnan%20Marquis%2C%20Pierre%20A%20knowledge%20compilation%20map%202002"
        },
        {
            "id": "Raedt_2014_a",
            "entry": "Luc De Raedt and Angelika Kimmig. Probabilistic programming. ECAI tutorial, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raedt%2C%20Luc%20De%20Kimmig%2C%20Angelika%20Probabilistic%20programming%202014"
        },
        {
            "id": "Raedt_2015_a",
            "entry": "Luc De Raedt and Angelika Kimmig. Probabilistic (logic) programming concepts. Machine Learning, 100(1):5\u201347, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raedt%2C%20Luc%20De%20Kimmig%2C%20Angelika%20Probabilistic%20%28logic%29%20programming%20concepts%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raedt%2C%20Luc%20De%20Kimmig%2C%20Angelika%20Probabilistic%20%28logic%29%20programming%20concepts%202015"
        },
        {
            "id": "Raedt_et+al_2007_a",
            "entry": "Luc De Raedt, Angelika Kimmig, and Hannu Toivonen. ProbLog: A probabilistic Prolog and its application in link discovery. In IJCAI, pages 2462\u20132467, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raedt%2C%20Luc%20De%20Kimmig%2C%20Angelika%20Toivonen%2C%20Hannu%20ProbLog%3A%20A%20probabilistic%20Prolog%20and%20its%20application%20in%20link%20discovery%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raedt%2C%20Luc%20De%20Kimmig%2C%20Angelika%20Toivonen%2C%20Hannu%20ProbLog%3A%20A%20probabilistic%20Prolog%20and%20its%20application%20in%20link%20discovery%202007"
        },
        {
            "id": "Raedt_et+al_2016_a",
            "entry": "Luc De Raedt, Kristian Kersting, Sriraam Natarajan, and David Poole. Statistical relational artificial intelligence: Logic, probability, and computation. Synthesis Lectures on Artificial Intelligence and Machine Learning, 10(2):1\u2013189, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raedt%2C%20Luc%20De%20Kersting%2C%20Kristian%20Natarajan%2C%20Sriraam%20Poole%2C%20David%20Statistical%20relational%20artificial%20intelligence%3A%20Logic%2C%20probability%2C%20and%20computation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raedt%2C%20Luc%20De%20Kersting%2C%20Kristian%20Natarajan%2C%20Sriraam%20Poole%2C%20David%20Statistical%20relational%20artificial%20intelligence%3A%20Logic%2C%20probability%2C%20and%20computation%202016"
        },
        {
            "id": "Diligenti_et+al_2017_a",
            "entry": "Michelangelo Diligenti, Marco Gori, and Claudio Sacca. Semantic-based regularization for learning and inference. Artificial Intelligence, 244:143\u2013165, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diligenti%2C%20Michelangelo%20Gori%2C%20Marco%20Sacca%2C%20Claudio%20Semantic-based%20regularization%20for%20learning%20and%20inference%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diligenti%2C%20Michelangelo%20Gori%2C%20Marco%20Sacca%2C%20Claudio%20Semantic-based%20regularization%20for%20learning%20and%20inference%202017"
        },
        {
            "id": "Donadello_et+al_2017_a",
            "entry": "Ivan Donadello, Luciano Serafini, and Artur S. d\u2019Avila Garcez. Logic tensor networks for semantic image interpretation. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne, Australia, August 19-25, 2017, pages 1596\u20131602, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donadello%2C%20Ivan%20Serafini%2C%20Luciano%20d%E2%80%99Avila%20Garcez%2C%20Artur%20S.%20Logic%20tensor%20networks%20for%20semantic%20image%20interpretation%202017-08-19",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donadello%2C%20Ivan%20Serafini%2C%20Luciano%20d%E2%80%99Avila%20Garcez%2C%20Artur%20S.%20Logic%20tensor%20networks%20for%20semantic%20image%20interpretation%202017-08-19"
        },
        {
            "id": "Sebastijan_2017_a",
            "entry": "Sebastijan Dumancicand Hendrik Blockeel. Clustering-based relational unsupervised representation learning with an explicit distributed representation. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, pages 1631\u20131637, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Sebastijan%20Dumancicand%20Hendrik%20Blockeel.%20Clustering-based%20relational%20unsupervised%20representation%20learning%20with%20an%20explicit%20distributed%20representation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Sebastijan%20Dumancicand%20Hendrik%20Blockeel.%20Clustering-based%20relational%20unsupervised%20representation%20learning%20with%20an%20explicit%20distributed%20representation%202017"
        },
        {
            "id": "Eisner_2002_a",
            "entry": "Jason Eisner. Parameter estimation for probabilistic finite-state transducers. In Proceedings of the 40th annual meeting on Association for Computational Linguistics, pages 1\u20138. Association for Computational Linguistics, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eisner%2C%20Jason%20Parameter%20estimation%20for%20probabilistic%20finite-state%20transducers%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eisner%2C%20Jason%20Parameter%20estimation%20for%20probabilistic%20finite-state%20transducers%202002"
        },
        {
            "id": "Evans_2018_a",
            "entry": "Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. Journal of Artificial Intelligence Research, 61:1\u201364, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Evans%2C%20Richard%20Grefenstette%2C%20Edward%20Learning%20explanatory%20rules%20from%20noisy%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Evans%2C%20Richard%20Grefenstette%2C%20Edward%20Learning%20explanatory%20rules%20from%20noisy%20data%202018"
        },
        {
            "id": "Fierens_et+al_2015_a",
            "entry": "Daan Fierens, Guy Van den Broeck, Joris Renkens, Dimitar Shterionov, Bernd Gutmann, Ingo Thon, Gerda Janssens, and Luc De Raedt. Inference and learning in probabilistic logic programs using weighted Boolean formulas. Theory and Practice of Logic Programming, 15(3):358\u2013401, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fierens%2C%20Daan%20den%20Broeck%2C%20Guy%20Van%20Renkens%2C%20Joris%20Shterionov%2C%20Dimitar%20Inference%20and%20learning%20in%20probabilistic%20logic%20programs%20using%20weighted%20Boolean%20formulas%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fierens%2C%20Daan%20den%20Broeck%2C%20Guy%20Van%20Renkens%2C%20Joris%20Shterionov%2C%20Dimitar%20Inference%20and%20learning%20in%20probabilistic%20logic%20programs%20using%20weighted%20Boolean%20formulas%202015"
        },
        {
            "id": "D_et+al_2012_a",
            "entry": "Artur S d\u2019Avila Garcez, Krysia B Broda, and Dov M Gabbay. Neural-symbolic learning systems: foundations and applications. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=d%E2%80%99Avila%20Garcez%2C%20Artur%20S.%20Broda%2C%20Krysia%20B.%20Gabbay%2C%20Dov%20M.%20Neural-symbolic%20learning%20systems%3A%20foundations%20and%20applications%202012"
        },
        {
            "id": "Getoor_2007_a",
            "entry": "Lise Getoor and Ben Taskar. Introduction to statistical relational learning. MIT press, 2007. Bernd Gutmann, Angelika Kimmig, Kristian Kersting, and Luc De Raedt. Parameter learning in probabilistic databases: A least squares approach. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 473\u2013488.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Getoor%2C%20Lise%20Taskar%2C%20Ben%20Introduction%20to%20statistical%20relational%20learning%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Getoor%2C%20Lise%20Taskar%2C%20Ben%20Introduction%20to%20statistical%20relational%20learning%202007"
        }
    ]
}
