{
    "filename": "7880-learning-latent-subspaces-in-variational-autoencoders.pdf",
    "metadata": {
        "date": 2018,
        "title": "Learning Latent Subspaces in Variational Autoencoders",
        "author": "Jack Klys, Jake Snell, Richard Zemel University of Toronto Vector Institute",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7880-learning-latent-subspaces-in-variational-autoencoders.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Variational autoencoders (VAEs) [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] are widely used deep generative models capable of learning unsupervised latent representations of data. Such representations are often difficult to interpret or control. We consider the problem of unsupervised learning of features correlated to specific labels in a dataset. We propose a VAE-based generative model which we show is capable of extracting features correlated to binary labels in the data and structuring it in a latent subspace which is easy to interpret. Our model, the Conditional Subspace VAE (CSVAE), uses mutual information minimization to learn a low-dimensional latent subspace associated with each label that can easily be inspected and independently manipulated. We demonstrate the utility of the learned representations for attribute manipulation tasks on both the Toronto Face [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] and CelebA [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] datasets."
    },
    "keywords": [
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        }
    ],
    "highlights": [
        "Variational Autoencoder (VAE)<br/><br/>The variational autoencoder (VAE) [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] is a widely-used generative model on top of which our model is built",
        "We propose the Conditional Subspace Variational Autoencoders (CSVAE), which learns a latent space Z \u21e5 W that separates information related to the label y into a predefined subspace W",
        "We demonstrate these capabilities on the Toronto Faces Dataset (TFD) [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] and the CelebA face dataset [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] by comparing it to baseline models including a conditional Variational Autoencoders [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] and a Variational Autoencoders with adversarial information minimization but no latent space factorization [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]",
        "Figure 6 shows the Conditional Subspace variational autoencoder model is capable of preserving the style of the given attribute over many identities, demonstrating that information about the given attribute is disentangled from the Z subspace.\n5.4",
        "We have proposed the Conditional Subspace variational autoencoder model as a deep generative model to capture intra-class variation using a latent subspace associated with each class",
        "We demonstrated through qualitative experiments on Toronto Faces Dataset and CelebA that our model successfully captures a range of variations associated with each class"
    ],
    "key_statements": [
        "Variational Autoencoder (VAE)<br/><br/>The variational autoencoder (VAE) [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] is a widely-used generative model on top of which our model is built",
        "We propose the Conditional Subspace Variational Autoencoders (CSVAE), which learns a latent space Z \u21e5 W that separates information related to the label y into a predefined subspace W",
        "We demonstrate these capabilities on the Toronto Faces Dataset (TFD) [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] and the CelebA face dataset [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] by comparing it to baseline models including a conditional Variational Autoencoders [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] and a Variational Autoencoders with adversarial information minimization but no latent space factorization [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]",
        "Figure 6 shows the Conditional Subspace variational autoencoder model is capable of preserving the style of the given attribute over many identities, demonstrating that information about the given attribute is disentangled from the Z subspace.\n5.4",
        "We have proposed the Conditional Subspace variational autoencoder model as a deep generative model to capture intra-class variation using a latent subspace associated with each class",
        "We demonstrated through qualitative experiments on Toronto Faces Dataset and CelebA that our model successfully captures a range of variations associated with each class"
    ],
    "summary": [
        "Variational Autoencoder (VAE)<br/><br/>The variational autoencoder (VAE) [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] is a widely-used generative model on top of which our model is built.",
        "We propose the Conditional Subspace VAE (CSVAE), which learns a latent space Z \u21e5 W that separates information related to the label y into a predefined subspace W.",
        "The second utilizes trained machine learning models to manipulate and generate data in a controllable way, often in the form of images.",
        "This is the case with other methods of structuring latent space which have been explored, such as batching data according to labels [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>] or use of a discriminator network in a non-generative model [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>].",
        "Once trained our model can modify an attribute of a single given image to any style encoded in the subspace.",
        "The approximate posterior q (z|x) functions as an encoder which maps the data x to a lower dimensional latent representation.",
        "Our goal is to learn a latent representation of our data which encodes all the information related to feature i labelled by yi exactly in the subspace Wi. We will do this by maximizing a form of variational lower bound on the marginal log likelihood of our model, along with minimizing the mutual information between Z and Y .",
        "The projection onto (z2, w1) shows the whole swiss roll in familiar form embedded in latent space, while the projections onto Z and W show how our model encodes the data to satisfy its constraints.",
        "Figure 3 shows the result of manipulating the glasses and facial hair attribute for a fixed subject using each model, following the procedure described in Section 4.3.",
        "We train a CSVAE on the joint CelebA-GlassesFacialHair dataset to show that it can independently manipulate attributes as above in the case where binary attribute labels are not mutually exclusive.",
        "Figure 6 shows the CSVAE model is capable of preserving the style of the given attribute over many identities, demonstrating that information about the given attribute is disentangled from the Z subspace.",
        ", K} which predicts the label y from x for (x, y) 2 D and evaluate its accuracy on data points with attributes changed using the model as described in Section 4.3.",
        "A shortcoming of this evaluation method is that it does not penalize images Gij (x, y, pj) which have large negative loglikelihood under the model, or are qualitatively poor, as long as the classifier can detect the desired attribute.",
        "We plan to extend this model to the semi-supervised setting, in which some of the attribute labels are missing"
    ],
    "headline": "We propose a Variational Autoencoders-based generative model which we show is capable of extracting features correlated to binary labels in the data and structuring it in a latent subspace which is easy to interpret",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06349"
        },
        {
            "id": "2",
            "entry": "[2] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "3",
            "entry": "[3] Antonia Creswell, Anil A Bharath, and Biswa Sengupta. Conditional autoencoders with adversarial information factorization. arXiv preprint arXiv:1711.05175, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.05175"
        },
        {
            "id": "4",
            "entry": "[4] Harrison Edwards and Amos Storkey. Censoring representations with an adversary. arxiv preprint arXiv:1511.05897, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05897"
        },
        {
            "id": "5",
            "entry": "[5] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research 2016, vol. 17, p. 1-35, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016"
        },
        {
            "id": "6",
            "entry": "[6] Rafael G\u00f3mez-Bombarelli, Jennifer N Wei, David Duvenaud, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Benjam\u00edn S\u00e1nchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Al\u00e1n Aspuru-Guzik. Automatic chemical design using a data-driven continuous representation of molecules. ACS Central Science, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=G%C3%B3mez-Bombarelli%2C%20Rafael%20Wei%2C%20Jennifer%20N.%20Duvenaud%2C%20David%20Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Automatic%20chemical%20design%20using%20a%20data-driven%20continuous%20representation%20of%20molecules%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=G%C3%B3mez-Bombarelli%2C%20Rafael%20Wei%2C%20Jennifer%20N.%20Duvenaud%2C%20David%20Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Automatic%20chemical%20design%20using%20a%20data-driven%20continuous%20representation%20of%20molecules%202016"
        },
        {
            "id": "7",
            "entry": "[7] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "8",
            "entry": "[8] Ishaan Gulrajani, Kundan Kumar, Faruk Ahmed, Adrien Ali Taiga, Francesco Visin, David Vazquez, and Aaron Courville. Pixelvae: A latent variable model for natural images. arXiv preprint arXiv:1611.05013, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.05013"
        },
        {
            "id": "9",
            "entry": "[9] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017"
        },
        {
            "id": "10",
            "entry": "[10] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "11",
            "entry": "[11] Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised learning with deep generative models. In Advances in Neural Information Processing Systems, pages 3581\u20133589, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Mohamed%2C%20Shakir%20Rezende%2C%20Danilo%20Jimenez%20Welling%2C%20Max%20Semi-supervised%20learning%20with%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Mohamed%2C%20Shakir%20Rezende%2C%20Danilo%20Jimenez%20Welling%2C%20Max%20Semi-supervised%20learning%20with%20deep%20generative%20models%202014"
        },
        {
            "id": "12",
            "entry": "[12] Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Josh Tenenbaum. Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems, pages 2539\u20132547, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015"
        },
        {
            "id": "13",
            "entry": "[13] Guillaume Lample, Neil Zeghidour, Nicolas Usunier, Antoine Bordes, Ludovic Denoyer, et al. Fader networks: Manipulating images by sliding attributes. In Advances in Neural Information Processing Systems, pages 5969\u20135978, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20Guillaume%20Zeghidour%2C%20Neil%20Usunier%2C%20Nicolas%20Bordes%2C%20Antoine%20Fader%20networks%3A%20Manipulating%20images%20by%20sliding%20attributes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lample%2C%20Guillaume%20Zeghidour%2C%20Neil%20Usunier%2C%20Nicolas%20Bordes%2C%20Antoine%20Fader%20networks%3A%20Manipulating%20images%20by%20sliding%20attributes%202017"
        },
        {
            "id": "14",
            "entry": "[14] Anders Boesen Lindbo Larsen, S\u00f8ren Kaae S\u00f8nderby, Hugo Larochelle, and Ole Winther. Autoencoding beyond pixels using a learned similarity metric. arXiv preprint arXiv:1512.09300, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.09300"
        },
        {
            "id": "15",
            "entry": "[15] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "16",
            "entry": "[16] Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard Zemel. The variational fair autoencoder. arxiv preprint arXiv:1511.00830, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.00830"
        },
        {
            "id": "17",
            "entry": "[17] Michael Mathieu, Junbo Zhao, Pablo Sprechmann, Aditya Ramesh, and Yann LeCun. Disentangling factors of variation in deep representations using adversarial training, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mathieu%2C%20Michael%20Zhao%2C%20Junbo%20Sprechmann%2C%20Pablo%20Ramesh%2C%20Aditya%20Disentangling%20factors%20of%20variation%20in%20deep%20representations%20using%20adversarial%20training%202016"
        },
        {
            "id": "18",
            "entry": "[18] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In NIPS-W, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Adam%20Paszke%20Sam%20Gross%20Soumith%20Chintala%20Gregory%20Chanan%20Edward%20Yang%20Zachary%20DeVito%20Zeming%20Lin%20Alban%20Desmaison%20Luca%20Antiga%20and%20Adam%20Lerer%20Automatic%20differentiation%20in%20pytorch%20In%20NIPSW%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Adam%20Paszke%20Sam%20Gross%20Soumith%20Chintala%20Gregory%20Chanan%20Edward%20Yang%20Zachary%20DeVito%20Zeming%20Lin%20Alban%20Desmaison%20Luca%20Antiga%20and%20Adam%20Lerer%20Automatic%20differentiation%20in%20pytorch%20In%20NIPSW%202017"
        },
        {
            "id": "19",
            "entry": "[19] Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. Journal of machine learning research, 12(Oct):2825\u20132830, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pedregosa%2C%20Fabian%20Varoquaux%2C%20Ga%C3%ABl%20Gramfort%2C%20Alexandre%20Michel%2C%20Vincent%20Scikit-learn%3A%20Machine%20learning%20in%20python%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pedregosa%2C%20Fabian%20Varoquaux%2C%20Ga%C3%ABl%20Gramfort%2C%20Alexandre%20Michel%2C%20Vincent%20Scikit-learn%3A%20Machine%20learning%20in%20python%202011"
        },
        {
            "id": "20",
            "entry": "[20] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1401.4082"
        },
        {
            "id": "21",
            "entry": "[21] Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning structured output representation using deep conditional generative models. In Advances in Neural Information Processing Systems, pages 3483\u20133491, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sohn%2C%20Kihyuk%20Lee%2C%20Honglak%20Yan%2C%20Xinchen%20Learning%20structured%20output%20representation%20using%20deep%20conditional%20generative%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sohn%2C%20Kihyuk%20Lee%2C%20Honglak%20Yan%2C%20Xinchen%20Learning%20structured%20output%20representation%20using%20deep%20conditional%20generative%20models%202015"
        },
        {
            "id": "22",
            "entry": "[22] Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative adversarial networks. arXiv preprint arXiv:1511.06390, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06390"
        },
        {
            "id": "23",
            "entry": "[23] Josh M Susskind, Adam K Anderson, and Geoffrey E Hinton. The toronto face database. Department of Computer Science, University of Toronto, Toronto, ON, Canada, Tech. Rep, 3, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Susskind%2C%20Josh%20M.%20Anderson%2C%20Adam%20K.%20Hinton%2C%20Geoffrey%20E.%20The%20toronto%20face%20database%202010"
        },
        {
            "id": "24",
            "entry": "[24] Taihong Xiao, Jiapeng Hong, and Jinwen Ma. Dna-gan: Learning disentangled representations from multi-attribute images. International Conference on Learning Representations, Workshop, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xiao%2C%20Taihong%20Hong%2C%20Jiapeng%20Ma%2C%20Jinwen%20Dna-gan%3A%20Learning%20disentangled%20representations%20from%20multi-attribute%20images%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xiao%2C%20Taihong%20Hong%2C%20Jiapeng%20Ma%2C%20Jinwen%20Dna-gan%3A%20Learning%20disentangled%20representations%20from%20multi-attribute%20images%202018"
        },
        {
            "id": "25",
            "entry": "[25] Taihong Xiao, Jiapeng Hong, and Jinwen Ma. Elegant: Exchanging latent encodings with gan for transferring multiple face attributes. arXiv preprint arXiv:1803.10562, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.10562"
        },
        {
            "id": "26",
            "entry": "[26] Shuchang Zhou, Taihong Xiao, Yi Yang, Dieqiao Feng, Qinyao He, and Weiran He. Genegan: Learning object transfiguration and attribute subspace from unpaired data. In Proceedings of the British Machine Vision Conference (BMVC), 2017. URL http://arxiv.org/abs/1705.04932. ",
            "url": "http://arxiv.org/abs/1705.04932",
            "arxiv_url": "https://arxiv.org/pdf/1705.04932"
        }
    ]
}
