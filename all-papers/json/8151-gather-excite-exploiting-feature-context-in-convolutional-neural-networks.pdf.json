{
    "filename": "8151-gather-excite-exploiting-feature-context-in-convolutional-neural-networks.pdf",
    "metadata": {
        "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks",
        "author": "Jie Hu, Li Shen, Samuel Albanie, Gang Sun, Andrea Vedaldi",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8151-gather-excite-exploiting-feature-context-in-convolutional-neural-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "While the use of bottom-up local operators in convolutional neural networks (CNNs) matches well some of the statistics of natural images, it may also prevent such models from capturing contextual long-range feature interactions. In this work, we propose a simple, lightweight approach for better context exploitation in CNNs. We do so by introducing a pair of operators: gather, which efficiently aggregates feature responses from a large spatial extent, and excite, which redistributes the pooled information to local features. The operators are cheap, both in terms of number of added parameters and computational complexity, and can be integrated directly in existing architectures to improve their performance. Experiments on several datasets show that gather-excite can bring benefits comparable to increasing the depth of a CNN at a fraction of the cost. For example, we find ResNet-50 with gather-excite operators is able to outperform its 101-layer counterpart on ImageNet with no additional learnable parameters. We also propose a parametric gather-excite operator pair which yields further performance gains, relate it to the recently-introduced Squeeze-and-Excitation Networks, and analyse the effects of these changes to the CNN feature activation statistics."
    },
    "keywords": [
        {
            "term": "image classification",
            "url": "https://en.wikipedia.org/wiki/image_classification"
        },
        {
            "term": "deep convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/deep_convolutional_neural_network"
        },
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        },
        {
            "term": "image segmentation",
            "url": "https://en.wikipedia.org/wiki/image_segmentation"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "object detection",
            "url": "https://en.wikipedia.org/wiki/object_detection"
        }
    ],
    "highlights": [
        "Convolutional neural networks (CNN) [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] are the gold-standard approach to problems such as image classification [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], object detection [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>] and image segmentation [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]",
        "An idea that has often improved visual representations is to augment functions that perform local decisions with functions that operate on a larger context, providing a cue for resolving local ambiguities [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>]",
        "While the term \u201ccontext\u201d is overloaded [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], in this work we focus specifically on feature context, namely the information captured by the feature extractor responses as a whole, spread over the full spatial extent of the input image",
        "In this work we considered the question of how to efficiently exploit feature context in convolutional neural networks",
        "In future work we plan to investigate whether gather-excite operators may prove useful in other computer vision tasks such as semantic segmentation, which we anticipate may benefit from efficient use of feature context"
    ],
    "key_statements": [
        "Convolutional neural networks (CNN) [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] are the gold-standard approach to problems such as image classification [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], object detection [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>] and image segmentation [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]",
        "An idea that has often improved visual representations is to augment functions that perform local decisions with functions that operate on a larger context, providing a cue for resolving local ambiguities [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>]",
        "While the term \u201ccontext\u201d is overloaded [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], in this work we focus specifically on feature context, namely the information captured by the feature extractor responses as a whole, spread over the full spatial extent of the input image",
        "In this work we considered the question of how to efficiently exploit feature context in convolutional neural networks",
        "In future work we plan to investigate whether gather-excite operators may prove useful in other computer vision tasks such as semantic segmentation, which we anticipate may benefit from efficient use of feature context"
    ],
    "summary": [
        "Convolutional neural networks (CNN) [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] are the gold-standard approach to problems such as image classification [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>, <a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], object detection [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>] and image segmentation [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>].",
        "Demonstrating the effectiveness of such an approach, the recently proposed Squeeze-and-Excitation (SE) networks [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] showed that reweighting feature channels as a function of features from the full extent of input can improve classification performance.",
        "We investigate the effect of the operators on distributed representation learned by existing deep architectures: we find the mechanism produces intermediate representations that exhibit lower class selectivity, suggesting that providing access to additional context may enable greater feature re-use.",
        "The objective of the excite operator is to make use of the gathered output as a contextual feature and takes the form \u03beE(x, x) = x f (x), where f : RH \u00d7W \u00d7C \u2192 [0, 1]H\u00d7W \u00d7C is the map responsible for rescaling and distributing the signal from the aggregates.",
        "We have seen that simple gather-excite operators without learned parameters can offer an effective mechanism for exploiting context.",
        "Effect on learned representations: We have seen that GE operators can improve the performance of a deep network for visual tasks and would like to gain some insight into how the learned features may differ from those found in the baseline ResNet-50 model.",
        "The gating mechanism of the excite operator allows the network to perform feature selection throughout the learning process, using the feature importance scores that are assigned to the outputs of the gather operator.",
        "We first examine the effect of pruning the least important features: given a building block of the models, for each test image we sort the channel importances induced by the gating mechanism in ascending order, and set a portion of the values to zero in a first-to-last manner.",
        "As a reference for the relative importance of features contained in these residual branches, we report the performance of the baseline ResNet-50 model with the prune ratio set to 0 and 1 respectively.",
        "By reweighting features as a generic function of all pairwise interactions, non-local networks [<a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>] showed that self-attention can be generalised to a broad family of global operator blocks useful for visual tasks.",
        "In this work we considered the question of how to efficiently exploit feature context in CNNs. We proposed the gather-excite (GE) framework to address this issue and provided experimental evidence that demonstrates the effectiveness of this approach across multiple datasets and model architectures.",
        "In future work we plan to investigate whether gather-excite operators may prove useful in other computer vision tasks such as semantic segmentation, which we anticipate may benefit from efficient use of feature context."
    ],
    "headline": "We propose a simple, lightweight approach for better context exploitation in convolutional neural networks",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sean Bell, C Lawrence Zitnick, Kavita Bala, and Ross Girshick. Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. In CVPR, 2016. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sean%20Bell%2C%20C.Lawrence%20Zitnick%20Bala%2C%20Kavita%20Girshick%2C%20Ross%20Inside-outside%20net%3A%20Detecting%20objects%20in%20context%20with%20skip%20pooling%20and%20recurrent%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sean%20Bell%2C%20C.Lawrence%20Zitnick%20Bala%2C%20Kavita%20Girshick%2C%20Ross%20Inside-outside%20net%3A%20Detecting%20objects%20in%20context%20with%20skip%20pooling%20and%20recurrent%20neural%20networks%202016"
        },
        {
            "id": "2",
            "entry": "[2] Irving Biederman, Robert J Mezzanotte, and Jan C Rabinowitz. Scene perception: Detecting and judging objects undergoing relational violations. Cognitive psychology, 1982. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Biederman%2C%20Irving%20Mezzanotte%2C%20Robert%20J.%20Rabinowitz%2C%20Jan%20C.%20Scene%20perception%3A%20Detecting%20and%20judging%20objects%20undergoing%20relational%20violations%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Biederman%2C%20Irving%20Mezzanotte%2C%20Robert%20J.%20Rabinowitz%2C%20Jan%20C.%20Scene%20perception%3A%20Detecting%20and%20judging%20objects%20undergoing%20relational%20violations%201982"
        },
        {
            "id": "3",
            "entry": "[3] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE TPAMI, 2018. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Liang-Chieh%20Papandreou%2C%20George%20Kokkinos%2C%20Iasonas%20Murphy%2C%20Kevin%20DeepLab%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%2C%20atrous%20convolution%2C%20and%20fully%20connected%20crfs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Liang-Chieh%20Papandreou%2C%20George%20Kokkinos%2C%20Iasonas%20Murphy%2C%20Kevin%20DeepLab%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%2C%20atrous%20convolution%2C%20and%20fully%20connected%20crfs%202018"
        },
        {
            "id": "4",
            "entry": "[4] Long Chen, Hanwang Zhang, Jun Xiao Xiao, Liqiang Nie, Jian Shao, Wei Liu Liu, and Tat-Seng Chua. SCA-CNN: Spatial and channel-wise attention in convolutional networks for image captioning. In CVPR, 2017. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Long%20Zhang%2C%20Hanwang%20Xiao%2C%20Jun%20Xiao%20Nie%2C%20Liqiang%20SCA-CNN%3A%20Spatial%20and%20channel-wise%20attention%20in%20convolutional%20networks%20for%20image%20captioning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Long%20Zhang%2C%20Hanwang%20Xiao%2C%20Jun%20Xiao%20Nie%2C%20Liqiang%20SCA-CNN%3A%20Spatial%20and%20channel-wise%20attention%20in%20convolutional%20networks%20for%20image%20captioning%202017"
        },
        {
            "id": "5",
            "entry": "[5] Gabriella Csurka, Christopher Dance, Lixin Fan, Jutta Willamowski, and C\u00e9dric Bray. Visual categorization with bags of keypoints. In ECCV Workshop, 2004. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Visual%20categorization%20with%20bags%20of%20keypoints%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Visual%20categorization%20with%20bags%20of%20keypoints%202004"
        },
        {
            "id": "6",
            "entry": "[6] Santosh K Divvala, Derek Hoiem, James H Hays, Alexei A Efros, and Martial Hebert. An empirical study of context in object detection. In CVPR, 2009. 1, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Divvala%2C%20Santosh%20K.%20Hoiem%2C%20Derek%20Hays%2C%20James%20H.%20Alexei%20A%20Efros%2C%20and%20Martial%20Hebert.%20An%20empirical%20study%20of%20context%20in%20object%20detection%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Divvala%2C%20Santosh%20K.%20Hoiem%2C%20Derek%20Hays%2C%20James%20H.%20Alexei%20A%20Efros%2C%20and%20Martial%20Hebert.%20An%20empirical%20study%20of%20context%20in%20object%20detection%202009"
        },
        {
            "id": "7",
            "entry": "[7] A Hanson. Visions: A computer system for interpreting scenes. Computer vision systems, 1978. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hanson%2C%20A.%20Visions%3A%20A%20computer%20system%20for%20interpreting%20scenes%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hanson%2C%20A.%20Visions%3A%20A%20computer%20system%20for%20interpreting%20scenes%201978"
        },
        {
            "id": "8",
            "entry": "[8] Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Girshick. Mask R-CNN. In ICCV, 2017. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Doll%C3%A1r%20and%20Ross%20Girshick%20Mask%20RCNN%20In%20ICCV%202017%206",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Doll%C3%A1r%20and%20Ross%20Girshick%20Mask%20RCNN%20In%20ICCV%202017%206"
        },
        {
            "id": "9",
            "entry": "[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 3, 4, 6, 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "10",
            "entry": "[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In ECCV, 2016. 3, 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Identity%20mappings%20in%20deep%20residual%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Identity%20mappings%20in%20deep%20residual%20networks%202016"
        },
        {
            "id": "11",
            "entry": "[11] Geremy Heitz and Daphne Koller. Learning spatial context: Using stuff to find things. In ECCV, 2008. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heitz%2C%20Geremy%20Koller%2C%20Daphne%20Learning%20spatial%20context%3A%20Using%20stuff%20to%20find%20things%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heitz%2C%20Geremy%20Koller%2C%20Daphne%20Learning%20spatial%20context%3A%20Using%20stuff%20to%20find%20things%202008"
        },
        {
            "id": "12",
            "entry": "[12] Geoffrey E Hinton, James L McClelland, David E Rumelhart, et al. Distributed representations. Parallel distributed processing: Explorations in the microstructure of cognition, 1986. 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20representations.%20Parallel%20distributed%20processing%3A%20Explorations%20in%20the%20microstructure%20of%20cognition%201986"
        },
        {
            "id": "13",
            "entry": "[13] Howard S Hock, Gregory P Gordon, and Robert Whitehurst. Contextual relations: the influence of familiarity, physical plausibility, and belongingness. Perception & Psychophysics, 1974. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hock%2C%20Howard%20S.%20Gordon%2C%20Gregory%20P.%20Whitehurst%2C%20Robert%20Contextual%20relations%3A%20the%20influence%20of%20familiarity%2C%20physical%20plausibility%2C%20and%20belongingness%201974",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hock%2C%20Howard%20S.%20Gordon%2C%20Gregory%20P.%20Whitehurst%2C%20Robert%20Contextual%20relations%3A%20the%20influence%20of%20familiarity%2C%20physical%20plausibility%2C%20and%20belongingness%201974"
        },
        {
            "id": "14",
            "entry": "[14] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. 5",
            "arxiv_url": "https://arxiv.org/pdf/1704.04861"
        },
        {
            "id": "15",
            "entry": "[15] Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. In CVPR, 2018. 2, 4, 5, 7, 8, 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Jie%20Shen%2C%20Li%20Sun%2C%20Gang%20Squeeze-and-excitation%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Jie%20Shen%2C%20Li%20Sun%2C%20Gang%20Squeeze-and-excitation%20networks%202018"
        },
        {
            "id": "16",
            "entry": "[16] Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q. Weinberger. Deep networks with stochastic depth. In ECCV, 2016. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Gao%20Sun%2C%20Yu%20Liu%2C%20Zhuang%20Sedra%2C%20Daniel%20Deep%20networks%20with%20stochastic%20depth%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Gao%20Sun%2C%20Yu%20Liu%2C%20Zhuang%20Sedra%2C%20Daniel%20Deep%20networks%20with%20stochastic%20depth%202016"
        },
        {
            "id": "17",
            "entry": "[17] Tsung-Wei Ke, Michael Maire, and X Yu Stella. Multigrid neural architectures. In CVPR, 2017. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ke%2C%20Tsung-Wei%20Maire%2C%20Michael%20Stella%2C%20X.Yu%20Multigrid%20neural%20architectures%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ke%2C%20Tsung-Wei%20Maire%2C%20Michael%20Stella%2C%20X.Yu%20Multigrid%20neural%20architectures%202017"
        },
        {
            "id": "18",
            "entry": "[18] Idan Kligvasser, Tamar Rott Shaham, and Tomer Michaeli. xUnit: Learning a spatial activation function for efficient image restoration. In CVPR, 2018. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kligvasser%2C%20Idan%20Shaham%2C%20Tamar%20Rott%20Michaeli%2C%20Tomer%20xUnit%3A%20Learning%20a%20spatial%20activation%20function%20for%20efficient%20image%20restoration%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kligvasser%2C%20Idan%20Shaham%2C%20Tamar%20Rott%20Michaeli%2C%20Tomer%20xUnit%3A%20Learning%20a%20spatial%20activation%20function%20for%20efficient%20image%20restoration%202018"
        },
        {
            "id": "19",
            "entry": "[19] Alex Krizhevsky. Learning multiple layers of features from tiny images. Tech Report, 2009. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "20",
            "entry": "[20] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, 2012. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "21",
            "entry": "[21] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 1998. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "22",
            "entry": "[22] Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In ICML, 2009. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Honglak%20Grosse%2C%20Roger%20Ranganath%2C%20Rajesh%20Ng%2C%20Andrew%20Y.%20Convolutional%20deep%20belief%20networks%20for%20scalable%20unsupervised%20learning%20of%20hierarchical%20representations%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Honglak%20Grosse%2C%20Roger%20Ranganath%2C%20Rajesh%20Ng%2C%20Andrew%20Y.%20Convolutional%20deep%20belief%20networks%20for%20scalable%20unsupervised%20learning%20of%20hierarchical%20representations%202009"
        },
        {
            "id": "23",
            "entry": "[23] Guosheng Lin, Chunhua Shen, Anton Van Den Hengel, and Ian Reid. Efficient piecewise training of deep structured models for semantic segmentation. In CVPR, 2016. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Guosheng%20Shen%2C%20Chunhua%20Hengel%2C%20Anton%20Van%20Den%20Reid%2C%20Ian%20Efficient%20piecewise%20training%20of%20deep%20structured%20models%20for%20semantic%20segmentation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Guosheng%20Shen%2C%20Chunhua%20Hengel%2C%20Anton%20Van%20Den%20Reid%2C%20Ian%20Efficient%20piecewise%20training%20of%20deep%20structured%20models%20for%20semantic%20segmentation%202016"
        },
        {
            "id": "24",
            "entry": "[24] Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. In ICLR, 2014. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Min%20Lin%20Qiang%20Chen%20and%20Shuicheng%20Yan%20Network%20in%20network%20In%20ICLR%202014%206",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Min%20Lin%20Qiang%20Chen%20and%20Shuicheng%20Yan%20Network%20in%20network%20In%20ICLR%202014%206"
        },
        {
            "id": "25",
            "entry": "[25] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, 2014. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=TsungYi%20Lin%20Michael%20Maire%20Serge%20Belongie%20James%20Hays%20Pietro%20Perona%20Deva%20Ramanan%20Piotr%20Doll%C3%A1r%20and%20C%20Lawrence%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20ECCV%202014%206",
            "oa_query": "https://api.scholarcy.com/oa_version?query=TsungYi%20Lin%20Michael%20Maire%20Serge%20Belongie%20James%20Hays%20Pietro%20Perona%20Deva%20Ramanan%20Piotr%20Doll%C3%A1r%20and%20C%20Lawrence%20Zitnick%20Microsoft%20coco%20Common%20objects%20in%20context%20In%20ECCV%202014%206"
        },
        {
            "id": "26",
            "entry": "[26] Wei Liu, Andrew Rabinovich, and Alexander C Berg. Parsenet: Looking wider to see better. In ICLR workshop, 2016. 1, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Wei%20Rabinovich%2C%20Andrew%20Berg%2C%20Alexander%20C.%20Parsenet%3A%20Looking%20wider%20to%20see%20better%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Wei%20Rabinovich%2C%20Andrew%20Berg%2C%20Alexander%20C.%20Parsenet%3A%20Looking%20wider%20to%20see%20better%202016"
        },
        {
            "id": "27",
            "entry": "[27] Wenjie Luo, Yujia Li, Raquel Urtasun, and Richard Zemel. Understanding the effective receptive field in deep convolutional neural networks. In NIPS, 2016. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20Wenjie%20Li%2C%20Yujia%20Urtasun%2C%20Raquel%20Zemel%2C%20Richard%20Understanding%20the%20effective%20receptive%20field%20in%20deep%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20Wenjie%20Li%2C%20Yujia%20Urtasun%2C%20Raquel%20Zemel%2C%20Richard%20Understanding%20the%20effective%20receptive%20field%20in%20deep%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "28",
            "entry": "[28] Ari S Morcos, David GT Barrett, Neil C Rabinowitz, and Matthew Botvinick. On the importance of single directions for generalization. In ICLR, 2018. 6, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Morcos%2C%20Ari%20S.%20Barrett%2C%20David%20G.T.%20Rabinowitz%2C%20Neil%20C.%20Botvinick%2C%20Matthew%20On%20the%20importance%20of%20single%20directions%20for%20generalization%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Morcos%2C%20Ari%20S.%20Barrett%2C%20David%20G.T.%20Rabinowitz%2C%20Neil%20C.%20Botvinick%2C%20Matthew%20On%20the%20importance%20of%20single%20directions%20for%20generalization%202018"
        },
        {
            "id": "29",
            "entry": "[29] Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-Gyu Cho, Seong-Whan Lee, Sanja Fidler, Raquel Urtasun, and Alan Yuille. The role of context for object detection and semantic segmentation in the wild. In CVPR, 2014. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mottaghi%2C%20Roozbeh%20Chen%2C%20Xianjie%20Liu%2C%20Xiaobai%20Cho%2C%20Nam-Gyu%20The%20role%20of%20context%20for%20object%20detection%20and%20semantic%20segmentation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mottaghi%2C%20Roozbeh%20Chen%2C%20Xianjie%20Liu%2C%20Xiaobai%20Cho%2C%20Nam-Gyu%20The%20role%20of%20context%20for%20object%20detection%20and%20semantic%20segmentation%202014"
        },
        {
            "id": "30",
            "entry": "[30] Kevin P Murphy, Antonio Torralba, and William T Freeman. Using the forest to see the trees: A graphical model relating features, objects, and scenes. In NIPS, 2004. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Murphy%2C%20Kevin%20P.%20Torralba%2C%20Antonio%20Freeman%2C%20William%20T.%20Using%20the%20forest%20to%20see%20the%20trees%3A%20A%20graphical%20model%20relating%20features%2C%20objects%2C%20and%20scenes%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Murphy%2C%20Kevin%20P.%20Torralba%2C%20Antonio%20Freeman%2C%20William%20T.%20Using%20the%20forest%20to%20see%20the%20trees%3A%20A%20graphical%20model%20relating%20features%2C%20objects%2C%20and%20scenes%202004"
        },
        {
            "id": "31",
            "entry": "[31] David Novotny, Samuel Albanie, Diane Larlus, and Andrea Vedaldi. Self-supervised learning of geometrically stable features through probabilistic introspection. In CVPR, 2018. 7",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Novotny%2C%20David%20Albanie%2C%20Samuel%20Larlus%2C%20Diane%20Vedaldi%2C%20Andrea%20Self-supervised%20learning%20of%20geometrically%20stable%20features%20through%20probabilistic%20introspection%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Novotny%2C%20David%20Albanie%2C%20Samuel%20Larlus%2C%20Diane%20Vedaldi%2C%20Andrea%20Self-supervised%20learning%20of%20geometrically%20stable%20features%20through%20probabilistic%20introspection%202018"
        },
        {
            "id": "32",
            "entry": "[32] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In NIPS, 2015. 1, 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20R-CNN%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20R-CNN%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015"
        },
        {
            "id": "33",
            "entry": "[33] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, and Michael Bernstein. ImageNet large scale visual recognition challenge. IJCV, 2015. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20ImageNet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20ImageNet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "34",
            "entry": "[34] Jorge Sanchez, Florent Perronnin, Thomas Mensink, and Jakob Verbeek. Image classification with the fisher vector: Theory and practice. IJCV, 2013. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sanchez%2C%20Jorge%20Perronnin%2C%20Florent%20Mensink%2C%20Thomas%20Verbeek%2C%20Jakob%20Image%20classification%20with%20the%20fisher%20vector%3A%20Theory%20and%20practice%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sanchez%2C%20Jorge%20Perronnin%2C%20Florent%20Mensink%2C%20Thomas%20Verbeek%2C%20Jakob%20Image%20classification%20with%20the%20fisher%20vector%3A%20Theory%20and%20practice%202013"
        },
        {
            "id": "35",
            "entry": "[35] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "36",
            "entry": "[36] Thomas M Strat and Martin A Fischler. Context-based vision: recognizing objects using information from both 2D and 3D imagery. IEEE TPMI, 1991. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Strat%2C%20Thomas%20M.%20Fischler%2C%20Martin%20A.%20Context-based%20vision%3A%20recognizing%20objects%20using%20information%20from%20both%202D%20and%203D%20imagery%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Strat%2C%20Thomas%20M.%20Fischler%2C%20Martin%20A.%20Context-based%20vision%3A%20recognizing%20objects%20using%20information%20from%20both%202D%20and%203D%20imagery%201991"
        },
        {
            "id": "37",
            "entry": "[37] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alex Alemi. Inception-v4, inceptionresnet and the impact of residual connections on learning. In ICLR Workshop, 2016. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Ioffe%2C%20Sergey%20Vanhoucke%2C%20Vincent%20Alemi%2C%20Alex%20Inception-v4%2C%20inceptionresnet%20and%20the%20impact%20of%20residual%20connections%20on%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Ioffe%2C%20Sergey%20Vanhoucke%2C%20Vincent%20Alemi%2C%20Alex%20Inception-v4%2C%20inceptionresnet%20and%20the%20impact%20of%20residual%20connections%20on%20learning%202016"
        },
        {
            "id": "38",
            "entry": "[38] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In CVPR, 2015. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "39",
            "entry": "[39] Antonio Torralba. Contextual priming for object detection. IJCV, 2003. 1, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Torralba%2C%20Antonio%20Contextual%20priming%20for%20object%20detection%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Torralba%2C%20Antonio%20Contextual%20priming%20for%20object%20detection%202003"
        },
        {
            "id": "40",
            "entry": "[40] Antonio Torralba, Kevin P Murphy, William T Freeman, Mark A Rubin, et al. Context-based vision system for place and object recognition. In ICCV, 2003. 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Torralba%2C%20Antonio%20Murphy%2C%20Kevin%20P.%20Freeman%2C%20William%20T.%20Rubin%2C%20Mark%20A.%20Context-based%20vision%20system%20for%20place%20and%20object%20recognition%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Torralba%2C%20Antonio%20Murphy%2C%20Kevin%20P.%20Freeman%2C%20William%20T.%20Rubin%2C%20Mark%20A.%20Context-based%20vision%20system%20for%20place%20and%20object%20recognition%202003"
        },
        {
            "id": "41",
            "entry": "[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, 2017. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20NIPS%202017%209",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20NIPS%202017%209"
        },
        {
            "id": "42",
            "entry": "[42] Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang, Xiaogang Wang, and Xiaoou Tang. Residual attention network for image classification. In CVPR, 2017. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Fei%20Jiang%2C%20Mengqing%20Qian%2C%20Chen%20Yang%2C%20Shuo%20Xiaogang%20Wang%2C%20and%20Xiaoou%20Tang.%20Residual%20attention%20network%20for%20image%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Fei%20Jiang%2C%20Mengqing%20Qian%2C%20Chen%20Yang%2C%20Shuo%20Xiaogang%20Wang%2C%20and%20Xiaoou%20Tang.%20Residual%20attention%20network%20for%20image%20classification%202017"
        },
        {
            "id": "43",
            "entry": "[43] Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local neural networks. In CVPR, 2018. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Xiaolong%20Girshick%2C%20Ross%20Abhinav%20Gupta%2C%20and%20Kaiming%20He.%20Non-local%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Xiaolong%20Girshick%2C%20Ross%20Abhinav%20Gupta%2C%20and%20Kaiming%20He.%20Non-local%20neural%20networks%202018"
        },
        {
            "id": "44",
            "entry": "[44] Lior Wolf and Stanley Bileschi. A critical view of context. IJCV, 2006. 2, 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wolf%2C%20Lior%20Bileschi%2C%20Stanley%20A%20critical%20view%20of%20context%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wolf%2C%20Lior%20Bileschi%2C%20Stanley%20A%20critical%20view%20of%20context%202006"
        },
        {
            "id": "45",
            "entry": "[45] Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon. CBAM: Convolutional block attention module. In ECCV, 2018. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Woo%2C%20Sanghyun%20Park%2C%20Jongchan%20Lee%2C%20Joon-Young%20Kweon%2C%20In%20So%20CBAM%3A%20Convolutional%20block%20attention%20module%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Woo%2C%20Sanghyun%20Park%2C%20Jongchan%20Lee%2C%20Joon-Young%20Kweon%2C%20In%20So%20CBAM%3A%20Convolutional%20block%20attention%20module%202018"
        },
        {
            "id": "46",
            "entry": "[46] Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, 2015. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Kelvin%20Ba%2C%20Jimmy%20Kiros%2C%20Ryan%20Cho%2C%20Kyunghyun%20attend%20and%20tell%3A%20Neural%20image%20caption%20generation%20with%20visual%20attention%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Kelvin%20Ba%2C%20Jimmy%20Kiros%2C%20Ryan%20Cho%2C%20Kyunghyun%20attend%20and%20tell%3A%20Neural%20image%20caption%20generation%20with%20visual%20attention%202015"
        },
        {
            "id": "47",
            "entry": "[47] Jun Yang, Yu-Gang Jiang, Alexander G Hauptmann, and Chong-Wah Ngo. Evaluating bag-ofvisual-words representations in scene classification. In MIR, 2007. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jun%20Jiang%2C%20Yu-Gang%20Hauptmann%2C%20Alexander%20G.%20Ngo%2C%20Chong-Wah%20Evaluating%20bag-ofvisual-words%20representations%20in%20scene%20classification%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jun%20Jiang%2C%20Yu-Gang%20Hauptmann%2C%20Alexander%20G.%20Ngo%2C%20Chong-Wah%20Evaluating%20bag-ofvisual-words%20representations%20in%20scene%20classification%202007"
        },
        {
            "id": "48",
            "entry": "[48] Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. In ICLR, 2016. 1, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20Fisher%20Koltun%2C%20Vladlen%20Multi-scale%20context%20aggregation%20by%20dilated%20convolutions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20Fisher%20Koltun%2C%20Vladlen%20Multi-scale%20context%20aggregation%20by%20dilated%20convolutions%202016"
        },
        {
            "id": "49",
            "entry": "[49] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In BMVC, 2016. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zagoruyko%2C%20Sergey%20Komodakis%2C%20Nikos%20Wide%20residual%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zagoruyko%2C%20Sergey%20Komodakis%2C%20Nikos%20Wide%20residual%20networks%202016"
        },
        {
            "id": "50",
            "entry": "[50] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. In CVPR, 2018. 5, 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Xiangyu%20Zhou%2C%20Xinyu%20Lin%2C%20Mengxiao%20Sun%2C%20Jian%20Shufflenet%3A%20An%20extremely%20efficient%20convolutional%20neural%20network%20for%20mobile%20devices%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Xiangyu%20Zhou%2C%20Xinyu%20Lin%2C%20Mengxiao%20Sun%2C%20Jian%20Shufflenet%3A%20An%20extremely%20efficient%20convolutional%20neural%20network%20for%20mobile%20devices%202018"
        },
        {
            "id": "51",
            "entry": "[51] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. In CVPR, 2018. 9 ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zoph%2C%20Barret%20Vasudevan%2C%20Vijay%20Shlens%2C%20Jonathon%20Le%2C%20Quoc%20V.%20Learning%20transferable%20architectures%20for%20scalable%20image%20recognition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zoph%2C%20Barret%20Vasudevan%2C%20Vijay%20Shlens%2C%20Jonathon%20Le%2C%20Quoc%20V.%20Learning%20transferable%20architectures%20for%20scalable%20image%20recognition%202018"
        }
    ]
}
