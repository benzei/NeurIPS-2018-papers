{
    "filename": "7611-scaling-the-poisson-glm-to-massive-neural-datasets-through-polynomial-approximations.pdf",
    "metadata": {
        "title": "Scaling the Poisson GLM to massive neural datasets through polynomial approximations",
        "author": "David Zoltowski, Jonathan W. Pillow",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7611-scaling-the-poisson-glm-to-massive-neural-datasets-through-polynomial-approximations.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Recent advances in recording technologies have allowed neuroscientists to record simultaneous spiking activity from hundreds to thousands of neurons in multiple brain regions. Such large-scale recordings pose a major challenge to existing statistical methods for neural data analysis. Here we develop highly scalable approximate inference methods for Poisson generalized linear models (GLMs) that require only a single pass over the data. Our approach relies on a recently proposed method for obtaining approximate sufficient statistics for GLMs using polynomial approximations [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], which we adapt to the Poisson GLM setting. We focus on inference using quadratic approximations to nonlinear terms in the Poisson GLM log-likelihood with Gaussian priors, for which we derive closed-form solutions to the approximate maximum likelihood and MAP estimates, posterior distribution, and marginal likelihood. We introduce an adaptive procedure to select the polynomial approximation interval and show that the resulting method allows for efficient and accurate inference and regularization of high-dimensional parameters. We use the quadratic estimator to fit a fully-coupled Poisson GLM to spike train data recorded from 831 neurons across five regions of the mouse brain for a duration of 41 minutes, binned at 1 ms resolution. Across all neurons, this model is fit to over 2 billion spike count bins and identifies fine-timescale statistical dependencies between neurons within and across cortical and subcortical areas."
    },
    "keywords": [
        {
            "term": "maximum likelihood",
            "url": "https://en.wikipedia.org/wiki/maximum_likelihood"
        },
        {
            "term": "generalized linear models",
            "url": "https://en.wikipedia.org/wiki/generalized_linear_models"
        },
        {
            "term": "log likelihood",
            "url": "https://en.wikipedia.org/wiki/log_likelihood"
        },
        {
            "term": "retinal ganglion cell",
            "url": "https://en.wikipedia.org/wiki/retinal_ganglion_cell"
        },
        {
            "term": "sufficient statistic",
            "url": "https://en.wikipedia.org/wiki/sufficient_statistic"
        },
        {
            "term": "high dimensional",
            "url": "https://en.wikipedia.org/wiki/high_dimensional"
        },
        {
            "term": "linear model",
            "url": "https://en.wikipedia.org/wiki/linear_model"
        }
    ],
    "highlights": [
        "Poisson generalized linear models<br/><br/>The Poisson generalized linear models in neuroscience is used to identify statistical dependencies between observed spiking activity and task-relevant variables such as environmental stimuli and recent spiking activity across neurons (Figure 1a)",
        "We show that fourth order approximations are useable for approximating the log-likelihood of Poisson generalized linear models",
        "We have developed a method for scalable inference in Poisson generalized linear models that is suitable for large-scale neural recordings",
        "The method is based on polynomial approximations for approximate sufficient statistics in generalized linear models [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>]",
        "While we focused on Gaussian priors in this paper, optimizing the paGLM objective with non-Gaussian, sparsity-inducing priors is an interesting direction of future work",
        "As the approximate sufficient statistics scale with the number of parameters, scaling the method to larger numbers of parameters may require low-rank approximations to the sufficient statistics"
    ],
    "key_statements": [
        "Poisson generalized linear models<br/><br/>The Poisson generalized linear models in neuroscience is used to identify statistical dependencies between observed spiking activity and task-relevant variables such as environmental stimuli and recent spiking activity across neurons (Figure 1a)",
        "We show that fourth order approximations are useable for approximating the log-likelihood of Poisson generalized linear models",
        "After validating these estimators on simulated spike train data and a spike train recording from a primate retinal ganglion cell, we demonstrate the scalability of these methods by fitting a fullycoupled generalized linear models to the responses of 831 neurons recorded across five different regions of the mouse brain.\n2.1",
        "When using quadratic approximations for Poisson generalized linear models we found that the parameter estimates were sensitive to the approximation interval [x0, x1], especially when using the exponential nonlinearity (Figure 3a,b)",
        "The performance of paGLM-2 was more robust to the approximation interval for the Poisson generalized linear models with a softplus nonlinearity and with \u2206 = 1, such that the rate is in spikes per bin (Figure 3e,f)",
        "We have developed a method for scalable inference in Poisson generalized linear models that is suitable for large-scale neural recordings",
        "The method is based on polynomial approximations for approximate sufficient statistics in generalized linear models [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>]",
        "While we focused on Gaussian priors in this paper, optimizing the paGLM objective with non-Gaussian, sparsity-inducing priors is an interesting direction of future work",
        "As the approximate sufficient statistics scale with the number of parameters, scaling the method to larger numbers of parameters may require low-rank approximations to the sufficient statistics"
    ],
    "summary": [
        "Poisson GLM<br/><br/>The Poisson GLM in neuroscience is used to identify statistical dependencies between observed spiking activity and task-relevant variables such as environmental stimuli and recent spiking activity across neurons (Figure 1a).",
        "Using quadratic approximations to nonlinear terms in the log-likelihood, we derive the closed-form approximate maximum likelihood and MAP estimates of the parameters in Poisson GLMs with general link functions and Gaussian priors.",
        "They provide theoretical guarantees on the quality of the MAP estimates using this method and on the quality of posterior approximations for specific cases, including the Poisson GLM with an exponential nonlinearity.",
        "An alternative approach for efficient inference in Poisson GLMs is the expected log-likelihood approximation [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>], which replaces the nonlinear exponential term in the log-likelihood with its expectation across data points.",
        "Nonlinearities such as the softplus function f (x) = log(1 + exp(x)) are often used in Poisson GLMs. We extend the above methods to general nonlinearities f (x) by approximating both terms involving f in the log-likelihood f\u2206 \u2248 a22 + a1xt w + a0 (11)",
        "When using quadratic approximations for Poisson GLMs we found that the parameter estimates were sensitive to the approximation interval [x0, x1], especially when using the exponential nonlinearity (Figure 3a,b).",
        "We computed the exact log-likelihood of the estimate given a random subset of training data, whose size was small enough to store in memory.",
        "We fit a Poisson GLM with an exponential nonlinearity, a stimulus filter, and a baseline firing rate to the responses in approximately 144,000 spike count bins.",
        "Approximation intervals, we computed the paGLM-2 estimate of the parameters and evaluated the training log-likelihood of the data given the paGLM-2 estimate.",
        "The stimulus filter estimates and training log-likelihood varied considerably as a function of the approximation interval (Figure 3a,b).",
        "The performance of paGLM-2 was more robust to the approximation interval for the Poisson GLM with a softplus nonlinearity and with \u2206 = 1, such that the rate is in spikes per bin (Figure 3e,f).",
        "The interval [\u22126, 3] covered most of this distribution, and the paGLM-2 estimate of the stimulus filter computed using this approximation interval was indistinguishable from the exact ML stimulus filter (Figure 3h).",
        "To investigate the quality of paGLM-2 MAP estimates and to verify our procedure for approximate evidence optimization, we increased the dimensionality of the stimulus filter to 100 weights and fit the filter to a smaller set of 21,000 spike counts binned at \u2206 = 1.66 ms, where the stimulus was upsampled.",
        "We used a random subset of the training data to select the approximation interval for each neuron and we computed the exact MAP estimates using 50 iterations of quasi-Newton optimization.",
        "Efficient computation and storage of higher order moments will make the more accurate fourth order methods appealing"
    ],
    "headline": "We develop highly scalable approximate inference methods for Poisson generalized linear models  that require only a single pass over the data",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Mikio Aoi and Jonathan W Pillow. Scalable bayesian inference for high-dimensional neural receptive fields. bioRxiv, page 212217, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aoi%2C%20Mikio%20Pillow%2C%20Jonathan%20W.%20Scalable%20bayesian%20inference%20for%20high-dimensional%20neural%20receptive%20fields%202017"
        },
        {
            "id": "2",
            "entry": "[2] Christopher M Bishop. Bayesian pca. In Advances in neural information processing systems, pages 382\u2013388, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bishop%2C%20Christopher%20M.%20Bayesian%20pca%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bishop%2C%20Christopher%20M.%20Bayesian%20pca%201999"
        },
        {
            "id": "3",
            "entry": "[3] Ana Calabrese, Joseph W Schumacher, David M Schneider, Liam Paninski, and Sarah MN Woolley. A generalized linear model for estimating spectrotemporal receptive fields from responses to natural sounds. PloS one, 6(1):e16104, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Calabrese%2C%20Ana%20Schumacher%2C%20Joseph%20W.%20Schneider%2C%20David%20M.%20Paninski%2C%20Liam%20A%20generalized%20linear%20model%20for%20estimating%20spectrotemporal%20receptive%20fields%20from%20responses%20to%20natural%20sounds%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Calabrese%2C%20Ana%20Schumacher%2C%20Joseph%20W.%20Schneider%2C%20David%20M.%20Paninski%2C%20Liam%20A%20generalized%20linear%20model%20for%20estimating%20spectrotemporal%20receptive%20fields%20from%20responses%20to%20natural%20sounds%202011"
        },
        {
            "id": "4",
            "entry": "[4] Jason E Chung, Hannah R Joo, Jiang Lan Fan, Daniel F Liu, Alex H Barnett, Supin Chen, Charlotte Geaghan-Breiner, Mattias P Karlsson, Magnus Karlsson, Kye Y Lee, Hexin Liang, Jeremy F Magland, Angela C Tooker, Leslie F Greengard, Vanessa M Tolosa, and Loren M Frank. High-density, long-lasting, and multi-region electrophysiological recordings using polymer electrode arrays. bioRxiv, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Jason%20E.%20Joo%2C%20Hannah%20R.%20Fan%2C%20Jiang%20Lan%20Liu%2C%20Daniel%20F.%20High-density%2C%20long-lasting%2C%20and%20multi-region%20electrophysiological%20recordings%20using%20polymer%20electrode%20arrays%202018"
        },
        {
            "id": "5",
            "entry": "[5] Stephen V David, Nima Mesgarani, and Shihab A Shamma. Estimating sparse spectro-temporal receptive fields with natural stimuli. Network: Computation in Neural Systems, 18(3):191\u2013212, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=David%2C%20Stephen%20V.%20Mesgarani%2C%20Nima%20and%20Shihab%20A%20Shamma.%20Estimating%20sparse%20spectro-temporal%20receptive%20fields%20with%20natural%20stimuli%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=David%2C%20Stephen%20V.%20Mesgarani%2C%20Nima%20and%20Shihab%20A%20Shamma.%20Estimating%20sparse%20spectro-temporal%20receptive%20fields%20with%20natural%20stimuli%202007"
        },
        {
            "id": "6",
            "entry": "[6] Sebastian Gerwinn, Jakob H Macke, and Matthias Bethge. Bayesian inference for generalized linear models for spiking neurons. Frontiers in computational neuroscience, 4:12, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gerwinn%2C%20Sebastian%20Macke%2C%20Jakob%20H.%20Bethge%2C%20Matthias%20Bayesian%20inference%20for%20generalized%20linear%20models%20for%20spiking%20neurons%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gerwinn%2C%20Sebastian%20Macke%2C%20Jakob%20H.%20Bethge%2C%20Matthias%20Bayesian%20inference%20for%20generalized%20linear%20models%20for%20spiking%20neurons%202010"
        },
        {
            "id": "7",
            "entry": "[7] Jonathan Huggins, Ryan P Adams, and Tamara Broderick. Pass-glm: polynomial approximate sufficient statistics for scalable bayesian glm inference. In Advances in Neural Information Processing Systems, pages 3614\u20133624, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huggins%2C%20Jonathan%20Adams%2C%20Ryan%20P.%20Broderick%2C%20Tamara%20Pass-glm%3A%20polynomial%20approximate%20sufficient%20statistics%20for%20scalable%20bayesian%20glm%20inference%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huggins%2C%20Jonathan%20Adams%2C%20Ryan%20P.%20Broderick%2C%20Tamara%20Pass-glm%3A%20polynomial%20approximate%20sufficient%20statistics%20for%20scalable%20bayesian%20glm%20inference%202017"
        },
        {
            "id": "8",
            "entry": "[8] James J Jun, Nicholas A Steinmetz, Joshua H Siegle, Daniel J Denman, Marius Bauza, Brian Barbarits, Albert K Lee, Costas A Anastassiou, Alexandru Andrei, \u00c7agatay Ayd\u0131n, et al. Fully integrated silicon probes for high-density recording of neural activity. Nature, 551(7679):232, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jun%2C%20James%20J.%20Steinmetz%2C%20Nicholas%20A.%20Siegle%2C%20Joshua%20H.%20Denman%2C%20Daniel%20J.%20Fully%20integrated%20silicon%20probes%20for%20high-density%20recording%20of%20neural%20activity%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jun%2C%20James%20J.%20Steinmetz%2C%20Nicholas%20A.%20Siegle%2C%20Joshua%20H.%20Denman%2C%20Daniel%20J.%20Fully%20integrated%20silicon%20probes%20for%20high-density%20recording%20of%20neural%20activity%202017"
        },
        {
            "id": "9",
            "entry": "[9] Scott Linderman, Ryan P Adams, and Jonathan W Pillow. Bayesian latent structure discovery from multi-neuron recordings. In Advances in neural information processing systems, pages 2002\u20132010, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Linderman%2C%20Scott%20Adams%2C%20Ryan%20P.%20Pillow%2C%20Jonathan%20W.%20Bayesian%20latent%20structure%20discovery%20from%20multi-neuron%20recordings%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Linderman%2C%20Scott%20Adams%2C%20Ryan%20P.%20Pillow%2C%20Jonathan%20W.%20Bayesian%20latent%20structure%20discovery%20from%20multi-neuron%20recordings%202002"
        },
        {
            "id": "10",
            "entry": "[10] David JC MacKay et al. Bayesian nonlinear modeling for the prediction competition. ASHRAE transactions, 100(2):1053\u20131062, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=MacKay%2C%20David%20J.C.%20Bayesian%20nonlinear%20modeling%20for%20the%20prediction%20competition%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=MacKay%2C%20David%20J.C.%20Bayesian%20nonlinear%20modeling%20for%20the%20prediction%20competition%201994"
        },
        {
            "id": "11",
            "entry": "[11] John C Mason and David C Handscomb. Chebyshev polynomials. CRC Press, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mason%2C%20John%20C.%20Handscomb%2C%20David%20C.%20Chebyshev%20polynomials%202002"
        },
        {
            "id": "12",
            "entry": "[12] Liam Paninski. Maximum likelihood estimation of cascade point-process neural encoding models. Network: Computation in Neural Systems, 15(4):243\u2013262, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paninski%2C%20Liam%20Maximum%20likelihood%20estimation%20of%20cascade%20point-process%20neural%20encoding%20models%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Paninski%2C%20Liam%20Maximum%20likelihood%20estimation%20of%20cascade%20point-process%20neural%20encoding%20models%202004"
        },
        {
            "id": "13",
            "entry": "[13] Il Memming Park, Miriam LR Meister, Alexander C Huk, and Jonathan W Pillow. Encoding and decoding in parietal cortex during sensorimotor decision-making. Nature neuroscience, 17(10):1395\u20131403, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20Il%20Memming%20Meister%2C%20Miriam%20L.R.%20Huk%2C%20Alexander%20C.%20Pillow%2C%20Jonathan%20W.%20Encoding%20and%20decoding%20in%20parietal%20cortex%20during%20sensorimotor%20decision-making%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20Il%20Memming%20Meister%2C%20Miriam%20L.R.%20Huk%2C%20Alexander%20C.%20Pillow%2C%20Jonathan%20W.%20Encoding%20and%20decoding%20in%20parietal%20cortex%20during%20sensorimotor%20decision-making%202014"
        },
        {
            "id": "14",
            "entry": "[14] Il Memming Park and Jonathan W Pillow. Bayesian spike-triggered covariance analysis. In Advances in neural information processing systems, pages 1692\u20131700, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20Il%20Memming%20Pillow%2C%20Jonathan%20W.%20Bayesian%20spike-triggered%20covariance%20analysis%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20Il%20Memming%20Pillow%2C%20Jonathan%20W.%20Bayesian%20spike-triggered%20covariance%20analysis%202011"
        },
        {
            "id": "15",
            "entry": "[15] Jonathan W Pillow, Jonathon Shlens, Liam Paninski, Alexander Sher, Alan M Litke, EJ Chichilnisky, and Eero P Simoncelli. Spatio-temporal correlations and visual signalling in a complete neuronal population. Nature, 454(7207):995, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pillow%2C%20Jonathan%20W.%20Shlens%2C%20Jonathon%20Paninski%2C%20Liam%20Sher%2C%20Alexander%20Spatio-temporal%20correlations%20and%20visual%20signalling%20in%20a%20complete%20neuronal%20population%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pillow%2C%20Jonathan%20W.%20Shlens%2C%20Jonathon%20Paninski%2C%20Liam%20Sher%2C%20Alexander%20Spatio-temporal%20correlations%20and%20visual%20signalling%20in%20a%20complete%20neuronal%20population%202008"
        },
        {
            "id": "16",
            "entry": "[16] Kamiar Rahnama Rad and Liam Paninski. Efficient, adaptive estimation of two-dimensional firing rate surfaces via gaussian process methods. Network: Computation in Neural Systems, 21(3-4):142\u2013168, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rad%2C%20Kamiar%20Rahnama%20Paninski%2C%20Liam%20Efficient%2C%20adaptive%20estimation%20of%20two-dimensional%20firing%20rate%20surfaces%20via%20gaussian%20process%20methods%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rad%2C%20Kamiar%20Rahnama%20Paninski%2C%20Liam%20Efficient%2C%20adaptive%20estimation%20of%20two-dimensional%20firing%20rate%20surfaces%20via%20gaussian%20process%20methods%202010"
        },
        {
            "id": "17",
            "entry": "[17] Alexandro D Ramirez and Liam Paninski. Fast inference in generalized linear models via expected log-likelihoods. Journal of computational neuroscience, 36(2):215\u2013234, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramirez%2C%20Alexandro%20D.%20Paninski%2C%20Liam%20Fast%20inference%20in%20generalized%20linear%20models%20via%20expected%20log-likelihoods%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ramirez%2C%20Alexandro%20D.%20Paninski%2C%20Liam%20Fast%20inference%20in%20generalized%20linear%20models%20via%20expected%20log-likelihoods%202014"
        },
        {
            "id": "18",
            "entry": "[18] Maneesh Sahani and Jennifer F Linden. Evidence optimization techniques for estimating stimulus-response functions. In Advances in neural information processing systems, pages 317\u2013324, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sahani%2C%20Maneesh%20Linden%2C%20Jennifer%20F.%20Evidence%20optimization%20techniques%20for%20estimating%20stimulus-response%20functions%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sahani%2C%20Maneesh%20Linden%2C%20Jennifer%20F.%20Evidence%20optimization%20techniques%20for%20estimating%20stimulus-response%20functions%202003"
        },
        {
            "id": "19",
            "entry": "[19] Eero P Simoncelli, Liam Paninski, Jonathan Pillow, Odelia Schwartz, et al. Characterization of neural responses with stochastic stimuli. The cognitive neurosciences, 3(327-338):1, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simoncelli%2C%20Eero%20P.%20Paninski%2C%20Liam%20Pillow%2C%20Jonathan%20Schwartz%2C%20Odelia%20Characterization%20of%20neural%20responses%20with%20stochastic%20stimuli%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simoncelli%2C%20Eero%20P.%20Paninski%2C%20Liam%20Pillow%2C%20Jonathan%20Schwartz%2C%20Odelia%20Characterization%20of%20neural%20responses%20with%20stochastic%20stimuli%202004"
        },
        {
            "id": "20",
            "entry": "[20] Ian H Stevenson, James M Rebesco, Nicholas G Hatsopoulos, Zach Haga, Lee E Miller, and Konrad P Kording. Bayesian inference of functional connectivity and network structure from spikes. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 17(3):203\u2013213, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stevenson%2C%20Ian%20H.%20Rebesco%2C%20James%20M.%20Hatsopoulos%2C%20Nicholas%20G.%20Haga%2C%20Zach%20Bayesian%20inference%20of%20functional%20connectivity%20and%20network%20structure%20from%20spikes%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stevenson%2C%20Ian%20H.%20Rebesco%2C%20James%20M.%20Hatsopoulos%2C%20Nicholas%20G.%20Haga%2C%20Zach%20Bayesian%20inference%20of%20functional%20connectivity%20and%20network%20structure%20from%20spikes%202009"
        },
        {
            "id": "21",
            "entry": "[21] Carsen Stringer, Marius Pachitariu, Nicholas Steinmetz, Charu Bai Reddy, Matteo Carandini, and Kenneth D Harris. Spontaneous behaviors drive multidimensional, brain-wide population activity. bioRxiv, page 306019, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stringer%2C%20Carsen%20Pachitariu%2C%20Marius%20Steinmetz%2C%20Nicholas%20Reddy%2C%20Charu%20Bai%20Spontaneous%20behaviors%20drive%20multidimensional%2C%20brain-wide%20population%20activity%202018"
        },
        {
            "id": "22",
            "entry": "[22] Michael E Tipping. Sparse bayesian learning and the relevance vector machine. Journal of machine learning research, 1(Jun):211\u2013244, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tipping%2C%20Michael%20E.%20Sparse%20bayesian%20learning%20and%20the%20relevance%20vector%20machine%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tipping%2C%20Michael%20E.%20Sparse%20bayesian%20learning%20and%20the%20relevance%20vector%20machine%202001"
        },
        {
            "id": "23",
            "entry": "[23] Wilson Truccolo, Uri T Eden, Matthew R Fellows, John P Donoghue, and Emery N Brown. A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects. Journal of neurophysiology, 93(2):1074\u20131089, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Truccolo%2C%20Wilson%20Eden%2C%20Uri%20T.%20Fellows%2C%20Matthew%20R.%20Donoghue%2C%20John%20P.%20A%20point%20process%20framework%20for%20relating%20neural%20spiking%20activity%20to%20spiking%20history%2C%20neural%20ensemble%2C%20and%20extrinsic%20covariate%20effects%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Truccolo%2C%20Wilson%20Eden%2C%20Uri%20T.%20Fellows%2C%20Matthew%20R.%20Donoghue%2C%20John%20P.%20A%20point%20process%20framework%20for%20relating%20neural%20spiking%20activity%20to%20spiking%20history%2C%20neural%20ensemble%2C%20and%20extrinsic%20covariate%20effects%202005"
        },
        {
            "id": "24",
            "entry": "[24] VJ Uzzell and EJ Chichilnisky. Precision of spike trains in primate retinal ganglion cells. Journal of Neurophysiology, 92(2):780\u2013789, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Uzzell%2C%20V.J.%20Chichilnisky%2C%20E.J.%20Precision%20of%20spike%20trains%20in%20primate%20retinal%20ganglion%20cells%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Uzzell%2C%20V.J.%20Chichilnisky%2C%20E.J.%20Precision%20of%20spike%20trains%20in%20primate%20retinal%20ganglion%20cells%202004"
        },
        {
            "id": "25",
            "entry": "[25] David P Wipf and Srikantan S Nagarajan. A new view of automatic relevance determination. In Advances in neural information processing systems, pages 1625\u20131632, 2008. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wipf%2C%20David%20P.%20Nagarajan%2C%20Srikantan%20S.%20A%20new%20view%20of%20automatic%20relevance%20determination%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wipf%2C%20David%20P.%20Nagarajan%2C%20Srikantan%20S.%20A%20new%20view%20of%20automatic%20relevance%20determination%202008"
        }
    ]
}
