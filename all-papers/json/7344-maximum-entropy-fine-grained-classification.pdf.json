{
    "filename": "7344-maximum-entropy-fine-grained-classification.pdf",
    "metadata": {
        "title": "Maximum-Entropy Fine Grained Classification",
        "author": "Abhimanyu Dubey, Otkrist Gupta, Ramesh Raskar, Nikhil Naik",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7344-maximum-entropy-fine-grained-classification.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Fine-Grained Visual Classification (FGVC) is an important computer vision problem that involves small diversity within the different classes, and often requires expert annotators to collect data. Utilizing this notion of small visual diversity, we revisit Maximum-Entropy learning in the context of fine-grained classification, and provide a training routine that maximizes the entropy of the output probability distribution for training convolutional neural networks on FGVC tasks. We provide a theoretical as well as empirical justification of our approach, and achieve stateof-the-art performance across a variety of classification tasks in FGVC, that can potentially be extended to any fine-tuning task. Our method is robust to different hyperparameter values, amount of training data and amount of training label noise and can hence be a valuable tool in many similar problems."
    },
    "keywords": [
        {
            "term": "fine tuning",
            "url": "https://en.wikipedia.org/wiki/fine_tuning"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "cross entropy",
            "url": "https://en.wikipedia.org/wiki/cross_entropy"
        },
        {
            "term": "maximum entropy",
            "url": "https://en.wikipedia.org/wiki/maximum_entropy"
        },
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        }
    ],
    "highlights": [
        "For ImageNet [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>] classification and similar large-scale classification tasks that span numerous diverse classes and millions of images, strongly discriminative learning by minimizing the cross-entropy from the labels improves performance for convolutional neural networks (CNNs)",
        "Fine-grained visual classification problems differ from such large-scale classification in two ways: (i) the classes are visually very similar to each other and are harder to distinguish between, and there are fewer training samples and the training dataset might not be representative of the application scenario",
        "This is helpful in finegrained classification: for instance, if a certain species of bird is mostly photographed against a different background compared to other species, memorizing the background will lower generalization performance while lowering training cross-entropy error, since the convolutional neural networks will associate the background to the bird itself",
        "Our contributions can be listed as follows: (i) we formalize the notion of \u201cfine-grained\u201d vs \u201clarge-scale\u201d image classification based on a measure of diversity of the features, we derive bounds on the 2 regularization of classifier weights based on this diversity and entropy of the classifier, we provide uniform convergence bounds on estimating entropy from samples in terms of feature diversity, we formulate a fine-tuning objective function that obtains state-of-the-art performance on five most-commonly used Fine-Grained Visual Classification datasets across six widely-used convolutional neural networks architectures, and (v) we analyze the effect of Maximum-Entropy training over different hyperparameter values, amount of training data, and amount of training label noise to demonstrate that our method is consistently robust to all the above.\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00e9al, Canada",
        "Many real-world applications of computer vision models involve extensive fine-tuning on small, relatively imbalanced datasets with much smaller diversity in the training set compared to the largescale models they are fine-tuned from, a notable example of which is fine-grained recognition"
    ],
    "key_statements": [
        "For ImageNet [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>] classification and similar large-scale classification tasks that span numerous diverse classes and millions of images, strongly discriminative learning by minimizing the cross-entropy from the labels improves performance for convolutional neural networks (CNNs)",
        "Fine-grained visual classification problems differ from such large-scale classification in two ways: (i) the classes are visually very similar to each other and are harder to distinguish between, and there are fewer training samples and the training dataset might not be representative of the application scenario",
        "This is helpful in finegrained classification: for instance, if a certain species of bird is mostly photographed against a different background compared to other species, memorizing the background will lower generalization performance while lowering training cross-entropy error, since the convolutional neural networks will associate the background to the bird itself",
        "Our contributions can be listed as follows: (i) we formalize the notion of \u201cfine-grained\u201d vs \u201clarge-scale\u201d image classification based on a measure of diversity of the features, we derive bounds on the 2 regularization of classifier weights based on this diversity and entropy of the classifier, we provide uniform convergence bounds on estimating entropy from samples in terms of feature diversity, we formulate a fine-tuning objective function that obtains state-of-the-art performance on five most-commonly used Fine-Grained Visual Classification datasets across six widely-used convolutional neural networks architectures, and (v) we analyze the effect of Maximum-Entropy training over different hyperparameter values, amount of training data, and amount of training label noise to demonstrate that our method is consistently robust to all the above.\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00e9al, Canada",
        "Many real-world applications of computer vision models involve extensive fine-tuning on small, relatively imbalanced datasets with much smaller diversity in the training set compared to the largescale models they are fine-tuned from, a notable example of which is fine-grained recognition"
    ],
    "summary": [
        "For ImageNet [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>] classification and similar large-scale classification tasks that span numerous diverse classes and millions of images, strongly discriminative learning by minimizing the cross-entropy from the labels improves performance for convolutional neural networks (CNNs).",
        "Learning CNN models that have a higher value of output entropy will reduce the \u201cconfidence\u201d of the classifier, leading in better generalization abilities when training with limited, fine-grained training data.",
        "Our work builds on their analysis by providing a theoretical treatment of fine-grained classification problems, and justifies the application of Maximum-Entropy to target scenarios with limited diversity between classes with limited training data.",
        "We obtain large improvements in fine-grained classification, which motivates the usage of the Maximum-Entropy training principle in the fine-tuning setting, opening up this idea to much broader range of applied computer vision problems.",
        "It can be understood that problems that are fine-grained will often require more information to distinguish between classes, and regularizing the prediction entropy prevents creating models that memorize a lot of information about the training data, and can potentially benefit generalization.",
        "The result ensures that for large N , in a fine-grained classification problem, the sample estimate of average conditional entropy is close to the expected conditional entropy.",
        "Corollary 1 shows that as long as the diversity of features is small, and N is large, the same conclusions drawn from Theorem 1 apply in the case of the empirical mean entropy as well.",
        "Maximum-Entropy training improves performance across five standard fine-grained datasets, with substantial gains in low-performing models.",
        "Classification Accuracy: First, we observe that Maximum-Entropy training obtains significant performance gains when fine-tuning from models trained on the ImageNet dataset (e.g., GoogLeNet",
        "Maximum-Entropy classification improves prediction performance for CNN architectures specifically designed for fine-grained visual classification.",
        "For Maximum-Entropy, we observe a substantial decrease in the width of the tail of eigenvalue magnitudes, suggesting a larger increase in generality of features in both training and test sets, which confirms our hypothesis.",
        "ImageNet Ablation Experiment: To understand the effect of Maximum-Entropy training on datasets with more samples compared to the small fine-grained datasets, we create two synthetic datasets: (i) Random-ImageNet, which is formed by selecting 116K images from a random subset of 117 classes of ImageNet [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], and Dogs-ImageNet, which is formed by selecting all classes from ImageNet that have dogs as labels, which has the same number of images and classes as Random-ImageNet. Dogs-ImageNet has less diversity compared to Random-ImageNet, and we expect the gains from Maximum-Entropy to be higher.",
        "On comparing performance with Label-Smoothing Regularization, we found that Maximum-Entropy provides much larger gains on fine-grained recognition."
    ],
    "headline": "We provide a theoretical as well as empirical justification of our approach, and achieve stateof-the-art performance across a variety of classification tasks in Fine-Grained Visual Classification, that can potentially be extended to any fine-tuning task",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sumiyoshi Abe and Yuko Okamoto. Nonextensive statistical mechanics and its applications, volume 560. Springer Science & Business Media, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abe%2C%20Sumiyoshi%20Okamoto%2C%20Yuko%20Nonextensive%20statistical%20mechanics%20and%20its%20applications%2C%20volume%20560%202001"
        },
        {
            "id": "2",
            "entry": "[2] Peter L Bartlett, Dylan J Foster, and Matus J Telgarsky. Spectrally-normalized margin bounds for neural networks. In Advances in Neural Information Processing Systems, pages 6240\u20136249, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20Peter%20L.%20Foster%2C%20Dylan%20J.%20Telgarsky%2C%20Matus%20J.%20Spectrally-normalized%20margin%20bounds%20for%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20Peter%20L.%20Foster%2C%20Dylan%20J.%20Telgarsky%2C%20Matus%20J.%20Spectrally-normalized%20margin%20bounds%20for%20neural%20networks%202017"
        },
        {
            "id": "3",
            "entry": "[3] Steve Branson, Grant Van Horn, Serge Belongie, and Pietro Perona. Bird species categorization using pose normalized deep convolutional nets. arXiv preprint arXiv:1406.2952, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1406.2952"
        },
        {
            "id": "4",
            "entry": "[4] Yihua Chen, Eric K Garcia, Maya R Gupta, Ali Rahimi, and Luca Cazzanti. Similarity-based classification: Concepts and algorithms. Journal of Machine Learning Research, 10(Mar):747\u2013776, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Yihua%20Garcia%2C%20Eric%20K.%20Gupta%2C%20Maya%20R.%20Rahimi%2C%20Ali%20Similarity-based%20classification%3A%20Concepts%20and%20algorithms%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Yihua%20Garcia%2C%20Eric%20K.%20Gupta%2C%20Maya%20R.%20Rahimi%2C%20Ali%20Similarity-based%20classification%3A%20Concepts%20and%20algorithms%202009"
        },
        {
            "id": "5",
            "entry": "[5] Mircea Cimpoi, Subhransu Maji, and Andrea Vedaldi. Deep filter banks for texture recognition and segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3828\u20133836, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cimpoi%2C%20Mircea%20Maji%2C%20Subhransu%20Vedaldi%2C%20Andrea%20Deep%20filter%20banks%20for%20texture%20recognition%20and%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cimpoi%2C%20Mircea%20Maji%2C%20Subhransu%20Vedaldi%2C%20Andrea%20Deep%20filter%20banks%20for%20texture%20recognition%20and%20segmentation%202015"
        },
        {
            "id": "6",
            "entry": "[6] Yin Cui, Feng Zhou, Jiang Wang, Xiao Liu, Yuanqing Lin, and Serge Belongie. Kernel pooling for convolutional neural networks. IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cui%2C%20Yin%20Zhou%2C%20Feng%20Wang%2C%20Jiang%20Liu%2C%20Xiao%20Kernel%20pooling%20for%20convolutional%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cui%2C%20Yin%20Zhou%2C%20Feng%20Wang%2C%20Jiang%20Liu%2C%20Xiao%20Kernel%20pooling%20for%20convolutional%20neural%20networks%202017"
        },
        {
            "id": "7",
            "entry": "[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20ImageNet%3A%20A%20Large-Scale%20Hierarchical%20Image%20Database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20ImageNet%3A%20A%20Large-Scale%20Hierarchical%20Image%20Database%202009"
        },
        {
            "id": "8",
            "entry": "[8] Mario A. T. Figueiredo and Anil K. Jain. Unsupervised learning of finite mixture models. IEEE Transactions on pattern analysis and machine intelligence, 24(3):381\u2013396, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Figueiredo%2C%20Mario%20A.T.%20Jain%2C%20Anil%20K.%20Unsupervised%20learning%20of%20finite%20mixture%20models%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Figueiredo%2C%20Mario%20A.T.%20Jain%2C%20Anil%20K.%20Unsupervised%20learning%20of%20finite%20mixture%20models%202002"
        },
        {
            "id": "9",
            "entry": "[9] Yang Gao, Oscar Beijbom, Ning Zhang, and Trevor Darrell. Compact bilinear pooling. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 317\u2013326, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gao%2C%20Yang%20Beijbom%2C%20Oscar%20Zhang%2C%20Ning%20Darrell%2C%20Trevor%20Compact%20bilinear%20pooling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gao%2C%20Yang%20Beijbom%2C%20Oscar%20Zhang%2C%20Ning%20Darrell%2C%20Trevor%20Compact%20bilinear%20pooling%202016"
        },
        {
            "id": "10",
            "entry": "[10] Gene H Golub, Per Christian Hansen, and Dianne P O\u2019Leary. Tikhonov regularization and total least squares. SIAM Journal on Matrix Analysis and Applications, 21(1):185\u2013194, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Golub%2C%20Gene%20H.%20Hansen%2C%20Per%20Christian%20O%E2%80%99Leary%2C%20Dianne%20P.%20Tikhonov%20regularization%20and%20total%20least%20squares%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Golub%2C%20Gene%20H.%20Hansen%2C%20Per%20Christian%20O%E2%80%99Leary%2C%20Dianne%20P.%20Tikhonov%20regularization%20and%20total%20least%20squares%201999"
        },
        {
            "id": "11",
            "entry": "[11] Yves Grandvalet and Yoshua Bengio. Entropy regularization.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grandvalet%2C%20Yves%20Bengio%2C%20Yoshua%20Entropy%20regularization"
        },
        {
            "id": "12",
            "entry": "[12] Stephen F Gull. Bayesian inductive inference and maximum entropy. In Maximum-entropy and Bayesian methods in science and engineering, pages 53\u201374.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gull%2C%20Stephen%20F.%20Bayesian%20inductive%20inference%20and%20maximum%20entropy",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gull%2C%20Stephen%20F.%20Bayesian%20inductive%20inference%20and%20maximum%20entropy"
        },
        {
            "id": "13",
            "entry": "[13] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. arXiv preprint arXiv:1706.04599, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04599"
        },
        {
            "id": "14",
            "entry": "[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "15",
            "entry": "[15] Max Jaderberg, Karen Simonyan, Andrew Zisserman, and Koray Kavukcuoglu. Spatial transformer networks. In Advances in Neural Information Processing Systems, pages 2017\u20132025, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Kavukcuoglu%2C%20Koray%20Spatial%20transformer%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Kavukcuoglu%2C%20Koray%20Spatial%20transformer%20networks%202017"
        },
        {
            "id": "16",
            "entry": "[16] Edwin T Jaynes. Information theory and statistical mechanics. Physical review, 106(4):620, 1957.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaynes%2C%20Edwin%20T.%20Information%20theory%20and%20statistical%20mechanics%201957",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaynes%2C%20Edwin%20T.%20Information%20theory%20and%20statistical%20mechanics%201957"
        },
        {
            "id": "17",
            "entry": "[17] Herve Jegou, Florent Perronnin, Matthijs Douze, Jorge S\u00e1nchez, Patrick Perez, and Cordelia Schmid. Aggregating local image descriptors into compact codes. IEEE transactions on pattern analysis and machine intelligence, 34(9):1704\u20131716, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aggregating%20local%20image%20descriptors%20into%20compact%20codes%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aggregating%20local%20image%20descriptors%20into%20compact%20codes%202012"
        },
        {
            "id": "18",
            "entry": "[18] Dag Jonsson. Some limit theorems for the eigenvalues of a sample covariance matrix. Journal of Multivariate Analysis, 12(1):1\u201338, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jonsson%2C%20Dag%20Some%20limit%20theorems%20for%20the%20eigenvalues%20of%20a%20sample%20covariance%20matrix%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jonsson%2C%20Dag%20Some%20limit%20theorems%20for%20the%20eigenvalues%20of%20a%20sample%20covariance%20matrix%201982"
        },
        {
            "id": "19",
            "entry": "[19] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Fei-Fei Li. Novel dataset for fine-grained image categorization: Stanford dogs.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khosla%2C%20Aditya%20Jayadevaprakash%2C%20Nityananda%20Yao%2C%20Bangpeng%20Li%2C%20Fei-Fei%20Novel%20dataset%20for%20fine-grained%20image%20categorization%3A%20Stanford%20dogs"
        },
        {
            "id": "20",
            "entry": "[20] Shu Kong and Charless Fowlkes. Low-rank bilinear pooling for fine-grained classification. IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kong%2C%20Shu%20Fowlkes%2C%20Charless%20Low-rank%20bilinear%20pooling%20for%20fine-grained%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kong%2C%20Shu%20Fowlkes%2C%20Charless%20Low-rank%20bilinear%20pooling%20for%20fine-grained%20classification%202017"
        },
        {
            "id": "21",
            "entry": "[21] Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig, James Philbin, and Li Fei-Fei. The unreasonable effectiveness of noisy data for fine-grained recognition. In European Conference on Computer Vision, pages 301\u2013320.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krause%2C%20Jonathan%20Sapp%2C%20Benjamin%20Howard%2C%20Andrew%20Zhou%2C%20Howard%20The%20unreasonable%20effectiveness%20of%20noisy%20data%20for%20fine-grained%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krause%2C%20Jonathan%20Sapp%2C%20Benjamin%20Howard%2C%20Andrew%20Zhou%2C%20Howard%20The%20unreasonable%20effectiveness%20of%20noisy%20data%20for%20fine-grained%20recognition"
        },
        {
            "id": "22",
            "entry": "[22] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained categorization. In Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 554\u2013561, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krause%2C%20Jonathan%20Stark%2C%20Michael%20Deng%2C%20Jia%20Fei-Fei%2C%20Li%203d%20object%20representations%20for%20fine-grained%20categorization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krause%2C%20Jonathan%20Stark%2C%20Michael%20Deng%2C%20Jia%20Fei-Fei%2C%20Li%203d%20object%20representations%20for%20fine-grained%20categorization%202013"
        },
        {
            "id": "23",
            "entry": "[23] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The cifar-10 dataset, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20The%20cifar-10%20dataset%202014"
        },
        {
            "id": "24",
            "entry": "[24] Tsung-Yu Lin and Subhransu Maji. Improved bilinear pooling with cnns. arXiv preprint arXiv:1707.06772, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06772"
        },
        {
            "id": "25",
            "entry": "[25] Tsung-Yu Lin, Aruni RoyChowdhury, and Subhransu Maji. Bilinear cnn models for fine-grained visual recognition. In Proceedings of the IEEE International Conference on Computer Vision, pages 1449\u20131457, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Tsung-Yu%20RoyChowdhury%2C%20Aruni%20Maji%2C%20Subhransu%20Bilinear%20cnn%20models%20for%20fine-grained%20visual%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Tsung-Yu%20RoyChowdhury%2C%20Aruni%20Maji%2C%20Subhransu%20Bilinear%20cnn%20models%20for%20fine-grained%20visual%20recognition%202015"
        },
        {
            "id": "26",
            "entry": "[26] Maolin Liu, Chengyue Yu, Hefei Ling, and Jie Lei. Hierarchical joint cnn-based models for fine-grained cars recognition. In International Conference on Cloud Computing and Security, pages 337\u2013347.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Maolin%20Yu%2C%20Chengyue%20Ling%2C%20Hefei%20Lei%2C%20Jie%20Hierarchical%20joint%20cnn-based%20models%20for%20fine-grained%20cars%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Maolin%20Yu%2C%20Chengyue%20Ling%2C%20Hefei%20Lei%2C%20Jie%20Hierarchical%20joint%20cnn-based%20models%20for%20fine-grained%20cars%20recognition"
        },
        {
            "id": "27",
            "entry": "[27] Yuping Luo, Chung-Cheng Chiu, Navdeep Jaitly, and Ilya Sutskever. Learning online alignments with continuous rewards policy gradient. arXiv preprint arXiv:1608.01281, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.01281"
        },
        {
            "id": "28",
            "entry": "[28] Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi. Fine-grained visual classification of aircraft. arXiv preprint arXiv:1306.5151, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1306.5151"
        },
        {
            "id": "29",
            "entry": "[29] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning, pages 1928\u20131937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "30",
            "entry": "[30] Mohammad Moghimi, Mohammad Saberian, Jian Yang, Li-Jia Li, Nuno Vasconcelos, and Serge Belongie. Boosted convolutional neural networks. In British Machine Vision Conference (BMVC), York, UK, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Moghimi%2C%20Mohammad%20Saberian%2C%20Mohammad%20Yang%2C%20Jian%20Li%2C%20Li-Jia%20Boosted%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Moghimi%2C%20Mohammad%20Saberian%2C%20Mohammad%20Yang%2C%20Jian%20Li%2C%20Li-Jia%20Boosted%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "31",
            "entry": "[31] Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. A pac-bayesian approach to spectrally-normalized margin bounds for neural networks. arXiv preprint arXiv:1707.09564, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.09564"
        },
        {
            "id": "32",
            "entry": "[32] Adam Paskze and Soumith Chintala. Tensors and Dynamic neural networks in Python with strong GPU acceleration. https://github.com/pytorch. Accessed:[January 1, 2017].",
            "url": "https://github.com/pytorch"
        },
        {
            "id": "33",
            "entry": "[33] Gabriel Pereyra, George Tucker, Jan Chorowski, \u0141ukasz Kaiser, and Geoffrey Hinton. Regularizing neural networks by penalizing confident output distributions. arXiv preprint arXiv:1701.06548, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.06548"
        },
        {
            "id": "34",
            "entry": "[34] Florent Perronnin, Jorge S\u00e1nchez, and Thomas Mensink. Improving the fisher kernel for large-scale image classification. Computer Vision\u2013ECCV 2010, pages 143\u2013156, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Florent%20Perronnin%2C%20Jorge%20S%C3%A1nchez%20Mensink%2C%20Thomas%20Improving%20the%20fisher%20kernel%20for%20large-scale%20image%20classification%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Florent%20Perronnin%2C%20Jorge%20S%C3%A1nchez%20Mensink%2C%20Thomas%20Improving%20the%20fisher%20kernel%20for%20large-scale%20image%20classification%202010"
        },
        {
            "id": "35",
            "entry": "[35] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91\u201399, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015"
        },
        {
            "id": "36",
            "entry": "[36] Kenneth Rose. Deterministic annealing for clustering, compression, classification, regression, and related optimization problems. Proceedings of the IEEE, 86(11):2210\u20132239, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rose%2C%20Kenneth%20Deterministic%20annealing%20for%20clustering%2C%20compression%2C%20classification%2C%20regression%2C%20and%20related%20optimization%20problems%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rose%2C%20Kenneth%20Deterministic%20annealing%20for%20clustering%2C%20compression%2C%20classification%2C%20regression%2C%20and%20related%20optimization%20problems%201998"
        },
        {
            "id": "37",
            "entry": "[37] John Shawe-Taylor and David Hardoon. Pac-bayes analysis of maximum entropy classification. In Artificial Intelligence and Statistics, pages 480\u2013487, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shawe-Taylor%2C%20John%20Hardoon%2C%20David%20Pac-bayes%20analysis%20of%20maximum%20entropy%20classification%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shawe-Taylor%2C%20John%20Hardoon%2C%20David%20Pac-bayes%20analysis%20of%20maximum%20entropy%20classification%202009"
        },
        {
            "id": "38",
            "entry": "[38] Marcel Simon, Erik Rodner, Yang Gao, Trevor Darrell, and Joachim Denzler. Generalized orderless pooling performs implicit salient matching. arXiv preprint arXiv:1705.00487, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.00487"
        },
        {
            "id": "39",
            "entry": "[39] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "40",
            "entry": "[40] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1\u20139, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "41",
            "entry": "[41] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2818\u20132826, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Vanhoucke%2C%20Vincent%20Ioffe%2C%20Sergey%20Shlens%2C%20Jon%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Vanhoucke%2C%20Vincent%20Ioffe%2C%20Sergey%20Shlens%2C%20Jon%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016"
        },
        {
            "id": "42",
            "entry": "[42] Martin Szummer and Tommi Jaakkola. Partially labeled classification with markov random walks. In Advances in neural information processing systems, pages 945\u2013952, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szummer%2C%20Martin%20Jaakkola%2C%20Tommi%20Partially%20labeled%20classification%20with%20markov%20random%20walks%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szummer%2C%20Martin%20Jaakkola%2C%20Tommi%20Partially%20labeled%20classification%20with%20markov%20random%20walks%202002"
        },
        {
            "id": "43",
            "entry": "[43] Grant Van Horn, Steve Branson, Ryan Farrell, Scott Haber, Jessie Barry, Panos Ipeirotis, Pietro Perona, and Serge Belongie. Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 595\u2013604, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Horn%2C%20Grant%20Van%20Branson%2C%20Steve%20Farrell%2C%20Ryan%20Haber%2C%20Scott%20Building%20a%20bird%20recognition%20app%20and%20large%20scale%20dataset%20with%20citizen%20scientists%3A%20The%20fine%20print%20in%20fine-grained%20dataset%20collection%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Horn%2C%20Grant%20Van%20Branson%2C%20Steve%20Farrell%2C%20Ryan%20Haber%2C%20Scott%20Building%20a%20bird%20recognition%20app%20and%20large%20scale%20dataset%20with%20citizen%20scientists%3A%20The%20fine%20print%20in%20fine-grained%20dataset%20collection%202015"
        },
        {
            "id": "44",
            "entry": "[44] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset. 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wah%2C%20Catherine%20Branson%2C%20Steve%20Welinder%2C%20Peter%20Perona%2C%20Pietro%20The%20caltech-ucsd%20birds-200-2011%202011"
        },
        {
            "id": "45",
            "entry": "[45] Yaming Wang, Jonghyun Choi, Vlad Morariu, and Larry S. Davis. Mining discriminative triplets of patches for fine-grained classification. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yaming%20Choi%2C%20Jonghyun%20Morariu%2C%20Vlad%20Davis%2C%20Larry%20S.%20Mining%20discriminative%20triplets%20of%20patches%20for%20fine-grained%20classification%202016-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Yaming%20Choi%2C%20Jonghyun%20Morariu%2C%20Vlad%20Davis%2C%20Larry%20S.%20Mining%20discriminative%20triplets%20of%20patches%20for%20fine-grained%20classification%202016-06"
        },
        {
            "id": "46",
            "entry": "[46] Ning Zhang, Ryan Farrell, and Trever Darrell. Pose pooling kernels for sub-category recognition. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3665\u20133672. IEEE, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Ning%20Farrell%2C%20Ryan%20Darrell%2C%20Trever%20Pose%20pooling%20kernels%20for%20sub-category%20recognition%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Ning%20Farrell%2C%20Ryan%20Darrell%2C%20Trever%20Pose%20pooling%20kernels%20for%20sub-category%20recognition%202012"
        },
        {
            "id": "47",
            "entry": "[47] Xiaopeng Zhang, Hongkai Xiong, Wengang Zhou, Weiyao Lin, and Qi Tian. Picking deep filter responses for fine-grained image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1134\u20131142, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Xiaopeng%20Xiong%2C%20Hongkai%20Zhou%2C%20Wengang%20Lin%2C%20Weiyao%20Picking%20deep%20filter%20responses%20for%20fine-grained%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Xiaopeng%20Xiong%2C%20Hongkai%20Zhou%2C%20Wengang%20Lin%2C%20Weiyao%20Picking%20deep%20filter%20responses%20for%20fine-grained%20image%20recognition%202016"
        },
        {
            "id": "48",
            "entry": "[48] Yu Zhang, Xiu-Shen Wei, Jianxin Wu, Jianfei Cai, Jiangbo Lu, Viet-Anh Nguyen, and Minh N Do. Weakly supervised fine-grained categorization with part-based image representation. IEEE Transactions on Image Processing, 25(4):1713\u20131725, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Yu%20Wei%2C%20Xiu-Shen%20Wu%2C%20Jianxin%20Cai%2C%20Jianfei%20Weakly%20supervised%20fine-grained%20categorization%20with%20part-based%20image%20representation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Yu%20Wei%2C%20Xiu-Shen%20Wu%2C%20Jianxin%20Cai%2C%20Jianfei%20Weakly%20supervised%20fine-grained%20categorization%20with%20part-based%20image%20representation%202016"
        },
        {
            "id": "49",
            "entry": "[49] Jun Zhu and Eric P Xing. Maximum entropy discrimination markov networks. Journal of Machine Learning Research, 10(Nov):2531\u20132569, 2009. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=and%2C%20Jun%20Zhu%20Eric%20P%20Xing.%20Maximum%20entropy%20discrimination%20markov%20networks%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=and%2C%20Jun%20Zhu%20Eric%20P%20Xing.%20Maximum%20entropy%20discrimination%20markov%20networks%202009"
        }
    ]
}
