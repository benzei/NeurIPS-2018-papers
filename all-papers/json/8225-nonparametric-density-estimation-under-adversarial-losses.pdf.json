{
    "filename": "8225-nonparametric-density-estimation-under-adversarial-losses.pdf",
    "metadata": {
        "title": "Nonparametric Density Estimation under Adversarial Losses",
        "author": "Shashank Singh, Ananya Uppal, Boyue Li, Chun-Liang Li, Manzil Zaheer, Barnabas Poczos",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8225-nonparametric-density-estimation-under-adversarial-losses.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We study minimax convergence rates of nonparametric density estimation under a large class of loss functions called \u201cadversarial losses\u201d, which, besides classical Lp losses, includes maximum mean discrepancy (MMD), Wasserstein distance, and total variation distance. These losses are closely related to the losses encoded by discriminator networks in generative adversarial networks (GANs). In a general framework, we study how the choice of loss and the assumed smoothness of the underlying density together determine the minimax rate. We also discuss implications for training GANs based on deep ReLU networks, and more general connections to learning implicit generative models in a minimax statistical sense."
    },
    "keywords": [
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "density estimation",
            "url": "https://en.wikipedia.org/wiki/density_estimation"
        },
        {
            "term": "wasserstein distance",
            "url": "https://en.wikipedia.org/wiki/wasserstein_distance"
        },
        {
            "term": "rectified linear unit",
            "url": "https://en.wikipedia.org/wiki/rectified_linear_unit"
        },
        {
            "term": "reproducing kernel Hilbert space",
            "url": "https://en.wikipedia.org/wiki/reproducing_kernel_Hilbert_space"
        }
    ],
    "highlights": [
        "That is, modeling the distribution from which data are drawn, is a central task in machine learning and statistics",
        "Generative modeling in these settings is usually studied from the perspective of nonparametric density estimation, in which histogram, kernel, orthogonal series, and nearestneighbor methods are popular approaches with well-understood statistical properties [<a class=\"ref-link\" id=\"c49\" href=\"#r49\">49</a>, <a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>]",
        "We present our main upper bound on the minimax rate of density estimation under adversarial losses",
        "This paper provided new minimax bounds for density estimation under adversarial losses, both with and without adaptivity to smoothness, and gave several applications, including both traditional statistical settings and perfectly optimized Generative Adversarial Neural Networks",
        "We gave simple conditions under which minimax bounds for density estimation imply bounds for the problem of implicit generative modeling, suggesting that sampling is typically not statistically easier than density estimation",
        "For example, the strong curse of dimensionality that is known to afflict to nonparametric density estimation Wasserman [<a class=\"ref-link\" id=\"c49\" href=\"#r49\">49</a>] should limit the performance of implicit generative models such as Generative Adversarial Neural Networks"
    ],
    "key_statements": [
        "That is, modeling the distribution from which data are drawn, is a central task in machine learning and statistics",
        "Generative modeling in these settings is usually studied from the perspective of nonparametric density estimation, in which histogram, kernel, orthogonal series, and nearestneighbor methods are popular approaches with well-understood statistical properties [<a class=\"ref-link\" id=\"c49\" href=\"#r49\">49</a>, <a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>]",
        "We present our main upper bound on the minimax rate of density estimation under adversarial losses",
        "Given the recent popularity of implicit generative models in many applications, it is important to theoretically understand why these models appear to outperform classical methods for similar problems",
        "This paper provided new minimax bounds for density estimation under adversarial losses, both with and without adaptivity to smoothness, and gave several applications, including both traditional statistical settings and perfectly optimized Generative Adversarial Neural Networks",
        "We gave simple conditions under which minimax bounds for density estimation imply bounds for the problem of implicit generative modeling, suggesting that sampling is typically not statistically easier than density estimation",
        "For example, the strong curse of dimensionality that is known to afflict to nonparametric density estimation Wasserman [<a class=\"ref-link\" id=\"c49\" href=\"#r49\">49</a>] should limit the performance of implicit generative models such as Generative Adversarial Neural Networks"
    ],
    "summary": [
        "That is, modeling the distribution from which data are drawn, is a central task in machine learning and statistics.",
        "They are implicit, rather than explicit generative models [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>]; that is, rather than an estimate of the probability of a set or the density at a point, they return novel samples from the data distribution.",
        "Under traditional statistical smoothness assumptions, we identify minimax convergence rates for density estimation under several losses of the form (1).",
        "The main contribution of this paper is a statistical analysis of the problem of estimating a distribution P from n IID observations using the loss dFD , in a minimax sense over P \u2208 FG, for fairly general nonparametric smoothness classes FD and FG.",
        "We present our main upper bound on the minimax rate of density estimation under adversarial losses.",
        "We lower bound the minimax risk M (FD, FG) of distribution estimation under dFD loss over FG, for the case when FD = Hp,a and FG := Hq,b are generalized ellipses.",
        "We leverage the fact that the rate-optimal choice \u03b6 = n 2t+d above does not rely on the loss parameters s, together with Theorem 1 to construct an adaptively minimax estimator, i.e., one that is minimax and fully-data dependent.",
        "We draw formal connections between our work on density estimation and the problem of implicit generative modeling under an appropriate measure of risk.",
        "We fix a class FG of probability measures on a sample space X and a loss function : FG \u00d7 FG \u2192 [0, \u221e] measuring the distance of an estimate P from the true distribution P .",
        "The following theorem identifies sufficient conditions under which, in the statistical minimax framework described above, density estimation is no harder than sampling.",
        "This paper provided new minimax bounds for density estimation under adversarial losses, both with and without adaptivity to smoothness, and gave several applications, including both traditional statistical settings and perfectly optimized GANs. We gave simple conditions under which minimax bounds for density estimation imply bounds for the problem of implicit generative modeling, suggesting that sampling is typically not statistically easier than density estimation.",
        "For example, the strong curse of dimensionality that is known to afflict to nonparametric density estimation Wasserman [<a class=\"ref-link\" id=\"c49\" href=\"#r49\">49</a>] should limit the performance of implicit generative models such as GANs. The Appendix describes several specific avenues for further investigation, including whether the curse of dimensionality can be avoided when data lie on a low-dimensional manifold.",
        "The Appendix describes several specific avenues for further investigation, including whether the curse of dimensionality can be avoided when data lie on a low-dimensional manifold"
    ],
    "headline": "We study minimax convergence rates of nonparametric density estimation under a large class of loss functions called \u201cadversarial losses\u201d, which, besides classical Lp losses, includes maximum mean discrepancy , Wasserstein distance, and total variation distance",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Ehsan Abbasnejad, Javen Shi, and Anton van den Hengel. Deep lipschitz networks and dudley GANs, 2018. URL https://openreview.net/forum?id=rkw-jlb0W.",
            "url": "https://openreview.net/forum?id=rkw-jlb0W"
        },
        {
            "id": "2",
            "entry": "[2] Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. cambridge university press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anthony%2C%20Martin%20Bartlett%2C%20Peter%20L.%20Neural%20network%20learning%3A%20Theoretical%20foundations%202009"
        },
        {
            "id": "3",
            "entry": "[3] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In International Conference on Machine Learning, pages 214\u2013223, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martin%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martin%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "4",
            "entry": "[4] Nachman Aronszajn. Theory of reproducing kernels. Transactions of the American mathematical society, 68(3):337\u2013404, 1950.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aronszajn%2C%20Nachman%20Theory%20of%20reproducing%20kernels.%20Transactions%20of%20the%20American%20mathematical%201950",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aronszajn%2C%20Nachman%20Theory%20of%20reproducing%20kernels.%20Transactions%20of%20the%20American%20mathematical%201950"
        },
        {
            "id": "5",
            "entry": "[5] Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium in generative adversarial nets (GANs). In International Conference on Machine Learning, pages 224\u2013232, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20Sanjeev%20Ge%2C%20Rong%20Liang%2C%20Yingyu%20Ma%2C%20Tengyu%20Generalization%20and%20equilibrium%20in%20generative%20adversarial%20nets%20%28GANs%29%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20Sanjeev%20Ge%2C%20Rong%20Liang%2C%20Yingyu%20Ma%2C%20Tengyu%20Generalization%20and%20equilibrium%20in%20generative%20adversarial%20nets%20%28GANs%29%202017"
        },
        {
            "id": "6",
            "entry": "[6] Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability and statistics. Springer Science & Business Media, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berlinet%2C%20Alain%20Thomas-Agnan%2C%20Christine%20Reproducing%20kernel%20Hilbert%20spaces%20in%20probability%20and%20statistics%202011"
        },
        {
            "id": "7",
            "entry": "[7] G\u00e9rard Biau and Luc Devroye. Lectures on the nearest neighbor method. Springer, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Biau%2C%20G%C3%A9rard%20Devroye%2C%20Luc%20Lectures%20on%20the%20nearest%20neighbor%20method%202015"
        },
        {
            "id": "8",
            "entry": "[8] Leon Bottou, Martin Arjovsky, David Lopez-Paz, and Maxime Oquab. Geometrical insights for implicit generative modeling. arXiv preprint arXiv:1712.07822, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.07822"
        },
        {
            "id": "9",
            "entry": "[9] Lawrence D Brown, Cun-Hui Zhang, et al. Asymptotic nonequivalence of nonparametric experiments when the smoothness index is 1/2. The Annals of Statistics, 26(1):279\u2013287, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brown%2C%20Lawrence%20D.%20Zhang%2C%20Cun-Hui%20Asymptotic%20nonequivalence%20of%20nonparametric%20experiments%20when%20the%20smoothness%20index%20is%201/2%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brown%2C%20Lawrence%20D.%20Zhang%2C%20Cun-Hui%20Asymptotic%20nonequivalence%20of%20nonparametric%20experiments%20when%20the%20smoothness%20index%20is%201/2%201998"
        },
        {
            "id": "10",
            "entry": "[10] Guillermo Canas and Lorenzo Rosasco. Learning probability measures with respect to optimal transport metrics. In Advances in Neural Information Processing Systems, pages 2492\u20132500, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Canas%2C%20Guillermo%20Rosasco%2C%20Lorenzo%20Learning%20probability%20measures%20with%20respect%20to%20optimal%20transport%20metrics%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Canas%2C%20Guillermo%20Rosasco%2C%20Lorenzo%20Learning%20probability%20measures%20with%20respect%20to%20optimal%20transport%20metrics%202012"
        },
        {
            "id": "11",
            "entry": "[11] Siddhartha Chib and Edward Greenberg. Understanding the Metropolis-Hastings algorithm. The american statistician, 49(4):327\u2013335, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chib%2C%20Siddhartha%20Greenberg%2C%20Edward%20Understanding%20the%20Metropolis-Hastings%20algorithm%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chib%2C%20Siddhartha%20Greenberg%2C%20Edward%20Understanding%20the%20Metropolis-Hastings%20algorithm%201995"
        },
        {
            "id": "12",
            "entry": "[12] Peter J Diggle and Richard J Gratton. Monte Carlo methods of inference for implicit statistical models. Journal of the Royal Statistical Society. Series B (Methodological), pages 193\u2013227, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diggle%2C%20Peter%20J.%20Gratton%2C%20Richard%20J.%20Monte%20Carlo%20methods%20of%20inference%20for%20implicit%20statistical%20models%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diggle%2C%20Peter%20J.%20Gratton%2C%20Richard%20J.%20Monte%20Carlo%20methods%20of%20inference%20for%20implicit%20statistical%20models%201984"
        },
        {
            "id": "13",
            "entry": "[13] RM Dudley. Speeds of metric probability convergence. Zeitschrift f\u00fcr Wahrscheinlichkeitstheorie und Verwandte Gebiete, 22(4):323\u2013332, 1972.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dudley%2C%20R.M.%20Speeds%20of%20metric%20probability%20convergence%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dudley%2C%20R.M.%20Speeds%20of%20metric%20probability%20convergence%201972"
        },
        {
            "id": "14",
            "entry": "[14] Sam Efromovich. Orthogonal series density estimation. Wiley Interdisciplinary Reviews: Computational Statistics, 2(4):467\u2013476, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Efromovich%2C%20Sam%20Orthogonal%20series%20density%20estimation%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Efromovich%2C%20Sam%20Orthogonal%20series%20density%20estimation%202010"
        },
        {
            "id": "15",
            "entry": "[15] Dominik Maria Endres and Johannes E Schindelin. A new metric for probability distributions. IEEE Transactions on Information theory, 49(7):1858\u20131860, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Endres%2C%20Dominik%20Maria%20Schindelin%2C%20Johannes%20E.%20A%20new%20metric%20for%20probability%20distributions%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Endres%2C%20Dominik%20Maria%20Schindelin%2C%20Johannes%20E.%20A%20new%20metric%20for%20probability%20distributions%202003"
        },
        {
            "id": "16",
            "entry": "[16] Alexander Goldenshluger and Oleg Lepski. On adaptive minimax density estimation on Rd. Probability Theory and Related Fields, 159(3-4):479\u2013543, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldenshluger%2C%20Alexander%20Lepski%2C%20Oleg%20On%20adaptive%20minimax%20density%20estimation%20on%20Rd%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldenshluger%2C%20Alexander%20Lepski%2C%20Oleg%20On%20adaptive%20minimax%20density%20estimation%20on%20Rd%202014"
        },
        {
            "id": "17",
            "entry": "[17] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "18",
            "entry": "[18] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Sch\u00f6lkopf, and Alexander Smola. A kernel two-sample test. Journal of Machine Learning Research, 13(Mar):723\u2013773, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Rasch%2C%20Malte%20J.%20Sch%C3%B6lkopf%2C%20Bernhard%20A%20kernel%20two-sample%20test%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Rasch%2C%20Malte%20J.%20Sch%C3%B6lkopf%2C%20Bernhard%20A%20kernel%20two-sample%20test%202012"
        },
        {
            "id": "19",
            "entry": "[19] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of Wasserstein GANs. In Advances in Neural Information Processing Systems, pages 5769\u20135779, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20Wasserstein%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20Wasserstein%20GANs%202017"
        },
        {
            "id": "20",
            "entry": "[20] Leonid Vasilevich Kantorovich and Gennady S Rubinstein. On a space of completely additive functions. Vestnik Leningrad. Univ, 13(7):52\u201359, 1958.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kantorovich%2C%20Leonid%20Vasilevich%20Rubinstein%2C%20Gennady%20S.%20On%20a%20space%20of%20completely%20additive%20functions%201958",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kantorovich%2C%20Leonid%20Vasilevich%20Rubinstein%2C%20Gennady%20S.%20On%20a%20space%20of%20completely%20additive%20functions%201958"
        },
        {
            "id": "21",
            "entry": "[21] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "22",
            "entry": "[22] Andrey Kolmogorov. Sulla determinazione empirica di una lgge di distribuzione. Inst. Ital. Attuari, Giorn., 4:83\u201391, 1933.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kolmogorov%2C%20Andrey%20Sulla%20determinazione%20empirica%20di%20una%20lgge%20di%20distribuzione%201933",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kolmogorov%2C%20Andrey%20Sulla%20determinazione%20empirica%20di%20una%20lgge%20di%20distribuzione%201933"
        },
        {
            "id": "23",
            "entry": "[23] Jing Lei. Convergence and concentration of empirical measures under wasserstein distance in unbounded functional spaces. arXiv preprint arXiv:1804.10556, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.10556"
        },
        {
            "id": "24",
            "entry": "[24] Giovanni Leoni. A first course in Sobolev spaces. American Mathematical Soc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Leoni%2C%20Giovanni%20A%20first%20course%20in%20Sobolev%20spaces%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Leoni%2C%20Giovanni%20A%20first%20course%20in%20Sobolev%20spaces%202017"
        },
        {
            "id": "25",
            "entry": "[25] Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang, and Barnab\u00e1s P\u00f3czos. MMD GAN: Towards deeper understanding of moment matching network. In Advances in Neural Information Processing Systems, pages 2200\u20132210, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Chun-Liang%20Chang%2C%20Wei-Cheng%20Cheng%2C%20Yu%20Yang%2C%20Yiming%20MMD%20GAN%3A%20Towards%20deeper%20understanding%20of%20moment%20matching%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Chun-Liang%20Chang%2C%20Wei-Cheng%20Cheng%2C%20Yu%20Yang%2C%20Yiming%20MMD%20GAN%3A%20Towards%20deeper%20understanding%20of%20moment%20matching%20network%202017"
        },
        {
            "id": "26",
            "entry": "[26] Tengyuan Liang. How well can generative adversarial networks (GAN) learn densities: A nonparametric view. arXiv preprint arXiv:1712.08244, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.08244"
        },
        {
            "id": "27",
            "entry": "[27] Tengyuan Liang and James Stokes. Interaction matters: A note on non-asymptotic local convergence of generative adversarial networks. arXiv preprint arXiv:1802.06132, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.06132"
        },
        {
            "id": "28",
            "entry": "[28] Pascal Massart. Concentration inequalities and model selection, volume 6.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Massart%2C%20Pascal%20Concentration%20inequalities%20and%20model%20selection"
        },
        {
            "id": "29",
            "entry": "[29] Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv preprint arXiv:1610.03483, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.03483"
        },
        {
            "id": "30",
            "entry": "[30] Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, and Yu Cheng. Sobolev gan. arXiv preprint arXiv:1711.04894, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.04894"
        },
        {
            "id": "31",
            "entry": "[31] Alfred M\u00fcller. Integral probability metrics and their generating classes of functions. Advances in Applied Probability, 29(2):429\u2013443, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%C3%BCller%2C%20Alfred%20Integral%20probability%20metrics%20and%20their%20generating%20classes%20of%20functions%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%C3%BCller%2C%20Alfred%20Integral%20probability%20metrics%20and%20their%20generating%20classes%20of%20functions%201997"
        },
        {
            "id": "32",
            "entry": "[32] Vaishnavh Nagarajan and J Zico Kolter. Gradient descent GAN optimization is locally stable. In Advances in Neural Information Processing Systems, pages 5591\u20135600, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nagarajan%2C%20Vaishnavh%20Kolter%2C%20J.Zico%20Gradient%20descent%20GAN%20optimization%20is%20locally%20stable%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nagarajan%2C%20Vaishnavh%20Kolter%2C%20J.Zico%20Gradient%20descent%20GAN%20optimization%20is%20locally%20stable%202017"
        },
        {
            "id": "33",
            "entry": "[33] Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-GAN: Training generative neural samplers using variational divergence minimization. In Advances in Neural Information Processing Systems, pages 271\u2013279, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nowozin%2C%20Sebastian%20Cseke%2C%20Botond%20Tomioka%2C%20Ryota%20f-GAN%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nowozin%2C%20Sebastian%20Cseke%2C%20Botond%20Tomioka%2C%20Ryota%20f-GAN%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016"
        },
        {
            "id": "34",
            "entry": "[34] Mark Owen. Practical signal processing. Cambridge university press, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Owen%2C%20Mark%20Practical%20signal%20processing%202007"
        },
        {
            "id": "35",
            "entry": "[35] Aaditya Ramdas, Sashank Jakkam Reddi, Barnab\u00e1s P\u00f3czos, Aarti Singh, and Larry A Wasserman. On the decreasing power of kernel and distance based nonparametric hypothesis tests in high dimensions. In AAAI, pages 3571\u20133577, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramdas%2C%20Aaditya%20Reddi%2C%20Sashank%20Jakkam%20P%C3%B3czos%2C%20Barnab%C3%A1s%20Singh%2C%20Aarti%20and%20Larry%20A%20Wasserman.%20On%20the%20decreasing%20power%20of%20kernel%20and%20distance%20based%20nonparametric%20hypothesis%20tests%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ramdas%2C%20Aaditya%20Reddi%2C%20Sashank%20Jakkam%20P%C3%B3czos%2C%20Barnab%C3%A1s%20Singh%2C%20Aarti%20and%20Larry%20A%20Wasserman.%20On%20the%20decreasing%20power%20of%20kernel%20and%20distance%20based%20nonparametric%20hypothesis%20tests%202015"
        },
        {
            "id": "36",
            "entry": "[36] Aaditya Ramdas, Nicol\u00e1s Garc\u00eda Trillos, and Marco Cuturi. On wasserstein two-sample testing and related families of nonparametric tests. Entropy, 19(2):47, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aaditya%20Ramdas%2C%20Nicol%C3%A1s%20Garc%C3%ADa%20Trillos%20Cuturi%2C%20Marco%20On%20wasserstein%20two-sample%20testing%20and%20related%20families%20of%20nonparametric%20tests%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aaditya%20Ramdas%2C%20Nicol%C3%A1s%20Garc%C3%ADa%20Trillos%20Cuturi%2C%20Marco%20On%20wasserstein%20two-sample%20testing%20and%20related%20families%20of%20nonparametric%20tests%202017"
        },
        {
            "id": "37",
            "entry": "[37] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In ICML, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014"
        },
        {
            "id": "38",
            "entry": "[38] Christian P Robert. Monte Carlo methods. Wiley Online Library, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robert%2C%20Christian%20P.%20Monte%20Carlo%20methods%202004"
        },
        {
            "id": "39",
            "entry": "[39] Shashank Singh and Barnab\u00e1s P\u00f3czos. Minimax distribution estimation in Wasserstein distance. arXiv preprint arXiv:1802.08855, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.08855"
        },
        {
            "id": "40",
            "entry": "[40] Nickolay Smirnov. Table for estimating the goodness of fit of empirical distributions. The annals of mathematical statistics, 19(2):279\u2013281, 1948.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smirnov%2C%20Nickolay%20Table%20for%20estimating%20the%20goodness%20of%20fit%20of%20empirical%20distributions%201948",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smirnov%2C%20Nickolay%20Table%20for%20estimating%20the%20goodness%20of%20fit%20of%20empirical%20distributions%201948"
        },
        {
            "id": "41",
            "entry": "[41] Bharath Sriperumbudur et al. On the optimal estimation of probability measures in weak and strong topologies. Bernoulli, 22(3):1839\u20131893, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sriperumbudur%2C%20Bharath%20On%20the%20optimal%20estimation%20of%20probability%20measures%20in%20weak%20and%20strong%20topologies%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sriperumbudur%2C%20Bharath%20On%20the%20optimal%20estimation%20of%20probability%20measures%20in%20weak%20and%20strong%20topologies%202016"
        },
        {
            "id": "42",
            "entry": "[42] Bharath K Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Sch\u00f6lkopf, and Gert RG Lanckriet. Non-parametric estimation of integral probability metrics. In Information Theory Proceedings (ISIT), 2010 IEEE International Symposium on, pages 1428\u20131432. IEEE, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sriperumbudur%2C%20Bharath%20K.%20Fukumizu%2C%20Kenji%20Gretton%2C%20Arthur%20Sch%C3%B6lkopf%2C%20Bernhard%20Non-parametric%20estimation%20of%20integral%20probability%20metrics%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sriperumbudur%2C%20Bharath%20K.%20Fukumizu%2C%20Kenji%20Gretton%2C%20Arthur%20Sch%C3%B6lkopf%2C%20Bernhard%20Non-parametric%20estimation%20of%20integral%20probability%20metrics%202010"
        },
        {
            "id": "43",
            "entry": "[43] Bharath K Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Sch\u00f6lkopf, Gert RG Lanckriet, et al. On the empirical estimation of integral probability metrics. Electronic Journal of Statistics, 6:1550\u20131599, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sriperumbudur%2C%20Bharath%20K.%20Fukumizu%2C%20Kenji%20Gretton%2C%20Arthur%20Sch%C3%B6lkopf%2C%20Bernhard%20On%20the%20empirical%20estimation%20of%20integral%20probability%20metrics%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sriperumbudur%2C%20Bharath%20K.%20Fukumizu%2C%20Kenji%20Gretton%2C%20Arthur%20Sch%C3%B6lkopf%2C%20Bernhard%20On%20the%20empirical%20estimation%20of%20integral%20probability%20metrics%202012"
        },
        {
            "id": "44",
            "entry": "[44] D. Sutherland, H-Y Tung, H. Strathmann, S. De, A. Ramdas, A. Smola, and A. Gretton. Generative models and model criticism via optimized maximum mean discrepancy. In ICLR, 2017. URL https://arxiv.org/abs/1611.04488.",
            "url": "https://arxiv.org/abs/1611.04488",
            "arxiv_url": "https://arxiv.org/pdf/1611.04488"
        },
        {
            "id": "45",
            "entry": "[45] G\u00e1bor J Sz\u00e9kely, Maria L Rizzo, Nail K Bakirov, et al. Measuring and testing dependence by correlation of distances. The annals of statistics, 35(6):2769\u20132794, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sz%C3%A9kely%2C%20G%C3%A1bor%20J.%20Rizzo%2C%20Maria%20L.%20Bakirov%2C%20Nail%20K.%20Measuring%20and%20testing%20dependence%20by%20correlation%20of%20distances%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sz%C3%A9kely%2C%20G%C3%A1bor%20J.%20Rizzo%2C%20Maria%20L.%20Bakirov%2C%20Nail%20K.%20Measuring%20and%20testing%20dependence%20by%20correlation%20of%20distances%202007"
        },
        {
            "id": "46",
            "entry": "[46] Ilya Tolstikhin, Bharath K Sriperumbudur, and Krikamol Muandet. Minimax estimation of kernel mean embeddings. The Journal of Machine Learning Research, 18(1):3002\u20133048, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tolstikhin%2C%20Ilya%20Sriperumbudur%2C%20Bharath%20K.%20Muandet%2C%20Krikamol%20Minimax%20estimation%20of%20kernel%20mean%20embeddings%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tolstikhin%2C%20Ilya%20Sriperumbudur%2C%20Bharath%20K.%20Muandet%2C%20Krikamol%20Minimax%20estimation%20of%20kernel%20mean%20embeddings%202017"
        },
        {
            "id": "47",
            "entry": "[47] Alexandre B Tsybakov. Introduction to nonparametric estimation. Springer Series in Statistics. Springer, New York, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsybakov%2C%20Alexandre%20B.%20Introduction%20to%20nonparametric%20estimation.%20Springer%20Series%20in%20Statistics%202009"
        },
        {
            "id": "48",
            "entry": "[48] C\u00e9dric Villani. Optimal transport: old and new, volume 338. Springer Science & Business Media, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Villani%2C%20C%C3%A9dric%20Optimal%20transport%3A%20old%20and%20new%2C%20volume%20338%202008"
        },
        {
            "id": "49",
            "entry": "[49] Larry Wasserman. All of Nonparametric Statistics. Springer Science & Business Media, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wasserman%2C%20Larry%20All%20of%20Nonparametric%20Statistics%202006"
        },
        {
            "id": "50",
            "entry": "[50] Jonathan Weed and Francis Bach. Sharp asymptotic and finite-sample rates of convergence of empirical measures in Wasserstein distance. arXiv preprint arXiv:1707.00087, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.00087"
        },
        {
            "id": "51",
            "entry": "[51] Holger Wendland. Scattered data approximation, volume 17. Cambridge university press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wendland%2C%20Holger%20Scattered%20data%20approximation%2C%20volume%2017%202004"
        },
        {
            "id": "52",
            "entry": "[52] Dmitry Yarotsky. Error bounds for approximations with deep ReLU networks. Neural Networks, 94: 103\u2013114, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yarotsky%2C%20Dmitry%20Error%20bounds%20for%20approximations%20with%20deep%20ReLU%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yarotsky%2C%20Dmitry%20Error%20bounds%20for%20approximations%20with%20deep%20ReLU%20networks%202017"
        }
    ]
}
