{
    "filename": "7738-on-the-local-minima-of-the-empirical-risk.pdf",
    "metadata": {
        "title": "On the Local Minima of the Empirical Risk",
        "author": "Chi Jin, Lydia T. Liu, Rong Ge, Michael I. Jordan",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7738-on-the-local-minima-of-the-empirical-risk.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Population risk is always of primary interest in machine learning; however, learning algorithms only have access to the empirical risk. Even for applications with nonconvex nonsmooth losses (such as modern deep networks), the population risk is generally significantly more well-behaved from an optimization point of view than the empirical risk. In particular, sampling can create many spurious local minima. We consider a general framework which aims to optimize a smooth nonconvex function F (population risk) given only access to an approximation f (empirical risk) that is pointwise close to F (i.e., F \u2212 f \u221e \u2264 \u03bd). Our objective is to find the -approximate local minima of the underlying function F while avoiding the shallow local minima\u2014arising because of the tolerance \u03bd\u2014which exist only in f . We propose a simple algorithm based on stochastic gradient descent (SGD) on a smoothed version of f that is guaranteed to achieve our goal as long as \u03bd \u2264 O( 1.5/d). We also provide an almost matching lower bound showing that our algorithm achieves optimal error tolerance \u03bd among all algorithms making a polynomial number of queries of f . As a concrete example, we show that our results can be directly used to give sample complexities for learning a ReLU unit."
    },
    "keywords": [
        {
            "term": "local minimum",
            "url": "https://en.wikipedia.org/wiki/local_minimum"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "rectified linear unit",
            "url": "https://en.wikipedia.org/wiki/rectified_linear_unit"
        },
        {
            "term": "online convex optimization",
            "url": "https://en.wikipedia.org/wiki/online_convex_optimization"
        },
        {
            "term": "local minima",
            "url": "https://en.wikipedia.org/wiki/local_minima"
        },
        {
            "term": "saddle point",
            "url": "https://en.wikipedia.org/wiki/saddle_point"
        },
        {
            "term": "Stochastic Gradient Langevin Dynamics",
            "url": "https://en.wikipedia.org/wiki/Stochastic_Gradient_Langevin_Dynamics"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        }
    ],
    "highlights": [
        "The optimization of nonconvex loss functions has been key to the success of modern machine learning",
        "While classical research in optimization focused on convex functions having a unique critical point that is both locally and globally minimal, a nonconvex function can have many local maxima, local minima and saddle points, all of which pose significant challenges for optimization",
        "We propose a simple algorithm based on SGD (Algorithm 1) that is guaranteed to find an approximate local minimum of F efficiently if \u03bd \u2264 O( 1.5/d), escaping all saddle points of F and all additional local minima introduced by f",
        "As a concrete example of the application to minimizing population risk, we show that our results can be directly used to give sample complexities for learning a rectified linear unit unit, whose empirical risk is nonsmooth while the population risk is smooth almost everywhere.\n1.1",
        "For nonconvex target functions F , Zhang et al [2017] studied the problem of finding approximate local minima of F , and proposed an algorithm based on Stochastic Gradient Langevin Dynamics (SGLD) [Welling and Teh, 2011], with maximum tolerance for function error \u03bd scaling as O( 2/d8)2",
        "There are three main difficulties in applying stochastic gradient descent to Problem 1: (1) in order to converge to a second-order stationary point of F , the algorithm must avoid being stuck in saddle points; (2) the algorithm does not have access to the gradient of f ; (3) there is a gap between the observed f and the target F , which might introduce non-smoothness or additional local minima"
    ],
    "key_statements": [
        "The optimization of nonconvex loss functions has been key to the success of modern machine learning",
        "While classical research in optimization focused on convex functions having a unique critical point that is both locally and globally minimal, a nonconvex function can have many local maxima, local minima and saddle points, all of which pose significant challenges for optimization",
        "We propose a simple algorithm based on SGD (Algorithm 1) that is guaranteed to find an approximate local minimum of F efficiently if \u03bd \u2264 O( 1.5/d), escaping all saddle points of F and all additional local minima introduced by f",
        "As a concrete example of the application to minimizing population risk, we show that our results can be directly used to give sample complexities for learning a rectified linear unit unit, whose empirical risk is nonsmooth while the population risk is smooth almost everywhere.\n1.1",
        "For nonconvex target functions F , Zhang et al [2017] studied the problem of finding approximate local minima of F , and proposed an algorithm based on Stochastic Gradient Langevin Dynamics (SGLD) [Welling and Teh, 2011], with maximum tolerance for function error \u03bd scaling as O( 2/d8)2",
        "There are three main difficulties in applying stochastic gradient descent to Problem 1: (1) in order to converge to a second-order stationary point of F , the algorithm must avoid being stuck in saddle points; (2) the algorithm does not have access to the gradient of f ; (3) there is a gap between the observed f and the target F , which might introduce non-smoothness or additional local minima"
    ],
    "summary": [
        "The optimization of nonconvex loss functions has been key to the success of modern machine learning.",
        "As in the sampling setting, we hope to show that simple algorithms such as stochastic gradient descent are able to escape the local minima that arise as a function of \u03bd.",
        "For nonconvex target functions F , Zhang et al [2017] studied the problem of finding approximate local minima of F , and proposed an algorithm based on Stochastic Gradient Langevin Dynamics (SGLD) [Welling and Teh, 2011], with maximum tolerance for function error \u03bd scaling as O( 2/d8)2.",
        "There are three main difficulties in applying stochastic gradient descent to Problem 1: (1) in order to converge to a second-order stationary point of F , the algorithm must avoid being stuck in saddle points; (2) the algorithm does not have access to the gradient of f ; (3) there is a gap between the observed f and the target F , which might introduce non-smoothness or additional local minima.",
        "Given that the function pair (F, f ) satisfies Assumption A1 with \u03bd \u2264 O( 3/\u03c1 \u00b7 (1/d)), for any \u03b4 > 0, with smoothing parameter \u03c3 = \u0398( /), learning rate \u03b7 = 1/ , perturbation r = \u0398 ( ), and mini-batch size m = poly(d, B, , \u03c1, 1/ , log(1/\u03b4)), ZPSGD will find an -second-order stationary point of F with probability 1 \u2212 \u03b4, in poly(d, B, , \u03c1, 1/ , log(1/\u03b4)) number of queries.",
        "If we allow an unlimited number of queries, we can show that the upper and lower bounds on the function error tolerance \u03bd no longer depends on the problem dimension d.",
        "There exists an algorithm so that if the function pair (F, f ) satisfies Assumption A1 with \u03bd \u2264 O( 3/\u03c1) and > \u221a\u03c1 , the algorithm will find an -second-order stationary point of F with an exponential number of queries.",
        "We may extend our algorithmic ideas to solve the problem of optimizing an unknown smooth function F when given only a gradient vector field g : Rd \u2192 Rd that is pointwise close to the gradient \u2207F .",
        "These assumptions suffice to guarantee that perturbed SGD (PSGD), a simple adaptation of PGD in <a class=\"ref-link\" id=\"cJin_et+al_2017_a\" href=\"#rJin_et+al_2017_a\">Jin et al [2017a</a>] with stochastic gradient and large mini-batch size, converges to the second-order stationary point of the objective function."
    ],
    "headline": "We propose a simple algorithm based on stochastic gradient descent  on a smoothed version of f that is guaranteed to achieve our goal as long as \u03bd \u2264 O",
    "reference_links": [
        {
            "id": "Agarwal_et+al_2010_a",
            "entry": "Alekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimization with multi-point bandit feedback. In Proceedings of the 23rd Annual Conference on Learning Theory (COLT), 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Alekh%20Dekel%2C%20Ofer%20Xiao%2C%20Lin%20Optimal%20algorithms%20for%20online%20convex%20optimization%20with%20multi-point%20bandit%20feedback%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Alekh%20Dekel%2C%20Ofer%20Xiao%2C%20Lin%20Optimal%20algorithms%20for%20online%20convex%20optimization%20with%20multi-point%20bandit%20feedback%202010"
        },
        {
            "id": "Agarwal_et+al_2017_a",
            "entry": "Naman Agarwal, Zeyuan Allen Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma. Finding approximate local minima faster than gradient descent. In Proceedings of the 49th Annual ACM Symposium on Theory of Computing, pages 1195\u20131199. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Naman%20Zhu%2C%20Zeyuan%20Allen%20Bullins%2C%20Brian%20Hazan%2C%20Elad%20Finding%20approximate%20local%20minima%20faster%20than%20gradient%20descent%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Naman%20Zhu%2C%20Zeyuan%20Allen%20Bullins%2C%20Brian%20Hazan%2C%20Elad%20Finding%20approximate%20local%20minima%20faster%20than%20gradient%20descent%202017"
        },
        {
            "id": "Anandkumar_2016_a",
            "entry": "Animashree Anandkumar and Rong Ge. Efficient approaches for escaping higher order saddle points in nonconvex optimization. In Proceedings of the 29th Annual Conference on Learning Theory (COLT), volume 49, pages 81\u2013102, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anandkumar%2C%20Animashree%20Ge%2C%20Rong%20Efficient%20approaches%20for%20escaping%20higher%20order%20saddle%20points%20in%20nonconvex%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anandkumar%2C%20Animashree%20Ge%2C%20Rong%20Efficient%20approaches%20for%20escaping%20higher%20order%20saddle%20points%20in%20nonconvex%20optimization%202016"
        },
        {
            "id": "Auer_et+al_1996_a",
            "entry": "Peter Auer, Mark Herbster, and Manfred K Warmuth. Exponentially many local minima for single neurons. In Advances in Neural Information Processing Systems (NIPS), pages 316\u2013322. 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Auer%2C%20Peter%20Herbster%2C%20Mark%20Warmuth%2C%20Manfred%20K.%20Exponentially%20many%20local%20minima%20for%20single%20neurons%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Auer%2C%20Peter%20Herbster%2C%20Mark%20Warmuth%2C%20Manfred%20K.%20Exponentially%20many%20local%20minima%20for%20single%20neurons%201996"
        },
        {
            "id": "Bartlett_2003_a",
            "entry": "Peter L. Bartlett and Shahar Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural results. J. Mach. Learn. Res., 3, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20Peter%20L.%20Mendelson%2C%20Shahar%20Rademacher%20and%20Gaussian%20complexities%3A%20Risk%20bounds%20and%20structural%20results%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20Peter%20L.%20Mendelson%2C%20Shahar%20Rademacher%20and%20Gaussian%20complexities%3A%20Risk%20bounds%20and%20structural%20results%202003"
        },
        {
            "id": "Belloni_et+al_2015_a",
            "entry": "Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, and Alexander Rakhlin. Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions. In Proceedings of the 28th Conference on Learning Theory (COLT), pages 240\u2013265, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belloni%2C%20Alexandre%20Liang%2C%20Tengyuan%20Narayanan%2C%20Hariharan%20Rakhlin%2C%20Alexander%20Escaping%20the%20Local%20Minima%20via%20Simulated%20Annealing%3A%20Optimization%20of%20Approximately%20Convex%20Functions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belloni%2C%20Alexandre%20Liang%2C%20Tengyuan%20Narayanan%2C%20Hariharan%20Rakhlin%2C%20Alexander%20Escaping%20the%20Local%20Minima%20via%20Simulated%20Annealing%3A%20Optimization%20of%20Approximately%20Convex%20Functions%202015"
        },
        {
            "id": "Boucheron_et+al_2013_a",
            "entry": "St\u00e9phane Boucheron, G\u00e1bor Lugosi, and Pascal Massart. Concentration Inequalities: A Nonasymptotic Theory of Independence. Oxford University Press, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boucheron%2C%20St%C3%A9phane%20Lugosi%2C%20G%C3%A1bor%20Massart%2C%20Pascal%20Concentration%20Inequalities%3A%20A%20Nonasymptotic%20Theory%20of%20Independence%202013"
        },
        {
            "id": "Brutzkus_2017_a",
            "entry": "Alon Brutzkus and Amir Globerson. Globally optimal gradient descent for a convnet with gaussian inputs. In Proceedings of the International Conference on Machine Learning (ICML), volume 70, pages 605\u2013614. PMLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brutzkus%2C%20Alon%20Globerson%2C%20Amir%20Globally%20optimal%20gradient%20descent%20for%20a%20convnet%20with%20gaussian%20inputs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brutzkus%2C%20Alon%20Globerson%2C%20Amir%20Globally%20optimal%20gradient%20descent%20for%20a%20convnet%20with%20gaussian%20inputs%202017"
        },
        {
            "id": "Carmon_et+al_2016_a",
            "entry": "Yair Carmon, John C Duchi, Oliver Hinder, and Aaron Sidford. Accelerated methods for non-convex optimization. arXiv preprint arXiv:1611.00756, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.00756"
        },
        {
            "id": "Chaudhuri_et+al_2011_a",
            "entry": "Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. Differentially private empirical risk minimization. J. Mach. Learn. Res., 12:1069\u20131109, July 2011. ISSN 1532-4435.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaudhuri%2C%20Kamalika%20Monteleoni%2C%20Claire%20Sarwate%2C%20Anand%20D.%20Differentially%20private%20empirical%20risk%20minimization%202011-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaudhuri%2C%20Kamalika%20Monteleoni%2C%20Claire%20Sarwate%2C%20Anand%20D.%20Differentially%20private%20empirical%20risk%20minimization%202011-07"
        },
        {
            "id": "Dinh_et+al_2017_a",
            "entry": "Laurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio. Sharp minima can generalize for deep nets. arXiv preprint arXiv:1703.04933, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.04933"
        },
        {
            "id": "Duchi_et+al_2015_a",
            "entry": "John C. Duchi, Michael I. Jordan, Martin J. Wainwright, and Andre Wibisono. Optimal rates for zero-order convex optimization: The power of two function evaluations. IEEE Trans. Information Theory, 61(5): 2788\u20132806, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20C.%20Jordan%2C%20Michael%20I.%20Wainwright%2C%20Martin%20J.%20Wibisono%2C%20Andre%20Optimal%20rates%20for%20zero-order%20convex%20optimization%3A%20The%20power%20of%20two%20function%20evaluations%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20C.%20Jordan%2C%20Michael%20I.%20Wainwright%2C%20Martin%20J.%20Wibisono%2C%20Andre%20Optimal%20rates%20for%20zero-order%20convex%20optimization%3A%20The%20power%20of%20two%20function%20evaluations%202015"
        },
        {
            "id": "Flaxman_et+al_2005_a",
            "entry": "Abraham D. Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex optimization in the bandit setting: Gradient descent without a gradient. In Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 385\u2013394, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Flaxman%2C%20Abraham%20D.%20Kalai%2C%20Adam%20Tauman%20McMahan%2C%20H.Brendan%20Online%20convex%20optimization%20in%20the%20bandit%20setting%3A%20Gradient%20descent%20without%20a%20gradient%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Flaxman%2C%20Abraham%20D.%20Kalai%2C%20Adam%20Tauman%20McMahan%2C%20H.Brendan%20Online%20convex%20optimization%20in%20the%20bandit%20setting%3A%20Gradient%20descent%20without%20a%20gradient%202005"
        },
        {
            "id": "Ge_et+al_2015_a",
            "entry": "Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points\u2014online stochastic gradient for tensor decomposition. In Proceedings of the 28th Conference on Learning Theory (COLT), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points%E2%80%94online%20stochastic%20gradient%20for%20tensor%20decomposition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points%E2%80%94online%20stochastic%20gradient%20for%20tensor%20decomposition%202015"
        },
        {
            "id": "Jin_et+al_2017_a",
            "entry": "Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M. Kakade, and Michael I. Jordan. How to escape saddle points efficiently. In Proceedings of the International Conference on Machine Learning (ICML), pages 1724\u20131732, 2017a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jin%2C%20Chi%20Ge%2C%20Rong%20Netrapalli%2C%20Praneeth%20Kakade%2C%20Sham%20M.%20How%20to%20escape%20saddle%20points%20efficiently%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jin%2C%20Chi%20Ge%2C%20Rong%20Netrapalli%2C%20Praneeth%20Kakade%2C%20Sham%20M.%20How%20to%20escape%20saddle%20points%20efficiently%202017"
        },
        {
            "id": "Jin_et+al_0000_a",
            "entry": "Chi Jin, Praneeth Netrapalli, and Michael I. Jordan. Accelerated gradient descent escapes saddle points faster than gradient descent. CoRR, abs/1711.10456, 2017b.",
            "arxiv_url": "https://arxiv.org/pdf/1711.10456"
        },
        {
            "id": "Jin_et+al_2018_a",
            "entry": "Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M. Kakade, and Michael I. Jordan. SGD escapes saddle points efficiently. Personal Communication, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jin%2C%20Chi%20Ge%2C%20Rong%20Netrapalli%2C%20Praneeth%20Kakade%2C%20Sham%20M.%20SGD%20escapes%20saddle%20points%20efficiently%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jin%2C%20Chi%20Ge%2C%20Rong%20Netrapalli%2C%20Praneeth%20Kakade%2C%20Sham%20M.%20SGD%20escapes%20saddle%20points%20efficiently%202018"
        },
        {
            "id": "Keskar_et+al_2016_a",
            "entry": "Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.04836"
        },
        {
            "id": "Scott_1983_a",
            "entry": "Scott Kirkpatrick, C. D. Gelatt, and Mario Vecchi. Optimization by simulated annealing. Science, 220(4598): 671\u2013680, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scott%20Kirkpatrick%2C%20C.D.Gelatt%20Vecchi%2C%20Mario%20Optimization%20by%20simulated%20annealing%201983",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scott%20Kirkpatrick%2C%20C.D.Gelatt%20Vecchi%2C%20Mario%20Optimization%20by%20simulated%20annealing%201983"
        },
        {
            "id": "Kleinberg_et+al_2018_a",
            "entry": "Robert Kleinberg, Yuanzhi Li, and Yang Yuan. An alternative view: When does SGD escape local minima? CoRR, abs/1802.06175, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.06175"
        },
        {
            "id": "Loh_2013_a",
            "entry": "Po-Ling Loh and Martin J Wainwright. Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima. In Advances in Neural Information Processing Systems (NIPS), pages 476\u2013484, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loh%2C%20Po-Ling%20Wainwright%2C%20Martin%20J.%20Regularized%20M-estimators%20with%20nonconvexity%3A%20Statistical%20and%20algorithmic%20theory%20for%20local%20optima%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Loh%2C%20Po-Ling%20Wainwright%2C%20Martin%20J.%20Regularized%20M-estimators%20with%20nonconvexity%3A%20Statistical%20and%20algorithmic%20theory%20for%20local%20optima%202013"
        },
        {
            "id": "Mei_et+al_2016_a",
            "entry": "Song Mei, Yu Bai, and Andrea Montanari. The landscape of empirical risk for non-convex losses. arXiv preprint arXiv:1607.06534, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.06534"
        },
        {
            "id": "Nesterov_1983_a",
            "entry": "Yurii Nesterov. A method of solving a convex programming problem with convergence rate o(1/k2). Soviet Mathematics Doklady, 27:372\u2013376, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20A%20method%20of%20solving%20a%20convex%20programming%20problem%20with%20convergence%20rate%20o%281/k2%29%201983",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20A%20method%20of%20solving%20a%20convex%20programming%20problem%20with%20convergence%20rate%20o%281/k2%29%201983"
        },
        {
            "id": "Nesterov_2004_a",
            "entry": "Yurii Nesterov. Introductory Lectures on Convex Programming. Springer, 2004. Ingo Rechenberg and Manfred Eigen. Evolutionsstrategie: Optimierung Technischer Systeme nach Prinzipien der Biologischen Evolution. Frommann-Holzboog, Stuttgart, 1973. Andrej Risteski and Yuanzhi Li. Algorithms and matching lower bounds for approximately-convex optimization.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Introductory%20Lectures%20on%20Convex%20Programming%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Introductory%20Lectures%20on%20Convex%20Programming%202004"
        },
        {
            "id": "Sinha_2016_a",
            "entry": "In Advances in Neural Information Processing Systems (NIPS), pages 4745\u20134753. 2016. Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex optimization. In Proceedings of the 26th Annual Conference on Learning Theory (COLT), volume 30, 2013. Yaron Singer and Jan Vondrak. Information-theoretic lower bounds for convex optimization with erroneous oracles. In Advances in Neural Information Processing Systems (NIPS), pages 3204\u20133212. 2015. Aman Sinha, Hongseok Namkoong, and John Duchi. Certifiable distributional robustness with principled adversarial training. International Conference on Learning Representations, 2018. Jacob Steinhardt, Pang W. Koh, and Percy Liang. Certified defenses for data poisoning attacks. In Advances in",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sinha%2C%20Hongseok%20Namkoong%20Duchi%2C%20John%20Ohad%20Shamir.%20On%20the%20complexity%20of%20bandit%20and%20derivative-free%20stochastic%20convex%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sinha%2C%20Hongseok%20Namkoong%20Duchi%2C%20John%20Ohad%20Shamir.%20On%20the%20complexity%20of%20bandit%20and%20derivative-free%20stochastic%20convex%20optimization%202016"
        },
        {
            "id": "Neural_2017_a",
            "entry": "Neural Information Processing Systems (NIPS), 2017. Max Welling and Yee Whye Teh. Bayesian Learning via Stochastic Gradient Langevin Dynamics. In Proceedings of the International Conference on Machine Learning (ICML), pages 681\u2013688, 2011. Yuchen Zhang, Percy Liang, and Moses Charikar. A hitting time analysis of stochastic gradient Langevin dynamics. Proceedings of the 30th Conference on Learning Theory (COLT), pages 1980\u20132022, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Max%20Welling%20and%20Yee%20Whye%20Teh.%20Bayesian%20Learning%20via%20Stochastic%20Gradient%20Langevin%20Dynamics%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Max%20Welling%20and%20Yee%20Whye%20Teh.%20Bayesian%20Learning%20via%20Stochastic%20Gradient%20Langevin%20Dynamics%202017"
        }
    ]
}
