{
    "filename": "7351-learning-disentangled-joint-continuous-and-discrete-representations.pdf",
    "metadata": {
        "title": "Learning Disentangled Joint Continuous and Discrete Representations",
        "author": "Emilien Dupont",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7351-learning-disentangled-joint-continuous-and-discrete-representations.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "volume": "1",
        "abstract": "We present a framework for learning disentangled and interpretable jointly continuous and discrete representations in an unsupervised manner. By augmenting the continuous latent distribution of variational autoencoders with a relaxed discrete distribution and controlling the amount of information encoded in each latent unit, we show how continuous and categorical factors of variation can be discovered automatically from data. Experiments show that the framework disentangles continuous and discrete generative factors on various datasets and outperforms current disentangling methods when a discrete generative factor is prominent."
    },
    "keywords": [
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        }
    ],
    "highlights": [
        "Disentangled representations are defined as ones where a change in a single unit of the representation corresponds to a change in single factor of variation of the data while being invariant to others (<a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\"><a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\">Bengio et al (2013</a></a>))",
        "In this paper we propose a framework, based on Variational Autoencoders (VAE), that learns disentangled continuous and discrete representations in an unsupervised manner",
        "For a large range of hyperparameters we were not able to achieve disentanglement using the purely continuous \u03b2-Variational Autoencoders framework. This is likely because MNIST has an inherently discrete generative factor, which \u03b2-Variational Autoencoders is unable to map onto a continuous latent variable",
        "We have proposed JointVAE, a framework for learning disentangled continuous and discrete representations in an unsupervised manner",
        "The framework comes with the advantages of Variational Autoencoders such as stable training and large sample diversity while being able to model complex jointly continuous and discrete generative factors",
        "We have shown that JointVAE disentangles factors of variation on several datasets while producing realistic samples"
    ],
    "key_statements": [
        "Disentangled representations are defined as ones where a change in a single unit of the representation corresponds to a change in single factor of variation of the data while being invariant to others (<a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\"><a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\">Bengio et al (2013</a></a>))",
        "Disentangled representations are defined as ones where a change in a single unit of the representation corresponds to a change in single factor of variation of the data while being invariant to others (<a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\">Bengio et al (2013</a>))",
        "A disentangled representation of 3D objects could contain a set of units each corresponding to a distinct generative factor such as position, color or scale",
        "A large number of datasets contain inherently discrete generative factors which can be difficult to capture with these methods",
        "In this paper we propose a framework, based on Variational Autoencoders (VAE), that learns disentangled continuous and discrete representations in an unsupervised manner",
        "For a large range of hyperparameters we were not able to achieve disentanglement using the purely continuous \u03b2-Variational Autoencoders framework. This is likely because MNIST has an inherently discrete generative factor, which \u03b2-Variational Autoencoders is unable to map onto a continuous latent variable",
        "We have proposed JointVAE, a framework for learning disentangled continuous and discrete representations in an unsupervised manner",
        "The framework comes with the advantages of Variational Autoencoders such as stable training and large sample diversity while being able to model complex jointly continuous and discrete generative factors",
        "We have shown that JointVAE disentangles factors of variation on several datasets while producing realistic samples"
    ],
    "summary": [
        "Disentangled representations are defined as ones where a change in a single unit of the representation corresponds to a change in single factor of variation of the data while being invariant to others (<a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\"><a class=\"ref-link\" id=\"cBengio_et+al_2013_a\" href=\"#rBengio_et+al_2013_a\">Bengio et al (2013</a></a>)).",
        "Most recent work on learning disentangled representations has focused on modeling continuous factors of variation (<a class=\"ref-link\" id=\"cHiggins_et+al_2016_a\" href=\"#rHiggins_et+al_2016_a\">Higgins et al (2016</a>); Kim & Mnih (2018); <a class=\"ref-link\" id=\"cChen_et+al_2018_a\" href=\"#rChen_et+al_2018_a\">Chen et al (2018</a>)).",
        "While this approach is able to model both discrete and continuous factors, it suffers from some of the shortcomings of Generative Adversarial Networks (GAN), such as unstable training and reduced sample diversity.",
        "In this paper we propose a framework, based on Variational Autoencoders (VAE), that learns disentangled continuous and discrete representations in an unsupervised manner.",
        "It comes with the advantages of VAEs, such as stable training, large sample diversity and a principled inference network, while having the flexibility to model a combination of continuous and discrete generative factors.",
        "\u0392-VAEs model a joint distribution of the data x and a set of latent variables z and learn continuous disentangled representations by maximizing the objective",
        "The loss is a weighted sum of a likelihood term Eq\u03c6(z|x)[log p\u03b8(x|z)] which encourages the model to encode the data x into a set of latent variables z which can efficiently reconstruct the data and a second term that encourages the distribution of the inferred latents z to be close to some prior p(z).",
        "We propose a modification to the \u03b2-VAE framework which allows us to model a joint distribution of continuous and discrete latent variables.",
        "The model discovers several factors of variation in the data, such as digit type, stroke thickness, angle and width in an unsupervised manner.",
        "This is likely because MNIST has an inherently discrete generative factor, which \u03b2-VAE is unable to map onto a continuous latent variable.",
        "As shown in Fig. 5, the JointVAE model discovers various factors of variation including azimuth, age and background color, while being able to generate realistic samples.",
        "As various factors of variation are discovered in the data, we would expect the KL divergence of the corresponding latent units to increase.",
        "On MNIST we can infer the digit type on test data with 88.7% accuracy by looking at the value of the discrete latent variable q\u03c6(c|x).",
        "After training a model on the chairs dataset and identifying the latent unit corresponding to azimuth, we can test the inference network on images that were not used during training.",
        "We have proposed JointVAE, a framework for learning disentangled continuous and discrete representations in an unsupervised manner.",
        "The framework comes with the advantages of VAEs such as stable training and large sample diversity while being able to model complex jointly continuous and discrete generative factors.",
        "The inference network can be used to infer unlabeled quantities on test data and to edit and manipulate images"
    ],
    "headline": "We present a framework for learning disentangled and interpretable jointly continuous and discrete representations in an unsupervised manner",
    "reference_links": [
        {
            "id": "Martin_2017_a",
            "entry": "Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein gan. arXiv preprint arXiv:1701.07875, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.07875"
        },
        {
            "id": "Aubry_et+al_2014_a",
            "entry": "Mathieu Aubry, Daniel Maturana, Alexei A Efros, Bryan C Russell, and Josef Sivic. Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3762\u20133769, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aubry%2C%20Mathieu%20Maturana%2C%20Daniel%20Efros%2C%20Alexei%20A.%20Russell%2C%20Bryan%20C.%20Seeing%203d%20chairs%3A%20exemplar%20part-based%202d-3d%20alignment%20using%20a%20large%20dataset%20of%20cad%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aubry%2C%20Mathieu%20Maturana%2C%20Daniel%20Efros%2C%20Alexei%20A.%20Russell%2C%20Bryan%20C.%20Seeing%203d%20chairs%3A%20exemplar%20part-based%202d-3d%20alignment%20using%20a%20large%20dataset%20of%20cad%20models%202014"
        },
        {
            "id": "Bengio_et+al_2013_a",
            "entry": "Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798\u20131828, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Vincent%2C%20Pascal%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Vincent%2C%20Pascal%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013"
        },
        {
            "id": "Burgess_et+al_2017_a",
            "entry": "Christopher Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. Understanding disentangling in beta-vae. NIPS 2017 Disentanglement Workshop, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Burgess%2C%20Christopher%20Higgins%2C%20Irina%20Pal%2C%20Arka%20Matthey%2C%20Loic%20Understanding%20disentangling%20in%20beta-vae%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Burgess%2C%20Christopher%20Higgins%2C%20Irina%20Pal%2C%20Arka%20Matthey%2C%20Loic%20Understanding%20disentangling%20in%20beta-vae%202017"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Tian Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud. Isolating sources of disentanglement in variational autoencoders. arXiv preprint arXiv:1802.04942, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04942"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "Gao_et+al_2018_a",
            "entry": "Shuyang Gao, Rob Brekelmans, Greg Ver Steeg, and Aram Galstyan. Auto-encoding total correlation explanation. arXiv preprint arXiv:1802.05822, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05822"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp. 5769\u20135779, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017"
        },
        {
            "id": "Gumbel_1954_a",
            "entry": "Emil Julius Gumbel. Statistical theory of extreme valuse and some practical applications. Nat. Bur. Standards Appl. Math. Ser. 33, 1954.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gumbel%2C%20Emil%20Julius%20Statistical%20theory%20of%20extreme%20valuse%20and%20some%20practical%20applications%201954",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gumbel%2C%20Emil%20Julius%20Statistical%20theory%20of%20extreme%20valuse%20and%20some%20practical%20applications%201954"
        },
        {
            "id": "Higgins_et+al_2016_a",
            "entry": "Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. ICLR 2017, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202016"
        },
        {
            "id": "Higgins_et+al_0000_a",
            "entry": "Irina Higgins, Arka Pal, Andrei A Rusu, Loic Matthey, Christopher P Burgess, Alexander Pritzel, Matthew Botvinick, Charles Blundell, and Alexander Lerchner. Darla: Improving zero-shot transfer in reinforcement learning. arXiv preprint arXiv:1707.08475, 2017a.",
            "arxiv_url": "https://arxiv.org/pdf/1707.08475"
        },
        {
            "id": "Higgins_et+al_2017_a",
            "entry": "Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner. Scan: learning abstract hierarchical compositional visual concepts. arXiv preprint arXiv:1707.03389, 2017b.",
            "arxiv_url": "https://arxiv.org/pdf/1707.03389"
        },
        {
            "id": "Jang_et+al_2016_a",
            "entry": "Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01144"
        },
        {
            "id": "Hyunjik_2018_a",
            "entry": "Hyunjik Kim and Andriy Mnih. Disentangling by factorising. arXiv preprint arXiv:1802.05983, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05983"
        },
        {
            "id": "Kingma_2013_a",
            "entry": "Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "Kulkarni_et+al_2015_a",
            "entry": "Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Josh Tenenbaum. Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems, pp. 2539\u20132547, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Josh%20Deep%20convolutional%20inverse%20graphics%20network%202015"
        },
        {
            "id": "Lake_et+al_2017_a",
            "entry": "Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "Maddison_2016_a",
            "entry": "Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.00712"
        },
        {
            "id": "Makhzani_1972_a",
            "entry": "Alireza Makhzani and Brendan J Frey. Pixelgan autoencoders. In Advances in Neural Information Processing Systems, pp. 1972\u20131982, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Makhzani%2C%20Alireza%20Frey%2C%20Brendan%20J.%20Pixelgan%20autoencoders%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Makhzani%2C%20Alireza%20Frey%2C%20Brendan%20J.%20Pixelgan%20autoencoders%201972"
        },
        {
            "id": "Reed_et+al_0000_a",
            "entry": "Scott Reed, Kihyuk Sohn, Yuting Zhang, and Honglak Lee. Learning to disentangle factors of variation with manifold interaction. In International Conference on Machine Learning, pp. 1431\u2013 1439, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Reed%2C%20Scott%20Sohn%2C%20Kihyuk%20Zhang%2C%20Yuting%20Lee%2C%20Honglak%20Learning%20to%20disentangle%20factors%20of%20variation%20with%20manifold%20interaction",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Reed%2C%20Scott%20Sohn%2C%20Kihyuk%20Zhang%2C%20Yuting%20Lee%2C%20Honglak%20Learning%20to%20disentangle%20factors%20of%20variation%20with%20manifold%20interaction"
        },
        {
            "id": "Rezende_et+al_2014_a",
            "entry": "Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1401.4082"
        },
        {
            "id": "Whitney_et+al_2016_a",
            "entry": "William F Whitney, Michael Chang, Tejas Kulkarni, and Joshua B Tenenbaum. Understanding visual concepts with continuation learning. arXiv preprint arXiv:1602.06822, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.06822"
        },
        {
            "id": "Xiao_et+al_2017_a",
            "entry": "Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.07747"
        },
        {
            "id": "Yang_et+al_2015_a",
            "entry": "Jimei Yang, Scott E Reed, Ming-Hsuan Yang, and Honglak Lee. Weakly-supervised disentangling with recurrent transformations for 3d view synthesis. In Advances in Neural Information Processing Systems, pp. 1099\u20131107, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jimei%20Reed%2C%20Scott%20E.%20Yang%2C%20Ming-Hsuan%20Lee%2C%20Honglak%20Weakly-supervised%20disentangling%20with%20recurrent%20transformations%20for%203d%20view%20synthesis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jimei%20Reed%2C%20Scott%20E.%20Yang%2C%20Ming-Hsuan%20Lee%2C%20Honglak%20Weakly-supervised%20disentangling%20with%20recurrent%20transformations%20for%203d%20view%20synthesis%202015"
        }
    ]
}
