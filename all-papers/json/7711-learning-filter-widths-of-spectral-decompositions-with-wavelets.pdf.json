{
    "filename": "7711-learning-filter-widths-of-spectral-decompositions-with-wavelets.pdf",
    "metadata": {
        "title": "Learning filter widths of spectral decompositions with wavelets",
        "author": "Haidar Khan, Bulent Yener",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7711-learning-filter-widths-of-spectral-decompositions-with-wavelets.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Time series classification using deep neural networks, such as convolutional neural networks (CNN), operate on the spectral decomposition of the time series computed using a preprocessing step. This step can include a large number of hyperparameters, such as window length, filter widths, and filter shapes, each with a range of possible values that must be chosen using time and data intensive cross-validation procedures. We propose the wavelet deconvolution (WD) layer as an efficient alternative to this preprocessing step that eliminates a significant number of hyperparameters. The WD layer uses wavelet functions with adjustable scale parameters to learn the spectral decomposition directly from the signal. Using backpropagation, we show the scale parameters can be optimized with gradient descent. Furthermore, the WD layer adds interpretability to the learned time series classifier by exploiting the properties of the wavelet transform. In our experiments, we show that the WD layer can automatically extract the frequency content used to generate a dataset. The WD layer combined with a CNN applied to the phone recognition task on the TIMIT database achieves a phone error rate of 18.1%, a relative improvement of 4% over the baseline CNN. Experiments on a dataset where engineered features are not available showed WD+CNN is the best performing method. Our results show that the WD layer can improve neural network based time series classifiers both in accuracy and interpretability by learning directly from the input signal."
    },
    "keywords": [
        {
            "term": "short-time Fourier transform",
            "url": "https://en.wikipedia.org/wiki/short-time_Fourier_transform"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "automatic speech recognition",
            "url": "https://en.wikipedia.org/wiki/automatic_speech_recognition"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "cross validation",
            "url": "https://en.wikipedia.org/wiki/cross_validation"
        },
        {
            "term": "continuous wavelet transform",
            "url": "https://en.wikipedia.org/wiki/continuous_wavelet_transform"
        },
        {
            "term": "scale parameter",
            "url": "https://en.wikipedia.org/wiki/scale_parameter"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "spectral decomposition",
            "url": "https://en.wikipedia.org/wiki/spectral_decomposition"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "wavelet transform",
            "url": "https://en.wikipedia.org/wiki/wavelet_transform"
        },
        {
            "term": "discrete cosine transform",
            "url": "https://en.wikipedia.org/wiki/discrete_cosine_transform"
        },
        {
            "term": "TIMIT",
            "url": "https://en.wikipedia.org/wiki/TIMIT"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        }
    ],
    "highlights": [
        "The spectral decomposition of signals plays an integral role in problems involving time series classification or prediction using machine learning",
        "In Section 3, we describe the wavelet deconvolution layer and show how the scale parameters can be learned with gradient descent",
        "We generate an artificial dataset to compare the performance of the wavelet deconvolution layer to a convolutional neural networks and verify that the learned scale parameters converge to the frequencies present in the signal",
        "We believe the improvement shown here, especially with respect to other convolutional neural networks based methods with similar model complexities, shows the wavelet deconvolution layer learns a spectral decomposition of the time series which results in improved classification accuracy",
        "We used the wavelet transform and convolutional neural networks to learn the parameters of a spectral decomposition for classification of signals",
        "We showed that the decomposition learned by backpropagation equaled or outperformed hand-selected spectral decompositions"
    ],
    "key_statements": [
        "The spectral decomposition of signals plays an integral role in problems involving time series classification or prediction using machine learning",
        "Effective spectral decomposition requires knowledge about the relevant frequency ranges present in an input signal. Since this information is usually unknown, it is encoded as a set of hyperparameters that are hand-tuned for the problem of interest. This approach can be summarized by the application of filters to a signal and transformation to the time/frequency domain in a preprocessing step with the short-time Fourier transform (STFT) [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>], wavelet transform [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], or empirical mode decomposition [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>]",
        "We propose a method to efficiently optimize the parameters of the spectral decomposition based on the wavelet transform in a neural network framework",
        "In Section 3, we describe the wavelet deconvolution layer and show how the scale parameters can be learned with gradient descent",
        "We are interested in the setting where this is not the case, i.e. the relevant frequency content of the signal is not known, and show how the scale parameters can be learned for a given problem using a combination of the wavelet transform and convolutional neural networks [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>].\n3 Wavelet deconvolutions",
        "Our experiments on artificial and real-world datasets show that including the wavelet deconvolution layer as the first layer of a neural network leads to improved accuracy as well as a reduction in tunable hyperparameters",
        "We show that the learned scales in the wavelet deconvolution layer converge to the frequencies present in the signal, adding interpretability to the learned model",
        "We generate an artificial dataset to compare the performance of the wavelet deconvolution layer to a convolutional neural networks and verify that the learned scale parameters converge to the frequencies present in the signal",
        "Our motivation is to show that the wavelet deconvolution layer is adaptable to different problem spaces and provide an approach that circumvents the need for extensive feature engineering",
        "We believe the improvement shown here, especially with respect to other convolutional neural networks based methods with similar model complexities, shows the wavelet deconvolution layer learns a spectral decomposition of the time series which results in improved classification accuracy",
        "We demonstrate that the wavelet deconvolution layer provides a powerful and flexible approach to learning the parameters of the spectral decomposition of a signal",
        "We used the wavelet transform and convolutional neural networks to learn the parameters of a spectral decomposition for classification of signals",
        "We showed that the decomposition learned by backpropagation equaled or outperformed hand-selected spectral decompositions"
    ],
    "summary": [
        "The spectral decomposition of signals plays an integral role in problems involving time series classification or prediction using machine learning.",
        "We propose a method to efficiently optimize the parameters of the spectral decomposition based on the wavelet transform in a neural network framework.",
        "Called the wavelet deconvolution (WD) layer, learns the spectral decomposition relevant to the classification task with backpropagation and gradient descent.",
        "In Section 3, we describe the wavelet deconvolution layer and show how the scale parameters can be learned with gradient descent.",
        "We are interested in the setting where this is not the case, i.e. the relevant frequency content of the signal is not known, and show how the scale parameters can be learned for a given problem using a combination of the wavelet transform and convolutional neural networks [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>].",
        "It computes the gradients of the loss function with respect to the scale parameters in the backward pass, allowing the network to adapt the transform to the problem it is tasked to solve.",
        "We generate an artificial dataset to compare the performance of the WD layer to a CNN and verify that the learned scale parameters converge to the frequencies present in the signal.",
        "We believe the improvement shown here, especially with respect to other CNN based methods with similar model complexities, shows the WD layer learns a spectral decomposition of the time series which results in improved classification accuracy.",
        "Combined with the backpropagation algorithm for calculating gradients with respect to a loss function, the WD layer can automatically set the filter widths to maximize classification accuracy.",
        "The scale parameters control both the target frequency as well as the filter width allowing a multiscale decomposition of the signal within a single layer of the network.",
        "One challenge to the optimization of the WD layer using stochastic gradient descent (SGD) with a fixed learning rate is that the scale parameters can change too slowly relative to their magnitude and convergence can be slow.",
        "We used the wavelet transform and convolutional neural networks to learn the parameters of a spectral decomposition for classification of signals.",
        "By learning the wavelet scales of the wavelet transform with backpropagation and gradient descent, we avoid having to choose the parameters of the spectral decomposition using cross-validation.",
        "The learned scale parameters reveal the frequency content of the signal important to the classification task, adding a layer of interpretability to the deep neural network.",
        "We plan to investigate how to extend the WD layer to signals in higher dimensions, such as images and video, as well as generalizing the wavelet transform to empirical mode decompositions"
    ],
    "headline": "We propose the wavelet deconvolution  layer as an efficient alternative to this preprocessing step that eliminates a significant number of hyperparameters",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv preprint arXiv:1603.04467, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.04467"
        },
        {
            "id": "2",
            "entry": "[2] Ossama Abdel-Hamid, Mohamed Abdel-rahman, Hui Jiang, Li Deng, Gerald Penn, and Dong Yu. Convolutional Neural Networks for Speech Recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 22(10):1533\u20131545, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abdel-Hamid%2C%20Ossama%20Abdel-rahman%2C%20Mohamed%20Jiang%2C%20Hui%20Deng%2C%20Li%20Convolutional%20Neural%20Networks%20for%20Speech%20Recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abdel-Hamid%2C%20Ossama%20Abdel-rahman%2C%20Mohamed%20Jiang%2C%20Hui%20Deng%2C%20Li%20Convolutional%20Neural%20Networks%20for%20Speech%20Recognition%202014"
        },
        {
            "id": "3",
            "entry": "[3] Ossama Abdel-Hamid, Abdel-rahman Mohamed, Hui Jiang, and Gerald Penn. Applying Convolutional Neural Networks concepts to hybrid NN-HMM model for speech recognition. In 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4277\u20134280. IEEE, mar 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abdel-Hamid%2C%20Ossama%20Mohamed%2C%20Abdel-rahman%20Jiang%2C%20Hui%20Penn%2C%20Gerald%20Applying%20Convolutional%20Neural%20Networks%20concepts%20to%20hybrid%20NN-HMM%20model%20for%20speech%20recognition%202012-03",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abdel-Hamid%2C%20Ossama%20Mohamed%2C%20Abdel-rahman%20Jiang%2C%20Hui%20Penn%2C%20Gerald%20Applying%20Convolutional%20Neural%20Networks%20concepts%20to%20hybrid%20NN-HMM%20model%20for%20speech%20recognition%202012-03"
        },
        {
            "id": "4",
            "entry": "[4] Evrim Acar, Canan Aykut-Bingol, Haluk Bingol, Rasmus Bro, and B\u00fclent Yener. Multiway analysis of epilepsy tensors. Bioinformatics, 23(13):i10\u2013i18, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Multiway%20analysis%20of%20epilepsy%20tensors%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Multiway%20analysis%20of%20epilepsy%20tensors%202007"
        },
        {
            "id": "5",
            "entry": "[5] Ghazi Al-Naymat, Sanjay Chawla, and Javid Taheri. SparseDTW: A novel approach to speed up dynamic time warping. Conferences in Research and Practice in Information Technology Series, 101(December 2003):117\u2013127, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Al-Naymat%2C%20Ghazi%20Chawla%2C%20Sanjay%20Taheri%2C%20Javid%20SparseDTW%3A%20A%20novel%20approach%20to%20speed%20up%20dynamic%20time%20warping%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Al-Naymat%2C%20Ghazi%20Chawla%2C%20Sanjay%20Taheri%2C%20Javid%20SparseDTW%3A%20A%20novel%20approach%20to%20speed%20up%20dynamic%20time%20warping%202003"
        },
        {
            "id": "6",
            "entry": "[6] Anthony Bagnall, Jason Lines, Jon Hills, and Aaron Bostrom. Time-series classification with COTE: The collective of transformation-based ensembles. 2016 IEEE 32nd International Conference on Data Engineering, ICDE 2016, 27(9):1548\u20131549, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anthony%20Bagnall%20Jason%20Lines%20Jon%20Hills%20and%20Aaron%20Bostrom%20Timeseries%20classification%20with%20COTE%20The%20collective%20of%20transformationbased%20ensembles%202016%20IEEE%2032nd%20International%20Conference%20on%20Data%20Engineering%20ICDE%202016%2027915481549%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anthony%20Bagnall%20Jason%20Lines%20Jon%20Hills%20and%20Aaron%20Bostrom%20Timeseries%20classification%20with%20COTE%20The%20collective%20of%20transformationbased%20ensembles%202016%20IEEE%2032nd%20International%20Conference%20on%20Data%20Engineering%20ICDE%202016%2027915481549%202016"
        },
        {
            "id": "7",
            "entry": "[7] Peter Brockwell and Richard Davis. Introduction to Time Series and Forecasting. Springer, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brockwell%2C%20Peter%20Davis%2C%20Richard%20Introduction%20to%20Time%20Series%20and%20Forecasting%202002"
        },
        {
            "id": "8",
            "entry": "[8] Yanping Chen, Eamonn Keogh, Bing Hu, Nurjahan Begum, Anthony Bagnall, Abdullah Mueen, and Gustavo Batista. The UCR Time Series Classification Archive, jul 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yanping%20Chen%20Eamonn%20Keogh%20Bing%20Hu%20Nurjahan%20Begum%20Anthony%20Bagnall%20Abdullah%20Mueen%20and%20Gustavo%20Batista%20The%20UCR%20Time%20Series%20Classification%20Archive%20jul%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yanping%20Chen%20Eamonn%20Keogh%20Bing%20Hu%20Nurjahan%20Begum%20Anthony%20Bagnall%20Abdullah%20Mueen%20and%20Gustavo%20Batista%20The%20UCR%20Time%20Series%20Classification%20Archive%20jul%202015"
        },
        {
            "id": "9",
            "entry": "[9] Fran\u00e7ois Chollet. keras, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fran%C3%A7ois%20Chollet%20keras%202015"
        },
        {
            "id": "10",
            "entry": "[10] Ingrid Daubechies. The wavelet transform, time-frequency localization and signal analysis. IEEE Transactions on Information Theory, 36(5):961\u20131005, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daubechies%2C%20Ingrid%20The%20wavelet%20transform%2C%20time-frequency%20localization%20and%20signal%20analysis%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daubechies%2C%20Ingrid%20The%20wavelet%20transform%2C%20time-frequency%20localization%20and%20signal%20analysis%201990"
        },
        {
            "id": "11",
            "entry": "[11] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Dung. Deep Learning. MIT press Cambridge, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Dung%20Deep%20Learning%202016"
        },
        {
            "id": "12",
            "entry": "[12] G\u00e1bor Gosztolya, Tam\u00e1s Gr\u00f3sz, L\u00e1szl\u00f3 T\u00f3th, and David Imseng. Building context-dependent DNN acoustic models using Kullback-Leibler divergence-based state tying. ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, 2015-Augus:4570\u20134574, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gosztolya%2C%20G%C3%A1bor%20Gr%C3%B3sz%2C%20Tam%C3%A1s%20T%C3%B3th%2C%20L%C3%A1szl%C3%B3%20Imseng%2C%20David%20Building%20context-dependent%20DNN%20acoustic%20models%20using%20Kullback-Leibler%20divergence-based%20state%20tying%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gosztolya%2C%20G%C3%A1bor%20Gr%C3%B3sz%2C%20Tam%C3%A1s%20T%C3%B3th%2C%20L%C3%A1szl%C3%B3%20Imseng%2C%20David%20Building%20context-dependent%20DNN%20acoustic%20models%20using%20Kullback-Leibler%20divergence-based%20state%20tying%202015"
        },
        {
            "id": "13",
            "entry": "[13] Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recurrent neural networks. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, number 3, pages 6645\u20136649. IEEE, may 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Mohamed%2C%20Abdel-rahman%20Hinton%2C%20Geoffrey%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks%202013-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Mohamed%2C%20Abdel-rahman%20Hinton%2C%20Geoffrey%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks%202013-05"
        },
        {
            "id": "14",
            "entry": "[14] David K. Hammond, Pierre Vandergheynst, and R\u00e9mi Gribonval. Wavelets on graphs via spectral graph theory. Applied and Computational Harmonic Analysis, 30(2):129\u2013150, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=David%20K.%20Hammond%2C%20Pierre%20Vandergheynst%20Gribonval%2C%20R%C3%A9mi%20Wavelets%20on%20graphs%20via%20spectral%20graph%20theory%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=David%20K.%20Hammond%2C%20Pierre%20Vandergheynst%20Gribonval%2C%20R%C3%A9mi%20Wavelets%20on%20graphs%20via%20spectral%20graph%20theory%202011"
        },
        {
            "id": "15",
            "entry": "[15] Geoffrey Hinton, Li Deng, Dong Yu, George Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara Sainath, and Brian Kingsbury. Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups. IEEE Signal Processing Magazine, 29(6):82\u201397, nov 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20Deng%2C%20Li%20Yu%2C%20Dong%20Dahl%2C%20George%20Deep%20Neural%20Networks%20for%20Acoustic%20Modeling%20in%20Speech%20Recognition%3A%20The%20Shared%20Views%20of%20Four%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20Geoffrey%20Deng%2C%20Li%20Yu%2C%20Dong%20Dahl%2C%20George%20Deep%20Neural%20Networks%20for%20Acoustic%20Modeling%20in%20Speech%20Recognition%3A%20The%20Shared%20Views%20of%20Four%202012"
        },
        {
            "id": "16",
            "entry": "[16] Norden E Huang and Zhaohua Wu. a Review on Hilbert-Huang Transform : Method and Its Applications. Reviews of Geophysics, 46(2007):1\u201323, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Norden%20E.%20Wu%2C%20Zhaohua%20a%20Review%20on%20Hilbert-Huang%20Transform%20%3A%20Method%20and%20Its%20Applications%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Norden%20E.%20Wu%2C%20Zhaohua%20a%20Review%20on%20Hilbert-Huang%20Transform%20%3A%20Method%20and%20Its%20Applications%202008"
        },
        {
            "id": "17",
            "entry": "[17] Po Sen Huang, Haim Avron, Tara N. Sainath, Vikas Sindhwani, and Bhuvana Ramabhadran. Kernel methods match deep neural networks on TIMIT. ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, pages 205\u2013209, may 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Po%20Sen%20Avron%2C%20Haim%20Sainath%2C%20Tara%20N.%20Sindhwani%2C%20Vikas%20Kernel%20methods%20match%20deep%20neural%20networks%20on%20TIMIT%202014-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Po%20Sen%20Avron%2C%20Haim%20Sainath%2C%20Tara%20N.%20Sindhwani%2C%20Vikas%20Kernel%20methods%20match%20deep%20neural%20networks%20on%20TIMIT%202014-05"
        },
        {
            "id": "18",
            "entry": "[18] Navdeep Jaitly and Geoffrey E. Hinton. Learning a Better Representation of Speech Sound Waves using Restricted Boltzmann Machines. Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, 1:5884\u20135887, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaitly%2C%20Navdeep%20Hinton%2C%20Geoffrey%20E.%20Learning%20a%20Better%20Representation%20of%20Speech%20Sound%20Waves%20using%20Restricted%20Boltzmann%20Machines%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaitly%2C%20Navdeep%20Hinton%2C%20Geoffrey%20E.%20Learning%20a%20Better%20Representation%20of%20Speech%20Sound%20Waves%20using%20Restricted%20Boltzmann%20Machines%202011"
        },
        {
            "id": "19",
            "entry": "[19] Haidar Khan, Lara Marcuse, Madeline Fields, Kalina Swann, and Bulent Yener. Focal onset seizure prediction using convolutional networks. IEEE Transactions on Biomedical Engineering, 9294(c):1\u20131, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khan%2C%20Haidar%20Marcuse%2C%20Lara%20Fields%2C%20Madeline%20Swann%2C%20Kalina%20Focal%20onset%20seizure%20prediction%20using%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khan%2C%20Haidar%20Marcuse%2C%20Lara%20Fields%2C%20Madeline%20Swann%2C%20Kalina%20Focal%20onset%20seizure%20prediction%20using%20convolutional%20networks%202017"
        },
        {
            "id": "20",
            "entry": "[20] Diederik P Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv preprint arXiv:1412.6980, pages 1\u201315, dec 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "21",
            "entry": "[21] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. ImageNet classification with deep convolutional neural networks. Communications of the ACM, 60(6):84\u201390, may 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202017-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202017-05"
        },
        {
            "id": "22",
            "entry": "[22] Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132323, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20Leon%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20Leon%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "23",
            "entry": "[23] Piotr Mirowski, Deepak Madhavan, Yann LeCun, and Ruben Kuzniecky. Classification of patterns of EEG synchronization for seizure prediction. Clinical Neurophysiology, 120(11):1927\u20131940, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mirowski%2C%20Piotr%20Madhavan%2C%20Deepak%20LeCun%2C%20Yann%20Kuzniecky%2C%20Ruben%20Classification%20of%20patterns%20of%20EEG%20synchronization%20for%20seizure%20prediction%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mirowski%2C%20Piotr%20Madhavan%2C%20Deepak%20LeCun%2C%20Yann%20Kuzniecky%2C%20Ruben%20Classification%20of%20patterns%20of%20EEG%20synchronization%20for%20seizure%20prediction%202009"
        },
        {
            "id": "24",
            "entry": "[24] Piotr W. Mirowski, Yann LeCun, Deepak Madhavan, and Ruben Kuzniecky. Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG. In Proceedings of the 2008 IEEE Workshop on Machine Learning for Signal Processing, MLSP 2008, pages 244\u2013249, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mirowski%2C%20Piotr%20W.%20LeCun%2C%20Yann%20Madhavan%2C%20Deepak%20Kuzniecky%2C%20Ruben%20Comparing%20SVM%20and%20convolutional%20networks%20for%20epileptic%20seizure%20prediction%20from%20intracranial%20EEG%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mirowski%2C%20Piotr%20W.%20LeCun%2C%20Yann%20Madhavan%2C%20Deepak%20Kuzniecky%2C%20Ruben%20Comparing%20SVM%20and%20convolutional%20networks%20for%20epileptic%20seizure%20prediction%20from%20intracranial%20EEG%202008"
        },
        {
            "id": "25",
            "entry": "[25] Abdel-Rahman Mohamed, George Dahl, and Geoffrey Hinton. Deep Belief Networks for Phone Recognition. Scholarpedia, 4(5):1\u20139, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mohamed%2C%20Abdel-Rahman%20Dahl%2C%20George%20Hinton%2C%20Geoffrey%20Deep%20Belief%20Networks%20for%20Phone%20Recognition%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mohamed%2C%20Abdel-Rahman%20Dahl%2C%20George%20Hinton%2C%20Geoffrey%20Deep%20Belief%20Networks%20for%20Phone%20Recognition%202009"
        },
        {
            "id": "26",
            "entry": "[26] Vinod Nair and Geoffrey E Hinton. Rectified Linear Units Improve Restricted Boltzmann Machines. In Proceedings of the 27th International Conference on Machine Learning, number 3, pages 807\u2013814, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20E.%20Rectified%20Linear%20Units%20Improve%20Restricted%20Boltzmann%20Machines%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20E.%20Rectified%20Linear%20Units%20Improve%20Restricted%20Boltzmann%20Machines%202010"
        },
        {
            "id": "27",
            "entry": "[27] Alan V Oppenheim and Ronald W Schafer. Discrete-Time Signal Processing. Pearson Education, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oppenheim%2C%20Alan%20V.%20Schafer%2C%20Ronald%20W.%20Discrete-Time%20Signal%20Processing%202014"
        },
        {
            "id": "28",
            "entry": "[28] Dimitri Palaz, Ronan Collobert, and Mathew Magimai. Doss. End-to-end Phoneme Sequence Recognition using Convolutional Neural Networks. arXiv preprint arXiv:1312.2137, pages 2\u20139, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.2137"
        },
        {
            "id": "29",
            "entry": "[29] Dimitri Palaz, Mathew Magimai-Doss, and Ronan Collobert. Analysis of CNN-based speech recognition system using raw speech as input. In Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, pages 11\u201315, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Palaz%2C%20Dimitri%20Magimai-Doss%2C%20Mathew%20Collobert%2C%20Ronan%20Analysis%20of%20CNN-based%20speech%20recognition%20system%20using%20raw%20speech%20as%20input%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Palaz%2C%20Dimitri%20Magimai-Doss%2C%20Mathew%20Collobert%2C%20Ronan%20Analysis%20of%20CNN-based%20speech%20recognition%20system%20using%20raw%20speech%20as%20input%202015"
        },
        {
            "id": "30",
            "entry": "[30] Robi Polikar. The engineer\u2019s ultimate guide to wavelet analysis-the wavelet tutorial. available at http://www.public.iastate.edu/\u0303 rpolikar/WAVELETS/WTtutorial.html, 14(2):81\u201387, 1996.",
            "url": "http://www.public.iastate.edu/\u0303"
        },
        {
            "id": "31",
            "entry": "[31] Tara N. Sainath, Brian Kingsbury, Abdel-Rahman Rahman Mohamed, and Bhuvana Ramabhadran. Learning Filter Banks Within a Deep Neural Network Framework. Proceedings of IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 297\u2013302, dec 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sainath%2C%20Tara%20N.%20Kingsbury%2C%20Brian%20Mohamed%2C%20Abdel-Rahman%20Rahman%20Ramabhadran%2C%20Bhuvana%20Learning%20Filter%20Banks%20Within%20a%20Deep%20Neural%20Network%20Framework%202013-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sainath%2C%20Tara%20N.%20Kingsbury%2C%20Brian%20Mohamed%2C%20Abdel-Rahman%20Rahman%20Ramabhadran%2C%20Bhuvana%20Learning%20Filter%20Banks%20Within%20a%20Deep%20Neural%20Network%20Framework%202013-12"
        },
        {
            "id": "32",
            "entry": "[32] Tara N. Sainath, Ron J. Weiss, Andrew Senior, Kevin W. Wilson, and Oriol Vinyals. Learning the speech front-end with raw waveform CLDNNs. In Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, pages 1\u20135, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sainath%2C%20Tara%20N.%20Weiss%2C%20Ron%20J.%20Senior%2C%20Andrew%20Wilson%2C%20Kevin%20W.%20Learning%20the%20speech%20front-end%20with%20raw%20waveform%20CLDNNs%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sainath%2C%20Tara%20N.%20Weiss%2C%20Ron%20J.%20Senior%2C%20Andrew%20Wilson%2C%20Kevin%20W.%20Learning%20the%20speech%20front-end%20with%20raw%20waveform%20CLDNNs%202015"
        },
        {
            "id": "33",
            "entry": "[33] Patrick Sch\u00e4fer. The BOSS is concerned with time series classification in the presence of noise. Data Mining and Knowledge Discovery, 29(6):1505\u20131530, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sch%C3%A4fer%2C%20Patrick%20The%20BOSS%20is%20concerned%20with%20time%20series%20classification%20in%20the%20presence%20of%20noise%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sch%C3%A4fer%2C%20Patrick%20The%20BOSS%20is%20concerned%20with%20time%20series%20classification%20in%20the%20presence%20of%20noise%202015"
        },
        {
            "id": "34",
            "entry": "[34] Patrice Y Simard, Dave Steinkraus, and John C Platt. Best practices for convolutional neural networks applied to visual document analysis. In Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings., volume 1, pages 958\u2013963. IEEE Comput. Soc, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simard%2C%20Patrice%20Y.%20Steinkraus%2C%20Dave%20Platt%2C%20John%20C.%20Best%20practices%20for%20convolutional%20neural%20networks%20applied%20to%20visual%20document%20analysis%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simard%2C%20Patrice%20Y.%20Steinkraus%2C%20Dave%20Platt%2C%20John%20C.%20Best%20practices%20for%20convolutional%20neural%20networks%20applied%20to%20visual%20document%20analysis%202003"
        },
        {
            "id": "35",
            "entry": "[35] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15:1929\u20131958, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20A%20Simple%20Way%20to%20Prevent%20Neural%20Networks%20from%20Overfitting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20A%20Simple%20Way%20to%20Prevent%20Neural%20Networks%20from%20Overfitting%202014"
        },
        {
            "id": "36",
            "entry": "[36] Sebastian Stober, Avital Avtial Sternin, Adrian M. Owen, and Jessica A. Grahn. Deep Feature Learning for EEG Recordings. Arxiv, pages 1\u201324, nov 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stober%2C%20Sebastian%20Sternin%2C%20Avital%20Avtial%20Owen%2C%20Adrian%20M.%20Grahn%2C%20Jessica%20A.%20Deep%20Feature%20Learning%20for%20EEG%20Recordings",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stober%2C%20Sebastian%20Sternin%2C%20Avital%20Avtial%20Owen%2C%20Adrian%20M.%20Grahn%2C%20Jessica%20A.%20Deep%20Feature%20Learning%20for%20EEG%20Recordings"
        },
        {
            "id": "37",
            "entry": "[37] Laszlo Toth. Phone recognition with deep sparse rectifier neural networks. ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, pages 6985\u20136989, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Toth%2C%20Laszlo%20Phone%20recognition%20with%20deep%20sparse%20rectifier%20neural%20networks%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Toth%2C%20Laszlo%20Phone%20recognition%20with%20deep%20sparse%20rectifier%20neural%20networks%202013"
        },
        {
            "id": "38",
            "entry": "[38] L\u00e1szl\u00f3 T\u00f3th. Convolutional deep maxout networks for phone recognition. Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, pages 1078\u20131082, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=T%C3%B3th%2C%20L%C3%A1szl%C3%B3%20Convolutional%20deep%20maxout%20networks%20for%20phone%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=T%C3%B3th%2C%20L%C3%A1szl%C3%B3%20Convolutional%20deep%20maxout%20networks%20for%20phone%20recognition%202014"
        },
        {
            "id": "39",
            "entry": "[39] Zoltan T\u00fcske, Pavel Golik, Ralf Schl\u00fcter, and Hermann Ney. Acoustic modeling with deep neural networks using raw time signal for LVCSR. In Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, pages 890\u2013894, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=T%C3%BCske%2C%20Zoltan%20Golik%2C%20Pavel%20Schl%C3%BCter%2C%20Ralf%20Ney%2C%20Hermann%20Acoustic%20modeling%20with%20deep%20neural%20networks%20using%20raw%20time%20signal%20for%20LVCSR%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=T%C3%BCske%2C%20Zoltan%20Golik%2C%20Pavel%20Schl%C3%BCter%2C%20Ralf%20Ney%2C%20Hermann%20Acoustic%20modeling%20with%20deep%20neural%20networks%20using%20raw%20time%20signal%20for%20LVCSR%202014"
        },
        {
            "id": "40",
            "entry": "[40] Zhiguang Wang, Weizhong Yan, and Tim Oates. Time Series Classification from Scratch with Deep Neural Networks : A Strong Baseline. In Neural Networks (IJCNN), 2017 International Joint Conference on, pages 1578\u20131585, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhiguang%20Yan%2C%20Weizhong%20Oates%2C%20Tim%20Time%20Series%20Classification%20from%20Scratch%20with%20Deep%20Neural%20Networks%20%3A%20A%20Strong%20Baseline%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhiguang%20Yan%2C%20Weizhong%20Oates%2C%20Tim%20Time%20Series%20Classification%20from%20Scratch%20with%20Deep%20Neural%20Networks%20%3A%20A%20Strong%20Baseline%202017"
        },
        {
            "id": "41",
            "entry": "[41] Dong Yu and Li Deng. Automatic Speech Recognition, volume 1976 of Signals and Communication Technology. Springer London, London, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%20Yu%20and%20Li%20Deng%20Automatic%20Speech%20Recognition%20volume%201976%20of%20Signals%20and%20Communication%20Technology%20Springer%20London%20London%202015"
        },
        {
            "id": "42",
            "entry": "[42] Matthew D. Zeiler. ADADELTA: An Adaptive Learning Rate Method. arXiv, page 6, 2012. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zeiler%2C%20Matthew%20D.%20ADADELTA%3A%20An%20Adaptive%20Learning%20Rate%20Method%202012"
        }
    ]
}
