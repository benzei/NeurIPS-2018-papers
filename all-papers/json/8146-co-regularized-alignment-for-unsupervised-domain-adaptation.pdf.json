{
    "filename": "8146-co-regularized-alignment-for-unsupervised-domain-adaptation.pdf",
    "metadata": {
        "title": "Co-regularized Alignment for Unsupervised Domain Adaptation",
        "author": "Abhishek Kumar, Prasanna Sattigeri, Kahini Wadhawan, Leonid Karlinsky, Rogerio Feris, Bill Freeman, Gregory Wornell",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8146-co-regularized-alignment-for-unsupervised-domain-adaptation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Deep neural networks, trained with large amount of labeled data, can fail to generalize well when tested with examples from a target domain whose distribution differs from the training data distribution, referred as the source domain. It can be expensive or even infeasible to obtain required amount of labeled data in all possible domains. Unsupervised domain adaptation sets out to address this problem, aiming to learn a good predictive model for the target domain using labeled examples from the source domain but only unlabeled examples from the target domain. Domain alignment approaches this problem by matching the source and target feature distributions, and has been used as a key component in many state-of-the-art domain adaptation methods. However, matching the marginal feature distributions does not guarantee that the corresponding class conditional distributions will be aligned across the two domains. We propose co-regularized domain alignment for unsupervised domain adaptation, which constructs multiple diverse feature spaces and aligns source and target distributions in each of them individually, while encouraging that alignments agree with each other with regard to the class predictions on the unlabeled target examples. The proposed method is generic and can be used to improve any domain adaptation method which uses domain alignment. We instantiate it in the context of a recent state-of-the-art method and observe that it provides significant performance improvements on several domain adaptation benchmarks."
    },
    "keywords": [
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "k-nearest neighbor",
            "url": "https://en.wikipedia.org/wiki/k-nearest_neighbor"
        },
        {
            "term": "predictive model",
            "url": "https://en.wikipedia.org/wiki/predictive_model"
        },
        {
            "term": "performance improvement",
            "url": "https://en.wikipedia.org/wiki/performance_improvement"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "Deep learning has shown impressive performance improvements on a wide variety of tasks",
        "A predictive model trained on certain distribution of data ({(x, y) : x \u223c Ps(x)}, referred as the source domain) can fail to generalize when faced with observations pertaining to same concepts but from a different distribution (x \u223c Pt(x), referred as the target domain)",
        "We propose an approach to improve the alignment of class conditional feature distributions of source and target domains for unsupervised domain adaptation",
        "Most unsupervised domain adaptation methods optimize for alignment of marginal distributions g#Ps and g#Pt, hoping that the corresponding class conditional distributions will get aligned as a result",
        "We evaluate the proposed Co-regularized Domain Alignment (Co-DA) by instantiating it in the context of a recently proposed method VADA [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] which has shown state-of-the-art results on several benchmarks, and observe that Co-regularized Domain Alignment yields further significant improvement over it, establishing new state-of-the-art in several cases",
        "We proposed co-regularization based domain alignment for unsupervised domain adaptation"
    ],
    "key_statements": [
        "Deep learning has shown impressive performance improvements on a wide variety of tasks",
        "A predictive model trained on certain distribution of data ({(x, y) : x \u223c Ps(x)}, referred as the source domain) can fail to generalize when faced with observations pertaining to same concepts but from a different distribution (x \u223c Pt(x), referred as the target domain)",
        "We propose an approach to improve the alignment of class conditional feature distributions of source and target domains for unsupervised domain adaptation",
        "Most unsupervised domain adaptation methods optimize for alignment of marginal distributions g#Ps and g#Pt, hoping that the corresponding class conditional distributions will get aligned as a result",
        "We evaluate the proposed Co-regularized Domain Alignment (Co-DA) by instantiating it in the context of a recently proposed method VADA [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] which has shown state-of-the-art results on several benchmarks, and observe that Co-regularized Domain Alignment yields further significant improvement over it, establishing new state-of-the-art in several cases",
        "We evaluate Co-regularized Domain Alignment on the following domain adaptation benchmarks",
        "We proposed co-regularization based domain alignment for unsupervised domain adaptation"
    ],
    "summary": [
        "Deep learning has shown impressive performance improvements on a wide variety of tasks.",
        "We propose an approach to improve the alignment of class conditional feature distributions of source and target domains for unsupervised domain adaptation.",
        "Our approach works by constructing two diverse feature embeddings for the source domain examples and aligning the target domain feature distribution to each of them individually.",
        "Directly pursuing the alignment of the class conditional distributions is not possible as we do not have access to target labels in unsupervised domain adaptation.",
        "Most unsupervised domain adaptation methods optimize for alignment of marginal distributions g#Ps and g#Pt, hoping that the corresponding class conditional distributions will get aligned as a result.",
        "A related work [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] used the idea of co-regularization for semi-supervised domain adaptation but their approach is quite different from our method where they learn different classifiers for source and target, making their predictions agree on the unlabeled target samples.",
        "Saito et al [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>] proposed Asymmetric tri-training for unsupervised domain adaptation where one of the three models is learned only on pseudo-labeled target examples.",
        "Ensemble methods have a different motivation from co-regularization/co-training: in the latter, diversity and agreement go hand in hand, working together towards reducing the size of the hypothesis space and the two classifiers converge to a similar performance after the completion of training due to the agreement objective.",
        "We evaluate the proposed Co-regularized Domain Alignment (Co-DA) by instantiating it in the context of a recently proposed method VADA [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] which has shown state-of-the-art results on several benchmarks, and observe that Co-DA yields further significant improvement over it, establishing new state-of-the-art in several cases.",
        "Shu et al [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] propose to incrementally refine the learned VADA model by shifting the classifier boundaries to pass through low density regions of target domain while keeping it from moving too far away.",
        "To directly measure the improvement in source and target feature distribution alignment, we do the following experiment: (i) We take the feature embeddings g1(\u00b7) for the source training examples, reduce the dimensionality to 50 using PCA, and",
        "We instantiated it in the context of a state-of-the-art domain adaptation method and observe that it provides improved performance on some commonly used domain adaptation benchmarks, with substantial gains in the more challenging tasks, setting new state-of-the-art in these cases.",
        "A theoretical understanding of co-regularization for domain adaptation in the context of deep neural networks, particularly characterizing its effect on the alignment of source and target feature distributions, is an interesting direction for future work."
    ],
    "headline": "We propose co-regularized domain alignment for unsupervised domain adaptation, which constructs multiple diverse feature spaces and aligns source and target distributions in each of them individually, while encouraging that alignments agree with each other with regard to the class predictions on the unlabeled target examples",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Maria-Florina Balcan, Avrim Blum, and Ke Yang. Co-training and expansion: Towards bridging theory and practice. In Advances in neural information processing systems, pages 89\u201396, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20Maria-Florina%20Blum%2C%20Avrim%20Yang%2C%20Ke%20Co-training%20and%20expansion%3A%20Towards%20bridging%20theory%20and%20practice%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20Maria-Florina%20Blum%2C%20Avrim%20Yang%2C%20Ke%20Co-training%20and%20expansion%3A%20Towards%20bridging%20theory%20and%20practice%202005"
        },
        {
            "id": "2",
            "entry": "[2] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151\u2013175, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20Shai%20Blitzer%2C%20John%20Crammer%2C%20Koby%20Kulesza%2C%20Alex%20A%20theory%20of%20learning%20from%20different%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20Shai%20Blitzer%2C%20John%20Crammer%2C%20Koby%20Kulesza%2C%20Alex%20A%20theory%20of%20learning%20from%20different%20domains%202010"
        },
        {
            "id": "3",
            "entry": "[3] A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In Conference on Learning Theory, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blum%2C%20A.%20Mitchell%2C%20T.%20Combining%20labeled%20and%20unlabeled%20data%20with%20co-training%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blum%2C%20A.%20Mitchell%2C%20T.%20Combining%20labeled%20and%20unlabeled%20data%20with%20co-training%201998"
        },
        {
            "id": "4",
            "entry": "[4] Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan. Domain separation networks. In Advances in Neural Information Processing Systems, pages 343\u2013351, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20Konstantinos%20Trigeorgis%2C%20George%20Silberman%2C%20Nathan%20Krishnan%2C%20Dilip%20Domain%20separation%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20Konstantinos%20Trigeorgis%2C%20George%20Silberman%2C%20Nathan%20Krishnan%2C%20Dilip%20Domain%20separation%20networks%202016"
        },
        {
            "id": "5",
            "entry": "[5] Konstantinos Bousmalis, Alex Irpan, Paul Wohlhart, Yunfei Bai, Matthew Kelcey, Mrinal Kalakrishnan, Laura Downs, Julian Ibarz, Peter Pastor, Kurt Konolige, et al. Using simulation and domain adaptation to improve efficiency of deep robotic grasping. arXiv preprint arXiv:1709.07857, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.07857"
        },
        {
            "id": "6",
            "entry": "[6] Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-level domain adaptation with generative adversarial networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 1, page 7, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20Konstantinos%20Silberman%2C%20Nathan%20Dohan%2C%20David%20Erhan%2C%20Dumitru%20Unsupervised%20pixel-level%20domain%20adaptation%20with%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20Konstantinos%20Silberman%2C%20Nathan%20Dohan%2C%20David%20Erhan%2C%20Dumitru%20Unsupervised%20pixel-level%20domain%20adaptation%20with%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "7",
            "entry": "[7] Olivier Chapelle and A. Zien. Semi-Supervised Classification by Low Density Separation. In AISTATS, pages 57\u201364, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chapelle%2C%20Olivier%20Zien%2C%20A.%20Semi-Supervised%20Classification%20by%20Low%20Density%20Separation%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chapelle%2C%20Olivier%20Zien%2C%20A.%20Semi-Supervised%20Classification%20by%20Low%20Density%20Separation%202005"
        },
        {
            "id": "8",
            "entry": "[8] Minmin Chen, Kilian Q Weinberger, and John Blitzer. Co-training for domain adaptation. In Advances in neural information processing systems, pages 2456\u20132464, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Minmin%20Weinberger%2C%20Kilian%20Q.%20Blitzer%2C%20John%20Co-training%20for%20domain%20adaptation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Minmin%20Weinberger%2C%20Kilian%20Q.%20Blitzer%2C%20John%20Co-training%20for%20domain%20adaptation%202011"
        },
        {
            "id": "9",
            "entry": "[9] Hal Daume III, Abhishek Kumar, and Avishek Saha. Co-regularization Based Semi-supervised Domain Adaptation. In Advances in Neural Information Processing Systems, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daume%2C%20III%2C%20Hal%20Kumar%2C%20Abhishek%20Saha%2C%20Avishek%20Co-regularization%20Based%20Semi-supervised%20Domain%20Adaptation%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daume%2C%20III%2C%20Hal%20Kumar%2C%20Abhishek%20Saha%2C%20Avishek%20Co-regularization%20Based%20Semi-supervised%20Domain%20Adaptation%202010"
        },
        {
            "id": "10",
            "entry": "[10] Thomas G Dietterich. Ensemble methods in machine learning. In International workshop on multiple classifier systems, pages 1\u201315.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dietterich%2C%20Thomas%20G.%20Ensemble%20methods%20in%20machine%20learning",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dietterich%2C%20Thomas%20G.%20Ensemble%20methods%20in%20machine%20learning"
        },
        {
            "id": "11",
            "entry": "[11] Harris Drucker, Corinna Cortes, Lawrence D Jackel, Yann LeCun, and Vladimir Vapnik. Boosting and other ensemble methods. Neural Computation, 6(6):1289\u20131301, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Drucker%2C%20Harris%20Cortes%2C%20Corinna%20Jackel%2C%20Lawrence%20D.%20LeCun%2C%20Yann%20Boosting%20and%20other%20ensemble%20methods%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Drucker%2C%20Harris%20Cortes%2C%20Corinna%20Jackel%2C%20Lawrence%20D.%20LeCun%2C%20Yann%20Boosting%20and%20other%20ensemble%20methods%201994"
        },
        {
            "id": "12",
            "entry": "[12] Vincent Dumoulin, Jonathon Shlens, and Manjunath Kudlur. A learned representation for artistic style. In Proceedings of the International Conference on Learning Representations, Toulon, France, April 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dumoulin%2C%20Vincent%20Shlens%2C%20Jonathon%20Kudlur%2C%20Manjunath%20A%20learned%20representation%20for%20artistic%20style%202017-04",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dumoulin%2C%20Vincent%20Shlens%2C%20Jonathon%20Kudlur%2C%20Manjunath%20A%20learned%20representation%20for%20artistic%20style%202017-04"
        },
        {
            "id": "13",
            "entry": "[13] Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. In Computer Vision (ICCV), 2013 IEEE International Conference on, pages 2960\u20132967. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fernando%2C%20Basura%20Habrard%2C%20Amaury%20Sebban%2C%20Marc%20Tuytelaars%2C%20Tinne%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fernando%2C%20Basura%20Habrard%2C%20Amaury%20Sebban%2C%20Marc%20Tuytelaars%2C%20Tinne%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013"
        },
        {
            "id": "14",
            "entry": "[14] Geoffrey French, Michal Mackiewicz, and Mark Fisher. Self-ensembling for domain adaptation. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=French%2C%20Geoffrey%20Mackiewicz%2C%20Michal%20Fisher%2C%20Mark%20Self-ensembling%20for%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=French%2C%20Geoffrey%20Mackiewicz%2C%20Michal%20Fisher%2C%20Mark%20Self-ensembling%20for%20domain%20adaptation%202018"
        },
        {
            "id": "15",
            "entry": "[15] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In ICML, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Yaroslav%20Lempitsky%2C%20Victor%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Lempitsky%2C%20Victor%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015"
        },
        {
            "id": "16",
            "entry": "[16] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The Journal of Machine Learning Research, 17(1):2096\u20132030, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016"
        },
        {
            "id": "17",
            "entry": "[17] Muhammad Ghifary, W Bastiaan Kleijn, and Mengjie Zhang. Domain adaptive neural networks for object recognition. In Pacific Rim International Conference on Artificial Intelligence, pages 898\u2013904.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Muhammad%20Ghifary%2C%20W.Bastiaan%20Kleijn%20Zhang%2C%20Mengjie%20Domain%20adaptive%20neural%20networks%20for%20object%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muhammad%20Ghifary%2C%20W.Bastiaan%20Kleijn%20Zhang%2C%20Mengjie%20Domain%20adaptive%20neural%20networks%20for%20object%20recognition"
        },
        {
            "id": "18",
            "entry": "[18] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "19",
            "entry": "[19] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Advances in neural information processing systems, pages 529\u2013536, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grandvalet%2C%20Yves%20Bengio%2C%20Yoshua%20Semi-supervised%20learning%20by%20entropy%20minimization%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grandvalet%2C%20Yves%20Bengio%2C%20Yoshua%20Semi-supervised%20learning%20by%20entropy%20minimization%202005"
        },
        {
            "id": "20",
            "entry": "[20] Abhishek Kumar and Hal Daum\u00e9. A co-training approach for multi-view spectral clustering. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 393\u2013400, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20Abhishek%20Daum%C3%A9%2C%20Hal%20A%20co-training%20approach%20for%20multi-view%20spectral%20clustering%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20Abhishek%20Daum%C3%A9%2C%20Hal%20A%20co-training%20approach%20for%20multi-view%20spectral%20clustering%202011"
        },
        {
            "id": "21",
            "entry": "[21] Abhishek Kumar, Piyush Rai, and Hal Daume. Co-regularized multi-view spectral clustering. In Advances in neural information processing systems, pages 1413\u20131421, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20Abhishek%20Rai%2C%20Piyush%20Daume%2C%20Hal%20Co-regularized%20multi-view%20spectral%20clustering%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20Abhishek%20Rai%2C%20Piyush%20Daume%2C%20Hal%20Co-regularized%20multi-view%20spectral%20clustering%202011"
        },
        {
            "id": "22",
            "entry": "[22] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.02242"
        },
        {
            "id": "23",
            "entry": "[23] Stefan Lee, Senthil Purushwalkam Shiva Prakash, Michael Cogswell, Viresh Ranjan, David Crandall, and Dhruv Batra. Stochastic multiple choice learning for training diverse deep ensembles. In Advances in Neural Information Processing Systems, pages 2119\u20132127, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Stefan%20Prakash%2C%20Senthil%20Purushwalkam%20Shiva%20Cogswell%2C%20Michael%20Ranjan%2C%20Viresh%20Stochastic%20multiple%20choice%20learning%20for%20training%20diverse%20deep%20ensembles%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Stefan%20Prakash%2C%20Senthil%20Purushwalkam%20Shiva%20Cogswell%2C%20Michael%20Ranjan%2C%20Viresh%20Stochastic%20multiple%20choice%20learning%20for%20training%20diverse%20deep%20ensembles%202016"
        },
        {
            "id": "24",
            "entry": "[24] Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised image-to-image translation networks. In Advances in Neural Information Processing Systems, pages 700\u2013708, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "25",
            "entry": "[25] Yong Liu and Xin Yao. Ensemble learning via negative correlation. Neural networks, 12(10):1399\u20131404, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Yong%20Yao%2C%20Xin%20Ensemble%20learning%20via%20negative%20correlation%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Yong%20Yao%2C%20Xin%20Ensemble%20learning%20via%20negative%20correlation%201999"
        },
        {
            "id": "26",
            "entry": "[26] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I Jordan. Learning transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1502.02791"
        },
        {
            "id": "27",
            "entry": "[27] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. arXiv preprint arXiv:1704.03976, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.03976"
        },
        {
            "id": "28",
            "entry": "[28] Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ramamoorthi, and Kyungnam Kim. Image to image translation for domain adaptation. arXiv preprint arXiv:1712.00479, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.00479"
        },
        {
            "id": "29",
            "entry": "[29] XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11): 5847\u20135861, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20XuanLong%20Wainwright%2C%20Martin%20J.%20Jordan%2C%20Michael%20I.%20Estimating%20divergence%20functionals%20and%20the%20likelihood%20ratio%20by%20convex%20risk%20minimization%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20XuanLong%20Wainwright%2C%20Martin%20J.%20Jordan%2C%20Michael%20I.%20Estimating%20divergence%20functionals%20and%20the%20likelihood%20ratio%20by%20convex%20risk%20minimization%202010"
        },
        {
            "id": "30",
            "entry": "[30] Bruce E Rosen. Ensemble learning using decorrelated neural networks. Connection science, 8(3-4): 373\u2013384, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosen%2C%20Bruce%20E.%20Ensemble%20learning%20using%20decorrelated%20neural%20networks%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosen%2C%20Bruce%20E.%20Ensemble%20learning%20using%20decorrelated%20neural%20networks%201996"
        },
        {
            "id": "31",
            "entry": "[31] David S Rosenberg and Peter L Bartlett. The rademacher complexity of co-regularized kernel classes. In Artificial Intelligence and Statistics, pages 396\u2013403, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosenberg%2C%20David%20S.%20Bartlett%2C%20Peter%20L.%20The%20rademacher%20complexity%20of%20co-regularized%20kernel%20classes%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosenberg%2C%20David%20S.%20Bartlett%2C%20Peter%20L.%20The%20rademacher%20complexity%20of%20co-regularized%20kernel%20classes%202007"
        },
        {
            "id": "32",
            "entry": "[32] Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric tri-training for unsupervised domain adaptation. arXiv preprint arXiv:1702.08400, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.08400"
        },
        {
            "id": "33",
            "entry": "[33] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada. Maximum classifier discrepancy for unsupervised domain adaptation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saito%2C%20Kuniaki%20Watanabe%2C%20Kohei%20Ushiku%2C%20Yoshitaka%20Harada%2C%20Tatsuya%20Maximum%20classifier%20discrepancy%20for%20unsupervised%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saito%2C%20Kuniaki%20Watanabe%2C%20Kohei%20Ushiku%2C%20Yoshitaka%20Harada%2C%20Tatsuya%20Maximum%20classifier%20discrepancy%20for%20unsupervised%20domain%20adaptation%202018"
        },
        {
            "id": "34",
            "entry": "[34] Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of statistical planning and inference, 90(2):227\u2013244, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shimodaira%2C%20Hidetoshi%20Improving%20predictive%20inference%20under%20covariate%20shift%20by%20weighting%20the%20log-likelihood%20function%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shimodaira%2C%20Hidetoshi%20Improving%20predictive%20inference%20under%20covariate%20shift%20by%20weighting%20the%20log-likelihood%20function%202000"
        },
        {
            "id": "35",
            "entry": "[35] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach to unsupervised domain adaptation. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shu%2C%20Rui%20Bui%2C%20Hung%20H.%20Narui%2C%20Hirokazu%20Ermon%2C%20Stefano%20A%20dirt-t%20approach%20to%20unsupervised%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shu%2C%20Rui%20Bui%2C%20Hung%20H.%20Narui%2C%20Hirokazu%20Ermon%2C%20Stefano%20A%20dirt-t%20approach%20to%20unsupervised%20domain%20adaptation%202018"
        },
        {
            "id": "36",
            "entry": "[36] Vikas Sindhwani and David S Rosenberg. An rkhs for multi-view learning and manifold co-regularization. In Proceedings of the 25th international conference on Machine learning, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sindhwani%2C%20Vikas%20Rosenberg%2C%20David%20S.%20An%20rkhs%20for%20multi-view%20learning%20and%20manifold%20co-regularization%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sindhwani%2C%20Vikas%20Rosenberg%2C%20David%20S.%20An%20rkhs%20for%20multi-view%20learning%20and%20manifold%20co-regularization%202008"
        },
        {
            "id": "37",
            "entry": "[37] Vikas Sindhwani, Partha Niyogi, and Mikhail Belkin. A Co-regularization approach to semi-supervised learning with multiple views. In Proceedings of the Workshop on Learning with Multiple Views, International Conference on Machine Learning, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sindhwani%2C%20Vikas%20Niyogi%2C%20Partha%20Belkin%2C%20Mikhail%20A%20Co-regularization%20approach%20to%20semi-supervised%20learning%20with%20multiple%20views%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sindhwani%2C%20Vikas%20Niyogi%2C%20Partha%20Belkin%2C%20Mikhail%20A%20Co-regularization%20approach%20to%20semi-supervised%20learning%20with%20multiple%20views%202005"
        },
        {
            "id": "38",
            "entry": "[38] Karthik Sridharan and Sham M Kakade. An information theoretic framework for multi-view learning. In COLT, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sridharan%2C%20Karthik%20Kakade%2C%20Sham%20M.%20An%20information%20theoretic%20framework%20for%20multi-view%20learning%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sridharan%2C%20Karthik%20Kakade%2C%20Sham%20M.%20An%20information%20theoretic%20framework%20for%20multi-view%20learning%202008"
        },
        {
            "id": "39",
            "entry": "[39] Baochen Sun and Kate Saenko. From virtual to reality: Fast adaptation of virtual object detectors to real domains. In BMVC, volume 1, page 3, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20and%20Kate%20Saenko.%20From%20virtual%20to%20reality%3A%20Fast%20adaptation%20of%20virtual%20object%20detectors%20to%20real%20domains%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20and%20Kate%20Saenko.%20From%20virtual%20to%20reality%3A%20Fast%20adaptation%20of%20virtual%20object%20detectors%20to%20real%20domains%202014"
        },
        {
            "id": "40",
            "entry": "[40] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European Conference on Computer Vision, pages 443\u2013450.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Baochen%20Saenko%2C%20Kate%20Deep%20coral%3A%20Correlation%20alignment%20for%20deep%20domain%20adaptation",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Baochen%20Saenko%2C%20Kate%20Deep%20coral%3A%20Correlation%20alignment%20for%20deep%20domain%20adaptation"
        },
        {
            "id": "41",
            "entry": "[41] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Computer Vision (ICCV), 2015 IEEE International Conference on, pages 4068\u20134076. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20Eric%20Hoffman%2C%20Judy%20Darrell%2C%20Trevor%20Saenko%2C%20Kate%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20Eric%20Hoffman%2C%20Judy%20Darrell%2C%20Trevor%20Saenko%2C%20Kate%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015"
        },
        {
            "id": "42",
            "entry": "[42] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In Computer Vision and Pattern Recognition (CVPR), volume 1, page 4, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20Eric%20Hoffman%2C%20Judy%20Saenko%2C%20Kate%20Darrell%2C%20Trevor%20Adversarial%20discriminative%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20Eric%20Hoffman%2C%20Judy%20Saenko%2C%20Kate%20Darrell%2C%20Trevor%20Adversarial%20discriminative%20domain%20adaptation%202017"
        },
        {
            "id": "43",
            "entry": "[43] David Vazquez, Antonio M Lopez, Javier Marin, Daniel Ponsa, and David Geronimo. Virtual and real world adaptation for pedestrian detection. IEEE transactions on pattern analysis and machine intelligence, 36(4):797\u2013809, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vazquez%2C%20David%20Lopez%2C%20Antonio%20M.%20Marin%2C%20Javier%20Ponsa%2C%20Daniel%20Virtual%20and%20real%20world%20adaptation%20for%20pedestrian%20detection%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vazquez%2C%20David%20Lopez%2C%20Antonio%20M.%20Marin%2C%20Javier%20Ponsa%2C%20Daniel%20Virtual%20and%20real%20world%20adaptation%20for%20pedestrian%20detection%202014"
        },
        {
            "id": "44",
            "entry": "[44] Hongliang Yan, Yukang Ding, Peihua Li, Qilong Wang, Yong Xu, and Wangmeng Zuo. Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2272\u20132281, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yan%2C%20Hongliang%20Ding%2C%20Yukang%20Li%2C%20Peihua%20Wang%2C%20Qilong%20Mind%20the%20class%20weight%20bias%3A%20Weighted%20maximum%20mean%20discrepancy%20for%20unsupervised%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yan%2C%20Hongliang%20Ding%2C%20Yukang%20Li%2C%20Peihua%20Wang%2C%20Qilong%20Mind%20the%20class%20weight%20bias%3A%20Weighted%20maximum%20mean%20discrepancy%20for%20unsupervised%20domain%20adaptation%202017"
        },
        {
            "id": "45",
            "entry": "[45] Zhi-Hua Zhou and Ming Li. Tri-training: Exploiting unlabeled data using three classifiers. IEEE Transactions on knowledge and Data Engineering, 17(11):1529\u20131541, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Zhi-Hua%20Li%2C%20Ming%20Tri-training%3A%20Exploiting%20unlabeled%20data%20using%20three%20classifiers%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20Zhi-Hua%20Li%2C%20Ming%20Tri-training%3A%20Exploiting%20unlabeled%20data%20using%20three%20classifiers%202005"
        },
        {
            "id": "46",
            "entry": "[46] Konrad Zolna, Devansh Arpit, Dendi Suhubdy, and Yoshua Bengio. Fraternal dropout. In International Conference on Learning Representations, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Konrad%20Zolna%20Devansh%20Arpit%20Dendi%20Suhubdy%20and%20Yoshua%20Bengio%20Fraternal%20dropout%20In%20International%20Conference%20on%20Learning%20Representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Konrad%20Zolna%20Devansh%20Arpit%20Dendi%20Suhubdy%20and%20Yoshua%20Bengio%20Fraternal%20dropout%20In%20International%20Conference%20on%20Learning%20Representations%202018"
        }
    ]
}
