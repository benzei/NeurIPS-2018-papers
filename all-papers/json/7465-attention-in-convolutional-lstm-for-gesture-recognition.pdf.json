{
    "filename": "7465-attention-in-convolutional-lstm-for-gesture-recognition.pdf",
    "metadata": {
        "title": "Attention in Convolutional LSTM for Gesture Recognition",
        "author": "Liang Zhang, Guangming Zhu, Lin Mei, Peiyi Shen, Syed Afaq Ali Shah, Mohammed Bennamoun",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7465-attention-in-convolutional-lstm-for-gesture-recognition.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Convolutional long short-term memory (LSTM) networks have been widely used for action/gesture recognition, and different attention mechanisms have also been embedded into the LSTM or the convolutional LSTM (ConvLSTM) networks. Based on the previous gesture recognition architectures which combine the threedimensional convolution neural network (3DCNN) and ConvLSTM, this paper explores the effects of attention mechanism in ConvLSTM. Several variants of ConvLSTM are evaluated: (a) Removing the convolutional structures of the three gates in ConvLSTM, (b) Applying the attention mechanism on the input of ConvLSTM, (c) Reconstructing the input and (d) output gates respectively with the modified channel-wise attention mechanism. The evaluation results demonstrate that the spatial convolutions in the three gates scarcely contribute to the spatiotemporal feature fusion, and the attention mechanisms embedded into the input and output gates cannot improve the feature fusion. In other words, ConvLSTM mainly contributes to the temporal fusion along with the recurrent steps to learn the long-term spatiotemporal features, when taking as input the spatial or spatiotemporal features. On this basis, a new variant of LSTM is derived, in which the convolutional structures are only embedded into the input-to-state transition of LSTM. The code of the LSTM variants is publicly available2."
    },
    "keywords": [
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "long term",
            "url": "https://en.wikipedia.org/wiki/long_term"
        },
        {
            "term": "long short term memory",
            "url": "https://en.wikipedia.org/wiki/long_short_term_memory"
        },
        {
            "term": "gesture recognition",
            "url": "https://en.wikipedia.org/wiki/gesture_recognition"
        },
        {
            "term": "action recognition",
            "url": "https://en.wikipedia.org/wiki/action_recognition"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "state transition",
            "url": "https://en.wikipedia.org/wiki/state_transition"
        },
        {
            "term": "Long short-term memory",
            "url": "https://en.wikipedia.org/wiki/Long_short-term_memory"
        },
        {
            "term": "Stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent"
        },
        {
            "term": "LSTM",
            "url": "https://en.wikipedia.org/wiki/LSTM"
        }
    ],
    "highlights": [
        "Long short-term memory (LSTM) [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] recurrent neural networks are widely used to process sequential data [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "We focus on the evaluation of the third case on the large-scale isolated gesture datasets Jester [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] and IsoGD [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>], since the \"3DCNN+ConvLSTM+2DCNN\" architecture was originally proposed for gesture recognition",
        "The extension from Long short-term memory to ConvLSTM can only increase the dimensionality of the states and memory, and keep the original gate mechanism unchanged. This evaluation leads to a new variant of Long short-term memory of ConvLSTM), in which the convolutional structures are only introduced into the input-to-state transition, and the gates still have the original fully-connected mechanism",
        "The effects of attention in Convolutional Long short-term memory are explored in this paper",
        "Our evaluation results and previous published results show that the convolutional structures in the gates of ConvLSTM do not play the role of spatial attention, even if the gates have independent weight values for each element of the feature maps in the spatial domain",
        "The reduction of the convolutional structures in the three gates results in a better accuracy, a lower parameter size and a lower computational consumption. This leads to a new variant of Long short-term memory, in which the convolutional structures are only added to the input-to-state transition, and the gates still stick to their own responsibility and superiority for long-term temporal fusion"
    ],
    "key_statements": [
        "Long short-term memory (LSTM) [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] recurrent neural networks are widely used to process sequential data [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "Thereafter, ConvLSTM has been used for action recognition [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], gesture recognition [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>\u2013<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] and in other fields [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>\u2013<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>]",
        "We focus on the evaluation of the third case on the large-scale isolated gesture datasets Jester [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] and IsoGD [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>], since the \"3DCNN+ConvLSTM+2DCNN\" architecture was originally proposed for gesture recognition",
        "Experimental results demonstrate that neither the convolutional structures in the three gates of ConvLSTM nor the extra spatial attention mechanisms contribute in the performance improvements, given the fact that the input spatiotemporal features of 3DCNN have paid attention to the noticeable spatial features",
        "The case in which ConvLSTM takes features from 2DCNN as input has been evaluated in [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and the improvement caused by the attention mechanism on the input features can indicate, in some degree, that the convolutional structures in the gates cannot play the role of spatial attention",
        "This paper only focuses on the evaluation of the case in which ConvLSTM takes features from 3DCNN as input",
        "The extension from Long short-term memory to ConvLSTM can only increase the dimensionality of the states and memory, and keep the original gate mechanism unchanged. This evaluation leads to a new variant of Long short-term memory of ConvLSTM), in which the convolutional structures are only introduced into the input-to-state transition, and the gates still have the original fully-connected mechanism",
        "The effects of attention in Convolutional Long short-term memory are explored in this paper",
        "Our evaluation results and previous published results show that the convolutional structures in the gates of ConvLSTM do not play the role of spatial attention, even if the gates have independent weight values for each element of the feature maps in the spatial domain",
        "The reduction of the convolutional structures in the three gates results in a better accuracy, a lower parameter size and a lower computational consumption. This leads to a new variant of Long short-term memory, in which the convolutional structures are only added to the input-to-state transition, and the gates still stick to their own responsibility and superiority for long-term temporal fusion"
    ],
    "summary": [
        "Long short-term memory (LSTM) [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] recurrent neural networks are widely used to process sequential data [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>].",
        "Since the 3DCNN networks have learnt the spatiotemporal features, the gates of ConvLSTM are more unlikely to have the function of spatial attention.",
        "The Res3D and MobileNet blocks are fixed, and the ConvLSTM component is modified to derive four variants: (a) Removing the convolutional structures of the gates by performing the spatial global average pooling on the input and the hidden states ahead.",
        "Experimental results demonstrate that neither the convolutional structures in the three gates of ConvLSTM nor the extra spatial attention mechanisms contribute in the performance improvements, given the fact that the input spatiotemporal features of 3DCNN have paid attention to the noticeable spatial features.",
        "Both the gate and the attention mechanisms need to perform convolutions on the input and the hidden states, as expressed in Eqs.",
        "The case in which ConvLSTM takes features from 2DCNN as input has been evaluated in [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and the improvement caused by the attention mechanism on the input features can indicate, in some degree, that the convolutional structures in the gates cannot play the role of spatial attention.",
        "The lower accuracy of variant (b) may indicate the uselessness of the extra attention mechanism on the inputs, since the learnt spatiotemporal features of 3DCNN have already paid attention to the noticeable spatial regions.",
        "The specific attention mechanism embedded in the input and output gates cannot contribute to the feature fusion, but it just brings extra memory and computational consumption.",
        "These observations demonstrate that the ConvLSTM component only needs to take full use of its advantages on the long-term temporal fusion, when the input features have learnt the local spatiotemporal information.",
        "This evaluation leads to a new variant of LSTM of ConvLSTM), in which the convolutional structures are only introduced into the input-to-state transition, and the gates still have the original fully-connected mechanism .",
        "The reduction of the convolutional structures of the three gates in ConvLSTM brings no side effects to spatiotemporal feature map fusion.",
        "Our evaluation results and previous published results show that the convolutional structures in the gates of ConvLSTM do not play the role of spatial attention, even if the gates have independent weight values for each element of the feature maps in the spatial domain.",
        "This leads to a new variant of LSTM, in which the convolutional structures are only added to the input-to-state transition, and the gates still stick to their own responsibility and superiority for long-term temporal fusion.",
        "This makes the proposed variant capable of effectively performing spatiotemporal feature fusion, with fewer parameters and computational consumption"
    ],
    "headline": "Based on the previous gesture recognition architectures which combine the threedimensional convolution neural network  and ConvLSTM, this paper explores the effects of attention mechanism in ConvLSTM",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "2",
            "entry": "[2] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1. MIT press Cambridge, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Bengio%2C%20Yoshua%20Deep%20learning%2C%20volume%201%202016"
        },
        {
            "id": "3",
            "entry": "[3] Klaus Greff, Rupesh K Srivastava, Jan Koutn\u00edk, Bas R Steunebrink, and J\u00fcrgen Schmidhuber. Lstm: A search space odyssey. IEEE transactions on neural networks and learning systems, 28(10):2222\u20132232, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Greff%2C%20Klaus%20Srivastava%2C%20Rupesh%20K.%20Koutn%C3%ADk%2C%20Jan%20Steunebrink%2C%20Bas%20R.%20Lstm%3A%20A%20search%20space%20odyssey%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Greff%2C%20Klaus%20Srivastava%2C%20Rupesh%20K.%20Koutn%C3%ADk%2C%20Jan%20Steunebrink%2C%20Bas%20R.%20Lstm%3A%20A%20search%20space%20odyssey%202017"
        },
        {
            "id": "4",
            "entry": "[4] Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. Convolutional lstm network: A machine learning approach for precipitation nowcasting. In Advances in neural information processing systems (NIPS), pages 802\u2013810, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shi%2C%20Xingjian%20Chen%2C%20Zhourong%20Wang%2C%20Hao%20Yeung%2C%20Dit-Yan%20Convolutional%20lstm%20network%3A%20A%20machine%20learning%20approach%20for%20precipitation%20nowcasting%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shi%2C%20Xingjian%20Chen%2C%20Zhourong%20Wang%2C%20Hao%20Yeung%2C%20Dit-Yan%20Convolutional%20lstm%20network%3A%20A%20machine%20learning%20approach%20for%20precipitation%20nowcasting%202015"
        },
        {
            "id": "5",
            "entry": "[5] Zhenyang Li, Kirill Gavrilyuk, Efstratios Gavves, Mihir Jain, and Cees GM Snoek. Videolstm convolves, attends and flows for action recognition. Computer Vision and Image Understanding, 166:41\u201350, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Zhenyang%20Gavrilyuk%2C%20Kirill%20Gavves%2C%20Efstratios%20Jain%2C%20Mihir%20Videolstm%20convolves%2C%20attends%20and%20flows%20for%20action%20recognition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Zhenyang%20Gavrilyuk%2C%20Kirill%20Gavves%2C%20Efstratios%20Jain%2C%20Mihir%20Videolstm%20convolves%2C%20attends%20and%20flows%20for%20action%20recognition%202018"
        },
        {
            "id": "6",
            "entry": "[6] Lei Wang, Yangyang Xu, Jun Cheng, Haiying Xia, Jianqin Yin, and Jiaji Wu. Human action recognition by learning spatio-temporal features with deep neural networks. IEEE Access, 6:17913\u201317922, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Lei%20Xu%2C%20Yangyang%20Human%20action%20recognition%20by%20learning%20spatio-temporal%20features%20with%20deep%20neural%20networks%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Lei%20Xu%2C%20Yangyang%20Human%20action%20recognition%20by%20learning%20spatio-temporal%20features%20with%20deep%20neural%20networks%202018-06"
        },
        {
            "id": "7",
            "entry": "[7] Guangming Zhu, Liang Zhang, Peiyi Shen, and Juan Song. Multimodal gesture recognition using 3-d convolution and convolutional lstm. IEEE Access, 5:4517\u20134524, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Guangming%20Zhang%2C%20Liang%20Shen%2C%20Peiyi%20Song%2C%20Juan%20Multimodal%20gesture%20recognition%20using%203-d%20convolution%20and%20convolutional%20lstm%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Guangming%20Zhang%2C%20Liang%20Shen%2C%20Peiyi%20Song%2C%20Juan%20Multimodal%20gesture%20recognition%20using%203-d%20convolution%20and%20convolutional%20lstm%202017"
        },
        {
            "id": "8",
            "entry": "[8] Liang Zhang, Guangming Zhu, Peiyi Shen, Juan Song, Syed Afaq Shah, and Mohammed Bennamoun. Learning spatiotemporal features using 3dcnn and convolutional lstm for gesture recognition. In Proceedings of IEEE International Conference on Computer Vision (ICCV), pages 3120\u20133128, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Liang%20Zhu%2C%20Guangming%20Shen%2C%20Peiyi%20Song%2C%20Juan%20Learning%20spatiotemporal%20features%20using%203dcnn%20and%20convolutional%20lstm%20for%20gesture%20recognition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Liang%20Zhu%2C%20Guangming%20Shen%2C%20Peiyi%20Song%2C%20Juan%20Learning%20spatiotemporal%20features%20using%203dcnn%20and%20convolutional%20lstm%20for%20gesture%20recognition%202017"
        },
        {
            "id": "9",
            "entry": "[9] Huogen Wang, Pichao Wang, Zhanjie Song, and Wanqing Li. Large-scale multimodal gesture segmentation and recognition based on convolutional neural networks. In Proceedings of IEEE International Conference on Computer Vision (ICCV), pages 3138\u20133146, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Huogen%20Wang%2C%20Pichao%20Song%2C%20Zhanjie%20Li%2C%20Wanqing%20Large-scale%20multimodal%20gesture%20segmentation%20and%20recognition%20based%20on%20convolutional%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Huogen%20Wang%2C%20Pichao%20Song%2C%20Zhanjie%20Li%2C%20Wanqing%20Large-scale%20multimodal%20gesture%20segmentation%20and%20recognition%20based%20on%20convolutional%20neural%20networks%202017"
        },
        {
            "id": "10",
            "entry": "[10] Swathikiran Sudhakaran and Oswald Lanz. Convolutional long short-term memory networks for recognizing first person interactions. In Proceedings of IEEE International Conference on Computer Vision (ICCV), pages 2339\u20132346, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sudhakaran%2C%20Swathikiran%20Lanz%2C%20Oswald%20Convolutional%20long%20short-term%20memory%20networks%20for%20recognizing%20first%20person%20interactions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sudhakaran%2C%20Swathikiran%20Lanz%2C%20Oswald%20Convolutional%20long%20short-term%20memory%20networks%20for%20recognizing%20first%20person%20interactions%202017"
        },
        {
            "id": "11",
            "entry": "[11] Weixin Luo, Wen Liu, and Shenghua Gao. Remembering history with convolutional lstm for anomaly detection. In 2017 IEEE International Conference on Multimedia and Expo (ICME), pages 439\u2013444, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20Weixin%20Liu%2C%20Wen%20Gao%2C%20Shenghua%20Remembering%20history%20with%20convolutional%20lstm%20for%20anomaly%20detection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20Weixin%20Liu%2C%20Wen%20Gao%2C%20Shenghua%20Remembering%20history%20with%20convolutional%20lstm%20for%20anomaly%20detection%202017"
        },
        {
            "id": "12",
            "entry": "[12] Yunbo Wang, Mingsheng Long, Jianmin Wang, Zhifeng Gao, and S Yu Philip. Predrnn: Recurrent neural networks for predictive learning using spatiotemporal lstms. In Advances in Neural Information Processing Systems (NIPS), pages 879\u2013888, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yunbo%20Long%2C%20Mingsheng%20Wang%2C%20Jianmin%20Gao%2C%20Zhifeng%20Predrnn%3A%20Recurrent%20neural%20networks%20for%20predictive%20learning%20using%20spatiotemporal%20lstms%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Yunbo%20Long%2C%20Mingsheng%20Wang%2C%20Jianmin%20Gao%2C%20Zhifeng%20Predrnn%3A%20Recurrent%20neural%20networks%20for%20predictive%20learning%20using%20spatiotemporal%20lstms%202017"
        },
        {
            "id": "13",
            "entry": "[13] Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. Long-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 2625\u20132634, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20Jeffrey%20Hendricks%2C%20Lisa%20Anne%20Guadarrama%2C%20Sergio%20Rohrbach%2C%20Marcus%20Long-term%20recurrent%20convolutional%20networks%20for%20visual%20recognition%20and%20description%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20Jeffrey%20Hendricks%2C%20Lisa%20Anne%20Guadarrama%2C%20Sergio%20Rohrbach%2C%20Marcus%20Long-term%20recurrent%20convolutional%20networks%20for%20visual%20recognition%20and%20description%202015"
        },
        {
            "id": "14",
            "entry": "[14] Lionel Pigou, A\u00e4ron Van Den Oord, Sander Dieleman, Mieke Van Herreweghe, and Joni Dambre. Beyond temporal pooling: Recurrence and temporal convolutions for gesture recognition in video. International Journal of Computer Vision, 126(2-4):430\u2013439, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pigou%2C%20Lionel%20Oord%2C%20A%C3%A4ron%20Van%20Den%20Dieleman%2C%20Sander%20Herreweghe%2C%20Mieke%20Van%20Beyond%20temporal%20pooling%3A%20Recurrence%20and%20temporal%20convolutions%20for%20gesture%20recognition%20in%20video%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pigou%2C%20Lionel%20Oord%2C%20A%C3%A4ron%20Van%20Den%20Dieleman%2C%20Sander%20Herreweghe%2C%20Mieke%20Van%20Beyond%20temporal%20pooling%3A%20Recurrence%20and%20temporal%20convolutions%20for%20gesture%20recognition%20in%20video%202018"
        },
        {
            "id": "15",
            "entry": "[15] Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. In International Conference on Machine Learning (ICML), pages 2048\u20132057, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Kelvin%20Ba%2C%20Jimmy%20Kiros%2C%20Ryan%20Cho%2C%20Kyunghyun%20attend%20and%20tell%3A%20Neural%20image%20caption%20generation%20with%20visual%20attention%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Kelvin%20Ba%2C%20Jimmy%20Kiros%2C%20Ryan%20Cho%2C%20Kyunghyun%20attend%20and%20tell%3A%20Neural%20image%20caption%20generation%20with%20visual%20attention%202015"
        },
        {
            "id": "16",
            "entry": "[16] Du Tran, Jamie Ray, Zheng Shou, Shih-Fu Chang, and Manohar Paluri. Convnet architecture search for spatiotemporal feature learning. arXiv preprint arXiv:1708.05038, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.05038"
        },
        {
            "id": "17",
            "entry": "[17] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04861"
        },
        {
            "id": "18",
            "entry": "[18] www.twentybn.com. Twentybn jester dataset: https://www.twentybn.com/datasets/jester, 2017.",
            "url": "http://www.twentybn.com"
        },
        {
            "id": "19",
            "entry": "[19] Jun Wan, Yibing Zhao, Shuai Zhou, Isabelle Guyon, Sergio Escalera, and Stan Z Li. Chalearn looking at people rgb-d isolated and continuous datasets for gesture recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pages 56\u201364, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wan%2C%20Jun%20Zhao%2C%20Yibing%20Zhou%2C%20Shuai%20Guyon%2C%20Isabelle%20Chalearn%20looking%20at%20people%20rgb-d%20isolated%20and%20continuous%20datasets%20for%20gesture%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wan%2C%20Jun%20Zhao%2C%20Yibing%20Zhou%2C%20Shuai%20Guyon%2C%20Isabelle%20Chalearn%20looking%20at%20people%20rgb-d%20isolated%20and%20continuous%20datasets%20for%20gesture%20recognition%202016"
        },
        {
            "id": "20",
            "entry": "[20] Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In European Conference on Computer Vision (ECCV), pages 20\u201336.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Limin%20Xiong%2C%20Yuanjun%20Wang%2C%20Zhe%20Qiao%2C%20Yu%20Temporal%20segment%20networks%3A%20Towards%20good%20practices%20for%20deep%20action%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Limin%20Xiong%2C%20Yuanjun%20Wang%2C%20Zhe%20Qiao%2C%20Yu%20Temporal%20segment%20networks%3A%20Towards%20good%20practices%20for%20deep%20action%20recognition"
        },
        {
            "id": "21",
            "entry": "[21] Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri. Learning spatiotemporal features with 3d convolutional networks. In 2015 IEEE International Conference on Computer Vision (ICCV), pages 4489\u20134497. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tran%2C%20Du%20Bourdev%2C%20Lubomir%20Fergus%2C%20Rob%20Torresani%2C%20Lorenzo%20Learning%20spatiotemporal%20features%20with%203d%20convolutional%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tran%2C%20Du%20Bourdev%2C%20Lubomir%20Fergus%2C%20Rob%20Torresani%2C%20Lorenzo%20Learning%20spatiotemporal%20features%20with%203d%20convolutional%20networks%202015"
        },
        {
            "id": "22",
            "entry": "[22] Joao Carreira and Andrew Zisserman. Quo vadis, action recognition? a new model and the kinetics dataset. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 4724\u20134733. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carreira%2C%20Joao%20Zisserman%2C%20Andrew%20Quo%20vadis%2C%20action%20recognition%3F%20a%20new%20model%20and%20the%20kinetics%20dataset%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carreira%2C%20Joao%20Zisserman%2C%20Andrew%20Quo%20vadis%2C%20action%20recognition%3F%20a%20new%20model%20and%20the%20kinetics%20dataset%202017"
        },
        {
            "id": "23",
            "entry": "[23] Lukasz Kaiser, Aidan N Gomez, and Francois Chollet. Depthwise separable convolutions for neural machine translation. arXiv preprint arXiv:1706.03059, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.03059"
        },
        {
            "id": "24",
            "entry": "[24] Hugo Jair Escalante, V\u00edctor Ponce-L\u00f3pez, Jun Wan, Michael A Riegler, Baiyu Chen, Albert Clap\u00e9s, Sergio Escalera, Isabelle Guyon, Xavier Bar\u00f3, P\u00e5l Halvorsen, et al. Chalearn joint contest on multimedia challenges beyond visual analysis: An overview. In 2016 23rd International Conference on Pattern Recognition (ICPR), pages 67\u201373, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Escalante%2C%20Hugo%20Jair%20Ponce-L%C3%B3pez%2C%20V%C3%ADctor%20Chalearn%20joint%20contest%20on%20multimedia%20challenges%20beyond%20visual%20analysis%3A%20An%20overview%202016-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Escalante%2C%20Hugo%20Jair%20Ponce-L%C3%B3pez%2C%20V%C3%ADctor%20Chalearn%20joint%20contest%20on%20multimedia%20challenges%20beyond%20visual%20analysis%3A%20An%20overview%202016-06"
        },
        {
            "id": "25",
            "entry": "[25] Jun Wan, Sergio Escalera, X Baro, Hugo Jair Escalante, I Guyon, M Madadi, J Allik, J Gorbova, and G Anbarjafari. Results and analysis of chalearn lap multi-modal isolated and continuous gesture recognition, and real versus fake expressed emotions challenges. In Proceedings of IEEE International Conference on Computer Vision (ICCV), pages 3189\u20133197, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wan%2C%20Jun%20Sergio%20Escalera%2C%20X.Baro%20Hugo%20Jair%20Escalante%2C%20I.Guyon%20Madadi%2C%20M.%20Results%20and%20analysis%20of%20chalearn%20lap%20multi-modal%20isolated%20and%20continuous%20gesture%20recognition%2C%20and%20real%20versus%20fake%20expressed%20emotions%20challenges%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wan%2C%20Jun%20Sergio%20Escalera%2C%20X.Baro%20Hugo%20Jair%20Escalante%2C%20I.Guyon%20Madadi%2C%20M.%20Results%20and%20analysis%20of%20chalearn%20lap%20multi-modal%20isolated%20and%20continuous%20gesture%20recognition%2C%20and%20real%20versus%20fake%20expressed%20emotions%20challenges%202017"
        },
        {
            "id": "26",
            "entry": "[26] Guangming Zhu, Liang Zhang, Lin Mei, Jie Shao, Juan Song, and Peiyi Shen. Large-scale isolated gesture recognition using pyramidal 3d convolutional networks. In 2016 23rd International Conference on Pattern Recognition (ICPR), pages 19\u201324, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Guangming%20Zhang%2C%20Liang%20Mei%2C%20Lin%20Shao%2C%20Jie%20Large-scale%20isolated%20gesture%20recognition%20using%20pyramidal%203d%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Guangming%20Zhang%2C%20Liang%20Mei%2C%20Lin%20Shao%2C%20Jie%20Large-scale%20isolated%20gesture%20recognition%20using%20pyramidal%203d%20convolutional%20networks%202016"
        },
        {
            "id": "27",
            "entry": "[27] Pradyumna Narayana, J. Ross Beveridge, and Bruce A Draper. Gesture recognition: Focus on the hands. In 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pradyumna%20Narayana%2C%20J.Ross%20Beveridge%20Draper%2C%20Bruce%20A.%20Gesture%20recognition%3A%20Focus%20on%20the%20hands%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pradyumna%20Narayana%2C%20J.Ross%20Beveridge%20Draper%2C%20Bruce%20A.%20Gesture%20recognition%3A%20Focus%20on%20the%20hands%202018"
        },
        {
            "id": "28",
            "entry": "[28] Yunan Li, Qiguang Miao, Kuan Tian, Yingying Fan, Xin Xu, Rui Li, and Jianfeng Song. Large-scale gesture recognition with a fusion of rgb-d data based on the c3d model. In 2016 23rd International Conference on Pattern Recognition (ICPR), pages 25\u201330, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Yunan%20Miao%2C%20Qiguang%20Tian%2C%20Kuan%20Fan%2C%20Yingying%20Large-scale%20gesture%20recognition%20with%20a%20fusion%20of%20rgb-d%20data%20based%20on%20the%20c3d%20model%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Yunan%20Miao%2C%20Qiguang%20Tian%2C%20Kuan%20Fan%2C%20Yingying%20Large-scale%20gesture%20recognition%20with%20a%20fusion%20of%20rgb-d%20data%20based%20on%20the%20c3d%20model%202016"
        },
        {
            "id": "29",
            "entry": "[29] Qiguang Miao, Yunan Li, Wanli Ouyang, Zhenxin Ma, Xin Xu, Weikang Shi, Xiaochun Cao, Zhipeng Liu, Xiujuan Chai, Zhuang Liu, et al. Multimodal gesture recognition based on the resc3d network. In Proceedings of IEEE International Conference on Computer Vision (ICCV), pages 3047\u20133055, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miao%2C%20Qiguang%20Li%2C%20Yunan%20Ouyang%2C%20Wanli%20Ma%2C%20Zhenxin%20Multimodal%20gesture%20recognition%20based%20on%20the%20resc3d%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miao%2C%20Qiguang%20Li%2C%20Yunan%20Ouyang%2C%20Wanli%20Ma%2C%20Zhenxin%20Multimodal%20gesture%20recognition%20based%20on%20the%20resc3d%20network%202017"
        }
    ]
}
