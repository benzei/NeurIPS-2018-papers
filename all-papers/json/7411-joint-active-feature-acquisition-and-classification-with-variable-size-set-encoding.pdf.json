{
    "filename": "7411-joint-active-feature-acquisition-and-classification-with-variable-size-set-encoding.pdf",
    "metadata": {
        "title": "Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding",
        "author": "Hajin Shim, Sung Ju Hwang, Eunho Yang",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7411-joint-active-feature-acquisition-and-classification-with-variable-size-set-encoding.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We consider the problem of active feature acquisition where the goal is to sequentially select the subset of features in order to achieve the maximum prediction performance in the most cost-effective way at test time. In this work, we formulate this active feature acquisition as a joint learning problem of training both the classifier (environment) and the reinforcement learning (RL) agent that decides either to \u2018stop and predict\u2019 or \u2018collect a new feature\u2019 at test time, in a cost-sensitive manner. We also introduce a novel encoding scheme to represent acquired subsets of features by proposing an order-invariant set encoding at the feature level, which also significantly reduces the search space for our agent. We evaluate our model on a carefully designed synthetic dataset for the active feature acquisition as well as several medical datasets. Our framework shows meaningful feature acquisition process for diagnosis that complies with human knowledge, and outperforms all baselines in terms of prediction performance as well as feature acquisition cost."
    },
    "keywords": [
        {
            "term": "cost effective",
            "url": "https://en.wikipedia.org/wiki/cost_effective"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "National Research Foundation of Korea",
            "url": "https://en.wikipedia.org/wiki/National_Research_Foundation_of_Korea"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "Glasgow coma scale",
            "url": "https://en.wikipedia.org/wiki/Glasgow_coma_scale"
        },
        {
            "term": "machine translation",
            "url": "https://en.wikipedia.org/wiki/machine_translation"
        },
        {
            "term": "low-density lipoprotein",
            "url": "https://en.wikipedia.org/wiki/low-density_lipoprotein"
        },
        {
            "term": "Markov decision process",
            "url": "https://en.wikipedia.org/wiki/Markov_decision_process"
        }
    ],
    "highlights": [
        "Deep learning has shown remarkable growth in recent years mainly due to easier access to vast amount of data from the internet, and demonstrated significant improvements over classical and standard algorithms on diverse tasks such as visual recognition [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] and machine translation [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], to name a few",
        "We first formulate the feature acquisition problem that minimizes the prediction error as well as the feature acquisition cost as an optimization problem.We provide the sequential feature acquisition framework with the classifier for predictions and the reinforcement learning agent for feature acquisitions, in order to systematically solve the proposed optimization problem",
        "As our main motivation of this work is to make cost-effective predictions in the medical diagnosis, we further examine how our model operates on real-world medical datasets",
        "A cost-aware sequential feature selection can be used in situations where the features are not provided in full and each collection of features incurs variable cost, such as with medical examination",
        "We validated our model on both synthetic and real medical datasets to confirm the superiority of proposed feature level set embedding under our joint learning framework",
        "In the synthetic dataset experiment, we found that features are overly acquired for a few instances whose class is indistinguishable because of the data generation rule"
    ],
    "key_statements": [
        "Deep learning has shown remarkable growth in recent years mainly due to easier access to vast amount of data from the internet, and demonstrated significant improvements over classical and standard algorithms on diverse tasks such as visual recognition [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] and machine translation [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], to name a few",
        "We first formulate the feature acquisition problem that minimizes the prediction error as well as the feature acquisition cost as an optimization problem.We provide the sequential feature acquisition framework with the classifier for predictions and the reinforcement learning agent for feature acquisitions, in order to systematically solve the proposed optimization problem",
        "As our main motivation of this work is to make cost-effective predictions in the medical diagnosis, we further examine how our model operates on real-world medical datasets",
        "A cost-aware sequential feature selection can be used in situations where the features are not provided in full and each collection of features incurs variable cost, such as with medical examination",
        "We validated our model on both synthetic and real medical datasets to confirm the superiority of proposed feature level set embedding under our joint learning framework",
        "In the synthetic dataset experiment, we found that features are overly acquired for a few instances whose class is indistinguishable because of the data generation rule",
        "We plan to explore some tricks or other reinforcement learning methods to alleviate this problem as future work"
    ],
    "summary": [
        "Deep learning has shown remarkable growth in recent years mainly due to easier access to vast amount of data from the internet, and demonstrated significant improvements over classical and standard algorithms on diverse tasks such as visual recognition [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] and machine translation [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], to name a few.",
        "The feature-level set encoding method helps to reduce the state space effectively, by making feature acquisition process to be order-invariant through the attention mechanism [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>].",
        "Ruckstiess et al [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>] set this problem as partially observable MDP (POMDP) with the assumption that pre-learned classifier and prediction result on each instance with missing entries from this classifier as the observation of the state.",
        "In order to learn the model that minimizes the classification loss and the acquisition cost simultaneously, we formulate our framework in the following optimization problem: minimize",
        "I=1 where L is the cross-entropy loss as in the standard classification problem and the binary vector z# 2 {0, 1}p encodes whether each feature is acquired at the end) when the sequential selection is performed by policy #.",
        "Since the cost term c>z#(i) is a constant w.r.t \u2713, it is trained to minimize the prediction loss given the subset of features acquired by #k 1.",
        "The model with the proposed set encoding outperforms both in terms of accuracy and the number of acquired features, showing the resilience against the increase of dummy features.We conjecture that set encoding can reduce the noise coming from dummy features by attention mechanism so is accompanied by stable policy learning.",
        "We can observe in Fig 2(b), (c) that our jointly trained model with set encoding can achieve higher accuracy with less features on average because our agent stops with enough informations and this is not the case for RAM.",
        "The model in our framework achieves AUC close to that of MLP while acquiring fewer features and outperforms all the others for prediction task of length of stay.",
        "MLP incurs large examination cost because it leverages coronary calcium score and Echo E/E\u2019 for prediction, and so does our model with uniform cost setting as it selects Echo EF value which are all expensive.",
        "In the IMT prediction task, rather than taking expensive features such as Echo E/E\u2019 and steatosis as done by MLP or our model with uniform cost, our cost-sensitive model makes a decision based on age, smoking history, genetic factors, weight, BMI, glucose, blood pressure, LDL cholesterol, TG.",
        "We formulated it into an optimization problem of simultaneously minimizing the prediction loss and the feature acquisition costs, and derived a joint learning framework for the classifier and the RL agent.",
        "We validated our model on both synthetic and real medical datasets to confirm the superiority of proposed feature level set embedding under our joint learning framework.",
        "We can take model uncertainty into account, so that our agent collects the features that can help to reduce uncertainty as well as increase classification performance with as small as possible amounts of cost"
    ],
    "headline": "We introduce a novel encoding scheme to represent acquired subsets of features by proposing an order-invariant set encoding at the feature level, which significantly reduces the search space for our agent",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] T. N. Sainath, A. r. Mohamed, B. Kingsbury, and B. Ramabhadran. Deep convolutional neural networks for lvcsr. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sainath%2C%20T.N.%20r.%20Mohamed%2C%20A.%20Kingsbury%2C%20B.%20Ramabhadran%2C%20B.%20Deep%20convolutional%20neural%20networks%20for%20lvcsr%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sainath%2C%20T.N.%20r.%20Mohamed%2C%20A.%20Kingsbury%2C%20B.%20Ramabhadran%2C%20B.%20Deep%20convolutional%20neural%20networks%20for%20lvcsr%202013"
        },
        {
            "id": "2",
            "entry": "[2] K He, X Zhang, S Ren, and J Sun. Deep residual learning for image recognition. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "3",
            "entry": "[3] D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.0473"
        },
        {
            "id": "4",
            "entry": "[4] O. Vinyals, S. Bengio, and M. Kudlur. Order matters: sequence to sequence for sets. In International Conference on Learning Representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20O.%20Bengio%2C%20S.%20Kudlur%2C%20M.%20Order%20matters%3A%20sequence%20to%20sequence%20for%20sets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20O.%20Bengio%2C%20S.%20Kudlur%2C%20M.%20Order%20matters%3A%20sequence%20to%20sequence%20for%20sets%202016"
        },
        {
            "id": "5",
            "entry": "[5] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In Proceedings of The 33rd International Conference on Machine Learning, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "6",
            "entry": "[6] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, 58(1):267\u2013288, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tibshirani%2C%20R.%20Regression%20shrinkage%20and%20selection%20via%20the%20lasso%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tibshirani%2C%20R.%20Regression%20shrinkage%20and%20selection%20via%20the%20lasso%201996"
        },
        {
            "id": "7",
            "entry": "[7] Isabelle Guyon and Andr\u00e9 Elisseeff. An introduction to variable and feature selection. Journal of machine learning research, 3:1157\u20131182, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guyon%2C%20Isabelle%20Elisseeff%2C%20Andr%C3%A9%20An%20introduction%20to%20variable%20and%20feature%20selection%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guyon%2C%20Isabelle%20Elisseeff%2C%20Andr%C3%A9%20An%20introduction%20to%20variable%20and%20feature%20selection%202003"
        },
        {
            "id": "8",
            "entry": "[8] Russell Greiner, Adam J. Grove, and Dan Roth. Learning cost-sensitive active classifiers. Artif. Intell., 139(2):137\u2013174, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Greiner%2C%20Russell%20Grove%2C%20Adam%20J.%20Roth%2C%20Dan%20Learning%20cost-sensitive%20active%20classifiers%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Greiner%2C%20Russell%20Grove%2C%20Adam%20J.%20Roth%2C%20Dan%20Learning%20cost-sensitive%20active%20classifiers%202002"
        },
        {
            "id": "9",
            "entry": "[9] Victor S. Sheng and Charles X. Ling. Feature value acquisition in testing: a sequential batch test algorithm. In International Conference on Machine learning (ICML), 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sheng%2C%20Victor%20S.%20Ling%2C%20Charles%20X.%20Feature%20value%20acquisition%20in%20testing%3A%20a%20sequential%20batch%20test%20algorithm%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sheng%2C%20Victor%20S.%20Ling%2C%20Charles%20X.%20Feature%20value%20acquisition%20in%20testing%3A%20a%20sequential%20batch%20test%20algorithm%202006"
        },
        {
            "id": "10",
            "entry": "[10] Pallika Kanani and Prem Melville. Prediction-time active feature-value acquisition for cost-effective customer targeting. Advances In Neural Information Processing Systems (NIPS), 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kanani%2C%20Pallika%20Melville%2C%20Prem%20Prediction-time%20active%20feature-value%20acquisition%20for%20cost-effective%20customer%20targeting%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kanani%2C%20Pallika%20Melville%2C%20Prem%20Prediction-time%20active%20feature-value%20acquisition%20for%20cost-effective%20customer%20targeting%202008"
        },
        {
            "id": "11",
            "entry": "[11] Ashish Kapoor and Eric Horvitz. Breaking boundaries: Active information acquisition across learning and diagnosis. In Proceedings of the 22nd International Conference on Neural Information Processing Systems, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Ashish%20Kapoor%20and%20Eric%20Horvitz.%20Breaking%20boundaries%3A%20Active%20information%20acquisition%20across%20learning%20and%20diagnosis%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Ashish%20Kapoor%20and%20Eric%20Horvitz.%20Breaking%20boundaries%3A%20Active%20information%20acquisition%20across%20learning%20and%20diagnosis%202009"
        },
        {
            "id": "12",
            "entry": "[12] Mustafa Bilgic and Lise Getoor. Voila: Efficient feature-value acquisition for classification. In Proceedings of the National Conference on Artificial Intelligence, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bilgic%2C%20Mustafa%20Getoor%2C%20Lise%20Voila%3A%20Efficient%20feature-value%20acquisition%20for%20classification%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bilgic%2C%20Mustafa%20Getoor%2C%20Lise%20Voila%3A%20Efficient%20feature-value%20acquisition%20for%20classification%202007"
        },
        {
            "id": "13",
            "entry": "[13] Kirill Trapeznikov and Venkatesh Saligrama. Supervised sequential classification under budget constraints. In Artificial Intelligence and Statistics, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Trapeznikov%2C%20Kirill%20Saligrama%2C%20Venkatesh%20Supervised%20sequential%20classification%20under%20budget%20constraints%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Trapeznikov%2C%20Kirill%20Saligrama%2C%20Venkatesh%20Supervised%20sequential%20classification%20under%20budget%20constraints%202013"
        },
        {
            "id": "14",
            "entry": "[14] F. Nan, J. Wang, K. Trapeznikov, and V. Saligrama. Fast margin-based cost-sensitive classification. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nan%2C%20F.%20Wang%2C%20J.%20Trapeznikov%2C%20K.%20Saligrama%2C%20V.%20Fast%20margin-based%20cost-sensitive%20classification%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nan%2C%20F.%20Wang%2C%20J.%20Trapeznikov%2C%20K.%20Saligrama%2C%20V.%20Fast%20margin-based%20cost-sensitive%20classification%202014"
        },
        {
            "id": "15",
            "entry": "[15] Zhixiang Xu, Matt J. Kusner, Kilian Q. Weinberger, and Minmin Chen. Cost-sensitive tree of classifiers. In Proceedings of the 30th International Conference on International Conference on Machine Learning Volume 28, ICML\u201913, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Zhixiang%20Kusner%2C%20Matt%20J.%20Weinberger%2C%20Kilian%20Q.%20Chen%2C%20Minmin%20Cost-sensitive%20tree%20of%20classifiers%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Zhixiang%20Kusner%2C%20Matt%20J.%20Weinberger%2C%20Kilian%20Q.%20Chen%2C%20Minmin%20Cost-sensitive%20tree%20of%20classifiers%202013"
        },
        {
            "id": "16",
            "entry": "[16] T. R\u00fcckstie\u00df, C. Osendorfer, and P. Patrick van der Smagt. Sequential feature selection for classification. In Australasian Conference on Artificial Intelligence, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=R%C3%BCckstie%C3%9F%2C%20T.%20Osendorfer%2C%20C.%20van%20der%20Smagt%2C%20P.Patrick%20Sequential%20feature%20selection%20for%20classification%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=R%C3%BCckstie%C3%9F%2C%20T.%20Osendorfer%2C%20C.%20van%20der%20Smagt%2C%20P.Patrick%20Sequential%20feature%20selection%20for%20classification%202011"
        },
        {
            "id": "17",
            "entry": "[17] G. Dulac-Arnold, L. Denoyer, P. Preux, and P. Gallinari. Datum-wise classification: A sequential approach to sparsity. In Proceedings of the ECML/PKDD 2011, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dulac-Arnold%2C%20G.%20Denoyer%2C%20L.%20Preux%2C%20P.%20Gallinari%2C%20P.%20Datum-wise%20classification%3A%20A%20sequential%20approach%20to%20sparsity%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dulac-Arnold%2C%20G.%20Denoyer%2C%20L.%20Preux%2C%20P.%20Gallinari%2C%20P.%20Datum-wise%20classification%3A%20A%20sequential%20approach%20to%20sparsity%202011"
        },
        {
            "id": "18",
            "entry": "[18] He He, Jason Eisner, and Hal Daume. Imitation learning by coaching. In Advances in Neural Information Processing Systems, pages 3149\u20133157, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20He%20Eisner%2C%20Jason%20Daume%2C%20Hal%20Imitation%20learning%20by%20coaching%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20He%20Eisner%2C%20Jason%20Daume%2C%20Hal%20Imitation%20learning%20by%20coaching%202012"
        },
        {
            "id": "19",
            "entry": "[19] H. He, P. Mineiro, and N. Karampatziakis. Active Information Acquisition. ArXiv e-prints, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20H.%20Mineiro%2C%20P.%20Karampatziakis%2C%20N.%20Active%20Information%20Acquisition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20H.%20Mineiro%2C%20P.%20Karampatziakis%2C%20N.%20Active%20Information%20Acquisition%202016"
        },
        {
            "id": "20",
            "entry": "[20] Volodymyr Mnih, Nicolas Heess, Alex Graves, et al. Recurrent models of visual attention. In Advances in neural information processing systems, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Heess%2C%20Nicolas%20Graves%2C%20Alex%20Recurrent%20models%20of%20visual%20attention%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Heess%2C%20Nicolas%20Graves%2C%20Alex%20Recurrent%20models%20of%20visual%20attention%202014"
        },
        {
            "id": "21",
            "entry": "[21] Jimmy Ba, Volodymyr Mnih, and Koray Kavukcuoglu. Multiple object recognition with visual attention. arXiv preprint arXiv:1412.7755, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.7755"
        },
        {
            "id": "22",
            "entry": "[22] Jimmy Ba, Ruslan R Salakhutdinov, Roger B Grosse, and Brendan J Frey. Learning wake-sleep recurrent attention models. In Advances in Neural Information Processing Systems, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ba%2C%20Jimmy%20Salakhutdinov%2C%20Ruslan%20R.%20Grosse%2C%20Roger%20B.%20Frey%2C%20Brendan%20J.%20Learning%20wake-sleep%20recurrent%20attention%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ba%2C%20Jimmy%20Salakhutdinov%2C%20Ruslan%20R.%20Grosse%2C%20Roger%20B.%20Frey%2C%20Brendan%20J.%20Learning%20wake-sleep%20recurrent%20attention%20models%202015"
        },
        {
            "id": "23",
            "entry": "[23] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229\u2013256, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Ronald%20J.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Ronald%20J.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992"
        },
        {
            "id": "24",
            "entry": "[24] Pallika H. Kanani and Andrew K. McCallum. Selecting actions for resource-bounded information extraction using reinforcement learning. In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, WSDM \u201912, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kanani%2C%20Pallika%20H.%20McCallum%2C%20Andrew%20K.%20Selecting%20actions%20for%20resource-bounded%20information%20extraction%20using%20reinforcement%20learning%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kanani%2C%20Pallika%20H.%20McCallum%2C%20Andrew%20K.%20Selecting%20actions%20for%20resource-bounded%20information%20extraction%20using%20reinforcement%20learning%202012"
        },
        {
            "id": "25",
            "entry": "[25] Karthik Narasimhan, Adam Yala, and Regina Barzilay. Improving information extraction by acquiring external evidence with reinforcement learning. arXiv preprint arXiv:1603.07954, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.07954"
        },
        {
            "id": "26",
            "entry": "[26] C. J. C. H. Watkins and P. Dayan. Q-learning. In Machine Learning, pages 279\u2013292, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=C%20J%20C%20H%20Watkins%20and%20P%20Dayan%20Qlearning%20In%20Machine%20Learning%20pages%20279292%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=C%20J%20C%20H%20Watkins%20and%20P%20Dayan%20Qlearning%20In%20Machine%20Learning%20pages%20279292%201992"
        },
        {
            "id": "27",
            "entry": "[27] Hado V. Hasselt. Double q-learning. In Advances in Neural Information Processing Systems 23. 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hasselt%2C%20Hado%20V.%20Double%20q-learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hasselt%2C%20Hado%20V.%20Double%20q-learning%202010"
        },
        {
            "id": "28",
            "entry": "[28] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "29",
            "entry": "[29] T R\u00fcckstie\u00df, C Osendorfer, and P van der Smagt. Minimizing data consumption with sequential online feature selection. Int. J. Machine Learning & Cybernetics, 4(3):235\u2013243, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=R%C3%BCckstie%C3%9F%2C%20T.%20Osendorfer%2C%20C.%20van%20der%20Smagt%2C%20P.%20Minimizing%20data%20consumption%20with%20sequential%20online%20feature%20selection%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=R%C3%BCckstie%C3%9F%2C%20T.%20Osendorfer%2C%20C.%20van%20der%20Smagt%2C%20P.%20Minimizing%20data%20consumption%20with%20sequential%20online%20feature%20selection%202013"
        },
        {
            "id": "30",
            "entry": "[30] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. Ch. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 101(23):e215\u2013e220, 2000 (June 13).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldberger%2C%20A.L.%20Amaral%2C%20L.A.N.%20Glass%2C%20L.%20Hausdorff%2C%20J.M.%20and%20PhysioNet%3A%20Components%20of%20a%20new%20research%20resource%20for%20complex%20physiologic%20signals%202000-06-13",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldberger%2C%20A.L.%20Amaral%2C%20L.A.N.%20Glass%2C%20L.%20Hausdorff%2C%20J.M.%20and%20PhysioNet%3A%20Components%20of%20a%20new%20research%20resource%20for%20complex%20physiologic%20signals%202000-06-13"
        },
        {
            "id": "31",
            "entry": "[31] Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5574\u20135584. Curran Associates, Inc., 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kendall%2C%20Alex%20Gal%2C%20Yarin%20What%20uncertainties%20do%20we%20need%20in%20bayesian%20deep%20learning%20for%20computer%20vision%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kendall%2C%20Alex%20Gal%2C%20Yarin%20What%20uncertainties%20do%20we%20need%20in%20bayesian%20deep%20learning%20for%20computer%20vision%3F%202017"
        }
    ]
}
