{
    "filename": "7384-a-block-coordinate-ascent-algorithm-for-mean-variance-optimization.pdf",
    "metadata": {
        "title": "A Block Coordinate Ascent Algorithm for Mean-Variance Optimization",
        "author": "Tengyang Xie, Bo Liu, Yangyang Xu, Mohammad Ghavamzadeh, Yinlam Chow, Daoming Lyu, Daesub Yoon",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7384-a-block-coordinate-ascent-algorithm-for-mean-variance-optimization.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Risk management in dynamic decision problems is a primary concern in many fields, including financial investment, autonomous driving, and healthcare. The mean-variance function is one of the most widely used objective functions in risk management due to its simplicity and interpretability. Existing algorithms for mean-variance optimization are based on multi-time-scale stochastic approximation, whose learning rate schedules are often hard to tune, and have only asymptotic convergence proof. In this paper, we develop a model-free policy search framework for mean-variance optimization with finite-sample error bound analysis (to local optima). Our starting point is a reformulation of the original mean-variance function with its Legendre-Fenchel dual, from which we propose a stochastic block coordinate ascent policy search algorithm. Both the asymptotic convergence guarantee of the last iteration\u2019s solution and the convergence rate of the randomly picked solution are provided, and their applicability is demonstrated on several benchmark domains."
    },
    "keywords": [
        {
            "term": "dynamic programming",
            "url": "https://en.wikipedia.org/wiki/dynamic_programming"
        },
        {
            "term": "Reinforcement Learning",
            "url": "https://en.wikipedia.org/wiki/Reinforcement_Learning"
        },
        {
            "term": "value at risk",
            "url": "https://en.wikipedia.org/wiki/value_at_risk"
        },
        {
            "term": "objective function",
            "url": "https://en.wikipedia.org/wiki/objective_function"
        },
        {
            "term": "Coordinate descent",
            "url": "https://en.wikipedia.org/wiki/Coordinate_descent"
        },
        {
            "term": "risk management",
            "url": "https://en.wikipedia.org/wiki/risk_management"
        },
        {
            "term": "Markov decision process",
            "url": "https://en.wikipedia.org/wiki/Markov_decision_process"
        },
        {
            "term": "autonomous driving",
            "url": "https://en.wikipedia.org/wiki/autonomous_driving"
        },
        {
            "term": "stochastic approximation",
            "url": "https://en.wikipedia.org/wiki/stochastic_approximation"
        },
        {
            "term": "conditional value at risk",
            "url": "https://en.wikipedia.org/wiki/conditional_value_at_risk"
        }
    ],
    "highlights": [
        "Risk management plays a central role in sequential decision-making problems, common in fields such as portfolio management [<a class=\"ref-link\" id=\"cLai_et+al_2011_a\" href=\"#rLai_et+al_2011_a\"><a class=\"ref-link\" id=\"cLai_et+al_2011_a\" href=\"#rLai_et+al_2011_a\">Lai et al, 2011</a></a>], autonomous driving [<a class=\"ref-link\" id=\"cMaurer_et+al_2016_a\" href=\"#rMaurer_et+al_2016_a\"><a class=\"ref-link\" id=\"cMaurer_et+al_2016_a\" href=\"#rMaurer_et+al_2016_a\">Maurer et al, 2016</a></a>], and healthcare [<a class=\"ref-link\" id=\"cParker_2009_a\" href=\"#rParker_2009_a\"><a class=\"ref-link\" id=\"cParker_2009_a\" href=\"#rParker_2009_a\">Parker, 2009</a></a>]",
        "We propose a new formulation of the meanvariance objective function that is based on its Legendre-Fenchel dual and derive novel algorithms that are based on the recent results in stochastic nonconvex block coordinate descent",
        "The objective function is reformulated based on the Legendre-Fenchel duality, and a novel stochastic block coordinate ascent algorithm is proposed with in-depth analysis",
        "Other reformulations of the meanvariance objective function are worth exploring, which will lead to new families of algorithms",
        "Distributional Reinforcement Learning [<a class=\"ref-link\" id=\"cBellemare_et+al_2016_a\" href=\"#rBellemare_et+al_2016_a\">Bellemare et al, 2016</a>] is strongly related to risk-sensitive policy search, and it is interesting to investigate the connections between risk-sensitive policy gradient methods and distributional Reinforcement Learning",
        "It is interesting to test the performance of the proposed algorithms together with other risk-sensitive Reinforcement Learning algorithms on highly-complex risk-sensitive tasks, such as autonomous driving problems and other challenging tasks"
    ],
    "key_statements": [
        "Risk management plays a central role in sequential decision-making problems, common in fields such as portfolio management [<a class=\"ref-link\" id=\"cLai_et+al_2011_a\" href=\"#rLai_et+al_2011_a\"><a class=\"ref-link\" id=\"cLai_et+al_2011_a\" href=\"#rLai_et+al_2011_a\">Lai et al, 2011</a></a>], autonomous driving [<a class=\"ref-link\" id=\"cMaurer_et+al_2016_a\" href=\"#rMaurer_et+al_2016_a\"><a class=\"ref-link\" id=\"cMaurer_et+al_2016_a\" href=\"#rMaurer_et+al_2016_a\">Maurer et al, 2016</a></a>], and healthcare [<a class=\"ref-link\" id=\"cParker_2009_a\" href=\"#rParker_2009_a\"><a class=\"ref-link\" id=\"cParker_2009_a\" href=\"#rParker_2009_a\">Parker, 2009</a></a>]",
        "By reformulating the mean-variance function with its Legendre-Fenchel dual [<a class=\"ref-link\" id=\"cBoyd_2004_a\" href=\"#rBoyd_2004_a\">Boyd and Vandenberghe, 2004</a>], we propose a new formulation for mean-variance optimization and use it to derive a computationally efficient algorithm that is based on stochastic cyclic block coordinate descent.\n2) We provide the sample complexity analysis of our proposed algorithm",
        "We introduce block coordinate descent methods",
        "We develop mean-variance optimization algorithms based on both nonconvex stochastic block stochastic gradient and stochastic block mirror descent",
        "We propose a new formulation of the meanvariance objective function that is based on its Legendre-Fenchel dual and derive novel algorithms that are based on the recent results in stochastic nonconvex block coordinate descent",
        "We report our block stochastic gradient-based algorithm in Section 3.3 and leave the details of the stochastic block mirror descent and stochastic gradient ascent based algorithms to Appendix C",
        "The objective function is reformulated based on the Legendre-Fenchel duality, and a novel stochastic block coordinate ascent algorithm is proposed with in-depth analysis",
        "Other reformulations of the meanvariance objective function are worth exploring, which will lead to new families of algorithms",
        "Distributional Reinforcement Learning [<a class=\"ref-link\" id=\"cBellemare_et+al_2016_a\" href=\"#rBellemare_et+al_2016_a\">Bellemare et al, 2016</a>] is strongly related to risk-sensitive policy search, and it is interesting to investigate the connections between risk-sensitive policy gradient methods and distributional Reinforcement Learning",
        "It is interesting to test the performance of the proposed algorithms together with other risk-sensitive Reinforcement Learning algorithms on highly-complex risk-sensitive tasks, such as autonomous driving problems and other challenging tasks"
    ],
    "summary": [
        "Risk management plays a central role in sequential decision-making problems, common in fields such as portfolio management [<a class=\"ref-link\" id=\"cLai_et+al_2011_a\" href=\"#rLai_et+al_2011_a\"><a class=\"ref-link\" id=\"cLai_et+al_2011_a\" href=\"#rLai_et+al_2011_a\">Lai et al, 2011</a></a>], autonomous driving [<a class=\"ref-link\" id=\"cMaurer_et+al_2016_a\" href=\"#rMaurer_et+al_2016_a\"><a class=\"ref-link\" id=\"cMaurer_et+al_2016_a\" href=\"#rMaurer_et+al_2016_a\">Maurer et al, 2016</a></a>], and healthcare [<a class=\"ref-link\" id=\"cParker_2009_a\" href=\"#rParker_2009_a\"><a class=\"ref-link\" id=\"cParker_2009_a\" href=\"#rParker_2009_a\">Parker, 2009</a></a>].",
        "The goal of this paper is to propose a mean-variance optimization algorithm that is both computationally efficient and has finite-sample analysis guarantees.",
        "We develop mean-variance optimization algorithms based on both nonconvex stochastic BSG and SBMD.",
        "The finite-sample analysis of our BSG-based algorithm reported in Section 4 is novel because there exists such analysis for convex stochastic BSG methods [<a class=\"ref-link\" id=\"cXu_2015_a\" href=\"#rXu_2015_a\">Xu and Yin, 2015</a>], we are not aware of similar results for their nonconvex version to the best our knowledge.",
        "We propose a new formulation of the meanvariance objective function that is based on its Legendre-Fenchel dual and derive novel algorithms that are based on the recent results in stochastic nonconvex block coordinate descent.",
        "Motivated by the recent papers by <a class=\"ref-link\" id=\"cNemirovski_et+al_2009_a\" href=\"#rNemirovski_et+al_2009_a\">Nemirovski et al [2009</a>], <a class=\"ref-link\" id=\"cGhadimi_2013_a\" href=\"#rGhadimi_2013_a\">Ghadimi and Lan [2013</a>], <a class=\"ref-link\" id=\"cXu_2015_a\" href=\"#rXu_2015_a\">Xu and Yin [2015</a>], and <a class=\"ref-link\" id=\"cDang_2015_a\" href=\"#rDang_2015_a\">Dang and Lan [2015</a>], in Section 4, we provide a finite-sample analysis for general nonconvex block stochastic gradient methods and apply it to Algorithm 1 with Option II.",
        "We first present a finite-sample analysis for the general class of nonconvex BSG algorithms [<a class=\"ref-link\" id=\"cXu_2013_a\" href=\"#rXu_2013_a\">Xu and Yin, 2013</a>], for which there are no established results, in Section 4.1.",
        "We provide a finite-sample analysis of the general nonconvex block stochastic gradient (BSG) method, where the problem formulation is given by min x\u2208Rn f (x) = E\u03be[F (x, \u03be)].",
        "The baseline algorithms are the vanilla policy gradient (PG), the mean-variance policy gradient in <a class=\"ref-link\" id=\"cTamar_et+al_2012_a\" href=\"#rTamar_et+al_2012_a\">Tamar et al [2012</a>], the stochastic gradient ascent (SGA) applied to our optimization problem (5), and the randomized coordinate ascent policy gradient (RCPG), i.e., the SBMD-based version of our algorithm.",
        "We optimize its Lagrangian parameter \u03bb by grid search and report the mean and variance of its return random variable as a Gaussian.2 Since the algorithms presented in the paper (MVP and RCPG) are policy gradient, we only compare them with Monte-Carlo based policy gradient algorithms and do not use any actor-critic algorithms, such as those in <a class=\"ref-link\" id=\"cPrashanth_2013_a\" href=\"#rPrashanth_2013_a\">Prashanth and Ghavamzadeh [2013</a>] and TRPO [<a class=\"ref-link\" id=\"cSchulman_et+al_2015_a\" href=\"#rSchulman_et+al_2015_a\">Schulman et al, 2015</a>], in the experiments.",
        "This paper is motivated to provide a risk-sensitive policy search algorithm with provable sample complexity analysis to maximize the mean-variance objective function.",
        "The objective function is reformulated based on the Legendre-Fenchel duality, and a novel stochastic block coordinate ascent algorithm is proposed with in-depth analysis.",
        "It is interesting to test the performance of the proposed algorithms together with other risk-sensitive RL algorithms on highly-complex risk-sensitive tasks, such as autonomous driving problems and other challenging tasks"
    ],
    "headline": "We develop a model-free policy search framework for mean-variance optimization with finite-sample error bound analysis ",
    "reference_links": [
        {
            "id": "Beck_2003_a",
            "entry": "Beck, A. and Teboulle, M. (2003). Mirror descent and nonlinear projected subgradient methods for convex optimization. Operations Research Letters, 31:167\u2013175.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beck%2C%20A.%20Teboulle%2C%20M.%20Mirror%20descent%20and%20nonlinear%20projected%20subgradient%20methods%20for%20convex%20optimization%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beck%2C%20A.%20Teboulle%2C%20M.%20Mirror%20descent%20and%20nonlinear%20projected%20subgradient%20methods%20for%20convex%20optimization%202003"
        },
        {
            "id": "Bellemare_et+al_2016_a",
            "entry": "Bellemare, M. G., Dabney, W., and Munos, R. (2016). A distributional perspective on reinforcement learning. In International Conference on Machine Learning.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bellemare%2C%20M.G.%20Dabney%2C%20W.%20Munos%2C%20R.%20A%20distributional%20perspective%20on%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bellemare%2C%20M.G.%20Dabney%2C%20W.%20Munos%2C%20R.%20A%20distributional%20perspective%20on%20reinforcement%20learning%202016"
        },
        {
            "id": "Bertsekas_1999_a",
            "entry": "Bertsekas, D. P. (1999). Nonlinear programming. Athena scientific Belmont.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bertsekas%2C%20D.P.%20Nonlinear%20programming.%20Athena%20scientific%20Belmont%201999"
        },
        {
            "id": "Bhatnagar_et+al_2013_a",
            "entry": "Bhatnagar, S., Prasad, H., and Prashanth, L. (2013). Stochastic Recursive Algorithms for Optimization, volume 434. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhatnagar%2C%20S.%20Prasad%2C%20H.%20Prashanth%2C%20L.%20Stochastic%20Recursive%20Algorithms%20for%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhatnagar%2C%20S.%20Prasad%2C%20H.%20Prashanth%2C%20L.%20Stochastic%20Recursive%20Algorithms%20for%202013"
        },
        {
            "id": "Borkar_2002_a",
            "entry": "Borkar, V. (2002). Q-learning for risk-sensitive control. Mathematics of operations research, 27(2):294\u2013311.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borkar%2C%20V.%20Q-learning%20for%20risk-sensitive%20control%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borkar%2C%20V.%20Q-learning%20for%20risk-sensitive%20control%202002"
        },
        {
            "id": "Borkar_2008_a",
            "entry": "Borkar, V. (2008). Stochastic Approximation: A Dynamical Systems Viewpoint. Cambridge University Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borkar%2C%20V.%20Stochastic%20Approximation%3A%20A%20Dynamical%20Systems%20Viewpoint%202008"
        },
        {
            "id": "Boyd_2004_a",
            "entry": "Boyd, S. and Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20S.%20Vandenberghe%2C%20L.%20Convex%20Optimization%202004"
        },
        {
            "id": "Chow_2014_a",
            "entry": "Chow, Y. and Ghavamzadeh, M. (2014). Algorithms for CVaR optimization in MDPs. In Advances in Neural Information Processing Systems, pages 3509\u20133517.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chow%2C%20Y.%20Ghavamzadeh%2C%20M.%20Algorithms%20for%20CVaR%20optimization%20in%20MDPs%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chow%2C%20Y.%20Ghavamzadeh%2C%20M.%20Algorithms%20for%20CVaR%20optimization%20in%20MDPs%202014"
        },
        {
            "id": "Chow_et+al_2018_a",
            "entry": "Chow, Y., Ghavamzadeh, M., Janson, L., and Pavone, M. (2018). Risk-constrained reinforcement learning with percentile risk criteria. Journal of Machine Learning Research.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chow%2C%20Y.%20Ghavamzadeh%2C%20M.%20Janson%2C%20L.%20Pavone%2C%20M.%20Risk-constrained%20reinforcement%20learning%20with%20percentile%20risk%20criteria%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chow%2C%20Y.%20Ghavamzadeh%2C%20M.%20Janson%2C%20L.%20Pavone%2C%20M.%20Risk-constrained%20reinforcement%20learning%20with%20percentile%20risk%20criteria%202018"
        },
        {
            "id": "Dalal_et+al_2018_a",
            "entry": "Dalal, G., Thoppe, G., Szorenyi, B., and Mannor, S. (2018). Finite sample analysis of two-timescale stochastic approximation with applications to reinforcement learning. In Bubeck, S., Perchet, V., and Rigollet, P., editors, Proceedings of the 31st Conference On Learning Theory, pages 1199\u20131233. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dalal%2C%20G.%20Thoppe%2C%20G.%20Szorenyi%2C%20B.%20Mannor%2C%20S.%20Finite%20sample%20analysis%20of%20two-timescale%20stochastic%20approximation%20with%20applications%20to%20reinforcement%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dalal%2C%20G.%20Thoppe%2C%20G.%20Szorenyi%2C%20B.%20Mannor%2C%20S.%20Finite%20sample%20analysis%20of%20two-timescale%20stochastic%20approximation%20with%20applications%20to%20reinforcement%20learning%202018"
        },
        {
            "id": "Dang_2015_a",
            "entry": "Dang, C. D. and Lan, G. (2015). Stochastic block mirror descent methods for nonsmooth and stochastic optimization. SIAM Journal on Optimization, 25(2):856\u2013881.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dang%2C%20C.D.%20Lan%2C%20G.%20Stochastic%20block%20mirror%20descent%20methods%20for%20nonsmooth%20and%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dang%2C%20C.D.%20Lan%2C%20G.%20Stochastic%20block%20mirror%20descent%20methods%20for%20nonsmooth%20and%20stochastic%20optimization%202015"
        },
        {
            "id": "Du_et+al_2017_a",
            "entry": "Du, S. S., Chen, J., Li, L., Xiao, L., and Zhou, D. (2017). Stochastic variance reduction methods for policy evaluation. arXiv preprint arXiv:1702.07944.",
            "arxiv_url": "https://arxiv.org/pdf/1702.07944"
        },
        {
            "id": "Ghadimi_2013_a",
            "entry": "Ghadimi, S. and Lan, G. (2013). Stochastic first-and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341\u20132368.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghadimi%2C%20S.%20Lan%2C%20G.%20Stochastic%20first-and%20zeroth-order%20methods%20for%20nonconvex%20stochastic%20programming%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghadimi%2C%20S.%20Lan%2C%20G.%20Stochastic%20first-and%20zeroth-order%20methods%20for%20nonconvex%20stochastic%20programming%202013"
        },
        {
            "id": "Hastie_et+al_2001_a",
            "entry": "Hastie, T., Tibshirani, R., and Friedman, J. (2001). The Elements of Statistical Learning. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hastie%2C%20T.%20Tibshirani%2C%20R.%20Friedman%2C%20J.%20The%20Elements%20of%20Statistical%20Learning%202001"
        },
        {
            "id": "Lai_et+al_2011_a",
            "entry": "Lai, T., Xing, H., and Chen, Z. (2011). Mean-variance portfolio optimization when means and covariances are unknown. The Annals of Applied Statistics, pages 798\u2013823.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lai%2C%20T.%20Xing%2C%20H.%20Chen%2C%20Z.%20Mean-variance%20portfolio%20optimization%20when%20means%20and%20covariances%20are%20unknown%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lai%2C%20T.%20Xing%2C%20H.%20Chen%2C%20Z.%20Mean-variance%20portfolio%20optimization%20when%20means%20and%20covariances%20are%20unknown%202011"
        },
        {
            "id": "Li_2000_a",
            "entry": "Li, D. and Ng, W. (2000). Optimal dynamic portfolio selection: Multiperiod mean-variance formulation. Mathematical Finance, 10(3):387\u2013406.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20D.%20Ng%2C%20W.%20Optimal%20dynamic%20portfolio%20selection%3A%20Multiperiod%20mean-variance%20formulation%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20D.%20Ng%2C%20W.%20Optimal%20dynamic%20portfolio%20selection%3A%20Multiperiod%20mean-variance%20formulation%202000"
        },
        {
            "id": "Liu_et+al_2018_a",
            "entry": "Liu, B., Gemp, I., Ghavamzadeh, M., Liu, J., Mahadevan, S., and Petrik, M. (2018). Proximal gradient temporal difference learning: Stable reinforcement learning with polynomial sample complexity. Journal of Artificial Intelligence Research.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20B.%20Gemp%2C%20I.%20Ghavamzadeh%2C%20M.%20Liu%2C%20J.%20Proximal%20gradient%20temporal%20difference%20learning%3A%20Stable%20reinforcement%20learning%20with%20polynomial%20sample%20complexity%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20B.%20Gemp%2C%20I.%20Ghavamzadeh%2C%20M.%20Liu%2C%20J.%20Proximal%20gradient%20temporal%20difference%20learning%3A%20Stable%20reinforcement%20learning%20with%20polynomial%20sample%20complexity%202018"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Liu, B., Liu, J., Ghavamzadeh, M., Mahadevan, S., and Petrik, M. (2015). Finite-sample analysis of proximal gradient td algorithms. In Conference on Uncertainty in Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20B.%20Liu%2C%20J.%20Ghavamzadeh%2C%20M.%20Mahadevan%2C%20S.%20Finite-sample%20analysis%20of%20proximal%20gradient%20td%20algorithms%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20B.%20Liu%2C%20J.%20Ghavamzadeh%2C%20M.%20Mahadevan%2C%20S.%20Finite-sample%20analysis%20of%20proximal%20gradient%20td%20algorithms%202015"
        },
        {
            "id": "Luo_1992_a",
            "entry": "Luo, Z. and Tseng, P. (1992). On the convergence of the coordinate descent method for convex differentiable minimization. Journal of Optimization Theory and Applications, 72(1):7\u201335.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20Z.%20Tseng%2C%20P.%20On%20the%20convergence%20of%20the%20coordinate%20descent%20method%20for%20convex%20differentiable%20minimization%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20Z.%20Tseng%2C%20P.%20On%20the%20convergence%20of%20the%20coordinate%20descent%20method%20for%20convex%20differentiable%20minimization%201992"
        },
        {
            "id": "Mairal_2013_a",
            "entry": "Mairal, J. (2013). Stochastic majorization-minimization algorithms for large-scale optimization. In Advances in Neural Information Processing Systems, pages 2283\u20132291.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mairal%2C%20J.%20Stochastic%20majorization-minimization%20algorithms%20for%20large-scale%20optimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mairal%2C%20J.%20Stochastic%20majorization-minimization%20algorithms%20for%20large-scale%20optimization%202013"
        },
        {
            "id": "Mannor_2011_a",
            "entry": "Mannor, S. and Tsitsiklis, J. (2011). Mean-variance optimization in markov decision processes. In Proceedings of the 28th International Conference on Machine Learning (ICML-11).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mannor%2C%20S.%20Tsitsiklis%2C%20J.%20Mean-variance%20optimization%20in%20markov%20decision%20processes%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mannor%2C%20S.%20Tsitsiklis%2C%20J.%20Mean-variance%20optimization%20in%20markov%20decision%20processes%202011"
        },
        {
            "id": "Markowitz_et+al_2000_a",
            "entry": "Markowitz, H. M., Todd, G. P., and Sharpe, W. F. (2000). Mean-variance analysis in portfolio choice and capital markets, volume 66. John Wiley & Sons.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Markowitz%2C%20H.M.%20Todd%2C%20G.P.%20Sharpe%2C%20W.F.%20Mean-variance%20analysis%20in%20portfolio%20choice%20and%20capital%20markets%2C%20volume%2066%202000"
        },
        {
            "id": "Maurer_et+al_2016_a",
            "entry": "Maurer, M., Gerdes, C., Lenz, B., and Winner, H. (2016). Autonomous driving: technical, legal and social aspects. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maurer%2C%20M.%20Gerdes%2C%20C.%20Lenz%2C%20B.%20Winner%2C%20H.%20Autonomous%20driving%3A%20technical%2C%20legal%20and%20social%20aspects%202016"
        },
        {
            "id": "Nemirovski_et+al_2009_a",
            "entry": "Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009). Robust stochastic approximation approach to stochastic programming. SIAM Journal on optimization, 19(4):1574\u20131609.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovski%2C%20A.%20Juditsky%2C%20A.%20Lan%2C%20G.%20Shapiro%2C%20A.%20Robust%20stochastic%20approximation%20approach%20to%20stochastic%20programming%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nemirovski%2C%20A.%20Juditsky%2C%20A.%20Lan%2C%20G.%20Shapiro%2C%20A.%20Robust%20stochastic%20approximation%20approach%20to%20stochastic%20programming%202009"
        },
        {
            "id": "Nesterov_2012_a",
            "entry": "Nesterov, Y. (2012). Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM Journal on Optimization, 22(2):341\u2013362.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Y.%20Efficiency%20of%20coordinate%20descent%20methods%20on%20huge-scale%20optimization%20problems%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Y.%20Efficiency%20of%20coordinate%20descent%20methods%20on%20huge-scale%20optimization%20problems%202012"
        },
        {
            "id": "Parker_2009_a",
            "entry": "Parker, D. (2009). Managing risk in healthcare: understanding your safety culture using the manchester patient safety framework. Journal of nursing management, 17(2):218\u2013222.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parker%2C%20D.%20Managing%20risk%20in%20healthcare%3A%20understanding%20your%20safety%20culture%20using%20the%20manchester%20patient%20safety%20framework%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parker%2C%20D.%20Managing%20risk%20in%20healthcare%3A%20understanding%20your%20safety%20culture%20using%20the%20manchester%20patient%20safety%20framework%202009"
        },
        {
            "id": "Prashanth_2013_a",
            "entry": "Prashanth, L. A. and Ghavamzadeh, M. (2013). Actor-critic algorithms for risk-sensitive mdps. In Advances in Neural Information Processing Systems, pages 252\u2013260.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Prashanth%2C%20L.A.%20Ghavamzadeh%2C%20M.%20Actor-critic%20algorithms%20for%20risk-sensitive%20mdps%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Prashanth%2C%20L.A.%20Ghavamzadeh%2C%20M.%20Actor-critic%20algorithms%20for%20risk-sensitive%20mdps%202013"
        },
        {
            "id": "Prashanth_2016_a",
            "entry": "Prashanth, L. A. and Ghavamzadeh, M. (2016). Variance-constrained actor-critic algorithms for discounted and average reward mdps. Machine Learning Journal, 105(3):367\u2013417.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Prashanth%2C%20L.A.%20Ghavamzadeh%2C%20M.%20Variance-constrained%20actor-critic%20algorithms%20for%20discounted%20and%20average%20reward%20mdps%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Prashanth%2C%20L.A.%20Ghavamzadeh%2C%20M.%20Variance-constrained%20actor-critic%20algorithms%20for%20discounted%20and%20average%20reward%20mdps%202016"
        },
        {
            "id": "Puterman_1994_a",
            "entry": "Puterman, M. L. (1994). Markov Decision Processes. Wiley Interscience, New York, USA.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Puterman%2C%20M.L.%20Markov%20Decision%20Processes.%20Wiley%20Interscience%201994"
        },
        {
            "id": "Razaviyayn_et+al_2013_a",
            "entry": "Razaviyayn, M., Hong, M., and Luo, Z. (2013). A unified convergence analysis of block successive minimization methods for nonsmooth optimization. SIAM Journal on Optimization, 23(2):1126\u2013 1153.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Razaviyayn%2C%20M.%20Hong%2C%20M.%20Luo%2C%20Z.%20A%20unified%20convergence%20analysis%20of%20block%20successive%20minimization%20methods%20for%20nonsmooth%20optimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Razaviyayn%2C%20M.%20Hong%2C%20M.%20Luo%2C%20Z.%20A%20unified%20convergence%20analysis%20of%20block%20successive%20minimization%20methods%20for%20nonsmooth%20optimization%202013"
        },
        {
            "id": "Schulman_et+al_2015_a",
            "entry": "Schulman, J., Levine, S., Abbeel, P., Jordan, M., and Moritz, P. (2015). Trust region policy optimization. In International Conference on Machine Learning, pages 1889\u20131897.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schulman%2C%20J.%20Levine%2C%20S.%20Abbeel%2C%20P.%20Jordan%2C%20M.%20Trust%20region%20policy%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schulman%2C%20J.%20Levine%2C%20S.%20Abbeel%2C%20P.%20Jordan%2C%20M.%20Trust%20region%20policy%20optimization%202015"
        },
        {
            "id": "Silver_et+al_2014_a",
            "entry": "Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M. (2014). Deterministic policy gradient algorithms. In ICML, pages 387\u2013395.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silver%2C%20D.%20Lever%2C%20G.%20Heess%2C%20N.%20Degris%2C%20T.%20Deterministic%20policy%20gradient%20algorithms%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silver%2C%20D.%20Lever%2C%20G.%20Heess%2C%20N.%20Degris%2C%20T.%20Deterministic%20policy%20gradient%20algorithms%202014"
        },
        {
            "id": "Sobel_1982_a",
            "entry": "Sobel, M. J. (1982). The variance of discounted markov decision processes. Journal of Applied Probability, 19(04):794\u2013802.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sobel%2C%20M.J.%20The%20variance%20of%20discounted%20markov%20decision%20processes%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sobel%2C%20M.J.%20The%20variance%20of%20discounted%20markov%20decision%20processes%201982"
        },
        {
            "id": "Sutton_1998_a",
            "entry": "Sutton, R. and Barto, A. G. (1998). Reinforcement Learning: An Introduction. MIT Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutton%2C%20R.%20Barto%2C%20A.G.%20Reinforcement%20Learning%3A%20An%20Introduction%201998"
        },
        {
            "id": "Tamar_et+al_2012_a",
            "entry": "Tamar, A., Castro, D., and Mannor, S. (2012). Policy gradients with variance related risk criteria. In ICML, pages 935\u2013942.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tamar%2C%20A.%20Castro%2C%20D.%20Mannor%2C%20S.%20Policy%20gradients%20with%20variance%20related%20risk%20criteria%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tamar%2C%20A.%20Castro%2C%20D.%20Mannor%2C%20S.%20Policy%20gradients%20with%20variance%20related%20risk%20criteria%202012"
        },
        {
            "id": "Tamar_et+al_2015_a",
            "entry": "Tamar, A., Chow, Y., Ghavamzadeh, M., and Mannor, S. (2015a). Policy gradient for coherent risk measures. In NIPS, pages 1468\u20131476.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tamar%2C%20A.%20Chow%2C%20Y.%20Ghavamzadeh%2C%20M.%20Mannor%2C%20S.%20Policy%20gradient%20for%20coherent%20risk%20measures%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tamar%2C%20A.%20Chow%2C%20Y.%20Ghavamzadeh%2C%20M.%20Mannor%2C%20S.%20Policy%20gradient%20for%20coherent%20risk%20measures%202015"
        },
        {
            "id": "Tamar_et+al_2015_b",
            "entry": "Tamar, A., Glassner, Y., and Mannor, S. (2015b). Optimizing the cvar via sampling. In AAAI Conference on Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tamar%2C%20A.%20Glassner%2C%20Y.%20Mannor%2C%20S.%20Optimizing%20the%20cvar%20via%20sampling%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tamar%2C%20A.%20Glassner%2C%20Y.%20Mannor%2C%20S.%20Optimizing%20the%20cvar%20via%20sampling%202015"
        },
        {
            "id": "Tamar_et+al_2014_a",
            "entry": "Tamar, A., Mannor, S., and Xu, H. (2014). Scaling up robust mdps using function approximation. In International Conference on Machine Learning, pages 181\u2013189.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tamar%2C%20A.%20Mannor%2C%20S.%20Xu%2C%20H.%20Scaling%20up%20robust%20mdps%20using%20function%20approximation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tamar%2C%20A.%20Mannor%2C%20S.%20Xu%2C%20H.%20Scaling%20up%20robust%20mdps%20using%20function%20approximation%202014"
        },
        {
            "id": "Tseng_2001_a",
            "entry": "Tseng, P. (2001). Convergence of a block coordinate descent method for nondifferentiable minimization. Journal of optimization theory and applications, 109(3):475\u2013494.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tseng%2C%20P.%20Convergence%20of%20a%20block%20coordinate%20descent%20method%20for%20nondifferentiable%20minimization%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tseng%2C%20P.%20Convergence%20of%20a%20block%20coordinate%20descent%20method%20for%20nondifferentiable%20minimization%202001"
        },
        {
            "id": "Williams_1992_a",
            "entry": "Williams, R. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229\u2013256.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20R.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20R.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992"
        },
        {
            "id": "Wright_2015_a",
            "entry": "Wright, S. (2015). Coordinate descent algorithms. Mathematical Programming, 151(1):3\u201334.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wright%2C%20S.%20Coordinate%20descent%20algorithms%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wright%2C%20S.%20Coordinate%20descent%20algorithms%202015"
        },
        {
            "id": "Xu_2013_a",
            "entry": "Xu, Y. and Yin, W. (2013). A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion. SIAM Journal on imaging sciences, 6(3):1758\u20131789.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Y.%20Yin%2C%20W.%20A%20block%20coordinate%20descent%20method%20for%20regularized%20multiconvex%20optimization%20with%20applications%20to%20nonnegative%20tensor%20factorization%20and%20completion%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Y.%20Yin%2C%20W.%20A%20block%20coordinate%20descent%20method%20for%20regularized%20multiconvex%20optimization%20with%20applications%20to%20nonnegative%20tensor%20factorization%20and%20completion%202013"
        },
        {
            "id": "Xu_2015_a",
            "entry": "Xu, Y. and Yin, W. (2015). Block stochastic gradient iteration for convex and nonconvex optimization. SIAM Journal on Optimization, 25(3):1686\u20131716.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Y.%20Yin%2C%20W.%20Block%20stochastic%20gradient%20iteration%20for%20convex%20and%20nonconvex%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Y.%20Yin%2C%20W.%20Block%20stochastic%20gradient%20iteration%20for%20convex%20and%20nonconvex%20optimization%202015"
        }
    ]
}
