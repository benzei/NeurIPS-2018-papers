{
    "filename": "7571-from-stochastic-planning-to-marginal-map.pdf",
    "metadata": {
        "title": "From Stochastic Planning to Marginal MAP",
        "author": "Hao Cui, Radu Marinescu, Roni Khardon",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7571-from-stochastic-planning-to-marginal-map.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "It is well known that the problems of stochastic planning and probabilistic inference are closely related. This paper makes two contributions in this context. The first is to provide an analysis of the recently developed SOGBOFA heuristic planning algorithm that was shown to be effective for problems with large factored state and action spaces. It is shown that SOGBOFA can be seen as a specialized inference algorithm that computes its solutions through a combination of a symbolic variant of belief propagation and gradient ascent. The second contribution is a new solver for Marginal MAP (MMAP) inference. We introduce a new reduction from MMAP to maximum expected utility problems which are suitable for the symbolic computation in SOGBOFA. This yields a novel algebraic gradient-based solver (AGS) for MMAP. An experimental evaluation illustrates the potential of AGS in solving difficult MMAP problems."
    },
    "keywords": [
        {
            "term": "dynamic Bayesian network",
            "url": "https://en.wikipedia.org/wiki/dynamic_Bayesian_network"
        },
        {
            "term": "automatic differentiation",
            "url": "https://en.wikipedia.org/wiki/automatic_differentiation"
        },
        {
            "term": "markov decision process",
            "url": "https://en.wikipedia.org/wiki/markov_decision_process"
        },
        {
            "term": "influence diagrams",
            "url": "https://en.wikipedia.org/wiki/influence_diagrams"
        },
        {
            "term": "Bayesian Network",
            "url": "https://en.wikipedia.org/wiki/Bayesian_Network"
        },
        {
            "term": "conditional probability table",
            "url": "https://en.wikipedia.org/wiki/conditional_probability_table"
        },
        {
            "term": "MMAP",
            "url": "https://en.wikipedia.org/wiki/MMAP"
        },
        {
            "term": "belief propagation",
            "url": "https://en.wikipedia.org/wiki/belief_propagation"
        }
    ],
    "highlights": [
        "This corresponds to Marginal MAP problems with MAP variables at the roots and a single evidence node at a leaf",
        "Our analysis shows that the value computed by SOGBOFA\u2019s computation graph is identical to the solution of Belief Propagation (BP) when conditioned on actions",
        "Finite horison planning can be captured using a dynamic Bayesian network (DBN) where state and action variables at each time step are represented explicitly and the conditional probability table of variables are given by the transition probabilities",
        "The marginals calculated by AROLLOUT are identical to the marginals calculated by Belief Propagation on the dynamic Bayesian network generated by the planning problem, conditioned on the initial state, initial action and rollout policy, and with no evidence",
        "The paper identifies a connection between a successful heuristic for planning in large factored spaces and belief propagation",
        "While previous work has shown how inference can be used for planning, this paper shows how ideas from planning can be used for inference"
    ],
    "key_statements": [
        "This corresponds to Marginal MAP problems with MAP variables at the roots and a single evidence node at a leaf",
        "Our analysis shows that the value computed by SOGBOFA\u2019s computation graph is identical to the solution of Belief Propagation (BP) when conditioned on actions",
        "We provide a new reduction from Marginal MAP problems to maximum expected utility whose output satisfies these requirements",
        "Finite horison planning can be captured using a dynamic Bayesian network (DBN) where state and action variables at each time step are represented explicitly and the conditional probability table of variables are given by the transition probabilities",
        "The marginals calculated by AROLLOUT are identical to the marginals calculated by Belief Propagation on the dynamic Bayesian network generated by the planning problem, conditioned on the initial state, initial action and rollout policy, and with no evidence",
        "Mixed Product BP uses belief propagation and is related to algebraic gradient-based solver, but in Mixed Product BP the search over MAP variables is integrated into the messages of Belief Propagation and like Belief Propagation it can be derived from the corresponding optimization problem",
        "The paper identifies a connection between a successful heuristic for planning in large factored spaces and belief propagation",
        "While previous work has shown how inference can be used for planning, this paper shows how ideas from planning can be used for inference"
    ],
    "summary": [
        "This corresponds to MMAP problems with MAP variables at the roots and a single evidence node at a leaf.",
        "Finite horison planning can be captured using a dynamic Bayesian network (DBN) where state and action variables at each time step are represented explicitly and the CPTs of variables are given by the transition probabilities.",
        "AROLLOUT and SOGBOFA perform on-line planning by estimating the value of initial actions at the current state s, Q\u03c0(s, a), where a fixed rollout policy \u03c0, typically a random policy, is used in future steps.",
        "The algorithm performs a forward pass calculating p(x), an approximation of the true marginal p(x), for any node x in the graph.",
        "The transitions and reward are given by the following RDDL expressions where primed variants of variables represent the value of the variable after performing the action.",
        "The main observation in SOGBOFA is that instead of calculating numerical values, as illustrated in the example, we can use the expressions computing these values to construct an explicit directed acyclic graph representing the computation steps, where the last node represents the expectation of the cumulative reward.",
        "Given concrete marginal for the action variables at the first step, i.e., a0, one can plug in that value into the computation graph and compute the value of the final Q node.",
        "The marginals calculated by AROLLOUT are identical to the marginals calculated by BP on the DBN generated by the planning problem, conditioned on the initial state, initial action and rollout policy, and with no evidence.",
        "Consider SOGBOFA with a fixed rollout policy \u03c0 and w.l.o.g. assume a single binary node V representing cumulative reward.1 For a start action a we have Q = p(V = 1|a, \u03c0) = E(V |a, \u03c0).",
        "1There are standard reductions showing how to translate a general reward to a binary variable whose expectations are proportional so that the optimization problems are equivalent.",
        "MPBP uses belief propagation and is related to AGS, but in MPBP the search over MAP variables is integrated into the messages of BP and like BP it can be derived from the corresponding optimization problem.",
        "To explore the performance of the algorithms we vary the proportion of MAP variables in each instance, and for each fixed ratio we generate 20 MMAP problems by picking the MAP nodes at random.",
        "This suggests a general scheme for approximate MMAP algorithms where the MAP value is represented using an explicit computation graph which is optimized directly through automatic differentiation.",
        "We believe that these connections can be further explored to yield improvements in both fields"
    ],
    "headline": "We introduce a new reduction from Marginal MAP to maximum expected utility problems which are suitable for the symbolic computation in SOGBOFA",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Craig Boutilier, Thomas Dean, and Steve Hanks. Planning under uncertainty: Structural assumptions and computational leverage. In Proceedings of the Second European Workshop on Planning, pages 157\u2013171, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boutilier%2C%20Craig%20Dean%2C%20Thomas%20Hanks%2C%20Steve%20Planning%20under%20uncertainty%3A%20Structural%20assumptions%20and%20computational%20leverage%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boutilier%2C%20Craig%20Dean%2C%20Thomas%20Hanks%2C%20Steve%20Planning%20under%20uncertainty%3A%20Structural%20assumptions%20and%20computational%20leverage%201995"
        },
        {
            "id": "2",
            "entry": "[2] Hao Cui and Roni Khardon. Online symbolic gradient-based optimization for factored action MDPs. In Proc. of the International Joint Conference on Artificial Intelligence, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cui%2C%20Hao%20Khardon%2C%20Roni%20Online%20symbolic%20gradient-based%20optimization%20for%20factored%20action%20MDPs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cui%2C%20Hao%20Khardon%2C%20Roni%20Online%20symbolic%20gradient-based%20optimization%20for%20factored%20action%20MDPs%202016"
        },
        {
            "id": "3",
            "entry": "[3] Hao Cui, Roni Khardon, Alan Fern, and Prasad Tadepalli. Factored MCTS for large scale stochastic planning. In Proc. of the AAAI Conference on Artificial Intelligence, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cui%2C%20Hao%20Khardon%2C%20Roni%20Fern%2C%20Alan%20Tadepalli%2C%20Prasad%20Factored%20MCTS%20for%20large%20scale%20stochastic%20planning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cui%2C%20Hao%20Khardon%2C%20Roni%20Fern%2C%20Alan%20Tadepalli%2C%20Prasad%20Factored%20MCTS%20for%20large%20scale%20stochastic%20planning%202015"
        },
        {
            "id": "4",
            "entry": "[4] Carmel Domshlak and Jorg Hoffmann. Fast probabilistic planning through weighted model counting. In Proc. of the International Conference on Automated Planning and Scheduling, pages 243\u2013252, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Domshlak%2C%20Carmel%20Hoffmann%2C%20Jorg%20Fast%20probabilistic%20planning%20through%20weighted%20model%20counting%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Domshlak%2C%20Carmel%20Hoffmann%2C%20Jorg%20Fast%20probabilistic%20planning%20through%20weighted%20model%20counting%202006"
        },
        {
            "id": "5",
            "entry": "[5] Thomas Furmston and David Barber. Variational methods for reinforcement learning. In Proceedings of the International Conference on Artificial Intelligence and Statistics, AISTATS, pages 241\u2013248, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Furmston%2C%20Thomas%20Barber%2C%20David%20Variational%20methods%20for%20reinforcement%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Furmston%2C%20Thomas%20Barber%2C%20David%20Variational%20methods%20for%20reinforcement%20learning%202010"
        },
        {
            "id": "6",
            "entry": "[6] Andreas Griewank and Andrea Walther. Evaluating derivatives - principles and techniques of algorithmic differentiation (2. ed.). SIAM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Griewank%2C%20Andreas%20Walther%2C%20Andrea%20Evaluating%20derivatives%20-%20principles%20and%20techniques%20of%20algorithmic%20differentiation%202008"
        },
        {
            "id": "7",
            "entry": "[7] Thomas Keller and Malte Helmert. Trial-based heuristic tree search for finite horizon MDPs. In Proc. of the International Conference on Automated Planning and Scheduling, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Keller%2C%20Thomas%20Helmert%2C%20Malte%20Trial-based%20heuristic%20tree%20search%20for%20finite%20horizon%20MDPs%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Keller%2C%20Thomas%20Helmert%2C%20Malte%20Trial-based%20heuristic%20tree%20search%20for%20finite%20horizon%20MDPs%202013"
        },
        {
            "id": "8",
            "entry": "[8] Igor Kiselev and Pascal Poupart. A novel single-dbn generative model for optimizing POMDP controllers by probabilistic inference. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 3112\u2013 3113. AAAI Press, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Igor%20Kiselev%20and%20Pascal%20Poupart.%20A%20novel%20single-dbn%20generative%20model%20for%20optimizing%20POMDP%20controllers%20by%20probabilistic%20inference%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Igor%20Kiselev%20and%20Pascal%20Poupart.%20A%20novel%20single-dbn%20generative%20model%20for%20optimizing%20POMDP%20controllers%20by%20probabilistic%20inference%202014"
        },
        {
            "id": "9",
            "entry": "[9] Andrey Kolobov, Peng Dai, Mausam Mausam, and Daniel S Weld. Reverse iterative deepening for finitehorizon MDPs with large branching factors. In Proc. of the International Conference on Automated Planning and Scheduling, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kolobov%2C%20Andrey%20Dai%2C%20Peng%20Mausam%2C%20Mausam%20Weld%2C%20Daniel%20S.%20Reverse%20iterative%20deepening%20for%20finitehorizon%20MDPs%20with%20large%20branching%20factors%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kolobov%2C%20Andrey%20Dai%2C%20Peng%20Mausam%2C%20Mausam%20Weld%2C%20Daniel%20S.%20Reverse%20iterative%20deepening%20for%20finitehorizon%20MDPs%20with%20large%20branching%20factors%202012"
        },
        {
            "id": "10",
            "entry": "[10] Junkyu Lee, Radu Marinescu, and Rina Dechter. Applying search based probabilistic inference algorithms to probabilistic conformant planning: Preliminary results. In Proceedings of the International Symposium on Artificial Intelligence and Mathematics (ISAIM), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Junkyu%20Marinescu%2C%20Radu%20Dechter%2C%20Rina%20Applying%20search%20based%20probabilistic%20inference%20algorithms%20to%20probabilistic%20conformant%20planning%3A%20Preliminary%20results%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Junkyu%20Marinescu%2C%20Radu%20Dechter%2C%20Rina%20Applying%20search%20based%20probabilistic%20inference%20algorithms%20to%20probabilistic%20conformant%20planning%3A%20Preliminary%20results%202016"
        },
        {
            "id": "11",
            "entry": "[11] Junkyu Lee, Radu Marinescu, Rina Dechter, and Alexander T. Ihler. From exact to anytime solutions for marginal MAP. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 3255\u20133262. AAAI Press, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Junkyu%20Marinescu%2C%20Radu%20Dechter%2C%20Rina%20Ihler%2C%20Alexander%20T.%20From%20exact%20to%20anytime%20solutions%20for%20marginal%20MAP%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Junkyu%20Marinescu%2C%20Radu%20Dechter%2C%20Rina%20Ihler%2C%20Alexander%20T.%20From%20exact%20to%20anytime%20solutions%20for%20marginal%20MAP%202016"
        },
        {
            "id": "12",
            "entry": "[12] Qiang Liu and Alexander T. Ihler. Belief propagation for structured decision making. In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), pages 523\u2013532, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Qiang%20Ihler%2C%20Alexander%20T.%20Belief%20propagation%20for%20structured%20decision%20making%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Qiang%20Ihler%2C%20Alexander%20T.%20Belief%20propagation%20for%20structured%20decision%20making%202012"
        },
        {
            "id": "13",
            "entry": "[13] Qiang Liu and Alexander T. Ihler. Variational algorithms for marginal MAP. Journal of Machine Learning Research, 14(1):3165\u20133200, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Qiang%20Ihler%2C%20Alexander%20T.%20Variational%20algorithms%20for%20marginal%20MAP%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Qiang%20Ihler%2C%20Alexander%20T.%20Variational%20algorithms%20for%20marginal%20MAP%202013"
        },
        {
            "id": "14",
            "entry": "[14] Radu Marinescu, Junkyu Lee, Alexander T. Ihler, and Rina Dechter. Anytime best+depth-first search for bounding marginal MAP. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, pages 3775\u20133782, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marinescu%2C%20Radu%20Lee%2C%20Junkyu%20Ihler%2C%20Alexander%20T.%20Dechter%2C%20Rina%20Anytime%20best%2Bdepth-first%20search%20for%20bounding%20marginal%20MAP%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marinescu%2C%20Radu%20Lee%2C%20Junkyu%20Ihler%2C%20Alexander%20T.%20Dechter%2C%20Rina%20Anytime%20best%2Bdepth-first%20search%20for%20bounding%20marginal%20MAP%202017"
        },
        {
            "id": "15",
            "entry": "[15] Denis Deratani Maua. Equivalences between maximum a posteriori inference in bayesian networks and maximum expected utility computation in influence diagrams. International Journal Approximate Reasoning, 68:211\u2013229, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maua%2C%20Denis%20Deratani%20Equivalences%20between%20maximum%20a%20posteriori%20inference%20in%20bayesian%20networks%20and%20maximum%20expected%20utility%20computation%20in%20influence%20diagrams%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maua%2C%20Denis%20Deratani%20Equivalences%20between%20maximum%20a%20posteriori%20inference%20in%20bayesian%20networks%20and%20maximum%20expected%20utility%20computation%20in%20influence%20diagrams%202016"
        },
        {
            "id": "16",
            "entry": "[16] Martin Mladenov, Vaishak Belle, and Kristian Kersting. The symbolic interior point method. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, pages 1199\u20131205, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mladenov%2C%20Martin%20Belle%2C%20Vaishak%20Kersting%2C%20Kristian%20The%20symbolic%20interior%20point%20method%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mladenov%2C%20Martin%20Belle%2C%20Vaishak%20Kersting%2C%20Kristian%20The%20symbolic%20interior%20point%20method%202017"
        },
        {
            "id": "17",
            "entry": "[17] Gerhard Neumann. Variational inference for policy search in changing situations. In Proceedings of the 28th International Conference on Machine Learning, ICML, pages 817\u2013824, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neumann%2C%20Gerhard%20Variational%20inference%20for%20policy%20search%20in%20changing%20situations%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neumann%2C%20Gerhard%20Variational%20inference%20for%20policy%20search%20in%20changing%20situations%202011"
        },
        {
            "id": "18",
            "entry": "[18] Duc Thien Nguyen, Akshat Kumar, and Hoong Chuin Lau. Collective multiagent sequential decision making under uncertainty. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 3036\u2013 3043, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20Duc%20Thien%20Kumar%2C%20Akshat%20Lau%2C%20Hoong%20Chuin%20Collective%20multiagent%20sequential%20decision%20making%20under%20uncertainty%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20Duc%20Thien%20Kumar%2C%20Akshat%20Lau%2C%20Hoong%20Chuin%20Collective%20multiagent%20sequential%20decision%20making%20under%20uncertainty%202017"
        },
        {
            "id": "19",
            "entry": "[19] Davide Nitti, Vaishak Belle, and Luc De Raedt. Planning in discrete and continuous markov decision processes by probabilistic programming. In ECML/PKDD (2), volume 9285 of Lecture Notes in Computer Science, pages 327\u2013342.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nitti%2C%20Davide%20Belle%2C%20Vaishak%20Raedt%2C%20Luc%20De%20Planning%20in%20discrete%20and%20continuous%20markov%20decision%20processes%20by%20probabilistic%20programming",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nitti%2C%20Davide%20Belle%2C%20Vaishak%20Raedt%2C%20Luc%20De%20Planning%20in%20discrete%20and%20continuous%20markov%20decision%20processes%20by%20probabilistic%20programming"
        },
        {
            "id": "20",
            "entry": "[20] James D. Park and Adnan Darwiche. Complexity results and approximation strategies for map explanations. Journal of AI Research, 21(1):101\u2013133, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Park%2C%20James%20D.%20Darwiche%2C%20Adnan%20Complexity%20results%20and%20approximation%20strategies%20for%20map%20explanations%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Park%2C%20James%20D.%20Darwiche%2C%20Adnan%20Complexity%20results%20and%20approximation%20strategies%20for%20map%20explanations%202004"
        },
        {
            "id": "21",
            "entry": "[21] Judea Pearl. Probabilistic reasoning in intelligent systems - networks of plausible inference. Morgan Kaufmann series in representation and reasoning. Morgan Kaufmann, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pearl%2C%20Judea%20Probabilistic%20reasoning%20in%20intelligent%20systems%20-%20networks%20of%20plausible%20inference.%20Morgan%20Kaufmann%20series%20in%20representation%20and%20reasoning%201989"
        },
        {
            "id": "22",
            "entry": "[22] Martin L. Puterman. Markov decision processes: Discrete stochastic dynamic programming. Wiley, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Puterman%2C%20Martin%20L.%20Markov%20decision%20processes%3A%20Discrete%20stochastic%20dynamic%20programming%201994"
        },
        {
            "id": "23",
            "entry": "[23] Regis Sabbadin, Nathalie Peyrard, and Nicklas Forsell. A framework and a mean-field algorithm for the local control of spatial processes. International Journal Approximate Reasoning, 53(1):66\u201386, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sabbadin%2C%20Regis%20Peyrard%2C%20Nathalie%20Forsell%2C%20Nicklas%20A%20framework%20and%20a%20mean-field%20algorithm%20for%20the%20local%20control%20of%20spatial%20processes%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sabbadin%2C%20Regis%20Peyrard%2C%20Nathalie%20Forsell%2C%20Nicklas%20A%20framework%20and%20a%20mean-field%20algorithm%20for%20the%20local%20control%20of%20spatial%20processes%202012"
        },
        {
            "id": "24",
            "entry": "[24] Scott Sanner. Relational dynamic influence diagram language (rddl): Language description. Unpublished Manuscript. Australian National University, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sanner%2C%20Scott%20Relational%20dynamic%20influence%20diagram%20language%20%28rddl%29%3A%20Language%20description.%20Unpublished%20Manuscript%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sanner%2C%20Scott%20Relational%20dynamic%20influence%20diagram%20language%20%28rddl%29%3A%20Language%20description.%20Unpublished%20Manuscript%202010"
        },
        {
            "id": "25",
            "entry": "[25] Marc Toussaint and Amos Storkey. Probabilistic inference for solving discrete and continuous state Markov decision processes. In Proceedings of the International Conference on Machine Learning, ICML, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Toussaint%2C%20Marc%20Storkey%2C%20Amos%20Probabilistic%20inference%20for%20solving%20discrete%20and%20continuous%20state%20Markov%20decision%20processes%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Toussaint%2C%20Marc%20Storkey%2C%20Amos%20Probabilistic%20inference%20for%20solving%20discrete%20and%20continuous%20state%20Markov%20decision%20processes%202006"
        },
        {
            "id": "26",
            "entry": "[26] Jan-Willem van de Meent, Brooks Paige, David Tolpin, and Frank Wood. Black-box policy search with probabilistic programs. In Proceedings of the International Conference on Artificial Intelligence and Statistics, AISTATS, pages 1195\u20131204, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20de%20Meent%2C%20Jan-Willem%20Paige%2C%20Brooks%20Tolpin%2C%20David%20Wood%2C%20Frank%20Black-box%20policy%20search%20with%20probabilistic%20programs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20de%20Meent%2C%20Jan-Willem%20Paige%2C%20Brooks%20Tolpin%2C%20David%20Wood%2C%20Frank%20Black-box%20policy%20search%20with%20probabilistic%20programs%202016"
        }
    ]
}
