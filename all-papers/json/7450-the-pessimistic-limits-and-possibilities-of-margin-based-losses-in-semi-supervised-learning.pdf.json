{
    "filename": "7450-the-pessimistic-limits-and-possibilities-of-margin-based-losses-in-semi-supervised-learning.pdf",
    "metadata": {
        "title": "The Pessimistic Limits and Possibilities of Margin-based Losses in Semi-supervised Learning",
        "author": "Jesse Krijthe, Marco Loog",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7450-the-pessimistic-limits-and-possibilities-of-margin-based-losses-in-semi-supervised-learning.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Consider a classification problem where we have both labeled and unlabeled data available. We show that for linear classifiers defined by convex margin-based surrogate losses that are decreasing, it is impossible to construct any semi-supervised approach that is able to guarantee an improvement over the supervised classifier measured by this surrogate loss on the labeled and unlabeled data. For convex margin-based loss functions that also increase, we demonstrate safe improvements are possible."
    },
    "keywords": [
        {
            "term": "semi supervised learning",
            "url": "https://en.wikipedia.org/wiki/semi_supervised_learning"
        },
        {
            "term": "loss function",
            "url": "https://en.wikipedia.org/wiki/loss_function"
        },
        {
            "term": "support vector machine",
            "url": "https://en.wikipedia.org/wiki/support_vector_machine"
        },
        {
            "term": "supervised learning",
            "url": "https://en.wikipedia.org/wiki/supervised_learning"
        }
    ],
    "highlights": [
        "Semi-supervised learning has been reported to deliver encouraging results in various settings, e.g. for object detection in computer vision (<a class=\"ref-link\" id=\"cRasmus_et+al_2015_a\" href=\"#rRasmus_et+al_2015_a\"><a class=\"ref-link\" id=\"cRasmus_et+al_2015_a\" href=\"#rRasmus_et+al_2015_a\">Rasmus et al, 2015</a></a>), protein function prediction from sequence data (<a class=\"ref-link\" id=\"cWeston_et+al_2005_a\" href=\"#rWeston_et+al_2005_a\"><a class=\"ref-link\" id=\"cWeston_et+al_2005_a\" href=\"#rWeston_et+al_2005_a\">Weston et al, 2005</a></a>) or prediction of cancer recurrence (<a class=\"ref-link\" id=\"cShi_2011_a\" href=\"#rShi_2011_a\"><a class=\"ref-link\" id=\"cShi_2011_a\" href=\"#rShi_2011_a\">Shi & Zhang, 2011</a></a>) in the bio-medical domain and part-of-speech tagging in natural language processing (<a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\"><a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\"><a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\">Elworthy, 1994</a></a></a>)",
        "We show under what conditions it is possible in this case to come up with a semi-supervised classifier that provides safe improvements over the supervised classifier",
        "We first show that for the class of decreasing loss functions it is impossible to derive any semi-supervised learning strategy that is not worse than the supervised classifier for all possible labelings of the unlabeled data",
        "Unlike, for instance, a hinge loss that is not regularized by something like a 2-norm of the weight vector, many interesting objective functions are strictly convex. This result means that for decreasing loss functions it is impossible to construct a semi-supervised learner that is different from the supervised learner and, in terms of its surrogate loss on the full training data, is never outperformed by the supervised solution",
        "We have shown that for the class of convex margin-based losses, the fact whether they are decreasing or not plays a key role in whether they admit safe semi-supervised procedures",
        "We have shown that, without making additional assumptions, it is impossible to construct safe semi-supervised procedures for decreasing losses by deriving what partial assignment of the unlabeled objects leads to the recovery of the supervised classifier from a semi-supervised objective"
    ],
    "key_statements": [
        "Semi-supervised learning has been reported to deliver encouraging results in various settings, e.g. for object detection in computer vision (<a class=\"ref-link\" id=\"cRasmus_et+al_2015_a\" href=\"#rRasmus_et+al_2015_a\"><a class=\"ref-link\" id=\"cRasmus_et+al_2015_a\" href=\"#rRasmus_et+al_2015_a\">Rasmus et al, 2015</a></a>), protein function prediction from sequence data (<a class=\"ref-link\" id=\"cWeston_et+al_2005_a\" href=\"#rWeston_et+al_2005_a\"><a class=\"ref-link\" id=\"cWeston_et+al_2005_a\" href=\"#rWeston_et+al_2005_a\">Weston et al, 2005</a></a>) or prediction of cancer recurrence (<a class=\"ref-link\" id=\"cShi_2011_a\" href=\"#rShi_2011_a\"><a class=\"ref-link\" id=\"cShi_2011_a\" href=\"#rShi_2011_a\">Shi & Zhang, 2011</a></a>) in the bio-medical domain and part-of-speech tagging in natural language processing (<a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\"><a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\"><a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\">Elworthy, 1994</a></a></a>)",
        "We show under what conditions it is possible in this case to come up with a semi-supervised classifier that provides safe improvements over the supervised classifier",
        "We first show that for the class of decreasing loss functions it is impossible to derive any semi-supervised learning strategy that is not worse than the supervised classifier for all possible labelings of the unlabeled data",
        "Unlike, for instance, a hinge loss that is not regularized by something like a 2-norm of the weight vector, many interesting objective functions are strictly convex. This result means that for decreasing loss functions it is impossible to construct a semi-supervised learner that is different from the supervised learner and, in terms of its surrogate loss on the full training data, is never outperformed by the supervised solution",
        "While our results applied to logistic regression corroborates their claim, the quadratic loss shows a counterexample. This shows that for losses that strictly increase over some interval, even safe improvements can be possible in the diagnostic setting",
        "Darnst\u00e4dt et al (2013) prove that a slightly altered and more precise formulation of this conjecture holds when hypothesis classes have finite VC-dimension, while they show that it does not hold for more complex hypothesis classes. Whereas these works consider generalization bounds on the error rate in the PAC learning framework, in our work, we considered a more conservative or pessimistic setting of safe semi-supervised learning, while considering performance on a finite sample in terms of the surrogate loss",
        "We have shown that for the class of convex margin-based losses, the fact whether they are decreasing or not plays a key role in whether they admit safe semi-supervised procedures",
        "We have shown that, without making additional assumptions, it is impossible to construct safe semi-supervised procedures for decreasing losses by deriving what partial assignment of the unlabeled objects leads to the recovery of the supervised classifier from a semi-supervised objective"
    ],
    "summary": [
        "Semi-supervised learning has been reported to deliver encouraging results in various settings, e.g. for object detection in computer vision (<a class=\"ref-link\" id=\"cRasmus_et+al_2015_a\" href=\"#rRasmus_et+al_2015_a\"><a class=\"ref-link\" id=\"cRasmus_et+al_2015_a\" href=\"#rRasmus_et+al_2015_a\">Rasmus et al, 2015</a></a>), protein function prediction from sequence data (<a class=\"ref-link\" id=\"cWeston_et+al_2005_a\" href=\"#rWeston_et+al_2005_a\"><a class=\"ref-link\" id=\"cWeston_et+al_2005_a\" href=\"#rWeston_et+al_2005_a\">Weston et al, 2005</a></a>) or prediction of cancer recurrence (<a class=\"ref-link\" id=\"cShi_2011_a\" href=\"#rShi_2011_a\"><a class=\"ref-link\" id=\"cShi_2011_a\" href=\"#rShi_2011_a\">Shi & Zhang, 2011</a></a>) in the bio-medical domain and part-of-speech tagging in natural language processing (<a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\"><a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\"><a class=\"ref-link\" id=\"cElworthy_1994_a\" href=\"#rElworthy_1994_a\">Elworthy, 1994</a></a></a>).",
        "We first show that for the class of decreasing loss functions it is impossible to derive any semi-supervised learning strategy that is not worse than the supervised classifier for all possible labelings of the unlabeled data.",
        "We first formalize this definition of safety, consider the cases of hard and soft labeling, and come to our negative results: for many loss functions safe semi-supervision is, not possible.",
        "Is it possible to construct some semi-supervised strategy that has this guaranteed improvement over the supervised solution for margin-based surrogate losses?",
        "The constraint set C is the set of all possible classifiers that can be obtained by minimizing the semi-supervised loss for any vector of responsibilities q assigned to the unlabeled data, i.e.,",
        "If is a decreasing convex margin-based loss function where for each unlabeled object x, the derivatives 0( x>wsup) and 0(x>wsup) exist, we can recover wsup by minimizing the semi-supervised loss by assigning responsibilities q 2 [0, 1]U as q=",
        "Let be a decreasing convex margin-based loss function and wsup be the unique minimizer of a strictly convex R (w, X, y) and suppose for each unlabeled object x, the derivatives 0( x>wsup) and 0(x>wsup) exist.",
        "This result means that for decreasing loss functions it is impossible to construct a semi-supervised learner that is different from the supervised learner and, in terms of its surrogate loss on the full training data, is never outperformed by the supervised solution.",
        "The range of the responsibilities will always be between [0, 1], meaning the labels of the unlabeled data can always be set in such a way that the supervised solution is obtained from the semi-supervised objective function.",
        "The improvement guarantee, in terms of classification accuracy, of the safe semi-supervised SVM by <a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\">Li & Zhou (2015</a>) depends on the assumption that the true labeling of the objects is given by one of the low-density separators that their algorithm finds.",
        "We have shown that for the class of convex margin-based losses, the fact whether they are decreasing or not plays a key role in whether they admit safe semi-supervised procedures.",
        "We have shown that, without making additional assumptions, it is impossible to construct safe semi-supervised procedures for decreasing losses by deriving what partial assignment of the unlabeled objects leads to the recovery of the supervised classifier from a semi-supervised objective.",
        "A less strict guarantee might admit performance improvement by aiming for semi-supervised solutions that in expectation rather than on any particular dataset, outperform their supervised counterparts"
    ],
    "headline": "We show that for linear classifiers defined by convex margin-based surrogate losses that are decreasing, it is impossible to construct any semi-supervised approach that is able to guarantee an improvement over the supervised classifier measured by this surrogate loss on the labeled and unlabeled data",
    "reference_links": [
        {
            "id": "Bartlett_et+al_2006_a",
            "entry": "Bartlett, Peter L, Jordan, Michael I., and McAuliffe, Jon D. Convexity, Classification, and Risk Bounds. Journal of the American Statistical Association, 101(473):138\u2013156, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%20Peter%20L%20Jordan%20Michael%20I%20and%20McAuliffe%20Jon%20D%20Convexity%20Classification%20and%20Risk%20Bounds%20Journal%20of%20the%20American%20Statistical%20Association%20101473138156%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%20Peter%20L%20Jordan%20Michael%20I%20and%20McAuliffe%20Jon%20D%20Convexity%20Classification%20and%20Risk%20Bounds%20Journal%20of%20the%20American%20Statistical%20Association%20101473138156%202006"
        },
        {
            "id": "Ben-David_et+al_2008_a",
            "entry": "Ben-David, Shai, Lu, Tyler, and P\u00e1l, David. Does Unlabeled Data Provably Help? Worst-case Analysis of the Sample Complexity of Semi-Supervised Learning. In Proceedings of the 21st Annual Conference on Learning Theory, pp. 33\u201344, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20Shai%20Lu%2C%20Tyler%20P%C3%A1l%2C%20David%20Does%20Unlabeled%20Data%20Provably%20Help%3F%20Worst-case%20Analysis%20of%20the%20Sample%20Complexity%20of%20Semi-Supervised%20Learning%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20Shai%20Lu%2C%20Tyler%20P%C3%A1l%2C%20David%20Does%20Unlabeled%20Data%20Provably%20Help%3F%20Worst-case%20Analysis%20of%20the%20Sample%20Complexity%20of%20Semi-Supervised%20Learning%202008"
        },
        {
            "id": "Cozman_2006_a",
            "entry": "Cozman, F and Cohen, Ira. Risks of Semi-Supervised Learning. In Chapelle, Olivier, Sch\u00f6lkopf, Bernhard, and Zien, A (eds.), Semi-Supervised Learning, chapter 4, pp. 56\u201372. MIT press, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cozman%2C%20F.%20Cohen%2C%20Ira%20Risks%20of%20Semi-Supervised%20Learning%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cozman%2C%20F.%20Cohen%2C%20Ira%20Risks%20of%20Semi-Supervised%20Learning%202006"
        },
        {
            "id": "Darnstaedt_et+al_2013_a",
            "entry": "Darnst\u00e4dt, Malte, Simon, HU, and Sz\u00f6r\u00e9nyi, Bal\u00e1zs. Unlabeled Data Does Provably Help. In 30th International Symposium on Theoretical Aspects of Computer Science, pp. 185\u2013196, 2013. doi: 10.4230/LIPIcs.STACS.2013.185.",
            "crossref": "https://dx.doi.org/10.4230/LIPIcs.STACS.2013.185",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.4230/LIPIcs.STACS.2013.185"
        },
        {
            "id": "Elworthy_1994_a",
            "entry": "Elworthy, David. Does Baum-Welch re-estimation help taggers? In Proceedings of the 4th Conference on Applied Natural Language Processing, pp. 53\u201358, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Elworthy%2C%20David%20Does%20Baum-Welch%20re-estimation%20help%20taggers%3F%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Elworthy%2C%20David%20Does%20Baum-Welch%20re-estimation%20help%20taggers%3F%201994"
        },
        {
            "id": "Fung_2001_a",
            "entry": "Fung, Glenn and Mangasarian, Olvi L. Proximal Support Vector Machine Classifiers. In KDD \u201901 Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 77\u201386, 2001. doi: 10.1145/502512.502527.",
            "crossref": "https://dx.doi.org/10.1145/502512.502527",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/502512.502527"
        },
        {
            "id": "Hastie_et+al_1994_a",
            "entry": "Hastie, Trevor, Tibshirani, Robert, and Buja, Andreas. Flexible Discriminant Analysis by Optimal Scoring. Journal of the Amercian Statistical Association, 89(428):1255\u20131270, 1994. ISSN 0162-1459. doi: 10.1080/01621459.1994.10476866.",
            "crossref": "https://dx.doi.org/10.1080/01621459.1994.10476866",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1080/01621459.1994.10476866"
        },
        {
            "id": "Joachims_1999_a",
            "entry": "Joachims, Thorsten. Transductive inference for text classification using support vector machines. In Proceedings of the 16th International Conference on Machine Learning, pp. 200\u2013209. Morgan Kaufmann Publishers, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Joachims%2C%20Thorsten%20Transductive%20inference%20for%20text%20classification%20using%20support%20vector%20machines%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Joachims%2C%20Thorsten%20Transductive%20inference%20for%20text%20classification%20using%20support%20vector%20machines%201999"
        },
        {
            "id": "Kawakita_2014_a",
            "entry": "Kawakita, Masanori and Takeuchi, Jun\u2019ichi. Safe semi-supervised learning based on weighted likelihood. Neural Networks, 53:146\u2013164, may 2014. doi: 10.1016/j.neunet.2014.01.016.",
            "crossref": "https://dx.doi.org/10.1016/j.neunet.2014.01.016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.neunet.2014.01.016"
        },
        {
            "id": "Krijthe_0000_a",
            "entry": "Krijthe, Jesse Hendrik and Loog, Marco. Robust Semi-supervised Least Squares Classification by Implicit Constraints. Pattern Recognition, 63:115\u2013126, 2017a. ISSN 00313203. doi: 10.1016/j. patcog.2016.09.009.",
            "crossref": "https://dx.doi.org/10.1016/j.patcog.2016.09.009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.patcog.2016.09.009"
        },
        {
            "id": "Krijthe_2017_a",
            "entry": "Krijthe, Jesse Hendrik and Loog, Marco. Projected Estimators for Robust Semi-supervised Classification. Machine Learning, 106(7):993\u20131008, 2017b. doi: 10.1007/s10994-017-5626-8.",
            "crossref": "https://dx.doi.org/10.1007/s10994-017-5626-8",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/s10994-017-5626-8"
        },
        {
            "id": "Li_2015_a",
            "entry": "Li, Yu-Feng and Zhou, Zhi-Hua. Towards Making Unlabeled Data Never Hurt. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(1):175\u2013188, jan 2015. doi: 10.1109/TPAMI. 2014.2299812.",
            "crossref": "https://dx.doi.org/10.1109/TPAMI.2014.2299812",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TPAMI.2014.2299812"
        },
        {
            "id": "Springer_2010_a",
            "entry": "Springer, 2010. doi: 10.1007/ 978-3-642-15883-4_19.",
            "crossref": "https://dx.doi.org/10.1007/978-3-642-15883-4_19"
        },
        {
            "id": "Loog_2016_a",
            "entry": "Loog, Marco. Contrastive Pessimistic Likelihood Estimation for Semi-Supervised Classification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(3):462\u2013475, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loog%2C%20Marco%20Contrastive%20Pessimistic%20Likelihood%20Estimation%20for%20Semi-Supervised%20Classification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Loog%2C%20Marco%20Contrastive%20Pessimistic%20Likelihood%20Estimation%20for%20Semi-Supervised%20Classification%202016"
        },
        {
            "id": "Poggio_2003_a",
            "entry": "Poggio, Tomaso and Smale, Steve. The Mathematics of Learning: Dealing with Data. Notices of the AMS, 50(5):537\u2013544, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Poggio%2C%20Tomaso%20Smale%2C%20Steve%20The%20Mathematics%20of%20Learning%3A%20Dealing%20with%20Data.%20Notices%20of%20the%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Poggio%2C%20Tomaso%20Smale%2C%20Steve%20The%20Mathematics%20of%20Learning%3A%20Dealing%20with%20Data.%20Notices%20of%20the%202003"
        },
        {
            "id": "Rasmus_et+al_2015_a",
            "entry": "Rasmus, Antti, Valpola, Harri, Honkala, Mikko, Berglund, Mathias, and Raiko, Tapani. Semisupervised learning with Ladder Networks. In Advances in Neural Information Processing Systems, pp. 3546\u20133554, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rasmus%2C%20Antti%20Valpola%2C%20Harri%20Honkala%2C%20Mikko%20Berglund%2C%20Mathias%20Semisupervised%20learning%20with%20Ladder%20Networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rasmus%2C%20Antti%20Valpola%2C%20Harri%20Honkala%2C%20Mikko%20Berglund%2C%20Mathias%20Semisupervised%20learning%20with%20Ladder%20Networks%202015"
        },
        {
            "id": "Rasmussen_2005_a",
            "entry": "Rasmussen, Carl Edward and Williams, Christopher K. I. Gaussian Processes for Machine Learning. MIT Press, apr 2005. ISBN 9780262182539.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rasmussen%2C%20Carl%20Edward%20Williams%2C%20Christopher%20K.I.%20Gaussian%20Processes%20for%20Machine%20Learning%202005-04"
        },
        {
            "id": "Rifkin_et+al_2003_a",
            "entry": "Rifkin, Ryan, Yeo, Gene, and Poggio, Tomaso. Regularized least-squares classification. In Suykens, Johan A. K., Horvath, Gabor, Basu, Sankar, Micchelli, Charles, and Vandewalle, Joos (eds.), Nato Science Series Sub Series III Computer and Systems Sciences 190, pp. 131\u2013154. IOS Press, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rifkin%2C%20Ryan%20Yeo%2C%20Gene%20Poggio%2C%20Tomaso%20Regularized%20least-squares%20classification%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rifkin%2C%20Ryan%20Yeo%2C%20Gene%20Poggio%2C%20Tomaso%20Regularized%20least-squares%20classification%202003"
        },
        {
            "id": "Seeger_2001_a",
            "entry": "Seeger, Matthias. Learning with labeled and unlabeled data. Technical report, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seeger%2C%20Matthias%20Learning%20with%20labeled%20and%20unlabeled%20data%202001"
        },
        {
            "id": "Shi_2011_a",
            "entry": "Shi, Mingguang and Zhang, Bing. Semi-supervised learning improves gene expression-based prediction of cancer recurrence. Bioinformatics, 27(21):3017\u20133023, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shi%2C%20Mingguang%20Zhang%2C%20Bing%20Semi-supervised%20learning%20improves%20gene%20expression-based%20prediction%20of%20cancer%20recurrence%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shi%2C%20Mingguang%20Zhang%2C%20Bing%20Semi-supervised%20learning%20improves%20gene%20expression-based%20prediction%20of%20cancer%20recurrence%202011"
        },
        {
            "id": "Sion_1958_a",
            "entry": "Sion, Maurice. On general minimax theorems. Pacific J. Math, 8(1):171\u2013176, 1958.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sion%2C%20Maurice%20On%20general%20minimax%20theorems%201958",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sion%2C%20Maurice%20On%20general%20minimax%20theorems%201958"
        },
        {
            "id": "Sokolovska_et+al_2008_a",
            "entry": "Sokolovska, Nataliya, Capp\u00e9, Olivier, and Yvon, Francois. The asymptotics of semi-supervised learning in discriminative probabilistic models. In Cohen, William W., McCallum, Andrew, and Roweis, Sam T. (eds.), Proceedings of the 25th International Conference on Machine Learning, pp. 984\u2013991, Helsinki, Finland, 2008. ACM Press. Suykens, Johan A. K. and Vandewalle, J. Least Squares Support Vector Machine Classifiers. Neural Processing Letters, 9:293\u2013300, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sokolovska%2C%20Nataliya%20Capp%C3%A9%2C%20Olivier%20Yvon%2C%20Francois%20The%20asymptotics%20of%20semi-supervised%20learning%20in%20discriminative%20probabilistic%20models%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sokolovska%2C%20Nataliya%20Capp%C3%A9%2C%20Olivier%20Yvon%2C%20Francois%20The%20asymptotics%20of%20semi-supervised%20learning%20in%20discriminative%20probabilistic%20models%202008"
        },
        {
            "id": "Weston_et+al_2005_a",
            "entry": "Weston, Jason, Leslie, Christina, Ie, Eugene, Zhou, Dengyong, Elisseeff, Andre, and Noble, William Stafford. Semi-supervised protein classification using cluster kernels. Bioinformatics, 21 (15):3241\u20137, aug 2005. ISSN 1367-4803. doi: 10.1093/bioinformatics/bti497.",
            "crossref": "https://dx.doi.org/10.1093/bioinformatics/bti497",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1093/bioinformatics/bti497"
        }
    ]
}
