{
    "filename": "7310-see-and-think-disentangling-semantic-scene-completion.pdf",
    "metadata": {
        "title": "See and Think: Disentangling Semantic Scene Completion",
        "author": "Shice Liu, YU HU, Yiming Zeng, Qiankun Tang, Beibei Jin, Yinhe Han, Xiaowei Li",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7310-see-and-think-disentangling-semantic-scene-completion.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Semantic scene completion predicts volumetric occupancy and object category of a 3D scene, which helps intelligent agents to understand and interact with the surroundings. In this work, we propose a disentangled framework, sequentially carrying out 2D semantic segmentation, 2D-3D reprojection and 3D semantic scene completion. This three-stage framework has three advantages: (1) explicit semantic segmentation significantly boosts performance; (2) flexible fusion ways of sensor data bring good extensibility; (3) progress in any subtask will promote the holistic performance. Experimental results show that regardless of inputing a single depth or RGB-D, our framework can generate high-quality semantic scene completion, and outperforms state-of-the-art approaches on both synthetic and real datasets."
    },
    "keywords": [
        {
            "term": "SLAM",
            "url": "https://en.wikipedia.org/wiki/SLAM"
        },
        {
            "term": "object detection",
            "url": "https://en.wikipedia.org/wiki/object_detection"
        }
    ],
    "highlights": [
        "For a single depth or RGB-D input, See And Think Network can finish semantic scene completion efficiently in a single-branch manner",
        "It can be seen that for the depth input, See And Think Network yields higher intersection over union for both SUNCG-D and SUNCG-RGB-D input datasets by 17.9% and 5.7% respectively, and the effect will be more prominent for the RGB-D input",
        "Is there any difference for different inputs? the mean intersection over union of single-branch RGB-D input and depth input on NYUv2 dataset are approximately equal, we find See And Think Network has different preferences in terms of two types of inputs",
        "We have shown that atrous spatial pyramid poolings benefits semantic scene completion, which is an example that more effective components in TNet account for higher performance on completion",
        "We propose See And Think Network, a disentangled semantic scene completion framework",
        "We provide single-branch and double-branch implementations within the See And Think Network framework, which demonstrates the See And Think Network framework is effective, extensible and evolvable"
    ],
    "key_statements": [
        "For a single depth or RGB-D input, See And Think Network can finish semantic scene completion efficiently in a single-branch manner",
        "Works on semantic scene completion is limited in visible surface partition [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] and shape recovery without considering object category or environment context [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>]",
        "We demonstrate that explicit semantic segmentation in See And Think Network boosts semantic scene completion, as is similar to human perception",
        "We briefly review related works on semantic segmentation and volume reconstruction, and detail semantic scene completion from two perspectives, model fitting based completion and voxel reasoning based completion",
        "As is shown in Figure 5, we introduce two double-branch fusion ways, SNetFuse and TNetFuse, to fuse RGB and depth",
        "We mainly evaluate our framework with intersection over union (IoU) between our predictions and ground truth, and two tasks are considered: scene completion and semantic scene completion",
        "Table 1 presents the semantic scene completion results on NYUv2 dataset with comparison to some alternative approaches",
        "It can be seen that for the depth input, See And Think Network yields higher intersection over union for both SUNCG-D and SUNCG-RGB-D input datasets by 17.9% and 5.7% respectively, and the effect will be more prominent for the RGB-D input",
        "To exclude the effect of the network structure, we maintain the same structure with See And Think Network but do not initialize SNet) with the weights trained on the semantic segmentation task",
        "Is there any difference for different inputs? the mean intersection over union of single-branch RGB-D input and depth input on NYUv2 dataset are approximately equal, we find See And Think Network has different preferences in terms of two types of inputs",
        "We have shown that atrous spatial pyramid poolings benefits semantic scene completion, which is an example that more effective components in TNet account for higher performance on completion",
        "We propose See And Think Network, a disentangled semantic scene completion framework",
        "We provide single-branch and double-branch implementations within the See And Think Network framework, which demonstrates the See And Think Network framework is effective, extensible and evolvable"
    ],
    "summary": [
        "For a single depth or RGB-D input, SATNet can finish semantic scene completion efficiently in a single-branch manner.",
        "Following the 2D-3D reprojection layer, TNet is proposed to accomplish higher-level semantic scene completion by the volume of lower-level semantic scene surface \u03c0 (SN et (I)) \u2208 RD\u00d7SX\u00d7SY \u00d7SZ .",
        "Unlike SSCNet, TNet takes advantage of semantic scene surface and leverages multiscale feature extractors to yield better performance.",
        "The branches of RGB and depth share the same architecture but their parameters are not tied, enabling two branches to extract useful features for semantic segmentation respectively.",
        "Another double-branch fusion way is to fuse RGB and depth at the end of the TNet, which integrates the two semantic scene completion results generated respectively by RGB and depth for a better one.",
        "Table 1 presents the semantic scene completion results on NYUv2 dataset with comparison to some alternative approaches.",
        "For each category, we acquire generally higher IoUs. 2D semantic segmentation for depth or RGB can promote the final completion.",
        "Figure 6 shows the qualitative results, where we complete six different scenes via double-branch TNetFuse and compare the results with SSCNet. Well as SSCNet works for many cases, it fails in the objects which are hard to distinguish from depth.",
        "It can be seen that for the depth input, SATNet yields higher IoU for both SUNCG-D and SUNCG-RGBD datasets by 17.9% and 5.7% respectively, and the effect will be more prominent for the RGB-D input.",
        "We intend to demonstrate that disentangling semantic segmentation is much more helpful for semantic scene completion, by means of presenting several ablation studies.",
        "To exclude the effect of the network structure, we maintain the same structure with SATNet but do not initialize SNet) with the weights trained on the semantic segmentation task.",
        "The mean IoU of single-branch RGB-D input and depth input on NYUv2 dataset are approximately equal, we find SATNet has different preferences in terms of two types of inputs.",
        "The result of double-branch SNetFuse is better than single-branch RGB-D or depth input on both datasets, on account of more accurate semantic segmentation by RGB-D than by a single RGB or depth.",
        "(2) Progress in TNet. In the previous discussion, we have shown that ASPP benefits semantic scene completion, which is an example that more effective components in TNet account for higher performance on completion.",
        "It consists of SNet for 2D semantic segmentation, a 2D-3D reprojection layer, and TNet for semantic scene completion.",
        "Experimental results show SATNet outperforms the state-of-the-art approaches"
    ],
    "headline": "We propose a disentangled framework, sequentially carrying out 2D semantic segmentation, 2D-3D reprojection and 3D semantic scene completion",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Shuran Song, Fisher Yu, Andy Zeng, Angel X Chang, Manolis Savva, and Thomas Funkhouser. Semantic Scene Completion from a Single Depth Image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 190\u2013198, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Shuran%20Yu%2C%20Fisher%20Zeng%2C%20Andy%20Chang%2C%20Angel%20X.%20Semantic%20Scene%20Completion%20from%20a%20Single%20Depth%20Image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Shuran%20Yu%2C%20Fisher%20Zeng%2C%20Andy%20Chang%2C%20Angel%20X.%20Semantic%20Scene%20Completion%20from%20a%20Single%20Depth%20Image%202017"
        },
        {
            "id": "2",
            "entry": "[2] Saurabh Gupta, Pablo Arbelaez, and Jitendra Malik. Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 564\u2013571, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Saurabh%20Arbelaez%2C%20Pablo%20Malik%2C%20Jitendra%20Perceptual%20Organization%20and%20Recognition%20of%20Indoor%20Scenes%20from%20RGB-D%20Images%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Saurabh%20Arbelaez%2C%20Pablo%20Malik%2C%20Jitendra%20Perceptual%20Organization%20and%20Recognition%20of%20Indoor%20Scenes%20from%20RGB-D%20Images%202013"
        },
        {
            "id": "3",
            "entry": "[3] Xiaofeng Ren, Liefeng Bo, and Dieter Fox. RGB-(D) Scene Labeling: Features and Algorithms. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2759\u20132766, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20Xiaofeng%20Bo%2C%20Liefeng%20Fox%2C%20Dieter%20RGB-%28D%29%20Scene%20Labeling%3A%20Features%20and%20Algorithms%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20Xiaofeng%20Bo%2C%20Liefeng%20Fox%2C%20Dieter%20RGB-%28D%29%20Scene%20Labeling%3A%20Features%20and%20Algorithms%202012"
        },
        {
            "id": "4",
            "entry": "[4] Michael Firman, Oisin Mac Aodha, Simon Julier, and Gabriel J Brostow. Structured Prediction of Unobserved Voxels from a Single Depth Image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5431\u20135440, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Firman%2C%20Michael%20Aodha%2C%20Oisin%20Mac%20Julier%2C%20Simon%20Brostow%2C%20Gabriel%20J.%20Structured%20Prediction%20of%20Unobserved%20Voxels%20from%20a%20Single%20Depth%20Image%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Firman%2C%20Michael%20Aodha%2C%20Oisin%20Mac%20Julier%2C%20Simon%20Brostow%2C%20Gabriel%20J.%20Structured%20Prediction%20of%20Unobserved%20Voxels%20from%20a%20Single%20Depth%20Image%202016"
        },
        {
            "id": "5",
            "entry": "[5] Duc Thanh Nguyen, Binh-Son Hua, Khoi Tran, Quang-Hieu Pham, and Sai-Kit Yeung. A Field Model for Repairing 3D Shapes. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5676\u20135684, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20Duc%20Thanh%20Hua%2C%20Binh-Son%20Tran%2C%20Khoi%20Pham%2C%20Quang-Hieu%20A%20Field%20Model%20for%20Repairing%203D%20Shapes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20Duc%20Thanh%20Hua%2C%20Binh-Son%20Tran%2C%20Khoi%20Pham%2C%20Quang-Hieu%20A%20Field%20Model%20for%20Repairing%203D%20Shapes%202016"
        },
        {
            "id": "6",
            "entry": "[6] Andre Bernardes Soares Guedes, Teofilo Emidio de Campos, and Adrian Hilton. Semantic Scene Completion Combining Colour and Depth: Preliminary Experiments. arXiv preprint arXiv:1802.04735, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04735"
        },
        {
            "id": "7",
            "entry": "[7] E Bruce Goldstein. The Blackwell Handbook of Sensation and Perception. John Wiley & Sons, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldstein%2C%20E.Bruce%20The%20Blackwell%20Handbook%20of%20Sensation%20and%20Perception%202008"
        },
        {
            "id": "8",
            "entry": "[8] Allison B Sekuler and Stephen E Palmer. Perception of Partly Occluded Objects: A Microgenetic Analysis. Journal of Experimental Psychology: General, 121(1):95, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sekuler%2C%20Allison%20B.%20Palmer%2C%20Stephen%20E.%20Perception%20of%20Partly%20Occluded%20Objects%3A%20A%20Microgenetic%20Analysis%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sekuler%2C%20Allison%20B.%20Palmer%2C%20Stephen%20E.%20Perception%20of%20Partly%20Occluded%20Objects%3A%20A%20Microgenetic%20Analysis%201992"
        },
        {
            "id": "9",
            "entry": "[9] Saurabh Gupta, Ross Girshick, Pablo Arbel\u00e1ez, and Jitendra Malik. Learning Rich Features from RGB-D Images for Object Detection and Segmentation. In European Conference on Computer Vision (ECCV), pages 345\u2013360, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Saurabh%20Girshick%2C%20Ross%20Arbel%C3%A1ez%2C%20Pablo%20Malik%2C%20Jitendra%20Learning%20Rich%20Features%20from%20RGB-D%20Images%20for%20Object%20Detection%20and%20Segmentation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Saurabh%20Girshick%2C%20Ross%20Arbel%C3%A1ez%2C%20Pablo%20Malik%2C%20Jitendra%20Learning%20Rich%20Features%20from%20RGB-D%20Images%20for%20Object%20Detection%20and%20Segmentation%202014"
        },
        {
            "id": "10",
            "entry": "[10] Fisher Yu and Vladlen Koltun. Multi-Scale Context Aggregation by Dilated Convolutions. arXiv preprint arXiv:1511.07122, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.07122"
        },
        {
            "id": "11",
            "entry": "[11] Guosheng Lin, Anton Milan, Chunhua Shen, and Ian Reid. RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5168\u20135177, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Guosheng%20Milan%2C%20Anton%20Shen%2C%20Chunhua%20Reid%2C%20Ian%20RefineNet%3A%20Multi-Path%20Refinement%20Networks%20for%20High-Resolution%20Semantic%20Segmentation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Guosheng%20Milan%2C%20Anton%20Shen%2C%20Chunhua%20Reid%2C%20Ian%20RefineNet%3A%20Multi-Path%20Refinement%20Networks%20for%20High-Resolution%20Semantic%20Segmentation%202017"
        },
        {
            "id": "12",
            "entry": "[12] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2881\u20132890, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Hengshuang%20Shi%2C%20Jianping%20Qi%2C%20Xiaojuan%20Wang%2C%20Xiaogang%20Pyramid%20Scene%20Parsing%20Network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Hengshuang%20Shi%2C%20Jianping%20Qi%2C%20Xiaojuan%20Wang%2C%20Xiaogang%20Pyramid%20Scene%20Parsing%20Network%202017"
        },
        {
            "id": "13",
            "entry": "[13] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(4):834\u2013848, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Liang-Chieh%20Papandreou%2C%20George%20Kokkinos%2C%20Iasonas%20Murphy%2C%20Kevin%20DeepLab%3A%20Semantic%20Image%20Segmentation%20with%20Deep%20Convolutional%20Nets%2C%20Atrous%20Convolution%2C%20and%20Fully%20Connected%20CRFs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Liang-Chieh%20Papandreou%2C%20George%20Kokkinos%2C%20Iasonas%20Murphy%2C%20Kevin%20DeepLab%3A%20Semantic%20Image%20Segmentation%20with%20Deep%20Convolutional%20Nets%2C%20Atrous%20Convolution%2C%20and%20Fully%20Connected%20CRFs%202018"
        },
        {
            "id": "14",
            "entry": "[14] Daniel Maturana and Sebastian Scherer. VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 922\u2013928, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maturana%2C%20Daniel%20Scherer%2C%20Sebastian%20VoxNet%3A%20A%203D%20Convolutional%20Neural%20Network%20for%20Real-Time%20Object%20Recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maturana%2C%20Daniel%20Scherer%2C%20Sebastian%20VoxNet%3A%20A%203D%20Convolutional%20Neural%20Network%20for%20Real-Time%20Object%20Recognition%202015"
        },
        {
            "id": "15",
            "entry": "[15] Charles R Qi, Hao Su, Matthias Nie\u00dfner, Angela Dai, Mengyuan Yan, and Leonidas J Guibas. Volumetric and Multi-View CNNs for Object Classification on 3D Data. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5648\u20135656, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Qi%2C%20Charles%20R.%20Su%2C%20Hao%20Nie%C3%9Fner%2C%20Matthias%20Dai%2C%20Angela%20Volumetric%20and%20Multi-View%20CNNs%20for%20Object%20Classification%20on%203D%20Data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Qi%2C%20Charles%20R.%20Su%2C%20Hao%20Nie%C3%9Fner%2C%20Matthias%20Dai%2C%20Angela%20Volumetric%20and%20Multi-View%20CNNs%20for%20Object%20Classification%20on%203D%20Data%202016"
        },
        {
            "id": "16",
            "entry": "[16] R Qi Charles, Hao Su, Mo Kaichun, and Leonidas J Guibas. PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 77\u201385, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charles%2C%20R.Qi%20Su%2C%20Hao%20Kaichun%2C%20Mo%20Guibas%2C%20Leonidas%20J.%20PointNet%3A%20Deep%20Learning%20on%20Point%20Sets%20for%203D%20Classification%20and%20Segmentation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charles%2C%20R.Qi%20Su%2C%20Hao%20Kaichun%2C%20Mo%20Guibas%2C%20Leonidas%20J.%20PointNet%3A%20Deep%20Learning%20on%20Point%20Sets%20for%203D%20Classification%20and%20Segmentation%202017"
        },
        {
            "id": "17",
            "entry": "[17] Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. ShapeNet: An Information-Rich 3D Model Repository. arXiv preprint arXiv:1512.03012, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.03012"
        },
        {
            "id": "18",
            "entry": "[18] Jiajun Wu, Tianfan Xue, Joseph J Lim, Yuandong Tian, Joshua B Tenenbaum, Antonio Torralba, and William T Freeman. Single Image 3D Interpreter Network. In European Conference on Computer Vision (ECCV), pages 365\u2013382, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Xue%2C%20Tianfan%20Lim%2C%20Joseph%20J.%20Tian%2C%20Yuandong%20Single%20Image%203D%20Interpreter%20Network%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Xue%2C%20Tianfan%20Lim%2C%20Joseph%20J.%20Tian%2C%20Yuandong%20Single%20Image%203D%20Interpreter%20Network%202016"
        },
        {
            "id": "19",
            "entry": "[19] Christopher B Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, and Silvio Savarese. 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction. In European Conference on Computer Vision (ECCV), pages 628\u2013644, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choy%2C%20Christopher%20B.%20Xu%2C%20Danfei%20Gwak%2C%20JunYoung%20Chen%2C%20Kevin%203D-R2N2%3A%20A%20Unified%20Approach%20for%20Single%20and%20Multi-view%203D%20Object%20Reconstruction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choy%2C%20Christopher%20B.%20Xu%2C%20Danfei%20Gwak%2C%20JunYoung%20Chen%2C%20Kevin%203D-R2N2%3A%20A%20Unified%20Approach%20for%20Single%20and%20Multi-view%203D%20Object%20Reconstruction%202016"
        },
        {
            "id": "20",
            "entry": "[20] Rohit Girdhar, David F Fouhey, Mikel Rodriguez, and Abhinav Gupta. Learning a Predictable and Generative Vector Representation for Objects. In European Conference on Computer Vision (ECCV), pages 484\u2013499, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Girdhar%2C%20Rohit%20Fouhey%2C%20David%20F.%20Rodriguez%2C%20Mikel%20Gupta%2C%20Abhinav%20Learning%20a%20Predictable%20and%20Generative%20Vector%20Representation%20for%20Objects%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Girdhar%2C%20Rohit%20Fouhey%2C%20David%20F.%20Rodriguez%2C%20Mikel%20Gupta%2C%20Abhinav%20Learning%20a%20Predictable%20and%20Generative%20Vector%20Representation%20for%20Objects%202016"
        },
        {
            "id": "21",
            "entry": "[21] Danilo Jimenez Rezende, SM Ali Eslami, Shakir Mohamed, Peter Battaglia, Max Jaderberg, and Nicolas Heess. Unsupervised Learning of 3D Structure from Images. In Advances in Neural Information Processing Systems (NIPS), pages 4996\u20135004, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Danilo%20Jimenez%20Rezende%2C%20S.M.Ali%20Eslami%20Mohamed%2C%20Shakir%20Battaglia%2C%20Peter%20Jaderberg%2C%20Max%20Unsupervised%20Learning%20of%203D%20Structure%20from%20Images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Danilo%20Jimenez%20Rezende%2C%20S.M.Ali%20Eslami%20Mohamed%2C%20Shakir%20Battaglia%2C%20Peter%20Jaderberg%2C%20Max%20Unsupervised%20Learning%20of%203D%20Structure%20from%20Images%202016"
        },
        {
            "id": "22",
            "entry": "[22] Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, Bill Freeman, and Josh Tenenbaum. MarrNet: 3D Shape Reconstruction via 2.5D Sketches. In Advances in Neural Information Processing Systems (NIPS), pages 540\u2013550, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Wang%2C%20Yifan%20Xue%2C%20Tianfan%20Sun%2C%20Xingyuan%20MarrNet%3A%203D%20Shape%20Reconstruction%20via%202.5D%20Sketches%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Wang%2C%20Yifan%20Xue%2C%20Tianfan%20Sun%2C%20Xingyuan%20MarrNet%3A%203D%20Shape%20Reconstruction%20via%202.5D%20Sketches%202017"
        },
        {
            "id": "23",
            "entry": "[23] Abhishek Kar, Christian H\u00e4ne, and Jitendra Malik. Learning a Multi-View Stereo Machine. In Advances in Neural Information Processing Systems (NIPS), pages 364\u2013375, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kar%2C%20Abhishek%20H%C3%A4ne%2C%20Christian%20Malik%2C%20Jitendra%20Learning%20a%20Multi-View%20Stereo%20Machine%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kar%2C%20Abhishek%20H%C3%A4ne%2C%20Christian%20Malik%2C%20Jitendra%20Learning%20a%20Multi-View%20Stereo%20Machine%202017"
        },
        {
            "id": "24",
            "entry": "[24] Martin Garbade, Johann Sawatzky, Alexander Richard, and Juergen Gall. Two Stream 3D Semantic Scene Completion. arXiv preprint arXiv:1804.03550, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.03550"
        },
        {
            "id": "25",
            "entry": "[25] Saurabh Gupta, Pablo Arbel\u00e1ez, Ross Girshick, and Jitendra Malik. Aligning 3D Models to RGB-D Images of Cluttered Scenes. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 4731\u20134740, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Saurabh%20Arbel%C3%A1ez%2C%20Pablo%20Girshick%2C%20Ross%20Malik%2C%20Jitendra%20Aligning%203D%20Models%20to%20RGB-D%20Images%20of%20Cluttered%20Scenes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Saurabh%20Arbel%C3%A1ez%2C%20Pablo%20Girshick%2C%20Ross%20Malik%2C%20Jitendra%20Aligning%203D%20Models%20to%20RGB-D%20Images%20of%20Cluttered%20Scenes%202015"
        },
        {
            "id": "26",
            "entry": "[26] Andreas Geiger and Chaohui Wang. Joint 3D Object and Layout Inference from a Single RGB-D Image. In German Conference on Pattern Recognition, pages 183\u2013195, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Geiger%2C%20Andreas%20Wang%2C%20Chaohui%20Joint%203D%20Object%20and%20Layout%20Inference%20from%20a%20Single%20RGB-D%20Image%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Geiger%2C%20Andreas%20Wang%2C%20Chaohui%20Joint%203D%20Object%20and%20Layout%20Inference%20from%20a%20Single%20RGB-D%20Image%202015"
        },
        {
            "id": "27",
            "entry": "[27] Oliver Mattausch, Daniele Panozzo, Claudio Mura, Olga Sorkine-Hornung, and Renato Pajarola. Object Detection and Classification from Large-Scale Cluttered Indoor Scans. In Computer Graphics Forum, volume 33, pages 11\u201321, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mattausch%2C%20Oliver%20Panozzo%2C%20Daniele%20Mura%2C%20Claudio%20Sorkine-Hornung%2C%20Olga%20Object%20Detection%20and%20Classification%20from%20Large-Scale%20Cluttered%20Indoor%20Scans%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mattausch%2C%20Oliver%20Panozzo%2C%20Daniele%20Mura%2C%20Claudio%20Sorkine-Hornung%2C%20Olga%20Object%20Detection%20and%20Classification%20from%20Large-Scale%20Cluttered%20Indoor%20Scans%202014"
        },
        {
            "id": "28",
            "entry": "[28] Hao Jiang and Jianxiong Xiao. A Linear Approach to Matching Cuboids in RGBD Images. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2171\u20132178, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jiang%2C%20Hao%20Xiao%2C%20Jianxiong%20A%20Linear%20Approach%20to%20Matching%20Cuboids%20in%20RGBD%20Images%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jiang%2C%20Hao%20Xiao%2C%20Jianxiong%20A%20Linear%20Approach%20to%20Matching%20Cuboids%20in%20RGBD%20Images%202013"
        },
        {
            "id": "29",
            "entry": "[29] Dahua Lin, Sanja Fidler, and Raquel Urtasun. Holistic Scene Understanding for 3D Object Detection with RGBD Cameras. In IEEE International Conference on Computer Vision (ICCV), pages 1417\u20131424, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Dahua%20Fidler%2C%20Sanja%20Urtasun%2C%20Raquel%20Holistic%20Scene%20Understanding%20for%203D%20Object%20Detection%20with%20RGBD%20Cameras%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Dahua%20Fidler%2C%20Sanja%20Urtasun%2C%20Raquel%20Holistic%20Scene%20Understanding%20for%203D%20Object%20Detection%20with%20RGBD%20Cameras%202013"
        },
        {
            "id": "30",
            "entry": "[30] Shuran Song and Jianxiong Xiao. Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 808\u2013816, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Shuran%20Xiao%2C%20Jianxiong%20Deep%20Sliding%20Shapes%20for%20Amodal%203D%20Object%20Detection%20in%20RGB-D%20Images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Shuran%20Xiao%2C%20Jianxiong%20Deep%20Sliding%20Shapes%20for%20Amodal%203D%20Object%20Detection%20in%20RGB-D%20Images%202016"
        },
        {
            "id": "31",
            "entry": "[31] Bo Zheng, Yibiao Zhao, C Yu Joey, Katsushi Ikeuchi, and Song-Chun Zhu. Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3127\u20133134, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20Bo%20Yibiao%20Zhao%2C%20C.Yu%20Joey%20Ikeuchi%2C%20Katsushi%20Zhu%2C%20Song-Chun%20Beyond%20Point%20Clouds%3A%20Scene%20Understanding%20by%20Reasoning%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20Bo%20Yibiao%20Zhao%2C%20C.Yu%20Joey%20Ikeuchi%2C%20Katsushi%20Zhu%2C%20Song-Chun%20Beyond%20Point%20Clouds%3A%20Scene%20Understanding%20by%20Reasoning%202013"
        },
        {
            "id": "32",
            "entry": "[32] Byung-soo Kim, Pushmeet Kohli, and Silvio Savarese. 3D Scene Understanding by Voxel-CRF. In IEEE International Conference on Computer Vision (ICCV), pages 1425\u20131432, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Byung-soo%20Kohli%2C%20Pushmeet%20Savarese%2C%20Silvio%203D%20Scene%20Understanding%20by%20Voxel-CRF%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Byung-soo%20Kohli%2C%20Pushmeet%20Savarese%2C%20Silvio%203D%20Scene%20Understanding%20by%20Voxel-CRF%202013"
        },
        {
            "id": "33",
            "entry": "[33] Nathan Silberman, Lior Shapira, Ran Gal, and Pushmeet Kohli. A Contour Completion Model for Augmenting Surface Reconstructions. In European Conference on Computer Vision (ECCV), pages 488\u2013503, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silberman%2C%20Nathan%20Shapira%2C%20Lior%20Gal%2C%20Ran%20Kohli%2C%20Pushmeet%20A%20Contour%20Completion%20Model%20for%20Augmenting%20Surface%20Reconstructions%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silberman%2C%20Nathan%20Shapira%2C%20Lior%20Gal%2C%20Ran%20Kohli%2C%20Pushmeet%20A%20Contour%20Completion%20Model%20for%20Augmenting%20Surface%20Reconstructions%202014"
        },
        {
            "id": "34",
            "entry": "[34] Christian H\u00e4ne, Christopher Zach, Andrea Cohen, Roland Angst, and Marc Pollefeys. Joint 3D Scene Reconstruction and Class Segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 97\u2013104, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%A4ne%2C%20Christian%20Zach%2C%20Christopher%20Cohen%2C%20Andrea%20Angst%2C%20Roland%20Joint%203D%20Scene%20Reconstruction%20and%20Class%20Segmentation%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=H%C3%A4ne%2C%20Christian%20Zach%2C%20Christopher%20Cohen%2C%20Andrea%20Angst%2C%20Roland%20Joint%203D%20Scene%20Reconstruction%20and%20Class%20Segmentation%202013"
        },
        {
            "id": "35",
            "entry": "[35] Maros Blaha, Christoph Vogel, Audrey Richard, Jan D Wegner, Thomas Pock, and Konrad Schindler. Large-Scale Semantic 3D Reconstruction: an Adaptive Multi-Resolution Model for Multi-Class Volumetric Labeling. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3176\u20133184, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blaha%2C%20Maros%20Vogel%2C%20Christoph%20Richard%2C%20Audrey%20Wegner%2C%20Jan%20D.%20Large-Scale%20Semantic%203D%20Reconstruction%3A%20an%20Adaptive%20Multi-Resolution%20Model%20for%20Multi-Class%20Volumetric%20Labeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blaha%2C%20Maros%20Vogel%2C%20Christoph%20Richard%2C%20Audrey%20Wegner%2C%20Jan%20D.%20Large-Scale%20Semantic%203D%20Reconstruction%3A%20an%20Adaptive%20Multi-Resolution%20Model%20for%20Multi-Class%20Volumetric%20Labeling%202016"
        },
        {
            "id": "36",
            "entry": "[36] Keisuke Tateno, Federico Tombari, and Nassir Navab. When 2.5D is Not Enough: Simultaneous Reconstruction, Segmentation and Recognition on Dense SLAM. In IEEE International Conference on Robotics and Automation (ICRA), pages 2295\u20132302, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tateno%2C%20Keisuke%20Tombari%2C%20Federico%20Navab%2C%20Nassir%20When%202.5D%20is%20Not%20Enough%3A%20Simultaneous%20Reconstruction%2C%20Segmentation%20and%20Recognition%20on%20Dense%20SLAM%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tateno%2C%20Keisuke%20Tombari%2C%20Federico%20Navab%2C%20Nassir%20When%202.5D%20is%20Not%20Enough%3A%20Simultaneous%20Reconstruction%2C%20Segmentation%20and%20Recognition%20on%20Dense%20SLAM%202016"
        },
        {
            "id": "37",
            "entry": "[37] Keisuke Tateno, Federico Tombari, Iro Laina, and Nassir Navab. CNN-SLAM: Real-Time Dense Monocular SLAM with Learned Depth Prediction. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6565\u20136574, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tateno%2C%20Keisuke%20Tombari%2C%20Federico%20Laina%2C%20Iro%20Navab%2C%20Nassir%20CNN-SLAM%3A%20Real-Time%20Dense%20Monocular%20SLAM%20with%20Learned%20Depth%20Prediction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tateno%2C%20Keisuke%20Tombari%2C%20Federico%20Laina%2C%20Iro%20Navab%2C%20Nassir%20CNN-SLAM%3A%20Real-Time%20Dense%20Monocular%20SLAM%20with%20Learned%20Depth%20Prediction%202017"
        },
        {
            "id": "38",
            "entry": "[38] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20Residual%20Learning%20for%20Image%20Recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20Residual%20Learning%20for%20Image%20Recognition%202016"
        },
        {
            "id": "39",
            "entry": "[39] Panqu Wang, Pengfei Chen, Ye Yuan, Ding Liu, Zehua Huang, Xiaodi Hou, and Garrison Cottrell. Understanding Convolution for Semantic Segmentation. arXiv preprint arXiv:1702.08502, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.08502"
        },
        {
            "id": "40",
            "entry": "[40] Bruno Caprile and Vincent Torre. Using Vanishing Points for Camera Calibration. International Journal of Computer Vision, 4(2):127\u2013139, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caprile%2C%20Bruno%20Torre%2C%20Vincent%20Using%20Vanishing%20Points%20for%20Camera%20Calibration%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caprile%2C%20Bruno%20Torre%2C%20Vincent%20Using%20Vanishing%20Points%20for%20Camera%20Calibration%201990"
        },
        {
            "id": "41",
            "entry": "[41] Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. Indoor Segmentation and Support Inference from RGBD Images. In European Conference on Computer Vision (ECCV), pages 746\u2013760, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silberman%2C%20Nathan%20Hoiem%2C%20Derek%20Kohli%2C%20Pushmeet%20Fergus%2C%20Rob%20Indoor%20Segmentation%20and%20Support%20Inference%20from%20RGBD%20Images%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silberman%2C%20Nathan%20Hoiem%2C%20Derek%20Kohli%2C%20Pushmeet%20Fergus%2C%20Rob%20Indoor%20Segmentation%20and%20Support%20Inference%20from%20RGBD%20Images%202012"
        },
        {
            "id": "42",
            "entry": "[42] Ruiqi Guo, Chuhang Zou, and Derek Hoiem. Predicting Complete 3D Models of Indoor Scenes. arXiv preprint arXiv:1504.02437, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1504.02437"
        },
        {
            "id": "43",
            "entry": "[43] Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, and Roberto Cipolla. SceneNet: Understanding Real World Indoor Scenes with Synthetic Data. arXiv preprint arXiv:1511.07041, 2015. ",
            "arxiv_url": "https://arxiv.org/pdf/1511.07041"
        }
    ]
}
