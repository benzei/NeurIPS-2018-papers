{
    "filename": "7329-soft-gated-warping-gan-for-pose-guided-person-image-synthesis.pdf",
    "metadata": {
        "title": "Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis",
        "author": "Haoye Dong, Xiaodan Liang, Ke Gong, Hanjiang Lai, Jia Zhu, Jian Yin",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7329-soft-gated-warping-gan-for-pose-guided-person-image-synthesis.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Despite remarkable advances in image synthesis research, existing works often fail in manipulating images under the context of large geometric transformations. Synthesizing person images conditioned on arbitrary poses is one of the most representative examples where the generation quality largely relies on the capability of identifying and modeling arbitrary transformations on different body parts. Current generative models are often built on local convolutions and overlook the key challenges (e.g. heavy occlusions, different views or dramatic appearance changes) when distinct geometric changes happen for each part, caused by arbitrary pose manipulations. This paper aims to resolve these challenges induced by geometric variability and spatial displacements via a new Soft-Gated Warping Generative Adversarial Network (Warping-GAN), which is composed of two stages: 1) it first synthesizes a target part segmentation map given a target pose, which depicts the region-level spatial layouts for guiding image synthesis with higher-level structure constraints; 2) the Warping-GAN equipped with a soft-gated warping-block learns feature-level mapping to render textures from the original image into the generated segmentation map. Warping-GAN is capable of controlling different transformation degrees given distinct target poses. Moreover, the proposed warping-block is lightweight and flexible enough to be injected into any networks. Human perceptual studies and quantitative evaluations demonstrate the superiority of our WarpingGAN that significantly outperforms all existing methods on two large datasets."
    },
    "keywords": [
        {
            "term": "Mechanical Turk",
            "url": "https://en.wikipedia.org/wiki/Mechanical_Turk"
        },
        {
            "term": "image synthesis",
            "url": "https://en.wikipedia.org/wiki/image_synthesis"
        },
        {
            "term": "Natural Science Foundation of China",
            "url": "https://en.wikipedia.org/wiki/Natural_Science_Foundation_of_China"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "convolutional neural networks",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_networks"
        },
        {
            "term": "Amazon Mechanical Turk",
            "url": "https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk"
        }
    ],
    "highlights": [
        "Posed as one of most challenging tasks in image analysis, has huge potential applications for movie making, human-computer interaction, motion prediction, etc",
        "We propose a novel Soft-Gated Warping-GAN to address the large spatial misalignment issues induced by geometric transformations of desired poses, which includes two stages: 1) a poseguided parser is employed to synthesize a part segmentation map given a target pose, which depicts part-level spatial layouts to better guide the image generation with high-level structure constraints; 2) a Warping-GAN renders detailed appearances into each segmentation part by learning geometric mappings from the original image to the target pose, conditioned on the predicted segmentation map",
        "We present and discuss a series of qualitative results that will highlight the main characteristics of the proposed approach, including its ability to render textures with high-level semantic part segmentation details and to control the transformation degrees conditioned on various poses",
        "In contrast to these methods, our approach accurately and seamlessly generates more detailed and precise virtual person images conditioned on different target poses",
        "We presented a novel Soft-Gated Warping-GAN for addressing pose-guided person image synthesis, which aims to resolve the challenges induced by geometric variability and spatial",
        "Controlling different transformation degrees conditioned on various target poses, our proposed Soft-Gated Warping-GAN can generate remarkably realistic and natural results with the best human perceptual score"
    ],
    "key_statements": [
        "Posed as one of most challenging tasks in image analysis, has huge potential applications for movie making, human-computer interaction, motion prediction, etc",
        "We propose a novel Soft-Gated Warping-GAN to address the large spatial misalignment issues induced by geometric transformations of desired poses, which includes two stages: 1) a poseguided parser is employed to synthesize a part segmentation map given a target pose, which depicts part-level spatial layouts to better guide the image generation with high-level structure constraints; 2) a Warping-GAN renders detailed appearances into each segmentation part by learning geometric mappings from the original image to the target pose, conditioned on the predicted segmentation map",
        "We proposed a novel Soft-Gated Warping-GAN that pays attention to pose alignment in deep feature space and deals with textures rendering on the region-level for synthesizing person images",
        "Inspired by the geometric matching method, GEO [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>], we propose a parsing-based geometric matching method to estimate the transformation between the condition and synthesized parsing",
        "Our proposed method consistently outperforms all baselines for the Structural SIMilarity metric on both datasets, thanks to the Soft-Gated Warping-GAN which can render high-level structure textures and control different transformation for the geometric variability",
        "We present and discuss a series of qualitative results that will highlight the main characteristics of the proposed approach, including its ability to render textures with high-level semantic part segmentation details and to control the transformation degrees conditioned on various poses",
        "In contrast to these methods, our approach accurately and seamlessly generates more detailed and precise virtual person images conditioned on different target poses",
        "There are some blurry results on Market-1501 [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>], which might result from that the performance of the human parser in our model may be influenced by the low-resolution images",
        "The results suggest the improved performance attained by the warping-block insertion is not merely due to the additional parameters, but the effective mechanism inherently brought by the warping operations which act as a soft gate to control different transformation degrees according to the pose manipulations",
        "We presented a novel Soft-Gated Warping-GAN for addressing pose-guided person image synthesis, which aims to resolve the challenges induced by geometric variability and spatial",
        "Controlling different transformation degrees conditioned on various target poses, our proposed Soft-Gated Warping-GAN can generate remarkably realistic and natural results with the best human perceptual score",
        "Qualitative and quantitative experimental results demonstrate the superiority of our proposed method, which achieves state-of-the-art performance on two large datasets"
    ],
    "summary": [
        "Posed as one of most challenging tasks in image analysis, has huge potential applications for movie making, human-computer interaction, motion prediction, etc.",
        "We proposed a novel Soft-Gated Warping-GAN that pays attention to pose alignment in deep feature space and deals with textures rendering on the region-level for synthesizing person images.",
        "We exploit a Soft-Gated Warping-GAN, including a pose-guided parser to generate the target parsing, which guides to render textures on the specific part segmentation regions, and a novel warping-block to align the image features, which produces more realistic-look textures for synthesizing high-quality person images conditioned on different poses.",
        "In stage II, we use the synthesized parsing result from the stage I, the condition image, and the target pose jointly to trained a deep warping-block based generator and a discriminator, which is able to render the texture details on the specific regions.",
        "We further learn the mapping between condition image and target pose by introducing two novel approaches: the geometric matcher and the soft-gated warping-block transfer.",
        "Inspired by [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], having obtained the transformation mapping from the geometric matcher, we subsequently use this mapping to warp deep feature maps, which is able to capture the significant high-level information and help to synthesize image in an approximated shape with more realistic-looking details.",
        "Our proposed method consistently outperforms all baselines for the SSIM metric on both datasets, thanks to the Soft-Gated Warping-GAN which can render high-level structure textures and control different transformation for the geometric variability.",
        "This superior performance confirms the effectiveness of our network comprised of a human parser and the soft-gated warping-block, which synthesizes more realistic and natural person images.",
        "In contrast to these methods, our approach accurately and seamlessly generates more detailed and precise virtual person images conditioned on different target poses.",
        "The results suggest the improved performance attained by the warping-block insertion is not merely due to the additional parameters, but the effective mechanism inherently brought by the warping operations which act as a soft gate to control different transformation degrees according to the pose manipulations.",
        "We presented a novel Soft-Gated Warping-GAN for addressing pose-guided person image synthesis, which aims to resolve the challenges induced by geometric variability and spatial",
        "Our approach incorporates a human parser to produce a target part segmentation map to instruct image synthesis with higher-level structure information, and a soft-gated warping-block to warp the feature maps for rendering the textures.",
        "Controlling different transformation degrees conditioned on various target poses, our proposed Soft-Gated Warping-GAN can generate remarkably realistic and natural results with the best human perceptual score.",
        "Qualitative and quantitative experimental results demonstrate the superiority of our proposed method, which achieves state-of-the-art performance on two large datasets"
    ],
    "headline": "We propose a novel Soft-Gated Warping-GAN to address the large spatial misalignment issues induced by geometric transformations of desired poses, which includes two stages: 1) a poseguided parser is employed to synthesize a part segmentation map given a target pose, which depicts part-level spatial layouts to better guide the image generation with high-level structure constraints; 2) a Warping-GAN renders detailed appearances into each segmentation part by learning geometric mappings from the original image to the target pose, conditioned on the predicted segmentation map",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Guha Balakrishnan, Amy Zhao, Adrian V Dalca, Fredo Durand, and John Guttag. Synthesizing images of humans in unseen poses. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balakrishnan%2C%20Guha%20Zhao%2C%20Amy%20Dalca%2C%20Adrian%20V.%20Durand%2C%20Fredo%20Synthesizing%20images%20of%20humans%20in%20unseen%20poses%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balakrishnan%2C%20Guha%20Zhao%2C%20Amy%20Dalca%2C%20Adrian%20V.%20Durand%2C%20Fredo%20Synthesizing%20images%20of%20humans%20in%20unseen%20poses%202018"
        },
        {
            "id": "2",
            "entry": "[2] Fred L. Bookstein. Principal warps: Thin-plate splines and the decomposition of deformations. IEEE Transactions on pattern analysis and machine intelligence, 11(6):567\u2013585, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bookstein%2C%20Fred%20L.%20Principal%20warps%3A%20Thin-plate%20splines%20and%20the%20decomposition%20of%20deformations%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bookstein%2C%20Fred%20L.%20Principal%20warps%3A%20Thin-plate%20splines%20and%20the%20decomposition%20of%20deformations%201989"
        },
        {
            "id": "3",
            "entry": "[3] Kaidi Cao, Yu Rong, Cheng Li, Xiaoou Tang, and Chen Change Loy. Pose-robust face recognition via deep residual equivariant mapping. In CVPR, pages 5187\u20135196, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Kaidi%20Rong%2C%20Yu%20Li%2C%20Cheng%20Tang%2C%20Xiaoou%20Pose-robust%20face%20recognition%20via%20deep%20residual%20equivariant%20mapping%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Kaidi%20Rong%2C%20Yu%20Li%2C%20Cheng%20Tang%2C%20Xiaoou%20Pose-robust%20face%20recognition%20via%20deep%20residual%20equivariant%20mapping%202018"
        },
        {
            "id": "4",
            "entry": "[4] Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh. Realtime multi-person 2d pose estimation using part affinity fields. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Zhe%20Simon%2C%20Tomas%20Wei%2C%20Shih-En%20Sheikh%2C%20Yaser%20Realtime%20multi-person%202d%20pose%20estimation%20using%20part%20affinity%20fields%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Zhe%20Simon%2C%20Tomas%20Wei%2C%20Shih-En%20Sheikh%2C%20Yaser%20Realtime%20multi-person%202d%20pose%20estimation%20using%20part%20affinity%20fields%202017"
        },
        {
            "id": "5",
            "entry": "[5] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Stargan: Unified generative adversarial networks for multi-domain image-to-image translation. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Yunjey%20Choi%2C%20Minje%20Kim%2C%20Munyoung%20Ha%2C%20Jung-Woo%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Yunjey%20Choi%2C%20Minje%20Kim%2C%20Munyoung%20Ha%2C%20Jung-Woo%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018"
        },
        {
            "id": "6",
            "entry": "[6] Zhijie Deng, Hao Zhang, Xiaodan Liang, Luona Yang, Shizhen Xu, Jun Zhu, and Eric P Xing. Structured generative adversarial networks. In Advances in Neural Information Processing Systems, pages 3899\u20133909, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Zhijie%20Zhang%2C%20Hao%20Liang%2C%20Xiaodan%20Yang%2C%20Luona%20and%20Eric%20P%20Xing.%20Structured%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Zhijie%20Zhang%2C%20Hao%20Liang%2C%20Xiaodan%20Yang%2C%20Luona%20and%20Eric%20P%20Xing.%20Structured%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "7",
            "entry": "[7] Ping Dong and Nikolas P Galatsanos. Affine transformation resistant watermarking based on image normalization. In ICIP (3), pages 489\u2013492, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Ping%20Galatsanos%2C%20Nikolas%20P.%20Affine%20transformation%20resistant%20watermarking%20based%20on%20image%20normalization%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Ping%20Galatsanos%2C%20Nikolas%20P.%20Affine%20transformation%20resistant%20watermarking%20based%20on%20image%20normalization%202002"
        },
        {
            "id": "8",
            "entry": "[8] Patrick Esser, Ekaterina Sutter, and Bj\u00f6rn Ommer. A variational u-net for conditional appearance and shape generation. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Esser%2C%20Patrick%20Sutter%2C%20Ekaterina%20Ommer%2C%20Bj%C3%B6rn%20A%20variational%20u-net%20for%20conditional%20appearance%20and%20shape%20generation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Esser%2C%20Patrick%20Sutter%2C%20Ekaterina%20Ommer%2C%20Bj%C3%B6rn%20A%20variational%20u-net%20for%20conditional%20appearance%20and%20shape%20generation%202018"
        },
        {
            "id": "9",
            "entry": "[9] Ke Gong, Xiaodan Liang, Xiaohui Shen, and Liang Lin. Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing. In CVPR, pages 6757\u2013 6765, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20Ke%20Liang%2C%20Xiaodan%20Shen%2C%20Xiaohui%20Lin%2C%20Liang%20Look%20into%20person%3A%20Self-supervised%20structure-sensitive%20learning%20and%20a%20new%20benchmark%20for%20human%20parsing%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20Ke%20Liang%2C%20Xiaodan%20Shen%2C%20Xiaohui%20Lin%2C%20Liang%20Look%20into%20person%3A%20Self-supervised%20structure-sensitive%20learning%20and%20a%20new%20benchmark%20for%20human%20parsing%202017"
        },
        {
            "id": "10",
            "entry": "[10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "11",
            "entry": "[11] Xintong Han, Zuxuan Wu, Zhe Wu, Ruichi Yu, and Larry S Davis. Viton: An image-based virtual try-on network. arXiv preprint arXiv:1711.08447, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.08447"
        },
        {
            "id": "12",
            "entry": "[12] Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Xiaodan Liang, Lianhui Qin, Haoye Dong, and Eric Xing. Deep generative models with learnable knowledge constraints. NIPS, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Zhiting%20Yang%2C%20Zichao%20Salakhutdinov%2C%20Ruslan%20Liang%2C%20Xiaodan%20Haoye%20Dong%2C%20and%20Eric%20Xing.%20Deep%20generative%20models%20with%20learnable%20knowledge%20constraints%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Zhiting%20Yang%2C%20Zichao%20Salakhutdinov%2C%20Ruslan%20Liang%2C%20Xiaodan%20Haoye%20Dong%2C%20and%20Eric%20Xing.%20Deep%20generative%20models%20with%20learnable%20knowledge%20constraints%202018"
        },
        {
            "id": "13",
            "entry": "[13] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "14",
            "entry": "[14] Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In ECCV, pages 694\u2013711, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016"
        },
        {
            "id": "15",
            "entry": "[15] Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jungkwon Lee, and Jiwon Kim. Learning to discover cross-domain relations with generative adversarial networks. arXiv preprint arXiv:1703.05192, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.05192"
        },
        {
            "id": "16",
            "entry": "[16] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "17",
            "entry": "[17] Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic single image super-resolution using a generative adversarial network. In CVPR, pages 105\u2013114, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%202017"
        },
        {
            "id": "18",
            "entry": "[18] Xiaodan Liang, Lisa Lee, Wei Dai, and Eric P Xing. Dual motion gan for future-flow embedded video prediction. In IEEE International Conference on Computer Vision (ICCV), volume 1, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20Xiaodan%20Lee%2C%20Lisa%20Dai%2C%20Wei%20and%20Eric%20P%20Xing.%20Dual%20motion%20gan%20for%20future-flow%20embedded%20video%20prediction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20Xiaodan%20Lee%2C%20Lisa%20Dai%2C%20Wei%20and%20Eric%20P%20Xing.%20Dual%20motion%20gan%20for%20future-flow%20embedded%20video%20prediction%202017"
        },
        {
            "id": "19",
            "entry": "[19] Xiaodan Liang, Hao Zhang, Liang Lin, and Eric Xing. Generative semantic manipulation with mask-contrasting gan. In Proceedings of the European Conference on Computer Vision (ECCV), pages 558\u2013573, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20Xiaodan%20Zhang%2C%20Hao%20Lin%2C%20Liang%20and%20Eric%20Xing.%20Generative%20semantic%20manipulation%20with%20mask-contrasting%20gan%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20Xiaodan%20Zhang%2C%20Hao%20Lin%2C%20Liang%20and%20Eric%20Xing.%20Generative%20semantic%20manipulation%20with%20mask-contrasting%20gan%202018"
        },
        {
            "id": "20",
            "entry": "[20] Liqian Ma, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, and Luc Van Gool. Pose guided person image generation. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Liqian%20Jia%2C%20Xu%20Sun%2C%20Qianru%20Schiele%2C%20Bernt%20Pose%20guided%20person%20image%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Liqian%20Jia%2C%20Xu%20Sun%2C%20Qianru%20Schiele%2C%20Bernt%20Pose%20guided%20person%20image%20generation%202017"
        },
        {
            "id": "21",
            "entry": "[21] Liqian Ma, Qianru Sun, Stamatios Georgoulis, Luc Van Gool, Bernt Schiele, and Mario Fritz. Disentangled person image generation. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Liqian%20Sun%2C%20Qianru%20Georgoulis%2C%20Stamatios%20Gool%2C%20Luc%20Van%20Disentangled%20person%20image%20generation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Liqian%20Sun%2C%20Qianru%20Georgoulis%2C%20Stamatios%20Gool%2C%20Luc%20Van%20Disentangled%20person%20image%20generation%202018"
        },
        {
            "id": "22",
            "entry": "[22] Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "23",
            "entry": "[23] Albert Pumarola, Antonio Agudo, Alberto Sanfeliu, and Francesc Moreno-Noguer. Unsupervised person image synthesis in arbitrary poses. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pumarola%2C%20Albert%20Agudo%2C%20Antonio%20Sanfeliu%2C%20Alberto%20Moreno-Noguer%2C%20Francesc%20Unsupervised%20person%20image%20synthesis%20in%20arbitrary%20poses%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pumarola%2C%20Albert%20Agudo%2C%20Antonio%20Sanfeliu%2C%20Alberto%20Moreno-Noguer%2C%20Francesc%20Unsupervised%20person%20image%20synthesis%20in%20arbitrary%20poses%202018"
        },
        {
            "id": "24",
            "entry": "[24] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "25",
            "entry": "[25] I. Rocco, R. Arandjelovic, and J. Sivic. Convolutional neural network architecture for geometric matching. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rocco%2C%20I.%20Arandjelovic%2C%20R.%20Sivic%2C%20J.%20Convolutional%20neural%20network%20architecture%20for%20geometric%20matching%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rocco%2C%20I.%20Arandjelovic%2C%20R.%20Sivic%2C%20J.%20Convolutional%20neural%20network%20architecture%20for%20geometric%20matching%202017"
        },
        {
            "id": "26",
            "entry": "[26] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In MICCAI, pages 234\u2013241, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ronneberger%2C%20Olaf%20Fischer%2C%20Philipp%20Brox%2C%20Thomas%20U-net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ronneberger%2C%20Olaf%20Fischer%2C%20Philipp%20Brox%2C%20Thomas%20U-net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation%202015"
        },
        {
            "id": "27",
            "entry": "[27] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and Xi Chen. Improved techniques for training gans. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016"
        },
        {
            "id": "28",
            "entry": "[28] Aliaksandr Siarohin, Enver Sangineto, Stephane Lathuiliere, and Nicu Sebe. Deformable gans for pose-based human image generation. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Siarohin%2C%20Aliaksandr%20Sangineto%2C%20Enver%20Lathuiliere%2C%20Stephane%20Sebe%2C%20Nicu%20Deformable%20gans%20for%20pose-based%20human%20image%20generation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Siarohin%2C%20Aliaksandr%20Sangineto%2C%20Enver%20Lathuiliere%2C%20Stephane%20Sebe%2C%20Nicu%20Deformable%20gans%20for%20pose-based%20human%20image%20generation%202018"
        },
        {
            "id": "29",
            "entry": "[29] Bochao Wang, Huabin Zheng, Xiaodan Liang, Yimin Chen, Liang Lin, and Meng Yang. Toward characteristic-preserving image-based virtual try-on network. ECCV, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Bochao%20Zheng%2C%20Huabin%20Liang%2C%20Xiaodan%20Chen%2C%20Yimin%20Toward%20characteristic-preserving%20image-based%20virtual%20try-on%20network%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Bochao%20Zheng%2C%20Huabin%20Liang%2C%20Xiaodan%20Chen%2C%20Yimin%20Toward%20characteristic-preserving%20image-based%20virtual%20try-on%20network%202018"
        },
        {
            "id": "30",
            "entry": "[30] Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-resolution image synthesis and semantic manipulation with conditional gans. arXiv preprint arXiv:1711.11585, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.11585"
        },
        {
            "id": "31",
            "entry": "[31] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. TIP, 13(4):600\u2013612, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004"
        },
        {
            "id": "32",
            "entry": "[32] Yichao Yan, Jingwei Xu, Bingbing Ni, Wendong Zhang, and Xiaokang Yang. Skeleton-aided articulated motion generation. In ACM MM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yan%2C%20Yichao%20Xu%2C%20Jingwei%20Ni%2C%20Bingbing%20Zhang%2C%20Wendong%20Skeleton-aided%20articulated%20motion%20generation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yan%2C%20Yichao%20Xu%2C%20Jingwei%20Ni%2C%20Bingbing%20Zhang%2C%20Wendong%20Skeleton-aided%20articulated%20motion%20generation%202017"
        },
        {
            "id": "33",
            "entry": "[33] Zili Yi, Hao Zhang, Ping Tan, and Minglun Gong. Dualgan: Unsupervised dual learning for image-to-image translation. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yi%2C%20Zili%20Zhang%2C%20Hao%20Tan%2C%20Ping%20Gong%2C%20Minglun%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-to-image%20translation.%20arXiv%20p%202017"
        },
        {
            "id": "34",
            "entry": "[34] Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, and Qi Tian. Scalable person re-identification: A benchmark. In ICCV, pages 1116\u20131124, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20Liang%20Shen%2C%20Liyue%20Tian%2C%20Lu%20Shengjin%20Wang%2C%20Jingdong%20Wang%2C%20and%20Qi%20Tian.%20Scalable%20person%20re-identification%3A%20A%20benchmark%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20Liang%20Shen%2C%20Liyue%20Tian%2C%20Lu%20Shengjin%20Wang%2C%20Jingdong%20Wang%2C%20and%20Qi%20Tian.%20Scalable%20person%20re-identification%3A%20A%20benchmark%202015"
        },
        {
            "id": "35",
            "entry": "[35] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20and%20Alexei%20A%20Efros.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20and%20Alexei%20A%20Efros.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017"
        },
        {
            "id": "36",
            "entry": "[36] Shi Qiu Xiaogang Wang Ziwei Liu, Ping Luo and Xiaoou Tang. Deepfashion: Powering robust clothes recognition and retrieval with rich annotations. In CVPR, pages 1096\u20131104, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Shi%20Qiu%20Xiaogang%20Wang%20Ziwei%20Luo%2C%20Ping%20Tang%2C%20Xiaoou%20Deepfashion%3A%20Powering%20robust%20clothes%20recognition%20and%20retrieval%20with%20rich%20annotations%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Shi%20Qiu%20Xiaogang%20Wang%20Ziwei%20Luo%2C%20Ping%20Tang%2C%20Xiaoou%20Deepfashion%3A%20Powering%20robust%20clothes%20recognition%20and%20retrieval%20with%20rich%20annotations%202016"
        }
    ]
}
