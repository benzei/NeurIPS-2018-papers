{
    "filename": "7830-dual-swap-disentangling.pdf",
    "metadata": {
        "title": "Dual Swap Disentangling",
        "author": "Zunlei Feng, Xinchao Wang, Chenglong Ke, An-Xiang Zeng, Dacheng Tao, Mingli Song",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7830-dual-swap-disentangling.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Learning interpretable disentangled representations is a crucial yet challenging task. In this paper, we propose a weakly semi-supervised method, termed as Dual Swap Disentangling (DSD), for disentangling using both labeled and unlabeled data. Unlike conventional weakly supervised methods that rely on full annotations on the group of samples, we require only limited annotations on paired samples that indicate their shared attribute like the color. Our model takes the form of a dual autoencoder structure. To achieve disentangling using the labeled pairs, we follow a \u201cencoding-swap-decoding\u201d process, where we first swap the parts of their encodings corresponding to the shared attribute, and then decode the obtained hybrid codes to reconstruct the original input pairs. For unlabeled pairs, we follow the \u201cencoding-swap-decoding\u201d process twice on designated encoding parts and enforce the final outputs to approximate the input pairs. By isolating parts of the encoding and swapping them back and forth, we impose the dimension-wise modularity and portability of the encodings of the unlabeled samples, which implicitly encourages disentangling under the guidance of labeled pairs. This dual swap mechanism, tailored for semi-supervised setting, turns out to be very effective. Experiments on image datasets from a wide domain show that our model yields state-of-the-art disentangling performances."
    },
    "keywords": [
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        }
    ],
    "highlights": [
        "Disentangling aims at learning dimension-wise interpretable representations from data",
        "We propose a weakly semi-supervised learning approach, dubbed as Dual Swap Disentangling (DSD), for disentangling that combines the best of the two worlds",
        "We propose the first dual-stage network architecture to utilize unlabeled sample pairs for semi-supervised disentangling, to facilitate and improve over the supervised learning using a small number of labeled pairs",
        "We evaluate the proposed Dual Swap Disentangling on a wide domain of image datasets, in term of both qualitative visualization and quantitative measures",
        "We propose the Dual Swap Disentangling (DSD) model that learns disentangled representations using limited and weakly-labeled training samples",
        "Such self-supervision mechanism for unlabeled samples turns out to be very effective: Dual Swap Disentangling yields results superior to the state-of-the-art on several datasets of different domains"
    ],
    "key_statements": [
        "Disentangling aims at learning dimension-wise interpretable representations from data",
        "We propose a weakly semi-supervised learning approach, dubbed as Dual Swap Disentangling (DSD), for disentangling that combines the best of the two worlds",
        "We propose the first dual-stage network architecture to utilize unlabeled sample pairs for semi-supervised disentangling, to facilitate and improve over the supervised learning using a small number of labeled pairs",
        "We evaluate the proposed Dual Swap Disentangling on a wide domain of image datasets, in term of both qualitative visualization and quantitative measures",
        "We show a visual illustration of our model in Fig. 1, where the dual-stage architecture is tailored for the self-supervision on the unlabeled samples",
        "We propose the Dual Swap Disentangling (DSD) model that learns disentangled representations using limited and weakly-labeled training samples",
        "Such self-supervision mechanism for unlabeled samples turns out to be very effective: Dual Swap Disentangling yields results superior to the state-of-the-art on several datasets of different domains"
    ],
    "summary": [
        "Disentangling aims at learning dimension-wise interpretable representations from data.",
        "The proposed DSD takes advantage of limited annotated sample pairs together with many unannotated ones to derive dimension-wise and semantic-controllable disentangling.",
        "We implement the DSD model using an autoencoder, training on both labeled and unlabeled input data pairs and by swapping designated parts of the encodings.",
        "With the guidance and constraint of labeled pairs, the dual swap strategy can generate informative feedback signals to train the DSD for the dimension-wise and semantic-controllable disentangling.",
        "The dual swap strategy, tailored for unlabeled pairs, turns out to be very effective in facilitating supervised learning with a limited number of samples.",
        "The goal of our proposed DSD model is to take both weakly labeled and unlabeled sample pairs as input, and train an autoencoder that accomplishes dimension-wise controllable disentangling.",
        "Unlike conventional weakly supervised methods like <a class=\"ref-link\" id=\"cBouchacourt_et+al_2017_a\" href=\"#rBouchacourt_et+al_2017_a\">Bouchacourt et al [2017</a>] that rely on full annotations on the group of samples, our model only requires limited and weak annotations as we only require the labels to indicate which attribute, if any, is shared by a pair of samples.",
        "Dual-stage For labeled pairs, we know what their shared attribute is and can swap the corresponding parts of the code.",
        "For a pair of labeled input (IA, IB) in group Gk, meaning that they share the attribute corresponding to the k-th part of their encodings RA and RB, we swap their k-th part and get a pair of hybrid codes RA = [a1, a2, ..., bk, ..., an] and RB = [b1, b2, ..., ak, ..., bn].",
        "By swapping random parts back and forth, we encourage the element-wise separability and modularity of the obtained encodings, which further helps the encoder to learn disentangled representations under the guidance of limited weak labels.",
        "Most of the hybrid images of DSD keep the angle effectively, indicating that swapped coded only contains the digital identity information.",
        "We propose the Dual Swap Disentangling (DSD) model that learns disentangled representations using limited and weakly-labeled training samples.",
        "Our model requires the shared attribute as the only annotation of a pair of input samples, and is able to take advantage of the vast amount of unlabeled samples to facilitate the model training.",
        "This is achieved by the dual-stage architecture, where the labeled samples go through the \u201cencoding-swap-decoding\u201d process once while the unlabeled ones go through the process twice.",
        "Such self-supervision mechanism for unlabeled samples turns out to be very effective: DSD yields results superior to the state-of-the-art on several datasets of different domains."
    ],
    "headline": "We propose a weakly semi-supervised method, termed as Dual Swap Disentangling , for disentangling using both labeled and unlabeled data",
    "reference_links": [
        {
            "id": "Banijamali_et+al_2017_a",
            "entry": "Ershad Banijamali, Amir Hossein Karimi, Alexander Wong, and Ali Ghodsi. Jade: Joint autoencoders for dis-entanglement. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Banijamali%2C%20Ershad%20Karimi%2C%20Amir%20Hossein%20Wong%2C%20Alexander%20Ghodsi%2C%20Ali%20Jade%3A%20Joint%20autoencoders%20for%20dis-entanglement%202017"
        },
        {
            "id": "Bouchacourt_et+al_2017_a",
            "entry": "Diane Bouchacourt, Ryota Tomioka, and Sebastian Nowozin. Multi-level variational autoencoder: Learning disentangled representations from grouped observations. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bouchacourt%2C%20Diane%20Tomioka%2C%20Ryota%20Nowozin%2C%20Sebastian%20Multi-level%20variational%20autoencoder%3A%20Learning%20disentangled%20representations%20from%20grouped%20observations%202017"
        },
        {
            "id": "Burgess_et+al_2017_a",
            "entry": "Christopher Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. Understanding disentangling in beta-vae. In NIPS 2017 Disentanglement Workshop, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Burgess%2C%20Christopher%20Higgins%2C%20Irina%20Pal%2C%20Arka%20Matthey%2C%20Loic%20Understanding%20disentangling%20in%20beta-vae%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Burgess%2C%20Christopher%20Higgins%2C%20Irina%20Pal%2C%20Arka%20Matthey%2C%20Loic%20Understanding%20disentangling%20in%20beta-vae%202017"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Tian Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud. Isolating sources of disentanglement in variational autoencoders. arXiv preprint arXiv:1802.04942, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04942"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "Dupont_2018_a",
            "entry": "Emilien Dupont. Joint-vae: Learning disentangled joint continuous and discrete representations. arXiv preprint arXiv:1804.00104, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.00104"
        },
        {
            "id": "Eastwood_2018_a",
            "entry": "Cian Eastwood and Christopher K. I. Williams. A framework for the quantitative evaluation of disentangled representations. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eastwood%2C%20Cian%20Williams%2C%20Christopher%20K.I.%20A%20framework%20for%20the%20quantitative%20evaluation%20of%20disentangled%20representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eastwood%2C%20Cian%20Williams%2C%20Christopher%20K.I.%20A%20framework%20for%20the%20quantitative%20evaluation%20of%20disentangled%20representations%202018"
        },
        {
            "id": "Feng_et+al_2018_a",
            "entry": "Zunlei Feng, Zhenyun Yu, Yezhou Yang, Yongcheng Jing, Junxiao Jiang, and Mingli Song. Interpretable partitioned embedding for customized fashion outfit composition. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feng%2C%20Zunlei%20Yu%2C%20Zhenyun%20Yang%2C%20Yezhou%20Jing%2C%20Yongcheng%20Interpretable%20partitioned%20embedding%20for%20customized%20fashion%20outfit%20composition%202018"
        },
        {
            "id": "Gao_et+al_2018_a",
            "entry": "Shuyang Gao, Rob Brekelmans, Greg Ver Steeg, and Aram Galstyan. Auto-encoding total correlation explanation. arXiv preprint arXiv:1802.05822, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05822"
        },
        {
            "id": "Gao_et+al_2008_a",
            "entry": "Wen Gao, Bo Cao, Shiguang Shan, Xilin Chen, Delong Zhou, Xiaohua Zhang, and Debin Zhao. The caspeal large-scale chinese face database and baseline evaluations. IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans, 38(1):149\u2013161, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gao%2C%20Wen%20Cao%2C%20Bo%20Shan%2C%20Shiguang%20Chen%2C%20Xilin%20The%20caspeal%20large-scale%20chinese%20face%20database%20and%20baseline%20evaluations%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gao%2C%20Wen%20Cao%2C%20Bo%20Shan%2C%20Shiguang%20Chen%2C%20Xilin%20The%20caspeal%20large-scale%20chinese%20face%20database%20and%20baseline%20evaluations%202008"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Improved training of wasserstein gans. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017"
        },
        {
            "id": "Haykin_2009_a",
            "entry": "S. Haykin and B. Kosko. Gradientbased learning applied to document recognition. In IEEE, pages 306\u2013351, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Haykin%2C%20S.%20Kosko%2C%20B.%20Gradientbased%20learning%20applied%20to%20document%20recognition%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Haykin%2C%20S.%20Kosko%2C%20B.%20Gradientbased%20learning%20applied%20to%20document%20recognition%202009"
        },
        {
            "id": "Higgins_et+al_2016_a",
            "entry": "Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20beta-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202016"
        },
        {
            "id": "Higgins_et+al_0000_a",
            "entry": "Irina Higgins, Arka Pal, Andrei A Rusu, Loic Matthey, Christopher P Burgess, Alexander Pritzel, Matthew Botvinick, Charles Blundell, and Alexander Lerchner. Darla: Improving zero-shot transfer in reinforcement learning. arXiv preprint arXiv:1707.08475, 2017a.",
            "arxiv_url": "https://arxiv.org/pdf/1707.08475"
        },
        {
            "id": "Higgins_et+al_2017_a",
            "entry": "Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner. Scan: Learning abstract hierarchical compositional visual concepts. 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Sonnerat%2C%20Nicolas%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Scan%3A%20Learning%20abstract%20hierarchical%20compositional%20visual%20concepts%202017"
        },
        {
            "id": "Hyunjik_2018_a",
            "entry": "Hyunjik Kim and Andriy Mnih. Disentangling by factorising. arXiv preprint arXiv:1802.05983, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05983"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. Computer Science, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014"
        },
        {
            "id": "Kingma_et+al_2014_b",
            "entry": "Diederik P Kingma, Danilo J Rezende, Shakir Mohamed, and Max Welling. Semi-supervised learning with deep generative models. Advances in Neural Information Processing Systems, 4:3581\u20133589, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Rezende%2C%20Danilo%20J.%20Mohamed%2C%20Shakir%20Welling%2C%20Max%20Semi-supervised%20learning%20with%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Rezende%2C%20Danilo%20J.%20Mohamed%2C%20Shakir%20Welling%2C%20Max%20Semi-supervised%20learning%20with%20deep%20generative%20models%202014"
        },
        {
            "id": "Kulkarni_et+al_2015_a",
            "entry": "Tejas D. Kulkarni, William F. Whitney, Pushmeet Kohli, and Joshua B. Tenenbaum. Deep convolutional inverse graphics network. 71(2):2539\u20132547, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Whitney%2C%20William%20F.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Deep%20convolutional%20inverse%20graphics%20network.%2071%282%29%202015"
        },
        {
            "id": "Lake_et+al_2017_a",
            "entry": "Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017"
        },
        {
            "id": "Moreno_et+al_2016_a",
            "entry": "Pol Moreno, Christopher K. I. Williams, Charlie Nash, and Pushmeet Kohli. Overcoming occlusion with inverse graphics. In European Conference on Computer Vision, pages 170\u2013185, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Moreno%2C%20Pol%20Williams%2C%20Christopher%20K.I.%20Nash%2C%20Charlie%20Kohli%2C%20Pushmeet%20Overcoming%20occlusion%20with%20inverse%20graphics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Moreno%2C%20Pol%20Williams%2C%20Christopher%20K.I.%20Nash%2C%20Charlie%20Kohli%2C%20Pushmeet%20Overcoming%20occlusion%20with%20inverse%20graphics%202016"
        },
        {
            "id": "Perarnau_et+al_2016_a",
            "entry": "Guim Perarnau, Van De Weijer Joost, Bogdan Raducanu, and Jose M Alvarez. Invertible conditional gans for image editing. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perarnau%2C%20Guim%20Joost%2C%20Van%20De%20Weijer%20Raducanu%2C%20Bogdan%20Alvarez%2C%20Jose%20M.%20Invertible%20conditional%20gans%20for%20image%20editing%202016"
        },
        {
            "id": "Shen_et+al_2016_a",
            "entry": "Xiaoyong Shen, Aaron Hertzmann, Jiaya Jia, Sylvain Paris, Brian Price, Eli Shechtman, and Ian Sachs. Automatic portrait segmentation for image stylization. Computer Graphics Forum, 35(2):93\u2013102, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shen%2C%20Xiaoyong%20Hertzmann%2C%20Aaron%20Jia%2C%20Jiaya%20Paris%2C%20Sylvain%20Automatic%20portrait%20segmentation%20for%20image%20stylization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shen%2C%20Xiaoyong%20Hertzmann%2C%20Aaron%20Jia%2C%20Jiaya%20Paris%2C%20Sylvain%20Automatic%20portrait%20segmentation%20for%20image%20stylization%202016"
        },
        {
            "id": "Siddharth_et+al_2017_a",
            "entry": "N Siddharth, Brooks Paige, Alban Desmaison, Jan-Willem van de Meent, Frank Wood, Noah Goodman, D, Pushmeet Kohli, and H S Torr, Philip. Learning disentangled representations in deep generative models. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Siddharth%2C%20N.%20Paige%2C%20Brooks%20Desmaison%2C%20Alban%20van%20de%20Meent%2C%20Jan-Willem%20Learning%20disentangled%20representations%20in%20deep%20generative%20models%202017"
        },
        {
            "id": "Wang_et+al_2017_a",
            "entry": "Chaoyue Wang, Chaohui Wang, Chang Xu, and Dacheng Tao. Tag disentangled generative adversarial network for object image re-rendering. In Twenty-Sixth International Joint Conference on Artificial Intelligence, pages 2901\u20132907, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Chaoyue%20Wang%2C%20Chaohui%20Xu%2C%20Chang%20Tao%2C%20Dacheng%20Tag%20disentangled%20generative%20adversarial%20network%20for%20object%20image%20re-rendering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Chaoyue%20Wang%2C%20Chaohui%20Xu%2C%20Chang%20Tao%2C%20Dacheng%20Tag%20disentangled%20generative%20adversarial%20network%20for%20object%20image%20re-rendering%202017"
        },
        {
            "id": "Xia_et+al_2016_a",
            "entry": "Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie Yan Liu, and Wei Ying Ma. Dual learning for machine translation. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xia%2C%20Yingce%20He%2C%20Di%20Qin%2C%20Tao%20Wang%2C%20Liwei%20Nenghai%20Yu%2C%20Tie%20Yan%20Liu%2C%20and%20Wei%20Ying%20Ma.%20Dual%20learning%20for%20machine%20translation%202016"
        },
        {
            "id": "Xiao_et+al_2017_a",
            "entry": "Taihong Xiao, Jiapeng Hong, and Jinwen Ma. Dna-gan: Learning disentangled representations from multiattribute images. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xiao%2C%20Taihong%20Hong%2C%20Jiapeng%20Ma%2C%20Jinwen%20Dna-gan%3A%20Learning%20disentangled%20representations%20from%20multiattribute%20images%202017"
        },
        {
            "id": "Zhu_et+al_2017_a",
            "entry": "Jun Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. pages 2242\u20132251, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun%20Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20and%20Alexei%20A%20Efros.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017"
        }
    ]
}
