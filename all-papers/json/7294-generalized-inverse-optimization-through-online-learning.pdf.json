{
    "filename": "7294-generalized-inverse-optimization-through-online-learning.pdf",
    "metadata": {
        "title": "Generalized Inverse Optimization through Online Learning",
        "author": "Chaosheng Dong, Yiran Chen, Bo Zeng",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7294-generalized-inverse-optimization-through-online-learning.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Inverse optimization is a powerful paradigm for learning preferences and restrictions that explain the behavior of a decision maker, based on a set of external signal and the corresponding decision pairs. However, most inverse optimization algorithms are designed specifically in batch setting, where all the data is available in advance. As a consequence, there has been rare use of these methods in an online setting suitable for real-time applications. In this paper, we propose a general framework for inverse optimization through online learning. Specifically, we develop an online learning algorithm that uses an implicit update rule which can handle noisy data. Moreover, under additional regularity assumptions in terms of t\u221ahe data and the model, we prove that our algorithm converges at a rate of O(1/ T ) and is statistically consistent. In our experiments, we show the online learning approach can learn the parameters with great accuracy and is very robust to noises, and achieves a dramatic improvement in computational efficacy over the batch learning approach."
    },
    "keywords": [
        {
            "term": "recommender systems",
            "url": "https://en.wikipedia.org/wiki/recommender_systems"
        },
        {
            "term": "decision maker",
            "url": "https://en.wikipedia.org/wiki/decision_maker"
        },
        {
            "term": "online learning",
            "url": "https://en.wikipedia.org/wiki/online_learning"
        },
        {
            "term": "Pittsburgh Supercomputing Center",
            "url": "https://en.wikipedia.org/wiki/Pittsburgh_Supercomputing_Center"
        },
        {
            "term": "utility maximization problem",
            "url": "https://en.wikipedia.org/wiki/utility_maximization_problem"
        },
        {
            "term": "linear programming",
            "url": "https://en.wikipedia.org/wiki/linear_programming"
        }
    ],
    "highlights": [
        "Possessing the ability to elicit customers\u2019 preferences and restrictions (PR) is crucial to the success for an organization in designing and providing services or products",
        "We provide a general mechanism for the incremental elicitation, revision and reuse of the inference about decision maker\u2019s preferences and restrictions",
        "We show the statistical consistency of our algorithm, which guarantees that our algorithm will asymptotically achieves the best prediction error permitted by the inverse model we consider",
        "Our contributions To the best of authors\u2019 knowledge, we propose the first general framework for eliciting decision maker\u2019s preferences and restrictions using inverse optimization through online learning",
        "In Figure 1, we provide the comparison of inverse optimization through batch learning versus through online learning",
        "We prove a regret bound for the implicit online learning algorithm under certain regularity conditions, and show the algorithm is statistically consistent, which guarantees that our algorithm will asymptotically achieves the best prediction error permitted by the inverse model"
    ],
    "key_statements": [
        "Possessing the ability to elicit customers\u2019 preferences and restrictions (PR) is crucial to the success for an organization in designing and providing services or products",
        "As in most scenarios, one can only observe their decisions or behaviors corresponding to external signals, while cannot directly access their decision making schemes",
        "We provide a general mechanism for the incremental elicitation, revision and reuse of the inference about decision maker\u2019s preferences and restrictions",
        "We show the statistical consistency of our algorithm, which guarantees that our algorithm will asymptotically achieves the best prediction error permitted by the inverse model we consider",
        "Our contributions To the best of authors\u2019 knowledge, we propose the first general framework for eliciting decision maker\u2019s preferences and restrictions using inverse optimization through online learning",
        "In Figure 1, we provide the comparison of inverse optimization through batch learning versus through online learning",
        "More\u221aover, we prove that the online learning algorithm, which adopts an implicit update rule, has a O( T ) regret under certain regularity conditions",
        "This algorithm is statistically consistent when the data satisfies some rather common conditions, which guarantees that our algorithm will asymptotically achieves the best prediction error permitted by the inverse model we consider",
        "Note that the implicit online learning algorithm is generally applicable to learn the parameter of any c\u221aonvex DMP",
        "We provide an example in supplementary material",
        "Remark 3.6. (i) Theorem 3.3 guarantees that the online learning algorithm proposed in this paper will asymptotically achieves the best prediction error permitted by the inverse model we consider. Corollary 3.3.1 suggests that the prediction error is inevitable as long as the data carries noise",
        "We study the consumer\u2019s behavior problem in a market with n products",
        "We prove a regret bound for the implicit online learning algorithm under certain regularity conditions, and show the algorithm is statistically consistent, which guarantees that our algorithm will asymptotically achieves the best prediction error permitted by the inverse model"
    ],
    "summary": [
        "Possessing the ability to elicit customers\u2019 preferences and restrictions (PR) is crucial to the success for an organization in designing and providing services or products.",
        "We formulate such learning problem as an IOP considering noisy data, and develop an online learning algorithm to derive unknown parameters occurring in either the objective function or constraints.",
        "Our contributions To the best of authors\u2019 knowledge, we propose the first general framework for eliciting decision maker\u2019s PR using inverse optimization through online learning.",
        "This framework can learn general convex utility functions and constraints with observed pairs.",
        "In our inverse optimization model, the learner aims to learn the decision maker\u2019s objective function or constraints from pairs.",
        "Given a pair (u, y) and a hypothesis \u03b8, we define the following loss function as the minimum distance between y and the optimal solution set S(u, \u03b8).",
        "If we seek to learn c, the optimal solution set for QP can be characterized by KKT conditions as S = {x : Ax \u2265 bt, u \u2208 R+m, uT (Ax \u2212 bt) = 0, Qx + c \u2212 AT u = 0}.",
        "Algorithm 1 Implicit Online Learning for Generalized Inverse Optimization",
        "To obtain a strong initialization of \u03b8 in Algorithm 1, we can incorporate an idea in [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>], which imputes a convex objective function by minimizing the residuals of KKT conditions incurred by the noisy data.",
        "Note that the implicit online learning algorithm is generally applicable to learn the parameter of any c\u221aonvex DMP.",
        "It is one of the major challenges when learning parameters of a function that\u2019s not strongly convex using inverse optimization.",
        "Our result shows the risk consistency of the online learning algorithm in the sense that the average cumulative loss converges in probability to the true risk in the batch setting.",
        "(i) Theorem 3.3 guarantees that the online learning algorithm proposed in this paper will asymptotically achieves the best prediction error permitted by the inverse model we consider.",
        "We will provide sketches of representative applications for inferring objective functions and constraints using the proposed online learning algorithm.",
        "Learning the utility function In the first set of experiments, the learner seeks to learn r given {}t\u2208[T ] that arrives seque\u221antially in T = 1000 rounds.",
        "Suppose the transportation cost on edge (2, 3) and (2, 5) are unknown, and the learner seeks to learn them given the pairs that arrive sequentially \u221ain T = 1000 rounds.",
        "We prove a regret bound for the implicit online learning algorithm under certain regularity conditions, and show the algorithm is statistically consistent, which guarantees that our algorithm will asymptotically achieves the best prediction error permitted by the inverse model."
    ],
    "headline": "We propose a general framework for inverse optimization through online learning",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Arezou Keshavarz, Yang Wang, and Stephen Boyd. Imputing a convex objective function. In Intelligent Control (ISIC), 2011 IEEE International Symposium on, pages 613\u2013619. IEEE, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Keshavarz%2C%20Arezou%20Wang%2C%20Yang%20Boyd%2C%20Stephen%20Imputing%20a%20convex%20objective%20function%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Keshavarz%2C%20Arezou%20Wang%2C%20Yang%20Boyd%2C%20Stephen%20Imputing%20a%20convex%20objective%20function%202011"
        },
        {
            "id": "2",
            "entry": "[2] Ravindra K Ahuja and James B Orlin. Inverse optimization. Operations Research, 49(5):771\u2013 783, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ravindra%20K%20Ahuja%20and%20James%20B%20Orlin%20Inverse%20optimization%20Operations%20Research%20495771%20783%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ravindra%20K%20Ahuja%20and%20James%20B%20Orlin%20Inverse%20optimization%20Operations%20Research%20495771%20783%202001"
        },
        {
            "id": "3",
            "entry": "[3] Garud Iyengar and Wanmo Kang. Inverse conic programming with applications. Operations Research Letters, 33(3):319\u2013330, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iyengar%2C%20Garud%20Kang%2C%20Wanmo%20Inverse%20conic%20programming%20with%20applications%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Iyengar%2C%20Garud%20Kang%2C%20Wanmo%20Inverse%20conic%20programming%20with%20applications%202005"
        },
        {
            "id": "4",
            "entry": "[4] Andrew J. Schaefer. Inverse integer programming. Optimization Letters, 3(4):483\u2013489, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schaefer%2C%20Andrew%20J.%20Inverse%20integer%20programming%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schaefer%2C%20Andrew%20J.%20Inverse%20integer%20programming%202009"
        },
        {
            "id": "5",
            "entry": "[5] Lizhi Wang. Cutting plane algorithms for the inverse mixed integer linear programming problem. Operations Research Letters, 37(2):114\u2013116, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Lizhi%20Cutting%20plane%20algorithms%20for%20the%20inverse%20mixed%20integer%20linear%20programming%20problem%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Lizhi%20Cutting%20plane%20algorithms%20for%20the%20inverse%20mixed%20integer%20linear%20programming%20problem%202009"
        },
        {
            "id": "6",
            "entry": "[6] Andreas B\u00e4rmann, Sebastian Pokutta, and Oskar Schneider. Emulating the expert: Inverse optimization through online learning. In Proceedings of the 34th International Conference on Machine Learning, pages 400\u2013410, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=B%C3%A4rmann%2C%20Andreas%20Pokutta%2C%20Sebastian%20Schneider%2C%20Oskar%20Emulating%20the%20expert%3A%20Inverse%20optimization%20through%20online%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=B%C3%A4rmann%2C%20Andreas%20Pokutta%2C%20Sebastian%20Schneider%2C%20Oskar%20Emulating%20the%20expert%3A%20Inverse%20optimization%20through%20online%20learning%202017"
        },
        {
            "id": "7",
            "entry": "[7] Anil Aswani, Zuo-Jun Shen, and Auyon Siddiq. Inverse optimization with noisy data. Operations Research, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aswani%2C%20Anil%20Shen%2C%20Zuo-Jun%20Siddiq%2C%20Auyon%20Inverse%20optimization%20with%20noisy%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aswani%2C%20Anil%20Shen%2C%20Zuo-Jun%20Siddiq%2C%20Auyon%20Inverse%20optimization%20with%20noisy%20data%202018"
        },
        {
            "id": "8",
            "entry": "[8] Timothy CY Chan, Tim Craig, Taewoo Lee, and Michael B Sharpe. Generalized inverse multiobjective optimization with application to cancer therapy. Operations Research, 62(3):680\u2013 695, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chan%2C%20Timothy%20C.Y.%20Craig%2C%20Tim%20Lee%2C%20Taewoo%20Sharpe%2C%20Michael%20B.%20Generalized%20inverse%20multiobjective%20optimization%20with%20application%20to%20cancer%20therapy%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chan%2C%20Timothy%20C.Y.%20Craig%2C%20Tim%20Lee%2C%20Taewoo%20Sharpe%2C%20Michael%20B.%20Generalized%20inverse%20multiobjective%20optimization%20with%20application%20to%20cancer%20therapy%202014"
        },
        {
            "id": "9",
            "entry": "[9] Dimitris Bertsimas, Vishal Gupta, and Ioannis Ch Paschalidis. Inverse optimization: A new perspective on the black-litterman model. Operations research, 60(6):1389\u20131403, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bertsimas%2C%20Dimitris%20Gupta%2C%20Vishal%20Paschalidis%2C%20Ioannis%20Ch%20Inverse%20optimization%3A%20A%20new%20perspective%20on%20the%20black-litterman%20model%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bertsimas%2C%20Dimitris%20Gupta%2C%20Vishal%20Paschalidis%2C%20Ioannis%20Ch%20Inverse%20optimization%3A%20A%20new%20perspective%20on%20the%20black-litterman%20model%202012"
        },
        {
            "id": "10",
            "entry": "[10] Peyman Mohajerin Esfahani, Soroosh Shafieezadeh-Abadeh, Grani A Hanasusanto, and Daniel Kuhn. Data-driven inverse optimization with imperfect information. Mathematical Programming, pages 1\u201344, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Esfahani%2C%20Peyman%20Mohajerin%20Shafieezadeh-Abadeh%2C%20Soroosh%20Hanasusanto%2C%20Grani%20A.%20Kuhn%2C%20Daniel%20Data-driven%20inverse%20optimization%20with%20imperfect%20information%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Esfahani%2C%20Peyman%20Mohajerin%20Shafieezadeh-Abadeh%2C%20Soroosh%20Hanasusanto%2C%20Grani%20A.%20Kuhn%2C%20Daniel%20Data-driven%20inverse%20optimization%20with%20imperfect%20information%202017"
        },
        {
            "id": "11",
            "entry": "[11] Chaosheng Dong and Bo Zeng. Inferring parameters through inverse multiobjective optimization. arXiv preprint arXiv:1808.00935, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.00935"
        },
        {
            "id": "12",
            "entry": "[12] Charu C Aggarwal. Recommender Systems: The Textbook. Springer, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aggarwal%2C%20Charu%20C.%20Recommender%20Systems%3A%20The%20Textbook%202016"
        },
        {
            "id": "13",
            "entry": "[13] Dimitris Bertsimas, Vishal Gupta, and Ioannis Ch Paschalidis. Data-driven estimation in equilibrium using inverse optimization. Mathematical Programming, 153(2):595\u2013633, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bertsimas%2C%20Dimitris%20Gupta%2C%20Vishal%20Paschalidis%2C%20Ioannis%20Ch%20Data-driven%20estimation%20in%20equilibrium%20using%20inverse%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bertsimas%2C%20Dimitris%20Gupta%2C%20Vishal%20Paschalidis%2C%20Ioannis%20Ch%20Data-driven%20estimation%20in%20equilibrium%20using%20inverse%20optimization%202015"
        },
        {
            "id": "14",
            "entry": "[14] Hai Yang, Tsuna Sasaki, Yasunori Iida, and Yasuo Asakura. Estimation of origin-destination matrices from link traffic counts on congested networks. Transportation Research Part B: Methodological, 26(6):417\u2013434, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Hai%20Sasaki%2C%20Tsuna%20Iida%2C%20Yasunori%20Asakura%2C%20Yasuo%20Estimation%20of%20origin-destination%20matrices%20from%20link%20traffic%20counts%20on%20congested%20networks%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Hai%20Sasaki%2C%20Tsuna%20Iida%2C%20Yasunori%20Asakura%2C%20Yasuo%20Estimation%20of%20origin-destination%20matrices%20from%20link%20traffic%20counts%20on%20congested%20networks%201992"
        },
        {
            "id": "15",
            "entry": "[15] Stephan Dempe and Sebastian Lohse. Inverse linear programming. In Recent Advances in Optimization, pages 19\u201328.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dempe%2C%20Stephan%20Lohse%2C%20Sebastian%20Inverse%20linear%20programming",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dempe%2C%20Stephan%20Lohse%2C%20Sebastian%20Inverse%20linear%20programming"
        },
        {
            "id": "16",
            "entry": "[16] Timothy CY Chan, Taewoo Lee, and Daria Terekhov. Inverse optimization: Closed-form solutions, geometry, and goodness of fit. Management Science, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chan%2C%20Timothy%20C.Y.%20Lee%2C%20Taewoo%20Terekhov%2C%20Daria%20Inverse%20optimization%3A%20Closed-form%20solutions%2C%20geometry%2C%20and%20goodness%20of%20fit%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chan%2C%20Timothy%20C.Y.%20Lee%2C%20Taewoo%20Terekhov%2C%20Daria%20Inverse%20optimization%3A%20Closed-form%20solutions%2C%20geometry%2C%20and%20goodness%20of%20fit%202018"
        },
        {
            "id": "17",
            "entry": "[17] Li Cheng, Dale Schuurmans, Shaojun Wang, Terry Caelli, and Svn Vishwanathan. Implicit online learning with kernels. In Advances in Neural Information Processing Systems, pages 249\u2013256, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cheng%2C%20Li%20Schuurmans%2C%20Dale%20Wang%2C%20Shaojun%20Caelli%2C%20Terry%20Implicit%20online%20learning%20with%20kernels%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cheng%2C%20Li%20Schuurmans%2C%20Dale%20Wang%2C%20Shaojun%20Caelli%2C%20Terry%20Implicit%20online%20learning%20with%20kernels%202007"
        },
        {
            "id": "18",
            "entry": "[18] Brian Kulis and Peter L. Bartlett. Implicit online learning. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 575\u2013582, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulis%2C%20Brian%20Bartlett%2C%20Peter%20L.%20Implicit%20online%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulis%2C%20Brian%20Bartlett%2C%20Peter%20L.%20Implicit%20online%20learning%202010"
        },
        {
            "id": "19",
            "entry": "[19] J Fr\u00e9d\u00e9ric Bonnans and Alexander Shapiro. Optimization problems with perturbations: A guided tour. SIAM Review, 40(2):228\u2013264, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bonnans%2C%20J.Fr%C3%A9d%C3%A9ric%20Shapiro%2C%20Alexander%20Optimization%20problems%20with%20perturbations%3A%20A%20guided%20tour%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bonnans%2C%20J.Fr%C3%A9d%C3%A9ric%20Shapiro%2C%20Alexander%20Optimization%20problems%20with%20perturbations%3A%20A%20guided%20tour%201998"
        },
        {
            "id": "20",
            "entry": "[20] J Fr\u00e9d\u00e9ric Bonnans and Alexander Shapiro. Perturbation analysis of optimization problems. Springer Science & Business Media, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bonnans%2C%20J.Fr%C3%A9d%C3%A9ric%20Shapiro%2C%20Alexander%20Perturbation%20analysis%20of%20optimization%20problems%202013"
        },
        {
            "id": "21",
            "entry": "[21] Jialei Wang, Weiran Wang, and Nathan Srebro. Memory and communication efficient distributed stochastic optimization with minibatch-prox. Proceedings of Machine Learning Research, 65:1\u201337, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Srebro.%20Memory%20and%20communication%20efficient%20distributed%20stochastic%20optimization%20with%20minibatch-prox%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Srebro.%20Memory%20and%20communication%20efficient%20distributed%20stochastic%20optimization%20with%20minibatch-prox%202017"
        },
        {
            "id": "22",
            "entry": "[22] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121\u20132159, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011"
        },
        {
            "id": "23",
            "entry": "[23] Nicholas A. Nystrom, Michael J. Levine, Ralph Z. Roskies, and J. Ray Scott. Bridges: A uniquely flexible hpc resource for new communities and data analytics. In Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure, XSEDE \u201915, pages 30:1\u201330:8, New York, NY, USA, 2015. ACM.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nystrom%2C%20Nicholas%20A.%20Levine%2C%20Michael%20J.%20Roskies%2C%20Ralph%20Z.%20Scott%2C%20J.Ray%20Bridges%3A%20A%20uniquely%20flexible%20hpc%20resource%20for%20new%20communities%20and%20data%20analytics%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nystrom%2C%20Nicholas%20A.%20Levine%2C%20Michael%20J.%20Roskies%2C%20Ralph%20Z.%20Scott%2C%20J.Ray%20Bridges%3A%20A%20uniquely%20flexible%20hpc%20resource%20for%20new%20communities%20and%20data%20analytics%202015"
        },
        {
            "id": "24",
            "entry": "[24] Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B Shah. Julia: A fresh approach to numerical computing. SIAM Review, 59(1):65\u201398, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bezanson%2C%20Jeff%20Edelman%2C%20Alan%20Karpinski%2C%20Stefan%20Shah%2C%20Viral%20B.%20Julia%3A%20A%20fresh%20approach%20to%20numerical%20computing%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bezanson%2C%20Jeff%20Edelman%2C%20Alan%20Karpinski%2C%20Stefan%20Shah%2C%20Viral%20B.%20Julia%3A%20A%20fresh%20approach%20to%20numerical%20computing%202017"
        },
        {
            "id": "25",
            "entry": "[25] Andreu Mas-Collell, Michael Whinston, and Jerry R Green. Microeconomic theory. 1995. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mas-Collell%2C%20Andreu%20Whinston%2C%20Michael%20Green%2C%20Jerry%20R.%20Microeconomic%20theory%201995"
        }
    ]
}
