{
    "filename": "7367-discrimination-aware-channel-pruning-for-deep-neural-networks.pdf",
    "metadata": {
        "title": "Discrimination-aware Channel Pruning for Deep Neural Networks",
        "author": "Zhuangwei Zhuang1\u2217, Mingkui Tan1\u2217\u2020, Bohan Zhuang2\u2217, Jing Liu1\u2217, Yong Guo1, Qingyao Wu1, Junzhou Huang3,4, Jinhui Zhu1\u2020",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7367-discrimination-aware-channel-pruning-for-deep-neural-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Channel pruning is one of the predominant approaches for deep model compression. Existing pruning methods either train from scratch with sparsity constraints on channels, or minimize the reconstruction error between the pre-trained feature maps and the compressed ones. Both strategies suffer from some limitations: the former kind is computationally expensive and difficult to converge, whilst the latter kind optimizes the reconstruction error but ignores the discriminative power of channels. In this paper, we investigate a simple-yet-effective method called discrimination-aware channel pruning (DCP) to choose those channels that really contribute to discriminative power. To this end, we introduce additional discrimination-aware losses into the network to increase the discriminative power of intermediate layers and then select the most discriminative channels for each layer by considering the additional loss and the reconstruction error. Last, we propose a greedy algorithm to conduct channel selection and parameter optimization in an iterative way. Extensive experiments demonstrate the effectiveness of our method. For example, on ILSVRC-12, our pruned ResNet-50 with 30% reduction of channels outperforms the baseline model by 0.39% in top-1 accuracy."
    },
    "keywords": [
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "Natural Science Foundation of China",
            "url": "https://en.wikipedia.org/wiki/Natural_Science_Foundation_of_China"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "face recognition",
            "url": "https://en.wikipedia.org/wiki/face_recognition"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "greedy algorithm",
            "url": "https://en.wikipedia.org/wiki/greedy_algorithm"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "Since 2012, convolutional neural networks (CNNs) have achieved great success in many computer vision tasks, e.g., image classification [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], face recognition [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>], object detection [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>, <a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>], image captioning [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>, <a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>] and video analysis [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>]",
        "We propose to find the channels with true discriminative power for the network",
        "We conduct channel pruning for each layer involved in the considered stage by considering both the additional loss and the reconstruction error of feature maps",
        "We propose a discrimination-aware channel pruning (DCP) scheme for compressing deep models with the introduction of additional losses",
        "Following general greedy methods in [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c51\" href=\"#r51\">51</a>, <a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>, <a class=\"ref-link\" id=\"c42\" href=\"#r42\">42</a>], we propose a greedy algorithm to solve",
        "We have proposed a discrimination-aware channel pruning method for the compression of deep neural networks"
    ],
    "key_statements": [
        "Since 2012, convolutional neural networks (CNNs) have achieved great success in many computer vision tasks, e.g., image classification [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], face recognition [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>], object detection [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>, <a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>], image captioning [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>, <a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>] and video analysis [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>]",
        "We propose to find the channels with true discriminative power for the network",
        "We conduct channel pruning for each layer involved in the considered stage by considering both the additional loss and the reconstruction error of feature maps",
        "We propose a discrimination-aware channel pruning (DCP) scheme for compressing deep models with the introduction of additional losses",
        "Following general greedy methods in [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c51\" href=\"#r51\">51</a>, <a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>, <a class=\"ref-link\" id=\"c42\" href=\"#r42\">42</a>], we propose a greedy algorithm to solve",
        "It is worth mentioning that both the reconstruction error and the cross-entropy loss contribute to better performance of the pruned model, which strongly supports the motivation to select the important channels by LS and LM",
        "We have proposed a discrimination-aware channel pruning method for the compression of deep neural networks"
    ],
    "summary": [
        "Since 2012, convolutional neural networks (CNNs) have achieved great success in many computer vision tasks, e.g., image classification [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>, <a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>], face recognition [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>], object detection [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>, <a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>], image captioning [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>, <a class=\"ref-link\" id=\"c47\" href=\"#r47\">47</a>] and video analysis [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>].",
        "Reconstruction-based methods seek to do channel pruning by minimizing the reconstruction error of feature maps between the pruned model and a pre-trained model [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>, <a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>].",
        "We conduct channel pruning for each layer involved in the considered stage by considering both the additional loss and the reconstruction error of feature maps.",
        "We propose a discrimination-aware channel pruning (DCP) scheme for compressing deep models with the introduction of additional losses.",
        "Extensive experiments demonstrate the superior performance of our method, especially on deep ResNet. On ILSVRC-12 [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], when pruning 30% channels of ResNet-50, DCP improves the original ResNet model by 0.39% in top-1 accuracy.",
        "By introducing P losses {LSp }Pp=1 to intermediate layers, the proposed discrimination-aware channel pruning (DCP) method is shown in Algorithm 1.",
        "Starting from a pre-trained model, DCP updates the model M and performs channel pruning with (P + 1) stages.",
        "Based on the pre-trained model, we apply our method to select the informative channels.",
        "With DCP-Adapt, our pruned VGGNet outperforms the pre-trained model by 0.58% in testing error, and obtains 15.58\u00d7 reduction in model size.",
        "E.g., FaceNet [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>], DeepFace [<a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>], and VGG [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>], our pruned model achieves comparable performance but has only 45.15M FLOPs and 5.89M parameters, which is sufficient to be deployed on embedded systems.",
        "Pruning 65% channels in SphereNet-4 results in a more compact model, which requires only 24.16M FLOPs with the accuracy of 98.02% on LFW.",
        "We only report the performance under different pruning rates, while the detailed model complexity comparisons are provided in Section S8 in the supplementary material.",
        "It is worth mentioning that both the reconstruction error and the cross-entropy loss contribute to better performance of the pruned model, which strongly supports the motivation to select the important channels by LS and LM .",
        "We visualize the feature maps w.r.t. the pruned/selected channels of the first block in ResNet-18 in Figure 2.",
        "We observe that feature maps of the pruned channels (See Figure 2(b)) are less informative compared to those of the selected ones (See Figure 2(c)).",
        "It proves that the proposed DCP selects the channels with strong discriminative power for the network.",
        "We have proposed a discrimination-aware channel pruning method for the compression of deep neural networks.",
        "We formulate the channel pruning/selection problem as a sparsity-induced optimization problem by considering both reconstruction error and channel discrimination power.",
        "We will incorporate the computational cost per layer into the optimization, and combine our method with other model compression strategies to further reduce the model size and inference cost"
    ],
    "headline": "We investigate a simple-yet-effective method called discrimination-aware channel pruning  to choose those channels that really contribute to discriminative power",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] J. M. Alvarez and M. Salzmann. Learning the number of neurons in deep networks. In NIPS, pages 2270\u20132278, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alvarez%2C%20J.M.%20Salzmann%2C%20M.%20Learning%20the%20number%20of%20neurons%20in%20deep%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alvarez%2C%20J.M.%20Salzmann%2C%20M.%20Learning%20the%20number%20of%20neurons%20in%20deep%20networks%202016"
        },
        {
            "id": "2",
            "entry": "[2] S. Bahmani, B. Raj, and P. T. Boufounos. Greedy sparsity-constrained optimization. JMLR, 14(Mar):807\u2013 841, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bahmani%2C%20S.%20Raj%2C%20B.%20Boufounos%2C%20P.T.%20Greedy%20sparsity-constrained%20optimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bahmani%2C%20S.%20Raj%2C%20B.%20Boufounos%2C%20P.T.%20Greedy%20sparsity-constrained%20optimization%202013"
        },
        {
            "id": "3",
            "entry": "[3] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, pages 248\u2013255, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20J.%20Dong%2C%20W.%20Socher%2C%20R.%20Li%2C%20L.-J.%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "4",
            "entry": "[4] E. L. Denton, W. Zaremba, J. Bruna, Y. LeCun, and R. Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In NIPS, pages 1269\u20131277, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20E.L.%20Zaremba%2C%20W.%20Bruna%2C%20J.%20LeCun%2C%20Y.%20Exploiting%20linear%20structure%20within%20convolutional%20networks%20for%20efficient%20evaluation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20E.L.%20Zaremba%2C%20W.%20Bruna%2C%20J.%20LeCun%2C%20Y.%20Exploiting%20linear%20structure%20within%20convolutional%20networks%20for%20efficient%20evaluation%202014"
        },
        {
            "id": "5",
            "entry": "[5] Y. Gong, L. Liu, M. Yang, and L. Bourdev. Compressing deep convolutional networks using vector quantization. arXiv preprint arXiv:1412.6115, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6115"
        },
        {
            "id": "6",
            "entry": "[6] Y. Guo, M. Tan, Q. Wu, J. Chen, A. V. D. Hengel, and Q. Shi. The shallow end: Empowering shallower deep-convolutional networks through auxiliary outputs. arXiv preprint arXiv:1611.01773, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01773"
        },
        {
            "id": "7",
            "entry": "[7] Y. Guo, Q. Wu, C. Deng, J. Chen, and M. Tan. Double forward propagation for memorized batch normalization. In AAAI, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Y.%20Wu%2C%20Q.%20Deng%2C%20C.%20Chen%2C%20J.%20Double%20forward%20propagation%20for%20memorized%20batch%20normalization%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Y.%20Wu%2C%20Q.%20Deng%2C%20C.%20Chen%2C%20J.%20Double%20forward%20propagation%20for%20memorized%20batch%20normalization%202018"
        },
        {
            "id": "8",
            "entry": "[8] Y. Guo, A. Yao, and Y. Chen. Dynamic network surgery for efficient dnns. In NIPS, pages 1379\u20131387, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Y.%20Yao%2C%20A.%20Chen%2C%20Y.%20Dynamic%20network%20surgery%20for%20efficient%20dnns%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Y.%20Yao%2C%20A.%20Chen%2C%20Y.%20Dynamic%20network%20surgery%20for%20efficient%20dnns%202016"
        },
        {
            "id": "9",
            "entry": "[9] S. Han, H. Mao, and W. J. Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Mao%2C%20H.%20Dally%2C%20W.J.%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20S.%20Mao%2C%20H.%20Dally%2C%20W.J.%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%202016"
        },
        {
            "id": "10",
            "entry": "[10] S. Han, J. Pool, J. Tran, and W. Dally. Learning both weights and connections for efficient neural network. In NIPS, pages 1135\u20131143, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20S.%20Pool%2C%20J.%20Tran%2C%20J.%20Dally%2C%20W.%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20S.%20Pool%2C%20J.%20Tran%2C%20J.%20Dally%2C%20W.%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20network%202015"
        },
        {
            "id": "11",
            "entry": "[11] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "12",
            "entry": "[12] Y. He, X. Zhang, and J. Sun. Channel pruning for accelerating very deep neural networks. In ICCV, pages 1389\u20131397, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Y.%20Zhang%2C%20X.%20Sun%2C%20J.%20Channel%20pruning%20for%20accelerating%20very%20deep%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Y.%20Zhang%2C%20X.%20Sun%2C%20J.%20Channel%20pruning%20for%20accelerating%20very%20deep%20neural%20networks%202017"
        },
        {
            "id": "13",
            "entry": "[13] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and H. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04861"
        },
        {
            "id": "14",
            "entry": "[14] H. Hu, R. Peng, Y.-W. Tai, and C.-K. Tang. Network trimming: A data-driven neuron pruning approach towards efficient deep architectures. arXiv preprint arXiv:1607.03250, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.03250"
        },
        {
            "id": "15",
            "entry": "[15] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical report, Technical Report 07-49, University of Massachusetts, Amherst, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20G.B.%20Ramesh%2C%20M.%20Berg%2C%20T.%20Learned-Miller%2C%20E.%20Labeled%20faces%20in%20the%20wild%3A%20A%20database%20for%20studying%20face%20recognition%20in%20unconstrained%20environments%202007"
        },
        {
            "id": "16",
            "entry": "[16] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, pages 448\u2013456, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "17",
            "entry": "[17] M. Jaderberg, A. Vedaldi, and A. Zisserman. Speeding up convolutional neural networks with low rank expansions. arXiv preprint arXiv:1405.3866, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1405.3866"
        },
        {
            "id": "18",
            "entry": "[18] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Tech Report, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Hinton%2C%20G.%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "19",
            "entry": "[19] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, pages 1097\u20131105, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "20",
            "entry": "[20] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu. Deeply-supervised nets. In AISTATS, pages 562\u2013570, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CY%20Lee%20S%20Xie%20P%20Gallagher%20Z%20Zhang%20and%20Z%20Tu%20Deeplysupervised%20nets%20In%20AISTATS%20pages%20562570%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=CY%20Lee%20S%20Xie%20P%20Gallagher%20Z%20Zhang%20and%20Z%20Tu%20Deeplysupervised%20nets%20In%20AISTATS%20pages%20562570%202015"
        },
        {
            "id": "21",
            "entry": "[21] F. Li, B. Zhang, and B. Liu. Ternary weight networks. arXiv preprint arXiv:1605.04711, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.04711"
        },
        {
            "id": "22",
            "entry": "[22] H. Li, A. Kadav, I. Durdanovic, H. Samet, and H. P. Graf. Pruning filters for efficient convnets. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20H.%20Kadav%2C%20A.%20Durdanovic%2C%20I.%20Samet%2C%20H.%20Pruning%20filters%20for%20efficient%20convnets%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20H.%20Kadav%2C%20A.%20Durdanovic%2C%20I.%20Samet%2C%20H.%20Pruning%20filters%20for%20efficient%20convnets%202017"
        },
        {
            "id": "23",
            "entry": "[23] J. Liu, J. Ye, and R. Fujimaki. Forward-backward greedy algorithms for general convex smooth functions over a cardinality constraint. In ICML, pages 503\u2013511, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20J.%20Ye%2C%20J.%20Fujimaki%2C%20R.%20Forward-backward%20greedy%20algorithms%20for%20general%20convex%20smooth%20functions%20over%20a%20cardinality%20constraint%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20J.%20Ye%2C%20J.%20Fujimaki%2C%20R.%20Forward-backward%20greedy%20algorithms%20for%20general%20convex%20smooth%20functions%20over%20a%20cardinality%20constraint%202014"
        },
        {
            "id": "24",
            "entry": "[24] W. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song. Sphereface: Deep hypersphere embedding for face recognition. In CVPR, pages 212\u2013220, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20W.%20Wen%2C%20Y.%20Yu%2C%20Z.%20Li%2C%20M.%20Sphereface%3A%20Deep%20hypersphere%20embedding%20for%20face%20recognition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20W.%20Wen%2C%20Y.%20Yu%2C%20Z.%20Li%2C%20M.%20Sphereface%3A%20Deep%20hypersphere%20embedding%20for%20face%20recognition%202017"
        },
        {
            "id": "25",
            "entry": "[25] Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang. Learning efficient convolutional networks through network slimming. In ICCV, pages 2736\u20132744, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Li%2C%20J.%20Shen%2C%20Z.%20Huang%2C%20G.%20Learning%20efficient%20convolutional%20networks%20through%20network%20slimming%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Z.%20Li%2C%20J.%20Shen%2C%20Z.%20Huang%2C%20G.%20Learning%20efficient%20convolutional%20networks%20through%20network%20slimming%202017"
        },
        {
            "id": "26",
            "entry": "[26] J.-H. Luo, J. Wu, and W. Lin. Thinet: A filter level pruning method for deep neural network compression. In ICCV, pages 5058\u20135066, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20J.-H.%20Wu%2C%20J.%20Lin%2C%20W.%20Thinet%3A%20A%20filter%20level%20pruning%20method%20for%20deep%20neural%20network%20compression%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20J.-H.%20Wu%2C%20J.%20Lin%2C%20W.%20Thinet%3A%20A%20filter%20level%20pruning%20method%20for%20deep%20neural%20network%20compression%202017"
        },
        {
            "id": "27",
            "entry": "[27] V. Nair and G. E. Hinton. Rectified linear units improve restricted boltzmann machines. In ICML, pages 807\u2013814, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nair%2C%20V.%20Hinton%2C%20G.E.%20Rectified%20linear%20units%20improve%20restricted%20boltzmann%20machines%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nair%2C%20V.%20Hinton%2C%20G.E.%20Rectified%20linear%20units%20improve%20restricted%20boltzmann%20machines%202010"
        },
        {
            "id": "28",
            "entry": "[28] Y. Nesterov. A method of solving a convex programming problem with convergence rate o (1/k2). In SMD, volume 27, pages 372\u2013376, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Y.%20A%20method%20of%20solving%20a%20convex%20programming%20problem%20with%20convergence%20rate%201983"
        },
        {
            "id": "29",
            "entry": "[29] O. M. Parkhi, A. Vedaldi, A. Zisserman, et al. Deep face recognition. In BMVC, volume 1, page 6, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parkhi%2C%20O.M.%20Vedaldi%2C%20A.%20Zisserman%2C%20A.%20Deep%20face%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parkhi%2C%20O.M.%20Vedaldi%2C%20A.%20Zisserman%2C%20A.%20Deep%20face%20recognition%202015"
        },
        {
            "id": "30",
            "entry": "[30] A. Paszke, S. Gross, S. Chintala, and G. Chanan. Pytorch: Tensors and dynamic neural networks in python with strong gpu acceleration, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20A.%20Gross%2C%20S.%20Chintala%2C%20S.%20Chanan%2C%20G.%20Pytorch%3A%20Tensors%20and%20dynamic%20neural%20networks%20in%20python%20with%20strong%20gpu%20acceleration%202017"
        },
        {
            "id": "31",
            "entry": "[31] M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. In ECCV, pages 525\u2013542, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rastegari%2C%20M.%20Ordonez%2C%20V.%20Redmon%2C%20J.%20Farhadi%2C%20A.%20Xnor-net%3A%20Imagenet%20classification%20using%20binary%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rastegari%2C%20M.%20Ordonez%2C%20V.%20Redmon%2C%20J.%20Farhadi%2C%20A.%20Xnor-net%3A%20Imagenet%20classification%20using%20binary%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "32",
            "entry": "[32] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. In CVPR, pages 779\u2013788, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Redmon%2C%20J.%20Divvala%2C%20S.%20Girshick%2C%20R.%20Farhadi%2C%20A.%20You%20only%20look%20once%3A%20Unified%2C%20real-time%20object%20detection%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Redmon%2C%20J.%20Divvala%2C%20S.%20Girshick%2C%20R.%20Farhadi%2C%20A.%20You%20only%20look%20once%3A%20Unified%2C%20real-time%20object%20detection%202016"
        },
        {
            "id": "33",
            "entry": "[33] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NIPS, pages 91\u201399, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20S.%20He%2C%20K.%20Girshick%2C%20R.%20Sun%2C%20J.%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20S.%20He%2C%20K.%20Girshick%2C%20R.%20Sun%2C%20J.%20Faster%20r-cnn%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks%202015"
        },
        {
            "id": "34",
            "entry": "[34] F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In CVPR, pages 815\u2013823, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schroff%2C%20F.%20Kalenichenko%2C%20D.%20Philbin%2C%20J.%20Facenet%3A%20A%20unified%20embedding%20for%20face%20recognition%20and%20clustering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schroff%2C%20F.%20Kalenichenko%2C%20D.%20Philbin%2C%20J.%20Facenet%3A%20A%20unified%20embedding%20for%20face%20recognition%20and%20clustering%202015"
        },
        {
            "id": "35",
            "entry": "[35] K. Simonyan and A. Zisserman. Two-stream convolutional networks for action recognition in videos. In NIPS, pages 568\u2013576, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Two-stream%20convolutional%20networks%20for%20action%20recognition%20in%20videos%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Two-stream%20convolutional%20networks%20for%20action%20recognition%20in%20videos%202014"
        },
        {
            "id": "36",
            "entry": "[36] V. Sindhwani, T. Sainath, and S. Kumar. Structured transforms for small-footprint deep learning. In NIPS, pages 3088\u20133096, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sindhwani%2C%20V.%20Sainath%2C%20T.%20Kumar%2C%20S.%20Structured%20transforms%20for%20small-footprint%20deep%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sindhwani%2C%20V.%20Sainath%2C%20T.%20Kumar%2C%20S.%20Structured%20transforms%20for%20small-footprint%20deep%20learning%202015"
        },
        {
            "id": "37",
            "entry": "[37] S. Srinivas, A. Subramanya, and R. V. Babu. Training sparse neural networks. In CVPRW, pages 455\u2013462, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srinivas%2C%20S.%20Subramanya%2C%20A.%20Babu%2C%20R.V.%20Training%20sparse%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srinivas%2C%20S.%20Subramanya%2C%20A.%20Babu%2C%20R.V.%20Training%20sparse%20neural%20networks%202017"
        },
        {
            "id": "38",
            "entry": "[38] R. K. Srivastava, K. Greff, and J. Schmidhuber. Training very deep networks. In NIPS, pages 2377\u20132385, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20R.K.%20Greff%2C%20K.%20Schmidhuber%2C%20J.%20Training%20very%20deep%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20R.K.%20Greff%2C%20K.%20Schmidhuber%2C%20J.%20Training%20very%20deep%20networks%202015"
        },
        {
            "id": "39",
            "entry": "[39] Y. Sun, D. Liang, X. Wang, and X. Tang. Deepid3: Face recognition with very deep neural networks. arXiv preprint arXiv:1502.00873, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1502.00873"
        },
        {
            "id": "40",
            "entry": "[40] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In CVPR, pages 1\u20139, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Liu%2C%20W.%20Jia%2C%20Y.%20Sermanet%2C%20P.%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20C.%20Liu%2C%20W.%20Jia%2C%20Y.%20Sermanet%2C%20P.%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "41",
            "entry": "[41] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. Deepface: Closing the gap to human-level performance in face verification. In CVPR, pages 1701\u20131708, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Taigman%2C%20Y.%20Yang%2C%20M.%20Ranzato%2C%20M.%20Wolf%2C%20L.%20Deepface%3A%20Closing%20the%20gap%20to%20human-level%20performance%20in%20face%20verification%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Taigman%2C%20Y.%20Yang%2C%20M.%20Ranzato%2C%20M.%20Wolf%2C%20L.%20Deepface%3A%20Closing%20the%20gap%20to%20human-level%20performance%20in%20face%20verification%202014"
        },
        {
            "id": "42",
            "entry": "[42] M. Tan, I. W. Tsang, and L. Wang. Towards ultrahigh dimensional feature selection for big data. JMLR, 15(1):1371\u20131429, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tan%2C%20M.%20Tsang%2C%20I.W.%20Wang%2C%20L.%20Towards%20ultrahigh%20dimensional%20feature%20selection%20for%20big%20data%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tan%2C%20M.%20Tsang%2C%20I.W.%20Wang%2C%20L.%20Towards%20ultrahigh%20dimensional%20feature%20selection%20for%20big%20data%202014"
        },
        {
            "id": "43",
            "entry": "[43] M. Tan, L. Wang, and I. W. Tsang. Learning sparse svm for feature selection on very high dimensional datasets. In ICML, pages 1047\u20131054, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tan%2C%20M.%20Wang%2C%20L.%20Tsang%2C%20I.W.%20Learning%20sparse%20svm%20for%20feature%20selection%20on%20very%20high%20dimensional%20datasets%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tan%2C%20M.%20Wang%2C%20L.%20Tsang%2C%20I.W.%20Learning%20sparse%20svm%20for%20feature%20selection%20on%20very%20high%20dimensional%20datasets%202010"
        },
        {
            "id": "44",
            "entry": "[44] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and tell: A neural image caption generator. In CVPR, pages 3156\u20133164, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20O.%20Toshev%2C%20A.%20Bengio%2C%20S.%20Erhan%2C%20D.%20Show%20and%20tell%3A%20A%20neural%20image%20caption%20generator%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20O.%20Toshev%2C%20A.%20Bengio%2C%20S.%20Erhan%2C%20D.%20Show%20and%20tell%3A%20A%20neural%20image%20caption%20generator%202015"
        },
        {
            "id": "45",
            "entry": "[45] L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and L. Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In ECCV, pages 20\u201336, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20L.%20Xiong%2C%20Y.%20Wang%2C%20Z.%20Qiao%2C%20Y.%20Temporal%20segment%20networks%3A%20Towards%20good%20practices%20for%20deep%20action%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20L.%20Xiong%2C%20Y.%20Wang%2C%20Z.%20Qiao%2C%20Y.%20Temporal%20segment%20networks%3A%20Towards%20good%20practices%20for%20deep%20action%20recognition%202016"
        },
        {
            "id": "46",
            "entry": "[46] W. Wen, C. Wu, Y. Wang, Y. Chen, and H. Li. Learning structured sparsity in deep neural networks. In NIPS, pages 2074\u20132082, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wen%2C%20W.%20Wu%2C%20C.%20Wang%2C%20Y.%20Chen%2C%20Y.%20Learning%20structured%20sparsity%20in%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wen%2C%20W.%20Wu%2C%20C.%20Wang%2C%20Y.%20Chen%2C%20Y.%20Learning%20structured%20sparsity%20in%20deep%20neural%20networks%202016"
        },
        {
            "id": "47",
            "entry": "[47] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, and Y. Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, pages 2048\u20132057, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20K.%20Ba%2C%20J.%20Kiros%2C%20R.%20Cho%2C%20K.%20attend%20and%20tell%3A%20Neural%20image%20caption%20generation%20with%20visual%20attention%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20K.%20Ba%2C%20J.%20Kiros%2C%20R.%20Cho%2C%20K.%20attend%20and%20tell%3A%20Neural%20image%20caption%20generation%20with%20visual%20attention%202015"
        },
        {
            "id": "48",
            "entry": "[48] J. Ye, X. Lu, Z. Lin, and J. Z. Wang. Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers. arXiv preprint arXiv:1802.00124, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.00124"
        },
        {
            "id": "49",
            "entry": "[49] D. Yi, Z. Lei, S. Liao, and S. Z. Li. Learning face representation from scratch. arXiv preprint arXiv:1411.7923, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.7923"
        },
        {
            "id": "50",
            "entry": "[50] R. Yu, A. Li, C.-F. Chen, J.-H. Lai, V. I. Morariu, X. Han, M. Gao, C.-Y. Lin, and L. S. Davis. Nisp: Pruning networks using neuron importance score propagation. In CVPR, pages 9194\u20139203, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20R.%20Li%2C%20A.%20Chen%2C%20C.-F.%20Lai%2C%20J.-H.%20Nisp%3A%20Pruning%20networks%20using%20neuron%20importance%20score%20propagation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20R.%20Li%2C%20A.%20Chen%2C%20C.-F.%20Lai%2C%20J.-H.%20Nisp%3A%20Pruning%20networks%20using%20neuron%20importance%20score%20propagation%202018"
        },
        {
            "id": "51",
            "entry": "[51] X. Yuan, P. Li, and T. Zhang. Gradient hard thresholding pursuit for sparsity-constrained optimization. In ICML, pages 127\u2013135, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yuan%2C%20X.%20Li%2C%20P.%20Zhang%2C%20T.%20Gradient%20hard%20thresholding%20pursuit%20for%20sparsity-constrained%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yuan%2C%20X.%20Li%2C%20P.%20Zhang%2C%20T.%20Gradient%20hard%20thresholding%20pursuit%20for%20sparsity-constrained%20optimization%202014"
        },
        {
            "id": "52",
            "entry": "[52] X. Zhang, J. Zou, K. He, and J. Sun. Accelerating very deep convolutional networks for classification and detection. TPAMI, 38(10):1943\u20131955, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20X.%20Zou%2C%20J.%20He%2C%20K.%20Sun%2C%20J.%20Accelerating%20very%20deep%20convolutional%20networks%20for%20classification%20and%20detection%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20X.%20Zou%2C%20J.%20He%2C%20K.%20Sun%2C%20J.%20Accelerating%20very%20deep%20convolutional%20networks%20for%20classification%20and%20detection%202016"
        },
        {
            "id": "53",
            "entry": "[53] A. Zhou, A. Yao, Y. Guo, L. Xu, and Y. Chen. Incremental network quantization: Towards lossless cnns with low-precision weights. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20A.%20Yao%2C%20A.%20Guo%2C%20Y.%20Xu%2C%20L.%20Incremental%20network%20quantization%3A%20Towards%20lossless%20cnns%20with%20low-precision%20weights%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20A.%20Yao%2C%20A.%20Guo%2C%20Y.%20Xu%2C%20L.%20Incremental%20network%20quantization%3A%20Towards%20lossless%20cnns%20with%20low-precision%20weights%202017"
        },
        {
            "id": "54",
            "entry": "[54] S. Zhou, Y. Wu, Z. Ni, X. Zhou, H. Wen, and Y. Zou. Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients. arXiv preprint arXiv:1606.06160, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.06160"
        },
        {
            "id": "55",
            "entry": "[55] C. Zhu, S. Han, H. Mao, and W. J. Dally. Trained ternary quantization. In ICLR, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20C.%20Han%2C%20S.%20Mao%2C%20H.%20Dally%2C%20W.J.%20Trained%20ternary%20quantization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20C.%20Han%2C%20S.%20Mao%2C%20H.%20Dally%2C%20W.J.%20Trained%20ternary%20quantization%202017"
        }
    ]
}
