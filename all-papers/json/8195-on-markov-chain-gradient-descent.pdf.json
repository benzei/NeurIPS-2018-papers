{
    "filename": "8195-on-markov-chain-gradient-descent.pdf",
    "metadata": {
        "title": "On Markov Chain Gradient Descent",
        "author": "Tao Sun, Yuejiao Sun, Wotao Yin",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8195-on-markov-chain-gradient-descent.pdf"
        },
        "abstract": "Stochastic gradient methods are the workhorse (algorithms) of large-scale optimization problems in machine learning, signal processing, and other computational sciences and engineering. This paper studies Markov chain gradient descent, a variant of stochastic gradient descent where the random samples are taken on the trajectory of a Markov chain. Existing results of this method assume convex objectives and a reversible Markov chain and thus have their limitations. We establish new non-ergodic convergence under wider step sizes, for nonconvex problems, and for non-reversible finite-state Markov chains. Nonconvexity makes our method applicable to broader problem classes. Non-reversible finite-state Markov chains, on the other hand, can mix substatially faster. To obtain these results, we introduce a new technique that varies the mixing levels of the Markov chains. The reported numerical results validate our contributions."
    },
    "keywords": [
        "minimization problem",
        "reversible finite state markov chain",
        "non ergodic convergence",
        "Stochastic Gradient Descent",
        "Markov Chain Gradient Descent",
        "non reversible finite state markov chain"
    ],
    "highlights": [
        "It is worth mentioning that [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] use time non-homogeneous Markov chains, where the transition probability can change over the iterations as long as there is still a finite mixing time",
        "We present the convergence results for Markov Chain Gradient Descent in the convex case",
        "We have analyzed the stochastic gradient descent method where the samples are taken on a trajectory of Markov chain",
        "One of our main contributions is non-ergodic convergence analysis for convex Markov Chain Gradient Descent, which uses a novel line of analysis"
    ],
    "key_statements": [
        "It is worth mentioning that [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] use time non-homogeneous Markov chains, where the transition probability can change over the iterations as long as there is still a finite mixing time",
        "We present the convergence results for Markov Chain Gradient Descent in the convex case",
        "We have analyzed the stochastic gradient descent method where the samples are taken on a trajectory of Markov chain",
        "One of our main contributions is non-ergodic convergence analysis for convex Markov Chain Gradient Descent, which uses a novel line of analysis"
    ],
    "summary": [
        "It is worth mentioning that [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] use time non-homogeneous Markov chains, where the transition probability can change over the iterations as long as there is still a finite mixing time.",
        "The Markov chain is required to be reversible, and all functions fi, i \u2208 [M ], are assumed to be convex.",
        "We improve the analyses of MCGD to non-reversible finite-state Markov chains and to nonconvex functions.",
        "This is essential because MCGD needs time to reduce its objective error from its current value to a lower one, and this time becomes longer when the current value is lower since a more accurate Markov chain convergence and a longer mixing time are required.",
        "Our results for finite-state Markov chains are first presented in Sections 3 and 4.",
        "We use the finite-state time-homogeneous Markov chain, results can be extended to more general chains under similar extra assumptions in [10, Assumptions 4, 5] and [1, Assumption C].",
        "Mixing time is how long a Markov chain evolves until its current state has a distribution very close to its stationary distribution.",
        "We consider a new type of mixing time of non-reversible Markov chain.",
        "We present the convergence results for MCGD in the convex case.",
        "Letk\u22650 be a sequence of noise and consider the inexact nonconvex MCGD iteration: xk+1 = xk \u2212 \u03b3k \u2207fjk + ek .",
        "K=1 the convergence results (20) and (21) still hold for inexact nonconvex MCGD.",
        "We consider an infinite-state Markov chain that is time-homogeneous and reversible.",
        "If Assumption 4 holds and the Markov chain is time-homogeneous, irreducible, aperiodic, and reversible, we have lim E E\u03be(F) \u2212 F \u2217 = 0, k",
        ", where 0 < \u03bb < 1 is the geometric rate of the mixing time of the Markov chain in the finite-state case).",
        "Corollary 2 Let the stepsizes satisfy (19),k\u22650 be generated by Algorithm (25), the noises obey (23), and Assumption 5 hold.",
        "We have analyzed the stochastic gradient descent method where the samples are taken on a trajectory of Markov chain.",
        "This analysis lets us establish convergence for non-reversible finite-state Markov chains and for nonconvex minimization problems.",
        "Our results are useful in the cases where it is impossible or expensive to directly take samples from a distribution, or the distribution is not even known, but sampling via a Markov chain is possible.",
        "Our results apply to decentralized learning over a network, where we can employ a random walker to traverse the network and minimizer the objective that is defined over the samples that are held at the nodes in a distribute fashion"
    ],
    "headline": "This paper studies Markov chain gradient descent, a variant of stochastic gradient descent where the random samples are taken on the trajectory of a Markov chain",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] John C Duchi, Alekh Agarwal, Mikael Johansson, and Michael I Jordan. Ergodic mirror descent. SIAM Journal on Optimization, 22(4):1549\u20131578, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20C.%20Agarwal%2C%20Alekh%20Johansson%2C%20Mikael%20Jordan%2C%20Michael%20I.%20Ergodic%20mirror%20descent%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20C.%20Agarwal%2C%20Alekh%20Johansson%2C%20Mikael%20Jordan%2C%20Michael%20I.%20Ergodic%20mirror%20descent%202012"
        },
        {
            "id": "2",
            "entry": "[2] Martin Dyer, Alan Frieze, Ravi Kannan, Ajai Kapoor, Ljubomir Perkovic, and Umesh Vazirani. A mildly exponential time algorithm for approximating the number of solutions to a multidimensional knapsack problem. Combinatorics, Probability and Computing, 2(3):271\u2013284, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dyer%2C%20Martin%20Frieze%2C%20Alan%20Kannan%2C%20Ravi%20Kapoor%2C%20Ajai%20A%20mildly%20exponential%20time%20algorithm%20for%20approximating%20the%20number%20of%20solutions%20to%20a%20multidimensional%20knapsack%20problem%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dyer%2C%20Martin%20Frieze%2C%20Alan%20Kannan%2C%20Ravi%20Kapoor%2C%20Ajai%20A%20mildly%20exponential%20time%20algorithm%20for%20approximating%20the%20number%20of%20solutions%20to%20a%20multidimensional%20knapsack%20problem%201993"
        },
        {
            "id": "3",
            "entry": "[3] James Allen Fill. Eigenvalue bounds on convergence to stationarity for nonreversible markov chains, with an application to the exclusion process. The annals of applied probability, 1(1):62\u2013 87, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fill%2C%20James%20Allen%20Eigenvalue%20bounds%20on%20convergence%20to%20stationarity%20for%20nonreversible%20markov%20chains%2C%20with%20an%20application%20to%20the%20exclusion%20process%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fill%2C%20James%20Allen%20Eigenvalue%20bounds%20on%20convergence%20to%20stationarity%20for%20nonreversible%20markov%20chains%2C%20with%20an%20application%20to%20the%20exclusion%20process%201991"
        },
        {
            "id": "4",
            "entry": "[4] Mark Jerrum and Alistair Sinclair. The Markov chain Monte Carlo method: an approach to approximate counting and integration. Citeseer, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jerrum%2C%20Mark%20Sinclair%2C%20Alistair%20The%20Markov%20chain%20Monte%20Carlo%20method%3A%20an%20approach%20to%20approximate%20counting%20and%20integration%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jerrum%2C%20Mark%20Sinclair%2C%20Alistair%20The%20Markov%20chain%20Monte%20Carlo%20method%3A%20an%20approach%20to%20approximate%20counting%20and%20integration%201996"
        },
        {
            "id": "5",
            "entry": "[5] Bjorn Johansson, Maben Rabi, and Mikael Johansson. A simple peer-to-peer algorithm for distributed optimization in sensor networks. In Decision and Control, 2007 46th IEEE Conference on, pages 4705\u20134710. IEEE, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johansson%2C%20Bjorn%20Rabi%2C%20Maben%20Johansson%2C%20Mikael%20A%20simple%20peer-to-peer%20algorithm%20for%20distributed%20optimization%20in%20sensor%20networks%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johansson%2C%20Bjorn%20Rabi%2C%20Maben%20Johansson%2C%20Mikael%20A%20simple%20peer-to-peer%20algorithm%20for%20distributed%20optimization%20in%20sensor%20networks%202007"
        },
        {
            "id": "6",
            "entry": "[6] Bj\u00f6rn Johansson, Maben Rabi, and Mikael Johansson. A randomized incremental subgradient method for distributed optimization in networked systems. SIAM Journal on Optimization, 20(3):1157\u20131170, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johansson%2C%20Bj%C3%B6rn%20Rabi%2C%20Maben%20Johansson%2C%20Mikael%20A%20randomized%20incremental%20subgradient%20method%20for%20distributed%20optimization%20in%20networked%20systems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johansson%2C%20Bj%C3%B6rn%20Rabi%2C%20Maben%20Johansson%2C%20Mikael%20A%20randomized%20incremental%20subgradient%20method%20for%20distributed%20optimization%20in%20networked%20systems%202009"
        },
        {
            "id": "7",
            "entry": "[7] Song Mei, Yu Bai, Andrea Montanari, et al. The landscape of empirical risk for nonconvex losses. The Annals of Statistics, 46(6A):2747\u20132774, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mei%2C%20Song%20Bai%2C%20Yu%20Montanari%2C%20Andrea%20The%20landscape%20of%20empirical%20risk%20for%20nonconvex%20losses%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mei%2C%20Song%20Bai%2C%20Yu%20Montanari%2C%20Andrea%20The%20landscape%20of%20empirical%20risk%20for%20nonconvex%20losses%202018"
        },
        {
            "id": "8",
            "entry": "[8] Ravi Montenegro, Prasad Tetali, et al. Mathematical aspects of mixing times in markov chains. Foundations and Trends R in Theoretical Computer Science, 1(3):237\u2013354, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Montenegro%2C%20Ravi%20Tetali%2C%20Prasad%20Mathematical%20aspects%20of%20mixing%20times%20in%20markov%20chains%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Montenegro%2C%20Ravi%20Tetali%2C%20Prasad%20Mathematical%20aspects%20of%20mixing%20times%20in%20markov%20chains%202006"
        },
        {
            "id": "9",
            "entry": "[9] Rufus Oldenburger et al. Infinite powers of matrices and characteristic roots. Duke Mathematical Journal, 6(2):357\u2013361, 1940.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oldenburger%2C%20Rufus%20Infinite%20powers%20of%20matrices%20and%20characteristic%20roots%201940",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oldenburger%2C%20Rufus%20Infinite%20powers%20of%20matrices%20and%20characteristic%20roots%201940"
        },
        {
            "id": "10",
            "entry": "[10] S Sundhar Ram, A Nedic, and Venugopal V Veeravalli. Incremental stochastic subgradient algorithms for convex optimization. SIAM Journal on Optimization, 20(2):691\u2013717, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ram%2C%20S.Sundhar%20Nedic%2C%20A.%20Veeravalli%2C%20Venugopal%20V.%20Incremental%20stochastic%20subgradient%20algorithms%20for%20convex%20optimization%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ram%2C%20S.Sundhar%20Nedic%2C%20A.%20Veeravalli%2C%20Venugopal%20V.%20Incremental%20stochastic%20subgradient%20algorithms%20for%20convex%20optimization%202009"
        },
        {
            "id": "11",
            "entry": "[11] Herbert Robbins and Sutton Monro. A stochastic approximation method. The Annals of Mathematical Statistics, 22(3):400\u2013407, 1951.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robbins%2C%20Herbert%20Monro%2C%20Sutton%20A%20stochastic%20approximation%20method%201951",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Robbins%2C%20Herbert%20Monro%2C%20Sutton%20A%20stochastic%20approximation%20method%201951"
        },
        {
            "id": "12",
            "entry": "[12] Herbert Robbins and David Siegmund. A convergence theorem for non negative almost supermartingales and some applications. In Optimizing methods in statistics, pages 233\u2013257.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robbins%2C%20Herbert%20Siegmund%2C%20David%20A%20convergence%20theorem%20for%20non%20negative%20almost%20supermartingales%20and%20some%20applications",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Robbins%2C%20Herbert%20Siegmund%2C%20David%20A%20convergence%20theorem%20for%20non%20negative%20almost%20supermartingales%20and%20some%20applications"
        },
        {
            "id": "13",
            "entry": "[13] Ralph Tyrell Rockafellar. Convex Analysis. Princeton university press, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rockafellar%2C%20Ralph%20Tyrell%20Convex%20Analysis%202015"
        },
        {
            "id": "14",
            "entry": "[14] Konstantin S Turitsyn, Michael Chertkov, and Marija Vucelja. Irreversible monte carlo algorithms for efficient sampling. Physica D: Nonlinear Phenomena, 240(4-5):410\u2013414, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Turitsyn%2C%20Konstantin%20S.%20Chertkov%2C%20Michael%20Vucelja%2C%20Marija%20Irreversible%20monte%20carlo%20algorithms%20for%20efficient%20sampling%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Turitsyn%2C%20Konstantin%20S.%20Chertkov%2C%20Michael%20Vucelja%2C%20Marija%20Irreversible%20monte%20carlo%20algorithms%20for%20efficient%20sampling%202011"
        },
        {
            "id": "15",
            "entry": "[15] Jinshan Zeng and Wotao Yin. On nonconvex decentralized gradient descent. IEEE Transactions on signal processing, 66(11):2834\u20132848, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zeng%2C%20Jinshan%20Yin%2C%20Wotao%20On%20nonconvex%20decentralized%20gradient%20descent%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zeng%2C%20Jinshan%20Yin%2C%20Wotao%20On%20nonconvex%20decentralized%20gradient%20descent%202018"
        }
    ]
}
