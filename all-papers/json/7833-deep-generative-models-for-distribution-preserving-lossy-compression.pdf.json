{
    "filename": "7833-deep-generative-models-for-distribution-preserving-lossy-compression.pdf",
    "metadata": {
        "title": "Deep Generative Models for Distribution-Preserving Lossy Compression",
        "author": "Michael Tschannen, Eirikur Agustsson, Mario Lucic",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7833-deep-generative-models-for-distribution-preserving-lossy-compression.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We propose and study the problem of distribution-preserving lossy compression. Motivated by recent advances in extreme image compression which allow to maintain artifact-free reconstructions even at very low bitrates, we propose to optimize the rate-distortion tradeoff under the constraint that the reconstructed samples follow the distribution of the training data. The resulting compression system recovers both ends of the spectrum: On one hand, at zero bitrate it learns a generative model of the data, and at high enough bitrates it achieves perfect reconstruction. Furthermore, for intermediate bitrates it smoothly interpolates between learning a generative model of the training data and perfectly reconstructing the training samples. We study several methods to approximately solve the proposed optimization problem, including a novel combination of Wasserstein GAN and Wasserstein Autoencoder, and present an extensive theoretical and empirical characterization of the proposed compression systems."
    },
    "keywords": [
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "WGAN",
            "url": "https://en.wikipedia.org/wiki/WGAN"
        },
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_networks"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "image compression",
            "url": "https://en.wikipedia.org/wiki/image_compression"
        },
        {
            "term": "peak signal-to-noise ratio",
            "url": "https://en.wikipedia.org/wiki/peak_signal-to-noise_ratio"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "Data compression methods based on deep neural networks (DNNs) have recently received a great deal of attention",
        "We empirically evaluate the proposed distribution-preserving lossy compression framework for G\u22c6 trained via Wasserstein Autoencoder-maximum mean discrepancy, Wasserstein GAN with gradient penalty (WGAN-GP) [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>], and Wasserstein++ via the gradient penalty from [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>]), on two standard generative modeling benchmark image datasets, CelebA [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] and LSUN bedrooms [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], both downscaled to 64 \u00d7 64 resolution",
        "In Figure 3 we plot the mean squared error, the reconstruction FID, and PV obtained by our distribution-preserving lossy compression models as a function of the bitrate, for different G\u22c6, along with the values obtained for the baselines",
        "Figure 1 presents visual examples produced by our distribution-preserving lossy compression model with G\u22c6 trained using Wasserstein++, along with examples obtained for generative compression and compressive autoencoders",
        "We studied the distribution-preserving lossy compression problem, which amounts to optimizing the rate-distortion tradeoff under the constraint that the reconstructed samples follow the distribution of the training data",
        "We proposed different approaches to solve the distribution-preserving lossy compression problem, in particular Wasserstein++, a novel combination of Wasserstein Autoencoder and Wasserstein GAN, and analytically characterized the properties of the resulting compression systems"
    ],
    "key_statements": [
        "Data compression methods based on deep neural networks (DNNs) have recently received a great deal of attention",
        "Such a system can be learned from data in a fully unsupervised fashion by solving what we call the distribution-preserving lossy compression (DPLC) problem: Optimizing the rate-distortion tradeoff under the constraint that the reconstruction follows the distribution of the training data",
        "We show that the algorithm proposed in [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] is solving a special case of the distribution-preserving lossy compression problem, and demonstrate that it fails to produce stochastic decoders as the rate tends to zero in practice, i.e., it is not effective in enforcing the distribution constraint at very low bitrates",
        "We present an extensive empirical evaluation of the proposed approach on two standard generative adversarial networks data sets, CelebA [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] and LSUN bedrooms [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], realizing the first system that effectively solves the distribution-preserving lossy compression problem",
        "We present several approaches to solve the distribution-preserving lossy compression problem in Section 3",
        "We propose and study different generative model-based approaches to approximately solve the distribution-preserving lossy compression problem",
        "Instead of replacing F in (7) by F, we propose to first learn G\u22c6 by either minimizing the primal form (6) via Wasserstein Autoencoder or the dual form (5) via Wasserstein GAN for c(x, y) = d(x, y), and subsequently minimize the distortion as min",
        "We empirically evaluate the proposed distribution-preserving lossy compression framework for G\u22c6 trained via Wasserstein Autoencoder-maximum mean discrepancy, Wasserstein GAN with gradient penalty (WGAN-GP) [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>], and Wasserstein++ via the gradient penalty from [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>]), on two standard generative modeling benchmark image datasets, CelebA [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] and LSUN bedrooms [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], both downscaled to 64 \u00d7 64 resolution",
        "In Figure 3 we plot the mean squared error, the reconstruction FID, and PV obtained by our distribution-preserving lossy compression models as a function of the bitrate, for different G\u22c6, along with the values obtained for the baselines",
        "Figure 1 presents visual examples produced by our distribution-preserving lossy compression model with G\u22c6 trained using Wasserstein++, along with examples obtained for generative compression and compressive autoencoders",
        "For both CelebA and LSUN bedrooms, the sample FID obtained by Wasserstein++ is considerably smaller than that of Wasserstein Autoencoder, but slightly larger than that of Wasserstein GAN-GP",
        "Note that the decrease in sample and reconstruction FID achieved by Wasserstein++ compared to Wasserstein Autoencoder should be expected to come at the cost of an increased reconstruction mean squared error, as the Wasserstein++ objective is obtained by adding a Wasserstein GAN term to the Wasserstein Autoencoder objective",
        "It can be seen that among our distribution-preserving lossy compression models, the one combined with G\u22c6 from Wasserstein Autoencoder yields the lowest mean squared error, followed by those based on Wasserstein++, and Wasserstein GAN-GP",
        "The qualitative behavior of distribution-preserving lossy compression based on Wasserstein Autoencoder and Wasserstein++ in terms of mean squared error, reconstruction FID, and PV is essentially the same as observed for CelebA",
        "For distribution-preserving lossy compression based on Wasserstein GAN-GP, in contrast, while the mean squared error and PV follow the same trend as for CelebA, the reconstruction FID increases notably as the bitrate decreases",
        "We studied the distribution-preserving lossy compression problem, which amounts to optimizing the rate-distortion tradeoff under the constraint that the reconstructed samples follow the distribution of the training data",
        "We proposed different approaches to solve the distribution-preserving lossy compression problem, in particular Wasserstein++, a novel combination of Wasserstein Autoencoder and Wasserstein GAN, and analytically characterized the properties of the resulting compression systems",
        "Our framework improves over previous methods by producing stochastic decoders at low bitrates, thereby effectively solving the distribution-preserving lossy compression problem for the first time"
    ],
    "summary": [
        "Data compression methods based on deep neural networks (DNNs) have recently received a great deal of attention.",
        "Such a system can be learned from data in a fully unsupervised fashion by solving what we call the distribution-preserving lossy compression (DPLC) problem: Optimizing the rate-distortion tradeoff under the constraint that the reconstruction follows the distribution of the training data.",
        "We propose and study different generative model-based approaches to approximately solve the DPLC problem.",
        "D = G \u25e6 B, where G is a generative model taking samples from a fixed prior distribution PZ as an input, trained to minimize a divergence between PG(Z) and PX , and B is a stochastic function that is trained together with E to minimize distortion for a fixed G.",
        "We empirically evaluate the proposed DPLC framework for G\u22c6 trained via WAE-MMD, WGAN with gradient penalty (WGAN-GP) [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>], and Wasserstein++ via the gradient penalty from [<a class=\"ref-link\" id=\"c28\" href=\"#r28\">28</a>]), on two standard generative modeling benchmark image datasets, CelebA [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] and LSUN bedrooms [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], both downscaled to 64 \u00d7 64 resolution.",
        "It can be seen that among our DPLC models, the one combined with G\u22c6 from WAE yields the lowest MSE, followed by those based on Wasserstein++, and WGAN-GP.",
        "The qualitative behavior of DPLC based on WAE and Wasserstein++ in terms of MSE, reconstruction FID, and PV is essentially the same as observed for CelebA.",
        "The reconstruction FID for WAE is high at all rates, which is not surprising as the sample FID obtained by WAE is large, i.e., WAE struggles to model the distribution of the LSUN bedrooms data set.",
        "For DPLC based on WGAN-GP, in contrast, while the MSE and PV follow the same trend as for CelebA, the reconstruction FID increases notably as the bitrate decreases.",
        "At low rates, the rFID of GC is considerably higher than that of DPLC based on Wasserstein++, meaning that it does not faithfully reproduce the data distribution despite using stochasticity.",
        "We studied the DPLC problem, which amounts to optimizing the rate-distortion tradeoff under the constraint that the reconstructed samples follow the distribution of the training data.",
        "We proposed different approaches to solve the DPLC problem, in particular Wasserstein++, a novel combination of WAE and WGAN, and analytically characterized the properties of the resulting compression systems.",
        "These systems allowed us to obtain essentially artifact-free reconstructions at all rates, covering the full spectrum from learning a generative model of the data at zero bitrate on one hand, to learning a compression system with almost perfect reconstruction at high bitrate on the other hand.",
        "Future work includes scaling the proposed approach up to full-resolution images and applying it to data types other than images"
    ],
    "headline": "We propose and study the problem of distribution-preserving lossy compression",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] G. Toderici, S. M. O\u2019Malley, S. J. Hwang, D. Vincent, D. Minnen, S. Baluja, M. Covell, and R. Sukthankar, \u201cVariable rate image compression with recurrent neural networks,\u201d International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Variable%20rate%20image%20compression%20with%20recurrent%20neural%20networks%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Variable%20rate%20image%20compression%20with%20recurrent%20neural%20networks%2C%202015"
        },
        {
            "id": "2",
            "entry": "[2] G. Toderici, D. Vincent, N. Johnston, S. J. Hwang, D. Minnen, J. Shor, and M. Covell, \u201cFull resolution image compression with recurrent neural networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5435\u20135443, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Toderici%2C%20G.%20Vincent%2C%20D.%20Johnston%2C%20N.%20Hwang%2C%20S.J.%20Full%20resolution%20image%20compression%20with%20recurrent%20neural%20networks%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Toderici%2C%20G.%20Vincent%2C%20D.%20Johnston%2C%20N.%20Hwang%2C%20S.J.%20Full%20resolution%20image%20compression%20with%20recurrent%20neural%20networks%2C%202017"
        },
        {
            "id": "3",
            "entry": "[3] L. Theis, W. Shi, A. Cunningham, and F. Huszar, \u201cLossy image compression with compressive autoencoders,\u201d in International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Theis%2C%20L.%20Shi%2C%20W.%20Cunningham%2C%20A.%20Huszar%2C%20F.%20Lossy%20image%20compression%20with%20compressive%20autoencoders%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Theis%2C%20L.%20Shi%2C%20W.%20Cunningham%2C%20A.%20Huszar%2C%20F.%20Lossy%20image%20compression%20with%20compressive%20autoencoders%2C%202017"
        },
        {
            "id": "4",
            "entry": "[4] O. Rippel and L. Bourdev, \u201cReal-time adaptive image compression,\u201d in Proceedings of the International Conference on Machine Learning (ICML), pp. 2922\u20132930, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rippel%2C%20O.%20Bourdev%2C%20L.%20Real-time%20adaptive%20image%20compression%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rippel%2C%20O.%20Bourdev%2C%20L.%20Real-time%20adaptive%20image%20compression%2C%202017"
        },
        {
            "id": "5",
            "entry": "[5] J. Ball\u00e9, V. Laparra, and E. P. Simoncelli, \u201cEnd-to-end optimized image compression,\u201d in International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ball%C3%A9%2C%20J.%20Laparra%2C%20V.%20Simoncelli%2C%20E.P.%20End-to-end%20optimized%20image%20compression%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ball%C3%A9%2C%20J.%20Laparra%2C%20V.%20Simoncelli%2C%20E.P.%20End-to-end%20optimized%20image%20compression%2C%202016"
        },
        {
            "id": "6",
            "entry": "[6] E. Agustsson, F. Mentzer, M. Tschannen, L. Cavigelli, R. Timofte, L. Benini, and L. V. Gool, \u201cSoft-to-hard vector quantization for end-to-end learning compressible representations,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 1141\u20131151, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agustsson%2C%20E.%20Mentzer%2C%20F.%20Tschannen%2C%20M.%20Cavigelli%2C%20L.%20Soft-to-hard%20vector%20quantization%20for%20end-to-end%20learning%20compressible%20representations%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agustsson%2C%20E.%20Mentzer%2C%20F.%20Tschannen%2C%20M.%20Cavigelli%2C%20L.%20Soft-to-hard%20vector%20quantization%20for%20end-to-end%20learning%20compressible%20representations%2C%202017"
        },
        {
            "id": "7",
            "entry": "[7] N. Johnston, D. Vincent, D. Minnen, M. Covell, S. Singh, T. Chinen, S. Jin Hwang, J. Shor, and G. Toderici, \u201cImproved lossy image compression with priming and spatially adaptive bit rates for recurrent networks,\u201d arXiv:1703.10114, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.10114"
        },
        {
            "id": "8",
            "entry": "[8] M. Li, W. Zuo, S. Gu, D. Zhao, and D. Zhang, \u201cLearning convolutional networks for contentweighted image compression,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3214\u20133223, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20M.%20Zuo%2C%20W.%20Gu%2C%20S.%20Zhao%2C%20D.%20Learning%20convolutional%20networks%20for%20contentweighted%20image%20compression%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20M.%20Zuo%2C%20W.%20Gu%2C%20S.%20Zhao%2C%20D.%20Learning%20convolutional%20networks%20for%20contentweighted%20image%20compression%2C%202018"
        },
        {
            "id": "9",
            "entry": "[9] F. Mentzer, E. Agustsson, M. Tschannen, R. Timofte, and L. Van Gool, \u201cConditional probability models for deep image compression,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4394\u20134402, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mentzer%2C%20F.%20Agustsson%2C%20E.%20Tschannen%2C%20M.%20Timofte%2C%20R.%20Conditional%20probability%20models%20for%20deep%20image%20compression%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mentzer%2C%20F.%20Agustsson%2C%20E.%20Tschannen%2C%20M.%20Timofte%2C%20R.%20Conditional%20probability%20models%20for%20deep%20image%20compression%2C%202018"
        },
        {
            "id": "10",
            "entry": "[10] J. Ball\u00e9, D. Minnen, S. Singh, S. J. Hwang, and N. Johnston, \u201cVariational image compression with a scale hyperprior,\u201d in International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ball%C3%A9%2C%20J.%20Minnen%2C%20D.%20Singh%2C%20S.%20Hwang%2C%20S.J.%20Variational%20image%20compression%20with%20a%20scale%20hyperprior%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ball%C3%A9%2C%20J.%20Minnen%2C%20D.%20Singh%2C%20S.%20Hwang%2C%20S.J.%20Variational%20image%20compression%20with%20a%20scale%20hyperprior%2C%202018"
        },
        {
            "id": "11",
            "entry": "[11] S. Kankanahalli, \u201cEnd-to-end optimized speech coding with deep neural networks,\u201d in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2521\u20132525, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kankanahalli%2C%20S.%20End-to-end%20optimized%20speech%20coding%20with%20deep%20neural%20networks%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kankanahalli%2C%20S.%20End-to-end%20optimized%20speech%20coding%20with%20deep%20neural%20networks%2C%202018"
        },
        {
            "id": "12",
            "entry": "[12] C.-Y. Wu, N. Singhal, and P. Kr\u00e4henb\u00fchl, \u201cVideo compression through image interpolation,\u201d in European Conference on Computer Vision (ECCV), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20C.-Y.%20Singhal%2C%20N.%20Kr%C3%A4henb%C3%BChl%2C%20P.%20Video%20compression%20through%20image%20interpolation%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20C.-Y.%20Singhal%2C%20N.%20Kr%C3%A4henb%C3%BChl%2C%20P.%20Video%20compression%20through%20image%20interpolation%2C%202018"
        },
        {
            "id": "13",
            "entry": "[13] R. Torfason, F. Mentzer, E. Agustsson, M. Tschannen, R. Timofte, and L. V. Gool, \u201cTowards image understanding from deep compression without decoding,\u201d in International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Torfason%2C%20R.%20Mentzer%2C%20F.%20Agustsson%2C%20E.%20Tschannen%2C%20M.%20Towards%20image%20understanding%20from%20deep%20compression%20without%20decoding%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Torfason%2C%20R.%20Mentzer%2C%20F.%20Agustsson%2C%20E.%20Tschannen%2C%20M.%20Towards%20image%20understanding%20from%20deep%20compression%20without%20decoding%2C%202018"
        },
        {
            "id": "14",
            "entry": "[14] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u201cGenerative adversarial nets,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%2C%202014"
        },
        {
            "id": "15",
            "entry": "[15] E. Agustsson, M. Tschannen, F. Mentzer, R. Timofte, and L. Van Gool, \u201cGenerative adversarial networks for extreme learned image compression,\u201d arXiv:1804.02958, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.02958"
        },
        {
            "id": "16",
            "entry": "[16] M. Arjovsky, S. Chintala, and L. Bottou, \u201cWasserstein generative adversarial networks,\u201d in Proceedings of the International Conference on Machine Learning (ICML), pp. 214\u2013223, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20M.%20Chintala%2C%20S.%20Bottou%2C%20L.%20Wasserstein%20generative%20adversarial%20networks%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20M.%20Chintala%2C%20S.%20Bottou%2C%20L.%20Wasserstein%20generative%20adversarial%20networks%2C%202017"
        },
        {
            "id": "17",
            "entry": "[17] I. Tolstikhin, O. Bousquet, S. Gelly, and B. Schoelkopf, \u201cWasserstein auto-encoders,\u201d in International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tolstikhin%2C%20I.%20Bousquet%2C%20O.%20Gelly%2C%20S.%20Schoelkopf%2C%20B.%20Wasserstein%20auto-encoders%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tolstikhin%2C%20I.%20Bousquet%2C%20O.%20Gelly%2C%20S.%20Schoelkopf%2C%20B.%20Wasserstein%20auto-encoders%2C%202018"
        },
        {
            "id": "18",
            "entry": "[18] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter, \u201cGANs trained by a two time-scale update rule converge to a local Nash equilibrium,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 6629\u20136640, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heusel%2C%20M.%20Ramsauer%2C%20H.%20Unterthiner%2C%20T.%20Nessler%2C%20B.%20Hochreiter%2C%20%E2%80%9CGANs%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20Nash%20equilibrium%2C%E2%80%9D%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heusel%2C%20M.%20Ramsauer%2C%20H.%20Unterthiner%2C%20T.%20Nessler%2C%20B.%20Hochreiter%2C%20%E2%80%9CGANs%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20Nash%20equilibrium%2C%E2%80%9D%202017"
        },
        {
            "id": "19",
            "entry": "[19] Z. Liu, P. Luo, X. Wang, and X. Tang, \u201cDeep learning face attributes in the wild,\u201d in Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 3730\u20133738, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%20in%20the%20wild%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Z.%20Luo%2C%20P.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20attributes%20in%20the%20wild%2C%202015"
        },
        {
            "id": "20",
            "entry": "[20] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and J. Xiao, \u201cLSUN: Construction of a large-scale image dataset using deep learning with humans in the loop,\u201d arXiv:1506.03365, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1506.03365"
        },
        {
            "id": "21",
            "entry": "[21] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, \u201cUnpaired image-to-image translation using cycleconsistent adversarial networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2223\u20132232, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycleconsistent%20adversarial%20networks%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycleconsistent%20adversarial%20networks%2C%202017"
        },
        {
            "id": "22",
            "entry": "[22] M. Mathieu, C. Couprie, and Y. LeCun, \u201cDeep multi-scale video prediction beyond mean square error,\u201d in International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mathieu%2C%20M.%20Couprie%2C%20C.%20LeCun%2C%20Y.%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mathieu%2C%20M.%20Couprie%2C%20C.%20LeCun%2C%20Y.%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%2C%202016"
        },
        {
            "id": "23",
            "entry": "[23] J.-Y. Zhu, R. Zhang, D. Pathak, T. Darrell, A. A. Efros, O. Wang, and E. Shechtman, \u201cToward multimodal image-to-image translation,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 465\u2013476, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Zhang%2C%20R.%20Pathak%2C%20D.%20Darrell%2C%20T.%20Toward%20multimodal%20image-to-image%20translation%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Zhang%2C%20R.%20Pathak%2C%20D.%20Darrell%2C%20T.%20Toward%20multimodal%20image-to-image%20translation%2C%202017"
        },
        {
            "id": "24",
            "entry": "[24] D. P. Kingma and M. Welling, \u201cAuto-encoding variational Bayes,\u201d in International Conference on Learning Representations (ICLR), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Welling%2C%20M.%20Auto-encoding%20variational%20Bayes%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20D.P.%20Welling%2C%20M.%20Auto-encoding%20variational%20Bayes%2C%202014"
        },
        {
            "id": "25",
            "entry": "[25] C. Villani, Optimal transport: Old and new, vol.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Villani%2C%20C.%20Optimal%20transport%3A%20Old%20and",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Villani%2C%20C.%20Optimal%20transport%3A%20Old%20and"
        },
        {
            "id": "338",
            "entry": "338. Springer Science & Business Media, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Springer%20Science%20%20Business%20Media%202008"
        },
        {
            "id": "26",
            "entry": "[26] F. Liese and K.-J. Miescke, \u201cStatistical decision theory,\u201d in Statistical Decision Theory, pp. 1\u201352, Springer, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liese%2C%20F.%20Miescke%2C%20K.-J.%20%E2%80%9CStatistical%20decision%20theory%2C%E2%80%9D%20in%20Statistical%20Decision%20Theory%202007"
        },
        {
            "id": "27",
            "entry": "[27] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch\u00f6lkopf, and A. Smola, \u201cA kernel two-sample test,\u201d Journal of Machine Learning Research, vol. 13, pp. 723\u2013773, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Rasch%2C%20M.J.%20Sch%C3%B6lkopf%2C%20B.%20A%20kernel%20two-sample%20test%2C%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Rasch%2C%20M.J.%20Sch%C3%B6lkopf%2C%20B.%20A%20kernel%20two-sample%20test%2C%202012"
        },
        {
            "id": "28",
            "entry": "[28] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, \u201cImproved training of Wasserstein GANs,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 5769\u2013 5779, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20I.%20Ahmed%2C%20F.%20Arjovsky%2C%20M.%20Dumoulin%2C%20V.%20Improved%20training%20of%20Wasserstein%20GANs%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20I.%20Ahmed%2C%20F.%20Arjovsky%2C%20M.%20Dumoulin%2C%20V.%20Improved%20training%20of%20Wasserstein%20GANs%2C%202017"
        },
        {
            "id": "29",
            "entry": "[29] M. Lucic, K. Kurach, M. Michalski, S. Gelly, and O. Bousquet, \u201cAre GANs Created Equal? A Large-Scale Study,\u201d in Advances in Neural Information Processing Systems (NIPS), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lucic%2C%20M.%20Kurach%2C%20K.%20Michalski%2C%20M.%20Gelly%2C%20S.%20Are%20GANs%20Created%20Equal%3F%20A%20Large-Scale%20Study%2C%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lucic%2C%20M.%20Kurach%2C%20K.%20Michalski%2C%20M.%20Gelly%2C%20S.%20Are%20GANs%20Created%20Equal%3F%20A%20Large-Scale%20Study%2C%202018"
        },
        {
            "id": "30",
            "entry": "[30] A. Radford, L. Metz, and S. Chintala, \u201cUnsupervised representation learning with deep convolutional generative adversarial networks,\u201d arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "31",
            "entry": "[31] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%2C%202016"
        },
        {
            "id": "32",
            "entry": "[32] F. Bellard, \u201cBPG Image format.\u201d https://bellard.org/bpg/, 2018.accessed 26 June 2018.",
            "url": "https://bellard.org/bpg/"
        },
        {
            "id": "33",
            "entry": "[33] D. P. Kingma and J. Ba, \u201cAdam: A method for stochastic optimization,\u201d in International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%2C%202015"
        },
        {
            "id": "34",
            "entry": "[34] S. Santurkar, D. Budden, and N. Shavit, \u201cGenerative compression,\u201d in Picture Coding Symposium (PCS), pp. 258\u2013262, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santurkar%2C%20S.%20Budden%2C%20D.%20Shavit%2C%20N.%20%E2%80%9CGenerative%20compression%2C%E2%80%9D%20in%20Picture%20Coding%20Symposium%20%28PCS%29%202018"
        },
        {
            "id": "35",
            "entry": "[35] L. Galteri, L. Seidenari, M. Bertini, and A. Del Bimbo, \u201cDeep generative adversarial compression artifact removal,\u201d in Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 4826\u20134835, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Galteri%2C%20L.%20Seidenari%2C%20L.%20Bertini%2C%20M.%20Bimbo%2C%20A.Del%20Deep%20generative%20adversarial%20compression%20artifact%20removal%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Galteri%2C%20L.%20Seidenari%2C%20L.%20Bertini%2C%20M.%20Bimbo%2C%20A.Del%20Deep%20generative%20adversarial%20compression%20artifact%20removal%2C%202017"
        },
        {
            "id": "36",
            "entry": "[36] C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, and W. Shi, \u201cPhoto-realistic single image super-resolution using a generative adversarial network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4681\u20134690, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20C.%20Theis%2C%20L.%20Huszar%2C%20F.%20Caballero%2C%20J.%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ledig%2C%20C.%20Theis%2C%20L.%20Huszar%2C%20F.%20Caballero%2C%20J.%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%2C%202017"
        },
        {
            "id": "37",
            "entry": "[37] K. Gregor, F. Besse, D. J. Rezende, I. Danihelka, and D. Wierstra, \u201cTowards conceptual compression,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 3549\u20133557, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gregor%2C%20K.%20Besse%2C%20F.%20Rezende%2C%20D.J.%20Danihelka%2C%20I.%20Towards%20conceptual%20compression%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gregor%2C%20K.%20Besse%2C%20F.%20Rezende%2C%20D.J.%20Danihelka%2C%20I.%20Towards%20conceptual%20compression%2C%202016"
        },
        {
            "id": "38",
            "entry": "[38] A. B. L. Larsen, S. K. S\u00f8nderby, H. Larochelle, and O. Winther, \u201cAutoencoding beyond pixels using a learned similarity metric,\u201d arXiv:1512.09300, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.09300"
        },
        {
            "id": "39",
            "entry": "[39] J. Donahue, P. Kr\u00e4henb\u00fchl, and T. Darrell, \u201cAdversarial feature learning,\u201d in International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20J.%20Kr%C3%A4henb%C3%BChl%2C%20P.%20Darrell%2C%20T.%20Adversarial%20feature%20learning%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20J.%20Kr%C3%A4henb%C3%BChl%2C%20P.%20Darrell%2C%20T.%20Adversarial%20feature%20learning%2C%202017"
        },
        {
            "id": "40",
            "entry": "[40] V. Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A. Lamb, M. Arjovsky, and A. Courville, \u201cAdversarially learned inference,\u201d in International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dumoulin%2C%20V.%20Belghazi%2C%20I.%20Poole%2C%20B.%20Mastropietro%2C%20O.%20Adversarially%20learned%20inference%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dumoulin%2C%20V.%20Belghazi%2C%20I.%20Poole%2C%20B.%20Mastropietro%2C%20O.%20Adversarially%20learned%20inference%2C%202017"
        },
        {
            "id": "41",
            "entry": "[41] A. Dosovitskiy and T. Brox, \u201cGenerating images with perceptual similarity metrics based on deep networks,\u201d in Advances in Neural Information Processing Systems (NIPS), pp. 658\u2013666, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dosovitskiy%2C%20A.%20Brox%2C%20T.%20Generating%20images%20with%20perceptual%20similarity%20metrics%20based%20on%20deep%20networks%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dosovitskiy%2C%20A.%20Brox%2C%20T.%20Generating%20images%20with%20perceptual%20similarity%20metrics%20based%20on%20deep%20networks%2C%202016"
        },
        {
            "id": "42",
            "entry": "[42] M. Rosca, B. Lakshminarayanan, D. Warde-Farley, and S. Mohamed, \u201cVariational approaches for auto-encoding generative adversarial networks,\u201d arXiv:1706.04987, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04987"
        },
        {
            "id": "43",
            "entry": "[43] E. J. Delp and O. R. Mitchell, \u201cMoment preserving quantization (signal processing),\u201d IEEE Transactions on Communications, vol. 39, no. 11, pp. 1549\u20131558, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Delp%2C%20E.J.%20Mitchell%2C%20O.R.%20Moment%20preserving%20quantization%20%28signal%20processing%29%2C%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Delp%2C%20E.J.%20Mitchell%2C%20O.R.%20Moment%20preserving%20quantization%20%28signal%20processing%29%2C%201991"
        },
        {
            "id": "44",
            "entry": "[44] M. Li, J. Klejsa, and W. B. Kleijn, \u201cDistribution preserving quantization with dithering and transformation,\u201d IEEE Signal Processing Letters, vol. 17, no. 12, pp. 1014\u20131017, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20M.%20Klejsa%2C%20J.%20Kleijn%2C%20W.B.%20Distribution%20preserving%20quantization%20with%20dithering%20and%20transformation%2C%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20M.%20Klejsa%2C%20J.%20Kleijn%2C%20W.B.%20Distribution%20preserving%20quantization%20with%20dithering%20and%20transformation%2C%202010"
        },
        {
            "id": "45",
            "entry": "[45] H. Luschgy and G. Pag\u00e8s, \u201cFunctional quantization of Gaussian processes,\u201d Journal of Functional Analysis, vol. 196, no. 2, pp. 486\u2013531, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luschgy%2C%20H.%20Pag%C3%A8s%2C%20G.%20Functional%20quantization%20of%20Gaussian%20processes%2C%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luschgy%2C%20H.%20Pag%C3%A8s%2C%20G.%20Functional%20quantization%20of%20Gaussian%20processes%2C%202002"
        },
        {
            "id": "46",
            "entry": "[46] S. Graf and H. Luschgy, Foundations of quantization for probability distributions. Springer, 2007. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graf%2C%20S.%20Luschgy%2C%20H.%20Foundations%20of%20quantization%20for%20probability%20distributions%202007"
        }
    ]
}
