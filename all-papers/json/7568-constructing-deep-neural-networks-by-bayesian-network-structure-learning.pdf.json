{
    "filename": "7568-constructing-deep-neural-networks-by-bayesian-network-structure-learning.pdf",
    "metadata": {
        "title": "Constructing Deep Neural Networks by Bayesian Network Structure Learning",
        "author": "Raanan Y. Rohekar, Shami Nisimov, Yaniv Gurwicz, Guy Koren, Gal Novik",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7568-constructing-deep-neural-networks-by-bayesian-network-structure-learning.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We introduce a principled approach for unsupervised structure learning of deep neural networks. We propose a new interpretation for depth and inter-layer connectivity where conditional independencies in the input distribution are encoded hierarchically in the network structure. Thus, the depth of the network is determined inherently. The proposed method casts the problem of neural network structure learning as a problem of Bayesian network structure learning. Then, instead of directly learning the discriminative structure, it learns a generative graph, constructs its stochastic inverse, and then constructs a discriminative graph. We prove that conditional-dependency relations among the latent variables in the generative graph are preserved in the class-conditional discriminative graph. We demonstrate on image classification benchmarks that the deepest layers (convolutional and dense) of common networks can be replaced by significantly smaller learned structures, while maintaining classification accuracy\u2014state-of-the-art on tested benchmarks. Our structure learning algorithm requires a small computational cost and runs efficiently on a standard desktop CPU."
    },
    "keywords": [
        {
            "term": "deep layer",
            "url": "https://en.wikipedia.org/wiki/deep_layer"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "bayesian network",
            "url": "https://en.wikipedia.org/wiki/bayesian_network"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "structure learning",
            "url": "https://en.wikipedia.org/wiki/Structure_Learning"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "conditional independence",
            "url": "https://en.wikipedia.org/wiki/conditional_independence"
        }
    ],
    "highlights": [
        "Deep neural networks have proven their effectiveness in solving many challenging problems in various domains such as speech recognition (<a class=\"ref-link\" id=\"cGraves_2005_a\" href=\"#rGraves_2005_a\"><a class=\"ref-link\" id=\"cGraves_2005_a\" href=\"#rGraves_2005_a\">Graves & Schmidhuber, 2005</a></a>), computer vision (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\"><a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a></a>; <a class=\"ref-link\" id=\"cGirshick_et+al_2014_a\" href=\"#rGirshick_et+al_2014_a\"><a class=\"ref-link\" id=\"cGirshick_et+al_2014_a\" href=\"#rGirshick_et+al_2014_a\">Girshick et al, 2014</a></a>; <a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\">Szegedy et al, 2015</a></a></a>) and machine translation (<a class=\"ref-link\" id=\"cCollobert_et+al_2011_a\" href=\"#rCollobert_et+al_2011_a\"><a class=\"ref-link\" id=\"cCollobert_et+al_2011_a\" href=\"#rCollobert_et+al_2011_a\">Collobert et al, 2011</a></a>)",
        "We propose a new interpretation for depth and inter-layer connectivity in deep neural networks",
        "We derive a structure learning algorithm such that a hierarchy of independencies in the input distribution is encoded in a deep generative graph, where lower-order independencies are encoded in deeper layers",
        "We presented a principled approach for learning the structure of deep neural networks",
        "The resulting structures encode a hierarchy of independencies in the input distribution, where a node in one layer may connect to another node in any deeper layer, and network depth is determined automatically",
        "We demonstrated that our algorithm learns small structures, and maintains classification accuracies for common image classification benchmarks"
    ],
    "key_statements": [
        "Deep neural networks have proven their effectiveness in solving many challenging problems in various domains such as speech recognition (<a class=\"ref-link\" id=\"cGraves_2005_a\" href=\"#rGraves_2005_a\"><a class=\"ref-link\" id=\"cGraves_2005_a\" href=\"#rGraves_2005_a\">Graves & Schmidhuber, 2005</a></a>), computer vision (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\"><a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a></a>; <a class=\"ref-link\" id=\"cGirshick_et+al_2014_a\" href=\"#rGirshick_et+al_2014_a\"><a class=\"ref-link\" id=\"cGirshick_et+al_2014_a\" href=\"#rGirshick_et+al_2014_a\">Girshick et al, 2014</a></a>; <a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\">Szegedy et al, 2015</a></a></a>) and machine translation (<a class=\"ref-link\" id=\"cCollobert_et+al_2011_a\" href=\"#rCollobert_et+al_2011_a\"><a class=\"ref-link\" id=\"cCollobert_et+al_2011_a\" href=\"#rCollobert_et+al_2011_a\">Collobert et al, 2011</a></a>)",
        "As compute resources became more available, large scale models having millions of parameters could be trained on massive volumes of data, to achieve state-of-the-art solutions",
        "We focus on the design of network topology\u2014structure learning",
        "We propose a new interpretation for depth and inter-layer connectivity in deep neural networks",
        "We derive a structure learning algorithm such that a hierarchy of independencies in the input distribution is encoded in a deep generative graph, where lower-order independencies are encoded in deeper layers",
        "Graph G can be described as a layered deep Bayesian network where the parents of a node can be in any deeper layer and not restricted to the previous layer1",
        "The key idea of constructing G, the generative graph, is to recursively introduce a new latent layer, H(n), after testing n-th order conditional independence in X, and connect it, as a parent, to latent layers created by subsequent recursive calls that test conditional independence of order n+1",
        "We construct Ginv, a graphical model that preserves all conditional dependencies in G but has a different node ordering in which the observed variables, X, have the highest topological order\u2014a stochastic inverse of G",
        "In preliminary experiments we found that, for SVHN and ImageNet, a small subset of the training data is sufficient for learning the structure",
        "It is evident that accuracies of the learned structures are significantly higher than those produced by a set of fully connected layers, especially in cases where the network is limited to a small number of parameters",
        "We presented a principled approach for learning the structure of deep neural networks",
        "The resulting structures encode a hierarchy of independencies in the input distribution, where a node in one layer may connect to another node in any deeper layer, and network depth is determined automatically",
        "We demonstrated that our algorithm learns small structures, and maintains classification accuracies for common image classification benchmarks"
    ],
    "summary": [
        "Deep neural networks have proven their effectiveness in solving many challenging problems in various domains such as speech recognition (<a class=\"ref-link\" id=\"cGraves_2005_a\" href=\"#rGraves_2005_a\"><a class=\"ref-link\" id=\"cGraves_2005_a\" href=\"#rGraves_2005_a\">Graves & Schmidhuber, 2005</a></a>), computer vision (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\"><a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a></a>; <a class=\"ref-link\" id=\"cGirshick_et+al_2014_a\" href=\"#rGirshick_et+al_2014_a\"><a class=\"ref-link\" id=\"cGirshick_et+al_2014_a\" href=\"#rGirshick_et+al_2014_a\">Girshick et al, 2014</a></a>; <a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2015_a\" href=\"#rSzegedy_et+al_2015_a\">Szegedy et al, 2015</a></a></a>) and machine translation (<a class=\"ref-link\" id=\"cCollobert_et+al_2011_a\" href=\"#rCollobert_et+al_2011_a\"><a class=\"ref-link\" id=\"cCollobert_et+al_2011_a\" href=\"#rCollobert_et+al_2011_a\">Collobert et al, 2011</a></a>).",
        "We derive a structure learning algorithm such that a hierarchy of independencies in the input distribution is encoded in a deep generative graph, where lower-order independencies are encoded in deeper layers.",
        "The key idea of constructing G, the generative graph, is to recursively introduce a new latent layer, H(n), after testing n-th order conditional independence in X, and connect it, as a parent, to latent layers created by subsequent recursive calls that test conditional independence of order n+1.",
        "To better understand why deeper layer represent smaller condition independence sets, consider an ancestral sampling of the generative graph.",
        "An autonomous set in gX includes all its nodes\u2019 parents and a corresponding latent structure can be further learned independently, using a recursive call.",
        "We construct Ginv, a graphical model that preserves all conditional dependencies in G but has a different node ordering in which the observed variables, X, have the highest topological order\u2014a stochastic inverse of G.",
        "A discriminative graph Gdis is constructed by replacing the bi-directional dependency relations in Ginv with explaining-away relations, which are provided by adding the observed class variable Y .",
        "Each latent variable H in Gdis is represented in the neural network by a fully-connected layer.",
        "We evaluate our algorithm by using the first convolutional layers of the vanilla topologies as \u201cfeature extractors\u201d and learning a deep structure, \u201clearned head\u201d, from their output.",
        "The deepest layers of the vanilla network, \u201cvanilla head\u201d, is removed and replaced by a structure which is learned, in an unsupervised manner, by our algorithm2.",
        "We evaluate the accuracy of the learned structure as a function of the number of parameters and compare it to a densely connected network having the same depth and size (Figure 5).",
        "It is evident that accuracies of the learned structures are significantly higher than those produced by a set of fully connected layers, especially in cases where the network is limited to a small number of parameters.",
        "In Figure 6 and Table 2 we provide a summary of network sizes and classification accuracies, achieved by replacing the deepest layers of common topologies with a learned structure.",
        "The resulting structures encode a hierarchy of independencies in the input distribution, where a node in one layer may connect to another node in any deeper layer, and network depth is determined automatically.",
        "Casting the problem of learning the connectivity of deep neural network as a Bayesian network structure learning problem, enables the development of new principled and efficient approaches.",
        "While the use of common topologies, for a variety of classification tasks is computationally inefficient, we would expect our approach to learn smaller and more accurate networks for each classification task, uniquely"
    ],
    "headline": "We introduce a principled approach for unsupervised structure learning of deep neural networks",
    "reference_links": [
        {
            "id": "Adams_et+al_2010_a",
            "entry": "Adams, Ryan, Wallach, Hanna, and Ghahramani, Zoubin. Learning the structure of deep sparse graphical models. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 1\u20138, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Adams%2C%20Ryan%20Wallach%2C%20Hanna%20Ghahramani%2C%20Zoubin%20Learning%20the%20structure%20of%20deep%20sparse%20graphical%20models%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Adams%2C%20Ryan%20Wallach%2C%20Hanna%20Ghahramani%2C%20Zoubin%20Learning%20the%20structure%20of%20deep%20sparse%20graphical%20models%202010"
        },
        {
            "id": "Ayinde_2018_a",
            "entry": "Ayinde, Babajide O. and Zurada, Jacek M. Building efficient convnets using redundant feature pruning. In Workshop Track of the International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ayinde%2C%20Babajide%20O.%20Zurada%2C%20Jacek%20M.%20Building%20efficient%20convnets%20using%20redundant%20feature%20pruning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ayinde%2C%20Babajide%20O.%20Zurada%2C%20Jacek%20M.%20Building%20efficient%20convnets%20using%20redundant%20feature%20pruning%202018"
        },
        {
            "id": "Baker_et+al_2016_a",
            "entry": "Baker, Bowen, Gupta, Otkrist, Naik, Nikhil, and Raskar, Ramesh. Designing neural network architectures using reinforcement learning. arXiv preprint arXiv:1611.02167, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02167"
        },
        {
            "id": "Chang_2015_a",
            "entry": "Chang, Jia-Ren and Chen, Yong-Sheng. Batch-normalized maxout network in network. arXiv preprint arXiv:1511.02583, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.02583"
        },
        {
            "id": "Chen_et+al_2015_a",
            "entry": "Chen, Tianqi, Goodfellow, Ian, and Shlens, Jonathon. Net2net: Accelerating learning via knowledge transfer. arXiv preprint arXiv:1511.05641, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05641"
        },
        {
            "id": "Chickering_2002_a",
            "entry": "Chickering, David Maxwell. Optimal structure identification with greedy search. Journal of machine learning research, 3(Nov):507\u2013554, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chickering%2C%20David%20Maxwell%20Optimal%20structure%20identification%20with%20greedy%20search%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chickering%2C%20David%20Maxwell%20Optimal%20structure%20identification%20with%20greedy%20search%202002"
        },
        {
            "id": "Collobert_et+al_2011_a",
            "entry": "Collobert, Ronan, Weston, Jason, Bottou, L\u00e9on, Karlen, Michael, Kavukcuoglu, Koray, and Kuksa, Pavel. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12(Aug): 2493\u20132537, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20Ronan%20Weston%2C%20Jason%20Bottou%2C%20L%C3%A9on%20Karlen%2C%20Michael%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20Ronan%20Weston%2C%20Jason%20Bottou%2C%20L%C3%A9on%20Karlen%2C%20Michael%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011"
        },
        {
            "id": "Cooper_1992_a",
            "entry": "Cooper, Gregory F and Herskovits, Edward. A Bayesian method for the induction of probabilistic networks from data. Machine learning, 9(4):309\u2013347, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cooper%2C%20Gregory%20F.%20Herskovits%2C%20Edward%20A%20Bayesian%20method%20for%20the%20induction%20of%20probabilistic%20networks%20from%20data%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cooper%2C%20Gregory%20F.%20Herskovits%2C%20Edward%20A%20Bayesian%20method%20for%20the%20induction%20of%20probabilistic%20networks%20from%20data%201992"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Deng, Jia, Dong, Wei, Socher, Richard, Li, Li-Jia, Li, Kai, and Fei-Fei, Li. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248\u2013255. IEEE, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "Denton_et+al_2014_a",
            "entry": "Denton, Emily L, Zaremba, Wojciech, Bruna, Joan, LeCun, Yann, and Fergus, Rob. Exploiting linear structure within convolutional networks for efficient evaluation. In Advances in Neural Information Processing Systems, pp. 1269\u20131277, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20L.%20Zaremba%2C%20Wojciech%20Bruna%2C%20Joan%20LeCun%2C%20Yann%20Exploiting%20linear%20structure%20within%20convolutional%20networks%20for%20efficient%20evaluation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20L.%20Zaremba%2C%20Wojciech%20Bruna%2C%20Joan%20LeCun%2C%20Yann%20Exploiting%20linear%20structure%20within%20convolutional%20networks%20for%20efficient%20evaluation%202014"
        },
        {
            "id": "Ding_et+al_2018_a",
            "entry": "Ding, Xiaohan, Ding, Guiguang, Han, Jungong, and Tang, Sheng. Auto-balanced filter pruning for efficient convolutional neural networks. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ding%2C%20Xiaohan%20Ding%2C%20Guiguang%20Han%2C%20Jungong%20Tang%2C%20Sheng%20Auto-balanced%20filter%20pruning%20for%20efficient%20convolutional%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ding%2C%20Xiaohan%20Ding%2C%20Guiguang%20Han%2C%20Jungong%20Tang%2C%20Sheng%20Auto-balanced%20filter%20pruning%20for%20efficient%20convolutional%20neural%20networks%202018"
        },
        {
            "id": "Donahue_et+al_2014_a",
            "entry": "Donahue, Jeff, Jia, Yangqing, Vinyals, Oriol, Hoffman, Judy, Zhang, Ning, Tzeng, Eric, and Darrell, Trevor. Decaf: A deep convolutional activation feature for generic visual recognition. In International Conference on Machine Learning, volume 32, pp. 647\u2013655, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20Jeff%20Jia%2C%20Yangqing%20Vinyals%2C%20Oriol%20Hoffman%2C%20Judy%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20Jeff%20Jia%2C%20Yangqing%20Vinyals%2C%20Oriol%20Hoffman%2C%20Judy%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014"
        },
        {
            "id": "Germain_et+al_2015_a",
            "entry": "Germain, Mathieu, Gregor, Karol, Murray, Iain, and Larochelle, Hugo. Made: Masked autoencoder for distribution estimation. In ICML, pp. 881\u2013889, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Germain%2C%20Mathieu%20Gregor%2C%20Karol%20Murray%2C%20Iain%20Larochelle%2C%20Hugo%20Made%3A%20Masked%20autoencoder%20for%20distribution%20estimation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Germain%2C%20Mathieu%20Gregor%2C%20Karol%20Murray%2C%20Iain%20Larochelle%2C%20Hugo%20Made%3A%20Masked%20autoencoder%20for%20distribution%20estimation%202015"
        },
        {
            "id": "Girshick_et+al_2014_a",
            "entry": "Girshick, Ross, Donahue, Jeff, Darrell, Trevor, and Malik, Jitendra. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 580\u2013587, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Girshick%2C%20Ross%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20Malik%2C%20Jitendra%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Girshick%2C%20Ross%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20Malik%2C%20Jitendra%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation%202014"
        },
        {
            "id": "Graves_2005_a",
            "entry": "Graves, Alex and Schmidhuber, J\u00fcrgen. Framewise phoneme classification with bidirectional lstm and other neural network architectures. Neural Networks, 18(5):602\u2013610, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Schmidhuber%2C%20J%C3%BCrgen%20Framewise%20phoneme%20classification%20with%20bidirectional%20lstm%20and%20other%20neural%20network%20architectures%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Schmidhuber%2C%20J%C3%BCrgen%20Framewise%20phoneme%20classification%20with%20bidirectional%20lstm%20and%20other%20neural%20network%20architectures%202005"
        },
        {
            "id": "Han_et+al_2015_a",
            "entry": "Han, Song, Pool, Jeff, Tran, John, and Dally, William. Learning both weights and connections for efficient neural networks. In Advances in Neural Information Processing Systems, pp. 1135\u20131143, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20Song%20Pool%2C%20Jeff%20Tran%2C%20John%20Dally%2C%20William%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20Song%20Pool%2C%20Jeff%20Tran%2C%20John%20Dally%2C%20William%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20networks%202015"
        },
        {
            "id": "Han_et+al_2016_a",
            "entry": "Han, Song, Mao, Huizi, and Dally, William J. Deep compression: Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In Proceedings of the International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20Song%20Mao%2C%20Huizi%20Dally%2C%20William%20J.%20Deep%20compression%3A%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20Song%20Mao%2C%20Huizi%20Dally%2C%20William%20J.%20Deep%20compression%3A%20Deep%20compression%3A%20Compressing%20deep%20neural%20networks%20with%20pruning%2C%20trained%20quantization%20and%20huffman%20coding%202016"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hinton_et+al_2015_a",
            "entry": "Hinton, Geoffrey, Vinyals, Oriol, and Dean, Jeff. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.02531"
        },
        {
            "id": "Hinton_et+al_2006_a",
            "entry": "Hinton, Geoffrey E, Osindero, Simon, and Teh, Yee-Whye. A fast learning algorithm for deep belief nets. Neural computation, 18(7):1527\u20131554, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20E.%20Osindero%2C%20Simon%20Teh%2C%20Yee-Whye%20A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20Geoffrey%20E.%20Osindero%2C%20Simon%20Teh%2C%20Yee-Whye%20A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets%202006"
        },
        {
            "id": "Huang_et+al_2016_a",
            "entry": "Huang, Gao, Liu, Zhuang, Weinberger, Kilian Q, and van der Maaten, Laurens. Densely connected convolutional networks. arXiv preprint arXiv:1608.06993, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.06993"
        },
        {
            "id": "Huang_et+al_2018_a",
            "entry": "Huang, Qiangui, Zhou, Kevin, You, Suya, and Neumann, Ulrich. Learning to prune filters in convolutional neural networks. arXiv preprint arXiv:1801.07365, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.07365"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Ioffe, Sergey and Szegedy, Christian. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning, pp. 448\u2013456, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "Jarrett_et+al_2009_a",
            "entry": "Jarrett, Kevin, Kavukcuoglu, Koray, LeCun, Yann, et al. What is the best multi-stage architecture for object recognition? In Computer Vision, 2009 IEEE 12th International Conference on, pp. 2146\u20132153. IEEE, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jarrett%2C%20Kevin%20Kavukcuoglu%2C%20Koray%20LeCun%2C%20Yann%20What%20is%20the%20best%20multi-stage%20architecture%20for%20object%20recognition%3F%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jarrett%2C%20Kevin%20Kavukcuoglu%2C%20Koray%20LeCun%2C%20Yann%20What%20is%20the%20best%20multi-stage%20architecture%20for%20object%20recognition%3F%202009"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Kingma, Diederik and Ba, Jimmy. Adam: A method for stochastic optimization. In Proceedings of the International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Krizhevsky, Alex and Hinton, Geoffrey. Learning multiple layers of features from tiny images. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey E. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pp. 1097\u20131105, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Larochelle_2011_a",
            "entry": "Larochelle, Hugo and Murray, Iain. The neural autoregressive distribution estimator. In AISTATS, volume 1, pp. 2, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Larochelle%2C%20Hugo%20Murray%2C%20Iain%20The%20neural%20autoregressive%20distribution%20estimator%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Larochelle%2C%20Hugo%20Murray%2C%20Iain%20The%20neural%20autoregressive%20distribution%20estimator%202011"
        },
        {
            "id": "Lecun_et+al_1998_a",
            "entry": "LeCun, Yann, Bottou, L\u00e9on, Bengio, Yoshua, and Haffner, Patrick. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "Li, Hao, Kadav, Asim, Durdanovic, Igor, Samet, Hanan, and Graf, Hans Peter. Pruning filters for efficient convnets. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Hao%20Kadav%2C%20Asim%20Durdanovic%2C%20Igor%20Samet%2C%20Hanan%20Pruning%20filters%20for%20efficient%20convnets%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Hao%20Kadav%2C%20Asim%20Durdanovic%2C%20Igor%20Samet%2C%20Hanan%20Pruning%20filters%20for%20efficient%20convnets%202017"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Liu, Baoyuan, Wang, Min, Foroosh, Hassan, Tappen, Marshall, and Pensky, Marianna. Sparse convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 806\u2013814, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Baoyuan%20Wang%2C%20Min%20Foroosh%2C%20Hassan%20Tappen%2C%20Marshall%20Sparse%20convolutional%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Baoyuan%20Wang%2C%20Min%20Foroosh%2C%20Hassan%20Tappen%2C%20Marshall%20Sparse%20convolutional%20neural%20networks%202015"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "Long, Mingsheng, Cao, Yue, Wang, Jianmin, and Jordan, Michael. Learning transferable features with deep adaptation networks. In International Conference on Machine Learning, pp. 97\u2013105, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20Mingsheng%20Cao%2C%20Yue%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20Mingsheng%20Cao%2C%20Yue%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015"
        },
        {
            "id": "Manessi_et+al_2017_a",
            "entry": "Manessi, Franco, Rozza, Alessandro, Bianco, Simone, Napoletano, Paolo, and Schettini, Raimondo. Automated pruning for deep neural network compression. arXiv preprint arXiv:1712.01721, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.01721"
        },
        {
            "id": "Miconi_2016_a",
            "entry": "Miconi, Thomas. Neural networks with differentiable structure. arXiv preprint arXiv:1606.06216, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.06216"
        },
        {
            "id": "Miikkulainen_et+al_2017_a",
            "entry": "Miikkulainen, Risto, Liang, Jason, Meyerson, Elliot, Rawal, Aditya, Fink, Dan, Francon, Olivier, Raju, Bala, Navruzyan, Arshak, Duffy, Nigel, and Hodjat, Babak. Evolving deep neural networks. arXiv preprint arXiv:1703.00548, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00548"
        },
        {
            "id": "Murphy_2001_a",
            "entry": "Murphy, K. The Bayes net toolbox for Matlab. Computing Science and Statistics, 33:331\u2013350, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Murphy%2C%20K.%20The%20Bayes%20net%20toolbox%20for%20Matlab%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Murphy%2C%20K.%20The%20Bayes%20net%20toolbox%20for%20Matlab%202001"
        },
        {
            "id": "Nair_2010_a",
            "entry": "Nair, Vinod and Hinton, Geoffrey E. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10), pp. 807\u2013814, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20E.%20Rectified%20linear%20units%20improve%20restricted%20boltzmann%20machines%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20E.%20Rectified%20linear%20units%20improve%20restricted%20boltzmann%20machines%202010"
        },
        {
            "id": "Neal_1992_a",
            "entry": "Neal, Radford M. Connectionist learning of belief networks. Artificial intelligence, 56(1):71\u2013113, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neal%2C%20Radford%20M.%20Connectionist%20learning%20of%20belief%20networks%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neal%2C%20Radford%20M.%20Connectionist%20learning%20of%20belief%20networks%201992"
        },
        {
            "id": "Negrinho_2017_a",
            "entry": "Negrinho, Renato and Gordon, Geoff. Deeparchitect: Automatically designing and training deep architectures. arXiv preprint arXiv:1704.08792, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.08792"
        },
        {
            "id": "Netzer_et+al_2011_a",
            "entry": "Netzer, Yuval, Wang, Tao, Coates, Adam, Bissacco, Alessandro, Wu, Bo, and Ng, Andrew Y. Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning, volume 2011, pp. 5, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "Paige_2016_a",
            "entry": "Paige, Brooks and Wood, Frank. Inference networks for sequential Monte Carlo in graphical models. In Proceedings of the 33rd International Conference on Machine Learning, volume 48 of JMLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paige%2C%20Brooks%20Wood%2C%20Frank%20Inference%20networks%20for%20sequential%20Monte%20Carlo%20in%20graphical%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Paige%2C%20Brooks%20Wood%2C%20Frank%20Inference%20networks%20for%20sequential%20Monte%20Carlo%20in%20graphical%20models%202016"
        },
        {
            "id": "Pearl_2009_a",
            "entry": "Pearl, Judea. Causality: Models, Reasoning, and Inference. Cambridge university press, second edition, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pearl%2C%20Judea%20Causality%3A%20Models%2C%20Reasoning%2C%20and%20Inference%202009"
        },
        {
            "id": "Raiko_et+al_2012_a",
            "entry": "Raiko, Tapani, Valpola, Harri, and LeCun, Yann. Deep learning made easier by linear transformations in perceptrons. In Artificial Intelligence and Statistics, pp. 924\u2013932, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raiko%2C%20Tapani%20Valpola%2C%20Harri%20LeCun%2C%20Yann%20Deep%20learning%20made%20easier%20by%20linear%20transformations%20in%20perceptrons%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raiko%2C%20Tapani%20Valpola%2C%20Harri%20LeCun%2C%20Yann%20Deep%20learning%20made%20easier%20by%20linear%20transformations%20in%20perceptrons%202012"
        },
        {
            "id": "Real_et+al_2017_a",
            "entry": "Real, Esteban, Moore, Sherry, Selle, Andrew, Saxena, Saurabh, Suematsu, Yutaka Leon, Le, Quoc, and Kurakin, Alex. Large-scale evolution of image classifiers. arXiv preprint arXiv:1703.01041, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.01041"
        },
        {
            "id": "Simonyan_2014_a",
            "entry": "Simonyan, Karen and Zisserman, Andrew. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "Smith_et+al_2016_a",
            "entry": "Smith, Leslie N, Hand, Emily M, and Doster, Timothy. Gradual dropin of layers to train very deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4763\u2013 4771, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20Leslie%20N.%20Hand%2C%20Emily%20M.%20Doster%2C%20Timothy%20Gradual%20dropin%20of%20layers%20to%20train%20very%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smith%2C%20Leslie%20N.%20Hand%2C%20Emily%20M.%20Doster%2C%20Timothy%20Gradual%20dropin%20of%20layers%20to%20train%20very%20deep%20neural%20networks%202016"
        },
        {
            "id": "Smithson_et+al_2016_a",
            "entry": "Smithson, Sean C, Yang, Guang, Gross, Warren J, and Meyer, Brett H. Neural networks designing neural networks: Multi-objective hyper-parameter optimization. In Computer-Aided Design (ICCAD), 2016 IEEE/ACM International Conference on, pp. 1\u20138. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smithson%2C%20Sean%20C.%20Yang%2C%20Guang%20Gross%2C%20Warren%20J.%20Meyer%2C%20Brett%20H.%20Neural%20networks%20designing%20neural%20networks%3A%20Multi-objective%20hyper-parameter%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smithson%2C%20Sean%20C.%20Yang%2C%20Guang%20Gross%2C%20Warren%20J.%20Meyer%2C%20Brett%20H.%20Neural%20networks%20designing%20neural%20networks%3A%20Multi-objective%20hyper-parameter%20optimization%202016"
        },
        {
            "id": "Spirtes_et+al_2000_a",
            "entry": "Spirtes, P., Glymour, C., and Scheines, R. Causation, Prediction and Search. MIT Press, 2nd edition, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spirtes%2C%20P.%20Glymour%2C%20C.%20Scheines%2C%20R.Causation%20Prediction%20and%20Search%202000"
        },
        {
            "id": "Srivastava_et+al_2014_a",
            "entry": "Srivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex, Sutskever, Ilya, and Salakhutdinov, Ruslan. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15: 1929\u20131958, 2014. URL http://jmlr.org/papers/v15/srivastava14a.html. Stuhlm\u00fcller, Andreas, Taylor, Jacob, and Goodman, Noah. Learning stochastic inverses. In Advances in neural information processing systems, pp.3048\u20133056, 2013.",
            "url": "http://jmlr.org/papers/v15/srivastava14a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014"
        },
        {
            "id": "Szegedy_et+al_2015_a",
            "entry": "Szegedy, Christian, Liu, Wei, Jia, Yangqing, Sermanet, Pierre, Reed, Scott, Anguelov, Dragomir, Erhan, Dumitru, Vanhoucke, Vincent, and Rabinovich, Andrew. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1\u20139, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "Yang_et+al_0000_a",
            "entry": "Yang, Zichao, Moczulski, Marcin, Denil, Misha, de Freitas, Nando, Smola, Alex, Song, Le, and Wang, Ziyu. Deep fried convnets. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1476\u2013 1483, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Zichao%20Moczulski%2C%20Marcin%20Denil%2C%20Misha%20de%20Freitas%20Deep%20fried%20convnets",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Zichao%20Moczulski%2C%20Marcin%20Denil%2C%20Misha%20de%20Freitas%20Deep%20fried%20convnets"
        },
        {
            "id": "Yehezkel_2009_a",
            "entry": "Yehezkel, Raanan and Lerner, Boaz. Bayesian network structure learning by recursive autonomy identification. Journal of Machine Learning Research, 10(Jul):1527\u20131570, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yehezkel%2C%20Raanan%20Lerner%2C%20Boaz%20Bayesian%20network%20structure%20learning%20by%20recursive%20autonomy%20identification%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yehezkel%2C%20Raanan%20Lerner%2C%20Boaz%20Bayesian%20network%20structure%20learning%20by%20recursive%20autonomy%20identification%202009"
        },
        {
            "id": "Zagoruyko_2016_a",
            "entry": "Zagoruyko, Sergey and Komodakis, Nikos. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.07146"
        },
        {
            "id": "Zoph_2016_a",
            "entry": "Zoph, Barret and Le, Quoc V. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01578"
        },
        {
            "id": "Zoph_et+al_2017_a",
            "entry": "Zoph, Barret, Vasudevan, Vijay, Shlens, Jonathon, and Le, Quoc V. Learning transferable architectures for scalable image recognition. arXiv preprint arXiv:1707.07012, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.07012"
        }
    ]
}
