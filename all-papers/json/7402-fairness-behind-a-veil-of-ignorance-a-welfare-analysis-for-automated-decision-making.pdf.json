{
    "filename": "7402-fairness-behind-a-veil-of-ignorance-a-welfare-analysis-for-automated-decision-making.pdf",
    "metadata": {
        "title": "Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making",
        "author": "Hoda Heidari, Claudio Ferrari, Krishna Gummadi, Andreas Krause",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7402-fairness-behind-a-veil-of-ignorance-a-welfare-analysis-for-automated-decision-making.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We draw attention to an important, yet largely overlooked aspect of evaluating fairness for automated decision making systems\u2014namely risk and welfare considerations. Our proposed family of measures corresponds to the long-established formulations of cardinal social welfare in economics, and is justified by the Rawlsian conception of fairness behind a veil of ignorance. The convex formulation of our welfare-based measures of fairness allows us to integrate them as a constraint into any convex loss minimization pipeline. Our empirical analysis reveals interesting trade-offs between our proposal and (a) prediction accuracy, (b) group discrimination, and (c) Dwork et al.\u2019s notion of individual fairness. Furthermore and perhaps most importantly, our work provides both heuristic justification and empirical evidence suggesting that a lower-bound on our measures often leads to bounded inequality in algorithmic outcomes; hence presenting the first computationally feasible mechanism for bounding individual-level inequality."
    },
    "keywords": [
        {
            "term": "Constant Relative Risk Aversion",
            "url": "https://en.wikipedia.org/wiki/Constant_Relative_Risk_Aversion"
        },
        {
            "term": "trade off",
            "url": "https://en.wikipedia.org/wiki/trade_off"
        },
        {
            "term": "social welfare",
            "url": "https://en.wikipedia.org/wiki/social_welfare"
        },
        {
            "term": "decision making",
            "url": "https://en.wikipedia.org/wiki/decision_making"
        },
        {
            "term": "Logistic Regression",
            "url": "https://en.wikipedia.org/wiki/Logistic_Regression"
        }
    ],
    "highlights": [
        "Data-driven decision making systems have been designed with the sole purpose of maximizing some system-wide measure of performance, such as accuracy or revenue",
        "In light of this example and inspired by the long line of research on distributive justice in economics, in this paper we propose a natural family of measures for evaluating algorithmic fairness corresponding to the well-studied notions of cardinal social welfare in economics [<a class=\"ref-link\" id=\"cHarsanyi_1953_a\" href=\"#rHarsanyi_1953_a\">Harsanyi, 1953</a>, 1955]",
        "We provide empirical evidence suggesting that a lower bound on social welfare often leads to bounded inequality in algorithmic outcomes; presenting the first computationally feasible mechanism for bounding individual-level inequality.\n1.1",
        "Our work makes an important connection between the growing literature on fairness for machine learning, and the long-established formulations of cardinal social welfare in economics",
        "Our measures can be bounded as part of any convex loss minimization program",
        "We provided evidence suggesting that constraining our measures often leads to bounded inequality in algorithmic outcomes"
    ],
    "key_statements": [
        "Data-driven decision making systems have been designed with the sole purpose of maximizing some system-wide measure of performance, such as accuracy or revenue",
        "In light of this example and inspired by the long line of research on distributive justice in economics, in this paper we propose a natural family of measures for evaluating algorithmic fairness corresponding to the well-studied notions of cardinal social welfare in economics [<a class=\"ref-link\" id=\"cHarsanyi_1953_a\" href=\"#rHarsanyi_1953_a\">Harsanyi, 1953</a>, 1955]",
        "We provide empirical evidence suggesting that a lower bound on social welfare often leads to bounded inequality in algorithmic outcomes; presenting the first computationally feasible mechanism for bounding individual-level inequality.\n1.1",
        "Our measures assess the fairness of a decision making model via the expected utility a randomly chosen, risk-averse individual receives as the result of being subject to decision making through that model",
        "Our work makes an important connection between the growing literature on fairness for machine learning, and the long-established formulations of cardinal social welfare in economics",
        "Our measures can be bounded as part of any convex loss minimization program",
        "We provided evidence suggesting that constraining our measures often leads to bounded inequality in algorithmic outcomes"
    ],
    "summary": [
        "Data-driven decision making systems have been designed with the sole purpose of maximizing some system-wide measure of performance, such as accuracy or revenue.",
        "All existing formulations of algorithmic fairness focus on guaranteeing equality of some notion of benefit across different individuals or socially salient groups.",
        "Example 1 Suppose we have four decision making models A, B, C, D each resulting in a different benefit distribution across 5 groups/individuals i1, i2, i3, i4, i5.",
        "In light of this example and inspired by the long line of research on distributive justice in economics, in this paper we propose a natural family of measures for evaluating algorithmic fairness corresponding to the well-studied notions of cardinal social welfare in economics [<a class=\"ref-link\" id=\"cHarsanyi_1953_a\" href=\"#rHarsanyi_1953_a\">Harsanyi, 1953</a>, 1955].",
        "Our core idea consists of comparing the expected utility a randomly chosen, risk-averse subject of algorithmic decision making receives under different predictive models.",
        "The key advantage of our measures of social welfare over those focusing on inequality manifests when, as we saw in the above example, comparing two benefit distributions of different means.",
        "Our empirical analysis reveals interesting trade-offs between our proposal and (a) prediction accuracy, (b) group discrimination, and (c) Dwork et al.\u2019s notion of individual fairness.",
        "<a class=\"ref-link\" id=\"cSpeicher_et+al_2018_a\" href=\"#rSpeicher_et+al_2018_a\">Speicher et al [2018</a>] recently proposed a new measure for quantifying individual unfairness utilizing income inequality indices from economics and applying them to algorithmic benefit distributions.",
        "Both existing formulations of individual-level fairness focus solely on the inter-personal comparisons of algorithmic outcomes/benefits across individuals and do not account for risk and welfare considerations.",
        "While our main focus in this work is on individual-level fairness, our proposal can be readily extended to measure and constraint group-level unfairness.",
        "Similar to [<a class=\"ref-link\" id=\"cZafar_et+al_2017_c\" href=\"#rZafar_et+al_2017_c\">Zafar et al, 2017c</a>], our work can be thought of as a preference-based notions of fairness, but unlike their proposal our measures lead to a total ordering among all alternatives, and can be utilized to measure both individual and group-levelfairness.",
        "Our measures assess the fairness of a decision making model via the expected utility a randomly chosen, risk-averse individual receives as the result of being subject to decision making through that model.",
        "For a fixed mean benefit value, our proposed measure of fairness results in the same total ordering as the Atkinson\u2019s index [<a class=\"ref-link\" id=\"cAtkinson_1970_a\" href=\"#rAtkinson_1970_a\">Atkinson, 1970</a>].",
        "Social welfare Atkinson index Dwork et al.\u2019s notion Mean difference Positive residual diff.",
        "As illustrated in Table 1, there is no unique predictors that simultaneously optimizes social welfare, accuracy, individual, and statistical notions of fairness.",
        "We empirically illustrate our proposal, and investigate the tradeoff between our family of measures and accuracy, as well as existing definitions of group discrimination and individual fairness.",
        "We plan to extend our framework to descriptive behavioural theories, such as prospect theory [<a class=\"ref-link\" id=\"cKahneman_2013_a\" href=\"#rKahneman_2013_a\"><a class=\"ref-link\" id=\"cKahneman_2013_a\" href=\"#rKahneman_2013_a\">Kahneman and Tversky, 2013</a></a>], to explore the human perception of fairness and contrast it with normative prescriptions"
    ],
    "headline": "Perhaps most importantly, our work provides both heuristic justification and empirical evidence suggesting that a lower-bound on our measures often leads to bounded inequality in algorithmic outcomes; presenting the first computationally feasible mechanism for bounding individual-level inequality",
    "reference_links": [
        {
            "id": "Amiel_2003_a",
            "entry": "Yoram Amiel and Frank A. Cowell. Inequality, welfare and monotonicity. In Inequality, Welfare and Poverty: Theory and Measurement, pages 35\u201346. Emerald Group Publishing Limited, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amiel%2C%20Yoram%20Cowell%2C%20Frank%20A.%20Inequality%2C%20welfare%20and%20monotonicity%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Amiel%2C%20Yoram%20Cowell%2C%20Frank%20A.%20Inequality%2C%20welfare%20and%20monotonicity%202003"
        },
        {
            "id": "Angwin_et+al_2016_a",
            "entry": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias. Propublica, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Angwin%2C%20Julia%20Larson%2C%20Jeff%20Mattu%2C%20Surya%20Kirchner%2C%20Lauren%20Machine%20bias%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Angwin%2C%20Julia%20Larson%2C%20Jeff%20Mattu%2C%20Surya%20Kirchner%2C%20Lauren%20Machine%20bias%202016"
        },
        {
            "id": "Atkinson_1970_a",
            "entry": "Anthony B. Atkinson. On the measurement of inequality. Journal of Economic Theory, 2(3):244\u2013263, 1970.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Atkinson%2C%20Anthony%20B.%20On%20the%20measurement%20of%20inequality%201970",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Atkinson%2C%20Anthony%20B.%20On%20the%20measurement%20of%20inequality%201970"
        },
        {
            "id": "Barry-Jester_et+al_2015_a",
            "entry": "Anna Barry-Jester, Ben Casselman, and Dana Goldstein. The new science of sentencing. The Marshall Project, August 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barry-Jester%2C%20Anna%20Casselman%2C%20Ben%20Goldstein%2C%20Dana%20The%20new%20science%20of%20sentencing%202015-08"
        },
        {
            "id": "Calders_et+al_2013_a",
            "entry": "Toon Calders, Asim Karim, Faisal Kamiran, Wasif Ali, and Xiangliang Zhang. Controlling attribute effect in linear regression. In Proceedings of the International Conference on Data Mining, pages 71\u201380. IEEE, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Calders%2C%20Toon%20Karim%2C%20Asim%20Kamiran%2C%20Faisal%20Ali%2C%20Wasif%20Controlling%20attribute%20effect%20in%20linear%20regression%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Calders%2C%20Toon%20Karim%2C%20Asim%20Kamiran%2C%20Faisal%20Ali%2C%20Wasif%20Controlling%20attribute%20effect%20in%20linear%20regression%202013"
        },
        {
            "id": "Carlsson_et+al_2005_a",
            "entry": "Fredrik Carlsson, Dinky Daruvala, and Olof Johansson-Stenman. Are people inequality-averse, or just risk-averse? Economica, 72(287):375\u2013396, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carlsson%2C%20Fredrik%20Daruvala%2C%20Dinky%20Johansson-Stenman%2C%20Olof%20Are%20people%20inequality-averse%2C%20or%20just%20risk-averse%3F%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carlsson%2C%20Fredrik%20Daruvala%2C%20Dinky%20Johansson-Stenman%2C%20Olof%20Are%20people%20inequality-averse%2C%20or%20just%20risk-averse%3F%202005"
        },
        {
            "id": "Corbett-Davies_et+al_2017_a",
            "entry": "Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 797\u2013806. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Corbett-Davies%2C%20Sam%20Pierson%2C%20Emma%20Feller%2C%20Avi%20Goel%2C%20Sharad%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Corbett-Davies%2C%20Sam%20Pierson%2C%20Emma%20Feller%2C%20Avi%20Goel%2C%20Sharad%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017"
        },
        {
            "id": "Frank_2001_a",
            "entry": "Frank A. Cowell and Erik Schokkaert. Risk perceptions and distributional judgments. European Economic Review, 45(4-6):941\u2013952, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Frank%2C%20A.%20Cowell%20and%20Erik%20Schokkaert.%20Risk%20perceptions%20and%20distributional%20judgments%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Frank%2C%20A.%20Cowell%20and%20Erik%20Schokkaert.%20Risk%20perceptions%20and%20distributional%20judgments%202001"
        },
        {
            "id": "Dagum_1990_a",
            "entry": "Camilo Dagum. On the relationship between income inequality measures and social welfare functions. Journal of Econometrics, 43(1-2):91\u2013102, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dagum%2C%20Camilo%20On%20the%20relationship%20between%20income%20inequality%20measures%20and%20social%20welfare%20functions%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dagum%2C%20Camilo%20On%20the%20relationship%20between%20income%20inequality%20measures%20and%20social%20welfare%20functions%201990"
        },
        {
            "id": "Dalton_1920_a",
            "entry": "Hugh Dalton. The measurement of the inequality of incomes. The Economic Journal, 30(119):348\u2013 361, 1920.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dalton%2C%20Hugh%20The%20measurement%20of%20the%20inequality%20of%20incomes%201920",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dalton%2C%20Hugh%20The%20measurement%20of%20the%20inequality%20of%20incomes%201920"
        },
        {
            "id": "Debreu_1959_a",
            "entry": "Gerard Debreu. Topological methods in cardinal utility theory. Technical report, Cowles Foundation for Research in Economics, Yale University, 1959.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Debreu%2C%20Gerard%20Topological%20methods%20in%20cardinal%20utility%20theory.%20Technical%20report%2C%20Cowles%20Foundation%20for%201959",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Debreu%2C%20Gerard%20Topological%20methods%20in%20cardinal%20utility%20theory.%20Technical%20report%2C%20Cowles%20Foundation%20for%201959"
        },
        {
            "id": "Dwork_et+al_2012_a",
            "entry": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness. In Proceedings of the Innovations in Theoretical Computer Science Conference, pages 214\u2013226. ACM, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Reingold%2C%20Omer%20Fairness%20through%20awareness%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Reingold%2C%20Omer%20Fairness%20through%20awareness%202012"
        },
        {
            "id": "Feldman_et+al_2015_a",
            "entry": "Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. Certifying and removing disparate impact. In Proceedings of the International Conference on Knowledge Discovery and Data Mining, pages 259\u2013268. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feldman%2C%20Michael%20Friedler%2C%20Sorelle%20A.%20Moeller%2C%20John%20Scheidegger%2C%20Carlos%20Certifying%20and%20removing%20disparate%20impact%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feldman%2C%20Michael%20Friedler%2C%20Sorelle%20A.%20Moeller%2C%20John%20Scheidegger%2C%20Carlos%20Certifying%20and%20removing%20disparate%20impact%202015"
        },
        {
            "id": "Gorman_1968_a",
            "entry": "William M. Gorman. The structure of utility functions. The Review of Economic Studies, 35(4):367\u2013 390, 1968.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gorman%2C%20William%20M.%20The%20structure%20of%20utility%20functions%201968",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gorman%2C%20William%20M.%20The%20structure%20of%20utility%20functions%201968"
        },
        {
            "id": "Hardt_et+al_2016_a",
            "entry": "Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In Proceedings of Advances in Neural Information Processing Systems, pages 3315\u20133323, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20Moritz%20Price%2C%20Eric%20Srebro%2C%20Nati%20Equality%20of%20opportunity%20in%20supervised%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20Moritz%20Price%2C%20Eric%20Srebro%2C%20Nati%20Equality%20of%20opportunity%20in%20supervised%20learning%202016"
        },
        {
            "id": "Harsanyi_1953_a",
            "entry": "John C. Harsanyi. Cardinal utility in welfare economics and in the theory of risk-taking. Journal of Political Economy, 61(5):434\u2013435, 1953.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harsanyi%2C%20John%20C.%20Cardinal%20utility%20in%20welfare%20economics%20and%20in%20the%20theory%20of%20risk-taking%201953",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Harsanyi%2C%20John%20C.%20Cardinal%20utility%20in%20welfare%20economics%20and%20in%20the%20theory%20of%20risk-taking%201953"
        },
        {
            "id": "Harsanyi_1955_a",
            "entry": "John C. Harsanyi. Cardinal welfare, individualistic ethics, and interpersonal comparisons of utility. Journal of political economy, 63(4):309\u2013321, 1955.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harsanyi%2C%20John%20C.%20Cardinal%20welfare%2C%20individualistic%20ethics%2C%20and%20interpersonal%20comparisons%20of%20utility%201955",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Harsanyi%2C%20John%20C.%20Cardinal%20welfare%2C%20individualistic%20ethics%2C%20and%20interpersonal%20comparisons%20of%20utility%201955"
        },
        {
            "id": "Kahneman_2013_a",
            "entry": "Daniel Kahneman and Amos Tversky. Prospect theory: An analysis of decision under risk. In Handbook of the Fundamentals of Financial Decision Making: Part I, pages 99\u2013127. World Scientific, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kahneman%2C%20Daniel%20Tversky%2C%20Amos%20Prospect%20theory%3A%20An%20analysis%20of%20decision%20under%20risk%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kahneman%2C%20Daniel%20Tversky%2C%20Amos%20Prospect%20theory%3A%20An%20analysis%20of%20decision%20under%20risk%202013"
        },
        {
            "id": "Kamiran_2009_a",
            "entry": "Faisal Kamiran and Toon Calders. Classifying without discriminating. In Proceedings of the 2nd International Conference on Computer, Control and Communication, pages 1\u20136. IEEE, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamiran%2C%20Faisal%20Calders%2C%20Toon%20Classifying%20without%20discriminating%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamiran%2C%20Faisal%20Calders%2C%20Toon%20Classifying%20without%20discriminating%202009"
        },
        {
            "id": "Kamishima_et+al_2011_a",
            "entry": "Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma. Fairness-aware learning through regularization approach. In Proceedings of the International Conference on Data Mining Workshops, pages 643\u2013650. IEEE, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamishima%2C%20Toshihiro%20Akaho%2C%20Shotaro%20Sakuma%2C%20Jun%20Fairness-aware%20learning%20through%20regularization%20approach%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamishima%2C%20Toshihiro%20Akaho%2C%20Shotaro%20Sakuma%2C%20Jun%20Fairness-aware%20learning%20through%20regularization%20approach%202011"
        },
        {
            "id": "Kleinberg_et+al_2017_a",
            "entry": "Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. Inherent trade-offs in the fair determination of risk scores. In In proceedings of the 8th Innovations in Theoretical Computer Science Conference, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kleinberg%2C%20Jon%20Mullainathan%2C%20Sendhil%20Raghavan%2C%20Manish%20Inherent%20trade-offs%20in%20the%20fair%20determination%20of%20risk%20scores%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kleinberg%2C%20Jon%20Mullainathan%2C%20Sendhil%20Raghavan%2C%20Manish%20Inherent%20trade-offs%20in%20the%20fair%20determination%20of%20risk%20scores%202017"
        },
        {
            "id": "Larson_et+al_2016_a",
            "entry": "Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. Data and analysis for \u2018How we analyzed the COMPAS recidivism algorithm\u2019. https://github.com/propublica/compas-analysis, 2016.",
            "url": "https://github.com/propublica/compas-analysis"
        },
        {
            "id": "Levin_2016_a",
            "entry": "Sam Levin. A beauty contest was judged by AI and the robots didn\u2019t like dark skin. The Guardian, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levin%2C%20Sam%20A%20beauty%20contest%20was%20judged%20by%20AI%20and%20the%20robots%20didn%E2%80%99t%20like%20dark%20skin%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levin%2C%20Sam%20A%20beauty%20contest%20was%20judged%20by%20AI%20and%20the%20robots%20didn%E2%80%99t%20like%20dark%20skin%202016"
        },
        {
            "id": "Lichman_2013_a",
            "entry": "M. Lichman. UCI machine learning repository: Communities and crime data set. http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime, 2013.",
            "url": "http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime"
        },
        {
            "id": "Miller_2015_a",
            "entry": "Clair Miller. Can an algorithm hire better than a human? The New York Times, June 25 2015. Retrieved 4/28/2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miller%2C%20Clair%20Can%20an%20algorithm%20hire%20better%20than%20a%20human%3F%202015-06-25",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miller%2C%20Clair%20Can%20an%20algorithm%20hire%20better%20than%20a%20human%3F%202015-06-25"
        },
        {
            "id": "Moulin_2004_a",
            "entry": "Herv\u00e9 Moulin. Fair division and collective welfare. MIT press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Moulin%2C%20Herv%C3%A9%20Fair%20division%20and%20collective%20welfare%202004"
        },
        {
            "id": "Petrasic_et+al_2017_a",
            "entry": "Kevin Petrasic, Benjamin Saul, James Greig, and Matthew Bornfreund. Algorithms and bias: What lenders need to know. White & Case, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Petrasic%2C%20Kevin%20Saul%2C%20Benjamin%20Greig%2C%20James%20Bornfreund%2C%20Matthew%20Algorithms%20and%20bias%3A%20What%20lenders%20need%20to%20know%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Petrasic%2C%20Kevin%20Saul%2C%20Benjamin%20Greig%2C%20James%20Bornfreund%2C%20Matthew%20Algorithms%20and%20bias%3A%20What%20lenders%20need%20to%20know%202017"
        },
        {
            "id": "Pigou_1912_a",
            "entry": "Arthur Cecil Pigou. Wealth and welfare. Macmillan and Company, limited, 1912.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pigou%2C%20Arthur%20Cecil%20Wealth%20and%20welfare%201912"
        },
        {
            "id": "Rawls_2009_a",
            "entry": "John Rawls. A theory of justice. Harvard university press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rawls%2C%20John%20A%20theory%20of%20justice%202009"
        },
        {
            "id": "Roberts_1980_a",
            "entry": "Kevin W. S. Roberts. Interpersonal comparability and social choice theory. The Review of Economic Studies, pages 421\u2013439, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roberts%2C%20Kevin%20W.S.%20Interpersonal%20comparability%20and%20social%20choice%20theory%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roberts%2C%20Kevin%20W.S.%20Interpersonal%20comparability%20and%20social%20choice%20theory%201980"
        },
        {
            "id": "Rudin_2013_a",
            "entry": "Cynthia Rudin. Predictive policing using machine learning to detect patterns of crime. Wired Magazine, August 2013. Retrieved 4/28/2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rudin%2C%20Cynthia%20Predictive%20policing%20using%20machine%20learning%20to%20detect%20patterns%20of%20crime%202013-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rudin%2C%20Cynthia%20Predictive%20policing%20using%20machine%20learning%20to%20detect%20patterns%20of%20crime%202013-08"
        },
        {
            "id": "Schwartz_1980_a",
            "entry": "Joseph Schwartz and Christopher Winship. The welfare approach to measuring inequality. Sociological methodology, 11:1\u201336, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schwartz%2C%20Joseph%20Winship%2C%20Christopher%20The%20welfare%20approach%20to%20measuring%20inequality%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schwartz%2C%20Joseph%20Winship%2C%20Christopher%20The%20welfare%20approach%20to%20measuring%20inequality%201980"
        },
        {
            "id": "Sen_1977_a",
            "entry": "Amartya Sen. On weights and measures: informational constraints in social welfare analysis. Econometrica: Journal of the Econometric Society, pages 1539\u20131572, 1977.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sen%2C%20Amartya%20On%20weights%20and%20measures%3A%20informational%20constraints%20in%20social%20welfare%20analysis%201977",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sen%2C%20Amartya%20On%20weights%20and%20measures%3A%20informational%20constraints%20in%20social%20welfare%20analysis%201977"
        },
        {
            "id": "Speicher_et+al_2018_a",
            "entry": "Till Speicher, Hoda Heidari, Nina Grgic-Hlaca, Krishna P. Gummadi, Adish Singla, Adrian Weller, and Muhammad Bilal Zafar. A unified approach to quantifying algorithmic unfairness: Measuring individual and group unfairness via inequality indices. In Proceedings of the International Conference on Knowledge Discovery and Data Mining, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Speicher%2C%20Till%20Heidari%2C%20Hoda%20Grgic-Hlaca%2C%20Nina%20Gummadi%2C%20Krishna%20P.%20A%20unified%20approach%20to%20quantifying%20algorithmic%20unfairness%3A%20Measuring%20individual%20and%20group%20unfairness%20via%20inequality%20indices%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Speicher%2C%20Till%20Heidari%2C%20Hoda%20Grgic-Hlaca%2C%20Nina%20Gummadi%2C%20Krishna%20P.%20A%20unified%20approach%20to%20quantifying%20algorithmic%20unfairness%3A%20Measuring%20individual%20and%20group%20unfairness%20via%20inequality%20indices%202018"
        },
        {
            "id": "Sweeney_2013_a",
            "entry": "Latanya Sweeney. Discrimination in online ad delivery. Queue, 11(3):10, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sweeney%2C%20Latanya%20Discrimination%20in%20online%20ad%20delivery%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sweeney%2C%20Latanya%20Discrimination%20in%20online%20ad%20delivery%202013"
        },
        {
            "id": "Equity_et+al_1974_a",
            "entry": "Hal R. Varian. Equity, envy, and efficiency. Journal of economic theory, 9(1):63\u201391, 1974.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hal%20R%20Varian%20Equity%20envy%20and%20efficiency%20Journal%20of%20economic%20theory%20916391%201974",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hal%20R%20Varian%20Equity%20envy%20and%20efficiency%20Journal%20of%20economic%20theory%20916391%201974"
        },
        {
            "id": "Zafar_et+al_2017_a",
            "entry": "Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th International Conference on World Wide Web, pages 1171\u20131180, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20Muhammad%20Bilal%20Valera%2C%20Isabel%20Rodriguez%2C%20Manuel%20Gomez%20Gummadi%2C%20Krishna%20P.%20Fairness%20beyond%20disparate%20treatment%20%26%20disparate%20impact%3A%20Learning%20classification%20without%20disparate%20mistreatment%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20Muhammad%20Bilal%20Valera%2C%20Isabel%20Rodriguez%2C%20Manuel%20Gomez%20Gummadi%2C%20Krishna%20P.%20Fairness%20beyond%20disparate%20treatment%20%26%20disparate%20impact%3A%20Learning%20classification%20without%20disparate%20mistreatment%202017"
        },
        {
            "id": "Zafar_et+al_2017_b",
            "entry": "Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. Fairness constraints: Mechanisms for fair classification. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20Muhammad%20Bilal%20Valera%2C%20Isabel%20Rodriguez%2C%20Manuel%20Gomez%20Gummadi%2C%20Krishna%20P.%20Fairness%20constraints%3A%20Mechanisms%20for%20fair%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20Muhammad%20Bilal%20Valera%2C%20Isabel%20Rodriguez%2C%20Manuel%20Gomez%20Gummadi%2C%20Krishna%20P.%20Fairness%20constraints%3A%20Mechanisms%20for%20fair%20classification%202017"
        },
        {
            "id": "Zafar_et+al_2017_c",
            "entry": "Muhammad Bilal Zafar, Isabel Valera, Manuel Rodriguez, Krishna Gummadi, and Adrian Weller. From parity to preference-based notions of fairness in classification. In Proceedings of Advances in Neural Information Processing Systems, pages 228\u2013238, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20Muhammad%20Bilal%20Valera%2C%20Isabel%20Rodriguez%2C%20Manuel%20Gummadi%2C%20Krishna%20From%20parity%20to%20preference-based%20notions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20Muhammad%20Bilal%20Valera%2C%20Isabel%20Rodriguez%2C%20Manuel%20Gummadi%2C%20Krishna%20From%20parity%20to%20preference-based%20notions%202017"
        }
    ]
}
