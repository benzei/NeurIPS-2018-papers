{
    "filename": "7970-how-to-tell-when-a-clustering-is-approximately-correct-using-convex-relaxations.pdf",
    "metadata": {
        "title": "How to tell when a clustering is (approximately) correct using convex relaxations",
        "author": "Marina Meila",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7970-how-to-tell-when-a-clustering-is-approximately-correct-using-convex-relaxations.pdf"
        },
        "abstract": "We introduce the Sublevel Set (SS) method, a generic method to obtain sufficient guarantees of near-optimality and uniqueness (up to small perturbations) for a clustering. This method can be instantiated for a variety of clustering loss functions for which convex relaxations exist. Obtaining the guarantees in practice amounts to solving a convex optimization. We demonstrate the applicability of this method by obtaining distribution free guarantees for K-means clustering on realistic data sets."
    },
    "keywords": [
        {
            "term": "positive semidefinite",
            "url": "https://en.wikipedia.org/wiki/positive_semidefinite"
        },
        {
            "term": "spectral clustering",
            "url": "https://en.wikipedia.org/wiki/spectral_clustering"
        },
        {
            "term": "Molecular Dynamics",
            "url": "https://en.wikipedia.org/wiki/Molecular_Dynamics"
        },
        {
            "term": "hierarchical clustering",
            "url": "https://en.wikipedia.org/wiki/hierarchical_clustering"
        }
    ],
    "highlights": [
        "This paper proposes a framework for providing theoretical guarantees for clustering, without making assumptions about the data generating process",
        "The sublevel set method we show how to use an existing relaxation to obtain guarantees of the form",
        "We have introduced a generic method for obtaining distribution free, worst case, guarantees for a variety of clustering algorithms",
        "The method exploits the vast amount of existing work in convex relaxations for clustering; as more results and tighter relaxations appear in this area, the Sublevel Set method will be able to take advantage of them",
        "For the case of K-means clustering, we have shown empirically that the bounds obtained apply to realistic cases, far surpassing the existing results",
        "When the relaxations used by the Sublevel Set method are tight, we obtain bounds that are not only informative, they are near 0 in non-trivial situations"
    ],
    "key_statements": [
        "This paper proposes a framework for providing theoretical guarantees for clustering, without making assumptions about the data generating process",
        "The main question we address is: can a user tell, with no prior knowledge, if the clustering C returned by a clustering algorithm is meaningful? This is the fundamental problem of cluster validation",
        "The sublevel set method we show how to use an existing relaxation to obtain guarantees of the form",
        "Given a Loss, its clustering problem (3), and a convex relaxation (4) for it we proceed as follows: Step 1 Use the convex relaxation to find a set of good clusterings that contains a given C",
        "The radii of these sublevel sets tell us how clusterable the data is, in a norm that depends on the relaxation X",
        "We provide examples and s1ufficient conditions when this is possible by existing methods.\n3 Bound from Tractable Relaxation bounds for the K-means loss",
        "We introduce the following Semi-Definite Program instantiating the generic Sublevel Set problem (5)",
        "Let D be represented by its squared distance matrix D, let C be a clustering of D, with K, p , p defined as in Section 2.1, and let C be the optimal value of problem (SS )",
        "We show that the framework of Section 2 can be readily applied to several other clustering paradigms with very little extra work",
        "Theorem 3 shows that getting bounds for a clustering paradigm does not depend directly on the Loss or clustering paradigm, but on the space of the convex relaxation",
        "Existing distribution free guarantees for clustering All the previous explicit Bound from Tractable Relaxation bounds we are aware of are based on spectral relaxations: [Mei06] gives a spectral bound for K-means and",
        "The distribution free Bound from Tractable Relaxation bounds hold even when the data are not contained in non-intersecting balls, which is the best known condition for clusterability under model assumptions",
        "We have found that the Bound from Tractable Relaxation \" is virtually insensitive to the value of n, and degrades slowly when p decreases",
        "We have introduced a generic method for obtaining distribution free, worst case, guarantees for a variety of clustering algorithms",
        "The method exploits the vast amount of existing work in convex relaxations for clustering; as more results and tighter relaxations appear in this area, the Sublevel Set method will be able to take advantage of them",
        "For the case of K-means clustering, we have shown empirically that the bounds obtained apply to realistic cases, far surpassing the existing results",
        "When the relaxations used by the Sublevel Set method are tight, we obtain bounds that are not only informative, they are near 0 in non-trivial situations"
    ],
    "summary": [
        "This paper proposes a framework for providing theoretical guarantees for clustering, without making assumptions about the data generating process.",
        "It should be evident, that it is not possible to obtain such guarantees in general; they can only exist for clusterable data, as illustrated in Figure 1.",
        "Specifies what kind of clusters the user is interested in, via the optimization problem below.",
        "Given a Loss, its clustering problem (3), and a convex relaxation (4) for it we proceed as follows: Step 1 Use the convex relaxation to find a set of good clusterings that contains a given C .",
        "The radii of these sublevel sets tell us how clusterable the data is, in a norm that depends on the relaxation X .",
        "Finding the best clustering of a data set D is equivalent to solving the following optimization problem [ABC+14], which we will refer to as the K-means problem.",
        "Let D be represented by its squared distance matrix D, let C be a clustering of D, with K, p , p defined as in Section 2.1, and let C be the optimal value of problem (SS ).",
        "Theorem 3 shows that getting bounds for a clustering paradigm does not depend directly on the Loss or clustering paradigm, but on the space of the convex relaxation.",
        "Existing distribution free guarantees for clustering All the previous explicit BTR bounds we are aware of are based on spectral relaxations: [Mei06] gives a spectral bound for K-means and",
        "The framework of [HM16] argues for the need of a hypothesis class, of an assumption that the data fits the model class decodability condition), and the use of problem specific tractable relaxations as vehicles for both tractable algorithms and error bounds.",
        "The distribution free BTR bounds hold even when the data are not contained in non-intersecting balls, which is the best known condition for clusterability under model assumptions",
        "We have introduced a generic method for obtaining distribution free, worst case, guarantees for a variety of clustering algorithms.",
        "For the case of K-means clustering, we have shown empirically that the bounds obtained apply to realistic cases, far surpassing the existing results.",
        "We cannot show that all the clusterable cases can be given guarantees; this depends on the tightness of the relaxation.",
        "We believe that expanding the method to larger data, beyond the scope of generic SDP solvers, is possible by exploiting the special structure of the SS problem.",
        "When the relaxations used by the SS method are tight, we obtain bounds that are not only informative, they are near 0 in non-trivial situations"
    ],
    "headline": "We introduce the Sublevel Set  method, a generic method to obtain sufficient guarantees of near-optimality and uniqueness  for a clustering",
    "reference_links": [
        {
            "id": "Awasthi_et+al_2014_a",
            "entry": "[ABC+14] P. Awasthi, A. S. Bandeira, M. Charikar, R. Krishnaswamy, S. Villar, and R. Ward. Relax, no need to round: integrality of clustering formulations. ArXiv e-prints, August 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Awasthi%2C%20P.%20Bandeira%2C%20A.S.%20Charikar%2C%20M.%20Krishnaswamy%2C%20R.%20Relax%2C%20no%20need%20to%20round%3A%20integrality%20of%20clustering%20formulations.%20ArXiv%20e-prints%202014-08"
        },
        {
            "id": "Awasthi_et+al_2010_a",
            "entry": "[ABS10] Pranjal Awasthi, Avrim Blum, and Or Sheffet. Center-based clustering under perturbation stability. ArXiv, 1009.3594, 2010.",
            "arxiv_url": "https://arxiv.org/pdf/1009.3594"
        },
        {
            "id": "Awasthi_et+al_2012_a",
            "entry": "[ABS12] Pranjal Awasthi, Avrim Blum, and Or Sheffet. Center-based clustering under perturbation stability. Inf. Process. Lett., 112(1-2):49\u201354, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Awasthi%2C%20Pranjal%20Blum%2C%20Avrim%20Sheffet%2C%20Or%20Center-based%20clustering%20under%20perturbation%20stability%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Awasthi%2C%20Pranjal%20Blum%2C%20Avrim%20Sheffet%2C%20Or%20Center-based%20clustering%20under%20perturbation%20stability%202012"
        },
        {
            "id": "Awasthi_et+al_2014_b",
            "entry": "[ABV14] Pranjal Awasthi, Maria-Florina Balcan, and Konstantin Voevodski. Local algorithms for interactive clustering. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014, pages 550\u2013558, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Awasthi%2C%20Pranjal%20Balcan%2C%20Maria-Florina%20Voevodski%2C%20Konstantin%20Local%20algorithms%20for%20interactive%20clustering%202014-06-21",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Awasthi%2C%20Pranjal%20Balcan%2C%20Maria-Florina%20Voevodski%2C%20Konstantin%20Local%20algorithms%20for%20interactive%20clustering%202014-06-21"
        },
        {
            "id": "Awasthi_et+al_2015_a",
            "entry": "[ACKS15] Pranjal Awasthi, Moses Charikar, Ravishankar Krishnaswamy, and Ali Kemal Sinop. The hardness of approximation of euclidean k-means. In Lars Arge and J\u00e1nos Pach, editors, 31st International Symposium on Computational Geometry, SoCG 2015, June 22-25, 2015, Eindhoven, The Netherlands, volume 34 of LIPIcs, pages 754\u2013767. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Awasthi%2C%20Pranjal%20Charikar%2C%20Moses%20Krishnaswamy%2C%20Ravishankar%20Sinop%2C%20Ali%20Kemal%20The%20hardness%20of%20approximation%20of%20euclidean%20k-means%202015-06-22",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Awasthi%2C%20Pranjal%20Charikar%2C%20Moses%20Krishnaswamy%2C%20Ravishankar%20Sinop%2C%20Ali%20Kemal%20The%20hardness%20of%20approximation%20of%20euclidean%20k-means%202015-06-22"
        },
        {
            "id": "Achlioptas_2005_a",
            "entry": "[AM05] Dimitris Achlioptas and Frank McSherry. On spectral learning of mixtures of distributions. In Peter Auer and Ron Meir, editors, 18th Annual Conference on Learning Theory, COLT 2005, pages 458\u2013471, Berlin/Heidelberg, 2005. Springer.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Achlioptas%2C%20Dimitris%20McSherry%2C%20Frank%20On%20spectral%20learning%20of%20mixtures%20of%20distributions%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Achlioptas%2C%20Dimitris%20McSherry%2C%20Frank%20On%20spectral%20learning%20of%20mixtures%20of%20distributions%202005"
        },
        {
            "id": "Abbe_2015_a",
            "entry": "[AS15] Emmanuel Abbe and Colin Sandon. Community detection in general stochastic block models: fundamental limits and efficient recovery algorithms. arXiv preprint arXiv:1503.00609, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.00609"
        },
        {
            "id": "Abbe_2016_a",
            "entry": "[AS16a] Emmanuel Abbe and Colin Sandon. Achieving the ks threshold in the general stochastic block model with linearized acyclic belief propagation. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing Systems 29, pages 1334\u20131342. Curran Associates, Inc., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbe%2C%20Emmanuel%20Sandon%2C%20Colin%20Achieving%20the%20ks%20threshold%20in%20the%20general%20stochastic%20block%20model%20with%20linearized%20acyclic%20belief%20propagation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abbe%2C%20Emmanuel%20Sandon%2C%20Colin%20Achieving%20the%20ks%20threshold%20in%20the%20general%20stochastic%20block%20model%20with%20linearized%20acyclic%20belief%20propagation%202016"
        },
        {
            "id": "Ahmadian_2016_a",
            "entry": "[AS16b] Sara Ahmadian and Chaitanya Swamy. Approximation algorithms for clustering problems with lower bounds and outliers. In Ioannis Chatzigiannakis, Michael Mitzenmacher, Yuval Rabani, and Davide Sangiorgi, editors, 43rd International Colloquium on Automata, Languages, and Programming, ICALP 2016, July 11-15, 2016, Rome, Italy, volume 55 of LIPIcs, pages 69:1\u201369:15. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahmadian%2C%20Sara%20Swamy%2C%20Chaitanya%20Approximation%20algorithms%20for%20clustering%20problems%20with%20lower%20bounds%20and%20outliers%202016-07-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahmadian%2C%20Sara%20Swamy%2C%20Chaitanya%20Approximation%20algorithms%20for%20clustering%20problems%20with%20lower%20bounds%20and%20outliers%202016-07-11"
        },
        {
            "id": "Ben-David_0000_a",
            "entry": "[Ben15] Shai Ben-David. Computational feasibility of clustering under clusterability assumptions. Technical Report arXiv:1501.00437, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1501.00437"
        },
        {
            "id": "Bach_2007_a",
            "entry": "[BH07] Francis R. Bach and Za\u00efd Harchaoui. DIFFRAC: a discriminative and flexible framework for clustering. In John C. Platt, Daphne Koller, Yoram Singer, and Sam T. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 49\u201356. Curran Associates, Inc., 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bach%2C%20Francis%20R.%20Harchaoui%2C%20Za%C3%AFd%20DIFFRAC%3A%20a%20discriminative%20and%20flexible%20framework%20for%20clustering%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bach%2C%20Francis%20R.%20Harchaoui%2C%20Za%C3%AFd%20DIFFRAC%3A%20a%20discriminative%20and%20flexible%20framework%20for%20clustering%202007"
        },
        {
            "id": "Balcan_et+al_2016_a",
            "entry": "[BHW16] Maria-Florina Balcan, Nika Haghtalab, and Colin White. k-center clustering under perturbation resilience. In 43rd International Colloquium on Automata, Languages, and Programming, ICALP 2016, July 11-15, 2016, Rome, Italy, pages 68:1\u201368:14, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20Maria-Florina%20Haghtalab%2C%20Nika%20White%2C%20Colin%20k-center%20clustering%20under%20perturbation%20resilience%202016-07-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20Maria-Florina%20Haghtalab%2C%20Nika%20White%2C%20Colin%20k-center%20clustering%20under%20perturbation%20resilience%202016-07-11"
        },
        {
            "id": "Bilu_2009_a",
            "entry": "[BL09] Yonatan Bilu and Nathan Linial. Are stable instances easy? CoRR, abs/0906.3162, 2009.",
            "arxiv_url": "https://arxiv.org/pdf/0906.3162"
        },
        {
            "id": "Balcan_2016_b",
            "entry": "[BL16] Maria-Florina Balcan and Yingyu Liang. Clustering under perturbation resilience. SIAM J. Comput., 45(1):102\u2013155, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20Maria-Florina%20Liang%2C%20Yingyu%20Clustering%20under%20perturbation%20resilience%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20Maria-Florina%20Liang%2C%20Yingyu%20Clustering%20under%20perturbation%20resilience%202016"
        },
        {
            "id": "Balcan_et+al_2014_a",
            "entry": "[BLG14] Maria-Florina Balcan, Yingyu Liang, and Pramod Gupta. Robust hierarchical clustering. Journal of Machine Learning Research, 15(1):3831\u20133871, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balcan%2C%20Maria-Florina%20Liang%2C%20Yingyu%20Gupta%2C%20Pramod%20Robust%20hierarchical%20clustering%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balcan%2C%20Maria-Florina%20Liang%2C%20Yingyu%20Gupta%2C%20Pramod%20Robust%20hierarchical%20clustering%202014"
        },
        {
            "id": "Bubeck_et+al_2012_a",
            "entry": "[BMvL12] Sebastien Bubeck, Marina Meila, and Ulrike von Luxburg. How the initialization affects the stability of the k-means algorithm. ESAIM: Probability and Statistics, 16:436\u2013452, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bubeck%2C%20Sebastien%20Meila%2C%20Marina%20von%20Luxburg%2C%20Ulrike%20How%20the%20initialization%20affects%20the%20stability%20of%20the%20k-means%20algorithm%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bubeck%2C%20Sebastien%20Meila%2C%20Marina%20von%20Luxburg%2C%20Ulrike%20How%20the%20initialization%20affects%20the%20stability%20of%20the%20k-means%20algorithm%202012"
        },
        {
            "id": "Balakrishnan_et+al_2014_a",
            "entry": "[BWY14] Sivaraman Balakrishnan, Martin J. Wainwright, and Bin Yu. Statistical guarantees for the EM algorithm: From population to sample-based analysis. CoRR, abs/1408.2156, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1408.2156"
        },
        {
            "id": "Charikar_2016_a",
            "entry": "[CC16] Moses Charikar and Vaggos Chatziafratis. Approximate hierarchical clustering via sparsest cut and spreading metrics. Technical Report 1609:09548, arXiv, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charikar%2C%20Moses%20Chatziafratis%2C%20Vaggos%20Approximate%20hierarchical%20clustering%20via%20sparsest%20cut%20and%20spreading%20metrics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charikar%2C%20Moses%20Chatziafratis%2C%20Vaggos%20Approximate%20hierarchical%20clustering%20via%20sparsest%20cut%20and%20spreading%20metrics%202016"
        },
        {
            "id": "Cole_et+al_2015_a",
            "entry": "[CFR15] Sam Cole, Shmuel Friedland, and Lev Reyzin. A simple spectral algorithm for recovering planted partitions. CoRR, abs/1503.00423, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.00423"
        },
        {
            "id": "Charikar_1999_a",
            "entry": "[CG99] M. Charikar and S. Guha. Improved combinatorial algorithms for the facility location and k-median problems. In 40th Annual Symposium on Foundations of Computer Science, pages 378\u2013388, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charikar%2C%20M.%20Guha%2C%20S.%20Improved%20combinatorial%20algorithms%20for%20the%20facility%20location%20and%20k-median%20problems%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charikar%2C%20M.%20Guha%2C%20S.%20Improved%20combinatorial%20algorithms%20for%20the%20facility%20location%20and%20k-median%20problems%201999"
        },
        {
            "id": "Chmiela_et+al_2017_a",
            "entry": "[CTS+17] Stefan Chmiela, Alexandre Tkatchenko, Huziel E. Sauceda, Igor Poltavsky, Kristof T. Sch\u00fctt, and Klaus-Robert M\u00fcller. Machine learning of accurate energy-conserving molecular force fields. Science Advances, 3(5):e1603015, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chmiela%2C%20Stefan%20Tkatchenko%2C%20Alexandre%20Sauceda%2C%20Huziel%20E.%20Poltavsky%2C%20Igor%20Machine%20learning%20of%20accurate%20energy-conserving%20molecular%20force%20fields%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chmiela%2C%20Stefan%20Tkatchenko%2C%20Alexandre%20Sauceda%2C%20Huziel%20E.%20Poltavsky%2C%20Igor%20Machine%20learning%20of%20accurate%20energy-conserving%20molecular%20force%20fields%202017"
        },
        {
            "id": "Chen_2014_a",
            "entry": "[CX14] Yudong Chen and Jiaming Xu. Statistical-computational tradeoffs in planted problems and submatrix localization with a growing number of clusters and submatrices. arXiv preprint arXiv:1402.1267, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1402.1267"
        },
        {
            "id": "Dasgupta_2000_a",
            "entry": "[Das00] Sanjoy Dasgupta. Experiments with random projection. In UAI \u201900: Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, pages 143\u2013151, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dasgupta%2C%20Sanjoy%20Experiments%20with%20random%20projection.%20In%20UAI%E2%80%99%2000%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dasgupta%2C%20Sanjoy%20Experiments%20with%20random%20projection.%20In%20UAI%E2%80%99%2000%202000"
        },
        {
            "id": "Dasgupta_2016_a",
            "entry": "[Das16] Sanjoy Dasgupta. A cost function for similarity-based hierarchical clustering. In Daniel Wichs and Yishay Mansour, editors, Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016, pages 118\u2013127. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dasgupta%2C%20Sanjoy%20A%20cost%20function%20for%20similarity-based%20hierarchical%20clustering%202016-06-18",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dasgupta%2C%20Sanjoy%20A%20cost%20function%20for%20similarity-based%20hierarchical%20clustering%202016-06-18"
        },
        {
            "id": "Dhillon_et+al_2004_a",
            "entry": "[DGK04] Inderjit S. Dhillon, Y. Guan, and Brian Kulis. Kernel K-means, spectral clustering and normalized cuts. In Ronny Kohavi, Johannes Gehrke, and Joydeep Ghosh, editors, Proceedings of The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining(KDD), pages 551\u2013556. ACM Press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dhillon%2C%20Inderjit%20S.%20Guan%2C%20Y.%20K-means%2C%20Brian%20Kulis%20Kernel%20spectral%20clustering%20and%20normalized%20cuts%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dhillon%2C%20Inderjit%20S.%20Guan%2C%20Y.%20K-means%2C%20Brian%20Kulis%20Kernel%20spectral%20clustering%20and%20normalized%20cuts%202004"
        },
        {
            "id": "Brodley_2004_a",
            "entry": "[DH04] Chris Ding and Xiaofeng He. K-means clustering via principal component analysis. In Carla E. Brodley, editor, Proceedings of the International Machine Learning Conference (ICML). Morgan Kauffman, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Chris%20Ding%20and%20Xiaofeng%20He.%20K-means%20clustering%20via%20principal%20component%20analysis%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Chris%20Ding%20and%20Xiaofeng%20He.%20K-means%20clustering%20via%20principal%20component%20analysis%202004"
        },
        {
            "id": "Deshpande_2015_a",
            "entry": "[DM15] Y. Deshpande and A. Montanari. Improved Sum-of-Squares Lower Bounds for Hidden Clique and Hidden Submatrix Problems. ArXiv e-prints, February 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deshpande%2C%20Y.%20Montanari%2C%20A.%20Improved%20Sum-of-Squares%20Lower%20Bounds%20for%20Hidden%20Clique%20and%20Hidden%20Submatrix%20Problems.%20ArXiv%20e-prints%202015-02"
        },
        {
            "id": "Dasgupta_2007_a",
            "entry": "[DS07] Sanjoy Dasgupta and Leonard Schulman. A probabilistic analysis of em for mixtures of separated, spherical gaussians. Journal of Machine Learnig Research, 8:203\u2013226, Feb 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dasgupta%2C%20Sanjoy%20Schulman%2C%20Leonard%20A%20probabilistic%20analysis%20of%20em%20for%20mixtures%20of%20separated%2C%20spherical%20gaussians%202007-02",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dasgupta%2C%20Sanjoy%20Schulman%2C%20Leonard%20A%20probabilistic%20analysis%20of%20em%20for%20mixtures%20of%20separated%2C%20spherical%20gaussians%202007-02"
        },
        {
            "id": "Holland_et+al_1983_a",
            "entry": "[HLL83] Paul W Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. Stochastic blockmodels: First steps. Social networks, 5(2):109\u2013137, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Holland%2C%20Paul%20W.%20Laskey%2C%20Kathryn%20Blackmond%20Leinhardt%2C%20Samuel%20Stochastic%20blockmodels%3A%20First%20steps%201983",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Holland%2C%20Paul%20W.%20Laskey%2C%20Kathryn%20Blackmond%20Leinhardt%2C%20Samuel%20Stochastic%20blockmodels%3A%20First%20steps%201983"
        },
        {
            "id": "Hazan_2016_a",
            "entry": "[HM16] Elad Hazan and Tengyu Ma. A non-generative framework and convex relaxations for unsupervised learning. CoRR, abs/1610.01132, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.01132"
        },
        {
            "id": "Hein_2011_a",
            "entry": "[HS11] Matthias Hein and Simon Setzer. Beyond spectral clustering - tight relaxations of balanced graph cuts. In J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 24, pages 2366\u20132374. Curran Associates, Inc., 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hein%2C%20Matthias%20Setzer%2C%20Simon%20Beyond%20spectral%20clustering%20-%20tight%20relaxations%20of%20balanced%20graph%20cuts%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hein%2C%20Matthias%20Setzer%2C%20Simon%20Beyond%20spectral%20clustering%20-%20tight%20relaxations%20of%20balanced%20graph%20cuts%202011"
        },
        {
            "id": "Iguchi_et+al_2015_a",
            "entry": "[IMPV15a] T. Iguchi, D. G. Mixon, J. Peterson, and S. Villar. On the tightness of an SDP relaxation of k-means. ArXiv e-prints, May 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iguchi%2C%20T.%20Mixon%2C%20D.G.%20Peterson%2C%20J.%20Villar%2C%20S.%20On%20the%20tightness%20of%20an%20SDP%20relaxation%20of%20k-means.%20ArXiv%20e-prints%202015-05"
        },
        {
            "id": "Iguchi_et+al_2015_b",
            "entry": "[IMPV15b] T. Iguchi, D. G. Mixon, J. Peterson, and S. Villar. Probably certifiably correct k-means clustering. ArXiv e-prints, September 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iguchi%2C%20T.%20Mixon%2C%20D.G.%20Peterson%2C%20J.%20Villar%2C%20S.%20Probably%20certifiably%20correct%20k-means%20clustering.%20ArXiv%20e-prints%202015-09"
        },
        {
            "id": "Jalali_et+al_2016_a",
            "entry": "[JHDF16] A. Jalali, Q. Han, I. Dumitriu, and M. Fazel. Relative density and exact recovery in heterogeneous stochastic block models. In Proc. of NIPS 2016, December 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jalali%2C%20A.%20Han%2C%20Q.%20Dumitriu%2C%20I.%20Fazel%2C%20M.%20Relative%20density%20and%20exact%20recovery%20in%20heterogeneous%20stochastic%20block%20models%202016-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jalali%2C%20A.%20Han%2C%20Q.%20Dumitriu%2C%20I.%20Fazel%2C%20M.%20Relative%20density%20and%20exact%20recovery%20in%20heterogeneous%20stochastic%20block%20models%202016-12"
        },
        {
            "id": "Karrer_2011_a",
            "entry": "[KN11] B. Karrer and M.E.J. Newman. Stochastic blockmodels and community structure in networks. Physical Review, 83:16107, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karrer%2C%20B.%20Newman%2C%20M.E.J.%20Stochastic%20blockmodels%20and%20community%20structure%20in%20networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karrer%2C%20B.%20Newman%2C%20M.E.J.%20Stochastic%20blockmodels%20and%20community%20structure%20in%20networks%202011"
        },
        {
            "id": "Kannan_et+al_2000_a",
            "entry": "[KVV00] Ravi Kannan, Santosh Vempala, and Adrian Vetta. On clusterings: good, bad and spectral. In Proc. of 41st Symposium on the Foundations of Computer Science, FOCS 2000, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kannan%2C%20Ravi%20Vempala%2C%20Santosh%20Vetta%2C%20Adrian%20On%20clusterings%3A%20good%2C%20bad%20and%20spectral%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kannan%2C%20Ravi%20Vempala%2C%20Santosh%20Vetta%2C%20Adrian%20On%20clusterings%3A%20good%2C%20bad%20and%20spectral%202000"
        },
        {
            "id": "Lee_et+al_2014_a",
            "entry": "[LGT14] James R. Lee, Shayan Oveis Gharan, and Luca Trevisan. Multi-way spectral partitioning and higher-order cheeger inequalities. arxiv preprint arXiv:1111.1055, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1111.1055"
        },
        {
            "id": "Meila_2006_a",
            "entry": "[Mei06] Marina Meila. The uniqueness of a good optimum for K-means. In Andrew Moore and William Cohen, editors, Proceedings of the International Machine Learning Conference (ICML), pages 625\u2013632. International Machine Learning Society, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meila%2C%20Marina%20The%20uniqueness%20of%20a%20good%20optimum%20for%20K-means%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Meila%2C%20Marina%20The%20uniqueness%20of%20a%20good%20optimum%20for%20K-means%202006"
        },
        {
            "id": "Meila_2012_a",
            "entry": "[Mei12] Marina Meila. Local equivalence of distances between clusterings \u2013 a geometric perspective. Machine Learning, 86(3):369\u2013389, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meila%2C%20Marina%20Local%20equivalence%20of%20distances%20between%20clusterings%20%E2%80%93%20a%20geometric%20perspective%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Meila%2C%20Marina%20Local%20equivalence%20of%20distances%20between%20clusterings%20%E2%80%93%20a%20geometric%20perspective%202012"
        },
        {
            "id": "Meila_et+al_2005_a",
            "entry": "[MSX05] Marina Meila, Susan Shortreed, and Liang Xu. Regularized spectral learning. In Robert Cowell and Zoubin Ghahramani, editors, Proceedings of the Artificial Intelligence and Statistics Workshop(AISTATS 05), 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meila%2C%20Marina%20Shortreed%2C%20Susan%20Xu%2C%20Liang%20Regularized%20spectral%20learning%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Meila%2C%20Marina%20Shortreed%2C%20Susan%20Xu%2C%20Liang%20Regularized%20spectral%20learning%202005"
        },
        {
            "id": "Peng_et+al_2015_a",
            "entry": "[PSZ15] Richard Peng, He Sun, and Luca Zanetti. Partitioning well-clustered graphs: Spectral clustering works! In Peter Gr\u00fcnwald and Elad Hazan, editors, Proceedings of The 28th Conference on Learning Theory (COLT), volume 40, pages 1\u201333, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peng%2C%20Richard%20Sun%2C%20He%20Zanetti%2C%20Luca%20Partitioning%20well-clustered%20graphs%3A%20Spectral%20clustering%20works%21%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peng%2C%20Richard%20Sun%2C%20He%20Zanetti%2C%20Luca%20Partitioning%20well-clustered%20graphs%3A%20Spectral%20clustering%20works%21%202015"
        },
        {
            "id": "Peng_2007_a",
            "entry": "[PW07] J Peng and Y Wei. Approximating k-means-type clustering via semidefinite programming. SIAM journal on optimization, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peng%2C%20J.%20Wei%2C%20Y.%20Approximating%20k-means-type%20clustering%20via%20semidefinite%20programming%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peng%2C%20J.%20Wei%2C%20Y.%20Approximating%20k-means-type%20clustering%20via%20semidefinite%20programming%202007"
        },
        {
            "id": "Qin_2013_a",
            "entry": "[QR13] Tai Qin and Karl Rohe. Regularized spectral clustering under the degree-corrected stochastic blockmodel. In Advances in Neural Information Processing Systems, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Qin%2C%20Tai%20Rohe%2C%20Karl%20Regularized%20spectral%20clustering%20under%20the%20degree-corrected%20stochastic%20blockmodel%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Qin%2C%20Tai%20Rohe%2C%20Karl%20Regularized%20spectral%20clustering%20under%20the%20degree-corrected%20stochastic%20blockmodel%202013"
        },
        {
            "id": "Rangapuram_et+al_2014_a",
            "entry": "[RMH14] Syama Sundar Rangapuram, Pramod Kaushik Mudrakarta, and Matthias Hein. Tight continuous relaxation of the balanced k-cut problem. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 3131\u20133139. Curran Associates, Inc., 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rangapuram%2C%20Syama%20Sundar%20Mudrakarta%2C%20Pramod%20Kaushik%20Hein%2C%20Matthias%20Tight%20continuous%20relaxation%20of%20the%20balanced%20k-cut%20problem%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rangapuram%2C%20Syama%20Sundar%20Mudrakarta%2C%20Pramod%20Kaushik%20Hein%2C%20Matthias%20Tight%20continuous%20relaxation%20of%20the%20balanced%20k-cut%20problem%202014"
        },
        {
            "id": "Roy_2016_a",
            "entry": "[RP16] Aurko Roy and Sebastian Pokutta. Hierarchical clustering via spreading metrics. In Isabelle Guyon and Ulrike von Luxburg, editors, Advances in Neural Information Processing Systems (NIPS), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roy%2C%20Aurko%20Pokutta%2C%20Sebastian%20Hierarchical%20clustering%20via%20spreading%20metrics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roy%2C%20Aurko%20Pokutta%2C%20Sebastian%20Hierarchical%20clustering%20via%20spreading%20metrics%202016"
        },
        {
            "id": "Munro_2004_a",
            "entry": "[Swa04] Chaitanya Swamy. Correlation clustering: maximizing agreements via semidefinite programming. In J. Ian Munro, editor, Proceedings of the Fifteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA, pages 526\u2013527. SIAM, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Chaitanya%20Swamy.%20Correlation%20clustering%3A%20maximizing%20agreements%20via%20semidefinite%20programming%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Chaitanya%20Swamy.%20Correlation%20clustering%3A%20maximizing%20agreements%20via%20semidefinite%20programming%202004"
        },
        {
            "id": "Vinayak_et+al_2014_a",
            "entry": "[VOH14] Ramya Korlakai Vinayak, Samet Oymak, and Babak Hassibi. Graph clustering with missing data: Convex algorithms and analysis. In Advances in Neural Information Processing Systems (NIPS), pages 2996\u20133004, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinayak%2C%20Ramya%20Korlakai%20Oymak%2C%20Samet%20Hassibi%2C%20Babak%20Graph%20clustering%20with%20missing%20data%3A%20Convex%20algorithms%20and%20analysis%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinayak%2C%20Ramya%20Korlakai%20Oymak%2C%20Samet%20Hassibi%2C%20Babak%20Graph%20clustering%20with%20missing%20data%3A%20Convex%20algorithms%20and%20analysis%202014"
        },
        {
            "id": "Vempala_2004_a",
            "entry": "[VW04] Santosh Vempala and Grant Wang. A spectral algorithm for learning mixtures of distributions. Journal of Computer Systems Science, 68(4):841\u2013860, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vempala%2C%20Santosh%20Wang%2C%20Grant%20A%20spectral%20algorithm%20for%20learning%20mixtures%20of%20distributions%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vempala%2C%20Santosh%20Wang%2C%20Grant%20A%20spectral%20algorithm%20for%20learning%20mixtures%20of%20distributions%202004"
        },
        {
            "id": "Wan_2015_a",
            "entry": "[WM15] Yali Wan and Marina Meila. A class of network models recoverable by spectral clustering. In Daniel Lee and Masashi Sugiyama, editors, Advances in Neural Information Processing Systems (NIPS), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wan%2C%20Yali%20Meila%2C%20Marina%20A%20class%20of%20network%20models%20recoverable%20by%20spectral%20clustering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wan%2C%20Yali%20Meila%2C%20Marina%20A%20class%20of%20network%20models%20recoverable%20by%20spectral%20clustering%202015"
        },
        {
            "id": "Xing_2003_a",
            "entry": "[XJ03] Eric P. Xing and Michael I. Jordan. On semidefinite relaxation for normalized k-cut and connections to spectral clustering. Technical Report UCB/CSD-03-1265, EECS Department, University of California, Berkeley, Jun 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xing%2C%20Eric%20P.%20Jordan%2C%20Michael%20I.%20On%20semidefinite%20relaxation%20for%20normalized%20k-cut%20and%20connections%20to%20spectral%20clustering%202003-06"
        },
        {
            "id": "Yang_et+al_2015_a",
            "entry": "[YST15] L.Q. Yang, D.F. Sun, and K.C. Toh. Sdpnal+: a majorized semismooth newton-cg augmented lagrangian method for semidefinite programming with nonnegative constraints. Mathematical Programming Computation, 7:331\u2013366, 2015. arXiv:1406.0942.",
            "arxiv_url": "https://arxiv.org/pdf/1406.0942"
        },
        {
            "id": "Zhao_et+al_2010_a",
            "entry": "[ZST10] Xinyuan Zhao, Defeng Sun, and Kim-Chuan Toh. A newton-cg augmented lagrangian method for semidefinite programming. SIAM J. Optimization, 20:1737\u20131765., 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Xinyuan%20Sun%2C%20Defeng%20Toh%2C%20Kim-Chuan%20A%20newton-cg%20augmented%20lagrangian%20method%20for%20semidefinite%20programming%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Xinyuan%20Sun%2C%20Defeng%20Toh%2C%20Kim-Chuan%20A%20newton-cg%20augmented%20lagrangian%20method%20for%20semidefinite%20programming%202010"
        }
    ]
}
