{
    "filename": "7670-an-information-theoretic-analysis-for-thompson-sampling-with-many-actions.pdf",
    "metadata": {
        "title": "An Information-Theoretic Analysis for Thompson Sampling with Many Actions",
        "author": "Shi Dong, Benjamin Van Roy",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7670-an-information-theoretic-analysis-for-thompson-sampling-with-many-actions.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Information-theoretic Bayesian regret bounds of Russo and Van Roy [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] capture the dependence of regret on prior uncertainty. However, this dependence is through entropy, which can become arbitrarily large as the number of actions increases. We establish new bounds that depend instead on a notion of rate-distortion. Among other things, this allows us to recover through information-theoretic arguments a near-optimal bound for the linear bandit. We also offer a bound for the logistic bandit that dramatically improves on the best previously available, though this bound depends on an information-theoretic statistic that we have only been able to quantify via computation."
    },
    "keywords": [
        {
            "term": "van roy",
            "url": "https://en.wikipedia.org/wiki/Van_Roy"
        },
        {
            "term": "thompson sampling",
            "url": "https://en.wikipedia.org/wiki/thompson_sampling"
        },
        {
            "term": "rate distortion",
            "url": "https://en.wikipedia.org/wiki/rate_distortion"
        },
        {
            "term": "information ratio",
            "url": "https://en.wikipedia.org/wiki/information_ratio"
        }
    ],
    "highlights": [
        "Thompson sampling [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has proved to be an effective heuristic across a broad range of online decision problems [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>]",
        "The information ratio \u0393 is a statistic that captures the manner in which an algorithm trades off between immediate reward and information acquisition; Russo and Van Roy [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] bound the information ratio of Thompson sampling for particular classes of problems",
        "Our analysis addresses th\u221ais gap in understanding by establishing a bound that decays as \u03b2 becomes large, converging to 2d T log 3 for any fixed T. This analysis relies on a conjecture about the information ratio of Thompson sampling for the logistic bandit, which we only support through computational results.\n2 Problem Formulation",
        "Since the logistic bandit setting is incompatible with Assumption 1, we propose the following conjecture, which is supported with numerical evidence",
        "Through an analysis based on rate-distortion, we established a new information-theoretic regret boun\u221ad for Thompson sampling that scales gracefully to large action spaces",
        "The same regret bound applies to the logistic bandit problem if a conjecture about the information ratio that agrees with computational results holds"
    ],
    "key_statements": [
        "Thompson sampling [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has proved to be an effective heuristic across a broad range of online decision problems [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>]",
        "The information ratio \u0393 is a statistic that captures the manner in which an algorithm trades off between immediate reward and information acquisition; Russo and Van Roy [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] bound the information ratio of Thompson sampling for particular classes of problems",
        "Our analysis addresses th\u221ais gap in understanding by establishing a bound that decays as \u03b2 becomes large, converging to 2d T log 3 for any fixed T. This analysis relies on a conjecture about the information ratio of Thompson sampling for the logistic bandit, which we only support through computational results.\n2 Problem Formulation",
        "Since the logistic bandit setting is incompatible with Assumption 1, we propose the following conjecture, which is supported with numerical evidence",
        "Through an analysis based on rate-distortion, we established a new information-theoretic regret boun\u221ad for Thompson sampling that scales gracefully to large action spaces",
        "The same regret bound applies to the logistic bandit problem if a conjecture about the information ratio that agrees with computational results holds"
    ],
    "summary": [
        "Thompson sampling [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has proved to be an effective heuristic across a broad range of online decision problems [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>].",
        "We apply our analysis to linear and generalized linear bandits and establish Bayesian regret bounds that rem\u221aain sharp with large action spaces.",
        "This analysis relies on a conjecture about the information ratio of Thompson sampling for the logistic bandit, which we only support through computational results.",
        "Conditioned on the true model parameter and the selected action, the reward is bounded1, i.e. sup R(y) \u2212 inf R(y) \u2264 1.",
        "We restate a result proven in [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], which proposes a bound for the regret of any policy in terms of the worst-case information ratio.",
        "Following the above line of analysis, we can bound the regret of Thompson sampling by the mutual information between the statistic \u03c8 and \u03b8\u2217.",
        "According to Proposition 2, over period t if the agent deviated from her original Thompson sampling scheme and applied a \u201cone-step\u201d compressed Thompson sampling to learn \u03b8t\u2217 by sampling \u03b8t, the extra regret that she would incur can be bounded).",
        "A similar line of analysis as in [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] allows us to bound the information ratio of the one-step compressed Thompson sampling.",
        "It significantly improves the bound O dT \u00b7 H(A\u2217) in [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>] and the bound O |A|T log |A| in [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>] in that it drops the dependence on the cardinality of the action set and imposes no assumption on the reward d\u221aistribution.",
        "Both the information ratio of the compressed Thompson sampling and the number of partitions can be bounded.",
        "We suspect that for every link function \u03c6, there exists an upper bound for the information ratio that depends only on d and \u03c6 and is independent of the cardinality of the parameter space.",
        "Under the logistic bandit setting where A, \u0398 \u2286 Bd(0, 1), for all \u03b2 > 0, if the link function is given by \u03c6L(x) = e\u03b2x/(1 + e\u03b2x), Assumption 3 holds with inf\u03b8\u2208\u0398 \u03b1(\u03b8) \u03b8 = \u03b4 > 0, and Conjecture 1 holds, for all sufficiently large T ,",
        "Through an analysis based on rate-distortion, we established a new information-theoretic regret boun\u221ad for Thompson sampling that scales gracefully to large action spaces.",
        "Our analysis yields an O(d T log T ) regret bound for the linear bandit problem, which strengthens state-of-the-art bounds.",
        "The same regret bound applies to the logistic bandit problem if a conjecture about the information ratio that agrees with computational results holds.",
        "We expect that our new line of analysis applies to a wide range of online decision algorithms"
    ],
    "headline": "We develop a sharper bound for Thompson sampling",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Shipra Agrawal and Navin Goyal. Near-optimal regret bounds for Thompson sampling. Journal of the ACM (JACM), 64(5):30, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agrawal%2C%20Shipra%20Goyal%2C%20Navin%20Near-optimal%20regret%20bounds%20for%20Thompson%20sampling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agrawal%2C%20Shipra%20Goyal%2C%20Navin%20Near-optimal%20regret%20bounds%20for%20Thompson%20sampling%202017"
        },
        {
            "id": "2",
            "entry": "[2] Olivier Chapelle and Lihong Li. An empirical evaluation of Thompson sampling. In Advances in neural information processing systems, pages 2249\u20132257, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chapelle%2C%20Olivier%20Li%2C%20Lihong%20An%20empirical%20evaluation%20of%20Thompson%20sampling%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chapelle%2C%20Olivier%20Li%2C%20Lihong%20An%20empirical%20evaluation%20of%20Thompson%20sampling%202011"
        },
        {
            "id": "3",
            "entry": "[3] Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20Thomas%20M.%20Thomas%2C%20Joy%20A.%20Elements%20of%20information%20theory%202012"
        },
        {
            "id": "4",
            "entry": "[4] Varsha Dani, Thomas P Hayes, and Sham M Kakade. Stochastic linear optimization under bandit feedback. In 21st Annual Conference on Learning Theory, pages 355\u2013366, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dani%2C%20Varsha%20Hayes%2C%20Thomas%20P.%20Kakade%2C%20Sham%20M.%20Stochastic%20linear%20optimization%20under%20bandit%20feedback%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dani%2C%20Varsha%20Hayes%2C%20Thomas%20P.%20Kakade%2C%20Sham%20M.%20Stochastic%20linear%20optimization%20under%20bandit%20feedback%202008"
        },
        {
            "id": "5",
            "entry": "[5] Lihong Li, Yu Lu, and Dengyong Zhou. Provably optimal algorithms for generalized linear contextual bandits. In International Conference on Machine Learning, pages 2071\u20132080, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Lihong%20Lu%2C%20Yu%20Zhou%2C%20Dengyong%20Provably%20optimal%20algorithms%20for%20generalized%20linear%20contextual%20bandits%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Lihong%20Lu%2C%20Yu%20Zhou%2C%20Dengyong%20Provably%20optimal%20algorithms%20for%20generalized%20linear%20contextual%20bandits%202017"
        },
        {
            "id": "6",
            "entry": "[6] Daniel Russo and Benjamin Van Roy. Learning to optimize via information-directed sampling. In Advances in Neural Information Processing Systems, pages 1583\u20131591, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20Learning%20to%20optimize%20via%20information-directed%20sampling%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20Learning%20to%20optimize%20via%20information-directed%20sampling%202014"
        },
        {
            "id": "7",
            "entry": "[7] Daniel Russo and Benjamin Van Roy. Learning to optimize via posterior sampling. Mathematics of Operations Research, 39(4):1221\u20131243, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20Learning%20to%20optimize%20via%20posterior%20sampling%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20Learning%20to%20optimize%20via%20posterior%20sampling%202014"
        },
        {
            "id": "8",
            "entry": "[8] Daniel Russo and Benjamin Van Roy. An information-theoretic analysis of Thompson sampling. The Journal of Machine Learning Research, 17(1):2442\u20132471, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20An%20information-theoretic%20analysis%20of%20Thompson%20sampling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20Daniel%20Roy%2C%20Benjamin%20Van%20An%20information-theoretic%20analysis%20of%20Thompson%20sampling%202016"
        },
        {
            "id": "9",
            "entry": "[9] Daniel Russo and Benjamin Van Roy. Satisficing in time-sensitive bandit learning. arXiv preprint arXiv:1803.02855, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.02855"
        },
        {
            "id": "10",
            "entry": "[10] Daniel J Russo, Benjamin Van Roy, Abbas Kazerouni, Ian Osband, and Zheng Wen. A tutorial on Thompson sampling. Foundations and Trends R in Machine Learning, 11(1):1\u201396, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20Daniel%20J.%20Roy%2C%20Benjamin%20Van%20Kazerouni%2C%20Abbas%20Osband%2C%20Ian%20A%20tutorial%20on%20Thompson%20sampling%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20Daniel%20J.%20Roy%2C%20Benjamin%20Van%20Kazerouni%2C%20Abbas%20Osband%2C%20Ian%20A%20tutorial%20on%20Thompson%20sampling%202018"
        },
        {
            "id": "11",
            "entry": "[11] William R Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3/4):285\u2013294, 1933. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thompson%2C%20William%20R.%20On%20the%20likelihood%20that%20one%20unknown%20probability%20exceeds%20another%20in%20view%20of%20the%20evidence%20of%20two%20samples%201933",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thompson%2C%20William%20R.%20On%20the%20likelihood%20that%20one%20unknown%20probability%20exceeds%20another%20in%20view%20of%20the%20evidence%20of%20two%20samples%201933"
        }
    ]
}
