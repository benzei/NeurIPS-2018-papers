{
    "filename": "8022-submodular-maximization-via-gradient-ascent-the-case-of-deep-submodular-functions.pdf",
    "metadata": {
        "date": 2018,
        "title": "Submodular Maximization via Gradient Ascent: The Case of Deep Submodular Functions",
        "author": "Wenruo Bai\u2021, William S Noble\u2217$, Jeff A. Bilmes\u2021$ Depts. of Electrical & Computer Engineering\u2021, Computer Science and Engineering$, and Genome Sciences\u2217",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8022-submodular-maximization-via-gradient-ascent-the-case-of-deep-submodular-functions.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We study the problem of maximizing deep submodular functions (DSFs) [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] subject to a matroid constraint. DSFs are an expressive class of submodular functions that include, as strict subfamilies, the facility location, weighted coverage, and sums of concave composed with modular functions. We use a strategy similar to the continuous greedy approach [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], but we show that the multilinear extension of any DSF has a natural and computationally attainable concave relaxation that we can optimize using gradient ascent. Our results show a guarantee of max0<\u03b4<1(1\u2212"
    },
    "keywords": [
        {
            "term": "Semiconductor Research Corporation",
            "url": "https://en.wikipedia.org/wiki/Semiconductor_Research_Corporation"
        },
        {
            "term": "gradient ascent",
            "url": "https://en.wikipedia.org/wiki/gradient_ascent"
        },
        {
            "term": "submodular maximization",
            "url": "https://en.wikipedia.org/wiki/submodular_maximization"
        },
        {
            "term": "matroid polytope",
            "url": "https://en.wikipedia.org/wiki/matroid_polytope"
        },
        {
            "term": "submodular set function",
            "url": "https://en.wikipedia.org/wiki/submodular_set_function"
        },
        {
            "term": "Facility location",
            "url": "https://en.wikipedia.org/wiki/Facility_location"
        },
        {
            "term": "greedy algorithm",
            "url": "https://en.wikipedia.org/wiki/greedy_algorithm"
        }
    ],
    "highlights": [
        "Related work [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] introduced deep submodular functions where [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] discussed their theoretical properties and [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>] their training in a fashion similar to how deep neural networks may be trained",
        "\u2212 \u03b4 \u2212 e\u2212\u03b42\u03a9(k)) with a running time of O(n2/ 2) plus time for pipage rounding [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] to recover a discrete solution, where k is the rank of the matroid constraint",
        "We focus on deep submodular functions maximization under a matroid constraint",
        "Sums of concave composed with non-negative modular functions plus an arbitrary modular function (SCMM), called feature-based functions [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], or \u201cdecomposable\u201d submodular functions [<a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>]",
        "We address any function that can be represented as a deep submodular functions",
        "Our framework in the present paper is a strict generalization of this previous method in the following ways: (1) The weighted coverage function class is a subclass of deep submodular functions, and Karimi et al.\u2019s proposed concave extension is a special case of a more general deep submodular functions concave extension; (2) We use a similar algorithmic approach which has the advantage of better running time over the continuous greedy algorithm; and (3) We offer a still better bound for large k where k is the rank of the matroid"
    ],
    "key_statements": [
        "Related work [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] introduced deep submodular functions where [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] discussed their theoretical properties and [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>] their training in a fashion similar to how deep neural networks may be trained",
        "\u2212 \u03b4 \u2212 e\u2212\u03b42\u03a9(k)) with a running time of O(n2/ 2) plus time for pipage rounding [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] to recover a discrete solution, where k is the rank of the matroid constraint",
        "We focus on deep submodular functions maximization under a matroid constraint",
        "Better guarantee for large k: Our method has a guarantee of max0<\u03b4<1(1 \u2212 \u2212 \u03b4 \u2212 e\u2212\u03b42\u03a9(k))), where k is the rank of the matroid constraint (Corollary 2)",
        "The following classes of functions are all strict subclasses of deep submodular functions [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>].\n1",
        "Sums of concave composed with non-negative modular functions plus an arbitrary modular function (SCMM), called feature-based functions [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], or \u201cdecomposable\u201d submodular functions [<a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>]",
        "We address any function that can be represented as a deep submodular functions",
        "Our framework in the present paper is a strict generalization of this previous method in the following ways: (1) The weighted coverage function class is a subclass of deep submodular functions, and Karimi et al.\u2019s proposed concave extension is a special case of a more general deep submodular functions concave extension; (2) We use a similar algorithmic approach which has the advantage of better running time over the continuous greedy algorithm; and (3) We offer a still better bound for large k where k is the rank of the matroid",
        "deep submodular functions functions have the form of nested sum of concave of modular (Equation (2)). [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] shows that there exists a natural concave extension of f by replacing the discrete variables with real values in the nested form F (x) = F(x) + m\u00b1 \u00b7 x where",
        "We show that given any deep submodular functions, it is not necessary to compute the multilinear extension at all"
    ],
    "summary": [
        "Related work [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] introduced deep submodular functions where [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] discussed their theoretical properties and [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>] their training in a fashion similar to how deep neural networks may be trained.",
        "[<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] offers a randomized continuous greedy algorithm that offers the same 1 \u2212 1/e bound for monotone non-decreasing submodular maximization subject to a more general matroid",
        "Recent studies showed stochastic projected gradient methods [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>, <a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>] can be useful on maximizing continuous DR-submodular function [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] 2.",
        "In the simplest case, maximizing a modular function (i.e., a function f for which both f and \u2212f are submodular) under a matroid constraint can be exactly solved by a greedy algorithm.",
        "Our approach has the following advantages over the continuous greedy algorithm with only oracle access to the submodular function: 1.",
        "3. Improved running time: Other than the fact that a natural concave extension of a DSF is readily available, the running time of our method is O(n2 \u22122) and is better than the O(n7) cost for the continuous greedy algorithm.",
        "Most of the continuous greedy algorithm\u2019s running time is for estimating the multilinear extension (O(n5) [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>]), while in our method, calculating the DSF",
        "In [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], submodular maximization of the special case of weighted coverage (WC) functions was studied, using an approach that took a concave relaxation of the multilinear extension of such functions.",
        "Our framework in the present paper is a strict generalization of this previous method in the following ways: (1) The weighted coverage function class is a subclass of DSFs, and Karimi et al.\u2019s proposed concave extension is a special case of a more general DSF concave extension; (2) We use a similar algorithmic approach which has the advantage of better running time over the continuous greedy algorithm; and (3) We offer a still better bound for large k where k is the rank of the matroid.",
        "In a DSF, \u03c6vi is a normalized = 0) monotone non-decreasing concave function defined on [0, +\u221e).",
        "DSF functions have the form of nested sum of concave of modular (Equation (2)).",
        "Following the general framework of [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], we first find a fractional solution of the concave extension and employ pipage rounding to obtain a feasible set.",
        "Algorithm 1: Projected Gradient Ascent [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>] input :DSF concave extension F , matroid polytope P, (7)",
        "Applying Theorem 2 to Algorithm 1 and using our propose concave function F (x), we have the following result: Lemma 3.",
        "We have a approximate solution to the concave maximization problem and using this, in concert with Lemma 2, we arrive at the following which offers a guarantee of our proposed method."
    ],
    "headline": "We study the problem of maximizing deep submodular functions   subject to a matroid constraint",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Man\u00e9, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\u00e9gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Largescale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20Mart%C3%ADn%20Agarwal%2C%20Ashish%20Barham%2C%20Paul%20Brevdo%2C%20Eugene%20TensorFlow%3A%20Largescale%20machine%20learning%20on%20heterogeneous%20systems%202015"
        },
        {
            "id": "2",
            "entry": "[2] Alexander A Ageev and Maxim I Sviridenko. Pipage rounding: A new method of constructing algorithms with proven performance guarantee. Journal of Combinatorial Optimization, 8(3):307\u2013328, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Alexander%20A%20Ageev%20and%20Maxim%20I%20Sviridenko.%20Pipage%20rounding%3A%20A%20new%20method%20of%20constructing%20algorithms%20with%20proven%20performance%20guarantee%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Alexander%20A%20Ageev%20and%20Maxim%20I%20Sviridenko.%20Pipage%20rounding%3A%20A%20new%20method%20of%20constructing%20algorithms%20with%20proven%20performance%20guarantee%202004"
        },
        {
            "id": "3",
            "entry": "[3] Jeffrey Bilmes and Wenruo Bai. Deep Submodular Functions. Arxiv, abs/1701.08939, Jan 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.08939"
        },
        {
            "id": "4",
            "entry": "[4] S\u00e9bastien Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends R in Machine Learning, 8(3-4):231\u2013357, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bubeck%2C%20S%C3%A9bastien%20Convex%20optimization%3A%20Algorithms%20and%20complexity%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bubeck%2C%20S%C3%A9bastien%20Convex%20optimization%3A%20Algorithms%20and%20complexity%202015"
        },
        {
            "id": "5",
            "entry": "[5] G. Calinescu, C. Chekuri, M. P\u00e1l, and J. Vondr\u00e1k. Maximizing a monotone submodular function subject to a matroid constraint. SIAM Journal on Computing, 40(6):1740\u20131766, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Calinescu%2C%20G.%20Chekuri%2C%20C.%20P%C3%A1l%2C%20M.%20Vondr%C3%A1k%2C%20J.%20Maximizing%20a%20monotone%20submodular%20function%20subject%20to%20a%20matroid%20constraint%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Calinescu%2C%20G.%20Chekuri%2C%20C.%20P%C3%A1l%2C%20M.%20Vondr%C3%A1k%2C%20J.%20Maximizing%20a%20monotone%20submodular%20function%20subject%20to%20a%20matroid%20constraint%202011"
        },
        {
            "id": "6",
            "entry": "[6] Gruia Calinescu, Chandra Chekuri, Martin P\u00e1l, and Jan Vondr\u00e1k. Maximizing a submodular set function subject to a matroid constraint. In International Conference on Integer Programming and Combinatorial Optimization, pages 182\u2013196.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Calinescu%2C%20Gruia%20Chekuri%2C%20Chandra%20P%C3%A1l%2C%20Martin%20Vondr%C3%A1k%2C%20Jan%20Maximizing%20a%20submodular%20set%20function%20subject%20to%20a%20matroid%20constraint",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Calinescu%2C%20Gruia%20Chekuri%2C%20Chandra%20P%C3%A1l%2C%20Martin%20Vondr%C3%A1k%2C%20Jan%20Maximizing%20a%20submodular%20set%20function%20subject%20to%20a%20matroid%20constraint"
        },
        {
            "id": "7",
            "entry": "[7] Deeparnab Chakrabarty, Yin Tat Lee, Aaron Sidford, and Sam Chiu-wai Wong. Subquadratic submodular function minimization. arXiv preprint arXiv:1610.09800, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.09800"
        },
        {
            "id": "8",
            "entry": "[8] Chandra Chekuri and Amit Kumar. Maximum coverage problem with group budget constraints and applications. In Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, pages 72\u201383.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chekuri%2C%20Chandra%20Kumar%2C%20Amit%20Maximum%20coverage%20problem%20with%20group%20budget%20constraints%20and%20applications",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chekuri%2C%20Chandra%20Kumar%2C%20Amit%20Maximum%20coverage%20problem%20with%20group%20budget%20constraints%20and%20applications"
        },
        {
            "id": "9",
            "entry": "[9] Chandra Chekuri, Jan Vondr\u00e1k, and Rico Zenklusen. Dependent randomized rounding for matroid polytopes and applications. arXiv preprint arXiv:0909.4348, 2009.",
            "arxiv_url": "https://arxiv.org/pdf/0909.4348"
        },
        {
            "id": "10",
            "entry": "[10] Gerard Cornuejols, Marshall L Fisher, and George L Nemhauser. Exceptional paper location of bank accounts to optimize float: An analytic study of exact and approximate algorithms. Management science, 23(8):789\u2013810, 1977.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cornuejols%2C%20Gerard%20Marshall%20L%20Fisher%2C%20and%20George%20L%20Nemhauser.%20Exceptional%20paper%20location%20of%20bank%20accounts%20to%20optimize%20float%3A%20An%20analytic%20study%20of%20exact%20and%20approximate%20algorithms%201977",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cornuejols%2C%20Gerard%20Marshall%20L%20Fisher%2C%20and%20George%20L%20Nemhauser.%20Exceptional%20paper%20location%20of%20bank%20accounts%20to%20optimize%20float%3A%20An%20analytic%20study%20of%20exact%20and%20approximate%20algorithms%201977"
        },
        {
            "id": "11",
            "entry": "[11] W.H. Cunningham. On submodular function minimization. Combinatorica, 5(3):185\u2013192, 1985.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cunningham%2C%20W.H.%20On%20submodular%20function%20minimization%201985",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cunningham%2C%20W.H.%20On%20submodular%20function%20minimization%201985"
        },
        {
            "id": "12",
            "entry": "[12] J. Djolonga and A. Krause. From MAP to Marginals: Variational Inference in Bayesian Submodular Models. In Neural Information Processing Society (NIPS), Montreal, CA, December 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Djolonga%2C%20J.%20Krause%2C%20A.%20From%20MAP%20to%20Marginals%3A%20Variational%20Inference%20in%20Bayesian%20Submodular%20Models%202014-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Djolonga%2C%20J.%20Krause%2C%20A.%20From%20MAP%20to%20Marginals%3A%20Variational%20Inference%20in%20Bayesian%20Submodular%20Models%202014-12"
        },
        {
            "id": "13",
            "entry": "[13] Brian W Dolhansky and Jeff A Bilmes. Deep submodular functions: Definitions and learning. In Advances in Neural Information Processing Systems, pages 3396\u20133404, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brian%2C%20W.%20Dolhansky%20and%20Jeff%20A%20Bilmes.%20Deep%20submodular%20functions%3A%20Definitions%20and%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brian%2C%20W.%20Dolhansky%20and%20Jeff%20A%20Bilmes.%20Deep%20submodular%20functions%3A%20Definitions%20and%20learning%202016"
        },
        {
            "id": "14",
            "entry": "[14] Shaddin Dughmi. Submodular functions: Extensions, distributions, and algorithms. a survey. arXiv preprint arXiv:0912.0322, 2009.",
            "arxiv_url": "https://arxiv.org/pdf/0912.0322"
        },
        {
            "id": "15",
            "entry": "[15] S. Fujishige. Submodular functions and optimization, volume 58. Elsevier Science, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fujishige%2C%20S.%20Submodular%20functions%20and%20optimization%2C%20volume%2058%202005"
        },
        {
            "id": "16",
            "entry": "[16] Toshihiro Fujito. Approximation algorithms for submodular set cover with applications. IEICE Transactions on Information and Systems, 83(3):480\u2013487, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fujito%2C%20Toshihiro%20Approximation%20algorithms%20for%20submodular%20set%20cover%20with%20applications%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fujito%2C%20Toshihiro%20Approximation%20algorithms%20for%20submodular%20set%20cover%20with%20applications%202000"
        },
        {
            "id": "17",
            "entry": "[17] Michael Gygli, Helmut Grabner, and Luc Van Gool. Video summarization by learning submodular mixtures of objectives. In Proceedings CVPR 2015, pages 3090\u20133098, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gygli%2C%20Michael%20Grabner%2C%20Helmut%20Gool%2C%20Luc%20Van%20Video%20summarization%20by%20learning%20submodular%20mixtures%20of%20objectives%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gygli%2C%20Michael%20Grabner%2C%20Helmut%20Gool%2C%20Luc%20Van%20Video%20summarization%20by%20learning%20submodular%20mixtures%20of%20objectives%202015"
        },
        {
            "id": "18",
            "entry": "[18] Hamed Hassani, Mahdi Soltanolkotabi, and Amin Karbasi. Gradient methods for submodular maximization. In Advances in Neural Information Processing Systems, pages 5841\u20135851, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hassani%2C%20Hamed%20Soltanolkotabi%2C%20Mahdi%20Karbasi%2C%20Amin%20Gradient%20methods%20for%20submodular%20maximization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hassani%2C%20Hamed%20Soltanolkotabi%2C%20Mahdi%20Karbasi%2C%20Amin%20Gradient%20methods%20for%20submodular%20maximization%202017"
        },
        {
            "id": "19",
            "entry": "[19] Stefanie Jegelka and Jeff Bilmes. Submodularity beyond submodular energies: coupling edges in graph cuts. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 1897\u20131904. IEEE, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jegelka%2C%20Stefanie%20Bilmes%2C%20Jeff%20Submodularity%20beyond%20submodular%20energies%3A%20coupling%20edges%20in%20graph%20cuts%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jegelka%2C%20Stefanie%20Bilmes%2C%20Jeff%20Submodularity%20beyond%20submodular%20energies%3A%20coupling%20edges%20in%20graph%20cuts%202011"
        },
        {
            "id": "20",
            "entry": "[20] Mohammad Karimi, Mario Lucic, Hamed Hassani, and Andreas Krause. Stochastic submodular maximization: The case of coverage functions. In Advances in Neural Information Processing Systems, pages 6856\u20136866, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karimi%2C%20Mohammad%20Lucic%2C%20Mario%20Hassani%2C%20Hamed%20Krause%2C%20Andreas%20Stochastic%20submodular%20maximization%3A%20The%20case%20of%20coverage%20functions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karimi%2C%20Mohammad%20Lucic%2C%20Mario%20Hassani%2C%20Hamed%20Krause%2C%20Andreas%20Stochastic%20submodular%20maximization%3A%20The%20case%20of%20coverage%20functions%202017"
        },
        {
            "id": "21",
            "entry": "[21] Katrin Kirchhoff and Jeff Bilmes. Submodularity for data selection in machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 131\u2013141, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kirchhoff%2C%20Katrin%20Bilmes%2C%20Jeff%20Submodularity%20for%20data%20selection%20in%20machine%20translation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kirchhoff%2C%20Katrin%20Bilmes%2C%20Jeff%20Submodularity%20for%20data%20selection%20in%20machine%20translation%202014"
        },
        {
            "id": "22",
            "entry": "[22] Pushmeet Kohli, M Pawan Kumar, and Philip HS Torr. P3 & beyond: Move making algorithms for solving higher order functions. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 31(9):1645\u20131656, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pushmeet%20Kohli%2C%20M.Pawan%20Kumar%20Torr%2C%20Philip%20H.S.%20P3%20%26%20beyond%3A%20Move%20making%20algorithms%20for%20solving%20higher%20order%20functions%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pushmeet%20Kohli%2C%20M.Pawan%20Kumar%20Torr%2C%20Philip%20H.S.%20P3%20%26%20beyond%3A%20Move%20making%20algorithms%20for%20solving%20higher%20order%20functions%202009"
        },
        {
            "id": "23",
            "entry": "[23] Andreas Krause, Carlos Guestrin, Anupam Gupta, and Jon Kleinberg. Near-optimal sensor placements: Maximizing information while minimizing communication cost. In Proceedings of the 5th international conference on Information processing in sensor networks, pages 2\u201310. ACM, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krause%2C%20Andreas%20Guestrin%2C%20Carlos%20Gupta%2C%20Anupam%20Kleinberg%2C%20Jon%20Near-optimal%20sensor%20placements%3A%20Maximizing%20information%20while%20minimizing%20communication%20cost%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krause%2C%20Andreas%20Guestrin%2C%20Carlos%20Gupta%2C%20Anupam%20Kleinberg%2C%20Jon%20Near-optimal%20sensor%20placements%3A%20Maximizing%20information%20while%20minimizing%20communication%20cost%202006"
        },
        {
            "id": "24",
            "entry": "[24] Yin Tat Lee, Aaron Sidford, and Sam Chiu-wai Wong. A faster cutting plane method and its implications for combinatorial and convex optimization. In Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on, pages 1049\u20131065. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Yin%20Tat%20Sidford%2C%20Aaron%20Wong%2C%20Sam%20Chiu-wai%20A%20faster%20cutting%20plane%20method%20and%20its%20implications%20for%20combinatorial%20and%20convex%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Yin%20Tat%20Sidford%2C%20Aaron%20Wong%2C%20Sam%20Chiu-wai%20A%20faster%20cutting%20plane%20method%20and%20its%20implications%20for%20combinatorial%20and%20convex%20optimization%202015"
        },
        {
            "id": "25",
            "entry": "[25] Maxwell W. Libbrecht, Jeffrey A. Bilmes, and William Stafford Noble. Choosing non-redundant representative subsets of protein sequence data sets using submodular optimization. Proteins: Structure, Function, and Bioinformatics, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Libbrecht%2C%20Maxwell%20W.%20Bilmes%2C%20Jeffrey%20A.%20Noble%2C%20William%20Stafford%20Choosing%20non-redundant%20representative%20subsets%20of%20protein%20sequence%20data%20sets%20using%20submodular%20optimization%202018"
        },
        {
            "id": "26",
            "entry": "[26] H. Lin, J. Bilmes, and S. Xie. Graph-based submodular selection for extractive summarization. In ASRU, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20H.%20Bilmes%2C%20J.%20Xie%2C%20S.%20Graph-based%20submodular%20selection%20for%20extractive%20summarization%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20H.%20Bilmes%2C%20J.%20Xie%2C%20S.%20Graph-based%20submodular%20selection%20for%20extractive%20summarization%202009"
        },
        {
            "id": "27",
            "entry": "[27] Hui Lin and Jeff Bilmes. A class of submodular functions for document summarization. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 510\u2013520. Association for Computational Linguistics, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Hui%20Bilmes%2C%20Jeff%20A%20class%20of%20submodular%20functions%20for%20document%20summarization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Hui%20Bilmes%2C%20Jeff%20A%20class%20of%20submodular%20functions%20for%20document%20summarization%202011"
        },
        {
            "id": "28",
            "entry": "[28] Hui Lin and Jeff Bilmes. Word alignment via submodular maximization over matroids. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 170\u2013175. Association for Computational Linguistics, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Hui%20Bilmes%2C%20Jeff%20Word%20alignment%20via%20submodular%20maximization%20over%20matroids%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Hui%20Bilmes%2C%20Jeff%20Word%20alignment%20via%20submodular%20maximization%20over%20matroids%202011"
        },
        {
            "id": "29",
            "entry": "[29] L\u00e1szl\u00f3 Lov\u00e1sz. Submodular functions and convexity. In Mathematical Programming The State of the Art, pages 235\u2013257.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lov%C3%A1sz%2C%20L%C3%A1szl%C3%B3%20Submodular%20functions%20and%20convexity",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lov%C3%A1sz%2C%20L%C3%A1szl%C3%B3%20Submodular%20functions%20and%20convexity"
        },
        {
            "id": "30",
            "entry": "[30] M. Minoux. Accelerated greedy algorithms for maximizing submodular set functions. Optimization Techniques, pages 234\u2013243, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minoux%2C%20M.%20Accelerated%20greedy%20algorithms%20for%20maximizing%20submodular%20set%20functions%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Minoux%2C%20M.%20Accelerated%20greedy%20algorithms%20for%20maximizing%20submodular%20set%20functions%201978"
        },
        {
            "id": "31",
            "entry": "[31] Aryan Mokhtari, Hamed Hassani, and Amin Karbasi. Conditional gradient method for stochastic submodular maximization: Closing the gap. In International Conference on Artificial Intelligence and Statistics, pages 1886\u20131895, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mokhtari%2C%20Aryan%20Hassani%2C%20Hamed%20Karbasi%2C%20Amin%20Conditional%20gradient%20method%20for%20stochastic%20submodular%20maximization%3A%20Closing%20the%20gap%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mokhtari%2C%20Aryan%20Hassani%2C%20Hamed%20Karbasi%2C%20Amin%20Conditional%20gradient%20method%20for%20stochastic%20submodular%20maximization%3A%20Closing%20the%20gap%202018"
        },
        {
            "id": "32",
            "entry": "[32] George L Nemhauser, Laurence A Wolsey, and Marshall L Fisher. An analysis of approximations for maximizing submodular set functions\u2014i. Mathematical Programming, 14(1):265\u2013294, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemhauser%2C%20George%20L.%20Wolsey%2C%20Laurence%20A.%20and%20Marshall%20L%20Fisher.%20An%20analysis%20of%20approximations%20for%20maximizing%20submodular%20set%20functions%E2%80%94i%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nemhauser%2C%20George%20L.%20Wolsey%2C%20Laurence%20A.%20and%20Marshall%20L%20Fisher.%20An%20analysis%20of%20approximations%20for%20maximizing%20submodular%20set%20functions%E2%80%94i%201978"
        },
        {
            "id": "33",
            "entry": "[33] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20Adam%20Gross%2C%20Sam%20Chintala%2C%20Soumith%20Chanan%2C%20Gregory%20Automatic%20differentiation%20in%20pytorch%202017"
        },
        {
            "id": "34",
            "entry": "[34] Prabhakar Raghavan. Probabilistic construction of deterministic algorithms: approximating packing integer programs. Journal of Computer and System Sciences, 37(2):130\u2013143, 1988.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raghavan%2C%20Prabhakar%20Probabilistic%20construction%20of%20deterministic%20algorithms%3A%20approximating%20packing%20integer%20programs%201988",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raghavan%2C%20Prabhakar%20Probabilistic%20construction%20of%20deterministic%20algorithms%3A%20approximating%20packing%20integer%20programs%201988"
        },
        {
            "id": "35",
            "entry": "[35] Tasuku Soma and Yuichi Yoshida. A generalization of submodular cover via the diminishing return property on the integer lattice. In Advances in Neural Information Processing Systems, pages 847\u2013855, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Soma%2C%20Tasuku%20Yoshida%2C%20Yuichi%20A%20generalization%20of%20submodular%20cover%20via%20the%20diminishing%20return%20property%20on%20the%20integer%20lattice%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Soma%2C%20Tasuku%20Yoshida%2C%20Yuichi%20A%20generalization%20of%20submodular%20cover%20via%20the%20diminishing%20return%20property%20on%20the%20integer%20lattice%202015"
        },
        {
            "id": "36",
            "entry": "[36] P. Stobbe and A. Krause. Efficient minimization of decomposable submodular functions. In NIPS, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stobbe%2C%20P.%20Krause%2C%20A.%20Efficient%20minimization%20of%20decomposable%20submodular%20functions%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stobbe%2C%20P.%20Krause%2C%20A.%20Efficient%20minimization%20of%20decomposable%20submodular%20functions%202010"
        },
        {
            "id": "37",
            "entry": "[37] Maxim Sviridenko, Jan Vondr\u00e1k, and Justin Ward. Optimal approximation for submodular and supermodular optimization with bounded curvature. In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1134\u20131148. Society for Industrial and Applied Mathematics, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sviridenko%2C%20Maxim%20Vondr%C3%A1k%2C%20Jan%20Ward%2C%20Justin%20Optimal%20approximation%20for%20submodular%20and%20supermodular%20optimization%20with%20bounded%20curvature%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sviridenko%2C%20Maxim%20Vondr%C3%A1k%2C%20Jan%20Ward%2C%20Justin%20Optimal%20approximation%20for%20submodular%20and%20supermodular%20optimization%20with%20bounded%20curvature%202015"
        },
        {
            "id": "38",
            "entry": "[38] Adrian Vetta. Nash equilibria in competitive societies, with applications to facility location, traffic routing and auctions. In Foundations of Computer Science, 2002. Proceedings. The 43rd Annual IEEE Symposium on, pages 416\u2013425. IEEE, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vetta%2C%20Adrian%20Nash%20equilibria%20in%20competitive%20societies%2C%20with%20applications%20to%20facility%20location%2C%20traffic%20routing%20and%20auctions%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vetta%2C%20Adrian%20Nash%20equilibria%20in%20competitive%20societies%2C%20with%20applications%20to%20facility%20location%2C%20traffic%20routing%20and%20auctions%202002"
        },
        {
            "id": "39",
            "entry": "[39] Kai Wei, Rishabh Iyer, and Jeff Bilmes. Submodularity in data subset selection and active learning. In International Conference on Machine Learning (ICML), Lille, France, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wei%2C%20Kai%20Iyer%2C%20Rishabh%20Bilmes%2C%20Jeff%20Submodularity%20in%20data%20subset%20selection%20and%20active%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wei%2C%20Kai%20Iyer%2C%20Rishabh%20Bilmes%2C%20Jeff%20Submodularity%20in%20data%20subset%20selection%20and%20active%20learning%202015"
        },
        {
            "id": "40",
            "entry": "[40] Kai Wei, Maxwell W Libbrecht, Jeffrey A Bilmes, and William Noble. Choosing panels of genomics assays using submodular optimization (tr). bioRxiv, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wei%2C%20Kai%20Libbrecht%2C%20Maxwell%20W.%20Bilmes%2C%20Jeffrey%20A.%20Noble%2C%20William%20Choosing%20panels%20of%20genomics%20assays%20using%20submodular%20optimization%20%28tr%29.%20bioRxiv%202016"
        },
        {
            "id": "41",
            "entry": "[41] Kai Wei, Yuzong Liu, Katrin Kirchhoff, Chris Bartels, and Jeff Bilmes. Submodular subset selection for large-scale speech training data. Proceedings of ICASSP, Florence, Italy, 2014. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wei%2C%20Kai%20Liu%2C%20Yuzong%20Kirchhoff%2C%20Katrin%20Bartels%2C%20Chris%20Submodular%20subset%20selection%20for%20large-scale%20speech%20training%20data%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wei%2C%20Kai%20Liu%2C%20Yuzong%20Kirchhoff%2C%20Katrin%20Bartels%2C%20Chris%20Submodular%20subset%20selection%20for%20large-scale%20speech%20training%20data%202014"
        }
    ]
}
