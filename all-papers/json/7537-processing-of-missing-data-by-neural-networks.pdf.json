{
    "filename": "7537-processing-of-missing-data-by-neural-networks.pdf",
    "metadata": {
        "title": "Processing of missing data by neural networks",
        "author": "Marek \u015amieja, \u0141ukasz Struski, Jacek Tabor, Bartosz Zieli\u0144ski, Przemys\u0142aw Spurek",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7537-processing-of-missing-data-by-neural-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We propose a general, theoretically justified mechanism for processing missing data by neural networks. Our idea is to replace typical neuron\u2019s response in the first hidden layer by its expected value. This approach can be applied for various types of networks at minimal cost in their modification. Moreover, in contrast to recent approaches, it does not require complete data for training. Experimental results performed on different types of architectures show that our method gives better results than typical imputation strategies and other methods dedicated for incomplete data."
    },
    "keywords": [
        {
            "term": "probability density function",
            "url": "https://en.wikipedia.org/wiki/probability_density_function"
        },
        {
            "term": "multilayer perceptron",
            "url": "https://en.wikipedia.org/wiki/multilayer_perceptron"
        },
        {
            "term": "radial basis function network",
            "url": "https://en.wikipedia.org/wiki/radial_basis_function_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "multiple imputation",
            "url": "https://en.wikipedia.org/wiki/multiple_imputation"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "extreme learning machines",
            "url": "https://en.wikipedia.org/wiki/Extreme_Learning_Machines"
        }
    ],
    "highlights": [
        "Learning from incomplete data has been recognized as one of the fundamental challenges in machine learning [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>]",
        "The proof is a natural modification of the respective standard proofs of Universal Approximation Property (UAP), and we present only its sketch",
        "We used a type of context encoder (CE), where missing features were replaced with mean values, in contrast to mean imputation, the complete data were used as an output of the network in training phase",
        "Since the classification is binary, we extended baseline with two additional SVM kernel models which work directly with incomplete data without performing any imputations: geom: Its objective function is based on the geometric interpretation of the margin and aims to maximize the margin of each sample in its own relevant subspace [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>]",
        "We proposed a general approach for adapting neural networks to process incomplete data, which is able to train on data set containing only incomplete samples",
        "Our strategy introduces input layer for processing missing data, which can be used for a wide range of networks and does not require their extensive modifications"
    ],
    "key_statements": [
        "Learning from incomplete data has been recognized as one of the fundamental challenges in machine learning [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>]",
        "We introduce a general, theoretically justified methodology for feeding neural networks with missing data",
        "Our idea is to model the uncertainty on missing attributes by probability density functions, which eliminates the need of direct completion by single values",
        "We show how to represent incomplete data by probability density functions and how to generalize neuron\u2019s activation function to process them",
        "The proof is a natural modification of the respective standard proofs of Universal Approximation Property (UAP), and we present only its sketch",
        "We considered combination of analogical architecture with popular imputation techniques: k-nn: Missing features were replaced with mean values of those features computed from the K nearest training samples",
        "We used a type of context encoder (CE), where missing features were replaced with mean values, in contrast to mean imputation, the complete data were used as an output of the network in training phase",
        "We considered a typical multilayer perceptron architecture with 3 ReLU hidden layers",
        "Since the classification is binary, we extended baseline with two additional SVM kernel models which work directly with incomplete data without performing any imputations: geom: Its objective function is based on the geometric interpretation of the margin and aims to maximize the margin of each sample in its own relevant subspace [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>]",
        "We proposed a general approach for adapting neural networks to process incomplete data, which is able to train on data set containing only incomplete samples",
        "Our strategy introduces input layer for processing missing data, which can be used for a wide range of networks and does not require their extensive modifications"
    ],
    "summary": [
        "Learning from incomplete data has been recognized as one of the fundamental challenges in machine learning [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>].",
        "Every missing data point is identified with parametric density, e.g. GMM, which is trained together with remaining network parameters.",
        "Possible values of incomplete data point (x, J) are described by a conditional density1 FS : S \u2192 R given by: FS(x) =",
        "We use the mixture of Gaussians (GMM) with diagonal covariance matrices as a missing data density F .",
        "For a probability density function FS, we define the generalized response of a neuron n : RD \u2192 R on FS as the mean output: n(FS) = E[n(x)|x \u223c FS] = n(x)FS(x)dx.",
        "We need to generalize the activation functions of all neurons in the first hidden layer of the network to process probability measures.",
        "Observe that our generalized network can process classical points, which do not contain any missing values.",
        "Generalized neurons reduce to classical ones, because missing data density F is only used to estimate possible values at absent attributes.",
        "If we want to use missing data in testing stage, we need to feed the network with incomplete data in training to fit accurate density model.",
        "The following theorem shows that a neural network with generalized ReLU units is able to identify any two probability measures.",
        "We used a type of context encoder (CE), where missing features were replaced with mean values, in contrast to mean imputation, the complete data were used as an output of the network in training phase.",
        "Since the classification is binary, we extended baseline with two additional SVM kernel models which work directly with incomplete data without performing any imputations: geom: Its objective function is based on the geometric interpretation of the margin and aims to maximize the margin of each sample in its own relevant subspace [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>].",
        "It partially confirms that the use of raw incomplete data in neural networks is usually better approach than filling missing attributes before learning process.",
        "We proposed a general approach for adapting neural networks to process incomplete data, which is able to train on data set containing only incomplete samples.",
        "Our strategy introduces input layer for processing missing data, which can be used for a wide range of networks and does not require their extensive modifications.",
        "Thanks to representing incomplete data with probability density function, it is possible to determine more generalized and accurate response of the neuron.",
        "It gives comparable results to the methods, which require complete data in training"
    ],
    "headline": "Theoretically justified mechanism for processing missing data by neural networks",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Deep%20learning%202016"
        },
        {
            "id": "2",
            "entry": "[2] Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Context encoders: Feature learning by inpainting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2536\u20132544, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016"
        },
        {
            "id": "3",
            "entry": "[3] Chao Yang, Xin Lu, Zhe Lin, Eli Shechtman, Oliver Wang, and Hao Li. High-resolution image inpainting using multi-scale neural patch synthesis. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 1, page 3, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Chao%20Lu%2C%20Xin%20Lin%2C%20Zhe%20Shechtman%2C%20Eli%20High-resolution%20image%20inpainting%20using%20multi-scale%20neural%20patch%20synthesis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Chao%20Lu%2C%20Xin%20Lin%2C%20Zhe%20Shechtman%2C%20Eli%20High-resolution%20image%20inpainting%20using%20multi-scale%20neural%20patch%20synthesis%202017"
        },
        {
            "id": "4",
            "entry": "[4] Junyuan Xie, Linli Xu, and Enhong Chen. Image denoising and inpainting with deep neural networks. In Advances in neural information processing systems, pages 341\u2013349, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20Junyuan%20Xu%2C%20Linli%20Chen%2C%20Enhong%20Image%20denoising%20and%20inpainting%20with%20deep%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20Junyuan%20Xu%2C%20Linli%20Chen%2C%20Enhong%20Image%20denoising%20and%20inpainting%20with%20deep%20neural%20networks%202012"
        },
        {
            "id": "5",
            "entry": "[5] Raymond A Yeh, Chen Chen, Teck Yian Lim, Alexander G Schwing, Mark Hasegawa-Johnson, and Minh N Do. Semantic image inpainting with deep generative models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5485\u20135493, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yeh%2C%20Raymond%20A.%20Chen%2C%20Chen%20Lim%2C%20Teck%20Yian%20Schwing%2C%20Alexander%20G.%20Semantic%20image%20inpainting%20with%20deep%20generative%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yeh%2C%20Raymond%20A.%20Chen%2C%20Chen%20Lim%2C%20Teck%20Yian%20Schwing%2C%20Alexander%20G.%20Semantic%20image%20inpainting%20with%20deep%20generative%20models%202017"
        },
        {
            "id": "6",
            "entry": "[6] Patrick E McKnight, Katherine M McKnight, Souraya Sidani, and Aurelio Jose Figueredo. Missing data: A gentle introduction. Guilford Press, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McKnight%2C%20Patrick%20E.%20McKnight%2C%20Katherine%20M.%20Sidani%2C%20Souraya%20Figueredo%2C%20Aurelio%20Jose%20Missing%20data%3A%20A%20gentle%20introduction%202007"
        },
        {
            "id": "7",
            "entry": "[7] Peter K Sharpe and RJ Solly. Dealing with missing values in neural network-based diagnostic systems. Neural Computing & Applications, 3(2):73\u201377, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sharpe%2C%20Peter%20K.%20Solly%2C%20R.J.%20Dealing%20with%20missing%20values%20in%20neural%20network-based%20diagnostic%20systems%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sharpe%2C%20Peter%20K.%20Solly%2C%20R.J.%20Dealing%20with%20missing%20values%20in%20neural%20network-based%20diagnostic%20systems%201995"
        },
        {
            "id": "8",
            "entry": "[8] Du\u0161an Sovilj, Emil Eirola, Yoan Miche, Kaj-Mikael Bj\u00f6rk, Rui Nian, Anton Akusok, and Amaury Lendasse. Extreme learning machine for missing data using multiple imputations. Neurocomputing, 174:220\u2013231, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sovilj%2C%20Du%C5%A1an%20Eirola%2C%20Emil%20Miche%2C%20Yoan%20Bj%C3%B6rk%2C%20Kaj-Mikael%20Extreme%20learning%20machine%20for%20missing%20data%20using%20multiple%20imputations%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sovilj%2C%20Du%C5%A1an%20Eirola%2C%20Emil%20Miche%2C%20Yoan%20Bj%C3%B6rk%2C%20Kaj-Mikael%20Extreme%20learning%20machine%20for%20missing%20data%20using%20multiple%20imputations%202016"
        },
        {
            "id": "9",
            "entry": "[9] Gustavo EAPA Batista, Maria Carolina Monard, et al. A study of k-nearest neighbour as an imputation method. HIS, 87(251-260):48, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Batista%2C%20Gustavo%20E.A.P.A.%20Monard%2C%20Maria%20Carolina%20A%20study%20of%20k-nearest%20neighbour%20as%20an%20imputation%20method%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Batista%2C%20Gustavo%20E.A.P.A.%20Monard%2C%20Maria%20Carolina%20A%20study%20of%20k-nearest%20neighbour%20as%20an%20imputation%20method%202002"
        },
        {
            "id": "10",
            "entry": "[10] Stef Buuren and Karin Groothuis-Oudshoorn. mice: Multivariate imputation by chained equations in r. Journal of statistical software, 45(3), 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Buuren%2C%20Stef%20Groothuis-Oudshoorn%2C%20Karin%20mice%3A%20Multivariate%20imputation%20by%20chained%20equations%20in%20r%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Buuren%2C%20Stef%20Groothuis-Oudshoorn%2C%20Karin%20mice%3A%20Multivariate%20imputation%20by%20chained%20equations%20in%20r%202011"
        },
        {
            "id": "11",
            "entry": "[11] Melissa J Azur, Elizabeth A Stuart, Constantine Frangakis, and Philip J Leaf. Multiple imputation by chained equations: what is it and how does it work? International journal of methods in psychiatric research, 20(1):40\u201349, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Azur%2C%20Melissa%20J.%20Stuart%2C%20Elizabeth%20A.%20Frangakis%2C%20Constantine%20Leaf%2C%20Philip%20J.%20Multiple%20imputation%20by%20chained%20equations%3A%20what%20is%20it%20and%20how%20does%20it%20work%3F%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Azur%2C%20Melissa%20J.%20Stuart%2C%20Elizabeth%20A.%20Frangakis%2C%20Constantine%20Leaf%2C%20Philip%20J.%20Multiple%20imputation%20by%20chained%20equations%3A%20what%20is%20it%20and%20how%20does%20it%20work%3F%202011"
        },
        {
            "id": "12",
            "entry": "[12] Jinsung Yoon, James Jordon, and Mihaela van der Schaar. Gain: Missing data imputation using generative adversarial nets. pages 5689\u20135698, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yoon%2C%20Jinsung%20Jordon%2C%20James%20van%20der%20Schaar%2C%20Mihaela%20Gain%3A%20Missing%20data%20imputation%20using%20generative%20adversarial%20nets%202018"
        },
        {
            "id": "13",
            "entry": "[13] Zoubin Ghahramani and Michael I Jordan. Supervised learning from incomplete data via an EM approach. In Advances in Neural Information Processing Systems, pages 120\u2013127.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghahramani%2C%20Zoubin%20Jordan%2C%20Michael%20I.%20Supervised%20learning%20from%20incomplete%20data%20via%20an%20EM%20approach",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghahramani%2C%20Zoubin%20Jordan%2C%20Michael%20I.%20Supervised%20learning%20from%20incomplete%20data%20via%20an%20EM%20approach"
        },
        {
            "id": "14",
            "entry": "[14] Volker Tresp, Subutai Ahmad, and Ralph Neuneier. Training neural networks with deficient data. In Advances in neural information processing systems, pages 128\u2013135, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tresp%2C%20Volker%20Ahmad%2C%20Subutai%20Neuneier%2C%20Ralph%20Training%20neural%20networks%20with%20deficient%20data%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tresp%2C%20Volker%20Ahmad%2C%20Subutai%20Neuneier%2C%20Ralph%20Training%20neural%20networks%20with%20deficient%20data%201994"
        },
        {
            "id": "15",
            "entry": "[15] David Williams, Xuejun Liao, Ya Xue, and Lawrence Carin. Incomplete-data classification using logistic regression. In Proceedings of the International Conference on Machine Learning, pages 972\u2013979. ACM, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20David%20Liao%2C%20Xuejun%20Xue%2C%20Ya%20Carin%2C%20Lawrence%20Incomplete-data%20classification%20using%20logistic%20regression%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20David%20Liao%2C%20Xuejun%20Xue%2C%20Ya%20Carin%2C%20Lawrence%20Incomplete-data%20classification%20using%20logistic%20regression%202005"
        },
        {
            "id": "16",
            "entry": "[16] Alexander J Smola, SVN Vishwanathan, and Thomas Hofmann. Kernel methods for missing variables. In Proceedings of the International Conference on Artificial Intelligence and Statistics. Citeseer, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smola%2C%20Alexander%20J.%20Vishwanathan%2C%20S.V.N.%20Hofmann%2C%20Thomas%20Kernel%20methods%20for%20missing%20variables%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smola%2C%20Alexander%20J.%20Vishwanathan%2C%20S.V.N.%20Hofmann%2C%20Thomas%20Kernel%20methods%20for%20missing%20variables%202005"
        },
        {
            "id": "17",
            "entry": "[17] David Williams and Lawrence Carin. Analytical kernel matrix completion with incomplete multi-view data. In Proceedings of the ICML Workshop on Learning With Multiple Views, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20David%20Carin%2C%20Lawrence%20Analytical%20kernel%20matrix%20completion%20with%20incomplete%20multi-view%20data%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20David%20Carin%2C%20Lawrence%20Analytical%20kernel%20matrix%20completion%20with%20incomplete%20multi-view%20data%202005"
        },
        {
            "id": "18",
            "entry": "[18] Pannagadatta K Shivaswamy, Chiranjib Bhattacharyya, and Alexander J Smola. Second order cone programming approaches for handling missing and uncertain data. Journal of Machine Learning Research, 7:1283\u20131314, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shivaswamy%2C%20Pannagadatta%20K.%20Bhattacharyya%2C%20Chiranjib%20Smola%2C%20Alexander%20J.%20Second%20order%20cone%20programming%20approaches%20for%20handling%20missing%20and%20uncertain%20data%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shivaswamy%2C%20Pannagadatta%20K.%20Bhattacharyya%2C%20Chiranjib%20Smola%2C%20Alexander%20J.%20Second%20order%20cone%20programming%20approaches%20for%20handling%20missing%20and%20uncertain%20data%202006"
        },
        {
            "id": "19",
            "entry": "[19] Diego PP Mesquita, Jo\u00e3o PP Gomes, and Leonardo R Rodrigues. Extreme learning machines for datasets with missing values using the unscented transform. In Intelligent Systems (BRACIS), 2016 5th Brazilian Conference on, pages 85\u201390. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mesquita%2C%20Diego%20P.P.%20Gomes%2C%20Jo%C3%A3o%20P.P.%20Rodrigues%2C%20Leonardo%20R.%20Extreme%20learning%20machines%20for%20datasets%20with%20missing%20values%20using%20the%20unscented%20transform%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mesquita%2C%20Diego%20P.P.%20Gomes%2C%20Jo%C3%A3o%20P.P.%20Rodrigues%2C%20Leonardo%20R.%20Extreme%20learning%20machines%20for%20datasets%20with%20missing%20values%20using%20the%20unscented%20transform%202016"
        },
        {
            "id": "20",
            "entry": "[20] Xuejun Liao, Hui Li, and Lawrence Carin. Quadratically gated mixture of experts for incomplete data classification. In Proceedings of the International Conference on Machine Learning, pages 553\u2013560. ACM, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liao%2C%20Xuejun%20Li%2C%20Hui%20Carin%2C%20Lawrence%20Quadratically%20gated%20mixture%20of%20experts%20for%20incomplete%20data%20classification%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liao%2C%20Xuejun%20Li%2C%20Hui%20Carin%2C%20Lawrence%20Quadratically%20gated%20mixture%20of%20experts%20for%20incomplete%20data%20classification%202007"
        },
        {
            "id": "21",
            "entry": "[21] Uwe Dick, Peter Haider, and Tobias Scheffer. Learning from incomplete data with infinite imputations. In Proceedings of the International Conference on Machine Learning, pages 232\u2013239. ACM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dick%2C%20Uwe%20Haider%2C%20Peter%20Scheffer%2C%20Tobias%20Learning%20from%20incomplete%20data%20with%20infinite%20imputations%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dick%2C%20Uwe%20Haider%2C%20Peter%20Scheffer%2C%20Tobias%20Learning%20from%20incomplete%20data%20with%20infinite%20imputations%202008"
        },
        {
            "id": "22",
            "entry": "[22] Ofer Dekel, Ohad Shamir, and Lin Xiao. Learning to classify with missing and corrupted features. Machine Learning, 81(2):149\u2013178, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dekel%2C%20Ofer%20Shamir%2C%20Ohad%20Xiao%2C%20Lin%20Learning%20to%20classify%20with%20missing%20and%20corrupted%20features%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dekel%2C%20Ofer%20Shamir%2C%20Ohad%20Xiao%2C%20Lin%20Learning%20to%20classify%20with%20missing%20and%20corrupted%20features%202010"
        },
        {
            "id": "23",
            "entry": "[23] Amir Globerson and Sam Roweis. Nightmare at test time: robust learning by feature deletion. In Proceedings of the International Conference on Machine Learning, pages 353\u2013360. ACM, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Globerson%2C%20Amir%20Roweis%2C%20Sam%20Nightmare%20at%20test%20time%3A%20robust%20learning%20by%20feature%20deletion%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Globerson%2C%20Amir%20Roweis%2C%20Sam%20Nightmare%20at%20test%20time%3A%20robust%20learning%20by%20feature%20deletion%202006"
        },
        {
            "id": "24",
            "entry": "[24] Gal Chechik, Geremy Heitz, Gal Elidan, Pieter Abbeel, and Daphne Koller. Max-margin classification of data with absent features. Journal of Machine Learning Research, 9:1\u201321, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chechik%2C%20Gal%20Heitz%2C%20Geremy%20Elidan%2C%20Gal%20Abbeel%2C%20Pieter%20Max-margin%20classification%20of%20data%20with%20absent%20features%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chechik%2C%20Gal%20Heitz%2C%20Geremy%20Elidan%2C%20Gal%20Abbeel%2C%20Pieter%20Max-margin%20classification%20of%20data%20with%20absent%20features%202008"
        },
        {
            "id": "25",
            "entry": "[25] Jing Xia, Shengyu Zhang, Guolong Cai, Li Li, Qing Pan, Jing Yan, and Gangmin Ning. Adjusted weight voting algorithm for random forests in handling missing values. Pattern Recognition, 69:52\u201360, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xia%2C%20Jing%20Zhang%2C%20Shengyu%20Cai%2C%20Guolong%20Li%2C%20Li%20Adjusted%20weight%20voting%20algorithm%20for%20random%20forests%20in%20handling%20missing%20values%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xia%2C%20Jing%20Zhang%2C%20Shengyu%20Cai%2C%20Guolong%20Li%2C%20Li%20Adjusted%20weight%20voting%20algorithm%20for%20random%20forests%20in%20handling%20missing%20values%202017"
        },
        {
            "id": "26",
            "entry": "[26] Kristiaan Pelckmans, Jos De Brabanter, Johan AK Suykens, and Bart De Moor. Handling missing values in support vector machine classifiers. Neural Networks, 18(5):684\u2013692, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pelckmans%2C%20Kristiaan%20Brabanter%2C%20Jos%20De%20Suykens%2C%20Johan%20A.K.%20Moor%2C%20Bart%20De%20Handling%20missing%20values%20in%20support%20vector%20machine%20classifiers%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pelckmans%2C%20Kristiaan%20Brabanter%2C%20Jos%20De%20Suykens%2C%20Johan%20A.K.%20Moor%2C%20Bart%20De%20Handling%20missing%20values%20in%20support%20vector%20machine%20classifiers%202005"
        },
        {
            "id": "27",
            "entry": "[27] Elad Hazan, Roi Livni, and Yishay Mansour. Classification with low rank and missing data. In Proceedings of The 32nd International Conference on Machine Learning, pages 257\u2013266, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Livni%2C%20Roi%20Mansour%2C%20Yishay%20Classification%20with%20low%20rank%20and%20missing%20data%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Livni%2C%20Roi%20Mansour%2C%20Yishay%20Classification%20with%20low%20rank%20and%20missing%20data%202015"
        },
        {
            "id": "28",
            "entry": "[28] Andrew Goldberg, Ben Recht, Junming Xu, Robert Nowak, and Xiaojin Zhu. Transduction with matrix completion: Three birds with one stone. In Advances in neural information processing systems, pages 757\u2013765, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goldberg%2C%20Andrew%20Recht%2C%20Ben%20Xu%2C%20Junming%20Nowak%2C%20Robert%20Transduction%20with%20matrix%20completion%3A%20Three%20birds%20with%20one%20stone%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goldberg%2C%20Andrew%20Recht%2C%20Ben%20Xu%2C%20Junming%20Nowak%2C%20Robert%20Transduction%20with%20matrix%20completion%3A%20Three%20birds%20with%20one%20stone%202010"
        },
        {
            "id": "29",
            "entry": "[29] Yoshua Bengio and Francois Gingras. Recurrent neural networks for missing or asynchronous data. In Advances in neural information processing systems, pages 395\u2013401, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Yoshua%20Gingras%2C%20Francois%20Recurrent%20neural%20networks%20for%20missing%20or%20asynchronous%20data%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Yoshua%20Gingras%2C%20Francois%20Recurrent%20neural%20networks%20for%20missing%20or%20asynchronous%20data%201996"
        },
        {
            "id": "30",
            "entry": "[30] Robert K Nowicki, Rafal Scherer, and Leszek Rutkowski. Novel rough neural network for classification with missing data. In Methods and Models in Automation and Robotics (MMAR), 2016 21st International Conference on, pages 820\u2013825. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nowicki%2C%20Robert%20K.%20Scherer%2C%20Rafal%20Rutkowski%2C%20Leszek%20Novel%20rough%20neural%20network%20for%20classification%20with%20missing%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nowicki%2C%20Robert%20K.%20Scherer%2C%20Rafal%20Rutkowski%2C%20Leszek%20Novel%20rough%20neural%20network%20for%20classification%20with%20missing%20data%202016"
        },
        {
            "id": "31",
            "entry": "[31] Ian Goodfellow, Mehdi Mirza, Aaron Courville, and Yoshua Bengio. Multi-prediction deep boltzmann machines. In Advances in Neural Information Processing Systems, pages 548\u2013556, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Mirza%2C%20Mehdi%20Courville%2C%20Aaron%20Bengio%2C%20Yoshua%20Multi-prediction%20deep%20boltzmann%20machines%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Mirza%2C%20Mehdi%20Courville%2C%20Aaron%20Bengio%2C%20Yoshua%20Multi-prediction%20deep%20boltzmann%20machines%202013"
        },
        {
            "id": "32",
            "entry": "[32] Calyampudi Radhakrishna Rao, Calyampudi Radhakrishna Rao, Mathematischer Statistiker, Calyampudi Radhakrishna Rao, and Calyampudi Radhakrishna Rao. Linear statistical inference and its applications, volume 2. Wiley New York, 1973.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Calyampudi%20Radhakrishna%20Rao%20Calyampudi%20Radhakrishna%20Rao%20Mathematischer%20Statistiker%20Calyampudi%20Radhakrishna%20Rao%20and%20Calyampudi%20Radhakrishna%20Rao%20Linear%20statistical%20inference%20and%20its%20applications%20volume%202%20Wiley%20New%20York%201973",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Calyampudi%20Radhakrishna%20Rao%20Calyampudi%20Radhakrishna%20Rao%20Mathematischer%20Statistiker%20Calyampudi%20Radhakrishna%20Rao%20and%20Calyampudi%20Radhakrishna%20Rao%20Linear%20statistical%20inference%20and%20its%20applications%20volume%202%20Wiley%20New%20York%201973"
        },
        {
            "id": "33",
            "entry": "[33] Ralph G Andrzejak, Klaus Lehnertz, Florian Mormann, Christoph Rieke, Peter David, and Christian E Elger. Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state. Physical Review E, 64(6):061907, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andrzejak%2C%20Ralph%20G.%20Lehnertz%2C%20Klaus%20Mormann%2C%20Florian%20Rieke%2C%20Christoph%20Indications%20of%20nonlinear%20deterministic%20and%20finite-dimensional%20structures%20in%20time%20series%20of%20brain%20electrical%20activity%3A%20Dependence%20on%20recording%20region%20and%20brain%20state%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andrzejak%2C%20Ralph%20G.%20Lehnertz%2C%20Klaus%20Mormann%2C%20Florian%20Rieke%2C%20Christoph%20Indications%20of%20nonlinear%20deterministic%20and%20finite-dimensional%20structures%20in%20time%20series%20of%20brain%20electrical%20activity%3A%20Dependence%20on%20recording%20region%20and%20brain%20state%202001"
        },
        {
            "id": "34",
            "entry": "[34] Arthur Asuncion and David J. Newman. UCI Machine Learning Repository, 2007. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arthur%20Asuncion%20and%20David%20J%20Newman%20UCI%20Machine%20Learning%20Repository%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arthur%20Asuncion%20and%20David%20J%20Newman%20UCI%20Machine%20Learning%20Repository%202007"
        }
    ]
}
