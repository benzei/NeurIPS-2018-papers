{
    "filename": "7444-learning-to-exploit-stability-for-3d-scene-parsing.pdf",
    "metadata": {
        "title": "Learning to Exploit Stability for 3D Scene Parsing",
        "author": "Yilun Du, Zhijian Liu, Hector Basevi, Ales Leonardis, Bill Freeman, Josh Tenenbaum, Jiajun Wu",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7444-learning-to-exploit-stability-for-3d-scene-parsing.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Human scene understanding uses a variety of visual and non-visual cues to perform inference on object types, poses, and relations. Physics is a rich and universal cue that we exploit to enhance scene understanding. In this paper, we integrate the physical cue of stability into the learning process by looping in a physics engine into bottom-up recognition models, and apply it to the problem of 3D scene parsing. We first show that applying physics supervision to an existing scene understanding model increases performance, produces more stable predictions, and allows training to an equivalent performance level with fewer annotated training examples. We then present a novel architecture for 3D scene parsing named Prim R-CNN, learning to predict bounding boxes as well as their 3D size, translation, and rotation. With physics supervision, Prim R-CNN outperforms existing scene understanding approaches on this problem. Finally, we show that finetuning with physics supervision on unlabeled real images improves real domain transfer of models training on synthetic data."
    },
    "keywords": [
        {
            "term": "real image",
            "url": "https://en.wikipedia.org/wiki/real_image"
        },
        {
            "term": "mean average precision",
            "url": "https://en.wikipedia.org/wiki/mean_average_precision"
        },
        {
            "term": "physics engine",
            "url": "https://en.wikipedia.org/wiki/physics_engine"
        },
        {
            "term": "depth image",
            "url": "https://en.wikipedia.org/wiki/depth_image"
        },
        {
            "term": "domain transfer",
            "url": "https://en.wikipedia.org/wiki/domain_transfer"
        }
    ],
    "highlights": [
        "Human scene understanding is rich, and operates robustly using limited information",
        "Physics comprises invisible causal relationships that are ubiquitous in natural scenes and crucial in scene understanding [<a class=\"ref-link\" id=\"cBattaglia_et+al_2013_a\" href=\"#rBattaglia_et+al_2013_a\">Battaglia et al, 2013</a>, <a class=\"ref-link\" id=\"cZhang_et+al_2016_a\" href=\"#rZhang_et+al_2016_a\">Zhang et al, 2016</a>]",
        "Image sequences enable the robust inference of physical properties through movement of visual features [<a class=\"ref-link\" id=\"cStewart_2017_a\" href=\"#rStewart_2017_a\">Stewart and Ermon, 2017</a>], but analysis of single images requires a different approach",
        "Raw Input Image For direct primitive prediction from a raw image, we propose a new network architecture called Prim R-CNN",
        "We found diminishing gains from the physics module on the whole SUNCG dataset, perhaps because on a scale of so many images, primitives are already predicted at a close-to-stable location, reducing need of physics supervision, we still observe increased stability",
        "Our model effectively uses unlabeled images for training and allows better domain transfer when applied to real images"
    ],
    "key_statements": [
        "Human scene understanding is rich, and operates robustly using limited information",
        "Physics comprises invisible causal relationships that are ubiquitous in natural scenes and crucial in scene understanding [<a class=\"ref-link\" id=\"cBattaglia_et+al_2013_a\" href=\"#rBattaglia_et+al_2013_a\">Battaglia et al, 2013</a>, <a class=\"ref-link\" id=\"cZhang_et+al_2016_a\" href=\"#rZhang_et+al_2016_a\">Zhang et al, 2016</a>]",
        "Image sequences enable the robust inference of physical properties through movement of visual features [<a class=\"ref-link\" id=\"cStewart_2017_a\" href=\"#rStewart_2017_a\">Stewart and Ermon, 2017</a>], but analysis of single images requires a different approach",
        "Raw Input Image For direct primitive prediction from a raw image, we propose a new network architecture called Prim R-CNN",
        "We found diminishing gains from the physics module on the whole SUNCG dataset, perhaps because on a scale of so many images, primitives are already predicted at a close-to-stable location, reducing need of physics supervision, we still observe increased stability",
        "Results We show quantitative results for training Prim R-CNN in Table 2",
        "We show plots for Prim R-CNN trained and finetuned with physics on limited data in Figure 5 and quantitative numbers in Table 3",
        "To demonstrate the generalization of our approach, we further show that our model can be finetuned on real images and obtain significant gains to performance on SUN RGB-D without using any 3D labeled real data",
        "Our model effectively uses unlabeled images for training and allows better domain transfer when applied to real images"
    ],
    "summary": [
        "Human scene understanding is rich, and operates robustly using limited information.",
        "Our work builds on the explicit object-based geometric primitive representation of 3D scenes in <a class=\"ref-link\" id=\"cTulsiani_et+al_2018_a\" href=\"#rTulsiani_et+al_2018_a\">Tulsiani et al [2018</a>], which facilitates physical prediction.",
        "To recover a 3D reconstructed scene, our physics stability model consists of (i) a primitive prediction module\u2014an inverse graphics component to build object representations from an input image, (b) a layout prediction module that estimates the enclosing space of objects, and (c) a physics stability module that simulates the stability of the prediction.",
        "The third component of our model is a physics stability module that takes predictions from both primitives and layout to generate a 3D scene and infer the stability of each of the primitives through a physics engine [<a class=\"ref-link\" id=\"cCoumans_2010_a\" href=\"#rCoumans_2010_a\">Coumans, 2010</a>].",
        "Our model can be trained in an semi-supervised manner on images without 3D annotations by learning to generate predictions that are physically stable.",
        "REINFORCE Details We train layout and primitive prediction modules simultaneously with the stability signal and apply REINFORCE at the scene level.",
        "We begin by showing that our proposed physical stability model provides gains to performance of the Factored3D model using ground truth 2D bounding boxes.",
        "We finetune using our remaining semi-supervised data without 3D annotations, containing only color images and ground truth bounding box annotations, to train our model using the physics stability module by using alternate batches of supervised and semi-supervised data.",
        "We found diminishing gains from the physics module on the whole SUNCG dataset, perhaps because on a scale of so many images, primitives are already predicted at a close-to-stable location, reducing need of physics supervision, we still observe increased stability.",
        "We further show that our proposed physical stability model is able to provide gains to an end-to-end primitive prediction network with further gains from utilizing unlabeled input images.",
        "We further note that with physics supervision, we get the same performance at 0.3 IOU mAP as the ground truth Factored3D model using only 10% of the data.",
        "To demonstrate the generalization of our approach, we further show that our model can be finetuned on real images and obtain significant gains to performance on SUN RGB-D without using any 3D labeled real data.",
        "Data We use 10,335 real training color images from the SUN RGB-D [<a class=\"ref-link\" id=\"cSong_et+al_2015_a\" href=\"#rSong_et+al_2015_a\">Song et al, 2015</a>] with 2D bounding box annotation.",
        "In the case of Prim R-CNN, when finetuning on unlabeled raw images from SUN RGB-D, we train the corresponding bounding box classification parts of the network.",
        "We propose a physical stability model that combines primitive and layout prediction modules with a physics simulation engine.",
        "We expect our model to have wider impact in the future due to the growing need for accurate 3D scene reconstruction methods and the increased prevalence of synthetic datasets"
    ],
    "headline": "We present a novel architecture for 3D scene parsing named Prim R-CNN, learning to predict bounding boxes as well as their 3D size, translation, and rotation",
    "reference_links": [
        {
            "id": "Ba_et+al_2015_a",
            "entry": "Jimmy Ba, Volodymyr Mnih, and Koray Kavukcuoglu. Multiple object recognition with visual attention. In ICLR, 2015. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ba%2C%20Jimmy%20Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Multiple%20object%20recognition%20with%20visual%20attention%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ba%2C%20Jimmy%20Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Multiple%20object%20recognition%20with%20visual%20attention%202015"
        },
        {
            "id": "Bansal_2016_a",
            "entry": "Aayush Bansal and Bryan Russell. Marr revisited: 2d-3d alignment via surface normal prediction. In CVPR, 2016. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bansal%2C%20Aayush%20Russell%2C%20Bryan%20Marr%20revisited%3A%202d-3d%20alignment%20via%20surface%20normal%20prediction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bansal%2C%20Aayush%20Russell%2C%20Bryan%20Marr%20revisited%3A%202d-3d%20alignment%20via%20surface%20normal%20prediction%202016"
        },
        {
            "id": "Battaglia_et+al_2013_a",
            "entry": "Peter W Battaglia, Jessica B Hamrick, and Joshua B Tenenbaum. Simulation as an engine of physical scene understanding. PNAS, 110(45):18327\u201318332, 2013. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Battaglia%2C%20Peter%20W.%20Hamrick%2C%20Jessica%20B.%20Tenenbaum%2C%20Joshua%20B.%20Simulation%20as%20an%20engine%20of%20physical%20scene%20understanding%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Battaglia%2C%20Peter%20W.%20Hamrick%2C%20Jessica%20B.%20Tenenbaum%2C%20Joshua%20B.%20Simulation%20as%20an%20engine%20of%20physical%20scene%20understanding%202013"
        },
        {
            "id": "Battaglia_et+al_2016_a",
            "entry": "Peter W. Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, and Koray Kavukcuoglu. Interaction networks for learning about objects, relations and physics. In NIPS, 2016. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Battaglia%2C%20Peter%20W.%20Pascanu%2C%20Razvan%20Lai%2C%20Matthew%20Rezende%2C%20Danilo%20Interaction%20networks%20for%20learning%20about%20objects%2C%20relations%20and%20physics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Battaglia%2C%20Peter%20W.%20Pascanu%2C%20Razvan%20Lai%2C%20Matthew%20Rezende%2C%20Danilo%20Interaction%20networks%20for%20learning%20about%20objects%2C%20relations%20and%20physics%202016"
        },
        {
            "id": "Brachmann_et+al_2016_a",
            "entry": "Eric Brachmann, Frank Michel, Alexander Krull, Michael Ying Yang, Stefan Gumhold, et al. Uncertainty-driven 6d pose estimation of objects and scenes from a single rgb image. In CVPR, 2016. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brachmann%2C%20Eric%20Michel%2C%20Frank%20Krull%2C%20Alexander%20Yang%2C%20Michael%20Ying%20Uncertainty-driven%206d%20pose%20estimation%20of%20objects%20and%20scenes%20from%20a%20single%20rgb%20image%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brachmann%2C%20Eric%20Michel%2C%20Frank%20Krull%2C%20Alexander%20Yang%2C%20Michael%20Ying%20Uncertainty-driven%206d%20pose%20estimation%20of%20objects%20and%20scenes%20from%20a%20single%20rgb%20image%202016"
        },
        {
            "id": "Chang_et+al_2017_a",
            "entry": "Michael B Chang, Tomer Ullman, Antonio Torralba, and Joshua B Tenenbaum. A compositional object-based approach to learning physical dynamics. In ICLR, 2017. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chang%2C%20Michael%20B.%20Ullman%2C%20Tomer%20Torralba%2C%20Antonio%20Tenenbaum%2C%20Joshua%20B.%20A%20compositional%20object-based%20approach%20to%20learning%20physical%20dynamics%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20Michael%20B.%20Ullman%2C%20Tomer%20Torralba%2C%20Antonio%20Tenenbaum%2C%20Joshua%20B.%20A%20compositional%20object-based%20approach%20to%20learning%20physical%20dynamics%202017"
        },
        {
            "id": "Coumans_2010_a",
            "entry": "Erwin Coumans. Bullet physics engine. Open Source Software: http://bulletphysics.org, 2010.3, 5",
            "url": "http://bulletphysics.org"
        },
        {
            "id": "Dai_et+al_2016_a",
            "entry": "Jifeng Dai, Yi Li, Kaiming He, and Jian Sun. R-fcn: Object detection via region-based fully convolutional networks. In NIPS, 2016. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20Jifeng%20Li%2C%20Yi%20He%2C%20Kaiming%20Sun%2C%20Jian%20R-fcn%3A%20Object%20detection%20via%20region-based%20fully%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20Jifeng%20Li%2C%20Yi%20He%2C%20Kaiming%20Sun%2C%20Jian%20R-fcn%3A%20Object%20detection%20via%20region-based%20fully%20convolutional%20networks%202016"
        },
        {
            "id": "Ehrhardt_et+al_2017_a",
            "entry": "Sebastien Ehrhardt, Aron Monszpart, Niloy J Mitra, and Andrea Vedaldi. Learning a physical long-term predictor. arXiv:1703.00247, 2017. 2",
            "arxiv_url": "https://arxiv.org/pdf/1703.00247"
        },
        {
            "id": "Eigen_2015_a",
            "entry": "David Eigen and Rob Fergus. Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture. In ICCV, 2015. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eigen%2C%20David%20Fergus%2C%20Rob%20Predicting%20depth%2C%20surface%20normals%20and%20semantic%20labels%20with%20a%20common%20multi-scale%20convolutional%20architecture%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eigen%2C%20David%20Fergus%2C%20Rob%20Predicting%20depth%2C%20surface%20normals%20and%20semantic%20labels%20with%20a%20common%20multi-scale%20convolutional%20architecture%202015"
        },
        {
            "id": "Eslami_et+al_2016_a",
            "entry": "SM Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, Koray Kavukcuoglu, and Geoffrey E Hinton. Attend, infer, repeat: Fast scene understanding with generative models. In NIPS, 2016. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eslami%2C%20S.M.%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eslami%2C%20S.M.%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016"
        },
        {
            "id": "Finn_et+al_2016_a",
            "entry": "Chelsea Finn, Ian Goodfellow, and Sergey Levine. Unsupervised learning for physical interaction through video prediction. In NIPS, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finn%2C%20Chelsea%20Goodfellow%2C%20Ian%20Levine%2C%20Sergey%20Unsupervised%20learning%20for%20physical%20interaction%20through%20video%20prediction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20Chelsea%20Goodfellow%2C%20Ian%20Levine%2C%20Sergey%20Unsupervised%20learning%20for%20physical%20interaction%20through%20video%20prediction%202016"
        },
        {
            "id": "Firman_et+al_2016_a",
            "entry": "Michael Firman, Oisin Mac Aodha, Simon Julier, and Gabriel J Brostow. Structured prediction of unobserved voxels from a single depth image. In CVPR, 2016. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Firman%2C%20Michael%20Aodha%2C%20Oisin%20Mac%20Julier%2C%20Simon%20Brostow%2C%20Gabriel%20J.%20Structured%20prediction%20of%20unobserved%20voxels%20from%20a%20single%20depth%20image%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Firman%2C%20Michael%20Aodha%2C%20Oisin%20Mac%20Julier%2C%20Simon%20Brostow%2C%20Gabriel%20J.%20Structured%20prediction%20of%20unobserved%20voxels%20from%20a%20single%20depth%20image%202016"
        },
        {
            "id": "Fisher_et+al_2011_a",
            "entry": "Matthew Fisher, Manolis Savva, and Pat Hanrahan. Characterizing structural relationships in scenes using graph kernels. ACM transactions on graphics (TOG), 30(4):34, 2011. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fisher%2C%20Matthew%20Savva%2C%20Manolis%20Hanrahan%2C%20Pat%20Characterizing%20structural%20relationships%20in%20scenes%20using%20graph%20kernels%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fisher%2C%20Matthew%20Savva%2C%20Manolis%20Hanrahan%2C%20Pat%20Characterizing%20structural%20relationships%20in%20scenes%20using%20graph%20kernels%202011"
        },
        {
            "id": "Fisher_et+al_2012_a",
            "entry": "Matthew Fisher, Daniel Ritchie, Manolis Savva, Thomas Funkhouser, and Pat Hanrahan. Example-based synthesis of 3d object arrangements. ACM TOG, 31(6):135, 2012. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fisher%2C%20Matthew%20Ritchie%2C%20Daniel%20Savva%2C%20Manolis%20Funkhouser%2C%20Thomas%20Example-based%20synthesis%20of%203d%20object%20arrangements%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fisher%2C%20Matthew%20Ritchie%2C%20Daniel%20Savva%2C%20Manolis%20Funkhouser%2C%20Thomas%20Example-based%20synthesis%20of%203d%20object%20arrangements%202012"
        },
        {
            "id": "Fragkiadaki_et+al_2016_a",
            "entry": "Katerina Fragkiadaki, Pulkit Agrawal, Sergey Levine, and Jitendra Malik. Learning visual predictive models of physics for playing billiards. In ICLR, 2016. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fragkiadaki%2C%20Katerina%20Agrawal%2C%20Pulkit%20Levine%2C%20Sergey%20Malik%2C%20Jitendra%20Learning%20visual%20predictive%20models%20of%20physics%20for%20playing%20billiards%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fragkiadaki%2C%20Katerina%20Agrawal%2C%20Pulkit%20Levine%2C%20Sergey%20Malik%2C%20Jitendra%20Learning%20visual%20predictive%20models%20of%20physics%20for%20playing%20billiards%202016"
        },
        {
            "id": "Gupta_et+al_2010_a",
            "entry": "Abhinav Gupta, Alexei A Efros, and Martial Hebert. Blocks world revisited: Image understanding using qualitative geometry and mechanics. In ECCV, 2010. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Abhinav%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Blocks%20world%20revisited%3A%20Image%20understanding%20using%20qualitative%20geometry%20and%20mechanics%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Abhinav%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Blocks%20world%20revisited%3A%20Image%20understanding%20using%20qualitative%20geometry%20and%20mechanics%202010"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2015. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015"
        },
        {
            "id": "He_et+al_2017_a",
            "entry": "Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Girshick. Mask r-cnn. In ICCV, 2017. 1, 2, 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Doll%C3%A1r%20and%20Ross%20Girshick%20Mask%20rcnn%20In%20ICCV%202017%201%202%204",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Doll%C3%A1r%20and%20Ross%20Girshick%20Mask%20rcnn%20In%20ICCV%202017%201%202%204"
        },
        {
            "id": "Hoiem_et+al_2005_a",
            "entry": "Derek Hoiem, Alexei A. Efros, and Martial Hebert. Geometric context from a single image. In ICCV, 2005. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoiem%2C%20Derek%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Geometric%20context%20from%20a%20single%20image%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoiem%2C%20Derek%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Geometric%20context%20from%20a%20single%20image%202005"
        },
        {
            "id": "Huang_2015_a",
            "entry": "Jonathan Huang and Kevin Murphy. Efficient inference in occlusion-aware generative models of images. In ICLR Workshop, 2015. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Jonathan%20Murphy%2C%20Kevin%20Efficient%20inference%20in%20occlusion-aware%20generative%20models%20of%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Jonathan%20Murphy%2C%20Kevin%20Efficient%20inference%20in%20occlusion-aware%20generative%20models%20of%20images%202015"
        },
        {
            "id": "Jia_et+al_2013_a",
            "entry": "Zhaoyin Jia, Andy Gallagher, Ashutosh Saxena, and Tsuhan Chen. 3d-based reasoning with blocks, support, and stability. In CVPR, 2013. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jia%2C%20Zhaoyin%20Gallagher%2C%20Andy%20Saxena%2C%20Ashutosh%20Chen%2C%20Tsuhan%203d-based%20reasoning%20with%20blocks%2C%20support%2C%20and%20stability%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Zhaoyin%20Gallagher%2C%20Andy%20Saxena%2C%20Ashutosh%20Chen%2C%20Tsuhan%203d-based%20reasoning%20with%20blocks%2C%20support%2C%20and%20stability%202013"
        },
        {
            "id": "Lerer_et+al_2016_a",
            "entry": "Adam Lerer, Sam Gross, and Rob Fergus. Learning physical intuition of block towers by example. In ICML, 2016. 1, 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lerer%2C%20Adam%20Gross%2C%20Sam%20Fergus%2C%20Rob%20Learning%20physical%20intuition%20of%20block%20towers%20by%20example%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lerer%2C%20Adam%20Gross%2C%20Sam%20Fergus%2C%20Rob%20Learning%20physical%20intuition%20of%20block%20towers%20by%20example%202016"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "Wenbin Li, Ales Leonardis, and Mario Fritz. Visual stability prediction for robotic manipulation. In ICRA. IEEE, 2017. 1, 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Wenbin%20Leonardis%2C%20Ales%20Fritz%2C%20Mario%20Visual%20stability%20prediction%20for%20robotic%20manipulation.%20In%20ICRA%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Wenbin%20Leonardis%2C%20Ales%20Fritz%2C%20Mario%20Visual%20stability%20prediction%20for%20robotic%20manipulation.%20In%20ICRA%202017"
        },
        {
            "id": "Lin_et+al_2017_a",
            "entry": "Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In CVPR, 2017. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Tsung-Yi%20Doll%C3%A1r%2C%20Piotr%20Girshick%2C%20Ross%20He%2C%20Kaiming%20Feature%20pyramid%20networks%20for%20object%20detection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Tsung-Yi%20Doll%C3%A1r%2C%20Piotr%20Girshick%2C%20Ross%20He%2C%20Kaiming%20Feature%20pyramid%20networks%20for%20object%20detection%202017"
        },
        {
            "id": "Liu_et+al_2018_a",
            "entry": "Zhijian Liu, William T Freeman, Joshua B Tenenbaum, and Jiajun Wu. Physical primitive decomposition. In ECCV, 2018. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Zhijian%20Freeman%2C%20William%20T.%20Tenenbaum%2C%20Joshua%20B.%20Wu%2C%20Jiajun%20Physical%20primitive%20decomposition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Zhijian%20Freeman%2C%20William%20T.%20Tenenbaum%2C%20Joshua%20B.%20Wu%2C%20Jiajun%20Physical%20primitive%20decomposition%202018"
        },
        {
            "id": "Mccormac_et+al_2017_a",
            "entry": "John McCormac, Ankur Handa, Stefan Leutenegger, and Andrew J Davison. Scenenet rgb-d: Can 5m synthetic images beat generic imagenet pre-training on indoor segmentation? In ICCV, 2017. 2, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McCormac%2C%20John%20Handa%2C%20Ankur%20Leutenegger%2C%20Stefan%20Davison%2C%20Andrew%20J.%20Scenenet%20rgb-d%3A%20Can%205m%20synthetic%20images%20beat%20generic%20imagenet%20pre-training%20on%20indoor%20segmentation%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McCormac%2C%20John%20Handa%2C%20Ankur%20Leutenegger%2C%20Stefan%20Davison%2C%20Andrew%20J.%20Scenenet%20rgb-d%3A%20Can%205m%20synthetic%20images%20beat%20generic%20imagenet%20pre-training%20on%20indoor%20segmentation%3F%202017"
        },
        {
            "id": "Mottaghi_et+al_2016_a",
            "entry": "Roozbeh Mottaghi, Mohammad Rastegari, Abhinav Gupta, and Ali Farhadi. \u201cwhat happens if...\u201d learning to predict the effect of forces in images. In ECCV, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mottaghi%2C%20Roozbeh%20Rastegari%2C%20Mohammad%20Gupta%2C%20Abhinav%20Farhadi%2C%20Ali%20%E2%80%9Cwhat%20happens%20if...%E2%80%9D%20learning%20to%20predict%20the%20effect%20of%20forces%20in%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mottaghi%2C%20Roozbeh%20Rastegari%2C%20Mohammad%20Gupta%2C%20Abhinav%20Farhadi%2C%20Ali%20%E2%80%9Cwhat%20happens%20if...%E2%80%9D%20learning%20to%20predict%20the%20effect%20of%20forces%20in%20images%202016"
        },
        {
            "id": "Ren_et+al_0000_a",
            "entry": "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In NIPS, 2015. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20R-CNN%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ren%2C%20Shaoqing%20He%2C%20Kaiming%20Girshick%2C%20Ross%20Sun%2C%20Jian%20Faster%20R-CNN%3A%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks"
        },
        {
            "id": "Roberts_1963_a",
            "entry": "Lawrence G Roberts. Machine perception of three-dimensional solids. PhD thesis, Massachusetts Institute of Technology, 1963. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roberts%2C%20Lawrence%20G.%20Machine%20perception%20of%20three-dimensional%20solids%201963"
        },
        {
            "id": "Shao_et+al_2014_a",
            "entry": "Tianjia Shao, Aron Monszpart, Youyi Zheng, Bongjin Koo, Weiwei Xu, Kun Zhou, and Niloy J Mitra. Imagining the unseen: Stability-based cuboid arrangements for scene understanding. ACM TOG, 33(6), 2014. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shao%2C%20Tianjia%20Monszpart%2C%20Aron%20Zheng%2C%20Youyi%20Koo%2C%20Bongjin%20Imagining%20the%20unseen%3A%20Stability-based%20cuboid%20arrangements%20for%20scene%20understanding%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shao%2C%20Tianjia%20Monszpart%2C%20Aron%20Zheng%2C%20Youyi%20Koo%2C%20Bongjin%20Imagining%20the%20unseen%3A%20Stability-based%20cuboid%20arrangements%20for%20scene%20understanding%202014"
        },
        {
            "id": "Silberman_et+al_2012_a",
            "entry": "Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. Indoor segmentation and support inference from rgbd images. In ECCV, 2012. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silberman%2C%20Nathan%20Hoiem%2C%20Derek%20Kohli%2C%20Pushmeet%20Fergus%2C%20Rob%20Indoor%20segmentation%20and%20support%20inference%20from%20rgbd%20images%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silberman%2C%20Nathan%20Hoiem%2C%20Derek%20Kohli%2C%20Pushmeet%20Fergus%2C%20Rob%20Indoor%20segmentation%20and%20support%20inference%20from%20rgbd%20images%202012"
        },
        {
            "id": "Song_et+al_2015_a",
            "entry": "Shuran Song, Samuel P Lichtenberg, and Jianxiong Xiao. Sun rgb-d: A rgb-d scene understanding benchmark suite. In CVPR, 2015. 2, 5, 8",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Shuran%20Lichtenberg%2C%20Samuel%20P.%20Xiao%2C%20Jianxiong%20Sun%20rgb-d%3A%20A%20rgb-d%20scene%20understanding%20benchmark%20suite%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Shuran%20Lichtenberg%2C%20Samuel%20P.%20Xiao%2C%20Jianxiong%20Sun%20rgb-d%3A%20A%20rgb-d%20scene%20understanding%20benchmark%20suite%202015"
        },
        {
            "id": "Song_et+al_2017_a",
            "entry": "Shuran Song, Fisher Yu, Andy Zeng, Angel X Chang, Manolis Savva, and Thomas Funkhouser. Semantic scene completion from a single depth image. In CVPR, 2017. 2, 3, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Shuran%20Yu%2C%20Fisher%20Zeng%2C%20Andy%20Chang%2C%20Angel%20X.%20Semantic%20scene%20completion%20from%20a%20single%20depth%20image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Shuran%20Yu%2C%20Fisher%20Zeng%2C%20Andy%20Chang%2C%20Angel%20X.%20Semantic%20scene%20completion%20from%20a%20single%20depth%20image%202017"
        },
        {
            "id": "Stewart_2017_a",
            "entry": "Russell Stewart and Stefano Ermon. Label-free supervision of neural networks with physics and domain knowledge. In AAAI, 2017. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stewart%2C%20Russell%20Ermon%2C%20Stefano%20Label-free%20supervision%20of%20neural%20networks%20with%20physics%20and%20domain%20knowledge%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stewart%2C%20Russell%20Ermon%2C%20Stefano%20Label-free%20supervision%20of%20neural%20networks%20with%20physics%20and%20domain%20knowledge%202017"
        },
        {
            "id": "Tulsiani_et+al_2018_a",
            "entry": "Shubham Tulsiani, Saurabh Gupta, David Fouhey, Alexei A Efros, and Jitendra Malik. Factoring shape, pose, and layout from the 2d image of a 3d scene. In CVPR, 2018. 2, 3, 4, 5, 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20Shubham%20Gupta%2C%20Saurabh%20Fouhey%2C%20David%20Efros%2C%20Alexei%20A.%20Factoring%20shape%2C%20pose%2C%20and%20layout%20from%20the%202d%20image%20of%20a%203d%20scene%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20Shubham%20Gupta%2C%20Saurabh%20Fouhey%2C%20David%20Efros%2C%20Alexei%20A.%20Factoring%20shape%2C%20pose%2C%20and%20layout%20from%20the%202d%20image%20of%20a%203d%20scene%202018"
        },
        {
            "id": "Williams_1992_a",
            "entry": "Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. MLJ, 8(3-4):229\u2013256, 1992. 2, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Ronald%20J.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Ronald%20J.%20Simple%20statistical%20gradient-following%20algorithms%20for%20connectionist%20reinforcement%20learning%201992"
        },
        {
            "id": "Wu_2016_a",
            "entry": "Jiajun Wu. Computational perception of physical object properties. Master\u2019s thesis, Massachusetts Institute of Technology, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Computational%20perception%20of%20physical%20object%20properties%202016"
        },
        {
            "id": "Wu_et+al_2015_a",
            "entry": "Jiajun Wu, Ilker Yildirim, Joseph J Lim, William T Freeman, and Joshua B Tenenbaum. Galileo: Perceiving physical object properties by integrating a physics engine with deep learning. In NIPS, 2015. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Yildirim%2C%20Ilker%20Lim%2C%20Joseph%20J.%20Freeman%2C%20William%20T.%20Galileo%3A%20Perceiving%20physical%20object%20properties%20by%20integrating%20a%20physics%20engine%20with%20deep%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Yildirim%2C%20Ilker%20Lim%2C%20Joseph%20J.%20Freeman%2C%20William%20T.%20Galileo%3A%20Perceiving%20physical%20object%20properties%20by%20integrating%20a%20physics%20engine%20with%20deep%20learning%202015"
        },
        {
            "id": "Wu_et+al_2016_b",
            "entry": "Jiajun Wu, Joseph J Lim, Hongyi Zhang, Joshua B Tenenbaum, and William T Freeman. Physics 101: Learning physical object properties from unlabeled videos. In BMVC, 2016. 2",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Lim%2C%20Joseph%20J.%20Zhang%2C%20Hongyi%20Tenenbaum%2C%20Joshua%20B.%20Physics%20101%3A%20Learning%20physical%20object%20properties%20from%20unlabeled%20videos%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Lim%2C%20Joseph%20J.%20Zhang%2C%20Hongyi%20Tenenbaum%2C%20Joshua%20B.%20Physics%20101%3A%20Learning%20physical%20object%20properties%20from%20unlabeled%20videos%202016"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "Jiajun Wu, Erika Lu, Pushmeet Kohli, Bill Freeman, and Josh Tenenbaum. Learning to see physics via visual de-animation. In NIPS, 2017a. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Lu%2C%20Erika%20Kohli%2C%20Pushmeet%20Freeman%2C%20Bill%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Lu%2C%20Erika%20Kohli%2C%20Pushmeet%20Freeman%2C%20Bill%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017"
        },
        {
            "id": "Wu_et+al_2017_b",
            "entry": "Jiajun Wu, Joshua B Tenenbaum, and Pushmeet Kohli. Neural scene de-rendering. In CVPR, 2017b. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20CVPR%202017b%203",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20CVPR%202017b%203"
        },
        {
            "id": "Zhang_et+al_2016_a",
            "entry": "Renqiao Zhang, Jiajun Wu, Chengkai Zhang, William T Freeman, and Joshua B Tenenbaum. A comparative evaluation of approximate probabilistic simulation and deep neural networks as accounts of human physical scene understanding. In CogSci, 2016. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Renqiao%20Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Freeman%2C%20William%20T.%20A%20comparative%20evaluation%20of%20approximate%20probabilistic%20simulation%20and%20deep%20neural%20networks%20as%20accounts%20of%20human%20physical%20scene%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Renqiao%20Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Freeman%2C%20William%20T.%20A%20comparative%20evaluation%20of%20approximate%20probabilistic%20simulation%20and%20deep%20neural%20networks%20as%20accounts%20of%20human%20physical%20scene%20understanding%202016"
        },
        {
            "id": "Zhang_et+al_2017_a",
            "entry": "Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, and Thomas Funkhouser. Physically-based rendering for indoor scene understanding using convolutional neural networks. In CVPR, 2017. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Yinda%20Song%2C%20Shuran%20Yumer%2C%20Ersin%20Savva%2C%20Manolis%20Physically-based%20rendering%20for%20indoor%20scene%20understanding%20using%20convolutional%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Yinda%20Song%2C%20Shuran%20Yumer%2C%20Ersin%20Savva%2C%20Manolis%20Physically-based%20rendering%20for%20indoor%20scene%20understanding%20using%20convolutional%20neural%20networks%202017"
        },
        {
            "id": "Zheng_et+al_2013_a",
            "entry": "Bo Zheng, Yibiao Zhao, Joey Yu, Katsushi Ikeuchi, and Song-Chun Zhu. Beyond point clouds: Scene understanding by reasoning geometry and physics. In CVPR, 2013. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20Bo%20Zhao%2C%20Yibiao%20Yu%2C%20Joey%20Ikeuchi%2C%20Katsushi%20Beyond%20point%20clouds%3A%20Scene%20understanding%20by%20reasoning%20geometry%20and%20physics%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20Bo%20Zhao%2C%20Yibiao%20Yu%2C%20Joey%20Ikeuchi%2C%20Katsushi%20Beyond%20point%20clouds%3A%20Scene%20understanding%20by%20reasoning%20geometry%20and%20physics%202013"
        },
        {
            "id": "Zheng_et+al_2015_a",
            "entry": "Bo Zheng, Yibiao Zhao, Joey Yu, Katsushi Ikeuchi, and Song-Chun Zhu. Scene understanding by reasoning stability and safety. IJCV, 112(2):221\u2013238, 2015. 2, 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20Bo%20Zhao%2C%20Yibiao%20Yu%2C%20Joey%20Ikeuchi%2C%20Katsushi%20Scene%20understanding%20by%20reasoning%20stability%20and%20safety%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20Bo%20Zhao%2C%20Yibiao%20Yu%2C%20Joey%20Ikeuchi%2C%20Katsushi%20Scene%20understanding%20by%20reasoning%20stability%20and%20safety%202015"
        },
        {
            "id": "Zitnick_0000_a",
            "entry": "C. Lawrence Zitnick and Piotr Doll\u00e1r. Edge boxes: Locating object proposals from edges. In ECCV, 2014. 4",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zitnick%2C%20C.Lawrence%20Doll%C3%A1r%2C%20Piotr%20Edge%20boxes%3A%20Locating%20object%20proposals%20from%20edges",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zitnick%2C%20C.Lawrence%20Doll%C3%A1r%2C%20Piotr%20Edge%20boxes%3A%20Locating%20object%20proposals%20from%20edges"
        }
    ]
}
