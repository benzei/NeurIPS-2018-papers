{
    "filename": "8090-learning-plannable-representations-with-causal-infogan.pdf",
    "metadata": {
        "title": "Learning Plannable Representations with Causal InfoGAN",
        "author": "Thanard Kurutach, Aviv Tamar, Ge Yang, Stuart J. Russell, Pieter Abbeel",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8090-learning-plannable-representations-with-causal-infogan.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In recent years, deep generative models have been shown to \u2018imagine\u2019 convincing high-dimensional observations such as images, audio, and even video, learning directly from raw data. In this work, we ask how to imagine goal-directed visual plans \u2013 a plausible sequence of observations that transition a dynamical system from its current configuration to a desired goal state, which can later be used as a reference trajectory for control. We focus on systems with high-dimensional observations, such as images, and propose an approach that naturally combines representation learning and planning. Our framework learns a generative model of sequential observations, where the generative process is induced by a transition in a low-dimensional planning model, and an additional noise. By maximizing the mutual information between the generated observations and the transition in the planning model, we obtain a low-dimensional representation that best explains the causal nature of the data. We structure the planning model to be compatible with efficient planning algorithms, and we propose several such models based on either discrete or continuous states. Finally, to generate a visual plan, we project the current and goal observations onto their respective states in the planning model, plan a trajectory, and then use the generative model to transform the trajectory to a sequence of observations. We demonstrate our method on imagining plausible visual plans of rope manipulation3."
    },
    "keywords": [
        {
            "term": "spectral clustering",
            "url": "https://en.wikipedia.org/wiki/spectral_clustering"
        },
        {
            "term": "high dimensional",
            "url": "https://en.wikipedia.org/wiki/high_dimensional"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        }
    ],
    "highlights": [
        "For future robots to perform general tasks in unstructured environments such as homes or hospitals, they must be able to reason about their domain and plan their actions",
        "In AI literature, this general problem has been investigated under two main paradigms \u2013 automated planning and scheduling [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>] (AI planning) and reinforcement learning [<a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>] (RL)",
        "We presented Causal InfoGAN, a framework for learning deep generative models of sequential data with a structured latent space",
        "By choosing the latent space to be compatible with efficient planning algorithms, we developed a framework capable of generating goal-directed trajectories from high-dimensional dynamical systems",
        "The binary latent models we explored provide a connection between deep representation learning and classical AI planning, where Causal InfoGAN can be seen as a method for learning object predicates directly from data",
        "In future work we intend to investigate this direction further, and incorporate object-oriented models, which are a fundamental component in classical AI.\n7The positive data are the pairs of rope images that are 1 step apart and the negative data are randomly chosen pairs that are from different runs which are highly likely to be farther than 1 step apart.\n8This selection process is applied the same way to the DCGAN and InfoGAN baselines"
    ],
    "key_statements": [
        "For future robots to perform general tasks in unstructured environments such as homes or hospitals, they must be able to reason about their domain and plan their actions",
        "In AI literature, this general problem has been investigated under two main paradigms \u2013 automated planning and scheduling [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>] (AI planning) and reinforcement learning [<a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>] (RL)",
        "Classical work in AI planning has drawn on the remarkable capability of humans to perform long-term reasoning and planning by using abstract representations of the world",
        "We present Causal InfoGAN (CIGAN), a method for learning plannable representations of dynamical systems with high-dimensional observations such as images",
        "We focus on discrete and deterministic dynamics models, which can be used with graph search methods, and on continuous models where planning is done by linear interpolation, though our framework can be generalized to other model types",
        "To learn such a model, we follow the InfoGAN idea [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and add to the generative adversarial net training loss a term that maximizes the mutual information between the observation pairs and the transitions that induced them",
        "We approach this challenge by proposing Causal InfoGAN \u2013 an expressive generative model with a structured representation that is compatible with planning algorithms",
        "We propose a generative adversarial net generator that is driven by states sampled from a parametrized dynamical system",
        "We propose the Causal InfoGAN objective: min max V (G, D) \u2212 \u03bbI (s, s ; o, o ) , s.t. o, o \u223c G(z, s, s ); s \u223c PM; s \u223c TM(s), (3)",
        "We present several latent planning systems that are compatible with efficient planning algorithms",
        "We propose a parametric transition model that is suitable for binary representations",
        "In the high-dimensional case, we find that the discriminator tends to overfit to the generator",
        "In Figure 2, we show the Causal InfoGAN classification of observations to abstract states, Q(s|o), and compare with the K-means baseline; the other baselines gave qualitatively similar results",
        "Note that Causal InfoGAN learned clusters that correspond to the possible dynamics of the particle in the task, and was able to generate reasonable planning trajectories",
        "We show that Causal InfoGAN can be used to generate walkthrough plans directly from data for long-horizon tasks, without requiring additional human guidance",
        "As described in Section 4, the encoding, planning, and decoding methods in this case are not specific to Causal InfoGAN, and can be used with a generative adversarial net or InfoGAN generative model, allowing a fair comparison with alternative representation learning methods",
        "To numerically evaluate planning performance we propose a visual fidelity score, inspired by the Inception score for evaluating generative adversarial net [<a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>], we train a binary classifier to classify whether two images are sequential in the data or not7",
        "We presented Causal InfoGAN, a framework for learning deep generative models of sequential data with a structured latent space",
        "By choosing the latent space to be compatible with efficient planning algorithms, we developed a framework capable of generating goal-directed trajectories from high-dimensional dynamical systems",
        "The binary latent models we explored provide a connection between deep representation learning and classical AI planning, where Causal InfoGAN can be seen as a method for learning object predicates directly from data",
        "In future work we intend to investigate this direction further, and incorporate object-oriented models, which are a fundamental component in classical AI.\n7The positive data are the pairs of rope images that are 1 step apart and the negative data are randomly chosen pairs that are from different runs which are highly likely to be farther than 1 step apart.\n8This selection process is applied the same way to the DCGAN and InfoGAN baselines"
    ],
    "summary": [
        "For future robots to perform general tasks in unstructured environments such as homes or hospitals, they must be able to reason about their domain and plan their actions .",
        "We present Causal InfoGAN (CIGAN), a method for learning plannable representations of dynamical systems with high-dimensional observations such as images.",
        "The GAN generator takes as input both unstructured random noise and a structured pair of consecutive states from a low-dimensional, parametrized dynamical system termed the planning model.",
        "To learn such a model, we follow the InfoGAN idea [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and add to the GAN training loss a term that maximizes the mutual information between the observation pairs and the transitions that induced them.",
        "We want to plan efficiently, which generally requires either low dimensional state spaces or well-structured representations.",
        "We approach this challenge by proposing Causal InfoGAN \u2013 an expressive generative model with a structured representation that is compatible with planning algorithms.",
        "We follow InfoGAN [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and add to the GAN objective a term that maximizes mutual information between the generated pair of observations and the abstract states.",
        "The key idea here is that, if only small local transitions are possible in the system, a linear interpolation between two states sstart, sgoal has a high probability, and represents a feasible trajectory in the observation space.",
        "We do not require a reward signal, and learn a general model of the dynamical system, which is used for goal-directed planning.",
        "This demonstrates the potential of CIGAN to learn meaningful state abstractions without requiring a distance function in observation space.",
        "Note that CIGAN learned clusters that correspond to the possible dynamics of the particle in the task, and was able to generate reasonable planning trajectories.",
        "We show that CIGAN can be used to generate walkthrough plans directly from data for long-horizon tasks, without requiring additional human guidance.",
        "As described in Section 4, the encoding, planning, and decoding methods in this case are not specific to CIGAN, and can be used with a GAN or InfoGAN generative model, allowing a fair comparison with alternative representation learning methods.",
        "We presented Causal InfoGAN, a framework for learning deep generative models of sequential data with a structured latent space.",
        "By choosing the latent space to be compatible with efficient planning algorithms, we developed a framework capable of generating goal-directed trajectories from high-dimensional dynamical systems.",
        "The binary latent models we explored provide a connection between deep representation learning and classical AI planning, where Causal InfoGAN can be seen as a method for learning object predicates directly from data.",
        "In future work we intend to investigate this direction further, and incorporate object-oriented models, which are a fundamental component in classical AI"
    ],
    "headline": "We focus on systems with high-dimensional observations, such as images, and propose an approach that naturally combines representation learning and planning",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] P. Agrawal, A. V. Nair, P. Abbeel, J. Malik, and S. Levine. Learning to poke by poking: Experiential learning of intuitive physics. In Advances in Neural Information Processing Systems, pages 5074\u20135082, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agrawal%2C%20P.%20Nair%2C%20A.V.%20Abbeel%2C%20P.%20Malik%2C%20J.%20Learning%20to%20poke%20by%20poking%3A%20Experiential%20learning%20of%20intuitive%20physics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agrawal%2C%20P.%20Nair%2C%20A.V.%20Abbeel%2C%20P.%20Malik%2C%20J.%20Learning%20to%20poke%20by%20poking%3A%20Experiential%20learning%20of%20intuitive%20physics%202016"
        },
        {
            "id": "2",
            "entry": "[2] M. Andrychowicz, F. Wolski, A. Ray, J. Schneider, R. Fong, P. Welinder, B. McGrew, J. Tobin, O. P. Abbeel, and W. Zaremba. Hindsight experience replay. In Advances in Neural Information Processing Systems, pages 5048\u20135058, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andrychowicz%2C%20M.%20Wolski%2C%20F.%20Ray%2C%20A.%20Schneider%2C%20J.%20Hindsight%20experience%20replay%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andrychowicz%2C%20M.%20Wolski%2C%20F.%20Ray%2C%20A.%20Schneider%2C%20J.%20Hindsight%20experience%20replay%202017"
        },
        {
            "id": "3",
            "entry": "[3] N. Baram, T. Zahavy, and S. Mannor. Spatio-temporal abstractions in reinforcement learning through neural encoding. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baram%2C%20N.%20Zahavy%2C%20T.%20Mannor%2C%20S.%20Spatio-temporal%20abstractions%20in%20reinforcement%20learning%20through%20neural%20encoding%202016"
        },
        {
            "id": "4",
            "entry": "[4] P. W. Battaglia, J. B. Hamrick, and J. B. Tenenbaum. Simulation as an engine of physical scene understanding. Proceedings of the National Academy of Sciences, 110(45):18327\u201318332, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Battaglia%2C%20P.W.%20Hamrick%2C%20J.B.%20Tenenbaum%2C%20J.B.%20Simulation%20as%20an%20engine%20of%20physical%20scene%20understanding%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Battaglia%2C%20P.W.%20Hamrick%2C%20J.B.%20Tenenbaum%2C%20J.B.%20Simulation%20as%20an%20engine%20of%20physical%20scene%20understanding%202013"
        },
        {
            "id": "5",
            "entry": "[5] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel. InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20X.%20Duan%2C%20Y.%20Houthooft%2C%20R.%20Schulman%2C%20J.%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "6",
            "entry": "[6] J. Chung, K. Kastner, L. Dinh, K. Goel, A. C. Courville, and Y. Bengio. A recurrent latent variable model for sequential data. In Advances in neural information processing systems, pages 2980\u20132988, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20J.%20Kastner%2C%20K.%20Dinh%2C%20L.%20Goel%2C%20K.%20A%20recurrent%20latent%20variable%20model%20for%20sequential%20data%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chung%2C%20J.%20Kastner%2C%20K.%20Dinh%2C%20L.%20Goel%2C%20K.%20A%20recurrent%20latent%20variable%20model%20for%20sequential%20data%202015"
        },
        {
            "id": "7",
            "entry": "[7] D. Corneil, W. Gerstner, and J. Brea. Efficient model-based deep reinforcement learning with variational state tabulation. arXiv preprint arXiv:1802.04325, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04325"
        },
        {
            "id": "8",
            "entry": "[8] T. M. Cover and J. A. Thomas. Elements of information theory. John Wiley & Sons, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20T.M.%20Thomas%2C%20J.A.%20Elements%20of%20information%20theory%202012"
        },
        {
            "id": "9",
            "entry": "[9] E. L. Denton and v. Birodkar. Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems 30, pages 4414\u20134423. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20E.L.%20v.%20Birodkar%20Unsupervised%20learning%20of%20disentangled%20representations%20from%20video%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20E.L.%20v.%20Birodkar%20Unsupervised%20learning%20of%20disentangled%20representations%20from%20video%202017"
        },
        {
            "id": "10",
            "entry": "[10] J. Donahue, P. Kr\u00e4henb\u00fchl, and T. Darrell. Adversarial feature learning. arXiv preprint arXiv:1605.09782, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.09782"
        },
        {
            "id": "11",
            "entry": "[11] R. E. Fikes, P. E. Hart, and N. J. Nilsson. Learning and executing generalized robot plans. In Readings in Artificial Intelligence, pages 231\u2013249.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fikes%2C%20R.E.%20Hart%2C%20P.E.%20Nilsson%2C%20N.J.%20Learning%20and%20executing%20generalized%20robot%20plans",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fikes%2C%20R.E.%20Hart%2C%20P.E.%20Nilsson%2C%20N.J.%20Learning%20and%20executing%20generalized%20robot%20plans"
        },
        {
            "id": "12",
            "entry": "[12] C. Finn and S. Levine. Deep visual foresight for planning robot motion. In Robotics and Automation (ICRA), 2017 IEEE International Conference on, pages 2786\u20132793. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finn%2C%20C.%20Levine%2C%20S.%20Deep%20visual%20foresight%20for%20planning%20robot%20motion%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20C.%20Levine%2C%20S.%20Deep%20visual%20foresight%20for%20planning%20robot%20motion%202017"
        },
        {
            "id": "13",
            "entry": "[13] C. Finn, S. Levine, and P. Abbeel. Guided cost learning: Deep inverse optimal control via policy optimization. In International Conference on Machine Learning, pages 49\u201358, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finn%2C%20C.%20Levine%2C%20S.%20Abbeel%2C%20P.%20Guided%20cost%20learning%3A%20Deep%20inverse%20optimal%20control%20via%20policy%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20C.%20Levine%2C%20S.%20Abbeel%2C%20P.%20Guided%20cost%20learning%3A%20Deep%20inverse%20optimal%20control%20via%20policy%20optimization%202016"
        },
        {
            "id": "14",
            "entry": "[14] C. Finn, X. Y. Tan, Y. Duan, T. Darrell, S. Levine, and P. Abbeel. Deep spatial autoencoders for visuomotor learning. In Robotics and Automation (ICRA), 2016 IEEE International Conference on, pages 512\u2013519. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finn%2C%20C.%20Tan%2C%20X.Y.%20Duan%2C%20Y.%20Darrell%2C%20T.%20Deep%20spatial%20autoencoders%20for%20visuomotor%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20C.%20Tan%2C%20X.Y.%20Duan%2C%20Y.%20Darrell%2C%20T.%20Deep%20spatial%20autoencoders%20for%20visuomotor%20learning%202016"
        },
        {
            "id": "15",
            "entry": "[15] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "16",
            "entry": "[16] E. Jang, S. Gu, and B. Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01144"
        },
        {
            "id": "17",
            "entry": "[17] M. Johnson, D. K. Duvenaud, A. Wiltschko, R. P. Adams, and S. R. Datta. Composing graphical models with neural networks for structured representations and fast inference. In NIPS, pages 2946\u20132954, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20M.%20Duvenaud%2C%20D.K.%20Wiltschko%2C%20A.%20Adams%2C%20R.P.%20Composing%20graphical%20models%20with%20neural%20networks%20for%20structured%20representations%20and%20fast%20inference%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20M.%20Duvenaud%2C%20D.K.%20Wiltschko%2C%20A.%20Adams%2C%20R.P.%20Composing%20graphical%20models%20with%20neural%20networks%20for%20structured%20representations%20and%20fast%20inference%202016"
        },
        {
            "id": "18",
            "entry": "[18] K. Kansky, T. Silver, D. A. M\u00e9ly, M. Eldawy, M. L\u00e1zaro-Gredilla, X. Lou, N. Dorfman, S. Sidor, S. Phoenix, and D. George. Schema networks: Zero-shot transfer with a generative causal model of intuitive physics. In ICML, volume 70, pages 1809\u20131818, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schema%20networks%3A%20Zero-shot%20transfer%20with%20a%20generative%20causal%20model%20of%20intuitive%20physics%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schema%20networks%3A%20Zero-shot%20transfer%20with%20a%20generative%20causal%20model%20of%20intuitive%20physics%202017"
        },
        {
            "id": "19",
            "entry": "[19] T. Karras, T. Aila, S. Laine, and J. Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10196"
        },
        {
            "id": "20",
            "entry": "[20] D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "21",
            "entry": "[21] G. Konidaris, L. P. Kaelbling, and T. Lozano-Perez. From skills to symbols: Learning symbolic representations for abstract high-level planning. Journal of Artificial Intelligence Research, 61:215\u2013289, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Konidaris%2C%20G.%20Kaelbling%2C%20L.P.%20Lozano-Perez%2C%20T.%20From%20skills%20to%20symbols%3A%20Learning%20symbolic%20representations%20for%20abstract%20high-level%20planning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Konidaris%2C%20G.%20Kaelbling%2C%20L.P.%20Lozano-Perez%2C%20T.%20From%20skills%20to%20symbols%3A%20Learning%20symbolic%20representations%20for%20abstract%20high-level%20planning%202018"
        },
        {
            "id": "22",
            "entry": "[22] A. Lerer, S. Gross, and R. Fergus. Learning physical intuition of block towers by example. arXiv preprint arXiv:1603.01312, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.01312"
        },
        {
            "id": "23",
            "entry": "[23] S. Levine, C. Finn, T. Darrell, and P. Abbeel. End-to-end training of deep visuomotor policies. JMLR, 17, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levine%2C%20S.%20Finn%2C%20C.%20Darrell%2C%20T.%20Abbeel%2C%20P.%20End-to-end%20training%20of%20deep%20visuomotor%20policies%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levine%2C%20S.%20Finn%2C%20C.%20Darrell%2C%20T.%20Abbeel%2C%20P.%20End-to-end%20training%20of%20deep%20visuomotor%20policies%202016"
        },
        {
            "id": "24",
            "entry": "[24] M. Liu, M. C. Machado, G. Tesauro, and M. Campbell. The eigenoption-critic framework. arXiv preprint arXiv:1712.04065, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.04065"
        },
        {
            "id": "25",
            "entry": "[25] M. C. Machado, M. G. Bellemare, and M. Bowling. A laplacian framework for option discovery in reinforcement learning. arXiv preprint arXiv:1703.00956, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00956"
        },
        {
            "id": "26",
            "entry": "[26] S. Mahadevan and M. Maggioni. Proto-value functions: A laplacian framework for learning representation and control in markov decision processes. Journal of Machine Learning Research, 8(Oct):2169\u20132231, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mahadevan%2C%20S.%20Maggioni%2C%20M.%20Proto-value%20functions%3A%20A%20laplacian%20framework%20for%20learning%20representation%20and%20control%20in%20markov%20decision%20processes%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mahadevan%2C%20S.%20Maggioni%2C%20M.%20Proto-value%20functions%3A%20A%20laplacian%20framework%20for%20learning%20representation%20and%20control%20in%20markov%20decision%20processes%202007"
        },
        {
            "id": "27",
            "entry": "[27] S. Mannor, I. Menache, A. Hoze, and U. Klein. Dynamic abstraction in reinforcement learning via clustering. In Proceedings of the twenty-first international conference on Machine learning, page 71. ACM, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mannor%2C%20S.%20Menache%2C%20I.%20Hoze%2C%20A.%20Klein%2C%20U.%20Dynamic%20abstraction%20in%20reinforcement%20learning%20via%20clustering%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mannor%2C%20S.%20Menache%2C%20I.%20Hoze%2C%20A.%20Klein%2C%20U.%20Dynamic%20abstraction%20in%20reinforcement%20learning%20via%20clustering%202004"
        },
        {
            "id": "28",
            "entry": "[28] V. Mnih, K. Kavukcuoglu, D. Silver, A. Rusu, J. Veness, M. Bellemare, A. Graves, M. Riedmiller, A. Fidjeland, G. Ostrovski, et al. Human-level control through deep reinforcement learning. Nature, 518(7540):529\u2013533, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20V.%20Kavukcuoglu%2C%20K.%20Silver%2C%20D.%20Rusu%2C%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20V.%20Kavukcuoglu%2C%20K.%20Silver%2C%20D.%20Rusu%2C%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015"
        },
        {
            "id": "29",
            "entry": "[29] A. Nair, D. Chen, P. Agrawal, P. Isola, P. Abbeel, J. Malik, and S. Levine. Combining self-supervised learning and imitation for vision-based rope manipulation. In Robotics and Automation (ICRA), 2017 IEEE International Conference on, pages 2146\u20132153. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nair%2C%20A.%20Chen%2C%20D.%20Agrawal%2C%20P.%20Isola%2C%20P.%20Combining%20self-supervised%20learning%20and%20imitation%20for%20vision-based%20rope%20manipulation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nair%2C%20A.%20Chen%2C%20D.%20Agrawal%2C%20P.%20Isola%2C%20P.%20Combining%20self-supervised%20learning%20and%20imitation%20for%20vision-based%20rope%20manipulation%202017"
        },
        {
            "id": "30",
            "entry": "[30] J. Oh, X. Guo, H. Lee, R. L. Lewis, and S. Singh. Action-conditional video prediction using deep networks in atari games. In Advances in Neural Information Processing Systems, pages 2863\u20132871, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oh%2C%20J.%20Guo%2C%20X.%20Lee%2C%20H.%20Lewis%2C%20R.L.%20Action-conditional%20video%20prediction%20using%20deep%20networks%20in%20atari%20games%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oh%2C%20J.%20Guo%2C%20X.%20Lee%2C%20H.%20Lewis%2C%20R.L.%20Action-conditional%20video%20prediction%20using%20deep%20networks%20in%20atari%20games%202015"
        },
        {
            "id": "31",
            "entry": "[31] J. Oh, S. Singh, and H. Lee. Value prediction network. In Advances in Neural Information Processing Systems, pages 6118\u20136128, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oh%2C%20J.%20Singh%2C%20S.%20Lee%2C%20H.%20Value%20prediction%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oh%2C%20J.%20Singh%2C%20S.%20Lee%2C%20H.%20Value%20prediction%20network%202017"
        },
        {
            "id": "32",
            "entry": "[32] V. Pong, S. Gu, M. Dalal, and S. Levine. Temporal difference models: Model-free deep RL for model-based control. CoRR, abs/1802.09081, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.09081"
        },
        {
            "id": "33",
            "entry": "[33] M. Riedmiller, R. Hafner, T. Lampe, M. Neunert, J. Degrave, T. Van de Wiele, V. Mnih, N. Heess, and J. T. Springenberg. Learning by playing-solving sparse reward tasks from scratch. arXiv preprint arXiv:1802.10567, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.10567"
        },
        {
            "id": "34",
            "entry": "[34] S. J. Russell and P. Norvig. Artificial Intelligence - A Modern Approach (3. internat. ed.). Pearson Education, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russell%2C%20S.J.%20Norvig%2C%20P.%20Artificial%20Intelligence%20-%20A%20Modern%20Approach%20%283.%20internat%202010"
        },
        {
            "id": "35",
            "entry": "[35] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pages 2234\u20132242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20T.%20Goodfellow%2C%20I.%20Zaremba%2C%20W.%20Cheung%2C%20V.%20Improved%20techniques%20for%20training%20gans%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20T.%20Goodfellow%2C%20I.%20Zaremba%2C%20W.%20Cheung%2C%20V.%20Improved%20techniques%20for%20training%20gans%202016"
        },
        {
            "id": "36",
            "entry": "[36] A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia, and T. Lillicrap. A simple neural network module for relational reasoning. In Advances in neural information processing systems, pages 4974\u20134983, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santoro%2C%20A.%20Raposo%2C%20D.%20Barrett%2C%20D.G.%20Malinowski%2C%20M.%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Santoro%2C%20A.%20Raposo%2C%20D.%20Barrett%2C%20D.G.%20Malinowski%2C%20M.%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017"
        },
        {
            "id": "37",
            "entry": "[37] N. Savinov, A. Dosovitskiy, and V. Koltun. Semi-parametric topological memory for navigation. arXiv preprint arXiv:1803.00653, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.00653"
        },
        {
            "id": "38",
            "entry": "[38] D. I. Simester, P. Sun, and J. N. Tsitsiklis. Dynamic catalog mailing policies. Management science, 52(5):683\u2013696, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simester%2C%20D.I.%20Sun%2C%20P.%20Tsitsiklis%2C%20J.N.%20Dynamic%20catalog%20mailing%20policies%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simester%2C%20D.I.%20Sun%2C%20P.%20Tsitsiklis%2C%20J.N.%20Dynamic%20catalog%20mailing%20policies%202006"
        },
        {
            "id": "39",
            "entry": "[39] A. Srinivas, A. Jabri, P. Abbeel, S. Levine, and C. Finn. Universal planning networks. arXiv preprint arXiv:1804.00645, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.00645"
        },
        {
            "id": "40",
            "entry": "[40] A. Srinivas, R. Krishnamurthy, P. Kumar, and B. Ravindran. Option discovery in hierarchical reinforcement learning using spatio-temporal clustering. arXiv preprint arXiv:1605.05359, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.05359"
        },
        {
            "id": "41",
            "entry": "[41] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction, volume 1. MIT press Cambridge, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutton%2C%20R.S.%20Barto%2C%20A.G.%20Reinforcement%20learning%3A%20An%20introduction%2C%20volume%201%201998"
        },
        {
            "id": "42",
            "entry": "[42] R. S. Sutton, D. Precup, and S. Singh. Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning. Artificial intelligence, 112(1-2):181\u2013211, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutton%2C%20R.S.%20Precup%2C%20D.%20Singh%2C%20S.%20Between%20mdps%20and%20semi-mdps%3A%20A%20framework%20for%20temporal%20abstraction%20in%20reinforcement%20learning%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutton%2C%20R.S.%20Precup%2C%20D.%20Singh%2C%20S.%20Between%20mdps%20and%20semi-mdps%3A%20A%20framework%20for%20temporal%20abstraction%20in%20reinforcement%20learning%201999"
        },
        {
            "id": "43",
            "entry": "[43] A. Tamar, Y. Wu, G. Thomas, S. Levine, and P. Abbeel. Value iteration networks. In NIPS, pages 2146\u20132154, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A%20Tamar%20Y%20Wu%20G%20Thomas%20S%20Levine%20and%20P%20Abbeel%20Value%20iteration%20networks%20In%20NIPS%20pages%2021462154%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A%20Tamar%20Y%20Wu%20G%20Thomas%20S%20Levine%20and%20P%20Abbeel%20Value%20iteration%20networks%20In%20NIPS%20pages%2021462154%202016"
        },
        {
            "id": "44",
            "entry": "[44] M. Vallati, L. Chrpa, M. Grzes, T. L. McCluskey, M. Roberts, S. Sanner, et al. The 2014 international planning competition: Progress and trends. Ai Magazine, 36(3):90\u201398, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%20Vallati%20L%20Chrpa%20M%20Grzes%20T%20L%20McCluskey%20M%20Roberts%20S%20Sanner%20et%20al%20The%202014%20international%20planning%20competition%20Progress%20and%20trends%20Ai%20Magazine%203639098%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%20Vallati%20L%20Chrpa%20M%20Grzes%20T%20L%20McCluskey%20M%20Roberts%20S%20Sanner%20et%20al%20The%202014%20international%20planning%20competition%20Progress%20and%20trends%20Ai%20Magazine%203639098%202015"
        },
        {
            "id": "45",
            "entry": "[45] W. Wang, A. Wang, A. Tamar, X. Chen, and P. Abbeel. Safer classification by synthesis. arXiv preprint arXiv:1711.08534, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.08534"
        },
        {
            "id": "46",
            "entry": "[46] M. Watter, J. Springenberg, J. Boedecker, and M. Riedmiller. Embed to control: A locally linear latent dynamics model for control from raw images. In Advances in neural information processing systems, pages 2746\u20132754, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Watter%2C%20M.%20Springenberg%2C%20J.%20Boedecker%2C%20J.%20Riedmiller%2C%20M.%20Embed%20to%20control%3A%20A%20locally%20linear%20latent%20dynamics%20model%20for%20control%20from%20raw%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Watter%2C%20M.%20Springenberg%2C%20J.%20Boedecker%2C%20J.%20Riedmiller%2C%20M.%20Embed%20to%20control%3A%20A%20locally%20linear%20latent%20dynamics%20model%20for%20control%20from%20raw%20images%202015"
        },
        {
            "id": "47",
            "entry": "[47] N. Watters, A. Tacchetti, T. Weber, R. Pascanu, P. Battaglia, and D. Zoran. Visual interaction networks. arXiv preprint arXiv:1706.01433, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.01433"
        },
        {
            "id": "48",
            "entry": "[48] J. Wu, E. Lu, P. Kohli, B. Freeman, and J. Tenenbaum. Learning to see physics via visual de-animation. In Advances in Neural Information Processing Systems, pages 152\u2013163, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20J.%20Lu%2C%20E.%20Kohli%2C%20P.%20Freeman%2C%20B.%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20J.%20Lu%2C%20E.%20Kohli%2C%20P.%20Freeman%2C%20B.%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017"
        },
        {
            "id": "49",
            "entry": "[49] J.-Y. Zhu, R. Zhang, D. Pathak, T. Darrell, A. A. Efros, O. Wang, and E. Shechtman. Toward multimodal image-to-image translation. In Advances in Neural Information Processing Systems, pages 465\u2013476, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Zhang%2C%20R.%20Pathak%2C%20D.%20Darrell%2C%20T.%20Toward%20multimodal%20image-to-image%20translation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Zhang%2C%20R.%20Pathak%2C%20D.%20Darrell%2C%20T.%20Toward%20multimodal%20image-to-image%20translation%202017"
        }
    ]
}
