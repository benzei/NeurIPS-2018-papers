{
    "filename": "7510-query-complexity-of-bayesian-private-learning.pdf",
    "metadata": {
        "title": "Query Complexity of Bayesian Private Learning",
        "author": "Kuang Xu",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7510-query-complexity-of-bayesian-private-learning.pdf"
        },
        "abstract": "We study the query complexity of Bayesian Private Learning: a learner wishes to locate a random target within an interval by submitting queries, in the presence of an adversary who observes all of her queries but not the responses. How many queries are necessary and sufficient in order for the learner to accurately estimate the target, while simultaneously concealing the target from the adversary?"
    },
    "keywords": [
        {
            "term": "query complexity",
            "url": "https://en.wikipedia.org/wiki/query_complexity"
        }
    ],
    "highlights": [
        "While ensuring that a spying adversary does not learn? Enabled by rapid advancements in the Internet, surveillance technologies and machine learning, companies and governments alike have become increasingly capable of monitoring the behavior of individuals or competitors, and use such data for inference and prediction",
        "We show that if the learner wants to estimate the target within an error of \u270f, while ensuring that no adversary estimator can achieve a constant additive error with probability greater than 1/L, the query complexity is on the order of L log(1/\u270f) as \u270f ! 0",
        "We prove a localized query complexity result: conditioning on the target being in a coarse sub-interval of [0, 1), any accurate learner still needs to submit a large number of queries within the said sub-interval",
        "The main contribution of the present paper is a tight query complexity lower bound for the Bayesian Private Learning problem, which, together with an upper bound in [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>], shows that the learner\u2019s query complexity depends multiplicatively on the level of privacy, L: if an \u270f-accurate learner wishes to ensure that an adversary\u2019s probability of making a -accurate estimation is at most 1/L, she needs to employ on the order of L log( /\u270f) queries",
        "Our query model assumes that the responses are noiseless, and it will be interesting to explore how may the presence of noise impact the design of private query strategies",
        "It appears challenging to prove that such replications preserve privacy, and still more difficult to see how one may obtain a matching query complexity lower bound in the noisy setting"
    ],
    "key_statements": [
        "While ensuring that a spying adversary does not learn? Enabled by rapid advancements in the Internet, surveillance technologies and machine learning, companies and governments alike have become increasingly capable of monitoring the behavior of individuals or competitors, and use such data for inference and prediction",
        "We show that if the learner wants to estimate the target within an error of \u270f, while ensuring that no adversary estimator can achieve a constant additive error with probability greater than 1/L, the query complexity is on the order of L log(1/\u270f) as \u270f ! 0",
        "Our main result is a tight lower bound on query complexity, showing that there will be a price to pay for the learner in exchange for improved privacy, whose magnitude scales multiplicatively with respect to the level of privacy desired",
        "We prove the query complexity lower bound in Theorem 2.1 which turns out to be significantly more challenging than showing the upper bound",
        "We prove a localized query complexity result: conditioning on the target being in a coarse sub-interval of [0, 1), any accurate learner still needs to submit a large number of queries within the said sub-interval",
        "We show that the original query complexity is always bounded from below by its discrete counterpart with some modified learner error parameters, and the final lower bound will be obtained by optimizing over these parameters",
        "The first step, accomplished in the present subsection, is to use Fano\u2019s inequality to establish a query complexity lower bound localized to a sub-interval: conditional on the target belonging to a subinterval in the -partition, any discrete-learner strategy must devote a non-trivial number of queries in that sub-interval if it wishes to be reasonably accurate.5",
        "The main contribution of the present paper is a tight query complexity lower bound for the Bayesian Private Learning problem, which, together with an upper bound in [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>], shows that the learner\u2019s query complexity depends multiplicatively on the level of privacy, L: if an \u270f-accurate learner wishes to ensure that an adversary\u2019s probability of making a -accurate estimation is at most 1/L, she needs to employ on the order of L log( /\u270f) queries",
        "Our query model assumes that the responses are noiseless, and it will be interesting to explore how may the presence of noise impact the design of private query strategies",
        "It appears challenging to prove that such replications preserve privacy, and still more difficult to see how one may obtain a matching query complexity lower bound in the noisy setting"
    ],
    "summary": [
        "While ensuring that a spying adversary does not learn? Enabled by rapid advancements in the Internet, surveillance technologies and machine learning, companies and governments alike have become increasingly capable of monitoring the behavior of individuals or competitors, and use such data for inference and prediction.",
        "We prove the upper bound, which has appeared in [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>] and [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>], where the authors proposed, without a formal proof, the Replicated Bisection learner strategy that achieves ( , L)-privacy with L log(1/\u270f) L 1) queries.",
        "We formulate a discrete version of the original problem where both the learner and adversary estimate the discrete index associated with a certain sub-interval that contains the target, instead of the continuous target value.",
        "We will show that the proportional-sampling estimator will succeed with overwhelming probability whenever an accurate learner strategy submits too few queries, obtaining the desired lower bound.",
        "We will resolve this problem by carefully bounding the learner\u2019s probability of estimation error, and apply the discrete query lower bound developed in the previous step, in which the learner is allowed to make mistakes.",
        "Discrete Bayesian Private Learning We begin by formulating a discrete version of the original problem, where the goal for both the learner and the adversary is to recover a discrete index associated with the target, as opposed to generating a continuous estimator.",
        "The only difference is that, instead of generating a continuous estimator, a discrete learner strategy produces an estimator for the index of the sub-interval containing the target in an \u270f-uniform partition, J(\u270f, X\u21e4).",
        "The first step, accomplished in the present subsection, is to use Fano\u2019s inequality to establish a query complexity lower bound localized to a sub-interval: conditional on the target belonging to a subinterval in the -partition, any discrete-learner strategy must devote a non-trivial number of queries in that sub-interval if it wishes to be reasonably accurate.5",
        "The lemma states that if the target were to lie in a given sub-interval in the -uniform partition, an accurate learner strategy would have to place at least log( /\u270f) queries within the said sub-interval on average.",
        "The main contribution of the present paper is a tight query complexity lower bound for the Bayesian Private Learning problem, which, together with an upper bound in [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>], shows that the learner\u2019s query complexity depends multiplicatively on the level of privacy, L: if an \u270f-accurate learner wishes to ensure that an adversary\u2019s probability of making a -accurate estimation is at most 1/L, she needs to employ on the order of L log( /\u270f) queries.",
        "To prove the lower bound, we develop a set of information-theoretic arguments which involve, as a main ingredient, the analysis of proportional-sampling adversary estimators that exploit the action-information proximity inherent in the learning problem.",
        "One may want to consider richer, and potentially more realistic, active learning models, such as one in which each query reveals to the learner the full gradient of a function at the queried location, instead of only the sign of the gradient as in the present model"
    ],
    "headline": "We study the query complexity of Bayesian Private Learning: a learner wishes to locate a random target within an interval by submitting queries, in the presence of an adversary who observes all of her queries but not the responses",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Michael Ben-Or and Avinatan Hassidim. The bayesian learner is optimal for noisy binary search (and pretty good for quantum as well). In Foundations of Computer Science, 2008. FOCS\u201908. IEEE 49th Annual IEEE Symposium on, pages 221\u2013230. IEEE, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Michael%20Ben-Or%20and%20Avinatan%20Hassidim.%20The%20bayesian%20learner%20is%20optimal%20for%20noisy%20binary%20search%20%28and%20pretty%20good%20for%20quantum%20as%20well%29%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Michael%20Ben-Or%20and%20Avinatan%20Hassidim.%20The%20bayesian%20learner%20is%20optimal%20for%20noisy%20binary%20search%20%28and%20pretty%20good%20for%20quantum%20as%20well%29%202008"
        },
        {
            "id": "2",
            "entry": "[2] Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12:1069\u20131109, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaudhuri%2C%20Kamalika%20Monteleoni%2C%20Claire%20Sarwate%2C%20Anand%20D.%20Differentially%20private%20empirical%20risk%20minimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaudhuri%2C%20Kamalika%20Monteleoni%2C%20Claire%20Sarwate%2C%20Anand%20D.%20Differentially%20private%20empirical%20risk%20minimization%202011"
        },
        {
            "id": "3",
            "entry": "[3] Thomas M Cover and Joy A Thomas. Elements of information theory, 2nd edition. John Wiley & Sons, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20Thomas%20M.%20Thomas%2C%20Joy%20A.%20Elements%20of%20information%20theory%202006"
        },
        {
            "id": "4",
            "entry": "[4] Rachel Cummings, Federico Echenique, and Adam Wierman. The empirical implications of privacy-aware choice. Operations Research, 64(1):67\u201378, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cummings%2C%20Rachel%20Echenique%2C%20Federico%20Wierman%2C%20Adam%20The%20empirical%20implications%20of%20privacy-aware%20choice%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cummings%2C%20Rachel%20Echenique%2C%20Federico%20Wierman%2C%20Adam%20The%20empirical%20implications%20of%20privacy-aware%20choice%202016"
        },
        {
            "id": "5",
            "entry": "[5] Cynthia Dwork. Differential privacy: A survey of results. In International Conference on Theory and Applications of Models of Computation, pages 1\u201319.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Differential%20privacy%3A%20A%20survey%20of%20results",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Differential%20privacy%3A%20A%20survey%20of%20results"
        },
        {
            "id": "6",
            "entry": "[6] Giulia Fanti, Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Spy vs. spy: Rumor source obfuscation. In ACM SIGMETRICS Performance Evaluation Review, volume 43, pages 271\u2013284. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fanti%2C%20Giulia%20Kairouz%2C%20Peter%20Oh%2C%20Sewoong%20Viswanath%2C%20Pramod%20Spy%20vs.%20spy%3A%20Rumor%20source%20obfuscation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fanti%2C%20Giulia%20Kairouz%2C%20Peter%20Oh%2C%20Sewoong%20Viswanath%2C%20Pramod%20Spy%20vs.%20spy%3A%20Rumor%20source%20obfuscation%202015"
        },
        {
            "id": "7",
            "entry": "[7] Michael Horstein. Sequential transmission using noiseless feedback. IEEE Transactions on Information Theory, 9(3):136\u2013143, 1963.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Horstein%2C%20Michael%20Sequential%20transmission%20using%20noiseless%20feedback%201963",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Horstein%2C%20Michael%20Sequential%20transmission%20using%20noiseless%20feedback%201963"
        },
        {
            "id": "8",
            "entry": "[8] Prateek Jain, Pravesh Kothari, and Abhradeep Thakurta. Differentially private online learning. In Conference on Learning Theory, pages 24\u20131, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jain%2C%20Prateek%20Kothari%2C%20Pravesh%20Thakurta%2C%20Abhradeep%20Differentially%20private%20online%20learning%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jain%2C%20Prateek%20Kothari%2C%20Pravesh%20Thakurta%2C%20Abhradeep%20Differentially%20private%20online%20learning%202012"
        },
        {
            "id": "9",
            "entry": "[9] Yehuda Lindell and Benny Pinkas. Secure multiparty computation for privacy-preserving data mining. Journal of Privacy and Confidentiality, 1(1):5, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lindell%2C%20Yehuda%20Pinkas%2C%20Benny%20Secure%20multiparty%20computation%20for%20privacy-preserving%20data%20mining%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lindell%2C%20Yehuda%20Pinkas%2C%20Benny%20Secure%20multiparty%20computation%20for%20privacy-preserving%20data%20mining%202009"
        },
        {
            "id": "10",
            "entry": "[10] Ronald L. Rivest, Albert R. Meyer, Daniel J. Kleitman, Karl Winklmann, and Joel Spencer. Coping with errors in binary search procedures. Journal of Computer and System Sciences, 20(3):396\u2013404, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rivest%2C%20Ronald%20L.%20Meyer%2C%20Albert%20R.%20Kleitman%2C%20Daniel%20J.%20Winklmann%2C%20Karl%20Coping%20with%20errors%20in%20binary%20search%20procedures%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rivest%2C%20Ronald%20L.%20Meyer%2C%20Albert%20R.%20Kleitman%2C%20Daniel%20J.%20Winklmann%2C%20Karl%20Coping%20with%20errors%20in%20binary%20search%20procedures%201980"
        },
        {
            "id": "11",
            "entry": "[11] Herbert Robbins and Sutton Monro. A stochastic approximation method. The annals of mathematical statistics, pages 400\u2013407, 1951.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robbins%2C%20Herbert%20Monro%2C%20Sutton%20A%20stochastic%20approximation%20method.%20The%20annals%20of%20mathematical%20statistics%201951"
        },
        {
            "id": "12",
            "entry": "[12] John N Tsitsiklis and Kuang Xu. Delay-predictability trade-offs in reaching a secret goal. Operations Research, 66(2):587\u2013596, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsitsiklis%2C%20John%20N.%20Xu%2C%20Kuang%20Delay-predictability%20trade-offs%20in%20reaching%20a%20secret%20goal%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsitsiklis%2C%20John%20N.%20Xu%2C%20Kuang%20Delay-predictability%20trade-offs%20in%20reaching%20a%20secret%20goal%202018"
        },
        {
            "id": "13",
            "entry": "[13] John N Tsitsiklis, Kuang Xu, and Zhi Xu. Private sequential learning. In Conference on Learning Theory (COLT), 2018. https://arxiv.org/abs/1805.02136.",
            "url": "https://arxiv.org/abs/1805.02136",
            "arxiv_url": "https://arxiv.org/pdf/1805.02136"
        },
        {
            "id": "14",
            "entry": "[14] Leslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134\u20131142, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Valiant%2C%20Leslie%20G.%20A%20theory%20of%20the%20learnable%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Valiant%2C%20Leslie%20G.%20A%20theory%20of%20the%20learnable%201984"
        },
        {
            "id": "15",
            "entry": "[15] Rolf Waeber, Peter I Frazier, and Shane G Henderson. Bisection search with noisy responses. SIAM Journal on Control and Optimization, 51(3):2261\u20132279, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Waeber%2C%20Rolf%20Frazier%2C%20Peter%20I.%20Henderson%2C%20Shane%20G.%20Bisection%20search%20with%20noisy%20responses%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Waeber%2C%20Rolf%20Frazier%2C%20Peter%20I.%20Henderson%2C%20Shane%20G.%20Bisection%20search%20with%20noisy%20responses%202013"
        },
        {
            "id": "16",
            "entry": "[16] Martin J Wainwright, Michael I Jordan, and John C Duchi. Privacy aware learning. In Advances in Neural Information Processing Systems, pages 1430\u20131438, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wainwright%2C%20Martin%20J.%20Jordan%2C%20Michael%20I.%20Duchi%2C%20John%20C.%20Privacy%20aware%20learning%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wainwright%2C%20Martin%20J.%20Jordan%2C%20Michael%20I.%20Duchi%2C%20John%20C.%20Privacy%20aware%20learning%202012"
        },
        {
            "id": "17",
            "entry": "[17] Zhi Xu. Private sequential search and optimization. Master\u2019s thesis, Massachusetts Institute of Technology, 2017. https://dspace.mit.edu/handle/1721.1/112054. ",
            "url": "https://dspace.mit.edu/handle/1721.1/112054"
        }
    ]
}
