{
    "filename": "7545-unsupervised-learning-of-shape-and-pose-with-differentiable-point-clouds.pdf",
    "metadata": {
        "title": "Unsupervised Learning of Shape and Pose with Differentiable Point Clouds",
        "author": "Eldar Insafutdinov\u2217 Max Planck Institute for Informatics eldar@mpi-inf.mpg.de",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7545-unsupervised-learning-of-shape-and-pose-with-differentiable-point-clouds.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We address the problem of learning accurate 3D shape and camera pose from a collection of unlabeled category-specific images. We train a convolutional network to predict both the shape and the pose from a single image by minimizing the reprojection error: given several views of an object, the projections of the predicted shapes to the predicted camera poses should match the provided views. To deal with pose ambiguity, we introduce an ensemble of pose predictors which we then distill to a single \u201cstudent\u201d model. To allow for efficient learning of high-fidelity shapes, we represent the shapes by point clouds and devise a formulation allowing for differentiable projection of these. Our experiments show that the distilled ensemble of pose predictors learns to estimate the pose accurately, while the point cloud representation allows to predict detailed shape models."
    },
    "keywords": [
        {
            "term": "Iterative Closest Point",
            "url": "https://en.wikipedia.org/wiki/Iterative_Closest_Point"
        },
        {
            "term": "3d model",
            "url": "https://en.wikipedia.org/wiki/3d_model"
        },
        {
            "term": "unsupervised learning",
            "url": "https://en.wikipedia.org/wiki/unsupervised_learning"
        }
    ],
    "highlights": [
        "We live in a three-dimensional world, and a proper understanding of its volumetric structure is crucial for acting and planning",
        "We evaluate the proposed approach on the task of estimating the shape and the camera pose from a single image of an object 2",
        "We address the task of predicting the three-dimensional shape of an object and the camera pose from a single view of the object",
        "Before starting the pose and shape evaluation, we align the canonical pose learned by the network with the canonical pose in the dataset, using Iterative Closest Point (ICP) algorithm on the first 20 models in the validation set",
        "We compare to the concurrent Multi-View Consistency (MVC) approach of Tulsiani et al [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], using results reported by the authors for pose estimation and pre-trained models provided by the authors for shape evaluations",
        "We have proposed a method for learning pose and shape of 3D objects given only their 2D projections, using the point cloud representation"
    ],
    "key_statements": [
        "We live in a three-dimensional world, and a proper understanding of its volumetric structure is crucial for acting and planning",
        "We evaluate the proposed approach on the task of estimating the shape and the camera pose from a single image of an object 2",
        "We address the task of predicting the three-dimensional shape of an object and the camera pose from a single view of the object",
        "Before starting the pose and shape evaluation, we align the canonical pose learned by the network with the canonical pose in the dataset, using Iterative Closest Point (ICP) algorithm on the first 20 models in the validation set",
        "We compare to the concurrent Multi-View Consistency (MVC) approach of Tulsiani et al [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], using results reported by the authors for pose estimation and pre-trained models provided by the authors for shape evaluations",
        "We have proposed a method for learning pose and shape of 3D objects given only their 2D projections, using the point cloud representation"
    ],
    "summary": [
        "We live in a three-dimensional world, and a proper understanding of its volumetric structure is crucial for acting and planning.",
        "Given a set of views of an object and the corresponding camera poses, these methods learn 3D shape via the reprojection error: given an estimated shape, one can project it to the known camera views and compare to the provided images.",
        "We learn high-fidelity shape models solely from their projections, without ground truth camera poses.",
        "To allow learning of high-fidelity shapes, we use the point cloud representation, in contrast with voxels used in previous works.",
        "To enable learning point clouds without explicit 3D supervision, we implement a differentiable projection operator that, given a point set and a camera pose, generates a 2D projection \u2013 a silhouette, a color image, or a depth map.",
        "The method successfully learns to predict both the shape and the pose, with only a minor performance drop relative to a model trained with ground truth camera poses.",
        "The point-cloud-based formulation allows for effective learning of high-fidelity shape models when provided with images of sufficiently high resolution as supervision.",
        "All these methods require exact ground truth camera pose corresponding to the 2D projections used for training.",
        "This training procedure requires that for all pairs of views of the same object, the renderings of the predicted point cloud match the provided ground truth views.",
        "Before starting the pose and shape evaluation, we align the canonical pose learned by the network with the canonical pose in the dataset, using Iterative Closest Point (ICP) algorithm on the first 20 models in the validation set.",
        "We start by benchmarking the proposed formulation against existing methods in the simple setup with known ground truth camera poses and silhouette-based training.",
        "We compare to Perspective Transformer Networks (PTN) of Yan et al [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>], Differentiable Ray Consistency (DRC) of Tulsiani et al [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], Efficient Point Cloud Generation (EPCG) of Lin et al [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>], and to the voxel-based counterpart of our method.",
        "We compare to the concurrent Multi-View Consistency (MVC) approach of Tulsiani et al [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], using results reported by the authors for pose estimation and pre-trained models provided by the authors for shape evaluations.",
        "We have proposed a method for learning pose and shape of 3D objects given only their 2D projections, using the point cloud representation.",
        "Since the method does not require accurate ground truth camera poses, it could be applied to learning from real-world data.",
        "The fact that the loss is explicitly computed on projections, allows directly applying advanced techniques from the 2D domain, such as perceptual losses and GANs, to learning 3D representations"
    ],
    "headline": "We address the problem of learning accurate 3D shape and camera pose from a collection of unlabeled category-specific images",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, et al. TensorFlow: A system for large-scale machine learning. In OSDI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20TensorFlow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20TensorFlow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016"
        },
        {
            "id": "2",
            "entry": "[2] T. J. Cashman and A. W. Fitzgibbon. What shape are dolphins? Building 3D morphable models from 2D images. PAMI, 35, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cashman%2C%20T.J.%20Fitzgibbon%2C%20A.W.%20What%20shape%20are%20dolphins%3F%20Building%203D%20morphable%20models%20from%202D%20images%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cashman%2C%20T.J.%20Fitzgibbon%2C%20A.W.%20What%20shape%20are%20dolphins%3F%20Building%203D%20morphable%20models%20from%202D%20images%202013"
        },
        {
            "id": "3",
            "entry": "[3] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, and F. Yu. ShapeNet: An information-rich 3D model repository. Technical Report arXiv:1512.03012, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.03012"
        },
        {
            "id": "4",
            "entry": "[4] Q. Chen and V. Koltun. Photographic image synthesis with cascaded refinement networks. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Q.%20Koltun%2C%20V.%20Photographic%20image%20synthesis%20with%20cascaded%20refinement%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Q.%20Koltun%2C%20V.%20Photographic%20image%20synthesis%20with%20cascaded%20refinement%20networks%202017"
        },
        {
            "id": "5",
            "entry": "[5] C. B. Choy, D. Xu, J. Gwak, K. Chen, and S. Savarese. 3D-R2N2: A unified approach for single and multi-view 3D object reconstruction. In ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choy%2C%20C.B.%20Xu%2C%20D.%20Gwak%2C%20J.%20Chen%2C%20K.%20Savarese.%203D-R2N2%3A%20A%20unified%20approach%20for%20single%20and%20multi-view%203D%20object%20reconstruction%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choy%2C%20C.B.%20Xu%2C%20D.%20Gwak%2C%20J.%20Chen%2C%20K.%20Savarese.%203D-R2N2%3A%20A%20unified%20approach%20for%20single%20and%20multi-view%203D%20object%20reconstruction%202016"
        },
        {
            "id": "6",
            "entry": "[6] H. Fan, H. Su, and L. J. Guibas. A point set generation network for 3D object reconstruction from a single image. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fan%2C%20H.%20Su%2C%20H.%20Guibas%2C%20L.J.%20A%20point%20set%20generation%20network%20for%203D%20object%20reconstruction%20from%20a%20single%20image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fan%2C%20H.%20Su%2C%20H.%20Guibas%2C%20L.J.%20A%20point%20set%20generation%20network%20for%203D%20object%20reconstruction%20from%20a%20single%20image%202017"
        },
        {
            "id": "7",
            "entry": "[7] A. Guzm\u00e1n-rivera, D. Batra, and P. Kohli. Multiple choice learning: Learning to produce multiple structured outputs. In NIPS. 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guzm%C3%A1n-rivera%2C%20A.%20Batra%2C%20D.%20Kohli%2C%20P.%20Multiple%20choice%20learning%3A%20Learning%20to%20produce%20multiple%20structured%20outputs.%20In%20NIPS%202012"
        },
        {
            "id": "8",
            "entry": "[8] H. Kato, Y. Ushiku, and T. Harada. Neural 3D mesh renderer. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%20Kato%20Y%20Ushiku%20and%20T%20Harada%20Neural%203D%20mesh%20renderer%20In%20CVPR%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=H%20Kato%20Y%20Ushiku%20and%20T%20Harada%20Neural%203D%20mesh%20renderer%20In%20CVPR%202018"
        },
        {
            "id": "9",
            "entry": "[9] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20D.P.%20Ba%2C%20J.%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "10",
            "entry": "[10] J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. GRASS: Generative recursive autoencoders for shape structures. SIGGRAPH, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20J.%20Xu%2C%20K.%20Chaudhuri%2C%20S.%20Yumer%2C%20E.%20GRASS%3A%20Generative%20recursive%20autoencoders%20for%20shape%20structures%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20J.%20Xu%2C%20K.%20Chaudhuri%2C%20S.%20Yumer%2C%20E.%20GRASS%3A%20Generative%20recursive%20autoencoders%20for%20shape%20structures%202017"
        },
        {
            "id": "11",
            "entry": "[11] C.-H. Lin, C. Kong, and S. Lucey. Learning efficient point cloud generation for dense 3D object reconstruction. In AAAI, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20C.-H.%20Kong%2C%20C.%20Lucey%2C%20S.%20Learning%20efficient%20point%20cloud%20generation%20for%20dense%203D%20object%20reconstruction%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20C.-H.%20Kong%2C%20C.%20Lucey%2C%20S.%20Learning%20efficient%20point%20cloud%20generation%20for%20dense%203D%20object%20reconstruction%202018"
        },
        {
            "id": "12",
            "entry": "[12] M. M. Loper and M. J. Black. OpenDR: An approximate differentiable renderer. In ECCV, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loper%2C%20M.M.%20Black%2C%20M.J.%20OpenDR%3A%20An%20approximate%20differentiable%20renderer%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Loper%2C%20M.M.%20Black%2C%20M.J.%20OpenDR%3A%20An%20approximate%20differentiable%20renderer%202014"
        },
        {
            "id": "13",
            "entry": "[13] D. Rezende, S. M. A. Eslami, S. Mohamed, P. Battaglia, M. Jaderberg, and N. Heess. Unsupervised learning of 3D structure from images. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rezende%2C%20D.%20Eslami%2C%20S.M.A.%20Mohamed%2C%20S.%20Battaglia%2C%20P.%20Unsupervised%20learning%20of%203D%20structure%20from%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rezende%2C%20D.%20Eslami%2C%20S.M.A.%20Mohamed%2C%20S.%20Battaglia%2C%20P.%20Unsupervised%20learning%20of%203D%20structure%20from%20images%202016"
        },
        {
            "id": "14",
            "entry": "[14] H. Rhodin, N. Robertini, C. Richardt, H.-P. Seidel, and C. Theobalt. A versatile scene model with differentiable visibility applied to generative pose estimation. In ICCV, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rhodin%2C%20H.%20Robertini%2C%20N.%20Richardt%2C%20C.%20Seidel%2C%20H.-P.%20Theobalt.%20A%20versatile%20scene%20model%20with%20differentiable%20visibility%20applied%20to%20generative%20pose%20estimation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rhodin%2C%20H.%20Robertini%2C%20N.%20Richardt%2C%20C.%20Seidel%2C%20H.-P.%20Theobalt.%20A%20versatile%20scene%20model%20with%20differentiable%20visibility%20applied%20to%20generative%20pose%20estimation%202015"
        },
        {
            "id": "15",
            "entry": "[15] A. A. Soltani, H. Huang, J. Wu, T. D. Kulkarni, and J. B. Tenenbaum. Synthesizing 3D shapes via modeling multi-view depth maps and silhouettes with deep generative networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Soltani%2C%20A.A.%20Huang%2C%20H.%20Wu%2C%20J.%20Kulkarni%2C%20T.D.%20Synthesizing%203D%20shapes%20via%20modeling%20multi-view%20depth%20maps%20and%20silhouettes%20with%20deep%20generative%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Soltani%2C%20A.A.%20Huang%2C%20H.%20Wu%2C%20J.%20Kulkarni%2C%20T.D.%20Synthesizing%203D%20shapes%20via%20modeling%20multi-view%20depth%20maps%20and%20silhouettes%20with%20deep%20generative%20networks%202017"
        },
        {
            "id": "16",
            "entry": "[16] X. Sun, J. Wu, X. Zhang, Z. Zhang, C. Zhang, T. Xue, J. B. Tenenbaum, and W. T. Freeman. Pix3d: Dataset and methods for single-image 3D shape modeling. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20X.%20Wu%2C%20J.%20Zhang%2C%20X.%20Zhang%2C%20Z.%20Pix3d%3A%20Dataset%20and%20methods%20for%20single-image%203D%20shape%20modeling%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20X.%20Wu%2C%20J.%20Zhang%2C%20X.%20Zhang%2C%20Z.%20Pix3d%3A%20Dataset%20and%20methods%20for%20single-image%203D%20shape%20modeling%202018"
        },
        {
            "id": "17",
            "entry": "[17] M. Tatarchenko, A. Dosovitskiy, and T. Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3D outputs. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tatarchenko%2C%20M.%20Dosovitskiy%2C%20A.%20Brox%2C%20T.%20Octree%20generating%20networks%3A%20Efficient%20convolutional%20architectures%20for%20high-resolution%203D%20outputs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tatarchenko%2C%20M.%20Dosovitskiy%2C%20A.%20Brox%2C%20T.%20Octree%20generating%20networks%3A%20Efficient%20convolutional%20architectures%20for%20high-resolution%203D%20outputs%202017"
        },
        {
            "id": "18",
            "entry": "[18] S. Tulsiani, A. Kar, J. Carreira, and J. Malik. Learning category-specific deformable 3D models for object reconstruction. PAMI, 39, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20S.%20Kar%2C%20A.%20Carreira%2C%20J.%20Malik%2C%20J.%20Learning%20category-specific%20deformable%203D%20models%20for%20object%20reconstruction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20S.%20Kar%2C%20A.%20Carreira%2C%20J.%20Malik%2C%20J.%20Learning%20category-specific%20deformable%203D%20models%20for%20object%20reconstruction%202017"
        },
        {
            "id": "19",
            "entry": "[19] S. Tulsiani, H. Su, L. J. Guibas, A. A. Efros, and J. Malik. Learning shape abstractions by assembling volumetric primitives. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20S.%20Su%2C%20H.%20Guibas%2C%20L.J.%20Efros%2C%20A.A.%20Learning%20shape%20abstractions%20by%20assembling%20volumetric%20primitives%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20S.%20Su%2C%20H.%20Guibas%2C%20L.J.%20Efros%2C%20A.A.%20Learning%20shape%20abstractions%20by%20assembling%20volumetric%20primitives%202017"
        },
        {
            "id": "20",
            "entry": "[20] S. Tulsiani, T. Zhou, A. A. Efros, and J. Malik. Multi-view supervision for single-view reconstruction via differentiable ray consistency. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20S.%20Zhou%2C%20T.%20Efros%2C%20A.A.%20Malik%2C%20J.%20Multi-view%20supervision%20for%20single-view%20reconstruction%20via%20differentiable%20ray%20consistency%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20S.%20Zhou%2C%20T.%20Efros%2C%20A.A.%20Malik%2C%20J.%20Multi-view%20supervision%20for%20single-view%20reconstruction%20via%20differentiable%20ray%20consistency%202017"
        },
        {
            "id": "21",
            "entry": "[21] S. Tulsiani, A. A. Efros, and J. Malik. Multi-view consistency as supervisory signal for learning shape and pose prediction. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20S.%20Efros%2C%20A.A.%20Malik%2C%20J.%20Multi-view%20consistency%20as%20supervisory%20signal%20for%20learning%20shape%20and%20pose%20prediction%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20S.%20Efros%2C%20A.A.%20Malik%2C%20J.%20Multi-view%20consistency%20as%20supervisory%20signal%20for%20learning%20shape%20and%20pose%20prediction%202018"
        },
        {
            "id": "22",
            "entry": "[22] S. Vicente, J. Carreira, L. Agapito, and J. Batista. Reconstructing PASCAL VOC. In CVPR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=S%20Vicente%20J%20Carreira%20L%20Agapito%20and%20J%20Batista%20Reconstructing%20PASCAL%20VOC%20In%20CVPR%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=S%20Vicente%20J%20Carreira%20L%20Agapito%20and%20J%20Batista%20Reconstructing%20PASCAL%20VOC%20In%20CVPR%202014"
        },
        {
            "id": "23",
            "entry": "[23] J. Wu, C. Zhang, T. Xue, W. T. Freeman, and J. B. Tenenbaum. Learning a probabilistic latent space of object shapes via 3D generative-adversarial modeling. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20J.%20Zhang%2C%20C.%20Xue%2C%20T.%20Freeman%2C%20W.T.%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203D%20generative-adversarial%20modeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20J.%20Zhang%2C%20C.%20Xue%2C%20T.%20Freeman%2C%20W.T.%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203D%20generative-adversarial%20modeling%202016"
        },
        {
            "id": "24",
            "entry": "[24] J. Wu, T. Xue, J. J. Lim, Y. Tian, J. B. Tenenbaum, A. Torralba, and W. T. Freeman. 3D interpreter networks for viewer-centered wireframe modeling. IJCV, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20J.%20Xue%2C%20T.%20Lim%2C%20J.J.%20Tian%2C%20Y.%203D%20interpreter%20networks%20for%20viewer-centered%20wireframe%20modeling%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20J.%20Xue%2C%20T.%20Lim%2C%20J.J.%20Tian%2C%20Y.%203D%20interpreter%20networks%20for%20viewer-centered%20wireframe%20modeling%202018"
        },
        {
            "id": "25",
            "entry": "[25] X. Yan, J. Yang, E. Yumer, Y. Guo, and H. Lee. Perspective transformer nets: Learning single-view 3D object reconstruction without 3D supervision. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yan%2C%20X.%20Yang%2C%20J.%20Yumer%2C%20E.%20Guo%2C%20Y.%20Perspective%20transformer%20nets%3A%20Learning%20single-view%203D%20object%20reconstruction%20without%203D%20supervision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yan%2C%20X.%20Yang%2C%20J.%20Yumer%2C%20E.%20Guo%2C%20Y.%20Perspective%20transformer%20nets%3A%20Learning%20single-view%203D%20object%20reconstruction%20without%203D%20supervision%202016"
        },
        {
            "id": "26",
            "entry": "[26] Y. Yang, C. Feng, Y. Shen, and D. Tian. FoldingNet: Interpretable unsupervised learning on 3D point clouds. In CVPR, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Y.%20Feng%2C%20C.%20Shen%2C%20Y.%20Tian%2C%20D.%20FoldingNet%3A%20Interpretable%20unsupervised%20learning%20on%203D%20point%20clouds%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Y.%20Feng%2C%20C.%20Shen%2C%20Y.%20Tian%2C%20D.%20FoldingNet%3A%20Interpretable%20unsupervised%20learning%20on%203D%20point%20clouds%202018"
        }
    ]
}
