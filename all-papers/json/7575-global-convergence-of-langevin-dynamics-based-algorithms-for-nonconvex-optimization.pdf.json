{
    "filename": "7575-global-convergence-of-langevin-dynamics-based-algorithms-for-nonconvex-optimization.pdf",
    "metadata": {
        "title": "Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization",
        "author": "Pan Xu, Jinghui Chen, Difan Zou, Quanquan Gu",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7575-global-convergence-of-langevin-dynamics-based-algorithms-for-nonconvex-optimization.pdf"
        },
        "abstract": "We present a unified framework to analyze the global convergence of Langevin dynamics based algorithms for nonconvex finite-sum optimization with n component functions. At the core of our analysis is a direct analysis of the ergodicity of the numerical approximations to Langevin dynamics, which leads to faster convergence rates. Specifically, we show that gradient Langevin dynamics (GLD)"
    },
    "keywords": [
        {
            "term": "global convergence",
            "url": "https://en.wikipedia.org/wiki/global_convergence"
        },
        {
            "term": "saddle point",
            "url": "https://en.wikipedia.org/wiki/saddle_point"
        },
        {
            "term": "monte carlo",
            "url": "https://en.wikipedia.org/wiki/monte_carlo"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "stochastic differential equation",
            "url": "https://en.wikipedia.org/wiki/stochastic_differential_equation"
        },
        {
            "term": "variance reduction",
            "url": "https://en.wikipedia.org/wiki/variance_reduction"
        },
        {
            "term": "SVRG",
            "url": "https://en.wikipedia.org/wiki/SVRG"
        },
        {
            "term": "Stochastic Gradient Langevin Dynamics",
            "url": "https://en.wikipedia.org/wiki/Stochastic_Gradient_Langevin_Dynamics"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        }
    ],
    "highlights": [
        "We consider the following nonconvex finite-sum optimization problem minx Fn(x) := 1/n n i=1 fi(x), (1.1)<br/><br/>where fi(x)\u2019s are called component functions, and both Fn(x) and fi(\u00b7)\u2019s can be nonconvex",
        "For the first time we prove the global convergence (VR-Stochastic Gradient Langevin Dynamics)",
        "In the optimization error of gradient Langevin dynamics (3.1), we denote the upper bound of the error term E[Fn(X\u21e1)] Fn(x\u21e4) by RM , which characterizes the distance between the expected function value at X\u21e1 and the global minimum of Fn",
        "Dubey et al [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] first proposed the VR-Stochastic Gradient Langevin Dynamics algorithm for posterior sampling, but only proved that the mean square error between averaged sample pass and the stationary distribution converges to \u270f within Oe(1/\u270f3/2) iterations, which has no implication for nonconvex optimization",
        "We present a new framework for analyzing the convergence of Langevin dynamics based algorithms, and provide non-asymptotic analysis on the convergence for nonconvex finitesum optimization",
        "It has been proved that stochastic variance-reduced gradient outperforms gradient descent universally for nonconvex finite-sum optimization [<a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]. This poses a natural question that whether VR-Stochastic Gradient Langevin Dynamics can be universally better than gradient Langevin dynamics for nonconvex optimization? We will attempt to answer this question in the future"
    ],
    "key_statements": [
        "We consider the following nonconvex finite-sum optimization problem minx Fn(x) := 1/n n i=1 fi(x), (1.1)<br/><br/>where fi(x)\u2019s are called component functions, and both Fn(x) and fi(\u00b7)\u2019s can be nonconvex",
        "For the first time we prove the global convergence (VR-Stochastic Gradient Langevin Dynamics)",
        "In the optimization error of gradient Langevin dynamics (3.1), we denote the upper bound of the error term E[Fn(X\u21e1)] Fn(x\u21e4) by RM , which characterizes the distance between the expected function value at X\u21e1 and the global minimum of Fn",
        "Dubey et al [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] first proposed the VR-Stochastic Gradient Langevin Dynamics algorithm for posterior sampling, but only proved that the mean square error between averaged sample pass and the stationary distribution converges to \u270f within Oe(1/\u270f3/2) iterations, which has no implication for nonconvex optimization",
        "Following existing literature [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>, <a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>, <a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], here we assume the existence of stationary distributions, 5For Stochastic Gradient Langevin Dynamics in [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>], the result in the table is obtained by choosing the exact batch size suggested by the authors that could make the stochastic variance small enough to cancel out the divergent term in their paper",
        "Consider the optimization error of Stochastic Gradient Langevin Dynamics (Algorithm 2), we only need to bound the error between E[Fn(YK )] and E[Fn(XK )] and apply the results for gradient Langevin dynamics, which is given by the following lemma",
        "We present a new framework for analyzing the convergence of Langevin dynamics based algorithms, and provide non-asymptotic analysis on the convergence for nonconvex finitesum optimization",
        "It has been proved that stochastic variance-reduced gradient outperforms gradient descent universally for nonconvex finite-sum optimization [<a class=\"ref-link\" id=\"c45\" href=\"#r45\">45</a>, <a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]. This poses a natural question that whether VR-Stochastic Gradient Langevin Dynamics can be universally better than gradient Langevin dynamics for nonconvex optimization? We will attempt to answer this question in the future"
    ],
    "summary": [
        "We consider the following nonconvex finite-sum optimization problem minx Fn(x) := 1/n n i=1 fi(x), (1.1)<br/><br/>where fi(x)\u2019s are called component functions, and both Fn(x) and fi(\u00b7)\u2019s can be nonconvex.",
        "They proved that SGLD converges to an almost minimizer up to d2/( 1/4 \u21e4) log(1/\u270f) within Oe(d/( \u21e4\u270f4)) iterations, where 2 is the variance of stochastic gradient and \u21e4 is called the uniform spectral gap of Langevin diffusion (1.2), and it is in the order of e Oe(d).",
        "In the optimization error of GLD (3.1), we denote the upper bound of the error term E[Fn(X\u21e1)] Fn(x\u21e4) by RM , which characterizes the distance between the expected function value at X\u21e1 and the global minimum of Fn. The stationary distribution of Langevin diffusion \u21e1 / e Fn(x) is a Gibbs distribution, which concentrates around the minimizer x\u21e4 of Fn. a random vector X\u21e1 following the law of \u21e1 is called an almost minimizer of Fn within a neighborhood of x\u21e4 with radius RM [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>].",
        "In Theorem 3.11 and Corollary 3.12, we establish the global convergence guarantee for VR-SGLD to an almost minimizer of a nonconvex function Fn. To the best of our knowledge, this is the first iteration/gradient complexity guarantee for VR-SGLD in nonconvex finite-sum optimization.",
        "Dubey et al [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] first proposed the VR-SGLD algorithm for posterior sampling, but only proved that the mean square error between averaged sample pass and the stationary distribution converges to \u270f within Oe(1/\u270f3/2) iterations, which has no implication for nonconvex optimization.",
        "Following existing literature [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>, <a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>, <a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], here we assume the existence of stationary distributions, 5For SGLD in [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>], the result in the table is obtained by choosing the exact batch size suggested by the authors that could make the stochastic variance small enough to cancel out the divergent term in their paper.",
        "To bound the first term in (4.1), we need to analyze the convergence of the Markov chain generated by Algorithm 1 to its stationary distribution, namely, the ergodic property of the numerical approximation of Langevin dynamics.",
        "Consider the optimization error of SGLD (Algorithm 2), we only need to bound the error between E[Fn(YK )] and E[Fn(XK )] and apply the results for GLD, which is given by the following lemma.",
        "We present a new framework for analyzing the convergence of Langevin dynamics based algorithms, and provide non-asymptotic analysis on the convergence for nonconvex finitesum optimization.",
        "By comparing the Langevin dynamics based algorithms and standard first-order optimization algorithms, we may see that the counterparts of GLD and VR-SGLD are gradient descent (GD) and stochastic variance-reduced gradient (SVRG) methods.",
        "This poses a natural question that whether VR-SGLD can be universally better than GLD for nonconvex optimization? We will attempt to answer this question in the future"
    ],
    "headline": "We present a unified framework to analyze the global convergence of Langevin dynamics based algorithms for nonconvex finite-sum optimization with n component functions",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma. Finding approximate local minima for nonconvex optimization in linear time. arXiv preprint arXiv:1611.01146, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01146"
        },
        {
            "id": "2",
            "entry": "[2] Sungjin Ahn, Anoop Korattikara, and Max Welling. Bayesian posterior sampling via stochastic gradient fisher scoring. In Proceedings of the 29th International Coference on International Conference on Machine Learning, pages 1771\u20131778, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahn%2C%20Sungjin%20Korattikara%2C%20Anoop%20Welling%2C%20Max%20Bayesian%20posterior%20sampling%20via%20stochastic%20gradient%20fisher%20scoring%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahn%2C%20Sungjin%20Korattikara%2C%20Anoop%20Welling%2C%20Max%20Bayesian%20posterior%20sampling%20via%20stochastic%20gradient%20fisher%20scoring%202012"
        },
        {
            "id": "3",
            "entry": "[3] Zeyuan Allen-Zhu and Elad Hazan. Variance reduction for faster non-convex optimization. arXiv preprint arXiv:1603.05643, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.05643"
        },
        {
            "id": "4",
            "entry": "[4] Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and geometry of Markov diffusion operators, volume 348. Springer Science & Business Media, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bakry%2C%20Dominique%20Gentil%2C%20Ivan%20Ledoux%2C%20Michel%20Analysis%20and%20geometry%20of%20Markov%20diffusion%20operators%2C%20volume%20348%202013"
        },
        {
            "id": "5",
            "entry": "[5] Francois Bolley and Cedric Villani. Weighted csisz\u00e1r-kullback-pinsker inequalities and applications to transportation inequalities. Annales de la Facult\u00e9 des Sciences de Toulouse. S\u00e9rie VI. Math\u00e9matiques, 14, 01 2005. doi: 10.5802/afst.1095.",
            "crossref": "https://dx.doi.org/10.5802/afst.1095",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.5802/afst.1095"
        },
        {
            "id": "6",
            "entry": "[6] Anton Bovier, Michael Eckhoff, V\u00e9ronique Gayrard, and Markus Klein. Metastability in reversible diffusion processes i: Sharp asymptotics for capacities and exit times. Journal of the European Mathematical Society, 6(4):399\u2013424, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bovier%2C%20Anton%20Eckhoff%2C%20Michael%20Gayrard%2C%20V%C3%A9ronique%20Klein%2C%20Markus%20Metastability%20in%20reversible%20diffusion%20processes%20i%3A%20Sharp%20asymptotics%20for%20capacities%20and%20exit%20times%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bovier%2C%20Anton%20Eckhoff%2C%20Michael%20Gayrard%2C%20V%C3%A9ronique%20Klein%2C%20Markus%20Metastability%20in%20reversible%20diffusion%20processes%20i%3A%20Sharp%20asymptotics%20for%20capacities%20and%20exit%20times%202004"
        },
        {
            "id": "7",
            "entry": "[7] Nicolas Brosse, Alain Durmus, \u00c9ric Moulines, and Marcelo Pereyra. Sampling from a log-concave distribution with compact support with proximal langevin monte carlo. arXiv preprint arXiv:1705.08964, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.08964"
        },
        {
            "id": "8",
            "entry": "[8] S\u00e9bastien Bubeck, Ronen Eldan, and Joseph Lehec. Sampling from a log-concave distribution with projected langevin monte carlo. arXiv preprint arXiv:1507.02564, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.02564"
        },
        {
            "id": "9",
            "entry": "[9] Yair Carmon and John C Duchi. Gradient descent efficiently finds the cubic-regularized non-convex newton step. arXiv preprint arXiv:1612.00547, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.00547"
        },
        {
            "id": "10",
            "entry": "[10] Yair Carmon, John C Duchi, Oliver Hinder, and Aaron Sidford. Accelerated methods for non-convex optimization. arXiv preprint arXiv:1611.00756, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.00756"
        },
        {
            "id": "11",
            "entry": "[11] Niladri S Chatterji, Nicolas Flammarion, Yi-An Ma, Peter L Bartlett, and Michael I Jordan. On the theory of variance reduction for stochastic gradient monte carlo. arXiv preprint arXiv:1802.05431, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05431"
        },
        {
            "id": "12",
            "entry": "[12] Changyou Chen, Nan Ding, and Lawrence Carin. On the convergence of stochastic gradient mcmc algorithms with high-order integrators. In Advances in Neural Information Processing Systems, pages 2278\u20132286, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Changyou%20Ding%2C%20Nan%20Carin%2C%20Lawrence%20On%20the%20convergence%20of%20stochastic%20gradient%20mcmc%20algorithms%20with%20high-order%20integrators%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Changyou%20Ding%2C%20Nan%20Carin%2C%20Lawrence%20On%20the%20convergence%20of%20stochastic%20gradient%20mcmc%20algorithms%20with%20high-order%20integrators%202015"
        },
        {
            "id": "13",
            "entry": "[13] Xiang Cheng, Niladri S. Chatterji, Peter L. Bartlett, and Michael I. Jordan. Underdamped langevin mcmc: A non-asymptotic analysis. In Proceedings of the 31st Conference On Learning Theory, volume 75, pages 300\u2013323, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cheng%2C%20Xiang%20Chatterji%2C%20Niladri%20S.%20Bartlett%2C%20Peter%20L.%20Jordan%2C%20Michael%20I.%20Underdamped%20langevin%20mcmc%3A%20A%20non-asymptotic%20analysis%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cheng%2C%20Xiang%20Chatterji%2C%20Niladri%20S.%20Bartlett%2C%20Peter%20L.%20Jordan%2C%20Michael%20I.%20Underdamped%20langevin%20mcmc%3A%20A%20non-asymptotic%20analysis%202018"
        },
        {
            "id": "14",
            "entry": "[14] Tzuu-Shuh Chiang, Chii-Ruey Hwang, and Shuenn Jyi Sheu. Diffusion for global optimization in rn. SIAM Journal on Control and Optimization, 25(3):737\u2013753, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chiang%2C%20Tzuu-Shuh%20Hwang%2C%20Chii-Ruey%20Sheu%2C%20Shuenn%20Jyi%20Diffusion%20for%20global%20optimization%20in%20rn%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chiang%2C%20Tzuu-Shuh%20Hwang%2C%20Chii-Ruey%20Sheu%2C%20Shuenn%20Jyi%20Diffusion%20for%20global%20optimization%20in%20rn%201987"
        },
        {
            "id": "15",
            "entry": "[15] Frank E Curtis, Daniel P Robinson, and Mohammadreza Samadi. A trust region algorithm with a worst-case iteration complexity of O(\u270f 3/2) for nonconvex optimization. Mathematical Programming, pages 1\u201332, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Curtis%2C%20Frank%20E.%20Robinson%2C%20Daniel%20P.%20Samadi%2C%20Mohammadreza%20A%20trust%20region%20algorithm%20with%20a%20worst-case%20iteration%20complexity%20of%20O%28%E2%9C%8F%203/2%29%20for%20nonconvex%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Curtis%2C%20Frank%20E.%20Robinson%2C%20Daniel%20P.%20Samadi%2C%20Mohammadreza%20A%20trust%20region%20algorithm%20with%20a%20worst-case%20iteration%20complexity%20of%20O%28%E2%9C%8F%203/2%29%20for%20nonconvex%20optimization%202014"
        },
        {
            "id": "16",
            "entry": "[16] Arnak S Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave densities. arXiv preprint arXiv:1412.7392, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.7392"
        },
        {
            "id": "17",
            "entry": "[17] Arnak S Dalalyan. Further and stronger analogy between sampling and optimization: Langevin monte carlo and gradient descent. arXiv preprint arXiv:1704.04752, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04752"
        },
        {
            "id": "18",
            "entry": "[18] Arnak S Dalalyan and Avetik G Karagulyan. User-friendly guarantees for the langevin monte carlo with inaccurate gradient. arXiv preprint arXiv:1710.00095, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.00095"
        },
        {
            "id": "19",
            "entry": "[19] Kumar Avinava Dubey, Sashank J Reddi, Sinead A Williamson, Barnabas Poczos, Alexander J Smola, and Eric P Xing. Variance reduction in stochastic gradient langevin dynamics. In Advances in Neural Information Processing Systems, pages 1154\u20131162, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dubey%2C%20Kumar%20Avinava%20Reddi%2C%20Sashank%20J.%20Williamson%2C%20Sinead%20A.%20Poczos%2C%20Barnabas%20and%20Eric%20P%20Xing.%20Variance%20reduction%20in%20stochastic%20gradient%20langevin%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dubey%2C%20Kumar%20Avinava%20Reddi%2C%20Sashank%20J.%20Williamson%2C%20Sinead%20A.%20Poczos%2C%20Barnabas%20and%20Eric%20P%20Xing.%20Variance%20reduction%20in%20stochastic%20gradient%20langevin%20dynamics%202016"
        },
        {
            "id": "20",
            "entry": "[20] Alain Durmus and Eric Moulines. Non-asymptotic convergence analysis for the unadjusted langevin algorithm. arXiv preprint arXiv:1507.05021, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.05021"
        },
        {
            "id": "21",
            "entry": "[21] Alain Durmus and Eric Moulines. High-dimensional bayesian inference via the unadjusted langevin algorithm. arXiv preprint arXiv:1605.01559, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.01559"
        },
        {
            "id": "22",
            "entry": "[22] Raaz Dwivedi, Yuansi Chen, Martin J Wainwright, and Bin Yu. Log-concave sampling: Metropolis-hastings algorithms are fast! arXiv preprint arXiv:1801.02309, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.02309"
        },
        {
            "id": "23",
            "entry": "[23] Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points-online stochastic gradient for tensor decomposition. In COLT, pages 797\u2013842, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points-online%20stochastic%20gradient%20for%20tensor%20decomposition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points-online%20stochastic%20gradient%20for%20tensor%20decomposition%202015"
        },
        {
            "id": "24",
            "entry": "[24] Rong Ge, Holden Lee, and Andrej Risteski. Beyond log-concavity: Provable guarantees for sampling multimodal distributions using simulated tempering langevin monte carlo. arXiv preprint arXiv:1710.02736, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.02736"
        },
        {
            "id": "25",
            "entry": "[25] Saul B Gelfand and Sanjoy K Mitter. Recursive stochastic algorithms for global optimization in rd. SIAM Journal on Control and Optimization, 29(5):999\u20131018, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gelfand%2C%20Saul%20B.%20Mitter%2C%20Sanjoy%20K.%20Recursive%20stochastic%20algorithms%20for%20global%20optimization%20in%20rd%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gelfand%2C%20Saul%20B.%20Mitter%2C%20Sanjoy%20K.%20Recursive%20stochastic%20algorithms%20for%20global%20optimization%20in%20rd%201991"
        },
        {
            "id": "26",
            "entry": "[26] Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341\u20132368, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghadimi%2C%20Saeed%20Lan%2C%20Guanghui%20Stochastic%20first-and%20zeroth-order%20methods%20for%20nonconvex%20stochastic%20programming%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghadimi%2C%20Saeed%20Lan%2C%20Guanghui%20Stochastic%20first-and%20zeroth-order%20methods%20for%20nonconvex%20stochastic%20programming%202013"
        },
        {
            "id": "27",
            "entry": "[27] Martin Hairer and Jonathan C Mattingly. Spectral gaps in wasserstein distances and the 2d stochastic navier-stokes equations. The Annals of Probability, pages 2050\u20132091, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hairer%2C%20Martin%20Mattingly%2C%20Jonathan%20C.%20Spectral%20gaps%20in%20wasserstein%20distances%20and%20the%202d%20stochastic%20navier-stokes%20equations%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hairer%2C%20Martin%20Mattingly%2C%20Jonathan%20C.%20Spectral%20gaps%20in%20wasserstein%20distances%20and%20the%202d%20stochastic%20navier-stokes%20equations%202008"
        },
        {
            "id": "28",
            "entry": "[28] Chii-Ruey Hwang. Laplace\u2019s method revisited: weak convergence of probability measures. The Annals of Probability, pages 1177\u20131182, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hwang%2C%20Chii-Ruey%20Laplace%E2%80%99s%20method%20revisited%3A%20weak%20convergence%20of%20probability%20measures%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hwang%2C%20Chii-Ruey%20Laplace%E2%80%99s%20method%20revisited%3A%20weak%20convergence%20of%20probability%20measures%201980"
        },
        {
            "id": "29",
            "entry": "[29] Nobuyuki Ikeda and Shinzo Watanabe. Stochastic differential equations and diffusion processes, volume 24.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ikeda%2C%20Nobuyuki%20Watanabe%2C%20Shinzo%20Stochastic%20differential%20equations%20and%20diffusion%20processes"
        },
        {
            "id": "30",
            "entry": "[30] Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan. How to escape saddle points efficiently. arXiv preprint arXiv:1703.00887, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00887"
        },
        {
            "id": "31",
            "entry": "[31] Chi Jin, Praneeth Netrapalli, and Michael I Jordan. Accelerated gradient descent escapes saddle points faster than gradient descent. arXiv preprint arXiv:1711.10456, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.10456"
        },
        {
            "id": "32",
            "entry": "[32] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance reduction. In Advances in Neural Information Processing Systems, pages 315\u2013323, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Rie%20Zhang%2C%20Tong%20Accelerating%20stochastic%20gradient%20descent%20using%20predictive%20variance%20reduction%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Rie%20Zhang%2C%20Tong%20Accelerating%20stochastic%20gradient%20descent%20using%20predictive%20variance%20reduction%202013"
        },
        {
            "id": "33",
            "entry": "[33] Peter E Kloeden and Eckhard Platen. Higher-order implicit strong numerical schemes for stochastic differential equations. Journal of statistical physics, 66(1):283\u2013314, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kloeden%2C%20Peter%20E.%20Platen%2C%20Eckhard%20Higher-order%20implicit%20strong%20numerical%20schemes%20for%20stochastic%20differential%20equations%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kloeden%2C%20Peter%20E.%20Platen%2C%20Eckhard%20Higher-order%20implicit%20strong%20numerical%20schemes%20for%20stochastic%20differential%20equations%201992"
        },
        {
            "id": "34",
            "entry": "[34] David Asher Levin, Yuval Peres, and Elizabeth Lee Wilmer. Markov chains and mixing times. American Mathematical Soc., 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levin%2C%20David%20Asher%20Peres%2C%20Yuval%20Wilmer%2C%20Elizabeth%20Lee%20Markov%20chains%20and%20mixing%20times%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levin%2C%20David%20Asher%20Peres%2C%20Yuval%20Wilmer%2C%20Elizabeth%20Lee%20Markov%20chains%20and%20mixing%20times%202009"
        },
        {
            "id": "35",
            "entry": "[35] Kfir Y Levy. The power of normalization: Faster evasion of saddle points. arXiv preprint arXiv:1611.04831, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.04831"
        },
        {
            "id": "36",
            "entry": "[36] Zhize Li, Tianyi Zhang, and Jian Li. Stochastic gradient hamiltonian monte carlo with variance reduction for bayesian inference. arXiv preprint arXiv:1803.11159, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.11159"
        },
        {
            "id": "37",
            "entry": "[37] Robert S Liptser and Albert N Shiryaev. Statistics of random Processes: I. general Theory, volume 5. Springer Science & Business Media, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liptser%2C%20Robert%20S.%20Shiryaev%2C%20Albert%20N.%20Statistics%20of%20random%20Processes%3A%20I%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liptser%2C%20Robert%20S.%20Shiryaev%2C%20Albert%20N.%20Statistics%20of%20random%20Processes%3A%20I%202013"
        },
        {
            "id": "38",
            "entry": "[38] Yi-An Ma, Tianqi Chen, and Emily Fox. A complete recipe for stochastic gradient mcmc. In Advances in Neural Information Processing Systems, pages 2917\u20132925, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Yi-An%20Chen%2C%20Tianqi%20Fox%2C%20Emily%20A%20complete%20recipe%20for%20stochastic%20gradient%20mcmc%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Yi-An%20Chen%2C%20Tianqi%20Fox%2C%20Emily%20A%20complete%20recipe%20for%20stochastic%20gradient%20mcmc%202015"
        },
        {
            "id": "39",
            "entry": "[39] Jonathan C Mattingly, Andrew M Stuart, and Desmond J Higham. Ergodicity for sdes and approximations: locally lipschitz vector fields and degenerate noise. Stochastic processes and their applications, 101(2): 185\u2013232, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mattingly%2C%20Jonathan%20C.%20Stuart%2C%20Andrew%20M.%20Higham%2C%20Desmond%20J.%20Ergodicity%20for%20sdes%20and%20approximations%3A%20locally%20lipschitz%20vector%20fields%20and%20degenerate%20noise.%20Stochastic%20processes%20and%20their%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mattingly%2C%20Jonathan%20C.%20Stuart%2C%20Andrew%20M.%20Higham%2C%20Desmond%20J.%20Ergodicity%20for%20sdes%20and%20approximations%3A%20locally%20lipschitz%20vector%20fields%20and%20degenerate%20noise.%20Stochastic%20processes%20and%20their%202002"
        },
        {
            "id": "40",
            "entry": "[40] Jonathan C Mattingly, Andrew M Stuart, and Michael V Tretyakov. Convergence of numerical timeaveraging and stationary measures via poisson equations. SIAM Journal on Numerical Analysis, 48(2): 552\u2013577, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mattingly%2C%20Jonathan%20C.%20Stuart%2C%20Andrew%20M.%20Tretyakov%2C%20Michael%20V.%20Convergence%20of%20numerical%20timeaveraging%20and%20stationary%20measures%20via%20poisson%20equations%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mattingly%2C%20Jonathan%20C.%20Stuart%2C%20Andrew%20M.%20Tretyakov%2C%20Michael%20V.%20Convergence%20of%20numerical%20timeaveraging%20and%20stationary%20measures%20via%20poisson%20equations%202010"
        },
        {
            "id": "41",
            "entry": "[41] Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer Science & Business Media, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Introductory%20lectures%20on%20convex%20optimization%3A%20A%20basic%20course%2C%20volume%2087%202013"
        },
        {
            "id": "42",
            "entry": "[42] Yurii Nesterov and Boris T Polyak. Cubic regularization of newton method and its global performance. Mathematical Programming, 108(1):177\u2013205, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Polyak%2C%20Boris%20T.%20Cubic%20regularization%20of%20newton%20method%20and%20its%20global%20performance%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Polyak%2C%20Boris%20T.%20Cubic%20regularization%20of%20newton%20method%20and%20its%20global%20performance%202006"
        },
        {
            "id": "43",
            "entry": "[43] Yury Polyanskiy and Yihong Wu. Wasserstein continuity of entropy and outer bounds for interference channels. IEEE Transactions on Information Theory, 62(7):3992\u20134002, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Polyanskiy%2C%20Yury%20Wu%2C%20Yihong%20Wasserstein%20continuity%20of%20entropy%20and%20outer%20bounds%20for%20interference%20channels%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Polyanskiy%2C%20Yury%20Wu%2C%20Yihong%20Wasserstein%20continuity%20of%20entropy%20and%20outer%20bounds%20for%20interference%20channels%202016"
        },
        {
            "id": "44",
            "entry": "[44] Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis. arXiv preprint arXiv:1702.03849, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.03849"
        },
        {
            "id": "45",
            "entry": "[45] Sashank J Reddi, Ahmed Hefny, Suvrit Sra, Barnabas Poczos, and Alex Smola. Stochastic variance reduction for nonconvex optimization. arXiv preprint arXiv:1603.06160, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.06160"
        },
        {
            "id": "46",
            "entry": "[46] Gareth O Roberts and Richard L Tweedie. Exponential convergence of langevin distributions and their discrete approximations. Bernoulli, pages 341\u2013363, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roberts%2C%20Gareth%20O.%20Tweedie%2C%20Richard%20L.%20Exponential%20convergence%20of%20langevin%20distributions%20and%20their%20discrete%20approximations%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roberts%2C%20Gareth%20O.%20Tweedie%2C%20Richard%20L.%20Exponential%20convergence%20of%20langevin%20distributions%20and%20their%20discrete%20approximations%201996"
        },
        {
            "id": "47",
            "entry": "[47] Issei Sato and Hiroshi Nakagawa. Approximation analysis of stochastic gradient langevin dynamics by using fokker-planck equation and ito process. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 982\u2013990, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sato%2C%20Issei%20Nakagawa%2C%20Hiroshi%20Approximation%20analysis%20of%20stochastic%20gradient%20langevin%20dynamics%20by%20using%20fokker-planck%20equation%20and%20ito%20process%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sato%2C%20Issei%20Nakagawa%2C%20Hiroshi%20Approximation%20analysis%20of%20stochastic%20gradient%20langevin%20dynamics%20by%20using%20fokker-planck%20equation%20and%20ito%20process%202014"
        },
        {
            "id": "48",
            "entry": "[48] Umut Simsekli, Cagatay Yildiz, Than Huy Nguyen, Taylan Cemgil, and Gael Richard. Asynchronous stochastic quasi-Newton MCMC for non-convex optimization. In Proceedings of the 35th International Conference on Machine Learning, pages 4674\u20134683, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simsekli%2C%20Umut%20Yildiz%2C%20Cagatay%20Nguyen%2C%20Than%20Huy%20Cemgil%2C%20Taylan%20Asynchronous%20stochastic%20quasi-Newton%20MCMC%20for%20non-convex%20optimization%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simsekli%2C%20Umut%20Yildiz%2C%20Cagatay%20Nguyen%2C%20Than%20Huy%20Cemgil%2C%20Taylan%20Asynchronous%20stochastic%20quasi-Newton%20MCMC%20for%20non-convex%20optimization%202018"
        },
        {
            "id": "49",
            "entry": "[49] Belinda Tzen, Tengyuan Liang, and Maxim Raginsky. Local optimality and generalization guarantees for the langevin algorithm via empirical metastability. arXiv preprint arXiv:1802.06439, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.06439"
        },
        {
            "id": "50",
            "entry": "[50] Sebastian J Vollmer, Konstantinos C Zygalakis, and Yee Whye Teh. Exploration of the (non-) asymptotic bias and variance of stochastic gradient langevin dynamics. Journal of Machine Learning Research, 17 (159):1\u201348, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vollmer%2C%20Sebastian%20J.%20Zygalakis%2C%20Konstantinos%20C.%20Teh%2C%20Yee%20Whye%20Exploration%20of%20the%20%28non-%29%20asymptotic%20bias%20and%20variance%20of%20stochastic%20gradient%20langevin%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vollmer%2C%20Sebastian%20J.%20Zygalakis%2C%20Konstantinos%20C.%20Teh%2C%20Yee%20Whye%20Exploration%20of%20the%20%28non-%29%20asymptotic%20bias%20and%20variance%20of%20stochastic%20gradient%20langevin%20dynamics%202016"
        },
        {
            "id": "51",
            "entry": "[51] Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceedings of the 28th International Conference on Machine Learning, pages 681\u2013688, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Welling%2C%20Max%20Teh%2C%20Yee%20W.%20Bayesian%20learning%20via%20stochastic%20gradient%20langevin%20dynamics%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Welling%2C%20Max%20Teh%2C%20Yee%20W.%20Bayesian%20learning%20via%20stochastic%20gradient%20langevin%20dynamics%202011"
        },
        {
            "id": "52",
            "entry": "[52] Yuchen Zhang, Percy Liang, and Moses Charikar. A hitting time analysis of stochastic gradient langevin dynamics. arXiv preprint arXiv:1702.05575, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.05575"
        },
        {
            "id": "53",
            "entry": "[53] Difan Zou, Pan Xu, and Quanquan Gu. Stochastic variance-reduced Hamilton Monte Carlo methods. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80, pages 6028\u20136037, 10\u201315 Jul 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zou%2C%20Difan%20Xu%2C%20Pan%20Gu%2C%20Quanquan%20Stochastic%20variance-reduced%20Hamilton%20Monte%20Carlo%20methods%202018-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zou%2C%20Difan%20Xu%2C%20Pan%20Gu%2C%20Quanquan%20Stochastic%20variance-reduced%20Hamilton%20Monte%20Carlo%20methods%202018-07"
        },
        {
            "id": "54",
            "entry": "[54] Difan Zou, Pan Xu, and Quanquan Gu. Subsampled stochastic variance-reduced gradient langevin dynamics. In Proceedings of International Conference on Uncertainty in Artificial Intelligence, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zou%2C%20Difan%20Xu%2C%20Pan%20Gu%2C%20Quanquan%20Subsampled%20stochastic%20variance-reduced%20gradient%20langevin%20dynamics%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zou%2C%20Difan%20Xu%2C%20Pan%20Gu%2C%20Quanquan%20Subsampled%20stochastic%20variance-reduced%20gradient%20langevin%20dynamics%202018"
        }
    ]
}
