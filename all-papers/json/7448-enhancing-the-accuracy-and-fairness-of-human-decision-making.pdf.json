{
    "filename": "7448-enhancing-the-accuracy-and-fairness-of-human-decision-making.pdf",
    "metadata": {
        "title": "Enhancing the Accuracy and Fairness of Human Decision Making",
        "author": "Isabel Valera, Adish Singla, Manuel Gomez Rodriguez",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7448-enhancing-the-accuracy-and-fairness-of-human-decision-making.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Societies often rely on human experts to take a wide variety of decisions affecting their members, from jail-or-release decisions taken by judges and stop-and-frisk decisions taken by police officers to accept-or-reject decisions taken by academics. In this context, each decision is taken by an expert who is typically chosen uniformly at random from a pool of experts. However, these decisions may be imperfect due to limited experience, implicit biases, or faulty probabilistic reasoning. Can we improve the accuracy and fairness of the overall decision making process by optimizing the assignment between experts and decisions?"
    },
    "keywords": [
        {
            "term": "implicit bias",
            "url": "https://en.wikipedia.org/wiki/implicit_bias"
        },
        {
            "term": "decision making process",
            "url": "https://en.wikipedia.org/wiki/decision_making_process"
        },
        {
            "term": "police officer",
            "url": "https://en.wikipedia.org/wiki/police_officer"
        }
    ],
    "highlights": [
        "There have been increasing concerns about the potential for unfairness of algorithmic decision making",
        "There have been a flurry of work on developing computational mechanisms to make sure that the machine learning methods that fuel algorithmic decision making are fair [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "To the best of our knowledge, there is a lack of machine learning methods to ensure accuracy and fairness in human decision making, which is still prevalent in a wide range of critical applications such as, e.g., jail-or-release decisions by judges, stop-and-frisk decisions by police officers or accept-or-reject decisions by academics",
        "We have proposed a set of practical algorithms to improve the utility and fairness of a sequential decision making process, where each decision is taken by a human expert, who is selected from a pool experts",
        "Experiments on synthetic data and real jail-or-release decisions by judges show that our algorithms are able to mitigate imperfect human decisions due to limited experience, implicit biases or faulty probabilistic reasoning"
    ],
    "key_statements": [
        "There have been increasing concerns about the potential for unfairness of algorithmic decision making",
        "There have been a flurry of work on developing computational mechanisms to make sure that the machine learning methods that fuel algorithmic decision making are fair [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "To the best of our knowledge, there is a lack of machine learning methods to ensure accuracy and fairness in human decision making, which is still prevalent in a wide range of critical applications such as, e.g., jail-or-release decisions by judges, stop-and-frisk decisions by police officers or accept-or-reject decisions by academics",
        "We have proposed a set of practical algorithms to improve the utility and fairness of a sequential decision making process, where each decision is taken by a human expert, who is selected from a pool experts",
        "Experiments on synthetic data and real jail-or-release decisions by judges show that our algorithms are able to mitigate imperfect human decisions due to limited experience, implicit biases or faulty probabilistic reasoning"
    ],
    "summary": [
        "There have been increasing concerns about the potential for unfairness of algorithmic decision making.",
        "We can find the assignment of human decision makers {v(t)}tT=1 with the highest expected utility by solving the following optimization problem: Tm maximize dvi(t), zi(t)),zi(t) \u2212 c)",
        "The optimal decision rule d\u2217(X, Z), given by Eq 4, maximizes the utility, as defined by Eq 1, under the following constraint [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>]: DI(d\u2217, c) = |bz=1(d\u2217, c) \u2212 bz=0(d\u2217, c)| \u2264 \u03b1.",
        "We can find the assignment of human decision makers {v(t)} with the highest expected utility and disparate impact less than \u03b1 as: Tm maximize dvi(t), zi(t)),zi(t) \u2212 c), t=1 i=1 subject to vi(t) \u2208 V for all t \u2208 {1, .",
        "Figures 1(a)-(b) show the expected utility and the disparate impact after T units of time for the optimal decision rule and for the group of experts under the assignments provided our algorithms and under random assignments.",
        "We find that the experts chosen by our algorithm provide decisions with higher utility and lower disparate impact than the experts chosen at random, even if the thresholds are unknown.",
        "If the threshold are known, the experts chosen by our algorithm closely match the performance of the optimal decision rule both in terms of utility and disparate impact.",
        "We compute the regret as defined by Eq 10, i.e., the difference between the utilities provided by algorithm with Known and Unknown thresholds over time.",
        "They reveal that our algorithms benefit from higher diversity across the pool experts helps and and they are able to ensure fairness even if a significant percentage of judges are biased against a group of individuals sharing a certain sensitive attribute value.",
        "We fix the following two things before setting up the problem instance: (i) let g(\u00b7) be a deterministic function which computes a point estimate of a distribution; we assume a deterministic tie-breaking by the assignment algorithm, and w.l.o.g. expert j = 1 is preferred over expert j = 2 for assignment when both of them have same edge weights.",
        "Given the true thresholds, the algorithm would have always assigned the individual to expert j = 2 and would have a cumulative expected utility of",
        "It would be very valuable to gain access to datasets with such information [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>]"
    ],
    "headline": "We address the above problem from the perspective of sequential decision making and show that, for different fairness notions in the literature, it reduces to a sequence of  weighted bipartite matchings, which can be solved efficiently using algorithms with approximation guarantees",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] S. Barocas and A. D. Selbst. Big datas disparate impact. California Law Review, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barocas%2C%20S.%20Selbst%2C%20A.D.%20Big%20datas%20disparate%20impact%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barocas%2C%20S.%20Selbst%2C%20A.D.%20Big%20datas%20disparate%20impact%202016"
        },
        {
            "id": "2",
            "entry": "[2] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20S.%20Vandenberghe%2C%20L.%20Convex%20optimization%202004"
        },
        {
            "id": "3",
            "entry": "[3] S. Corbett-Davies, E. Pierson, A. Feller, S. Goel, and A. Huq. Algorithmic decision making and the cost of fairness. KDD, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Corbett-Davies%2C%20S.%20Pierson%2C%20E.%20Feller%2C%20A.%20Goel%2C%20S.%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Corbett-Davies%2C%20S.%20Pierson%2C%20E.%20Feller%2C%20A.%20Goel%2C%20S.%20Algorithmic%20decision%20making%20and%20the%20cost%20of%20fairness%202017"
        },
        {
            "id": "4",
            "entry": "[4] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. Fairness through awareness. In ITCS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20C.%20Hardt%2C%20M.%20Pitassi%2C%20T.%20Reingold%2C%20O.%20Fairness%20through%20awareness%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20C.%20Hardt%2C%20M.%20Pitassi%2C%20T.%20Reingold%2C%20O.%20Fairness%20through%20awareness%202012"
        },
        {
            "id": "5",
            "entry": "[5] M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian. Certifying and removing disparate impact. In KDD, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feldman%2C%20M.%20Friedler%2C%20S.A.%20Moeller%2C%20J.%20Scheidegger%2C%20C.%20Certifying%20and%20removing%20disparate%20impact%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feldman%2C%20M.%20Friedler%2C%20S.A.%20Moeller%2C%20J.%20Scheidegger%2C%20C.%20Certifying%20and%20removing%20disparate%20impact%202015"
        },
        {
            "id": "6",
            "entry": "[6] M. Hardt, E. Price, N. Srebro, et al. Equality of opportunity in supervised learning. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20M.%20Price%2C%20E.%20Srebro%2C%20N.%20Equality%20of%20opportunity%20in%20supervised%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20M.%20Price%2C%20E.%20Srebro%2C%20N.%20Equality%20of%20opportunity%20in%20supervised%20learning%202016"
        },
        {
            "id": "7",
            "entry": "[7] J. Kleinberg, H. Lakkaraju, J. Leskovec, J. Ludwig, and S. Mullainathan. Human decisions and machine predictions. The Quarterly Journal of Economics, 133(1):237\u2013293, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kleinberg%2C%20J.%20Lakkaraju%2C%20H.%20Leskovec%2C%20J.%20Ludwig%2C%20J.%20Human%20decisions%20and%20machine%20predictions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kleinberg%2C%20J.%20Lakkaraju%2C%20H.%20Leskovec%2C%20J.%20Ludwig%2C%20J.%20Human%20decisions%20and%20machine%20predictions%202017"
        },
        {
            "id": "8",
            "entry": "[8] J. Larson, S. Mattu, L. Kirchner, and J. Angwin. https://github.com/propublica/compas-analysis, 2016.",
            "url": "https://github.com/propublica/compas-analysis"
        },
        {
            "id": "9",
            "entry": "[9] M. Mastrolilli and G. Stamoulis. Constrained matching problems in bipartite graphs. In ISCO, pages 344\u2013355.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mastrolilli%2C%20M.%20Stamoulis%2C%20G.%20Constrained%20matching%20problems%20in%20bipartite%20graphs",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mastrolilli%2C%20M.%20Stamoulis%2C%20G.%20Constrained%20matching%20problems%20in%20bipartite%20graphs"
        },
        {
            "id": "10",
            "entry": "[10] C. Mu\u00f1oz, M. Smith, and D. Patil. Big Data: A Report on Algorithmic Systems, Opportunity, and Civil Rights. Executive Office of the President. The White House., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mu%C3%B1oz%2C%20C.%20Smith%2C%20M.%20Patil%2C%20D.%20Big%20Data%3A%20A%20Report%20on%20Algorithmic%20Systems%2C%20Opportunity%2C%20and%20Civil%20Rights.%20Executive%20Office%20of%20the%20President%202016"
        },
        {
            "id": "11",
            "entry": "[11] I. Osband, D. Russo, and B. Van Roy. (more) efficient reinforcement learning via posterior sampling. In NIPS, pages 3003\u20133011, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Osband%2C%20I.%20Russo%2C%20D.%20Roy%2C%20B.Van%20efficient%20reinforcement%20learning%20via%20posterior%20sampling%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Osband%2C%20I.%20Russo%2C%20D.%20Roy%2C%20B.Van%20efficient%20reinforcement%20learning%20via%20posterior%20sampling%202013"
        },
        {
            "id": "12",
            "entry": "[12] D. B. West et al. Introduction to graph theory, volume 2. Prentice hall Upper Saddle River, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=West%2C%20D.B.%20Introduction%20to%20graph%20theory%2C%20volume%202%202001"
        },
        {
            "id": "13",
            "entry": "[13] B. Zafar, I. Valera, M. Gomez-Rodriguez, and K. Gummadi. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In WWW, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20B.%20Valera%2C%20I.%20Gomez-Rodriguez%2C%20M.%20Gummadi%2C%20K.%20Fairness%20beyond%20disparate%20treatment%20%26%20disparate%20impact%3A%20Learning%20classification%20without%20disparate%20mistreatment%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20B.%20Valera%2C%20I.%20Gomez-Rodriguez%2C%20M.%20Gummadi%2C%20K.%20Fairness%20beyond%20disparate%20treatment%20%26%20disparate%20impact%3A%20Learning%20classification%20without%20disparate%20mistreatment%202017"
        },
        {
            "id": "14",
            "entry": "[14] B. Zafar, I. Valera, M. Gomez-Rodriguez, and K. Gummadi. Training fair classifiers. AISTATS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20B.%20Valera%2C%20I.%20Gomez-Rodriguez%2C%20M.%20Gummadi%2C%20K.%20Training%20fair%20classifiers%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20B.%20Valera%2C%20I.%20Gomez-Rodriguez%2C%20M.%20Gummadi%2C%20K.%20Training%20fair%20classifiers%202017"
        },
        {
            "id": "15",
            "entry": "[15] B. Zafar, I. Valera, M. Gomez-Rodriguez, K. Gummadi, and A. Weller. From parity to preference: Learning with cost-effective notions of fairness. In NIPS, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zafar%2C%20B.%20Valera%2C%20I.%20Gomez-Rodriguez%2C%20M.%20Gummadi%2C%20K.%20From%20parity%20to%20preference%3A%20Learning%20with%20cost-effective%20notions%20of%20fairness%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zafar%2C%20B.%20Valera%2C%20I.%20Gomez-Rodriguez%2C%20M.%20Gummadi%2C%20K.%20From%20parity%20to%20preference%3A%20Learning%20with%20cost-effective%20notions%20of%20fairness%202017"
        }
    ]
}
