{
    "filename": "7809-bandit-learning-in-concave-n-person-games.pdf",
    "metadata": {
        "title": "Bandit Learning in Concave N-Person Games",
        "author": "Mario Bravo, David Leslie, Panayotis Mertikopoulos",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7809-bandit-learning-in-concave-n-person-games.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "This paper examines the long-run behavior of learning with bandit feedback in non-cooperative concave games. The bandit framework accounts for extremely lowinformation environments where the agents may not even know they are playing a game; as such, the agents\u2019 most sensible choice in this setting would be to employ a no-regret learning algorithm. In general, this does not mean that the players\u2019 behavior stabilizes in the long run: no-regret learning may lead to cycles, even with perfect gradient information. However, if a standard monotonicity condition is satisfied, our analysis shows that no-regret learning based on mirror descent with bandit feedback converges to Nash equilibrium with probability 1. We also derive an upper bound for the convergence rate of the process that nearly matches the best attainable rate for single-agent bandit stochastic optimization."
    },
    "keywords": [
        {
            "term": "convex optimization",
            "url": "https://en.wikipedia.org/wiki/convex_optimization"
        },
        {
            "term": "online convex optimization",
            "url": "https://en.wikipedia.org/wiki/online_convex_optimization"
        },
        {
            "term": "convergence rate",
            "url": "https://en.wikipedia.org/wiki/convergence_rate"
        },
        {
            "term": "Nash equilibrium",
            "url": "https://en.wikipedia.org/wiki/Nash_equilibrium"
        },
        {
            "term": "simultaneous perturbation stochastic approximation",
            "url": "https://en.wikipedia.org/wiki/simultaneous_perturbation_stochastic_approximation"
        },
        {
            "term": "NIPS",
            "url": "https://en.wikipedia.org/wiki/NIPS"
        },
        {
            "term": "long run",
            "url": "https://en.wikipedia.org/wiki/long_run"
        },
        {
            "term": "multiple-input and multiple-output",
            "url": "https://en.wikipedia.org/wiki/multiple-input_and_multiple-output"
        }
    ],
    "highlights": [
        "The bane of decision-making in an unknown environment is regret: noone wants to realize in hindsight that the decision policy they employed was strictly inferior to a plain policy prescribing the same action throughout",
        "This issue becomes considerably more intricate when the decision-maker is subject to situational uncertainty and the \u201cfog of war\u201d: when the only information at the optimizer\u2019s disposal is the reward obtained from a given action, is it even possible to design a no-regret policy? Especially in the context of online convex optimization, this problem becomes even more challenging because the decision-maker typically needs to infer gradient information from the observation of a single scalar",
        "To do away with player coordination requirements, we focus on learning processes which could be sensibly deployed in a single-agent setting and we show that, in monotone games, the sequence of play induced by a wide class of no-regret learning policies converges to Nash equilibrium with probability 1",
        "The most sensible choice for agents who are oblivious to the presence of each other, is to deploy a no-regret learning algorithm",
        "We studied the long-run behavior of individual regularized no-regret learning policies and we showed that, in monotone games, play converges to equilibrium with probability 1, and the rate of convergence almost matches the optimal rates of single-agent, stochastic convex optimization",
        "Several questions remain open: whether there is an intrinsic information-theoretic obstacle to bridging this gap; whether our convergence rate estimates hold with high probability; and whether our analysis extends to a fully decentralized setting where the players\u2019 updates need not be synchronous"
    ],
    "key_statements": [
        "The bane of decision-making in an unknown environment is regret: noone wants to realize in hindsight that the decision policy they employed was strictly inferior to a plain policy prescribing the same action throughout",
        "This issue becomes considerably more intricate when the decision-maker is subject to situational uncertainty and the \u201cfog of war\u201d: when the only information at the optimizer\u2019s disposal is the reward obtained from a given action, is it even possible to design a no-regret policy? Especially in the context of online convex optimization, this problem becomes even more challenging because the decision-maker typically needs to infer gradient information from the observation of a single scalar",
        "The agents \u2013 or players \u2013 might be completely oblivious to this mechanism, perhaps even ignoring its existence: for instance, when choosing how much to bid for a good in an online auction, an agent is typically unaware of who the other bidders are, what are their specific valuations, etc",
        "A fundamental question that arises is a) whether the agents\u2019 sequence of actions stabilizes to a rationally admissible state under no-regret learning; and b) if it does, whether convergence is affected by the information available to the agents.\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00e9al, Canada",
        "To do away with player coordination requirements, we focus on learning processes which could be sensibly deployed in a single-agent setting and we show that, in monotone games, the sequence of play induced by a wide class of no-regret learning policies converges to Nash equilibrium with probability 1",
        "We find this outcome particularly appealing for practical applications of game theory because it shows that in a wide class of nonlinear games, the Nash equilibrium prediction does not require full rationality, common knowledge of rationality, flawless execution, or even the knowledge that a game is being played: a commonly-used, individual no-regret algorithm suffices.\n2 Problem setup and preliminaries",
        "As we show in the paper\u2019s supplement, Examples 2.1 and 2.2 both satisfy diagonal strict concavity, as do atomic splittable congestion games in networks with parallel links (<a class=\"ref-link\" id=\"cOrda_et+al_1993_a\" href=\"#rOrda_et+al_1993_a\">Orda et al, 1993</a>; <a class=\"ref-link\" id=\"cSorin_2016_a\" href=\"#rSorin_2016_a\">Sorin and Wan, 2016</a>), multi-user covariance matrix optimization problems in multiple-input and multiple-output (MIMO) systems (<a class=\"ref-link\" id=\"cMertikopoulos_et+al_2017_a\" href=\"#rMertikopoulos_et+al_2017_a\">Mertikopoulos et al, 2017</a>), and many other problems where online decision-making is the norm",
        "It is more common to assume that each player has access to a stochastic oracle which, when called against a sequence of actions Xn \u2208 X , produces a sequence of gradient estimates vn =i\u2208N that satisfies the following statistical assumptions: a) Unbiasedness: E[vn | Fn] = v(Xn)",
        "We show below that this bound is attainable for games that are strongly monotone, i.e., they satisfy the following stronger variant of diagonal strict concavity: \u03bbi vi(x ) \u2212 vi(x), xi \u2212 xi \u03b2 \u2264\u2212",
        "The step-size schedule \u03b3n \u221d 1/n is not required to obtain an O(n\u22121/3) convergence rate: as we show in the paper\u2019s supplement, more general schedules of the form \u03b3n \u221d 1/np and \u03b4n \u221d 1/nq with p > 3/4 and q = p/3 > 1/4, still guarantee an O(n\u22121/3) rate of convergence for (MD-b)",
        "The most sensible choice for agents who are oblivious to the presence of each other, is to deploy a no-regret learning algorithm",
        "We studied the long-run behavior of individual regularized no-regret learning policies and we showed that, in monotone games, play converges to equilibrium with probability 1, and the rate of convergence almost matches the optimal rates of single-agent, stochastic convex optimization",
        "Several questions remain open: whether there is an intrinsic information-theoretic obstacle to bridging this gap; whether our convergence rate estimates hold with high probability; and whether our analysis extends to a fully decentralized setting where the players\u2019 updates need not be synchronous"
    ],
    "summary": [
        "The bane of decision-making in an unknown environment is regret: noone wants to realize in hindsight that the decision policy they employed was strictly inferior to a plain policy prescribing the same action throughout.",
        "More relevant for our purposes is the analysis of <a class=\"ref-link\" id=\"cNesterov_2009_a\" href=\"#rNesterov_2009_a\">Nesterov (2009</a>) who showed that the time-averaged sequence of play induced by a no-regret dual averaging (DA) process with noisy gradient feedback converges to Nash equilibrium in monotone games (a class which, in turn, contains all concave potential games).",
        "To do away with player coordination requirements, we focus on learning processes which could be sensibly deployed in a single-agent setting and we show that, in monotone games, the sequence of play induced by a wide class of no-regret learning policies converges to Nash equilibrium with probability 1.",
        "It is more common to assume that each player has access to a stochastic oracle which, when called against a sequence of actions Xn \u2208 X , produces a sequence of gradient estimates vn =i\u2208N that satisfies the following statistical assumptions: a) Unbiasedness: E[vn | Fn] = v(Xn).",
        "If players don\u2019t have access to a first-order oracle \u2013 the so-called bandit or payoff-based framework \u2013 they will need to derive an individual gradient estimate from the only information at their disposal: the actual payoffs they receive at each stage.",
        "In a game-theoretic setting multiple-point estimation techniques do not apply because, in general, a player\u2019s payoff function depends on the actions of all players.",
        "Combining the learning framework of Section 3 with the single-shot gradient estimation machinery of Section 4, we obtain the following variant of (MD) with payoff-based, bandit feedback: Xn = Xn + \u03b4nWn, Xn+1 = PXn. In the above, the perturbations Wn and the estimates vn are given respectively by (4.4) and (4.2), i.e., Wi,n = Zi,n \u2212 ri\u22121(Xi,n \u2212 pi)",
        "In a game-theoretic setting it is the players\u2019 realized actions that determine their rewards at each stage, so the figure of merit is the actual sequence of play Xn. This sequence is more difficult to control, so this disparity is, perhaps, not too surprising; we believe that this gap can be closed by using a more sophisticated single-shot estimate, e.g., as in <a class=\"ref-link\" id=\"cGhadimi_2013_a\" href=\"#rGhadimi_2013_a\">Ghadimi and Lan (2013</a>).",
        "We studied the long-run behavior of individual regularized no-regret learning policies and we showed that, in monotone games, play converges to equilibrium with probability 1, and the rate of convergence almost matches the optimal rates of single-agent, stochastic convex optimization."
    ],
    "headline": "This paper examines the long-run behavior of learning with bandit feedback in non-cooperative concave games",
    "reference_links": [
        {
            "id": "Agarwal_et+al_2010_a",
            "entry": "Agarwal, Alekh, O. Dekel, L. Xiao. 2010. Optimal algorithms for online convex optimization with multi-point bandit feedback. COLT \u201910: Proceedings of the 23rd Annual Conference on Learning Theory.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Alekh%20Dekel%2C%20O.%20Xiao%2C%20L.%20Optimal%20algorithms%20for%20online%20convex%20optimization%20with%20multi-point%20bandit%20feedback.%20COLT%E2%80%99%2010%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Alekh%20Dekel%2C%20O.%20Xiao%2C%20L.%20Optimal%20algorithms%20for%20online%20convex%20optimization%20with%20multi-point%20bandit%20feedback.%20COLT%E2%80%99%2010%202010"
        },
        {
            "id": "Arora_et+al_2012_a",
            "entry": "Arora, Sanjeev, Elad Hazan, Satyen Kale. 2012. The multiplicative weights update method: A meta-algorithm and applications. Theory of Computing 8(1) 121\u2013164.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20Sanjeev%20Hazan%2C%20Elad%20Kale%2C%20Satyen%20The%20multiplicative%20weights%20update%20method%3A%20A%20meta-algorithm%20and%20applications%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20Sanjeev%20Hazan%2C%20Elad%20Kale%2C%20Satyen%20The%20multiplicative%20weights%20update%20method%3A%20A%20meta-algorithm%20and%20applications%202012"
        },
        {
            "id": "Auer_et+al_1995_a",
            "entry": "Auer, Peter, Nicol\u00f2 Cesa-Bianchi, Yoav Freund, Robert E. Schapire. 1995. Gambling in a rigged casino: The adversarial multi-armed bandit problem. Proceedings of the 36th Annual Symposium on Foundations of Computer Science.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Auer%2C%20Peter%20Cesa-Bianchi%2C%20Nicol%C3%B2%20Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20Gambling%20in%20a%20rigged%20casino%3A%20The%20adversarial%20multi-armed%20bandit%20problem%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Auer%2C%20Peter%20Cesa-Bianchi%2C%20Nicol%C3%B2%20Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20Gambling%20in%20a%20rigged%20casino%3A%20The%20adversarial%20multi-armed%20bandit%20problem%201995"
        },
        {
            "id": "Bauschke_2017_a",
            "entry": "Bauschke, Heinz H., Patrick L. Combettes. 2017. Convex Analysis and Monotone Operator Theory in Hilbert Spaces. 2nd ed. Springer, New York, NY, USA.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bauschke%2C%20Heinz%20H.%20Combettes%2C%20Patrick%20L.%20Convex%20Analysis%20and%20Monotone%20Operator%20Theory%20in%20Hilbert%20Spaces%202017"
        },
        {
            "id": "Bena_1999_a",
            "entry": "Bena\u00efm, Michel. 1999. Dynamics of stochastic approximation algorithms. Jacques Az\u00e9ma, Michel \u00c9mery, Michel Ledoux, Marc Yor, eds., S\u00e9minaire de Probabilit\u00e9s XXXIII, Lecture Notes in Mathematics, vol. 1709. Springer Berlin Heidelberg, 1\u201368.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bena%C3%AFm%2C%20Michel%20Dynamics%20of%20stochastic%20approximation%20algorithms.%20Jacques%20Az%C3%A9ma%2C%20Michel%20%C3%89mery%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bena%C3%AFm%2C%20Michel%20Dynamics%20of%20stochastic%20approximation%20algorithms.%20Jacques%20Az%C3%A9ma%2C%20Michel%20%C3%89mery%201999"
        },
        {
            "id": "Bervoets_et+al_2018_a",
            "entry": "Bervoets, Sebastian, Mario Bravo, Mathieu Faure. 2018. Learning with minimal information in continuous games. https://arxiv.org/abs/1806.11506.",
            "url": "https://arxiv.org/abs/1806.11506",
            "arxiv_url": "https://arxiv.org/pdf/1806.11506"
        },
        {
            "id": "Chen_1993_a",
            "entry": "Chen, Gong, Marc Teboulle. 1993. Convergence analysis of a proximal-like minimization algorithm using Bregman functions. SIAM Journal on Optimization 3(3) 538\u2013543.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Gong%20Teboulle%2C%20Marc%20Convergence%20analysis%20of%20a%20proximal-like%20minimization%20algorithm%20using%20Bregman%20functions%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Gong%20Teboulle%2C%20Marc%20Convergence%20analysis%20of%20a%20proximal-like%20minimization%20algorithm%20using%20Bregman%20functions%201993"
        },
        {
            "id": "Cohen_et+al_2017_a",
            "entry": "Cohen, Johanne, Am\u00e9lie H\u00e9liou, Panayotis Mertikopoulos. 2017. Learning with bandit feedback in potential games. NIPS \u201917: Proceedings of the 31st International Conference on Neural Information Processing Systems.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20Johanne%20H%C3%A9liou%2C%20Am%C3%A9lie%20Mertikopoulos%2C%20Panayotis%20Learning%20with%20bandit%20feedback%20in%20potential%20games.%20NIPS%E2%80%99%2017%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20Johanne%20H%C3%A9liou%2C%20Am%C3%A9lie%20Mertikopoulos%2C%20Panayotis%20Learning%20with%20bandit%20feedback%20in%20potential%20games.%20NIPS%E2%80%99%2017%202017"
        },
        {
            "id": "Debreu_1952_a",
            "entry": "Debreu, Gerard. 1952. A social equilibrium existence theorem. Proceedings of the National Academy of Sciences of the USA 38(10) 886\u2013893.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Debreu%2C%20Gerard.%201952%20A%20social%20equilibrium%20existence%20theorem%201952",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Debreu%2C%20Gerard.%201952%20A%20social%20equilibrium%20existence%20theorem%201952"
        },
        {
            "id": "Flaxman_2005_a",
            "entry": "Flaxman, Abraham D., Adam Tauman Kalai, H. Brendan McMahan. 2005. Online convex optimization in the bandit setting: gradient descent without a gradient. SODA \u201905: Proceedings of the 16th annual ACM-SIAM Symposium on Discrete Algorithms. 385\u2013394.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Flaxman%2C%20Abraham%20D.%20Adam%20Tauman%20Kalai%2C%20H.Brendan%20McMahan%20Online%20convex%20optimization%20in%20the%20bandit%20setting%3A%20gradient%20descent%20without%20a%20gradient.%20SODA%E2%80%99%2005%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Flaxman%2C%20Abraham%20D.%20Adam%20Tauman%20Kalai%2C%20H.Brendan%20McMahan%20Online%20convex%20optimization%20in%20the%20bandit%20setting%3A%20gradient%20descent%20without%20a%20gradient.%20SODA%E2%80%99%2005%202005"
        },
        {
            "id": "Foster_et+al_2016_a",
            "entry": "Foster, Dylan J., Thodoris Lykouris, Kathrik Sridharan, \u00c9va Tardos. 2016. Learning in games: Robustness of fast convergence. NIPS \u201916: Proceedings of the 30th International Conference on Neural Information Processing Systems. 4727\u20134735.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Foster%2C%20Dylan%20J.%20Lykouris%2C%20Thodoris%20Sridharan%2C%20Kathrik%20Tardos%2C%20%C3%89va%20Learning%20in%20games%3A%20Robustness%20of%20fast%20convergence.%20NIPS%E2%80%99%2016%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Foster%2C%20Dylan%20J.%20Lykouris%2C%20Thodoris%20Sridharan%2C%20Kathrik%20Tardos%2C%20%C3%89va%20Learning%20in%20games%3A%20Robustness%20of%20fast%20convergence.%20NIPS%E2%80%99%2016%202016"
        },
        {
            "id": "Freund_1999_a",
            "entry": "Freund, Yoav, Robert E. Schapire. 1999. Adaptive game playing using multiplicative weights. Games and Economic Behavior 29 79\u2013103.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20Adaptive%20game%20playing%20using%20multiplicative%20weights%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20Adaptive%20game%20playing%20using%20multiplicative%20weights%201999"
        },
        {
            "id": "Ghadimi_2013_a",
            "entry": "Ghadimi, Saeed, Guanghui Lan. 2013. Stochastic firstand zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization 23(4) 2341\u20132368.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghadimi%2C%20Saeed%20Lan%2C%20Guanghui%20Stochastic%20firstand%20zeroth-order%20methods%20for%20nonconvex%20stochastic%20programming%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghadimi%2C%20Saeed%20Lan%2C%20Guanghui%20Stochastic%20firstand%20zeroth-order%20methods%20for%20nonconvex%20stochastic%20programming%202013"
        },
        {
            "id": "Kleinberg_2004_a",
            "entry": "Kleinberg, Robert D. 2004. Nearly tight bounds for the continuum-armed bandit problem. NIPS\u2019 04: Proceedings of the 18th Annual Conference on Neural Information Processing Systems.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kleinberg%2C%20Robert%20D.%20Nearly%20tight%20bounds%20for%20the%20continuum-armed%20bandit%20problem.%20NIPS%E2%80%99%2004%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kleinberg%2C%20Robert%20D.%20Nearly%20tight%20bounds%20for%20the%20continuum-armed%20bandit%20problem.%20NIPS%E2%80%99%2004%202004"
        },
        {
            "id": "Mertikopoulos_et+al_2017_a",
            "entry": "Mertikopoulos, Panayotis, E. Veronica Belmega, Romain Negrel, Luca Sanguinetti. 2017. Distributed stochastic optimization via matrix exponential learning. IEEE Trans. Signal Process. 65(9) 2277\u20132290.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mertikopoulos%2C%20Panayotis%20Belmega%2C%20E.Veronica%20Negrel%2C%20Romain%20Sanguinetti%2C%20Luca%20Distributed%20stochastic%20optimization%20via%20matrix%20exponential%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mertikopoulos%2C%20Panayotis%20Belmega%2C%20E.Veronica%20Negrel%2C%20Romain%20Sanguinetti%2C%20Luca%20Distributed%20stochastic%20optimization%20via%20matrix%20exponential%20learning%202017"
        },
        {
            "id": "Mertikopoulos_et+al_0000_a",
            "entry": "Mertikopoulos, Panayotis, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chandrasekhar, Georgios Piliouras. 2018a. Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile. https://arxiv.org/abs/1807.02629.",
            "url": "https://arxiv.org/abs/1807.02629",
            "arxiv_url": "https://arxiv.org/pdf/1807.02629"
        },
        {
            "id": "Mertikopoulos_0000_b",
            "entry": "Mertikopoulos, Panayotis, Christos H. Papadimitriou, Georgios Piliouras. 2018b. Cycles in adversarial regularized learning. SODA \u201918: Proceedings of the 29th annual ACM-SIAM Symposium on Discrete Algorithms.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mertikopoulos%2C%20Panayotis%20Papadimitriou%2C%20Christos%20H.%20Georgios%20Piliouras.%202018b.%20Cycles%20in%20adversarial%20regularized%20learning.%20SODA%E2%80%99%2018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mertikopoulos%2C%20Panayotis%20Papadimitriou%2C%20Christos%20H.%20Georgios%20Piliouras.%202018b.%20Cycles%20in%20adversarial%20regularized%20learning.%20SODA%E2%80%99%2018"
        },
        {
            "id": "Mertikopoulos_2018_a",
            "entry": "Mertikopoulos, Panayotis, Zhengyuan Zhou. 2018. Learning in games with continuous action sets and unknown payoff functions. Mathematical Programming .",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mertikopoulos%2C%20Panayotis%20Zhou%2C%20Zhengyuan%20Learning%20in%20games%20with%20continuous%20action%20sets%20and%20unknown%20payoff%20functions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mertikopoulos%2C%20Panayotis%20Zhou%2C%20Zhengyuan%20Learning%20in%20games%20with%20continuous%20action%20sets%20and%20unknown%20payoff%20functions%202018"
        },
        {
            "id": "Nemirovski_1983_a",
            "entry": "Nemirovski, Arkadi Semen, David Berkovich Yudin. 1983. Problem Complexity and Method Efficiency in Optimization. Wiley, New York, NY.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovski%2C%20Arkadi%20Semen%20Yudin%2C%20David%20Berkovich%20Problem%20Complexity%20and%20Method%20Efficiency%20in%20Optimization%201983"
        },
        {
            "id": "Nesterov_2004_a",
            "entry": "Nesterov, Yurii. 2004. Introductory Lectures on Convex Optimization: A Basic Course. No. 87 in Applied Optimization, Kluwer Academic Publishers.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Introductory%20Lectures%20on%20Convex%20Optimization%3A%20A%20Basic%20Course.%20No.%2087%20in%20Applied%20Optimization%202004"
        },
        {
            "id": "Nesterov_2009_a",
            "entry": "Nesterov, Yurii. 2009. Primal-dual subgradient methods for convex problems. Mathematical Programming 120(1) 221\u2013259.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Primal-dual%20subgradient%20methods%20for%20convex%20problems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Primal-dual%20subgradient%20methods%20for%20convex%20problems%202009"
        },
        {
            "id": "Orda_et+al_1993_a",
            "entry": "Orda, Ariel, Raphael Rom, Nahum Shimkin. 1993. Competitive routing in multi-user communication networks. IEEE/ACM Trans. Netw. 1(5) 614\u2013627.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Orda%2C%20Ariel%20Rom%2C%20Raphael%20Shimkin%2C%20Nahum%20Competitive%20routing%20in%20multi-user%20communication%20networks%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Orda%2C%20Ariel%20Rom%2C%20Raphael%20Shimkin%2C%20Nahum%20Competitive%20routing%20in%20multi-user%20communication%20networks%201993"
        },
        {
            "id": "Palaiopanos_et+al_2017_a",
            "entry": "Palaiopanos, Gerasimos, Ioannis Panageas, Georgios Piliouras. 2017. Multiplicative weights update with constant step-size in congestion games: Convergence, limit cycles and chaos. NIPS \u201917: Proceedings of the 31st International Conference on Neural Information Processing Systems.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Palaiopanos%2C%20Gerasimos%20Panageas%2C%20Ioannis%20Piliouras%2C%20Georgios%20Multiplicative%20weights%20update%20with%20constant%20step-size%20in%20congestion%20games%3A%20Convergence%2C%20limit%20cycles%20and%20chaos.%20NIPS%E2%80%99%2017%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Palaiopanos%2C%20Gerasimos%20Panageas%2C%20Ioannis%20Piliouras%2C%20Georgios%20Multiplicative%20weights%20update%20with%20constant%20step-size%20in%20congestion%20games%3A%20Convergence%2C%20limit%20cycles%20and%20chaos.%20NIPS%E2%80%99%2017%202017"
        },
        {
            "id": "Perkins_2014_a",
            "entry": "Perkins, Steven, David S. Leslie. 2014. Stochastic fictitious play with continuous action sets. Journal of Economic Theory 152 179\u2013213.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perkins%2C%20Steven%20Leslie%2C%20David%20S.%20Stochastic%20fictitious%20play%20with%20continuous%20action%20sets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Perkins%2C%20Steven%20Leslie%2C%20David%20S.%20Stochastic%20fictitious%20play%20with%20continuous%20action%20sets%202014"
        },
        {
            "id": "Perkins_et+al_2017_a",
            "entry": "Perkins, Steven, Panayotis Mertikopoulos, David S. Leslie. 2017. Mixed-strategy learning with continuous action sets. IEEE Trans. Autom. Control 62(1) 379\u2013384.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perkins%2C%20Steven%20Mertikopoulos%2C%20Panayotis%20Leslie%2C%20David%20S.%20Mixed-strategy%20learning%20with%20continuous%20action%20sets%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Perkins%2C%20Steven%20Mertikopoulos%2C%20Panayotis%20Leslie%2C%20David%20S.%20Mixed-strategy%20learning%20with%20continuous%20action%20sets%202017"
        },
        {
            "id": "Rosen_1965_a",
            "entry": "Rosen, J. B. 1965. Existence and uniqueness of equilibrium points for concave N -person games. Econometrica 33(3) 520\u2013534.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosen%2C%20J.B.%20Existence%20and%20uniqueness%20of%20equilibrium%20points%20for%20concave%20N%20-person%20games%201965",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosen%2C%20J.B.%20Existence%20and%20uniqueness%20of%20equilibrium%20points%20for%20concave%20N%20-person%20games%201965"
        },
        {
            "id": "Shamir_2013_a",
            "entry": "Shamir, Ohad. 2013. On the complexity of bandit and derivative-free stochastic convex optimization. COLT \u201913: Proceedings of the 26th Annual Conference on Learning Theory.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shamir%2C%20Ohad%20On%20the%20complexity%20of%20bandit%20and%20derivative-free%20stochastic%20convex%20optimization.%20COLT%E2%80%99%2013%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shamir%2C%20Ohad%20On%20the%20complexity%20of%20bandit%20and%20derivative-free%20stochastic%20convex%20optimization.%20COLT%E2%80%99%2013%202013"
        },
        {
            "id": "Sorin_2016_a",
            "entry": "Sorin, Sylvain, Cheng Wan. 2016. Finite composite games: Equilibria and dynamics. Journal of Dynamics and Games 3(1) 101\u2013120.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sorin%2C%20Sylvain%20Wan%2C%20Cheng%20Finite%20composite%20games%3A%20Equilibria%20and%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sorin%2C%20Sylvain%20Wan%2C%20Cheng%20Finite%20composite%20games%3A%20Equilibria%20and%20dynamics%202016"
        },
        {
            "id": "Spall_1997_a",
            "entry": "Spall, James C. 1997. A one-measurement form of simultaneous perturbation stochastic approximation. Automatica 33(1) 109\u2013112.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spall%2C%20James%20C.%20A%20one-measurement%20form%20of%20simultaneous%20perturbation%20stochastic%20approximation%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Spall%2C%20James%20C.%20A%20one-measurement%20form%20of%20simultaneous%20perturbation%20stochastic%20approximation%201997"
        },
        {
            "id": "Syrgkanis_et+al_2015_a",
            "entry": "Syrgkanis, Vasilis, Alekh Agarwal, Haipeng Luo, Robert E. Schapire. 2015. Fast convergence of regularized learning in games. NIPS \u201915: Proceedings of the 29th International Conference on Neural Information Processing Systems. 2989\u20132997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Syrgkanis%2C%20Vasilis%20Agarwal%2C%20Alekh%20Luo%2C%20Haipeng%20Schapire%2C%20Robert%20E.%20Fast%20convergence%20of%20regularized%20learning%20in%20games.%20NIPS%E2%80%99%2015%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Syrgkanis%2C%20Vasilis%20Agarwal%2C%20Alekh%20Luo%2C%20Haipeng%20Schapire%2C%20Robert%20E.%20Fast%20convergence%20of%20regularized%20learning%20in%20games.%20NIPS%E2%80%99%2015%202015"
        },
        {
            "id": "Viossat_2013_a",
            "entry": "Viossat, Yannick, Andriy Zapechelnyuk. 2013. No-regret dynamics and fictitious play. Journal of Economic Theory 148(2) 825\u2013842.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Viossat%2C%20Yannick%20Zapechelnyuk%2C%20Andriy%20No-regret%20dynamics%20and%20fictitious%20play%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Viossat%2C%20Yannick%20Zapechelnyuk%2C%20Andriy%20No-regret%20dynamics%20and%20fictitious%20play%202013"
        },
        {
            "id": "Zinkevich_2003_a",
            "entry": "Zinkevich, Martin. 2003. Online convex programming and generalized infinitesimal gradient ascent. ICML \u201903: Proceedings of the 20th International Conference on Machine Learning. 928\u2013936.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zinkevich%2C%20Martin%20Online%20convex%20programming%20and%20generalized%20infinitesimal%20gradient%20ascent.%20ICML%E2%80%99%2003%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zinkevich%2C%20Martin%20Online%20convex%20programming%20and%20generalized%20infinitesimal%20gradient%20ascent.%20ICML%E2%80%99%2003%202003"
        }
    ]
}
