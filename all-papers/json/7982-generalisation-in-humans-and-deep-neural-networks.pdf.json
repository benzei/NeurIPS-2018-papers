{
    "filename": "7982-generalisation-in-humans-and-deep-neural-networks.pdf",
    "metadata": {
        "title": "Generalisation in humans and deep neural networks",
        "author": "Robert Geirhos, Carlos R. M. Temme, Jonas Rauber, Heiko H. Sch\u00fctt, Matthias Bethge, Felix A. Wichmann",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7982-generalisation-in-humans-and-deep-neural-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system."
    },
    "keywords": [
        {
            "term": "human visual system",
            "url": "https://en.wikipedia.org/wiki/human_visual_system"
        },
        {
            "term": "deep convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/deep_convolutional_neural_network"
        },
        {
            "term": "Intelligence Advanced Research Projects Activity",
            "url": "https://en.wikipedia.org/wiki/Intelligence_Advanced_Research_Projects_Activity"
        },
        {
            "term": "object recognition",
            "url": "https://en.wikipedia.org/wiki/object_recognition"
        },
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        }
    ],
    "highlights": [
        "Deep neural networks as models of human object recognition<br/><br/>The visual recognition of objects by humans in everyday life is rapid and seemingly effortless, as well as largely independent of viewpoint and object orientation [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>]",
        "We assess how top-performing deep neural networks that are trained on ImageNet, GoogLeNet [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>], VGG19 [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>] and ResNet-152 [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>], compare against human observers when tested on twelve different distortions such as additive noise or phase noise\u2014in other words, how well do they generalise towards previously unseen distortions.2",
        "We developed an experimental paradigm aimed at comparing human observers and deep neural networks as fair as possible by using a forced-choice image categorisation task.3",
        "Achieving a fair psychophysical comparison comes with a number of challenges: First of all, many highperforming deep neural networks are trained on the ILSRVR 2012 database [<a class=\"ref-link\" id=\"c50\" href=\"#r50\">50</a>] with 1,000 fine-grained categories",
        "A second challenge is the fact that standard deep neural networks only use feedforward computations at inference time, while recurrent connections are ubiquitous in the human brain [<a class=\"ref-link\" id=\"c52\" href=\"#r52\">52</a>, <a class=\"ref-link\" id=\"c53\" href=\"#r53\">53</a>].4",
        "In comparison to human observers, we find the classification performance of three well-known deep neural networks trained on ImageNet\u2014ResNet-152, GoogLeNet and VGG19\u2014to decline rapidly with decreasing signal-to-noise ratio under image distortions"
    ],
    "key_statements": [
        "Deep neural networks as models of human object recognition<br/><br/>The visual recognition of objects by humans in everyday life is rapid and seemingly effortless, as well as largely independent of viewpoint and object orientation [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>]",
        "We assess how top-performing deep neural networks that are trained on ImageNet, GoogLeNet [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>], VGG19 [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>] and ResNet-152 [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>], compare against human observers when tested on twelve different distortions such as additive noise or phase noise\u2014in other words, how well do they generalise towards previously unseen distortions.2",
        "We developed an experimental paradigm aimed at comparing human observers and deep neural networks as fair as possible by using a forced-choice image categorisation task.3",
        "Achieving a fair psychophysical comparison comes with a number of challenges: First of all, many highperforming deep neural networks are trained on the ILSRVR 2012 database [<a class=\"ref-link\" id=\"c50\" href=\"#r50\">50</a>] with 1,000 fine-grained categories",
        "A second challenge is the fact that standard deep neural networks only use feedforward computations at inference time, while recurrent connections are ubiquitous in the human brain [<a class=\"ref-link\" id=\"c52\" href=\"#r52\">52</a>, <a class=\"ref-link\" id=\"c53\" href=\"#r53\">53</a>].4",
        "We find that object recognition performance of models B1 to B9 is improved compared to models A1 to A9, both on the distortions they were trained on as well as on a few of the distortions that were not part of the training data",
        "We find that it is possible even for a single model to reach high accuracies on all of the eight distortions it was trained on, for both left-out uniform and salt-and-pepper noise, object recognition accuracy stayed around 11 to 14%, which is by far closer to chance level than to the accuracy reached by a specialised network trained on this exact distortion",
        "In comparison to human observers, we find the classification performance of three well-known deep neural networks trained on ImageNet\u2014ResNet-152, GoogLeNet and VGG19\u2014to decline rapidly with decreasing signal-to-noise ratio under image distortions"
    ],
    "summary": [
        "Deep neural networks as models of human object recognition<br/><br/>The visual recognition of objects by humans in everyday life is rapid and seemingly effortless, as well as largely independent of viewpoint and object orientation [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>].",
        "This has changed, with the advent of brain-inspired deep neural networks (DNNs) which, after having been trained on millions of labeled images, achieve human-level performance when classifying objects in images of natural scenes [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>].",
        "We assess how top-performing DNNs that are trained on ImageNet, GoogLeNet [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>], VGG19 [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>] and ResNet-152 [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>], compare against human observers when tested on twelve different distortions such as additive noise or phase noise\u2014in other words, how well do they generalise towards previously unseen distortions.2 In a second set of experiments, we train networks directly on distorted images to see how well they can in general cope with noisy input, and how much training on distortions as a form of data augmentation helps in dealing with other distortions.",
        "Data from human observers were compared against classification performance of three pre-trained DNNs: VGG-19 [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>], GoogLeNet [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>] and ResNet-152 [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>].",
        "These images at various levels of signal strength were shown to both human observers in a lab and to pre-trained DNNs (ResNet-152, GoogLeNet and VGG-19) for classification.",
        "While human and DNN performance was similar for comparatively minor colour-related distortions such as conversion to greyscale or opponent colours, we find human observers to be more robust for all of the other distortions: by a small margin for low contrast, power equalisation and phase noise images and by a larger margin for uniform noise, low-pass, high-pass, rotation and all three eidolon experiments.",
        "We find that it is possible even for a single model to reach high accuracies on all of the eight distortions it was trained on, for both left-out uniform and salt-and-pepper noise, object recognition accuracy stayed around 11 to 14%, which is by far closer to chance level than to the accuracy reached by a specialised network trained on this exact distortion.",
        "We conducted a behavioural comparison of human and DNN object recognition robustness against twelve different image distortions.",
        "In comparison to human observers, we find the classification performance of three well-known DNNs trained on ImageNet\u2014ResNet-152, GoogLeNet and VGG19\u2014to decline rapidly with decreasing signal-to-noise ratio under image distortions.",
        "We believe that solving this generalisation problem will be crucial both for robust machine inference and towards better models of human object recognition, and we envision that our findings as well as our carefully measured and freely available behavioural data7 may provide a new useful benchmark for improving DNN robustness and a motivation for neuroscientists to identify mechanisms in the brain that may be responsible for this remarkable robustness."
    ],
    "headline": "Using three well known deep neural networks  we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and deep neural networks when the signal gets weaker",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Irving Biederman. Recognition-by-components: a theory of human image understanding. Psychological Review, 94(2):115\u2013147, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Biederman%2C%20Irving%20Recognition-by-components%3A%20a%20theory%20of%20human%20image%20understanding%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Biederman%2C%20Irving%20Recognition-by-components%3A%20a%20theory%20of%20human%20image%20understanding%201987"
        },
        {
            "id": "2",
            "entry": "[2] James J DiCarlo, Davide Zoccolan, and Nicole C Rust. How does the brain solve visual object recognition? Neuron, 73(3):415\u2013434, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=DiCarlo%2C%20James%20J.%20Zoccolan%2C%20Davide%20Rust%2C%20Nicole%20C.%20How%20does%20the%20brain%20solve%20visual%20object%20recognition%3F%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=DiCarlo%2C%20James%20J.%20Zoccolan%2C%20Davide%20Rust%2C%20Nicole%20C.%20How%20does%20the%20brain%20solve%20visual%20object%20recognition%3F%202012"
        },
        {
            "id": "3",
            "entry": "[3] Mary C Potter. Short-term conceptual memory for pictures. Journal of Experimental Psychology: human learning and memory, 2(5):509, 1976.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Potter%2C%20Mary%20C.%20Short-term%20conceptual%20memory%20for%20pictures%201976",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Potter%2C%20Mary%20C.%20Short-term%20conceptual%20memory%20for%20pictures%201976"
        },
        {
            "id": "4",
            "entry": "[4] Simon Thorpe, Denis Fize, and Catherine Marlot. Speed of processing in the human visual system. Nature, 381(6582):520\u2013522, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thorpe%2C%20Simon%20Fize%2C%20Denis%20Marlot%2C%20Catherine%20Speed%20of%20processing%20in%20the%20human%20visual%20system%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thorpe%2C%20Simon%20Fize%2C%20Denis%20Marlot%2C%20Catherine%20Speed%20of%20processing%20in%20the%20human%20visual%20system%201996"
        },
        {
            "id": "5",
            "entry": "[5] Melvyn A. Goodale and A. David Milner. Separate visual pathways for perception and action. Trends in Neurosciences, 15(1):20\u201325, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodale%2C%20Melvyn%20A.%20Milner%2C%20A.David%20Separate%20visual%20pathways%20for%20perception%20and%20action%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodale%2C%20Melvyn%20A.%20Milner%2C%20A.David%20Separate%20visual%20pathways%20for%20perception%20and%20action%201992"
        },
        {
            "id": "6",
            "entry": "[6] A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, pages 1097\u20131105, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "7",
            "entry": "[7] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In Proceedings of the IEEE International Conference on Computer Vision, pages 1026\u20131034, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Delving%20deep%20into%20rectifiers%3A%20Surpassing%20human-level%20performance%20on%20ImageNet%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Delving%20deep%20into%20rectifiers%3A%20Surpassing%20human-level%20performance%20on%20ImageNet%20classification%202015"
        },
        {
            "id": "8",
            "entry": "[8] David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. Mastering the game of Go with deep neural networks and tree search. Nature, 529(7587):484\u2013489, 2016. ISSN 0028-0836.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silver%2C%20David%20Huang%2C%20Aja%20Maddison%2C%20Chris%20J.%20Guez%2C%20Arthur%20Mastering%20the%20game%20of%20Go%20with%20deep%20neural%20networks%20and%20tree%20search%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silver%2C%20David%20Huang%2C%20Aja%20Maddison%2C%20Chris%20J.%20Guez%2C%20Arthur%20Mastering%20the%20game%20of%20Go%20with%20deep%20neural%20networks%20and%20tree%20search%202016"
        },
        {
            "id": "9",
            "entry": "[9] Charles F. Cadieu, H. Hong, D. L. K. Yamins, N. Pinto, D. Ardila, E. A. Solomon, N. J. Majaj, and J. J. DiCarlo. Deep neural networks rival the representation of primate IT cortex for core visual object recognition. PLoS Computational Biology, 10(12), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cadieu%2C%20Charles%20F.%20Hong%2C%20H.%20Yamins%2C%20D.L.K.%20Pinto%2C%20N.%20Deep%20neural%20networks%20rival%20the%20representation%20of%20primate%20IT%20cortex%20for%20core%20visual%20object%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cadieu%2C%20Charles%20F.%20Hong%2C%20H.%20Yamins%2C%20D.L.K.%20Pinto%2C%20N.%20Deep%20neural%20networks%20rival%20the%20representation%20of%20primate%20IT%20cortex%20for%20core%20visual%20object%20recognition%202014"
        },
        {
            "id": "10",
            "entry": "[10] Daniel LK Yamins, Ha Hong, Charles F Cadieu, Ethan A Solomon, Darren Seibert, and James J DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences, 111(23):8619\u20138624, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yamins%2C%20Daniel%20L.K.%20Hong%2C%20Ha%20Charles%20F%20Cadieu%2C%20Ethan%20A%20Solomon%2C%20Darren%20Seibert%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yamins%2C%20Daniel%20L.K.%20Hong%2C%20Ha%20Charles%20F%20Cadieu%2C%20Ethan%20A%20Solomon%2C%20Darren%20Seibert%202014"
        },
        {
            "id": "11",
            "entry": "[11] Radoslaw Martin Cichy, Aditya Khosla, Dimitrios Pantazis, and Aude Oliva. Dynamics of scene representations in the human brain revealed by magnetoencephalography and deep neural networks. NeuroImage, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cichy%2C%20Radoslaw%20Martin%20Khosla%2C%20Aditya%20Pantazis%2C%20Dimitrios%20Oliva%2C%20Aude%20Dynamics%20of%20scene%20representations%20in%20the%20human%20brain%20revealed%20by%20magnetoencephalography%20and%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cichy%2C%20Radoslaw%20Martin%20Khosla%2C%20Aditya%20Pantazis%2C%20Dimitrios%20Oliva%2C%20Aude%20Dynamics%20of%20scene%20representations%20in%20the%20human%20brain%20revealed%20by%20magnetoencephalography%20and%20deep%20neural%20networks%202016"
        },
        {
            "id": "12",
            "entry": "[12] Saeed Reza Kheradpisheh, Masoud Ghodrati, Mohammad Ganjtabesh, and Timoth\u00e9e Masquelier. Deep networks resemble human feed-forward vision in invariant object recognition. arXiv preprint arXiv:1508.03929, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1508.03929"
        },
        {
            "id": "13",
            "entry": "[13] Samuel Dodge and Lina Karam. A study and comparison of human and deep learning recognition performance under visual distortions. arXiv preprint arXiv:1705.02498, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.02498"
        },
        {
            "id": "14",
            "entry": "[14] Samuel Dodge and Lina Karam. Can the early human visual system compete with deep neural networks? arXiv preprint arXiv:1710.04744, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.04744"
        },
        {
            "id": "15",
            "entry": "[15] Ron Dekel. Human perception in computer vision. arXiv preprint arXiv:1701.04674, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.04674"
        },
        {
            "id": "16",
            "entry": "[16] RT Pramod and SP Arun. Do computational models differ systematically from human object perception? In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1601\u20131609, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20RT%20Pramod%20and%20SP%20Arun.%20Do%20computational%20models%20differ%20systematically%20from%20human%20object%20perception%3F%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20RT%20Pramod%20and%20SP%20Arun.%20Do%20computational%20models%20differ%20systematically%20from%20human%20object%20perception%3F%202016"
        },
        {
            "id": "17",
            "entry": "[17] Hamid Karimi-Rouzbahani, Nasour Bagheri, and Reza Ebrahimpour. Invariant object recognition is a personalized selection of invariant features in humans, not simply explained by hierarchical feed-forward vision models. Scientific reports, 7(1):14402, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karimi-Rouzbahani%2C%20Hamid%20Bagheri%2C%20Nasour%20Ebrahimpour%2C%20Reza%20Invariant%20object%20recognition%20is%20a%20personalized%20selection%20of%20invariant%20features%20in%20humans%2C%20not%20simply%20explained%20by%20hierarchical%20feed-forward%20vision%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karimi-Rouzbahani%2C%20Hamid%20Bagheri%2C%20Nasour%20Ebrahimpour%2C%20Reza%20Invariant%20object%20recognition%20is%20a%20personalized%20selection%20of%20invariant%20features%20in%20humans%2C%20not%20simply%20explained%20by%20hierarchical%20feed-forward%20vision%20models%202017"
        },
        {
            "id": "18",
            "entry": "[18] Amir Rosenfeld, Markus D Solbach, and John K Tsotsos. Totally looks like-how humans compare, compared to machines. arXiv preprint arXiv:1803.01485, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.01485"
        },
        {
            "id": "19",
            "entry": "[19] Alban Flachot and Karl R Gegenfurtner. Processing of chromatic information in a deep convolutional neural network. JOSA A, 35(4):B334\u2013B346, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Flachot%2C%20Alban%20Gegenfurtner%2C%20Karl%20R.%20Processing%20of%20chromatic%20information%20in%20a%20deep%20convolutional%20neural%20network%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Flachot%2C%20Alban%20Gegenfurtner%2C%20Karl%20R.%20Processing%20of%20chromatic%20information%20in%20a%20deep%20convolutional%20neural%20network%202018"
        },
        {
            "id": "20",
            "entry": "[20] Thomas SA Wallis, Christina M Funke, Alexander S Ecker, Leon A Gatys, Felix A Wichmann, and Matthias Bethge. A parametric texture model based on deep convolutional features closely matches texture appearance for humans. Journal of vision, 17(12):5\u20135, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wallis%2C%20Thomas%20S.A.%20Funke%2C%20Christina%20M.%20Ecker%2C%20Alexander%20S.%20Leon%20A%20Gatys%2C%20Felix%20A%20Wichmann%2C%20and%20Matthias%20Bethge.%20A%20parametric%20texture%20model%20based%20on%20deep%20convolutional%20features%20closely%20matches%20texture%20appearance%20for%20humans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wallis%2C%20Thomas%20S.A.%20Funke%2C%20Christina%20M.%20Ecker%2C%20Alexander%20S.%20Leon%20A%20Gatys%2C%20Felix%20A%20Wichmann%2C%20and%20Matthias%20Bethge.%20A%20parametric%20texture%20model%20based%20on%20deep%20convolutional%20features%20closely%20matches%20texture%20appearance%20for%20humans%202017"
        },
        {
            "id": "21",
            "entry": "[21] Alexander Berardino, Valero Laparra, Johannes Ball\u00e9, and Eero Simoncelli. Eigen-distortions of hierarchical representations. In Advances in Neural Information Processing Systems, pages 3533\u20133542, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berardino%2C%20Alexander%20Laparra%2C%20Valero%20Ball%C3%A9%2C%20Johannes%20Simoncelli%2C%20Eero%20Eigen-distortions%20of%20hierarchical%20representations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Berardino%2C%20Alexander%20Laparra%2C%20Valero%20Ball%C3%A9%2C%20Johannes%20Simoncelli%2C%20Eero%20Eigen-distortions%20of%20hierarchical%20representations%202017"
        },
        {
            "id": "22",
            "entry": "[22] Kamila M Jozwik, Nikolaus Kriegeskorte, Katherine R Storrs, and Marieke Mur. Deep convolutional neural networks outperform feature-based but not categorical models in explaining object similarity judgments. Frontiers in psychology, 8:1726, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jozwik%2C%20Kamila%20M.%20Kriegeskorte%2C%20Nikolaus%20Storrs%2C%20Katherine%20R.%20Mur%2C%20Marieke%20Deep%20convolutional%20neural%20networks%20outperform%20feature-based%20but%20not%20categorical%20models%20in%20explaining%20object%20similarity%20judgments%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jozwik%2C%20Kamila%20M.%20Kriegeskorte%2C%20Nikolaus%20Storrs%2C%20Katherine%20R.%20Mur%2C%20Marieke%20Deep%20convolutional%20neural%20networks%20outperform%20feature-based%20but%20not%20categorical%20models%20in%20explaining%20object%20similarity%20judgments%202017"
        },
        {
            "id": "23",
            "entry": "[23] Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017"
        },
        {
            "id": "24",
            "entry": "[24] Tim C Kietzmann, Patrick McClure, and Nikolaus Kriegeskorte. Deep neural networks in computational neuroscience. bioRxiv, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kietzmann%2C%20Tim%20C.%20McClure%2C%20Patrick%20Kriegeskorte%2C%20Nikolaus%20Deep%20neural%20networks%20in%20computational%20neuroscience%202017"
        },
        {
            "id": "25",
            "entry": "[25] Rodney J Douglas and Kevan A C Martin. Opening the grey box. Trends in Neurosciences, 14(7):286\u2013293, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Douglas%2C%20Rodney%20J.%20Martin%2C%20Kevan%20A.C.%20Opening%20the%20grey%20box%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Douglas%2C%20Rodney%20J.%20Martin%2C%20Kevan%20A.C.%20Opening%20the%20grey%20box%201991"
        },
        {
            "id": "26",
            "entry": "[26] George E P Box. Science and statistics. Journal of the American Statistical Association, 71(356):791\u2013799, 1976.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=George%20E%20P%20Box%20Science%20and%20statistics%20Journal%20of%20the%20American%20Statistical%20Association%2071356791799%201976",
            "oa_query": "https://api.scholarcy.com/oa_version?query=George%20E%20P%20Box%20Science%20and%20statistics%20Journal%20of%20the%20American%20Statistical%20Association%2071356791799%201976"
        },
        {
            "id": "27",
            "entry": "[27] Nikolaus Kriegeskorte. Deep neural networks: A new framework for modeling biological vision and brain information processing. Annual Review of Vision Science, 1(15):417\u2013446, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kriegeskorte%2C%20Nikolaus%20Deep%20neural%20networks%3A%20A%20new%20framework%20for%20modeling%20biological%20vision%20and%20brain%20information%20processing%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kriegeskorte%2C%20Nikolaus%20Deep%20neural%20networks%3A%20A%20new%20framework%20for%20modeling%20biological%20vision%20and%20brain%20information%20processing%202015"
        },
        {
            "id": "28",
            "entry": "[28] Zhiyuan Chen and Bing Liu. Lifelong Machine Learning. Morgan & Claypool Publishers, 2016. ISBN 1627055010, 9781627055017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Zhiyuan%20Liu%2C%20Bing%20Lifelong%20Machine%20Learning%202016"
        },
        {
            "id": "29",
            "entry": "[29] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.03530"
        },
        {
            "id": "30",
            "entry": "[30] Kenji Kawaguchi, Leslie Pack Kaelbling, and Yoshua Bengio. Generalization in deep learning. arXiv preprint arXiv:1710.05468, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.05468"
        },
        {
            "id": "31",
            "entry": "[31] Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro. Exploring generalization in deep learning. In Advances in Neural Information Processing Systems, pages 5949\u20135958, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neyshabur%2C%20Behnam%20Bhojanapalli%2C%20Srinadh%20McAllester%2C%20David%20Srebro%2C%20Nati%20Exploring%20generalization%20in%20deep%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neyshabur%2C%20Behnam%20Bhojanapalli%2C%20Srinadh%20McAllester%2C%20David%20Srebro%2C%20Nati%20Exploring%20generalization%20in%20deep%20learning%202017"
        },
        {
            "id": "32",
            "entry": "[32] Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00810"
        },
        {
            "id": "33",
            "entry": "[33] Matthias K\u00fcmmerer, Thomas SA Wallis, and Matthias Bethge. Deepgaze II: Reading fixations from deep features trained on object recognition. arXiv preprint arXiv:1610.01563, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.01563"
        },
        {
            "id": "34",
            "entry": "[34] Hong-Wei Ng, Viet Dung Nguyen, Vassilios Vonikakis, and Stefan Winkler. Deep learning for emotion recognition on small datasets using transfer learning. In Proceedings of the 2015 ACM on international conference on multimodal interaction, pages 443\u2013449. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ng%2C%20Hong-Wei%20Nguyen%2C%20Viet%20Dung%20Vonikakis%2C%20Vassilios%20Winkler%2C%20Stefan%20Deep%20learning%20for%20emotion%20recognition%20on%20small%20datasets%20using%20transfer%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ng%2C%20Hong-Wei%20Nguyen%2C%20Viet%20Dung%20Vonikakis%2C%20Vassilios%20Winkler%2C%20Stefan%20Deep%20learning%20for%20emotion%20recognition%20on%20small%20datasets%20using%20transfer%20learning%202015"
        },
        {
            "id": "35",
            "entry": "[35] Hayit Greenspan, Bram van Ginneken, and Ronald M Summers. Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique. IEEE Transactions on Medical Imaging, 35(5):1153\u20131159, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Greenspan%2C%20Hayit%20van%20Ginneken%2C%20Bram%20Summers%2C%20Ronald%20M.%20Guest%20editorial%20deep%20learning%20in%20medical%20imaging%3A%20Overview%20and%20future%20promise%20of%20an%20exciting%20new%20technique%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Greenspan%2C%20Hayit%20van%20Ginneken%2C%20Bram%20Summers%2C%20Ronald%20M.%20Guest%20editorial%20deep%20learning%20in%20medical%20imaging%3A%20Overview%20and%20future%20promise%20of%20an%20exciting%20new%20technique%202016"
        },
        {
            "id": "36",
            "entry": "[36] Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In International conference on machine learning, pages 647\u2013655, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20Jeff%20Jia%2C%20Yangqing%20Vinyals%2C%20Oriol%20Hoffman%2C%20Judy%20Ning%20Zhang%2C%20Eric%20Tzeng%2C%20and%20Trevor%20Darrell.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20Jeff%20Jia%2C%20Yangqing%20Vinyals%2C%20Oriol%20Hoffman%2C%20Judy%20Ning%20Zhang%2C%20Eric%20Tzeng%2C%20and%20Trevor%20Darrell.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202014"
        },
        {
            "id": "37",
            "entry": "[37] Sebastian Thrun. Is learning the n-th thing any easier than learning the first? In Advances in Neural Information Processing Systems, pages 640\u2013646. The MIT Press, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thrun%2C%20Sebastian%20Is%20learning%20the%20n-th%20thing%20any%20easier%20than%20learning%20the%20first%3F%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thrun%2C%20Sebastian%20Is%20learning%20the%20n-th%20thing%20any%20easier%20than%20learning%20the%20first%3F%201996"
        },
        {
            "id": "38",
            "entry": "[38] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1\u20139, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "39",
            "entry": "[39] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "40",
            "entry": "[40] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "41",
            "entry": "[41] Robert Geirhos, David HJ Janssen, Heiko H Sch\u00fctt, Jonas Rauber, Matthias Bethge, and Felix A Wichmann. Comparing deep neural networks against humans: object recognition when the signal gets weaker. arXiv preprint arXiv:1706.06969, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.06969"
        },
        {
            "id": "42",
            "entry": "[42] Jacob Nachmias and R V Sansbury. Grating contrast: Discrimination may be better than detection. Vision Research, 14(10):1039\u20131042, 1974.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nachmias%2C%20Jacob%20Sansbury%2C%20R.V.%20Grating%20contrast%3A%20Discrimination%20may%20be%20better%20than%20detection%201974",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nachmias%2C%20Jacob%20Sansbury%2C%20R.V.%20Grating%20contrast%3A%20Discrimination%20may%20be%20better%20than%20detection%201974"
        },
        {
            "id": "43",
            "entry": "[43] Denis G Pelli and Bart Farell. Why use noise? Journal of the Optical Society of America A, 16(3):647\u2013653, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pelli%2C%20Denis%20G.%20Farell%2C%20Bart%20Why%20use%20noise%3F%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pelli%2C%20Denis%20G.%20Farell%2C%20Bart%20Why%20use%20noise%3F%201999"
        },
        {
            "id": "44",
            "entry": "[44] Felix A Wichmann. Some Aspects of Modelling Human Spatial Vision: Contrast Discrimination. PhD thesis, The University of Oxford, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wichmann%2C%20Felix%20A.%20Some%20Aspects%20of%20Modelling%20Human%20Spatial%20Vision%3A%20Contrast%20Discrimination%201999"
        },
        {
            "id": "45",
            "entry": "[45] G Bruce Henning, C M Bird, and Felix A Wichmann. Contrast discrimination with pulse trains in pink noise. Journal of the Optical Society of America A, 19(7):1259\u20131266, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henning%2C%20G.Bruce%20Bird%2C%20C.M.%20Wichmann%2C%20Felix%20A.%20Contrast%20discrimination%20with%20pulse%20trains%20in%20pink%20noise%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Henning%2C%20G.Bruce%20Bird%2C%20C.M.%20Wichmann%2C%20Felix%20A.%20Contrast%20discrimination%20with%20pulse%20trains%20in%20pink%20noise%202002"
        },
        {
            "id": "46",
            "entry": "[46] Matteo Carandini and David J Heeger. Normalization as a canonical neural computation. Nature Reviews Neuroscience, 13(1):51\u201362, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carandini%2C%20Matteo%20Heeger%2C%20David%20J.%20Normalization%20as%20a%20canonical%20neural%20computation%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carandini%2C%20Matteo%20Heeger%2C%20David%20J.%20Normalization%20as%20a%20canonical%20neural%20computation%202012"
        },
        {
            "id": "47",
            "entry": "[47] Matteo Carandini, David J Heeger, and J Anthony Movshon. Linearity and normalization in simple cells of the macaque primary visual cortex. The Journal of Neuroscience, 17(21):8621\u20138644, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carandini%2C%20Matteo%20Heeger%2C%20David%20J.%20Movshon%2C%20J.Anthony%20Linearity%20and%20normalization%20in%20simple%20cells%20of%20the%20macaque%20primary%20visual%20cortex%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carandini%2C%20Matteo%20Heeger%2C%20David%20J.%20Movshon%2C%20J.Anthony%20Linearity%20and%20normalization%20in%20simple%20cells%20of%20the%20macaque%20primary%20visual%20cortex%201997"
        },
        {
            "id": "48",
            "entry": "[48] Arnaud Delorme, Guillaume Richard, and Michele Fabre-Thorpe. Ultra-rapid categorisation of natural scenes does not rely on colour cues: a study in monkeys and humans. Vision Research, 40(16):2187\u20132200, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Delorme%2C%20Arnaud%20Richard%2C%20Guillaume%20Fabre-Thorpe%2C%20Michele%20Ultra-rapid%20categorisation%20of%20natural%20scenes%20does%20not%20rely%20on%20colour%20cues%3A%20a%20study%20in%20monkeys%20and%20humans%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Delorme%2C%20Arnaud%20Richard%2C%20Guillaume%20Fabre-Thorpe%2C%20Michele%20Ultra-rapid%20categorisation%20of%20natural%20scenes%20does%20not%20rely%20on%20colour%20cues%3A%20a%20study%20in%20monkeys%20and%20humans%202000"
        },
        {
            "id": "49",
            "entry": "[49] Felix A Wichmann, David HJ Janssen, Robert Geirhos, Guillermo Aguilar, Heiko H Sch\u00fctt, Marianne Maertens, and Matthias Bethge. Methods and measurements to compare men against machines. Electronic Imaging, Human Vision and Electronic Imaging, 2017(14):36\u201345, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wichmann%2C%20Felix%20A.%20Janssen%2C%20David%20H.J.%20Geirhos%2C%20Robert%20Aguilar%2C%20Guillermo%20Methods%20and%20measurements%20to%20compare%20men%20against%20machines%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wichmann%2C%20Felix%20A.%20Janssen%2C%20David%20H.J.%20Geirhos%2C%20Robert%20Aguilar%2C%20Guillermo%20Methods%20and%20measurements%20to%20compare%20men%20against%20machines%202017"
        },
        {
            "id": "50",
            "entry": "[50] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20ImageNet%20Large%20Scale%20Visual%20Recognition%20Challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20ImageNet%20Large%20Scale%20Visual%20Recognition%20Challenge%202015"
        },
        {
            "id": "51",
            "entry": "[51] George A Miller. Wordnet: a lexical database for English. Communications of the ACM, 38(11):39\u201341, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20George%20A%20Miller.%20Wordnet%3A%20a%20lexical%20database%20for%20English%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20George%20A%20Miller.%20Wordnet%3A%20a%20lexical%20database%20for%20English%201995"
        },
        {
            "id": "52",
            "entry": "[52] Victor AF Lamme, Hans Super, and Henk Spekreijse. Feedforward, horizontal, and feedback processing in the visual cortex. Current opinion in neurobiology, 8(4):529\u2013535, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lamme%2C%20Victor%20A.F.%20Super%2C%20Hans%20Feedforward%2C%20Henk%20Spekreijse%20horizontal%20and%20feedback%20processing%20in%20the%20visual%20cortex%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lamme%2C%20Victor%20A.F.%20Super%2C%20Hans%20Feedforward%2C%20Henk%20Spekreijse%20horizontal%20and%20feedback%20processing%20in%20the%20visual%20cortex%201998"
        },
        {
            "id": "53",
            "entry": "[53] Olaf Sporns and Jonathan D Zwi. The small world of the cerebral cortex. Neuroinformatics, 2(2):145\u2013162, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sporns%2C%20Olaf%20Zwi%2C%20Jonathan%20D.%20The%20small%20world%20of%20the%20cerebral%20cortex%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sporns%2C%20Olaf%20Zwi%2C%20Jonathan%20D.%20The%20small%20world%20of%20the%20cerebral%20cortex%202004"
        },
        {
            "id": "54",
            "entry": "[54] Wulfram Gerstner. How can the brain be so fast? In J. Leo van Hemmen and Terrence J Sejnowski, editors, 23 Problems in Systems Neuroscience, pages 135\u2013142. Oxford University Press, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gerstner%2C%20Wulfram%20How%20can%20the%20brain%20be%20so%20fast%3F%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gerstner%2C%20Wulfram%20How%20can%20the%20brain%20be%20so%20fast%3F%202005"
        },
        {
            "id": "55",
            "entry": "[55] Jonas Kubilius, Stefania Bracci, and Hans P Op de Beeck. Deep neural networks as a computational model for human shape sensitivity. PLoS Computational Biology, 12(4):e1004896, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kubilius%2C%20Jonas%20Bracci%2C%20Stefania%20de%20Beeck%2C%20Hans%20P.Op%20Deep%20neural%20networks%20as%20a%20computational%20model%20for%20human%20shape%20sensitivity%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kubilius%2C%20Jonas%20Bracci%2C%20Stefania%20de%20Beeck%2C%20Hans%20P.Op%20Deep%20neural%20networks%20as%20a%20computational%20model%20for%20human%20shape%20sensitivity%202016"
        },
        {
            "id": "56",
            "entry": "[56] Felix A Wichmann, Doris I Braun, and Karl R Gegenfurtner. Phase noise and the classification of natural images. Vision Research, 46(8):1520\u20131529, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wichmann%2C%20Felix%20A.%20Braun%2C%20Doris%20I.%20Gegenfurtner%2C%20Karl%20R.%20Phase%20noise%20and%20the%20classification%20of%20natural%20images%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wichmann%2C%20Felix%20A.%20Braun%2C%20Doris%20I.%20Gegenfurtner%2C%20Karl%20R.%20Phase%20noise%20and%20the%20classification%20of%20natural%20images%202006"
        },
        {
            "id": "57",
            "entry": "[57] Jan Koenderink, Matteo Valsecchi, Andrea van Doorn, Johan Wagemans, and Karl Gegenfurtner. Eidolons: Novel stimuli for vision research. Journal of Vision, 17(2):7\u20137, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koenderink%2C%20Jan%20Valsecchi%2C%20Matteo%20van%20Doorn%2C%20Andrea%20Wagemans%2C%20Johan%20Eidolons%3A%20Novel%20stimuli%20for%20vision%20research%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koenderink%2C%20Jan%20Valsecchi%2C%20Matteo%20van%20Doorn%2C%20Andrea%20Wagemans%2C%20Johan%20Eidolons%3A%20Novel%20stimuli%20for%20vision%20research%202017"
        },
        {
            "id": "58",
            "entry": "[58] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv preprint arXiv:1603.04467, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.04467"
        },
        {
            "id": "59",
            "entry": "[59] I. Vasiljevic, A. Chakrabarti, and G. Shakhnarovich. Examining the Impact of Blur on Recognition by Convolutional Networks. arXiv preprint arXiv:1611.05760, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.05760"
        },
        {
            "id": "60",
            "entry": "[60] Samuel Dodge and Lina Karam. Understanding how image quality affects deep neural networks. In Quality of Multimedia Experience (QoMEX), 2016 Eighth International Conference on, pages 1\u20136. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dodge%2C%20Samuel%20Karam%2C%20Lina%20Understanding%20how%20image%20quality%20affects%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dodge%2C%20Samuel%20Karam%2C%20Lina%20Understanding%20how%20image%20quality%20affects%20deep%20neural%20networks%202016"
        },
        {
            "id": "61",
            "entry": "[61] Yiren Zhou, Sibo Song, and Ngai-Man Cheung. On classification of distorted images with deep convolutional neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, pages 1213\u20131217. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Yiren%20Song%2C%20Sibo%20Cheung%2C%20Ngai-Man%20On%20classification%20of%20distorted%20images%20with%20deep%20convolutional%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20Yiren%20Song%2C%20Sibo%20Cheung%2C%20Ngai-Man%20On%20classification%20of%20distorted%20images%20with%20deep%20convolutional%20neural%20networks%202017"
        },
        {
            "id": "62",
            "entry": "[62] David H Wolpert and William G Macready. No free lunch theorems for optimization. IEEE transactions on evolutionary computation, 1(1):67\u201382, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wolpert%2C%20David%20H.%20Macready%2C%20William%20G.%20No%20free%20lunch%20theorems%20for%20optimization%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wolpert%2C%20David%20H.%20Macready%2C%20William%20G.%20No%20free%20lunch%20theorems%20for%20optimization%201997"
        },
        {
            "id": "63",
            "entry": "[63] Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53\u201369, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Patel%2C%20Vishal%20M.%20Gopalan%2C%20Raghuraman%20Li%2C%20Ruonan%20Chellappa%2C%20Rama%20Visual%20domain%20adaptation%3A%20A%20survey%20of%20recent%20advances%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Patel%2C%20Vishal%20M.%20Gopalan%2C%20Raghuraman%20Li%2C%20Ruonan%20Chellappa%2C%20Rama%20Visual%20domain%20adaptation%3A%20A%20survey%20of%20recent%20advances%202015"
        },
        {
            "id": "64",
            "entry": "[64] Heiko H Sch\u00fctt and Felix A Wichmann. An image-computable psychophysical spatial vision model. Journal of vision, 17(12):12\u201312, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sch%C3%BCtt%2C%20Heiko%20H.%20Wichmann%2C%20Felix%20A.%20An%20image-computable%20psychophysical%20spatial%20vision%20model%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sch%C3%BCtt%2C%20Heiko%20H.%20Wichmann%2C%20Felix%20A.%20An%20image-computable%20psychophysical%20spatial%20vision%20model%202017"
        },
        {
            "id": "65",
            "entry": "[65] Kevin Jarrett, Koray Kavukcuoglu, Yann LeCun, et al. What is the best multi-stage architecture for object recognition? In Computer Vision, 2009 IEEE 12th International Conference on, pages 2146\u20132153. IEEE, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jarrett%2C%20Kevin%20Kavukcuoglu%2C%20Koray%20LeCun%2C%20Yann%20What%20is%20the%20best%20multi-stage%20architecture%20for%20object%20recognition%3F%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jarrett%2C%20Kevin%20Kavukcuoglu%2C%20Koray%20LeCun%2C%20Yann%20What%20is%20the%20best%20multi-stage%20architecture%20for%20object%20recognition%3F%202009"
        },
        {
            "id": "66",
            "entry": "[66] Mengye Ren, Renjie Liao, Raquel Urtasun, Fabian H Sinz, and Richard S Zemel. Normalizing the normalizers: Comparing and extending network normalization schemes. arXiv preprint arXiv:1611.04520, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.04520"
        },
        {
            "id": "67",
            "entry": "[67] R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria, 2016. URL https://www.R-project.org/.",
            "url": "https://www.R-project.org/",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Team%2C%20R.Core%20R%3A%20A%20Language%20and%20Environment%20for%20Statistical%20Computing%202016"
        },
        {
            "id": "68",
            "entry": "[68] David H Brainard. The psychophysics toolbox. Spatial Vision, 10:433\u2013436, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brainard%2C%20David%20H.%20The%20psychophysics%20toolbox%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brainard%2C%20David%20H.%20The%20psychophysics%20toolbox%201997"
        },
        {
            "id": "69",
            "entry": "[69] Mario Kleiner, David Brainard, Denis Pelli, Allen Ingling, Richard Murray, and Christopher Broussard. Perception, 36(14):1, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mario%20Kleiner%20David%20Brainard%20Denis%20Pelli%20Allen%20Ingling%20Richard%20Murray%20and%20Christopher%20Broussard%20Perception%2036141%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mario%20Kleiner%20David%20Brainard%20Denis%20Pelli%20Allen%20Ingling%20Richard%20Murray%20and%20Christopher%20Broussard%20Perception%2036141%202007"
        },
        {
            "id": "70",
            "entry": "[70] Eleanor Rosch. Principles of categorization. Concepts: core readings, 189, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosch%2C%20Eleanor%20Principles%20of%20categorization.%20Concepts%3A%20core%20readings%201999"
        },
        {
            "id": "71",
            "entry": "[71] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In European Conference on Computer Vision, pages 740\u2013755.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=TsungYi%20Lin%20Michael%20Maire%20Serge%20Belongie%20James%20Hays%20Pietro%20Perona%20Deva%20Ramanan%20Piotr%20Doll%C3%A1r%20and%20C%20Lawrence%20Zitnick%20Microsoft%20COCO%20Common%20objects%20in%20context%20In%20European%20Conference%20on%20Computer%20Vision%20pages%20740755",
            "oa_query": "https://api.scholarcy.com/oa_version?query=TsungYi%20Lin%20Michael%20Maire%20Serge%20Belongie%20James%20Hays%20Pietro%20Perona%20Deva%20Ramanan%20Piotr%20Doll%C3%A1r%20and%20C%20Lawrence%20Zitnick%20Microsoft%20COCO%20Common%20objects%20in%20context%20In%20European%20Conference%20on%20Computer%20Vision%20pages%20740755"
        },
        {
            "id": "72",
            "entry": "[72] Stefan Van der Walt, Johannes L Sch\u00f6nberger, Juan Nunez-Iglesias, Fran\u00e7ois Boulogne, Joshua D Warner, Neil Yager, Emmanuelle Gouillart, and Tony Yu. scikit-image: image processing in Python. PeerJ, 2:e453, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=der%20Walt%2C%20Stefan%20Van%20Sch%C3%B6nberger%2C%20Johannes%20L.%20Nunez-Iglesias%2C%20Juan%20Boulogne%2C%20Fran%C3%A7ois%20scikit-image%3A%20image%20processing%20in%20Python%202014"
        },
        {
            "id": "73",
            "entry": "[73] A. M. Derrington, J. Krauskopf, and P. Lennie. Chromatic mechanisms in lateral geniculate nucleus of macaque. The Journal of Physiology, 357:241\u2013265, 1984.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Derrington%2C%20A.M.%20Krauskopf%2C%20J.%20Lennie%2C%20P.%20Chromatic%20mechanisms%20in%20lateral%20geniculate%20nucleus%20of%20macaque%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Derrington%2C%20A.M.%20Krauskopf%2C%20J.%20Lennie%2C%20P.%20Chromatic%20mechanisms%20in%20lateral%20geniculate%20nucleus%20of%20macaque%201984"
        },
        {
            "id": "74",
            "entry": "[74] Andrew Stockman and Lindsay T Sharpe. The spectral sensitivities of the middle-and long-wavelengthsensitive cones derived from measurements in observers of known genotype. Vision research, 40(13): 1711\u20131737, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stockman%2C%20Andrew%20Sharpe%2C%20Lindsay%20T.%20The%20spectral%20sensitivities%20of%20the%20middle-and%20long-wavelengthsensitive%20cones%20derived%20from%20measurements%20in%20observers%20of%20known%20genotype%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stockman%2C%20Andrew%20Sharpe%2C%20Lindsay%20T.%20The%20spectral%20sensitivities%20of%20the%20middle-and%20long-wavelengthsensitive%20cones%20derived%20from%20measurements%20in%20observers%20of%20known%20genotype%202000"
        },
        {
            "id": "75",
            "entry": "[75] David H Brainard. Human color vision, chapter Cone Contrast and Opponent Modulation Color Spaces. Optical Society of America, Washington, DC, 2 edition, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brainard%2C%20David%20H.%20Human%20color%20vision%2C%20chapter%20Cone%20Contrast%20and%20Opponent%20Modulation%20Color%20Spaces.%20Optical%20Society%20of%20America%201996"
        },
        {
            "id": "76",
            "entry": "[76] A. van der Schaaf and J.H. van Hateren. Modelling the power spectra of natural images: Statistics and information. Vision Research, 36(17):2759 \u2013 2770, 1996. ISSN 0042-6989. doi: http://dx.doi.org/10.1016/0042-6989(96)00002-8.",
            "crossref": "https://dx.doi.org/10.1016/0042-6989(96)00002-8",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/0042-6989%2896%2900002-8"
        },
        {
            "id": "77",
            "entry": "[77] Felix A Wichmann, Jan Drewes, Pedro Rosas, and Karl R Gegenfurtner. Animal detection in natural scenes: Critical features revisited. Journal of Vision, 10(4:6):1\u201327, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wichmann%2C%20Felix%20A.%20Drewes%2C%20Jan%20Rosas%2C%20Pedro%20Gegenfurtner%2C%20Karl%20R.%20Animal%20detection%20in%20natural%20scenes%3A%20Critical%20features%20revisited%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wichmann%2C%20Felix%20A.%20Drewes%2C%20Jan%20Rosas%2C%20Pedro%20Gegenfurtner%2C%20Karl%20R.%20Animal%20detection%20in%20natural%20scenes%3A%20Critical%20features%20revisited%202010"
        },
        {
            "id": "78",
            "entry": "[78] Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pages 1050\u20131059, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Dropout%20as%20a%20Bayesian%20approximation%3A%20Representing%20model%20uncertainty%20in%20deep%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Dropout%20as%20a%20Bayesian%20approximation%3A%20Representing%20model%20uncertainty%20in%20deep%20learning%202016"
        }
    ]
}
