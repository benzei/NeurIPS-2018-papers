{
    "filename": "7897-incorporating-context-into-language-encoding-models-for-fmri.pdf",
    "metadata": {
        "title": "Incorporating Context into Language Encoding Models for fMRI",
        "author": "Shailee Jain, Alexander Huth",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7897-incorporating-context-into-language-encoding-models-for-fmri.pdf",
            "doi": "10.1101/327601"
        },
        "abstract": "Language encoding models help explain language processing in the human brain by learning functions that predict brain responses from the language stimuli that elicited them. Current word embedding-based approaches treat each stimulus word independently and thus ignore the influence of context on language understanding. In this work, we instead build encoding models using rich contextual representations derived from an LSTM language model. Our models show a significant improvement in encoding performance relative to state-of-the-art embeddings in nearly every brain area. By varying the amount of context used in the models and providing the models with distorted context, we show that this improvement is due to a combination of better word embeddings learned by the LSTM language model and contextual information. We are also able to use our models to map context sensitivity across the cortex. These results suggest that LSTM language models learn high-level representations that are related to representations in the human brain."
    },
    "keywords": [
        {
            "term": "language processing",
            "url": "https://en.wikipedia.org/wiki/language_processing"
        },
        {
            "term": "auditory cortex",
            "url": "https://en.wikipedia.org/wiki/auditory_cortex"
        },
        {
            "term": "Standard error of the mean",
            "url": "https://en.wikipedia.org/wiki/Standard_error_of_the_mean"
        },
        {
            "term": "temporo-parietal junction",
            "url": "https://en.wikipedia.org/wiki/temporo-parietal_junction"
        },
        {
            "term": "long short-term memory",
            "url": "https://en.wikipedia.org/wiki/long_short-term_memory"
        },
        {
            "term": "language model",
            "url": "https://en.wikipedia.org/wiki/language_model"
        },
        {
            "term": "natural speech",
            "url": "https://en.wikipedia.org/wiki/natural_speech"
        },
        {
            "term": "high level",
            "url": "https://en.wikipedia.org/wiki/high_level"
        },
        {
            "term": "finite impulse response",
            "url": "https://en.wikipedia.org/wiki/finite_impulse_response"
        },
        {
            "term": "functional magnetic resonance imaging",
            "url": "https://en.wikipedia.org/wiki/functional_magnetic_resonance_imaging"
        },
        {
            "term": "Texas Advanced Computing Center",
            "url": "https://en.wikipedia.org/wiki/Texas_Advanced_Computing_Center"
        },
        {
            "term": "LSTM",
            "url": "https://en.wikipedia.org/wiki/LSTM"
        }
    ],
    "highlights": [
        "To extract meaning from natural speech, the human brain combines information about each word with previous words, or context",
        "One powerful tool for mapping cortical representations is encoding models, which use features extracted from stimuli to predict brain responses recorded with functional magnetic resonance imaging",
        "Previous language encoding studies have successfully mapped word-level semantic representations using embedding vectors (15; 22; 9; 8), but this approach neglects the effect of context by assuming that the response to each word is independent",
        "We use representations discovered by an long short-term memory language models to incorporate context into encoding models that predict functional magnetic resonance imaging responses to natural, narrative speech (Figure 1)",
        "Encoding models that use word embeddings have proven quite successful at predicting brain responses to both single words (15; 25) and continuous language (22; 9; 8; 17)",
        "We show how our models explain the differences in language processing across different cortical regions, from low-level to high-level language areas"
    ],
    "key_statements": [
        "To extract meaning from natural speech, the human brain combines information about each word with previous words, or context",
        "One powerful tool for mapping cortical representations is encoding models, which use features extracted from stimuli to predict brain responses recorded with functional magnetic resonance imaging",
        "Previous language encoding studies have successfully mapped word-level semantic representations using embedding vectors (15; 22; 9; 8), but this approach neglects the effect of context by assuming that the response to each word is independent",
        "We use representations discovered by an long short-term memory language models to incorporate context into encoding models that predict functional magnetic resonance imaging responses to natural, narrative speech (Figure 1)",
        "Encoding models that use word embeddings have proven quite successful at predicting brain responses to both single words (15; 25) and continuous language (22; 9; 8; 17)",
        "After training the long short-term memory language models, we evaluate its performance using S as a test set",
        "After fitting the 60 contextual encoding models and a baseline embedding model from [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], we evaluate model performance by predicting functional magnetic resonance imaging responses on a test dataset comprising one 10-minute story",
        "We show how our models explain the differences in language processing across different cortical regions, from low-level to high-level language areas"
    ],
    "summary": [
        "To extract meaning from natural speech, the human brain combines information about each word with previous words, or context.",
        "One powerful tool for mapping cortical representations is encoding models, which use features extracted from stimuli to predict brain responses recorded with fMRI.",
        "Previous language encoding studies have successfully mapped word-level semantic representations using embedding vectors (15; 22; 9; 8), but this approach neglects the effect of context by assuming that the response to each word is independent.",
        "We use representations discovered by an LSTM LM to incorporate context into encoding models that predict fMRI responses to natural, narrative speech (Figure 1).",
        "We compare the effectiveness of models that use different LSTM layers and context lengths.",
        "Our LSTM-based contextual encoding models not only outperform the best hand-designed feature spaces for language encoding, but provide insights into the representation of linguistic context in the cortex.",
        "The state-of-the-art language encoding model [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] uses a word embedding space that represents each word wi as a 985-dimensional vector ei.",
        "Encoding models that use word embeddings have proven quite successful at predicting brain responses to both single words (15; 25) and continuous language (22; 9; 8; 17).",
        "For the input representations ei, we use the 985-dimensional word embedding from the state-of-the-art encoding model [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>].",
        "Our LSTM LM uses information from up to M = 20 previous words to construct L = 3 separate context representations.",
        "We evaluate the performance of our contextual encoding models against the state-of-the-art embedding-based model and examine the effect of using different context layers and lengths.",
        "We examine which brain areas are best fit by different context lengths and layers, revealing a temporal hierarchy in the human language processing system.",
        "After fitting the 60 contextual encoding models and a baseline embedding model from [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], we evaluate model performance by predicting fMRI responses on a test dataset comprising one 10-minute story.",
        "Model performance plateaus after 10-15 words, suggesting that the LSTM LM was unable to successfully incorporate contextual information beyond this timescale.",
        "Models with zero context length use no contextual information and are nonlinear transformations of the input embedding.",
        "The best model for each layer uses the longest context, suggesting that contextual information is important above and beyond the improved embedding.",
        "We observe that representations outperform state-of-the-art embedding based models and show distinct behavior across different context lengths and LSTM layers.",
        "We would like to explore and understand the information captured in the contextual representations that helps to model language processing in the cortex.",
        "We show how our models explain the differences in language processing across different cortical regions, from low-level to high-level language areas"
    ],
    "headline": "By varying the amount of context used in the models and providing the models with distorted context, we show that this improvement is due to a combination of better word embeddings learned by the long short-term memory language model and contextual information",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., Zheng, X.: Tensorflow: A system for large-scale machine learning. In: Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation. pp. 265\u2013283. OSDI\u201916, USENIX Association, Berkeley, CA, USA (2016), http://dl.acm.org/citation.cfm?id=3026877.3026899",
            "url": "http://dl.acm.org/citation.cfm?id=3026877.3026899",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20X.%3A%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016"
        },
        {
            "id": "2",
            "entry": "[2] Agrawal, P., Stansbury, D., Malik, J., Gallant, J.L.: Pixels to voxels: Modeling visual representation in the human brain. CoRR abs/1407.5104 (2014)",
            "arxiv_url": "https://arxiv.org/pdf/1407.5104"
        },
        {
            "id": "3",
            "entry": "[3] Baldassano, C., Chen, J., Zadbood, A., Pillow, J.W., Hasson, U., Norman, K.A.: Discovering event structure in continuous narrative perception and memory. Neuron 95(3), 709 \u2013 721.e5 (2017), http://www.sciencedirect.com/science/article/pii/S0896627317305937",
            "url": "http://www.sciencedirect.com/science/article/pii/S0896627317305937",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baldassano%2C%20C.%20Chen%2C%20J.%20Zadbood%2C%20A.%20Pillow%2C%20J.W.%20A.%3A%20Discovering%20event%20structure%20in%20continuous%20narrative%20perception%20and%20memory%202017"
        },
        {
            "id": "4",
            "entry": "[4] Bengio, Y., Ducharme, R., Vincent, P., Janvin, C.: A neural probabilistic language model. J. Mach. Learn. Res. 3, 1137\u20131155 (Mar 2003), http://dl.acm.org/citation.cfm?id=944919.944966",
            "url": "http://dl.acm.org/citation.cfm?id=944919.944966",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Y.%20Ducharme%2C%20R.%20Vincent%2C%20P.%20Janvin%20C.%3A%20A%20neural%20probabilistic%20language%20model%202003-03"
        },
        {
            "id": "5",
            "entry": "[5] Eickenberg, M., Gramfort, A., Varoquaux, G., Thirion, B.: Seeing it all: Convolutional network layers map the function of the human visual system. NeuroImage 152(Supplement C), 184 \u2013 194 (2017), http://www.sciencedirect.com/science/article/pii/S1053811916305481",
            "url": "http://www.sciencedirect.com/science/article/pii/S1053811916305481",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eickenberg%2C%20M.%20Gramfort%2C%20A.%20Varoquaux%2C%20G.%20Thirion%20B.%3A%20Seeing%20it%20all%3A%20Convolutional%20network%20layers%20map%20the%20function%20of%20the%20human%20visual%20system%202017"
        },
        {
            "id": "6",
            "entry": "[6] Gao, J.S., Huth, A.G., Lescroart, M.D., Gallant, J.L.: Pycortex: an interactive surface visualizer for fmri. Frontiers in Neuroinformatics 9, 23 (2015), https://www.frontiersin.org/article/10.3389/fninf.2015.00023",
            "url": "https://www.frontiersin.org/article/10.3389/fninf.2015.00023",
            "arxiv_url": "https://arxiv.org/pdf/2015.00023"
        },
        {
            "id": "7",
            "entry": "[7] G\u00fc\u00e7l\u00fc, U., van Gerven, M.A.J.: Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. Journal of Neuroscience 35(27), 10005\u201310014 (2015), http://www.jneurosci.org/content/35/27/10005",
            "url": "http://www.jneurosci.org/content/35/27/10005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=G%C3%BC%C3%A7l%C3%BC%2C%20U.%20van%20Gerven%2C%20M.A.%20J.%3A%20Deep%20neural%20networks%20reveal%20a%20gradient%20in%20the%20complexity%20of%20neural%20representations%20across%20the%20ventral%20stream%202015"
        },
        {
            "id": "8",
            "entry": "[8] de Heer, W.A., Huth, A.G., Griffiths, T.L., Gallant, J.L., Theunissen, F.E.: The hierarchical cortical organization of human speech processing. Journal of Neuroscience (2017), http://www.jneurosci.org/content/early/2017/06/06/JNEUROSCI.3267-16.2017",
            "url": "http://www.jneurosci.org/content/early/2017/06/06/JNEUROSCI.3267-16.2017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=de%20Heer%2C%20W.A.%20Huth%2C%20A.G.%20Griffiths%2C%20T.L.%20Gallant%2C%20J.L.%20E.%3A%20The%20hierarchical%20cortical%20organization%20of%20human%20speech%20processing%202017"
        },
        {
            "id": "9",
            "entry": "[9] Huth, A.G., de Heer, W.A., Griffiths, T.L., Theunissen, F.E., Gallant, J.L.: Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532(7600), 453\u2013458 (2016), https://doi.org/10.1038/nature17637",
            "crossref": "https://dx.doi.org/10.1038/nature17637",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1038/nature17637"
        },
        {
            "id": "10",
            "entry": "[10] Kay, K., Naselaris, T., Prenger, R., Gallant, J.: Identifying natural images from human brain activity. Nature 452(7185), 352\u2013355 (3 2008)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kay%2C%20K.%20Naselaris%2C%20T.%20Prenger%2C%20R.%20Gallant%20J.%3A%20Identifying%20natural%20images%20from%20human%20brain%20activity%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kay%2C%20K.%20Naselaris%2C%20T.%20Prenger%2C%20R.%20Gallant%20J.%3A%20Identifying%20natural%20images%20from%20human%20brain%20activity%202008"
        },
        {
            "id": "11",
            "entry": "[11] Kell, A.J., Yamins, D.L., Shook, E.N., Norman-Haignere, S.V., McDermott, J.H.: A task-optimized neural network replicates human auditory behavior, predicts brain responses, and reveals a cortical processing hierarchy. Neuron 98(3), 630 \u2013 644.e16 (2018), http://www.sciencedirect.com/science/article/pii/S0896627318302502",
            "url": "http://www.sciencedirect.com/science/article/pii/S0896627318302502",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kell%2C%20A.J.%20Yamins%2C%20D.L.%20Shook%2C%20E.N.%20Norman-Haignere%2C%20S.V.%20H.%3A%20A%20task-optimized%20neural%20network%20replicates%20human%20auditory%20behavior%2C%20predicts%20brain%20responses%2C%20and%20reveals%20a%20cortical%20processing%20hierarchy%202018"
        },
        {
            "id": "12",
            "entry": "[12] Lerner, Y., Honey, C.J., Silbert, L.J., Hasson, U.: Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. Journal of Neuroscience 31(8), 2906\u20132915 (2011), http://www.jneurosci.org/content/31/8/2906",
            "url": "http://www.jneurosci.org/content/31/8/2906",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lerner%2C%20Y.%20Honey%2C%20C.J.%20Silbert%2C%20L.J.%20Hasson%20U.%3A%20Topographic%20mapping%20of%20a%20hierarchy%20of%20temporal%20receptive%20windows%20using%20a%20narrated%20story%202011"
        },
        {
            "id": "13",
            "entry": "[13] McCann, B., Bradbury, J., Xiong, C., Socher, R.: Learned in translation: Contextualized word vectors. CoRR abs/1708.00107 (2017)",
            "arxiv_url": "https://arxiv.org/pdf/1708.00107"
        },
        {
            "id": "14",
            "entry": "[14] Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed representations of words and phrases and their compositionality. In: Burges, C.J.C., Bottou, L., Welling, M., Ghahramani, Z., Weinberger, K.Q. (eds.) Advances in Neural Information Processing Systems 26, pp. 3111\u20133119. Curran Associates, Inc. (2013), http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf",
            "url": "http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mikolov%2C%20T.%20Sutskever%2C%20I.%20Chen%2C%20K.%20Corrado%2C%20G.S.%20J.%3A%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013"
        },
        {
            "id": "15",
            "entry": "[15] Mitchell, T.M., Shinkareva, S.V., Carlson, A., Chang, K.M., Malave, V.L., Mason, R.A., Just, M.A.: Predicting human brain activity associated with the meanings of nouns. Science 320(5880), 1191\u20131195 (2008), http://science.sciencemag.org/content/320/5880/1191",
            "url": "http://science.sciencemag.org/content/320/5880/1191",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mitchell%2C%20T.M.%20Shinkareva%2C%20S.V.%20Carlson%2C%20A.%20Chang%2C%20K.M.%20A.%3A%20Predicting%20human%20brain%20activity%20associated%20with%20the%20meanings%20of%20nouns%202008"
        },
        {
            "id": "16",
            "entry": "[16] Naselaris, T., Kay, K., Nishimoto, S., Gallant, J.: Encoding and decoding in fmri 56, 400\u201310 (05 2011)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Naselaris%2C%20T.%20Kay%2C%20K.%20Nishimoto%2C%20S.%20Gallant%20J.%3A%20Encoding%20and%20decoding%20in%20fmri%2056%202011"
        },
        {
            "id": "17",
            "entry": "[17] Pereira, F., Lou, B., Pritchett, B., Ritter, S., Gershman, S.J., Kanwisher, N., Botvinick, M., Fedorenko, E.: Toward a universal decoder of linguistic meaning from brain activation. Nature communications 9(1), 963 (2018)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pereira%2C%20F.%20Lou%2C%20B.%20Pritchett%2C%20B.%20Ritter%2C%20S.%20E.%3A%20Toward%20a%20universal%20decoder%20of%20linguistic%20meaning%20from%20brain%20activation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pereira%2C%20F.%20Lou%2C%20B.%20Pritchett%2C%20B.%20Ritter%2C%20S.%20E.%3A%20Toward%20a%20universal%20decoder%20of%20linguistic%20meaning%20from%20brain%20activation%202018"
        },
        {
            "id": "18",
            "entry": "[18] Peters, M.E., Ammar, W., Bhagavatula, C., Power, R.: Semi-supervised sequence tagging with bidirectional language models. In: ACL (1). pp. 1756\u20131765. Association for Computational Linguistics (2017)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peters%2C%20M.E.%20Ammar%2C%20W.%20Bhagavatula%2C%20C.%20Power%20R.%3A%20Semi-supervised%20sequence%20tagging%20with%20bidirectional%20language%20models%202017"
        },
        {
            "id": "19",
            "entry": "[19] Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L.: Deep contextualized word representations. CoRR abs/1802.05365 (2018), http://arxiv.org/abs/1802.05365",
            "url": "http://arxiv.org/abs/1802.05365",
            "arxiv_url": "https://arxiv.org/pdf/1802.05365"
        },
        {
            "id": "20",
            "entry": "[20] Ruder, S.: An overview of gradient descent optimization algorithms. CoRR abs/1609.04747 (2016)",
            "arxiv_url": "https://arxiv.org/pdf/1609.04747"
        },
        {
            "id": "21",
            "entry": "[21] Sundermeyer, M., Schl\u00fcter, R., Ney, H.: Lstm neural networks for language modeling. In: Thirteenth Annual Conference of the International Speech Communication Association (2012)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sundermeyer%2C%20M.%20Schl%C3%BCter%2C%20R.%20Ney%20H.%3A%20Lstm%20neural%20networks%20for%20language%20modeling%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sundermeyer%2C%20M.%20Schl%C3%BCter%2C%20R.%20Ney%20H.%3A%20Lstm%20neural%20networks%20for%20language%20modeling%202012"
        },
        {
            "id": "22",
            "entry": "[22] Wehbe, L., Murphy, B., Talukdar, P., Fyshe, A., Ramdas, A., Mitchell, T.: Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses. PLOS ONE 9(11), 1\u201319 (11 2014), https://doi.org/10.1371/journal.pone.0112575",
            "crossref": "https://dx.doi.org/10.1371/journal.pone.0112575",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1371/journal.pone.0112575"
        },
        {
            "id": "23",
            "entry": "[23] Wehbe, L., Vaswani, A., Knight, K., Mitchell, T.M.: Aligning context-based statistical models of language with brain activity during reading. In: EMNLP (2014)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wehbe%2C%20L.%20Vaswani%2C%20A.%20Knight%2C%20K.%20Mitchell%2C%20T.%20M.%3A%20Aligning%20context-based%20statistical%20models%20of%20language%20with%20brain%20activity%20during%20reading%202014"
        },
        {
            "id": "24",
            "entry": "[24] Wu, M.C.K., David, S.V., Gallant, J.L.: Complete functional characterization of sensory neurons by system identification. Annual Review of Neuroscience 29(1), 477\u2013505 (2006), https://doi.org/10.1146/annurev.neuro.29.051605.113024, pMID:16776594",
            "crossref": "https://dx.doi.org/10.1146/annurev.neuro.29.051605.113024",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1146/annurev.neuro.29.051605.113024"
        },
        {
            "id": "25",
            "entry": "[25] Xu, H., Murphy, B., Fyshe, A.: Brainbench: A brain-image test suite for distributional semantic models. In: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. pp. 2017\u20132021 (2016) ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20H.%20Murphy%2C%20B.%20Fyshe%20A.%3A%20Brainbench%3A%20A%20brain-image%20test%20suite%20for%20distributional%20semantic%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20H.%20Murphy%2C%20B.%20Fyshe%20A.%3A%20Brainbench%3A%20A%20brain-image%20test%20suite%20for%20distributional%20semantic%20models%202016"
        }
    ]
}
