{
    "filename": "7712-byzantine-stochastic-gradient-descent.pdf",
    "metadata": {
        "date": 2011,
        "title": "Lectures on Modern Convex Optimization",
        "author": "Aharon Ben-Tal, Arkadi Nemirovski",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7712-byzantine-stochastic-gradient-descent.pdf",
            "doi": "10.1137/1.9780898718829"
        },
        "abstract": "This paper studies the problem of distributed stochastic optimization in an adversarial setting where, out of m machines which allegedly compute stochastic gradients every iteration, an \u21b5-fraction are Byzantine, and may behave adversarially. Our main result is a variant of stochastic gradient descent (SGD) which finds"
    },
    "keywords": [
        {
            "term": "convex optimization",
            "url": "https://en.wikipedia.org/wiki/convex_optimization"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "stochastic optimization",
            "url": "https://en.wikipedia.org/wiki/stochastic_optimization"
        },
        {
            "term": "robust regression",
            "url": "https://en.wikipedia.org/wiki/robust_regression"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "byzantine failure",
            "url": "https://en.wikipedia.org/wiki/byzantine_failure"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        }
    ],
    "highlights": [
        "Machine learning applications are becoming increasingly decentralized, either because data is naturally distributed\u2014in applications such as federated learning [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]\u2014or because data is partitioned across machines to parallelize computation, e.g. [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "We study the convex formulation of this Byzantine stochastic optimization problem: we assume f (x) is convex, each of the functions fs(x) may not necessarily be convex",
        "We provide the first algorithms that, in the presence of Byzantine machines, guarantee the following, up to logarithmic and lower-order terms: (1) achieve optimal sample complexity, (2) achieve optimal number of stochastic gradient computations, (3) match the sample and time complexities of traditional stochastic gradient descent as \u21b5 ! 0, and (4) achieve (1)-(3) even as the dimension grows, without losing additional dimension factors",
        "E.g. [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>], to the best of our knowledge, prior to our work there were no algorithms for stochastic optimization in high dimensions that achieved any of the four objectives highlighted above",
        "As for Theorem 3.2, the first two terms are asymptotically tight for stochastic gradient descent in this setting, and the last term is necessary in our Byzantine setting, as we show in Theorem 4.3",
        "We have presented the first tight sample and time complexity bounds for distributed stochastic gradient descent in the Byzantine setting, by leveraging concentration bounds to obtain a new set of detection criteria for malevolent machines"
    ],
    "key_statements": [
        "Machine learning applications are becoming increasingly decentralized, either because data is naturally distributed\u2014in applications such as federated learning [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]\u2014or because data is partitioned across machines to parallelize computation, e.g. [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>]",
        "We study the convex formulation of this Byzantine stochastic optimization problem: we assume f (x) is convex, each of the functions fs(x) may not necessarily be convex",
        "We provide the first algorithms that, in the presence of Byzantine machines, guarantee the following, up to logarithmic and lower-order terms: (1) achieve optimal sample complexity, (2) achieve optimal number of stochastic gradient computations, (3) match the sample and time complexities of traditional stochastic gradient descent as \u21b5 ! 0, and (4) achieve (1)-(3) even as the dimension grows, without losing additional dimension factors",
        "E.g. [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>], to the best of our knowledge, prior to our work there were no algorithms for stochastic optimization in high dimensions that achieved any of the four objectives highlighted above",
        "As for Theorem 3.2, the first two terms are asymptotically tight for stochastic gradient descent in this setting, and the last term is necessary in our Byzantine setting, as we show in Theorem 4.3",
        "We have presented the first tight sample and time complexity bounds for distributed stochastic gradient descent in the Byzantine setting, by leveraging concentration bounds to obtain a new set of detection criteria for malevolent machines"
    ],
    "summary": [
        "Machine learning applications are becoming increasingly decentralized, either because data is naturally distributed\u2014in applications such as federated learning [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>]\u2014or because data is partitioned across machines to parallelize computation, e.g. [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>].",
        "We provide the first algorithms that, in the presence of Byzantine machines, guarantee the following, up to logarithmic and lower-order terms: (1) achieve optimal sample complexity, (2) achieve optimal number of stochastic gradient computations, (3) match the sample and time complexities of traditional SGD as \u21b5 !",
        "In the non-strongly convex setting, each worker machine needs to compute \" 2 stochastic gradients per iteration, and the overall number of iterations will be at least \" 1.",
        "Machine i allegedly computes n stochastic gradients at point xk and averages them.",
        "Our algorithm is a Byzantine variant of SGD: a total of T m functions are sampled and a total of T m stochastic gradient computations are performed.",
        "Yin et al [<a class=\"ref-link\" id=\"c31\" href=\"#r31\">31</a>] provided a lower bound in terms of sampling complexity \u2014 the number of functions fs(\u00b7) needed to be sampled in the presence of Byzantine machines.",
        "The algorithm requires careful parametrization of the sample size at each machine to obtain good error bounds, which renders it suboptimal with respect to sample complexity.",
        "We can obtain optimal rates to those we obtained before, by reducing the problem to repeatedly solving non-strongly convex ones, as in Hazan and Kale [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>].",
        "Just as in the rates for non-strongly convex functions, the first two terms are necessary even when there are no Byzantine workers, and the last term matches the lower bound we give in Theorem 4.4 for Byzantine optimization.",
        "Our result for non-strongly convex stochastic optimization is the following: Theorem 4.3.",
        "V2 so that, given m machines, of which \u21b5m are Byzantine, and T samples from the stochastic estimator per m\u21e3achine, no algori\u2318thm can output x so that f (x) f (x\u21e4) < \" with probability 2/3 unless T = \u2326",
        "R with a subgaussian stochastic estimator of variance proxy V2 so that, given m machines, of which \u21b5m are Byzantine, and T samples from the stochastic estimato\u21e3r per machine, n\u2318o algorithm can output x so that |x",
        "We have presented the first tight sample and time complexity bounds for distributed SGD in the Byzantine setting, by leveraging concentration bounds to obtain a new set of detection criteria for malevolent machines.",
        "We believe that in practice, our algorithm should add minimal overhead, while providing strong robustness guarantees against machine failure, essentially \u201cfor free\u201d.",
        "Is it possible to achieve similar results while assuming weaker assumptions on the gradients? Alternatively, is it possible that the problem provably becomes more difficult?"
    ],
    "headline": "This paper studies the problem of distributed stochastic optimization in an adversarial setting where, out of m machines which allegedly compute stochastic gradients every iteration, an \u21b5-fraction are Byzantine, and may behave adversarially",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Sivaraman Balakrishnan, Simon S Du, Jerry Li, and Aarti Singh. Computationally efficient robust sparse estimation in high dimensions. In Conference on Learning Theory, pages 169\u2013 212, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balakrishnan%2C%20Sivaraman%20Du%2C%20Simon%20S.%20Li%2C%20Jerry%20Singh%2C%20Aarti%20Computationally%20efficient%20robust%20sparse%20estimation%20in%20high%20dimensions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balakrishnan%2C%20Sivaraman%20Du%2C%20Simon%20S.%20Li%2C%20Jerry%20Singh%2C%20Aarti%20Computationally%20efficient%20robust%20sparse%20estimation%20in%20high%20dimensions%202017"
        },
        {
            "id": "2",
            "entry": "[2] Ron Bekkerman, Mikhail Bilenko, and John Langford. Scaling up machine learning: Parallel and distributed approaches. Cambridge University Press, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bekkerman%2C%20Ron%20Bilenko%2C%20Mikhail%20Langford%2C%20John%20Scaling%20up%20machine%20learning%3A%20Parallel%20and%20distributed%20approaches%202011"
        },
        {
            "id": "3",
            "entry": "[3] Aharon Ben-Tal and Arkadi Nemirovski. Lectures on Modern Convex Optimization. Society for Industrial and Applied Mathematics, January 2013. ISBN 978-0-89871-491-3. doi: 10. 1137/1.9780898718829.",
            "crossref": "https://dx.doi.org/10.1137/1.9780898718829",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1137/1.9780898718829"
        },
        {
            "id": "4",
            "entry": "[4] K. Bhatia, P. Jain, P. Kamalaruban, and P. Kar. Consistent robust regression. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pages 2107\u20132116, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhatia%2C%20K.%20Jain%2C%20P.%20Kamalaruban%2C%20P.%20Kar%2C%20P.%20Consistent%20robust%20regression%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhatia%2C%20K.%20Jain%2C%20P.%20Kamalaruban%2C%20P.%20Kar%2C%20P.%20Consistent%20robust%20regression%202017"
        },
        {
            "id": "5",
            "entry": "[5] Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding. In Advances in Neural Information Processing Systems, pages 721\u2013729, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhatia%2C%20Kush%20Jain%2C%20Prateek%20Kar%2C%20Purushottam%20Robust%20regression%20via%20hard%20thresholding%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhatia%2C%20Kush%20Jain%2C%20Prateek%20Kar%2C%20Purushottam%20Robust%20regression%20via%20hard%20thresholding%202015"
        },
        {
            "id": "6",
            "entry": "[6] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine learning with adversaries: Byzantine tolerant gradient descent. In NIPS, pages 118\u2013128, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blanchard%2C%20Peva%20Mhamdi%2C%20El%20Mahdi%20El%20Guerraoui%2C%20Rachid%20Stainer%2C%20Julien%20Machine%20learning%20with%20adversaries%3A%20Byzantine%20tolerant%20gradient%20descent%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blanchard%2C%20Peva%20Mhamdi%2C%20El%20Mahdi%20El%20Guerraoui%2C%20Rachid%20Stainer%2C%20Julien%20Machine%20learning%20with%20adversaries%3A%20Byzantine%20tolerant%20gradient%20descent%202017"
        },
        {
            "id": "7",
            "entry": "[7] Moses Charikar, Jacob Steinhardt, and Gregory Valiant. Learning from untrusted data. In STOC, pages 47\u201360. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charikar%2C%20Moses%20Steinhardt%2C%20Jacob%20Valiant%2C%20Gregory%20Learning%20from%20untrusted%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charikar%2C%20Moses%20Steinhardt%2C%20Jacob%20Valiant%2C%20Gregory%20Learning%20from%20untrusted%20data%202017"
        },
        {
            "id": "8",
            "entry": "[8] Yudong Chen, Lili Su, and Jiaming Xu. Distributed statistical machine learning in adversarial settings: Byzantine gradient descent. arXiv preprint arXiv:1705.05491, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.05491"
        },
        {
            "id": "9",
            "entry": "[9] Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust estimators in high dimensions without the computational intractability. In FOCS, pages 655\u2013664. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ilias%20Diakonikolas%20Gautam%20Kamath%20Daniel%20M%20Kane%20Jerry%20Li%20Ankur%20Moitra%20and%20Alistair%20Stewart%20Robust%20estimators%20in%20high%20dimensions%20without%20the%20computational%20intractability%20In%20FOCS%20pages%20655664%20IEEE%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ilias%20Diakonikolas%20Gautam%20Kamath%20Daniel%20M%20Kane%20Jerry%20Li%20Ankur%20Moitra%20and%20Alistair%20Stewart%20Robust%20estimators%20in%20high%20dimensions%20without%20the%20computational%20intractability%20In%20FOCS%20pages%20655664%20IEEE%202016"
        },
        {
            "id": "10",
            "entry": "[10] Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robustly learning a gaussian: Getting optimal error, efficiently. In SODA, pages 2683\u20132702. SIAM, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diakonikolas%2C%20Ilias%20Kamath%2C%20Gautam%20Kane%2C%20Daniel%20M.%20Li%2C%20Jerry%20Robustly%20learning%20a%20gaussian%3A%20Getting%20optimal%20error%2C%20efficiently%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diakonikolas%2C%20Ilias%20Kamath%2C%20Gautam%20Kane%2C%20Daniel%20M.%20Li%2C%20Jerry%20Robustly%20learning%20a%20gaussian%3A%20Getting%20optimal%20error%2C%20efficiently%202018"
        },
        {
            "id": "11",
            "entry": "[11] Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart. Sever: A robust meta-algorithm for stochastic optimization. arXiv preprint arXiv:1803.02815, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.02815"
        },
        {
            "id": "12",
            "entry": "[12] Paul Feldman and Silvio Micali. Optimal algorithms for byzantine agreement. In Proceedings of the twentieth annual ACM symposium on Theory of computing, pages 148\u2013161. ACM, 1988.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feldman%2C%20Paul%20Micali%2C%20Silvio%20Optimal%20algorithms%20for%20byzantine%20agreement%201988",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feldman%2C%20Paul%20Micali%2C%20Silvio%20Optimal%20algorithms%20for%20byzantine%20agreement%201988"
        },
        {
            "id": "13",
            "entry": "[13] Jiashi Feng, Huan Xu, and Shie Mannor. Distributed robust learning. arXiv preprint arXiv:1409.5937, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.5937"
        },
        {
            "id": "14",
            "entry": "[14] Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: Optimal algorithms for stochastic strongly-convex optimization. The Journal of Machine Learning Research, 15(1): 2489\u20132512, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Kale%2C%20Satyen%20Beyond%20the%20regret%20minimization%20barrier%3A%20Optimal%20algorithms%20for%20stochastic%20strongly-convex%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Kale%2C%20Satyen%20Beyond%20the%20regret%20minimization%20barrier%3A%20Optimal%20algorithms%20for%20stochastic%20strongly-convex%20optimization%202014"
        },
        {
            "id": "15",
            "entry": "[15] P. J. Huber and E. M. Ronchetti. Robust statistics. Wiley New York, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huber%2C%20P.J.%20Ronchetti%2C%20E.M.%20Robust%20statistics%202009"
        },
        {
            "id": "16",
            "entry": "[16] Adam Klivans, Pravesh K. Kothari, and Raghu Meka. Efficient algorithms for outlier-robust regression. arXiv preprint arXiv:1803.03241, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.03241"
        },
        {
            "id": "17",
            "entry": "[17] Jakub Konecny, H Brendan McMahan, Felix X Yu, Peter Richtarik, Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.05492"
        },
        {
            "id": "18",
            "entry": "[18] Kevin A Lai, Anup B Rao, and Santosh Vempala. Agnostic estimation of mean and covariance. In FOCS, pages 665\u2013674. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lai%2C%20Kevin%20A.%20Rao%2C%20Anup%20B.%20Vempala%2C%20Santosh%20Agnostic%20estimation%20of%20mean%20and%20covariance%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lai%2C%20Kevin%20A.%20Rao%2C%20Anup%20B.%20Vempala%2C%20Santosh%20Agnostic%20estimation%20of%20mean%20and%20covariance%202016"
        },
        {
            "id": "19",
            "entry": "[19] Leslie Lamport, Robert Shostak, and Marshall Pease. The byzantine generals problem. ACM Transactions on Programming Languages and Systems (TOPLAS), 4(3):382\u2013401, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lamport%2C%20Leslie%20Shostak%2C%20Robert%20Pease%2C%20Marshall%20The%20byzantine%20generals%20problem%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lamport%2C%20Leslie%20Shostak%2C%20Robert%20Pease%2C%20Marshall%20The%20byzantine%20generals%20problem%201982"
        },
        {
            "id": "20",
            "entry": "[20] N. M. Nasrabadi, T. D. Tran, and N. Nguyen. Robust lasso with missing and grossly corrupted observations. In Advances in Neural Information Processing Systems (NIPS), 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nasrabadi%2C%20N.M.%20Tran%2C%20T.D.%20Nguyen%2C%20N.%20Robust%20lasso%20with%20missing%20and%20grossly%20corrupted%20observations%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nasrabadi%2C%20N.M.%20Tran%2C%20T.D.%20Nguyen%2C%20N.%20Robust%20lasso%20with%20missing%20and%20grossly%20corrupted%20observations%202011"
        },
        {
            "id": "21",
            "entry": "[21] Yurii Nesterov. Introductory Lectures on Convex Programming Volume: A Basic course, volume I. Kluwer Academic Publishers, 2004. ISBN 1402075537.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Introductory%20Lectures%20on%20Convex%20Programming%20Volume%3A%20A%20Basic%20course%2C%20volume%20I%202004"
        },
        {
            "id": "22",
            "entry": "[22] N. H. Nguyen and T. D. Tran. Exact recoverability from dense corrupted observations via1-minimization. IEEE Transactions on Information Theory, 59(4):2017\u20132035, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20N.H.%20Tran%2C%20T.D.%20Exact%20recoverability%20from%20dense%20corrupted%20observations%20via1-minimization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20N.H.%20Tran%2C%20T.D.%20Exact%20recoverability%20from%20dense%20corrupted%20observations%20via1-minimization%202013"
        },
        {
            "id": "23",
            "entry": "[23] Iosif Pinelis. Optimum bounds for the distributions of martingales in banach spaces. The Annals of Probability, pages 1679\u20131706, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pinelis%2C%20Iosif%20Optimum%20bounds%20for%20the%20distributions%20of%20martingales%20in%20banach%20spaces%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pinelis%2C%20Iosif%20Optimum%20bounds%20for%20the%20distributions%20of%20martingales%20in%20banach%20spaces%201994"
        },
        {
            "id": "24",
            "entry": "[24] Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, and Pradeep Ravikumar. Robust estimation via robust gradient estimation. arXiv preprint arXiv:1802.06485, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.06485"
        },
        {
            "id": "25",
            "entry": "[25] Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal for strongly convex stochastic optimization. In ICML, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rakhlin%2C%20Alexander%20Shamir%2C%20Ohad%20Sridharan%2C%20Karthik%20Making%20gradient%20descent%20optimal%20for%20strongly%20convex%20stochastic%20optimization%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rakhlin%2C%20Alexander%20Shamir%2C%20Ohad%20Sridharan%2C%20Karthik%20Making%20gradient%20descent%20optimal%20for%20strongly%20convex%20stochastic%20optimization%202012"
        },
        {
            "id": "26",
            "entry": "[26] Lili Su and Nitin H Vaidya. Fault-tolerant multi-agent optimization: optimal iterative distributed algorithms. In PODC, pages 425\u2013434. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Su%2C%20Lili%20Vaidya%2C%20Nitin%20H.%20Fault-tolerant%20multi-agent%20optimization%3A%20optimal%20iterative%20distributed%20algorithms%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Su%2C%20Lili%20Vaidya%2C%20Nitin%20H.%20Fault-tolerant%20multi-agent%20optimization%3A%20optimal%20iterative%20distributed%20algorithms%202016"
        },
        {
            "id": "27",
            "entry": "[27] Lili Su and Nitin H Vaidya. Defending non-bayesian learning against adversarial attacks. ISDC, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Su%2C%20Lili%20Vaidya%2C%20Nitin%20H.%20Defending%20non-bayesian%20learning%20against%20adversarial%20attacks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Su%2C%20Lili%20Vaidya%2C%20Nitin%20H.%20Defending%20non-bayesian%20learning%20against%20adversarial%20attacks%202016"
        },
        {
            "id": "28",
            "entry": "[28] J.W. Tukey. Mathematics and picturing of data. In Proceedings of ICM, volume 6, pages 523\u2013531, 1975.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tukey%2C%20J.W.%20Mathematics%20and%20picturing%20of%20data%201975",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tukey%2C%20J.W.%20Mathematics%20and%20picturing%20of%20data%201975"
        },
        {
            "id": "29",
            "entry": "[29] Blake Woodworth and Nati Srebro. Tight Complexity Bounds for Optimizing Composite Objectives. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Woodworth%2C%20Blake%20Srebro%2C%20Nati%20Tight%20Complexity%20Bounds%20for%20Optimizing%20Composite%20Objectives%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Woodworth%2C%20Blake%20Srebro%2C%20Nati%20Tight%20Complexity%20Bounds%20for%20Optimizing%20Composite%20Objectives%202016"
        },
        {
            "id": "30",
            "entry": "[30] Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Generalized Byzantine-tolerant SGD. arXiv preprint arXiv:1802.10116, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.10116"
        },
        {
            "id": "31",
            "entry": "[31] Dong Yin, Yudong Chen, Kanna Ramchandran, and Peter Bartlett. Byzantine-robust distributed learning: Towards optimal statistical rates. arXiv preprint arXiv:1803.01498, 2018. ",
            "arxiv_url": "https://arxiv.org/pdf/1803.01498"
        }
    ]
}
