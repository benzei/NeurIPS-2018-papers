{
    "filename": "8235-learning-and-inference-in-hilbert-space-with-quantum-graphical-models.pdf",
    "metadata": {
        "title": "Learning and Inference in Hilbert Space with Quantum Graphical Models",
        "author": "Siddarth Srinivasan, Carlton Downey, Byron Boots",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8235-learning-and-inference-in-hilbert-space-with-quantum-graphical-models.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Quantum Graphical Models (QGMs) generalize classical graphical models by adopting the formalism for reasoning about uncertainty from quantum mechanics. Unlike classical graphical models, QGMs represent uncertainty with density matrices in complex Hilbert spaces. Hilbert space embeddings (HSEs) also generalize Bayesian inference in Hilbert spaces. We investigate the link between QGMs and HSEs and show that the sum rule and Bayes rule for QGMs are equivalent to the kernel sum rule in HSEs and a special case of Nadaraya-Watson kernel regression, respectively. We show that these operations can be kernelized, and use these insights to propose a Hilbert Space Embedding of Hidden Quantum Markov Models (HSE-HQMM) to model dynamics. We present experimental results showing that HSE-HQMMs are competitive with state-of-the-art models like LSTMs and PSRNNs on several datasets, while also providing a nonparametric method for maintaining a probability distribution over continuous-valued features."
    },
    "keywords": [
        {
            "term": "special case",
            "url": "https://en.wikipedia.org/wiki/special_case"
        },
        {
            "term": "probability distribution",
            "url": "https://en.wikipedia.org/wiki/probability_distribution"
        },
        {
            "term": "Mean Squared Error",
            "url": "https://en.wikipedia.org/wiki/Mean_Squared_Error"
        },
        {
            "term": "Predictive State Representation",
            "url": "https://en.wikipedia.org/wiki/Predictive_State_Representation"
        },
        {
            "term": "reproducing kernel Hilbert space",
            "url": "https://en.wikipedia.org/wiki/reproducing_kernel_Hilbert_space"
        },
        {
            "term": "dynamical system",
            "url": "https://en.wikipedia.org/wiki/dynamical_system"
        },
        {
            "term": "sum rule",
            "url": "https://en.wikipedia.org/wiki/sum_rule"
        }
    ],
    "highlights": [
        "Various formulations of Quantum Graphical Models (QGMs) have been proposed by researchers in physics and machine learning [<a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\"><a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\">Srinivasan et al, 2018</a></a>, Yeang, 2010, <a class=\"ref-link\" id=\"cLeifer_2008_a\" href=\"#rLeifer_2008_a\"><a class=\"ref-link\" id=\"cLeifer_2008_a\" href=\"#rLeifer_2008_a\">Leifer and Poulin, 2008</a></a>] as a way of generalizing probabilistic inference on graphical models by adopting quantum mechanics\u2019 formalism for reasoning about uncertainty",
        "Inference using Hilbert space embeddings (HSE) is a generalization of Bayesian reasoning, where data is mapped to a Hilbert space in which kernel sum, chain, and Bayes rules can be used [Smola et al, 2007, Song et al, 2009, 2013]",
        "We present four contributions: (1) we show that the sum rule for Quantum Graphical Models is identical to the kernel sum rule for Hilbert space embeddings, while the Bayesian update in Quantum Graphical Models is equivalent to performing Nadaraya-Watson kernel regression, (2) we show how to kernelize these operations and argue that with the right choice of features, we are mapping our data to quantum systems and modeling dynamics as quantum state evolution, (3) we use these insights to propose a Hilbert space embeddings-hidden quantum Markov models to model dynamics by mapping data to quantum systems and performing inference in Hilbert space, and, (4) we present a learning algorithm and experimental results showing that Hilbert space embeddings-hidden quantum Markov models are competitive with other state-of-the-art methods for modeling sequences, while providing a nonparametric method for estimating the distribution of continuous-valued features.\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00e9al, Canada.\n2 Quantum Graphical Models\n2.1",
        ", we have shown that this modification can be interpreted as a heuristically generalization of Bayes rule for Quantum Graphical Models or Nadaraya-Watson kernel regression",
        "We explored the connections between Quantum Graphical Models and Hilbert space embeddings, and showed that the sum rule and Bayes rule in Quantum Graphical Models is equivalent to kernel sum rule and a special case of Nadaraya-Watson kernel regression",
        "We proposed Hilbert space embeddings-hidden quantum Markov models to model dynamics, and showed experimentally that these models are competitive with LSTMs and Predictive State Recurrent Neural Networks on making point predictions, while being a nonparametric method for maintaining a probability distribution over continuous-valued features"
    ],
    "key_statements": [
        "Various formulations of Quantum Graphical Models (QGMs) have been proposed by researchers in physics and machine learning [<a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\"><a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\">Srinivasan et al, 2018</a></a>, Yeang, 2010, <a class=\"ref-link\" id=\"cLeifer_2008_a\" href=\"#rLeifer_2008_a\"><a class=\"ref-link\" id=\"cLeifer_2008_a\" href=\"#rLeifer_2008_a\">Leifer and Poulin, 2008</a></a>] as a way of generalizing probabilistic inference on graphical models by adopting quantum mechanics\u2019 formalism for reasoning about uncertainty",
        "Inference using Hilbert space embeddings (HSE) is a generalization of Bayesian reasoning, where data is mapped to a Hilbert space in which kernel sum, chain, and Bayes rules can be used [Smola et al, 2007, Song et al, 2009, 2013]",
        "We present four contributions: (1) we show that the sum rule for Quantum Graphical Models is identical to the kernel sum rule for Hilbert space embeddings, while the Bayesian update in Quantum Graphical Models is equivalent to performing Nadaraya-Watson kernel regression, (2) we show how to kernelize these operations and argue that with the right choice of features, we are mapping our data to quantum systems and modeling dynamics as quantum state evolution, (3) we use these insights to propose a Hilbert space embeddings-hidden quantum Markov models to model dynamics by mapping data to quantum systems and performing inference in Hilbert space, and, (4) we present a learning algorithm and experimental results showing that Hilbert space embeddings-hidden quantum Markov models are competitive with other state-of-the-art methods for modeling sequences, while providing a nonparametric method for estimating the distribution of continuous-valued features.\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00e9al, Canada.\n2 Quantum Graphical Models\n2.1",
        ", we have shown that this modification can be interpreted as a heuristically generalization of Bayes rule for Quantum Graphical Models or Nadaraya-Watson kernel regression",
        "We explored the connections between Quantum Graphical Models and Hilbert space embeddings, and showed that the sum rule and Bayes rule in Quantum Graphical Models is equivalent to kernel sum rule and a special case of Nadaraya-Watson kernel regression",
        "We proposed Hilbert space embeddings-hidden quantum Markov models to model dynamics, and showed experimentally that these models are competitive with LSTMs and Predictive State Recurrent Neural Networks on making point predictions, while being a nonparametric method for maintaining a probability distribution over continuous-valued features",
        "We note that our experiments only consider real kernels/features, so we are not utilizing the full complex Hilbert space; it would be interesting to investigate whether incorporating complex numbers improves our model"
    ],
    "summary": [
        "Various formulations of Quantum Graphical Models (QGMs) have been proposed by researchers in physics and machine learning [<a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\"><a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\">Srinivasan et al, 2018</a></a>, Yeang, 2010, <a class=\"ref-link\" id=\"cLeifer_2008_a\" href=\"#rLeifer_2008_a\"><a class=\"ref-link\" id=\"cLeifer_2008_a\" href=\"#rLeifer_2008_a\">Leifer and Poulin, 2008</a></a>] as a way of generalizing probabilistic inference on graphical models by adopting quantum mechanics\u2019 formalism for reasoning about uncertainty.",
        "We further develop the operations on QGMs introduced by <a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\"><a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\">Srinivasan et al [2018</a></a>], working with the notion that the density matrix is the quantum analogue of a classical belief state.",
        "Quantum Mean Maps We still take the expectation of the features of the data, except we require that the feature maps (\u00b7) produce valid density matrices representing pure states.",
        "Matrix, which is consistent with estimating it from data as the expectation of outer product of feature maps (\u00b7) that produce vectorized density matrices.",
        "We re-write the Bayesian update for QGMs from Equation 6 in the language of HSEs. First, we modify the quantum circuit in 1b to allow for measurement of a rank-1 density matrixin basis \u21e2y any to obtain the circuit shown in Figure 2, described by the equation:",
        "Our choice of feature map produces density matrices, so their inner product in Hilbert space is equivalent to computing the squared kernel, and this constraint is satisfied.",
        "As we discussed at the end of Section 2.2, Figure 1c is an alternate way of generalizing Bayes rule for QGMs. But following the same approach of rewriting the quantum circuit in the language of Hilbert Space embeddings as in Section 3.2, we get exactly Kernel Bayes Rule [<a class=\"ref-link\" id=\"cSong_et+al_2013_a\" href=\"#rSong_et+al_2013_a\">Song et al, 2013</a>]: \u03bc~ X",
        "We note that interpreting operations on QGMs as inference in Hilbert space is a special case; if the feature maps don\u2019t produce density matrices, we can still perform inference in Hilbert space using the quantum/kernel sum rule, and Nadaraya-Watson/kernel",
        "We consider mapping data to vectorized density matrices and modeling the dynamics in Hilbert space using a specific quantum graphical model \u2013 hidden quantum Markov models (HQMMs).",
        "Making Predictions As discussed in <a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\"><a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\">Srinivasan et al [2018</a></a>], conditioning on some discretevalued observation y in the quantum model produces an unnormalized density matrix whose trace is the probability of observing y.",
        "The learned parameters are not guaranteed to satisfy the quantum constraints, and we handle this by projecting the state back to a valid density matrix at each time step.",
        "One key difference between these approaches is that we directly use states in Hilbert space to estimate the probability density of observations; in other words HSE-HQMMs are a generative model.",
        "We proposed HSE-HQMMs to model dynamics, and showed experimentally that these models are competitive with LSTMs and PSRNNs on making point predictions, while being a nonparametric method for maintaining a probability distribution over continuous-valued features.",
        "The density estimation properties of the model are an avenue for future exploration"
    ],
    "headline": "We investigate the link between Quantum Graphical Models and Hilbert space embeddings and show that the sum rule and Bayes rule for Quantum Graphical Models are equivalent to the kernel sum rule in Hilbert space embeddings and a special case of Nadaraya-Watson kernel regression, respectively",
    "reference_links": [
        {
            "id": "Boots_et+al_2012_a",
            "entry": "B. Boots, A. Gretton, and G. J. Gordon. Hilbert space embeddings of PSRs. NIPS Workshop on Spectral Algorithms for Latent Variable Models, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boots%2C%20B.%20Gretton%2C%20A.%20Gordon%2C%20G.J.%20Hilbert%20space%20embeddings%20of%20PSRs.%20NIPS%20Workshop%20on%20Spectral%20Algorithms%20for%20Latent%20Variable%20Models%202012"
        },
        {
            "id": "Boots_et+al_2013_a",
            "entry": "B. Boots, G. J. Gordon, and A. Gretton. Hilbert space embeddings of predictive state representations. CoRR, abs/1309.6819, 2013. URL http://arxiv.org/abs/1309.6819.",
            "url": "http://arxiv.org/abs/1309.6819",
            "arxiv_url": "https://arxiv.org/pdf/1309.6819"
        },
        {
            "id": "Downey_et+al_2017_a",
            "entry": "C. Downey, A. Hefny, B. Li, B. Boots, and G. J. Gordon. Predictive state recurrent neural networks. In Proceedings of Advances in Neural Information Processing Systems (NIPS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Downey%2C%20C.%20Hefny%2C%20A.%20Li%2C%20B.%20Boots%2C%20B.%20Predictive%20state%20recurrent%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Downey%2C%20C.%20Hefny%2C%20A.%20Li%2C%20B.%20Boots%2C%20B.%20Predictive%20state%20recurrent%20neural%20networks%202017"
        },
        {
            "id": "Hefny_et+al_2015_a",
            "entry": "A. Hefny, C. Downey, and G. J. Gordon. Supervised learning for dynamical system learning. In Advances in neural information processing systems, pages 1963\u20131971, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hefny%2C%20A.%20Downey%2C%20C.%20Gordon%2C%20G.J.%20Supervised%20learning%20for%20dynamical%20system%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hefny%2C%20A.%20Downey%2C%20C.%20Gordon%2C%20G.J.%20Supervised%20learning%20for%20dynamical%20system%20learning%202015"
        },
        {
            "id": "Leifer_2008_a",
            "entry": "M. Leifer and D. Poulin. Quantum graphical models and belief propagation. Ann. Phys., 323:1899, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Leifer%2C%20M.%20Poulin%2C%20D.%20Quantum%20graphical%20models%20and%20belief%20propagation%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Leifer%2C%20M.%20Poulin%2C%20D.%20Quantum%20graphical%20models%20and%20belief%20propagation%202008"
        },
        {
            "id": "Marcus_et+al_1993_a",
            "entry": "M. P. Marcus, M. A. Marcinkiewicz, and B. Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313\u2013330, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcus%2C%20M.P.%20Marcinkiewicz%2C%20M.A.%20Santorini%2C%20B.%20Building%20a%20large%20annotated%20corpus%20of%20english%3A%20The%20penn%20treebank%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcus%2C%20M.P.%20Marcinkiewicz%2C%20M.A.%20Santorini%2C%20B.%20Building%20a%20large%20annotated%20corpus%20of%20english%3A%20The%20penn%20treebank%201993"
        },
        {
            "id": "Monras_et+al_2010_a",
            "entry": "A. Monras, A. Beige, and K. Wiesner. Hidden quantum Markov models and non-adaptive read-out of many-body states. arXiv preprint arXiv:1002.2337, 2010. E. A. Nadaraya. On estimating regression. Theory of Probability & Its Applications, 9(1):141\u2013142, 1964. M. A. Nielsen and I. Chuang. Quantum computation and quantum information, 2002. A. Rahimi and B. Recht. Random features for large-scale kernel machines. In Advances in neural information processing systems, pages 1177\u20131184, 2008. M. Schuld and N. Killoran. Quantum machine learning in feature Hilbert spaces. arXiv preprint arXiv:1803.07128, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1002.2337"
        },
        {
            "id": "Springer_2009_a",
            "entry": "Springer, 2007. L. Song, J. Huang, A. Smola, and K. Fukumizu. Hilbert space embeddings of conditional distributions with applications to dynamical systems. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 961\u2013968. ACM, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hilbert%20space%20embeddings%20of%20conditional%20distributions%20with%20applications%20to%20dynamical%20systems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hilbert%20space%20embeddings%20of%20conditional%20distributions%20with%20applications%20to%20dynamical%20systems%202009"
        },
        {
            "id": "Song_et+al_2010_a",
            "entry": "L. Song, B. Boots, S. M. Siddiqi, G. J. Gordon, and A. J. Smola. Hilbert space embeddings of hidden Markov models. In Proceedings of the 27th International Conference on Machine Learning (ICML), 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20L.%20Boots%2C%20B.%20Siddiqi%2C%20S.M.%20Gordon%2C%20G.J.%20Hilbert%20space%20embeddings%20of%20hidden%20Markov%20models%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20L.%20Boots%2C%20B.%20Siddiqi%2C%20S.M.%20Gordon%2C%20G.J.%20Hilbert%20space%20embeddings%20of%20hidden%20Markov%20models%202010"
        },
        {
            "id": "Song_et+al_2013_a",
            "entry": "L. Song, K. Fukumizu, and A. Gretton. Kernel embeddings of conditional distributions: A unified kernel framework for nonparametric inference in graphical models. IEEE Signal Processing Magazine, 30(4): 98\u2013111, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20L.%20Fukumizu%2C%20K.%20Gretton%2C%20A.%20Kernel%20embeddings%20of%20conditional%20distributions%3A%20A%20unified%20kernel%20framework%20for%20nonparametric%20inference%20in%20graphical%20models%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20L.%20Fukumizu%2C%20K.%20Gretton%2C%20A.%20Kernel%20embeddings%20of%20conditional%20distributions%3A%20A%20unified%20kernel%20framework%20for%20nonparametric%20inference%20in%20graphical%20models%202013"
        },
        {
            "id": "Srinivasan_et+al_2018_a",
            "entry": "S. Srinivasan, G. J. Gordon, and B. Boots. Learning hidden quantum Markov models. In Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, 2018. L. Wasserman. All of Nonparametric Statistics (Springer Texts in Statistics). Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387251456. G. S. Watson. Smooth regression analysis. Sankhya: The Indian Journal of Statistics, Series A, pages 359\u2013372, 1964. C.-H. Yeang. A probabilistic graphical model of quantum systems. In Machine Learning and Applications (ICMLA), 2010 Ninth International Conference on, pages 155\u2013162. IEEE, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srinivasan%2C%20S.%20Gordon%2C%20G.J.%20Boots%2C%20B.%20Learning%20hidden%20quantum%20Markov%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srinivasan%2C%20S.%20Gordon%2C%20G.J.%20Boots%2C%20B.%20Learning%20hidden%20quantum%20Markov%20models%202018"
        }
    ]
}
