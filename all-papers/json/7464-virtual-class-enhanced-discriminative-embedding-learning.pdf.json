{
    "filename": "7464-virtual-class-enhanced-discriminative-embedding-learning.pdf",
    "metadata": {
        "title": "Virtual Class Enhanced Discriminative Embedding Learning",
        "author": "Binghui Chen, Weihong Deng, Haifeng Shen",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7464-virtual-class-enhanced-discriminative-embedding-learning.pdf"
        },
        "abstract": "Recently, learning discriminative features to improve the recognition performances gradually becomes the primary goal of deep learning, and numerous remarkable works have emerged. In this paper, we propose a novel yet extremely simple method Virtual Softmax to enhance the discriminative property of learned features by injecting a dynamic virtual negative class into the original softmax. Injecting virtual class aims to enlarge inter-class margin and compress intra-class distribution by strengthening the decision boundary constraint. Although it seems weird to optimize with this additional virtual class, we show that our method derives from an intuitive and clear motivation, and it indeed encourages the features to be more compact and separable. This paper empirically and experimentally demonstrates the superiority of Virtual Softmax, improving the performances on a variety of object classification and face verification tasks."
    },
    "keywords": [
        {
            "term": "virtual class",
            "url": "https://en.wikipedia.org/wiki/virtual_class"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        }
    ],
    "highlights": [
        "In the community of deep learning, the Softmax layer is widely adopted as a supervisor at the top of the model due to its simplicity and differentiability, such as in object classification[<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>\u2013<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>] and face recognition[<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>], etc",
        "One can observe another important phenomenon that the feature vector X optimized by Virtual Softmax has a much smaller angle \u03b8 to the class anchor Wyi than original Softmax, well explaining the reason why the features learned by Virtual Softmax is much more compact and separable than original Softmax",
        "We evaluate our Virtual Softmax on classification tasks and on face verification tasks",
        "We propose a novel but extremely simple method Virtual Softmax to enhance the discriminative property of learned features by encouraging larger angular margin between classes",
        "Extensive experiments on both object classification and face verification tasks validate that our Virtual Softmax can significantly outperforms the original softmax and serves as an efficient feature-enhancing method"
    ],
    "key_statements": [
        "In the community of deep learning, the Softmax layer is widely adopted as a supervisor at the top of the model due to its simplicity and differentiability, such as in object classification[<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>\u2013<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>] and face recognition[<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>], etc",
        "There are a few research works concentrating on learning discriminative features through refining this commonly used softmax layer, e.g. L-Softmax [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>] and A-Softmax[<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]",
        "One can observe another important phenomenon that the feature vector X optimized by Virtual Softmax has a much smaller angle \u03b8 to the class anchor Wyi than original Softmax, well explaining the reason why the features learned by Virtual Softmax is much more compact and separable than original Softmax",
        "We evaluate our Virtual Softmax on classification tasks and on face verification tasks",
        "We propose a novel but extremely simple method Virtual Softmax to enhance the discriminative property of learned features by encouraging larger angular margin between classes",
        "Extensive experiments on both object classification and face verification tasks validate that our Virtual Softmax can significantly outperforms the original softmax and serves as an efficient feature-enhancing method"
    ],
    "summary": [
        "In the community of deep learning, the Softmax layer is widely adopted as a supervisor at the top of the model due to its simplicity and differentiability, such as in object classification[<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>\u2013<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>] and face recognition[<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>], etc.",
        "To our best knowledge, it is the first work to employ additional virtual class in Softmax to optimize the feature learning and to improve the recognition performance.",
        "Except for the above analysis that Virtual Softmax optimizes a much more rigorous objective than the original Softmax for learning discriminative features, we will give some interpretations from several other perspectives, i.e. coupling decay5.1 and feature update5.2.",
        "One can observe another important phenomenon that the feature vector X optimized by Virtual Softmax has a much smaller angle \u03b8 to the class anchor Wyi than original Softmax, well explaining the reason why the features learned by Virtual Softmax is much more compact and separable than original Softmax.",
        "One can observe that the learned features by our Virtual Softmax are much compact and well separated, with larger inter-class angular margin and tighter intra-class distribution than softmax, and Virtual Softmax can consistently improve the performances in both 2-D (99.2% vs.",
        "Our method differs from L-Softmax and A-softmax in a heuristic idea that training deep models with the additional virtual class not only the given ones, which is the first work to extend the original Softmax to employ virtual class for discriminative feature learning and may inspire other researchers.",
        "For example on CIFAR100+, it can be observed that as the model width increasing the recognition error rate of Virtual Softmax is diminishing, and our method achieves",
        "CIFAR100+ Softmax t=2 32.72 29.84 2.88 t=2 30.44 28.62 t=3 30.74 28.4 2.34 t=3 28.59 26.81 t=4 28.76 27.81 0.95 t=4 27.21 26.17 t=7 27.7 26.02 1.68 t=7 25.52 24.01 consistent performance gain over the original soft-Improvement 1.82 1.78 1.04 1.51 max when training with different networks, verifying the robustness of our method.",
        "Since the class number for training is very large, i.e. 67k, the optimizing procedure is difficult than that in object classification tasks, if the training phase can be eased by human guidance and control, the performance will be more better, e.g. AS*[<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]+Normface*[<a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>] achieve the best results when artificially and specifically choose the optimal margin constraints and feature scale for the current training set.",
        "We propose a novel but extremely simple method Virtual Softmax to enhance the discriminative property of learned features by encouraging larger angular margin between classes.",
        "Extensive experiments on both object classification and face verification tasks validate that our Virtual Softmax can significantly outperforms the original softmax and serves as an efficient feature-enhancing method."
    ],
    "headline": "We propose a novel yet extremely simple method Virtual Softmax to enhance the discriminative property of learned features by injecting a dynamic virtual negative class into the original softmax",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] S. Branson, G. Van Horn, S. Belongie, and P. Perona. Bird species categorization using pose normalized deep convolutional nets. arXiv preprint arXiv:1406.2952, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1406.2952"
        },
        {
            "id": "2",
            "entry": "[2] B. Chen and W. Deng. Almn: Deep embedding learning with geometrical virtual point generating. arXiv preprint arXiv:1806.00974, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.00974"
        },
        {
            "id": "3",
            "entry": "[3] B. Chen, W. Deng, and J. Du. Noisy softmax: Improving the generalization ability of dcnn via postponing the early softmax saturation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20B.%20Deng%2C%20W.%20Du%2C%20J.%20Noisy%20softmax%3A%20Improving%20the%20generalization%20ability%20of%20dcnn%20via%20postponing%20the%20early%20softmax%20saturation%202017-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20B.%20Deng%2C%20W.%20Du%2C%20J.%20Noisy%20softmax%3A%20Improving%20the%20generalization%20ability%20of%20dcnn%20via%20postponing%20the%20early%20softmax%20saturation%202017-07"
        },
        {
            "id": "4",
            "entry": "[4] D. Cheng, Y. Gong, S. Zhou, J. Wang, and N. Zheng. Person re-identification by multi-channel parts-based cnn with improved triplet loss function. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1335\u20131344, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cheng%2C%20D.%20Gong%2C%20Y.%20Zhou%2C%20S.%20Wang%2C%20J.%20Person%20re-identification%20by%20multi-channel%20parts-based%20cnn%20with%20improved%20triplet%20loss%20function%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cheng%2C%20D.%20Gong%2C%20Y.%20Zhou%2C%20S.%20Wang%2C%20J.%20Person%20re-identification%20by%20multi-channel%20parts-based%20cnn%20with%20improved%20triplet%20loss%20function%202016"
        },
        {
            "id": "5",
            "entry": "[5] P. Chrabaszcz, I. Loshchilov, and F. Hutter. A downsampled variant of imagenet as an alternative to the cifar datasets. arXiv preprint arXiv:1707.08819, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.08819"
        },
        {
            "id": "6",
            "entry": "[6] W. Deng, J. Hu, N. Zhang, B. Chen, and J. Guo. Fine-grained face verification: Fglfw database, baselines, and human-dcmn partnership. Pattern Recognition, 66:63\u201373, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20W.%20Hu%2C%20J.%20Zhang%2C%20N.%20Chen%2C%20B.%20Fine-grained%20face%20verification%3A%20Fglfw%20database%2C%20baselines%2C%20and%20human-dcmn%20partnership%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20W.%20Hu%2C%20J.%20Zhang%2C%20N.%20Chen%2C%20B.%20Fine-grained%20face%20verification%3A%20Fglfw%20database%2C%20baselines%2C%20and%20human-dcmn%20partnership%202017"
        },
        {
            "id": "7",
            "entry": "[7] I. J. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville, and Y. Bengio. Maxout networks. arXiv preprint arXiv:1302.4389, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1302.4389"
        },
        {
            "id": "8",
            "entry": "[8] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. In European Conference on Computer Vision (ECCV), pages 87\u2013102.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Y.%20Zhang%2C%20L.%20Hu%2C%20Y.%20He%2C%20X.%20Ms-celeb-%201m%3A%20A%20dataset%20and%20benchmark%20for%20large-scale%20face%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Y.%20Zhang%2C%20L.%20Hu%2C%20Y.%20He%2C%20X.%20Ms-celeb-%201m%3A%20A%20dataset%20and%20benchmark%20for%20large-scale%20face%20recognition"
        },
        {
            "id": "9",
            "entry": "[9] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "10",
            "entry": "[10] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. arXiv preprint arXiv:1709.01507, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.01507"
        },
        {
            "id": "11",
            "entry": "[11] G. Huang, Z. Liu, K. Q. Weinberger, and L. van der Maaten. Densely connected convolutional networks. arXiv preprint arXiv:1608.06993, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.06993"
        },
        {
            "id": "12",
            "entry": "[12] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical report, Technical Report 07-49, University of Massachusetts, Amherst, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20G.B.%20Ramesh%2C%20M.%20Berg%2C%20T.%20Learned-Miller%2C%20E.%20Labeled%20faces%20in%20the%20wild%3A%20A%20database%20for%20studying%20face%20recognition%20in%20unconstrained%20environments%202007"
        },
        {
            "id": "13",
            "entry": "[13] Y. Jeon and J. Kim. Active convolution: Learning the shape of convolution for image classification. arXiv preprint arXiv:1703.09076, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.09076"
        },
        {
            "id": "14",
            "entry": "[14] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In Proceedings of the 22nd ACM international conference on Multimedia, pages 675\u2013678. ACM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jia%2C%20Y.%20Shelhamer%2C%20E.%20Donahue%2C%20J.%20Karayev%2C%20S.%20Caffe%3A%20Convolutional%20architecture%20for%20fast%20feature%20embedding%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Y.%20Shelhamer%2C%20E.%20Donahue%2C%20J.%20Karayev%2C%20S.%20Caffe%3A%20Convolutional%20architecture%20for%20fast%20feature%20embedding%202014"
        },
        {
            "id": "15",
            "entry": "[15] J. Krause, H. Jin, J. Yang, and L. Fei-Fei. Fine-grained recognition without part annotations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5546\u20135555, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krause%2C%20J.%20Jin%2C%20H.%20Yang%2C%20J.%20Fei-Fei%2C%20L.%20Fine-grained%20recognition%20without%20part%20annotations%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krause%2C%20J.%20Jin%2C%20H.%20Yang%2C%20J.%20Fei-Fei%2C%20L.%20Fine-grained%20recognition%20without%20part%20annotations%202015"
        },
        {
            "id": "16",
            "entry": "[16] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Hinton%2C%20G.%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "17",
            "entry": "[17] Y. LeCun. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998.",
            "url": "http://yann.lecun.com/exdb/mnist/"
        },
        {
            "id": "18",
            "entry": "[18] C.-Y. Lee, P. W. Gallagher, and Z. Tu. Generalizing pooling functions in convolutional neural networks: Mixed, gated, and tree. In International conference on artificial intelligence and statistics, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20C.-Y.%20Gallagher%2C%20P.W.%20Tu%2C%20Z.%20Generalizing%20pooling%20functions%20in%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20C.-Y.%20Gallagher%2C%20P.W.%20Tu%2C%20Z.%20Generalizing%20pooling%20functions%20in%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "19",
            "entry": "[19] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu. Deeply-supervised nets. In Artificial Intelligence and Statistics, pages 562\u2013570, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CY%20Lee%20S%20Xie%20P%20Gallagher%20Z%20Zhang%20and%20Z%20Tu%20Deeplysupervised%20nets%20In%20Artificial%20Intelligence%20and%20Statistics%20pages%20562570%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=CY%20Lee%20S%20Xie%20P%20Gallagher%20Z%20Zhang%20and%20Z%20Tu%20Deeplysupervised%20nets%20In%20Artificial%20Intelligence%20and%20Statistics%20pages%20562570%202015"
        },
        {
            "id": "20",
            "entry": "[20] M. Liang and X. Hu. Recurrent convolutional neural network for object recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3367\u20133375, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20M.%20Hu%2C%20X.%20Recurrent%20convolutional%20neural%20network%20for%20object%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20M.%20Hu%2C%20X.%20Recurrent%20convolutional%20neural%20network%20for%20object%20recognition%202015"
        },
        {
            "id": "21",
            "entry": "[21] W. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song. Sphereface: Deep hypersphere embedding for face recognition. arXiv preprint arXiv:1704.08063, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.08063"
        },
        {
            "id": "22",
            "entry": "[22] W. Liu, Y. Wen, Z. Yu, and M. Yang. Large-margin softmax loss for convolutional neural networks. In Proceedings of The 33rd International Conference on Machine Learning (ICML), pages 507\u2013516, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20W.%20Wen%2C%20Y.%20Yu%2C%20Z.%20Yang%2C%20M.%20Large-margin%20softmax%20loss%20for%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20W.%20Wen%2C%20Y.%20Yu%2C%20Z.%20Yang%2C%20M.%20Large-margin%20softmax%20loss%20for%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "23",
            "entry": "[23] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng. Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning, volume 2011, page 5, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Netzer%2C%20Y.%20Wang%2C%20T.%20Coates%2C%20A.%20Bissacco%2C%20A.%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Y.%20Wang%2C%20T.%20Coates%2C%20A.%20Bissacco%2C%20A.%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "24",
            "entry": "[24] H. Oh Song, Y. Xiang, S. Jegelka, and S. Savarese. Deep metric learning via lifted structured feature embedding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 4004\u20134012, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20H.Oh%20Xiang%2C%20Y.%20Jegelka%2C%20S.%20Savarese%2C%20S.%20Deep%20metric%20learning%20via%20lifted%20structured%20feature%20embedding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20H.Oh%20Xiang%2C%20Y.%20Jegelka%2C%20S.%20Savarese%2C%20S.%20Deep%20metric%20learning%20via%20lifted%20structured%20feature%20embedding%202016"
        },
        {
            "id": "25",
            "entry": "[25] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep face recognition. In BMVC, volume 1, page 6, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parkhi%2C%20O.M.%20Vedaldi%2C%20A.%20Zisserman%2C%20A.%20Deep%20face%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parkhi%2C%20O.M.%20Vedaldi%2C%20A.%20Zisserman%2C%20A.%20Deep%20face%20recognition%202015"
        },
        {
            "id": "26",
            "entry": "[26] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20O.%20Deng%2C%20J.%20Su%2C%20H.%20Krause%2C%20J.%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "27",
            "entry": "[27] F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 815\u2013823, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schroff%2C%20F.%20Kalenichenko%2C%20D.%20Philbin%2C%20J.%20Facenet%3A%20A%20unified%20embedding%20for%20face%20recognition%20and%20clustering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schroff%2C%20F.%20Kalenichenko%2C%20D.%20Philbin%2C%20J.%20Facenet%3A%20A%20unified%20embedding%20for%20face%20recognition%20and%20clustering%202015"
        },
        {
            "id": "28",
            "entry": "[28] K. Sohn. Improved deep metric learning with multi-class n-pair loss objective. In Advances in Neural Information Processing Systems (NIPS), pages 1849\u20131857, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sohn%2C%20K.%20Improved%20deep%20metric%20learning%20with%20multi-class%20n-pair%20loss%20objective%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sohn%2C%20K.%20Improved%20deep%20metric%20learning%20with%20multi-class%20n-pair%20loss%20objective%202016"
        },
        {
            "id": "29",
            "entry": "[29] Y. Sun, Y. Chen, X. Wang, and X. Tang. Deep learning face representation by joint identification-verification. In Advances in neural information processing systems (NIPS), pages 1988\u20131996, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Y.%20Chen%2C%20Y.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20representation%20by%20joint%20identification-verification%201988",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Y.%20Chen%2C%20Y.%20Wang%2C%20X.%20Tang%2C%20X.%20Deep%20learning%20face%20representation%20by%20joint%20identification-verification%201988"
        },
        {
            "id": "30",
            "entry": "[30] Y. Sun, X. Wang, and X. Tang. Deeply learned face representations are sparse, selective, and robust. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2892\u20132900, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Y.%20Wang%2C%20X.%20Tang%2C%20X.%20Deeply%20learned%20face%20representations%20are%20sparse%2C%20selective%2C%20and%20robust%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Y.%20Wang%2C%20X.%20Tang%2C%20X.%20Deeply%20learned%20face%20representations%20are%20sparse%2C%20selective%2C%20and%20robust%202015"
        },
        {
            "id": "31",
            "entry": "[31] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1\u20139, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Liu%2C%20W.%20Jia%2C%20Y.%20Sermanet%2C%20P.%20Going%20deeper%20with%20convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20C.%20Liu%2C%20W.%20Jia%2C%20Y.%20Sermanet%2C%20P.%20Going%20deeper%20with%20convolutions%202015"
        },
        {
            "id": "32",
            "entry": "[32] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2818\u20132826, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20C.%20Vanhoucke%2C%20V.%20Ioffe%2C%20S.%20Shlens%2C%20J.%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20C.%20Vanhoucke%2C%20V.%20Ioffe%2C%20S.%20Shlens%2C%20J.%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016"
        },
        {
            "id": "33",
            "entry": "[33] F. Wang, X. Xiang, J. Cheng, and A. L. Yuille. Normface: l_2 hypersphere embedding for face verification. arXiv preprint arXiv:1704.06369, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.06369"
        },
        {
            "id": "34",
            "entry": "[34] Y. Wang, J. Choi, V. Morariu, and L. S. Davis. Mining discriminative triplets of patches for fine-grained classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1163\u20131172, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Y.%20Choi%2C%20J.%20Morariu%2C%20V.%20Davis%2C%20L.S.%20Mining%20discriminative%20triplets%20of%20patches%20for%20fine-grained%20classification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Y.%20Choi%2C%20J.%20Morariu%2C%20V.%20Davis%2C%20L.S.%20Mining%20discriminative%20triplets%20of%20patches%20for%20fine-grained%20classification%202016"
        },
        {
            "id": "35",
            "entry": "[35] P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, and P. Perona. Caltech-ucsd birds 200. 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Welinder%2C%20P.%20Branson%2C%20S.%20Mita%2C%20T.%20Wah%2C%20C.%20Caltech-ucsd%20birds%202010"
        },
        {
            "id": "36",
            "entry": "[36] Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A discriminative feature learning approach for deep face recognition. In European Conference on Computer Vision (ECCV), pages 499\u2013515.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wen%2C%20Y.%20Zhang%2C%20K.%20Li%2C%20Z.%20Qiao%2C%20Y.%20A%20discriminative%20feature%20learning%20approach%20for%20deep%20face%20recognition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wen%2C%20Y.%20Zhang%2C%20K.%20Li%2C%20Z.%20Qiao%2C%20Y.%20A%20discriminative%20feature%20learning%20approach%20for%20deep%20face%20recognition"
        },
        {
            "id": "37",
            "entry": "[37] X. Wu, R. He, and Z. Sun. A lightened cnn for deep face representation. arXiv preprint arXiv:1511.02683, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.02683"
        },
        {
            "id": "38",
            "entry": "[38] L. Xie, J. Wang, Z. Wei, M. Wang, and Q. Tian. Disturblabel: Regularizing cnn on the loss layer. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 4753\u20134762, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xie%2C%20L.%20Wang%2C%20J.%20Wei%2C%20Z.%20Wang%2C%20M.%20Disturblabel%3A%20Regularizing%20cnn%20on%20the%20loss%20layer%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xie%2C%20L.%20Wang%2C%20J.%20Wei%2C%20Z.%20Wang%2C%20M.%20Disturblabel%3A%20Regularizing%20cnn%20on%20the%20loss%20layer%202016"
        },
        {
            "id": "39",
            "entry": "[39] S. Zagoruyko and N. Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.07146"
        },
        {
            "id": "40",
            "entry": "[40] N. Zhang, J. Donahue, R. Girshick, and T. Darrell. Part-based r-cnns for fine-grained category detection. In European conference on computer vision (ECCV), pages 834\u2013849.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20N.%20Donahue%2C%20J.%20Girshick%2C%20R.%20Darrell%2C%20T.%20Part-based%20r-cnns%20for%20fine-grained%20category%20detection",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20N.%20Donahue%2C%20J.%20Girshick%2C%20R.%20Darrell%2C%20T.%20Part-based%20r-cnns%20for%20fine-grained%20category%20detection"
        },
        {
            "id": "41",
            "entry": "[41] F. Zhou and Y. Lin. Fine-grained image classification by exploring bipartite-graph labels. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1124\u20131133, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20F.%20Lin%2C%20Y.%20Fine-grained%20image%20classification%20by%20exploring%20bipartite-graph%20labels%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20F.%20Lin%2C%20Y.%20Fine-grained%20image%20classification%20by%20exploring%20bipartite-graph%20labels%202016"
        }
    ]
}
