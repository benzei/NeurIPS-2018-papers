{
    "filename": "7933-gen-oja-simple-efficient-algorithm-for-streaming-generalized-eigenvector-computation.pdf",
    "metadata": {
        "date": 2018,
        "title": "Gen-Oja: A Simple and Efficient Algorithm for Streaming Generalized Eigenvector Computation",
        "author": "Kush Bhatia\u2217 University of California, Berkeley kushbhatia@berkeley.edu",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7933-gen-oja-simple-efficient-algorithm-for-streaming-generalized-eigenvector-computation.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In this paper, we study the problems of principal Generalized Eigenvector computation and Canonical Correlation Analysis in the stochastic setting. We propose a simple and efficient algorithm, Gen-Oja, for these problems. We prove the global convergence of our algorithm, borrowing ideas from the theory of fastmixing Markov chains and two-time-scale stochastic approximation, showing that it achieves the optimal rate of convergence. In the process, we develop tools for understanding stochastic processes with Markovian noise which might be of independent interest."
    },
    "keywords": [
        {
            "term": "principal component",
            "url": "https://en.wikipedia.org/wiki/principal_component"
        },
        {
            "term": "stochastic approximation",
            "url": "https://en.wikipedia.org/wiki/stochastic_approximation"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "canonical correlation analysis",
            "url": "https://en.wikipedia.org/wiki/canonical_correlation_analysis"
        },
        {
            "term": "random variable",
            "url": "https://en.wikipedia.org/wiki/random_variable"
        },
        {
            "term": "markov chain",
            "url": "https://en.wikipedia.org/wiki/markov_chain"
        },
        {
            "term": "Principal Component Analysis",
            "url": "https://en.wikipedia.org/wiki/Principal_Component_Analysis"
        }
    ],
    "highlights": [
        "Cannonical Correlation Analysis (CCA) and the Generalized Eigenvalue Problem are two fundamental problems in machine learning and statistics, widely used for feature extraction in applications including regression [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], clustering [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] and classification [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>].<br/><br/>Originally introduced by Hotelling in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], Cannonical Correlation Analysis is a statistical tool for the analysis of multi-view data that can be viewed as a \u201ccorrelation-aware\" version of Principal Component Analysis (PCA)",
        "Introduced by Hotelling in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], Cannonical Correlation Analysis is a statistical tool for the analysis of multi-view data that can be viewed as a \u201ccorrelation-aware\" version of Principal Component Analysis (PCA)",
        "Given two multidimensional random variables, the objective in Cannonical Correlation Analysis is to obtain a pair of linear transformations that maximize the correlation between the transformed variables",
        "Cannonical Correlation Analysis aims to find a pair of vectors u, v \u2208 Rd such that projections of X onto v and Y onto u are maximally correlated",
        "We describe the evolution of the Markov chainst\u22650,t\u22650, in the process outlining the intuition underlying Gen-Oja and understanding the key challenges which arise in the convergence analysis",
        "We have proposed and analyzed a simple online algorithm to solve the streaming generalized eigenvector problem and applied it to Cannonical Correlation Analysis"
    ],
    "key_statements": [
        "Cannonical Correlation Analysis (CCA) and the Generalized Eigenvalue Problem are two fundamental problems in machine learning and statistics, widely used for feature extraction in applications including regression [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], clustering [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] and classification [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>].<br/><br/>Originally introduced by Hotelling in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], Cannonical Correlation Analysis is a statistical tool for the analysis of multi-view data that can be viewed as a \u201ccorrelation-aware\" version of Principal Component Analysis (PCA)",
        "Introduced by Hotelling in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], Cannonical Correlation Analysis is a statistical tool for the analysis of multi-view data that can be viewed as a \u201ccorrelation-aware\" version of Principal Component Analysis (PCA)",
        "Given two multidimensional random variables, the objective in Cannonical Correlation Analysis is to obtain a pair of linear transformations that maximize the correlation between the transformed variables",
        "Cannonical Correlation Analysis aims to find a pair of vectors u, v \u2208 Rd such that projections of X onto v and Y onto u are maximally correlated",
        "We propose a simple, globally convergent, two-line algorithm, Gen-Oja, for the stochastic principal generalized eigenvector problem and, as a consequence, we obtain a natural extension of Oja\u2019s algorithm for the streaming Cannonical Correlation Analysis problem",
        "We describe the evolution of the Markov chainst\u22650,t\u22650, in the process outlining the intuition underlying Gen-Oja and understanding the key challenges which arise in the convergence analysis",
        "We have proposed and analyzed a simple online algorithm to solve the streaming generalized eigenvector problem and applied it to Cannonical Correlation Analysis"
    ],
    "summary": [
        "Cannonical Correlation Analysis (CCA) and the Generalized Eigenvalue Problem are two fundamental problems in machine learning and statistics, widely used for feature extraction in applications including regression [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], clustering [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] and classification [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>].<br/><br/>Originally introduced by Hotelling in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], CCA is a statistical tool for the analysis of multi-view data that can be viewed as a \u201ccorrelation-aware\" version of Principal Component Analysis (PCA).",
        "We propose a simple, globally convergent, two-line algorithm, Gen-Oja, for the stochastic principal generalized eigenvector problem and, as a consequence, we obtain a natural extension of Oja\u2019s algorithm for the streaming CCA problem.",
        "Gen-Oja is an iterative algorithm which works by updating two coupled sequences at every time step.",
        "Sharp convergence results were obtained recently by [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>] and [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] for the principal eigenvector computation problem using Oja\u2019s algorithm and later extended to the streaming k-PCA setting by [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>].",
        "Gen-Oja takes a single stochastic gradient step for the inner least squares problem and updates its estimate of the eigenvector after each sample.",
        "With the setting of step-size \u03b1t = 1, Gen-Oja recovers the Oja\u2019s algorithm given by vt =",
        "While previous works on the stochastic CCA problem required to use logarithmic independent samples to solve the inner least-squares problem in order to perform an approximate power method step, the theory of two-time-scale stochastic approximation suggests that it is possible to obtain a similar effect by evolving the sequences wt and vt at two different time scales.",
        "We present our main convergence guarantee for Gen-Oja when applied to the streaming generalized eigenvector problem.",
        "The above result shows that with probability at least 1 \u2212 \u03b4, Gen-Oja converges in the B-norm to the right eigenvector, u1, corresponding to the maximum eigenvalue of the matrix B\u22121A.",
        "The proof follows the line of [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>] with two additional tedious difficulties: the Markovian noise is neither unbiased nor independent of the previous iterates, and the matrix B\u22121A is no longer symmetric, which is precisely why we consider the left eigenvector ui in the right-hand side of Eq (14).",
        "Solving the associated generalized streaming eigenvector problem, we obtain the following result for estimating the canonical correlation vector whose proof follows from Theorem 5.1.",
        "Since the method by [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>] is of complexity O(d2), we compare Gen-Oja to a method which alternates between one step of Oja\u2019s algorithm and \u03c4 steps of averaged stochastic gradient descent with constant step size 1/2R2.",
        "W\u221ae observe that considering the streaming average of [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>] on Gen-Oja with a step size \u03b2t \u221d 1/ t enables to recover the fast O(1/t) convergence while being robust to constant misspecification.",
        "We have proposed and analyzed a simple online algorithm to solve the streaming generalized eigenvector problem and applied it to CCA.",
        "It would be worth considering removing the dimension dependence in our convergence guarantee"
    ],
    "headline": "We study the problems of principal Generalized Eigenvector computation and Canonical Correlation Analysis in the stochastic setting",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Z. Allen-Zhu and Y. Li. First efficient convergence for streaming k-PCA: a global, gap-free, and nearoptimal rate. In Foundations of Computer Science (FOCS), 2017 IEEE 58th Annual Symposium on, pages 487\u2013492. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allen-Zhu%2C%20Z.%20Li%2C%20Y.%20First%20efficient%20convergence%20for%20streaming%20k-PCA%3A%20a%20global%2C%20gap-free%2C%20and%20nearoptimal%20rate%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allen-Zhu%2C%20Z.%20Li%2C%20Y.%20First%20efficient%20convergence%20for%20streaming%20k-PCA%3A%20a%20global%2C%20gap-free%2C%20and%20nearoptimal%20rate%202017"
        },
        {
            "id": "2",
            "entry": "[2] Z. Allen-Zhu and Y. Li. Doubly accelerated methods for faster CCA and generalized eigendecomposition. In International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allen-Zhu%2C%20Z.%20Li%2C%20Y.%20Doubly%20accelerated%20methods%20for%20faster%20CCA%20and%20generalized%20eigendecomposition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allen-Zhu%2C%20Z.%20Li%2C%20Y.%20Doubly%20accelerated%20methods%20for%20faster%20CCA%20and%20generalized%20eigendecomposition%202017"
        },
        {
            "id": "3",
            "entry": "[3] C. Andrieu, E. Moulines, and P. Priouret. Stability of stochastic approximation under verifiable conditions. SIAM Journal on Control and Optimization, 44(1):283\u2013312, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andrieu%2C%20C.%20Moulines%2C%20E.%20Priouret%2C%20P.%20Stability%20of%20stochastic%20approximation%20under%20verifiable%20conditions%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andrieu%2C%20C.%20Moulines%2C%20E.%20Priouret%2C%20P.%20Stability%20of%20stochastic%20approximation%20under%20verifiable%20conditions%202005"
        },
        {
            "id": "4",
            "entry": "[4] R. Arora, T. V. Marinov, P. Mianjy, and N. Srebro. Stochastic approximation for canonical correlation analysis. In Advances in Neural Information Processing Systems. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20R.%20Marinov%2C%20T.V.%20Mianjy%2C%20P.%20Srebro%2C%20N.%20Stochastic%20approximation%20for%20canonical%20correlation%20analysis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20R.%20Marinov%2C%20T.V.%20Mianjy%2C%20P.%20Srebro%2C%20N.%20Stochastic%20approximation%20for%20canonical%20correlation%20analysis%202017"
        },
        {
            "id": "5",
            "entry": "[5] F. Bach and E. Moulines. Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n). In Advances in Neural Information Processing Systems, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bach%2C%20F.%20Moulines%2C%20E.%20Non-strongly-convex%20smooth%20stochastic%20approximation%20with%20convergence%20rate%20O%281/n%29%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bach%2C%20F.%20Moulines%2C%20E.%20Non-strongly-convex%20smooth%20stochastic%20approximation%20with%20convergence%20rate%20O%281/n%29%202013"
        },
        {
            "id": "6",
            "entry": "[6] A. Benveniste, M. M\u00e9tivier, and P. Priouret. Adaptive Algorithms and Stochastic Approximations. Springer Publishing Company, Incorporated, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Benveniste%2C%20A.%20M%C3%A9tivier%2C%20M.%20Priouret%2C%20P.%20Adaptive%20Algorithms%20and%20Stochastic%20Approximations%201990"
        },
        {
            "id": "7",
            "entry": "[7] V. S. Borkar. Stochastic approximation with two time scales. Systems & Control Letters, 29(5):291\u2013294, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borkar%2C%20V.S.%20Stochastic%20approximation%20with%20two%20time%20scales%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borkar%2C%20V.S.%20Stochastic%20approximation%20with%20two%20time%20scales%201997"
        },
        {
            "id": "9",
            "entry": "[9] K. Chaudhuri, S. M. Kakade, K. Livescu, and K. Sridharan. Multi-view clustering via canonical correlation analysis. In International Conference on Machine Learning, pages 129\u2013136, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaudhuri%2C%20K.%20Kakade%2C%20S.M.%20Livescu%2C%20K.%20Sridharan%2C%20K.%20Multi-view%20clustering%20via%20canonical%20correlation%20analysis%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaudhuri%2C%20K.%20Kakade%2C%20S.M.%20Livescu%2C%20K.%20Sridharan%2C%20K.%20Multi-view%20clustering%20via%20canonical%20correlation%20analysis%202009"
        },
        {
            "id": "10",
            "entry": "[10] P. Diaconis and D. Freedman. Iterated random functions. SIAM Review, 41(1):45\u201376, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diaconis%2C%20P.%20Freedman%2C%20D.%20Iterated%20random%20functions%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diaconis%2C%20P.%20Freedman%2C%20D.%20Iterated%20random%20functions%201999"
        },
        {
            "id": "11",
            "entry": "[11] A. Dieuleveut, A. Durmus, and F. Bach. Bridging the gap between constant step size stochastic gradient descent and Markov chains. arXiv preprint arXiv:1707.06386, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06386"
        },
        {
            "id": "12",
            "entry": "[12] C. Gao, D. Garber, N. Srebro, J. Wang, and W. Wang. Stochastic canonical correlation analysis. arXiv preprint arXiv:1702.06533, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.06533"
        },
        {
            "id": "13",
            "entry": "[13] D. Garber, E. Hazan, J. Jin, S. Kakade, C. Musco, P. Netrapalli, and A. Sidford. Faster eigenvector computation via shift-and-invert preconditioning. In International Conference on Machine Learning, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Garber%2C%20D.%20Hazan%2C%20E.%20Jin%2C%20J.%20Kakade%2C%20S.%20Faster%20eigenvector%20computation%20via%20shift-and-invert%20preconditioning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Garber%2C%20D.%20Hazan%2C%20E.%20Jin%2C%20J.%20Kakade%2C%20S.%20Faster%20eigenvector%20computation%20via%20shift-and-invert%20preconditioning%202016"
        },
        {
            "id": "14",
            "entry": "[14] R. Ge, C. Jin, S. Kakade, P. Netrapalli, and A. Sidford. Efficient algorithms for large-scale generalized eigenvector computation and canonical correlation analysis. In International Conference on International Conference on Machine, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20R.%20Jin%2C%20C.%20Kakade%2C%20S.%20Netrapalli%2C%20P.%20Efficient%20algorithms%20for%20large-scale%20generalized%20eigenvector%20computation%20and%20canonical%20correlation%20analysis%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20R.%20Jin%2C%20C.%20Kakade%2C%20S.%20Netrapalli%2C%20P.%20Efficient%20algorithms%20for%20large-scale%20generalized%20eigenvector%20computation%20and%20canonical%20correlation%20analysis%202016"
        },
        {
            "id": "15",
            "entry": "[15] M. Hardt and E. Price. The noisy power method: A meta algorithm with applications. In Advances in Neural Information Processing Systems, pages 2861\u20132869, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20M.%20Price%2C%20E.%20The%20noisy%20power%20method%3A%20A%20meta%20algorithm%20with%20applications%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20M.%20Price%2C%20E.%20The%20noisy%20power%20method%3A%20A%20meta%20algorithm%20with%20applications%202014"
        },
        {
            "id": "16",
            "entry": "[16] H. Hotelling. Relations between two sets of variates. Biometrika, 28(3/4):321\u2013377, 1936.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hotelling%2C%20H.%20Relations%20between%20two%20sets%20of%20variates%201936",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hotelling%2C%20H.%20Relations%20between%20two%20sets%20of%20variates%201936"
        },
        {
            "id": "17",
            "entry": "[17] P. Jain, C. Jin, S. M. Kakade, P. Netrapalli, and A. Sidford. Streaming PCA: Matching matrix Bernstein and near-optimal finite sample guarantees for Oja\u2019s algorithm. In Conference on Learning Theory, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jain%2C%20P.%20Jin%2C%20C.%20Kakade%2C%20S.M.%20Netrapalli%2C%20P.%20Streaming%20PCA%3A%20Matching%20matrix%20Bernstein%20and%20near-optimal%20finite%20sample%20guarantees%20for%20Oja%E2%80%99s%20algorithm%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jain%2C%20P.%20Jin%2C%20C.%20Kakade%2C%20S.M.%20Netrapalli%2C%20P.%20Streaming%20PCA%3A%20Matching%20matrix%20Bernstein%20and%20near-optimal%20finite%20sample%20guarantees%20for%20Oja%E2%80%99s%20algorithm%202016"
        },
        {
            "id": "18",
            "entry": "[18] S. M. Kakade and D. P. Foster. Multi-view regression via canonical correlation analysis. In International Conference on Computational Learning Theory, pages 82\u201396.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kakade%2C%20S.M.%20Foster%2C%20D.P.%20Multi-view%20regression%20via%20canonical%20correlation%20analysis",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kakade%2C%20S.M.%20Foster%2C%20D.P.%20Multi-view%20regression%20via%20canonical%20correlation%20analysis"
        },
        {
            "id": "19",
            "entry": "[19] N. Karampatziakis and P. Mineiro. Discriminative features via generalized eigenvectors. arXiv preprint arXiv:1310.1934, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1310.1934"
        },
        {
            "id": "20",
            "entry": "[20] Y. Lu and D. P. Foster. Large scale canonical correlation analysis with iterative least squares. In Advances in Neural Information Processing Systems, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lu%2C%20Y.%20Foster%2C%20D.P.%20Large%20scale%20canonical%20correlation%20analysis%20with%20iterative%20least%20squares%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lu%2C%20Y.%20Foster%2C%20D.P.%20Large%20scale%20canonical%20correlation%20analysis%20with%20iterative%20least%20squares%202014"
        },
        {
            "id": "21",
            "entry": "[21] Z. Ma, Y. Lu, and D. Foster. Finding linear structure in large datasets with scalable canonical correlation analysis. In International Conference on International Conference on Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Z.%20Lu%2C%20Y.%20Foster%2C%20D.%20Finding%20linear%20structure%20in%20large%20datasets%20with%20scalable%20canonical%20correlation%20analysis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Z.%20Lu%2C%20Y.%20Foster%2C%20D.%20Finding%20linear%20structure%20in%20large%20datasets%20with%20scalable%20canonical%20correlation%20analysis%202015"
        },
        {
            "id": "22",
            "entry": "[22] S. P. Meyn and R. L. Tweedie. Markov Chains and Stochastic Stability. Cambridge University Press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meyn%2C%20S.P.%20Tweedie%2C%20R.L.%20Markov%20Chains%20and%20Stochastic%20Stability%202009"
        },
        {
            "id": "23",
            "entry": "[23] C. Musco and C. Musco. Randomized block Krylov methods for stronger and faster approximate singular value decomposition. In Advances in Neural Information Processing Systems, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Musco%2C%20C.%20Musco%2C%20C.%20Randomized%20block%20Krylov%20methods%20for%20stronger%20and%20faster%20approximate%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Musco%2C%20C.%20Musco%2C%20C.%20Randomized%20block%20Krylov%20methods%20for%20stronger%20and%20faster%20approximate%202015"
        },
        {
            "id": "24",
            "entry": "[24] A. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method Efficiency in Optimization. Wiley- Interscience Series in Discrete Mathematics. John Wiley & Sons, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovsky%2C%20A.S.%20Yudin%2C%20D.B.%20Problem%20Complexity%20and%20Method%20Efficiency%20in%20Optimization.%20Wiley-%20Interscience%20Series%20in%20Discrete%20Mathematics%201983"
        },
        {
            "id": "25",
            "entry": "[25] E. Oja. Simplified neuron model as a principal component analyzer. Journal of Mathematical Biology, 15 (3):267\u2013273, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oja%2C%20E.%20Simplified%20neuron%20model%20as%20a%20principal%20component%20analyzer%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oja%2C%20E.%20Simplified%20neuron%20model%20as%20a%20principal%20component%20analyzer%201982"
        },
        {
            "id": "26",
            "entry": "[26] H. Robbins and S. Monro. A stochastic approximation method. The Annals of Mathematical Statistics, 22 (3):400\u2013407, 1951.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robbins%2C%20H.%20Monro%2C%20S.%20A%20stochastic%20approximation%20method%201951",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Robbins%2C%20H.%20Monro%2C%20S.%20A%20stochastic%20approximation%20method%201951"
        },
        {
            "id": "28",
            "entry": "[28] D. Steinsaltz. Locally contractive iterated function systems. Annals of Probability, pages 1952\u20131979, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Steinsaltz%2C%20D.%20Locally%20contractive%20iterated%20function%20systems%201952",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Steinsaltz%2C%20D.%20Locally%20contractive%20iterated%20function%20systems%201952"
        },
        {
            "id": "29",
            "entry": "[29] N. Tripuraneni, N. Flammarion, F. Bach, and M. I. Jordan. Averaging stochastic gradient descent on Riemannian manifolds. In Conference on Learning Theory, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tripuraneni%2C%20N.%20Flammarion%2C%20N.%20Bach%2C%20F.%20Jordan%2C%20M.I.%20Averaging%20stochastic%20gradient%20descent%20on%20Riemannian%20manifolds%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tripuraneni%2C%20N.%20Flammarion%2C%20N.%20Bach%2C%20F.%20Jordan%2C%20M.I.%20Averaging%20stochastic%20gradient%20descent%20on%20Riemannian%20manifolds%202018"
        },
        {
            "id": "30",
            "entry": "[30] C. Villani. Optimal Transport: Old and New, volume 338. Springer-Verlag Berlin Heidelberg, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Villani%2C%20C.%20Optimal%20Transport%3A%20Old%20and%20New%2C%20volume%20338%202008"
        },
        {
            "id": "31",
            "entry": "[31] W. Wang, J. Wang, D. Garber, and N. Srebro. Efficient globally convergent stochastic optimization for canonical correlation analysis. In Advances in Neural Information Processing Systems, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20W.%20Wang%2C%20J.%20Garber%2C%20D.%20Srebro%2C%20N.%20Efficient%20globally%20convergent%20stochastic%20optimization%20for%20canonical%20correlation%20analysis%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20W.%20Wang%2C%20J.%20Garber%2C%20D.%20Srebro%2C%20N.%20Efficient%20globally%20convergent%20stochastic%20optimization%20for%20canonical%20correlation%20analysis%202016"
        }
    ]
}
