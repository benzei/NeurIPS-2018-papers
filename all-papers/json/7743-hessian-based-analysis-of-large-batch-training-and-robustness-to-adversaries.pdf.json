{
    "filename": "7743-hessian-based-analysis-of-large-batch-training-and-robustness-to-adversaries.pdf",
    "metadata": {
        "title": "Hessian-based Analysis of Large Batch Training and Robustness to Adversaries",
        "author": "Zhewei Yao, Amir Gholami, Qi Lei, Kurt Keutzer, Michael W. Mahoney",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7743-hessian-based-analysis-of-large-batch-training-and-robustness-to-adversaries.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Large batch size training of Neural Networks has been shown to incur accuracy loss when trained with the current methods. The exact underlying reasons for this are still not completely understood. Here, we study large batch size training through the lens of the Hessian operator and robust optimization. In particular, we perform a Hessian based study to analyze exactly how the landscape of the loss function changes when training with large batch size. We compute the true Hessian spectrum, without approximation, by back-propagating the second derivative. Extensive experiments on multiple networks show that saddle-points are not the cause for generalization gap of large batch size training, and the results consistently show that large batch converges to points with noticeably higher Hessian spectrum. Furthermore, we show that robust training allows one to favor flat areas, as points with large Hessian spectrum show poor robustness to adversarial perturbation. We further study this relationship, and provide empirical and theoretical proof that the inner loop for robust training is a saddle-free optimization problem almost everywhere. We present detailed experiments with five different network architectures, including a residual network, tested on MNIST, CIFAR-10/100 datasets."
    },
    "keywords": [
        {
            "term": "optimization problem",
            "url": "https://en.wikipedia.org/wiki/optimization_problem"
        },
        {
            "term": "saddle point",
            "url": "https://en.wikipedia.org/wiki/saddle_point"
        },
        {
            "term": "robust optimization",
            "url": "https://en.wikipedia.org/wiki/robust_optimization"
        },
        {
            "term": "Neural Network",
            "url": "https://en.wikipedia.org/wiki/Neural_Network"
        }
    ],
    "highlights": [
        "During the training of a Neural Network (NN), we are given a set of input data x with the corresponding labels y drawn from an unknown distribution P",
        "A2 We show that robust optimization is antithetical to large batch training, in the sense that it favors areas with small spectrum",
        "We studied Neural Network through the lens of the Hessian operator",
        "By computing the Hessian spectrum we provided several points of evidence that show that large batch size training tends to get attracted to areas with higher Hessian spectrum",
        "We provided several empirical results on multiple datasets that show large batch size training is more prone to adversarial attacks",
        "We observed that robust training is antithetical to large batch size training, in the sense that it favors areas with noticeably smaller Hessian spectrum w.r.t. \u2713"
    ],
    "key_statements": [
        "During the training of a Neural Network (NN), we are given a set of input data x with the corresponding labels y drawn from an unknown distribution P",
        "We only observe a set of discrete examples drawn from P, and train the Neural Network to learn this unknown distribution",
        "A2 We show that robust optimization is antithetical to large batch training, in the sense that it favors areas with small spectrum",
        "We show that points converged with large batch size are significantly more prone to adversarial attacks as compared to a model trained with small batch size",
        "We show that robust training progressively favors the opposite, leading to points with flat spectrum and robust to adversarial perturbation",
        "We provide empirical and theoretical proof that the inner loop of the robust optimization, where we find the worst case, is a saddle-free optimization problem",
        "We present results showing how robust training affects the spectrum with empirical studies",
        "Note that the values for total gradient along with the Hessian spectrum show that large batch does not get \u201cstuck\u201d in saddle points, but areas in the optimization landscape that have high curvature",
        "Going back to Fig. 4, we show how the spectrum changes during training when we use robust optimization",
        "A preliminary result is shown in Table 10, where we can see that robust optimization performs better for large batch size training as opposed to the baseline, or when we use the method proposed by [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>]",
        "We studied Neural Network through the lens of the Hessian operator",
        "By computing the Hessian spectrum we provided several points of evidence that show that large batch size training tends to get attracted to areas with higher Hessian spectrum",
        "Our empirical results show that adversarial attacks/training and large batches are closely related",
        "We provided several empirical results on multiple datasets that show large batch size training is more prone to adversarial attacks",
        "We observed that robust training is antithetical to large batch size training, in the sense that it favors areas with noticeably smaller Hessian spectrum w.r.t. \u2713",
        "We can see the results are consistent with the other datasets in that larger batches are less robust to adversarial perturbation, and the Hessian spectrum increases for larger batch"
    ],
    "summary": [
        "During the training of a Neural Network (NN), we are given a set of input data x with the corresponding labels y drawn from an unknown distribution P.",
        "The structure of this paper is as follows: We present the results by first analyzing how the spectrum changes during training, and test the generalization performances of the model for different batch sizes in \u00a72.",
        "We provide theoretical proof that finding adversarial perturbation is a saddle-free problem under certain conditions, and test the robustness of the model for different batch sizes.",
        "We can clearly see that the large batch size models have been attracted to areas with higher curvature for both the test and training losses.",
        "We test the robustness of the models trained with different batches to an adversarial attack.",
        "We report the performance for both the training and test datasets for different values of \u270f = 0.02, 0.01 (\u270f is the metric for the adversarial perturbation magnitude in L1 norm).",
        "Note that the values for total gradient along with the Hessian spectrum show that large batch does not get \u201cstuck\u201d in saddle points, but areas in the optimization landscape that have high curvature.",
        "We study how the Hessian spectrum and the landscape of the loss functional change after adversarial training is performed.",
        "A preliminary result is shown in Table 10, where we can see that robust optimization performs better for large batch size training as opposed to the baseline, or when we use the method proposed by [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>].",
        "We studied large batch size training and its connection with stability of the model in the presence of white-box adversarial attacks.",
        "We provided several empirical results on multiple datasets that show large batch size training is more prone to adversarial attacks.",
        "We observed that robust training is antithetical to large batch size training, in the sense that it favors areas with noticeably smaller Hessian spectrum w.r.t.",
        "We showed that even though the model may converge to an area with positive curvature when considering all of the training dataset, if we look at individual samples the Hessian can have significant negative eigenvalues.",
        "The main goal of this work has been to perform detailed analysis to better understand the problems with large batch training.",
        "We can see the results are consistent with the other datasets in that larger batches are less robust to adversarial perturbation, and the Hessian spectrum increases for larger batch"
    ],
    "headline": "We study large batch size training through the lens of the Hessian operator and robust optimization",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. cambridge university press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anthony%2C%20Martin%20Bartlett%2C%20Peter%20L.%20Neural%20network%20learning%3A%20Theoretical%20foundations%202009"
        },
        {
            "id": "2",
            "entry": "[2] Arjun Nitin Bhagoji, Daniel Cullina, and Prateek Mittal. Dimensionality reduction as a defense against evasion attacks on machine learning classifiers. arXiv preprint arXiv:1704.02654, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.02654"
        },
        {
            "id": "3",
            "entry": "[3] L\u00e9on Bottou, Corinna Cortes, John S Denker, Harris Drucker, Isabelle Guyon, Lawrence D Jackel, Yann LeCun, Urs A Muller, Edward Sackinger, Patrice Simard, et al. Comparison of classifier methods: a case study in handwritten digit recognition. In Computer Vision & Image Processing., Proceedings of the 12th IAPR International, volume 2, pages 77\u201382, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bottou%2C%20L%C3%A9on%20Cortes%2C%20Corinna%20Denker%2C%20John%20S.%20Drucker%2C%20Harris%20Comparison%20of%20classifier%20methods%3A%20a%20case%20study%20in%20handwritten%20digit%20recognition%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bottou%2C%20L%C3%A9on%20Cortes%2C%20Corinna%20Denker%2C%20John%20S.%20Drucker%2C%20Harris%20Comparison%20of%20classifier%20methods%3A%20a%20case%20study%20in%20handwritten%20digit%20recognition%201994"
        },
        {
            "id": "4",
            "entry": "[4] Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In Security and Privacy (SP), pages 39\u201357. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carlini%2C%20Nicholas%20Wagner%2C%20David%20Towards%20evaluating%20the%20robustness%20of%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carlini%2C%20Nicholas%20Wagner%2C%20David%20Towards%20evaluating%20the%20robustness%20of%20neural%20networks%202017"
        },
        {
            "id": "5",
            "entry": "[5] Pratik Chaudhari, Anna Choromanska, Stefano Soatto, and Yann LeCun. Entropy-SGD: Biasing gradient descent into wide valleys. arXiv preprint arXiv:1611.01838, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01838"
        },
        {
            "id": "6",
            "entry": "[6] Yann N Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, and Yoshua Bengio. Identifying and attacking the saddle point problem in high-dimensional nonconvex optimization. In Advances in neural information processing systems, pages 2933\u20132941, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dauphin%2C%20Yann%20N.%20Pascanu%2C%20Razvan%20Gulcehre%2C%20Caglar%20Cho%2C%20Kyunghyun%20Identifying%20and%20attacking%20the%20saddle%20point%20problem%20in%20high-dimensional%20nonconvex%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dauphin%2C%20Yann%20N.%20Pascanu%2C%20Razvan%20Gulcehre%2C%20Caglar%20Cho%2C%20Kyunghyun%20Identifying%20and%20attacking%20the%20saddle%20point%20problem%20in%20high-dimensional%20nonconvex%20optimization%202014"
        },
        {
            "id": "7",
            "entry": "[7] Olivier Delalleau and Yoshua Bengio. Shallow vs. deep sum-product networks. In Advances in Neural Information Processing Systems, pages 666\u2013674, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Delalleau%2C%20Olivier%20Bengio%2C%20Yoshua%20Shallow%20vs.%20deep%20sum-product%20networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Delalleau%2C%20Olivier%20Bengio%2C%20Yoshua%20Shallow%20vs.%20deep%20sum-product%20networks%202011"
        },
        {
            "id": "8",
            "entry": "[8] Guillaume Desjardins, Karen Simonyan, Razvan Pascanu, and Koray Kavukcuoglu. Natural neural networks. In Advances in Neural Information Processing Systems, pages 2071\u20132079, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guillaume%20Desjardins%20Karen%20Simonyan%20Razvan%20Pascanu%20and%20Koray%20Kavukcuoglu%20Natural%20neural%20networks%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pages%2020712079%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guillaume%20Desjardins%20Karen%20Simonyan%20Razvan%20Pascanu%20and%20Koray%20Kavukcuoglu%20Natural%20neural%20networks%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pages%2020712079%202015"
        },
        {
            "id": "9",
            "entry": "[9] Laurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio. Sharp minima can generalize for deep nets. arXiv preprint arXiv:1703.04933, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.04933"
        },
        {
            "id": "10",
            "entry": "[10] Stanley C Eisenstat and Homer F Walker. Choosing the forcing terms in an inexact newton method. SIAM Journal on Scientific Computing, 17(1):16\u201332, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eisenstat%2C%20Stanley%20C.%20Walker%2C%20Homer%20F.%20Choosing%20the%20forcing%20terms%20in%20an%20inexact%20newton%20method%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eisenstat%2C%20Stanley%20C.%20Walker%2C%20Homer%20F.%20Choosing%20the%20forcing%20terms%20in%20an%20inexact%20newton%20method%201996"
        },
        {
            "id": "11",
            "entry": "[11] Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00410"
        },
        {
            "id": "12",
            "entry": "[12] Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points\u2014online stochastic gradient for tensor decomposition. In Conference on Learning Theory, pages 797\u2013 842, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points%E2%80%94online%20stochastic%20gradient%20for%20tensor%20decomposition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points%E2%80%94online%20stochastic%20gradient%20for%20tensor%20decomposition%202015"
        },
        {
            "id": "13",
            "entry": "[13] A. Gholami, A. Azad, P. Jin, K. Keutzer, and A. Buluc. Integrated model, batch and domain parallelism in training neural networks. SPAA\u20198, 2018. [PDF].",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gholami%2C%20A.%20Azad%2C%20A.%20Jin%2C%20P.%20Keutzer%2C%20K.%20Integrated%20model%2C%20batch%20and%20domain%20parallelism%20in%20training%20neural%20networks%202018"
        },
        {
            "id": "14",
            "entry": "[14] Zhitao Gong, Wenlu Wang, and Wei-Shinn Ku. Adversarial and clean data are not twins. arXiv preprint arXiv:1704.04960, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04960"
        },
        {
            "id": "15",
            "entry": "[15] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6572"
        },
        {
            "id": "16",
            "entry": "[16] Priya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.02677"
        },
        {
            "id": "17",
            "entry": "[17] Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, and Patrick McDaniel. On the (statistical) detection of adversarial examples. arXiv preprint arXiv:1702.06280, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.06280"
        },
        {
            "id": "18",
            "entry": "[18] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Flat minima. Neural Computation, 9(1):1\u201342, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Flat%20minima%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Flat%20minima%201997"
        },
        {
            "id": "19",
            "entry": "[19] Forrest N Iandola, Matthew W Moskewicz, Khalid Ashraf, and Kurt Keutzer. Firecaffe: nearlinear acceleration of deep neural network training on compute clusters. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2592\u20132600, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iandola%2C%20Forrest%20N.%20Moskewicz%2C%20Matthew%20W.%20Ashraf%2C%20Khalid%20Keutzer%2C%20Kurt%20Firecaffe%3A%20nearlinear%20acceleration%20of%20deep%20neural%20network%20training%20on%20compute%20clusters%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Iandola%2C%20Forrest%20N.%20Moskewicz%2C%20Matthew%20W.%20Ashraf%2C%20Khalid%20Keutzer%2C%20Kurt%20Firecaffe%3A%20nearlinear%20acceleration%20of%20deep%20neural%20network%20training%20on%20compute%20clusters%202016"
        },
        {
            "id": "20",
            "entry": "[20] Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.04836"
        },
        {
            "id": "21",
            "entry": "[21] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world. arXiv preprint arXiv:1607.02533, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.02533"
        },
        {
            "id": "22",
            "entry": "[22] Nicolas Le Roux and Yoshua Bengio. Deep belief networks are compact universal approximators. Neural computation, 22(8):2192\u20132207, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roux%2C%20Nicolas%20Le%20Bengio%2C%20Yoshua%20Deep%20belief%20networks%20are%20compact%20universal%20approximators%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roux%2C%20Nicolas%20Le%20Bengio%2C%20Yoshua%20Deep%20belief%20networks%20are%20compact%20universal%20approximators%202010"
        },
        {
            "id": "23",
            "entry": "[23] Jason D Lee, Ioannis Panageas, Georgios Piliouras, Max Simchowitz, Michael I Jordan, and Benjamin Recht. First-order methods almost always avoid saddle points. arXiv preprint arXiv:1710.07406, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.07406"
        },
        {
            "id": "24",
            "entry": "[24] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Madry%2C%20Aleksander%20Makelov%2C%20Aleksandar%20Schmidt%2C%20Ludwig%20Tsipras%2C%20Dimitris%20Towards%20deep%20learning%20models%20resistant%20to%20adversarial%20attacks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Madry%2C%20Aleksander%20Makelov%2C%20Aleksandar%20Schmidt%2C%20Ludwig%20Tsipras%2C%20Dimitris%20Towards%20deep%20learning%20models%20resistant%20to%20adversarial%20attacks%202018"
        },
        {
            "id": "25",
            "entry": "[25] James Martens and Ilya Sutskever. Training deep and recurrent networks with hessian-free optimization. In Neural Networks: Tricks of the trade, pages 479\u2013535.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martens%2C%20James%20Sutskever%2C%20Ilya%20Training%20deep%20and%20recurrent%20networks%20with%20hessian-free%20optimization",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martens%2C%20James%20Sutskever%2C%20Ilya%20Training%20deep%20and%20recurrent%20networks%20with%20hessian-free%20optimization"
        },
        {
            "id": "26",
            "entry": "[26] Jan Hendrik Metzen, Tim Genewein, Volker Fischer, and Bastian Bischoff. On detecting adversarial perturbations. arXiv preprint arXiv:1702.04267, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.04267"
        },
        {
            "id": "27",
            "entry": "[27] Guido F Montufar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the number of linear regions of deep neural networks. In Advances in neural information processing systems, pages 2924\u20132932, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Montufar%2C%20Guido%20F.%20Pascanu%2C%20Razvan%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20On%20the%20number%20of%20linear%20regions%20of%20deep%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Montufar%2C%20Guido%20F.%20Pascanu%2C%20Razvan%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20On%20the%20number%20of%20linear%20regions%20of%20deep%20neural%20networks%202014"
        },
        {
            "id": "28",
            "entry": "[28] Jorma Rissanen. Modeling by shortest data description. Automatica, 14(5):465\u2013471, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rissanen%2C%20Jorma%20Modeling%20by%20shortest%20data%20description%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rissanen%2C%20Jorma%20Modeling%20by%20shortest%20data%20description%201978"
        },
        {
            "id": "29",
            "entry": "[29] Uri Shaham, Yutaro Yamada, and Sahand Negahban. Understanding adversarial training: Increasing local stability of neural nets through robust optimization. arXiv preprint arXiv:1511.05432, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05432"
        },
        {
            "id": "30",
            "entry": "[30] Samuel L Smith, Pieter-Jan Kindermans, and Quoc V Le. Don\u2019t decay the learning rate, increase the batch size. arXiv preprint arXiv:1711.00489, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.00489"
        },
        {
            "id": "31",
            "entry": "[31] Samuel L Smith and Quoc V Le. A bayesian perspective on generalization and stochastic gradient descent. Second workshop on Bayesian Deep Learning (NIPS 2017), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20Samuel%20L.%20Le%2C%20Quoc%20V.%20A%20bayesian%20perspective%20on%20generalization%20and%20stochastic%20gradient%20descent.%20Second%20workshop%20on%20Bayesian%20Deep%20Learning%202017"
        },
        {
            "id": "32",
            "entry": "[32] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6199"
        },
        {
            "id": "33",
            "entry": "[33] Zhewei Yao, Amir Gholami, Kurt Keutzer, and Michael Mahoney. Large batch size training of neural networks with adversarial training and second-order information. arXiv preprint arXiv:1810.01021, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1810.01021"
        },
        {
            "id": "34",
            "entry": "[34] Yang You, Igor Gitman, and Boris Ginsburg. Scaling SGD batch size to 32K for imagenet training. arXiv preprint arXiv:1708.03888, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.03888"
        },
        {
            "id": "35",
            "entry": "[35] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016. ",
            "arxiv_url": "https://arxiv.org/pdf/1611.03530"
        }
    ]
}
