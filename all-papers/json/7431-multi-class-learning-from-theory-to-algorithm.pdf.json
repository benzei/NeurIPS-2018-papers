{
    "filename": "7431-multi-class-learning-from-theory-to-algorithm.pdf",
    "metadata": {
        "title": "Multi-Class Learning: From Theory to Algorithm",
        "author": "Jian Li, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, Weiping Wang",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7431-multi-class-learning-from-theory-to-algorithm.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In this paper, we study the generalization performance of multi-class classification and obtain a shaper data-dependent generalization error bound with fast convergence rate, substantially improving the state-of-art bounds in the existing data-dependent generalization analysis. The theoretical analysis motivates us to devise two effective multi-class kernel learning algorithms with statistical guarantees. Experimental results show that our proposed methods can significantly outperform the existing multi-class classification methods."
    },
    "keywords": [
        {
            "term": "generalization error",
            "url": "https://en.wikipedia.org/wiki/generalization_error"
        },
        {
            "term": "kernel method",
            "url": "https://en.wikipedia.org/wiki/kernel_method"
        },
        {
            "term": "statistical learning theory",
            "url": "https://en.wikipedia.org/wiki/statistical_learning_theory"
        }
    ],
    "highlights": [
        "Multi-class classification is an important problem in various applications, such as natural language processing, information retrieval, computer vision, web advertising, etc",
        "We derive a novel data-dependent generalization bound for multi-class classification via the notion of local Rademacher complexity and further devise two effective multi-class kernel learning algorithms based on the above theoretical analysis",
        "We compare our proposed Conv-MKL (Algorithm 1) and SMSD-MKL (Algorithm 2) with 7 popular multi-class classification methods: One-against-One [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], One-against-the-Rest [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], 1-norm linear multi-class SVM (LMC) [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], generalized minimal norm problem solver (GMNP) [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], the Multiclass MKL (MC-MKL) with 1-norm and 2-norm [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>] and mixed-norm MKL solved by stochastic gradient descent (UFO-MKL) [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>]",
        "The above results show that the use of the local Rademacher complexity can significantly improve the performance of multi-class multiple kernel learning algorithms, which conforms to our theoretical analysis",
        "We studied the generalization performance of multi-class classification, and derived a sharper data dependent generalization error bound using the local Rademacher complexity, which is much sharper than existing data-dependent generalization bounds of multi-class classification",
        "Based on local Rademacher complexity, our analysis can be used as a solid basis for the design of new multi-class kernel learning algorithms"
    ],
    "key_statements": [
        "Multi-class classification is an important problem in various applications, such as natural language processing, information retrieval, computer vision, web advertising, etc",
        "We derive a novel data-dependent generalization bound for multi-class classification via the notion of local Rademacher complexity and further devise two effective multi-class kernel learning algorithms based on the above theoretical analysis",
        "We compare our proposed Conv-MKL (Algorithm 1) and SMSD-MKL (Algorithm 2) with 7 popular multi-class classification methods: One-against-One [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], One-against-the-Rest [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], 1-norm linear multi-class SVM (LMC) [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], generalized minimal norm problem solver (GMNP) [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], the Multiclass MKL (MC-MKL) with 1-norm and 2-norm [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>] and mixed-norm MKL solved by stochastic gradient descent (UFO-MKL) [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>]",
        "The above results show that the use of the local Rademacher complexity can significantly improve the performance of multi-class multiple kernel learning algorithms, which conforms to our theoretical analysis",
        "We studied the generalization performance of multi-class classification, and derived a sharper data dependent generalization error bound using the local Rademacher complexity, which is much sharper than existing data-dependent generalization bounds of multi-class classification",
        "Based on local Rademacher complexity, our analysis can be used as a solid basis for the design of new multi-class kernel learning algorithms"
    ],
    "summary": [
        "Multi-class classification is an important problem in various applications, such as natural language processing, information retrieval, computer vision, web advertising, etc.",
        "Some generalization bounds have been proposed to estimate the ability of multi-class classification algorithms based on different measures, such as VC-dimension [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>], Natarajan dimension",
        "We derive a novel data-dependent generalization bound for multi-class classification via the notion of local Rademacher complexity and further devise two effective multi-class kernel learning algorithms based on the above theoretical analysis.",
        "Using precomputed kernel matrices regularized by local Rademancher complexity, this method can be implemented by any p-norm multi-class MKL solvers; b) SMSD-MKL.",
        "Koltchinskii and Panchenko [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>] and Koltchinskii, Panchenko, and Lozano [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>] first introduced a margin-based bound for multi-class classification in terms of Rademacher complexity.",
        "We consider the use of the local Rademacher complexity to devise the novel multi-class classification algorithms, which have statistical guarantees and fast convergence rates.",
        "Generalization bounds based on the notion of Rademacher complexity for multi-class classification are standard [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>]:",
        "To derive sharper generalization bound, we consider the use of the local Rademacher complexity in this paper.",
        "We first estimate the local Rademacher complexity, and further derive a sharper generalization bound.",
        "The estimate the local Rademacher complexity of multi-class classification is given as follows.",
        "A sharper bound for multi-class classification based on the notion of local Rademacher complexity is derived as follows.",
        "We derive a sharper bound based on the local Rademacher complexity with order",
        "Motivated by the above analysis of generalization bound, we will exploit the properties of the local Rademacher complexity to devise two algorithms for multi-class multiple kernel learning (MC-MKL).",
        "We compare our proposed Conv-MKL (Algorithm 1) and SMSD-MKL (Algorithm 2) with 7 popular multi-class classification methods: One-against-One [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>], One-against-the-Rest [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], 1-norm linear multi-class SVM (LMC) [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>], generalized minimal norm problem solver (GMNP) [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], the Multiclass MKL (MC-MKL) with 1-norm and 2-norm [<a class=\"ref-link\" id=\"c38\" href=\"#r38\">38</a>] and mixed-norm MKL solved by stochastic gradient descent (UFO-MKL) [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>].",
        "The above results show that the use of the local Rademacher complexity can significantly improve the performance of multi-class multiple kernel learning algorithms, which conforms to our theoretical analysis.",
        "We studied the generalization performance of multi-class classification, and derived a sharper data dependent generalization error bound using the local Rademacher complexity, which is much sharper than existing data-dependent generalization bounds of multi-class classification.",
        "Based on local Rademacher complexity, our analysis can be used as a solid basis for the design of new multi-class kernel learning algorithms."
    ],
    "headline": "We study the generalization performance of multi-class classification and obtain a shaper data-dependent generalization error bound with fast convergence rate, substantially improving the state-of-art bounds in the existing data-dependent generalization analysis",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] E. L. Allwein, R. E. Schapire, and Y. Singer. Reducing multiclass to binary: A unifying approach for margin classifiers. Journal of machine learning research, 1:113\u2013141, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allwein%2C%20E.L.%20Schapire%2C%20R.E.%20Singer%2C%20Y.%20Reducing%20multiclass%20to%20binary%3A%20A%20unifying%20approach%20for%20margin%20classifiers%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allwein%2C%20E.L.%20Schapire%2C%20R.E.%20Singer%2C%20Y.%20Reducing%20multiclass%20to%20binary%3A%20A%20unifying%20approach%20for%20margin%20classifiers%202000"
        },
        {
            "id": "2",
            "entry": "[2] P. L. Bartlett, O. Bousquet, and S. Mendelson. Local Rademacher complexities. The Annals of Statistics, 33(4):1497\u20131537, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20P.L.%20Bousquet%2C%20O.%20Mendelson%2C%20S.%20Local%20Rademacher%20complexities%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20P.L.%20Bousquet%2C%20O.%20Mendelson%2C%20S.%20Local%20Rademacher%20complexities%202005"
        },
        {
            "id": "3",
            "entry": "[3] L. Bottou, C. Cortes, J. S. Denker, H. Drucker, I. Guyon, L. D. Jackel, Y. LeCun, U. A. Muller, E. Sackinger, P. Simard, et al. Comparison of classifier methods: a case study in handwritten digit recognition. In Proceedings of the 12th IAPR International Conference on Pattern Recognition, pages 77\u201382, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bottou%2C%20L.%20Cortes%2C%20C.%20Denker%2C%20J.S.%20Drucker%2C%20H.%20Comparison%20of%20classifier%20methods%3A%20a%20case%20study%20in%20handwritten%20digit%20recognition%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bottou%2C%20L.%20Cortes%2C%20C.%20Denker%2C%20J.S.%20Drucker%2C%20H.%20Comparison%20of%20classifier%20methods%3A%20a%20case%20study%20in%20handwritten%20digit%20recognition%201994"
        },
        {
            "id": "4",
            "entry": "[4] C. Cortes, M. Kloft, and M. Mohri. Learning kernels using local Rademacher complexity. In Advances in Neural Information Processing Systems 25 (NIPS), pages 2760\u20132768, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20C.%20Kloft%2C%20M.%20Mohri%2C%20M.%20Learning%20kernels%20using%20local%20Rademacher%20complexity%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20C.%20Kloft%2C%20M.%20Mohri%2C%20M.%20Learning%20kernels%20using%20local%20Rademacher%20complexity%202013"
        },
        {
            "id": "5",
            "entry": "[5] C. Cortes, M. Mohri, and A. Rostamizadeh. Multi-class classification with maximum margin multiple kernel. In Proceedings of the 30th International Conference on Machine Learning (ICML), pages 46\u201354, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20C.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Multi-class%20classification%20with%20maximum%20margin%20multiple%20kernel%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20C.%20Mohri%2C%20M.%20Rostamizadeh%2C%20A.%20Multi-class%20classification%20with%20maximum%20margin%20multiple%20kernel%202013"
        },
        {
            "id": "6",
            "entry": "[6] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of Machine Learning Research, 2:265\u2013292, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crammer%2C%20K.%20Singer%2C%20Y.%20On%20the%20algorithmic%20implementation%20of%20multiclass%20kernel-based%20vector%20machines%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Crammer%2C%20K.%20Singer%2C%20Y.%20On%20the%20algorithmic%20implementation%20of%20multiclass%20kernel-based%20vector%20machines%202002"
        },
        {
            "id": "7",
            "entry": "[7] A. Daniely and S. Shalev-Shwartz. Optimal learners for multiclass problems. In Proceedings of the 27th Conference on Learning Theory (COLT), pages 287\u2013316, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daniely%2C%20A.%20Shalev-Shwartz%2C%20S.%20Optimal%20learners%20for%20multiclass%20problems%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daniely%2C%20A.%20Shalev-Shwartz%2C%20S.%20Optimal%20learners%20for%20multiclass%20problems%202014"
        },
        {
            "id": "8",
            "entry": "[8] V. Franc. Optimization algorithms for kernel methods. Prague: A PhD dissertation. Czech Technical University, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Franc%2C%20V.%20Optimization%20algorithms%20for%20kernel%20methods.%20Prague%3A%20A%20PhD%20dissertation%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Franc%2C%20V.%20Optimization%20algorithms%20for%20kernel%20methods.%20Prague%3A%20A%20PhD%20dissertation%202005"
        },
        {
            "id": "9",
            "entry": "[9] Y. Guermeur. Combining discriminant models with new multi-class SVMs. Pattern Analysis & Applications, 5(2):168\u2013179, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guermeur%2C%20Y.%20Combining%20discriminant%20models%20with%20new%20multi-class%20SVMs%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guermeur%2C%20Y.%20Combining%20discriminant%20models%20with%20new%20multi-class%20SVMs%202002"
        },
        {
            "id": "10",
            "entry": "[10] M. Hardt, B. Recht, and Y. Singer. Train faster, generalize better: Stability of stochastic gradient descent. In Proceedings of the 33rd International Conference on Machine Learning (ICML), pages 1225\u20131234, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20M.%20Recht%2C%20B.%20Singer%2C%20Y.%20Train%20faster%2C%20generalize%20better%3A%20Stability%20of%20stochastic%20gradient%20descent%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20M.%20Recht%2C%20B.%20Singer%2C%20Y.%20Train%20faster%2C%20generalize%20better%3A%20Stability%20of%20stochastic%20gradient%20descent%202016"
        },
        {
            "id": "11",
            "entry": "[11] S. I. Hill and A. Doucet. A framework for kernel-based multi-category classification. Journal of Artificial Intelligence Research, 30:525\u2013564, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hill%2C%20S.I.%20Doucet%2C%20A.%20A%20framework%20for%20kernel-based%20multi-category%20classification%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hill%2C%20S.I.%20Doucet%2C%20A.%20A%20framework%20for%20kernel-based%20multi-category%20classification%202007"
        },
        {
            "id": "12",
            "entry": "[12] S. Knerr, L. Personnaz, and G. Dreyfus. Single-layer learning revisited: a stepwise procedure for building and training a neural network. In Neurocomputing, pages 41\u201350.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Knerr%2C%20S.%20Personnaz%2C%20L.%20Dreyfus%2C%20G.%20Single-layer%20learning%20revisited%3A%20a%20stepwise%20procedure%20for%20building%20and%20training%20a%20neural%20network",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Knerr%2C%20S.%20Personnaz%2C%20L.%20Dreyfus%2C%20G.%20Single-layer%20learning%20revisited%3A%20a%20stepwise%20procedure%20for%20building%20and%20training%20a%20neural%20network"
        },
        {
            "id": "13",
            "entry": "[13] V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization. The Annals of Statistics, 34(6):2593\u20132656, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koltchinskii%2C%20V.%20Local%20Rademacher%20complexities%20and%20oracle%20inequalities%20in%20risk%20minimization%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koltchinskii%2C%20V.%20Local%20Rademacher%20complexities%20and%20oracle%20inequalities%20in%20risk%20minimization%202006"
        },
        {
            "id": "14",
            "entry": "[14] V. Koltchinskii and D. Panchenko. Empirical margin distributions and bounding the generalization error of combined classifiers. The Annals of Statistics, 30:1\u201350, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koltchinskii%2C%20V.%20Panchenko%2C%20D.%20Empirical%20margin%20distributions%20and%20bounding%20the%20generalization%20error%20of%20combined%20classifiers%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koltchinskii%2C%20V.%20Panchenko%2C%20D.%20Empirical%20margin%20distributions%20and%20bounding%20the%20generalization%20error%20of%20combined%20classifiers%202002"
        },
        {
            "id": "15",
            "entry": "[15] V. Koltchinskii, D. Panchenko, and F. Lozano. Some new bounds on the generalization error of combined classifiers. In Advances in Neural Information Processing Systems 14 (NIPS), pages 245\u2013251, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koltchinskii%2C%20V.%20Panchenko%2C%20D.%20Lozano%2C%20F.%20Some%20new%20bounds%20on%20the%20generalization%20error%20of%20combined%20classifiers%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koltchinskii%2C%20V.%20Panchenko%2C%20D.%20Lozano%2C%20F.%20Some%20new%20bounds%20on%20the%20generalization%20error%20of%20combined%20classifiers%202001"
        },
        {
            "id": "16",
            "entry": "[16] V. Kuznetsov, M. Mohri, and U. Syed. Multi-class deep boosting. In Advances in Neural Information Processing Systems 27 (NIPS), pages 2501\u20132509, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuznetsov%2C%20V.%20Mohri%2C%20M.%20Syed%2C%20U.%20Multi-class%20deep%20boosting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuznetsov%2C%20V.%20Mohri%2C%20M.%20Syed%2C%20U.%20Multi-class%20deep%20boosting%202014"
        },
        {
            "id": "17",
            "entry": "[17] G. R. G. Lanckriet, N. Cristianini, P. L. Bartlett, L. E. Ghaoui, and M. I. Jordan. Learning the kernel matrix with semidefinite programming. Journal of Machine Learning Research, 5:27\u201372, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lanckriet%2C%20G.R.G.%20Cristianini%2C%20N.%20Bartlett%2C%20P.L.%20Ghaoui%2C%20L.E.%20Learning%20the%20kernel%20matrix%20with%20semidefinite%20programming%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lanckriet%2C%20G.R.G.%20Cristianini%2C%20N.%20Bartlett%2C%20P.L.%20Ghaoui%2C%20L.E.%20Learning%20the%20kernel%20matrix%20with%20semidefinite%20programming%202004"
        },
        {
            "id": "18",
            "entry": "[18] Y. Lei, U. D. A. Binder, and M. Kloft. Multi-class SVMs: From tighter data-dependent generalization bounds to novel algorithms. In Advances in Neural Information Processing Systems 27 (NIPS), pages 2035\u20132043, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lei%2C%20Y.%20Binder%2C%20U.D.A.%20Kloft%2C%20M.%20Multi-class%20SVMs%3A%20From%20tighter%20data-dependent%20generalization%20bounds%20to%20novel%20algorithms%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lei%2C%20Y.%20Binder%2C%20U.D.A.%20Kloft%2C%20M.%20Multi-class%20SVMs%3A%20From%20tighter%20data-dependent%20generalization%20bounds%20to%20novel%20algorithms%202015"
        },
        {
            "id": "19",
            "entry": "[19] Y. Liu, S. Jiang, and S. Liao. Eigenvalues perturbation of integral operator for kernel selection. In Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM), pages 2189\u20132198, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Jiang%2C%20S.%20Liao%2C%20S.%20Eigenvalues%20perturbation%20of%20integral%20operator%20for%20kernel%20selection%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Jiang%2C%20S.%20Liao%2C%20S.%20Eigenvalues%20perturbation%20of%20integral%20operator%20for%20kernel%20selection%202013"
        },
        {
            "id": "20",
            "entry": "[20] Y. Liu, S. Jiang, and S. Liao. Efficient approximation of cross-validation for kernel methods using Bouligand influence function. In Proceedings of the 31st International Conference on Machine Learning (ICML), pages 324\u2013332, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Jiang%2C%20S.%20Liao%2C%20S.%20Efficient%20approximation%20of%20cross-validation%20for%20kernel%20methods%20using%20Bouligand%20influence%20function%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Jiang%2C%20S.%20Liao%2C%20S.%20Efficient%20approximation%20of%20cross-validation%20for%20kernel%20methods%20using%20Bouligand%20influence%20function%202014"
        },
        {
            "id": "21",
            "entry": "[21] Y. Liu and S. Liao. Preventing over-fitting of cross-validation with kernel stability. In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML), pages 290\u2013305, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Liao%2C%20S.%20Preventing%20over-fitting%20of%20cross-validation%20with%20kernel%20stability%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Liao%2C%20S.%20Preventing%20over-fitting%20of%20cross-validation%20with%20kernel%20stability%202014"
        },
        {
            "id": "22",
            "entry": "[22] Y. Liu and S. Liao. Eigenvalues ratio for kernel selection of kernel methods. In Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI), pages 2814\u20132820, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Liao%2C%20S.%20Eigenvalues%20ratio%20for%20kernel%20selection%20of%20kernel%20methods%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Liao%2C%20S.%20Eigenvalues%20ratio%20for%20kernel%20selection%20of%20kernel%20methods%202015"
        },
        {
            "id": "23",
            "entry": "[23] Y. Liu, S. Liao, and Y. Hou. Learning kernels with upper bounds of leave-one-out error. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management (CIKM), pages 2205\u20132208, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Liao%2C%20S.%20Hou%2C%20Y.%20Learning%20kernels%20with%20upper%20bounds%20of%20leave-one-out%20error%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Liao%2C%20S.%20Hou%2C%20Y.%20Learning%20kernels%20with%20upper%20bounds%20of%20leave-one-out%20error%202011"
        },
        {
            "id": "24",
            "entry": "[24] Y. Liu, S. Liao, H. Lin, Y. Yue, and W. Wang. Infinite kernel learning: generalization bounds and algorithms. In Proceedings of the 21st AAAI Conference on Artificial Intelligence (AAAI), pages 2280\u20132286, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Y.%20Liao%2C%20S.%20Lin%2C%20H.%20Yue%2C%20Y.%20Infinite%20kernel%20learning%3A%20generalization%20bounds%20and%20algorithms%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Y.%20Liao%2C%20S.%20Lin%2C%20H.%20Yue%2C%20Y.%20Infinite%20kernel%20learning%3A%20generalization%20bounds%20and%20algorithms%202017"
        },
        {
            "id": "25",
            "entry": "[25] Y. Maximov and D. Reshetova. Tight risk bounds for multi-class margin classifiers. Pattern Recognition and Image Analysis, 26(4):673\u2013680, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maximov%2C%20Y.%20Reshetova%2C%20D.%20Tight%20risk%20bounds%20for%20multi-class%20margin%20classifiers%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maximov%2C%20Y.%20Reshetova%2C%20D.%20Tight%20risk%20bounds%20for%20multi-class%20margin%20classifiers%202016"
        },
        {
            "id": "26",
            "entry": "[26] D. McAllester. A pac-bayesian tutorial with a dropout bound. Arxiv\u201913, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McAllester%2C%20D.%20A%20pac-bayesian%20tutorial%20with%20a%20dropout%20bound%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McAllester%2C%20D.%20A%20pac-bayesian%20tutorial%20with%20a%20dropout%20bound%202013"
        },
        {
            "id": "27",
            "entry": "[27] M. Moh, A. Rostamizadeh, and A. Talwalkar. Foundations of machine learning. MIT press, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Moh%2C%20M.%20Rostamizadeh%2C%20A.%20Talwalkar%2C%20A.%20Foundations%20of%20machine%20learning%202012"
        },
        {
            "id": "28",
            "entry": "[28] B. K. Natarajan. On learning sets and functions. Machine Learning, 4(1):67\u201397, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Natarajan%2C%20B.K.%20On%20learning%20sets%20and%20functions%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Natarajan%2C%20B.K.%20On%20learning%20sets%20and%20functions%201989"
        },
        {
            "id": "29",
            "entry": "[29] F. Orabona and J. Luo. Ultra-fast optimization algorithm for sparse multi kernel learning. In Proceedings of the 28th International Conference on Machine Learning (ICML), pages 249\u2013256, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Orabona%2C%20F.%20Luo%2C%20J.%20Ultra-fast%20optimization%20algorithm%20for%20sparse%20multi%20kernel%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Orabona%2C%20F.%20Luo%2C%20J.%20Ultra-fast%20optimization%20algorithm%20for%20sparse%20multi%20kernel%20learning%202011"
        },
        {
            "id": "30",
            "entry": "[30] F. Orabona, J. Luo, and B. Caputo. Online-batch strongly convex multi kernel learning. In The 23rd IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 787\u2013794, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Orabona%2C%20F.%20Luo%2C%20J.%20Caputo%2C%20B.%20Online-batch%20strongly%20convex%20multi%20kernel%20learning%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Orabona%2C%20F.%20Luo%2C%20J.%20Caputo%2C%20B.%20Online-batch%20strongly%20convex%20multi%20kernel%20learning%202010"
        },
        {
            "id": "31",
            "entry": "[31] S. Shalev-Shwartz and A. Tewari. Stochastic methods for l1-regularized loss minimization. Journal of Machine Learning Research, 12:1865\u20131892, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shalev-Shwartz%2C%20S.%20Tewari%2C%20A.%20Stochastic%20methods%20for%20l1-regularized%20loss%20minimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shalev-Shwartz%2C%20S.%20Tewari%2C%20A.%20Stochastic%20methods%20for%20l1-regularized%20loss%20minimization%202011"
        },
        {
            "id": "32",
            "entry": "[32] S. Sonnenburg, G. R\u00e4tsch, C. Sch\u00e4fer, and B. Sch\u00f6lkopf. Large scale multiple kernel learning. Journal of Machine Learning Research, 7:1531\u20131565, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sonnenburg%2C%20S.%20R%C3%A4tsch%2C%20G.%20Sch%C3%A4fer%2C%20C.%20Sch%C3%B6lkopf%2C%20B.%20Large%20scale%20multiple%20kernel%20learning%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sonnenburg%2C%20S.%20R%C3%A4tsch%2C%20G.%20Sch%C3%A4fer%2C%20C.%20Sch%C3%B6lkopf%2C%20B.%20Large%20scale%20multiple%20kernel%20learning%202006"
        },
        {
            "id": "33",
            "entry": "[33] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In Proceedings of the 21st International Conference on Machine Learning (ICML), page 104, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsochantaridis%2C%20I.%20Hofmann%2C%20T.%20Joachims%2C%20T.%20Altun%2C%20Y.%20Support%20vector%20machine%20learning%20for%20interdependent%20and%20structured%20output%20spaces%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsochantaridis%2C%20I.%20Hofmann%2C%20T.%20Joachims%2C%20T.%20Altun%2C%20Y.%20Support%20vector%20machine%20learning%20for%20interdependent%20and%20structured%20output%20spaces%202004"
        },
        {
            "id": "34",
            "entry": "[34] V. Vapnik. The nature of statistical learning theory. Springer Verlag, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vapnik%2C%20V.%20The%20nature%20of%20statistical%20learning%20theory%202000"
        },
        {
            "id": "35",
            "entry": "[35] C. Xu, T. Liu, D. Tao, and C. Xu. Local rademacher complexity for multi-label learning. IEEE Transactions on Image Processing, 25(3):1495\u20131507, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20C.%20Liu%2C%20T.%20Tao%2C%20D.%20Xu%2C%20C.%20Local%20rademacher%20complexity%20for%20multi-label%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20C.%20Liu%2C%20T.%20Tao%2C%20D.%20Xu%2C%20C.%20Local%20rademacher%20complexity%20for%20multi-label%20learning%202016"
        },
        {
            "id": "36",
            "entry": "[36] N. Yousefi, Y. Lei, M. Kloft, M. Mollaghasemi, and G. Anagnostopoulos. Local rademacher complexity-based learning guarantees for multi-task learning. arXiv preprint arXiv:1602.05916, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.05916"
        },
        {
            "id": "37",
            "entry": "[37] T. Zhang. Statistical analysis of some multi-category large margin classification methods. Journal of Machine Learning Research, 5:1225\u20131251, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20T.%20Statistical%20analysis%20of%20some%20multi-category%20large%20margin%20classification%20methods%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20T.%20Statistical%20analysis%20of%20some%20multi-category%20large%20margin%20classification%20methods%202004"
        },
        {
            "id": "38",
            "entry": "[38] A. Zien and C. S. Ong. Multiclass multiple kernel learning. In Proceedings of the 24th International Conference on Machine Learning (ICML), pages 1191\u20131198, 2007. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zien%2C%20A.%20Ong%2C%20C.S.%20Multiclass%20multiple%20kernel%20learning%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zien%2C%20A.%20Ong%2C%20C.S.%20Multiclass%20multiple%20kernel%20learning%202007"
        }
    ]
}
