{
    "filename": "7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf",
    "metadata": {
        "title": "Hierarchical Graph Representation Learning with Differentiable Pooling",
        "author": "Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, Jure Leskovec",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs\u2014a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DIFFPOOL, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DIFFPOOL learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DIFFPOOL yields an average improvement of 5\u201310% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark data sets."
    },
    "keywords": [
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "graph representation",
            "url": "https://en.wikipedia.org/wiki/graph_representation"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "new state",
            "url": "https://en.wikipedia.org/wiki/New_State"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "highlights": [
        "In recent years there has been a surge of interest in developing graph neural networks (GNNs)\u2014 general deep learning architectures that can operate over graph structured data, such as social network data [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>] or graph-based representations of molecules [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "We show that DIFFPOOL can be combined with various graph neural networks approaches, resulting in an average 7% gain in accuracy and a new state of the art on four out of five benchmark graph classification tasks",
        "In the context of graph classification\u2014the task that we study here\u2014a major challenge in applying graph neural networks is going from node embeddings, which are the output of graph neural networks, to a representation of the entire graph",
        "At the penultimate layer L \u2212 1 of a deep graph neural networks model using DIFFPOOL, we set the assignment matrix S(L\u22121) be a vector of 1\u2019s, i.e., all nodes at the final layer L are assigned to a single cluster, generating a final embedding vector corresponding to the entire graph",
        "The graph neural networks model used for DIFFPOOL is built on top of the GRAPHSAGE architecture, as we found this architecture to have superior performance compared to the standard Graph Convolutional Networks approach as introduced in [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]",
        "We introduced a differentiable pooling method for graph neural networks that is able to extract the complex hierarchical structure of real-world graphs"
    ],
    "key_statements": [
        "In recent years there has been a surge of interest in developing graph neural networks (GNNs)\u2014 general deep learning architectures that can operate over graph structured data, such as social network data [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>] or graph-based representations of molecules [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>]",
        "The general approach with graph neural networks is to view the underlying graph as a computation graph and learn neural network primitives that generate individual node embeddings by passing, transforming, and aggregating node feature information across the graph [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>]",
        "We show that DIFFPOOL can be combined with various graph neural networks approaches, resulting in an average 7% gain in accuracy and a new state of the art on four out of five benchmark graph classification tasks",
        "In the context of graph classification\u2014the task that we study here\u2014a major challenge in applying graph neural networks is going from node embeddings, which are the output of graph neural networks, to a representation of the entire graph",
        "The differentiable pooling model we propose can be applied to any graph neural networks model implementing Equation (1), and is agnostic with regards to the specifics of how M is implemented",
        "DIFFPOOL, addresses the above challenges by learning a cluster assignment matrix over the nodes using the output of a graph neural networks model",
        "At the penultimate layer L \u2212 1 of a deep graph neural networks model using DIFFPOOL, we set the assignment matrix S(L\u22121) be a vector of 1\u2019s, i.e., all nodes at the final layer L are assigned to a single cluster, generating a final embedding vector corresponding to the entire graph",
        "We evaluate the benefits of DIFFPOOL against a number of state-of-the-art graph classification approaches, with the goal of answering the following questions: Q1 How does DIFFPOOL compare to other pooling methods proposed for graph neural networks?",
        "The graph neural networks model used for DIFFPOOL is built on top of the GRAPHSAGE architecture, as we found this architecture to have superior performance compared to the standard Graph Convolutional Networks approach as introduced in [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]",
        "SORTPOOL [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>] applies a graph neural networks architecture and performs a single layer of soft pooling followed by 1D convolution on sorted node embeddings",
        "We introduced a differentiable pooling method for graph neural networks that is able to extract the complex hierarchical structure of real-world graphs"
    ],
    "summary": [
        "In recent years there has been a surge of interest in developing graph neural networks (GNNs)\u2014 general deep learning architectures that can operate over graph structured data, such as social network data [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>] or graph-based representations of molecules [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>].",
        "Our approach DIFFPOOL learns a differentiable soft assignment at each layer of a deep GNN, mapping nodes to a set of clusters based on their learned embeddings.",
        "The key idea of DIFFPOOL is that it enables the construction of deep, multi-layer GNN models by providing a differentiable module to hierarchically pool graph nodes.",
        "Our goal is to learn how to cluster or pool together nodes using the output of a GNN, so that we can use this coarsened graph as input to another GNN layer.",
        "DIFFPOOL, addresses the above challenges by learning a cluster assignment matrix over the nodes using the output of a GNN model.",
        "The GNNs in DIFFPOOL learn to encode a general pooling strategy that is useful for a large set of training graphs.",
        "We generate these two matrices using two separate GNNs that are both applied to the input cluster node features X(l) and coarsened adjacency matrix A(l).",
        "At the penultimate layer L \u2212 1 of a deep GNN model using DIFFPOOL, we set the assignment matrix S(L\u22121) be a vector of 1\u2019s, i.e., all nodes at the final layer L are assigned to a single cluster, generating a final embedding vector corresponding to the entire graph.",
        "We evaluate the benefits of DIFFPOOL against a number of state-of-the-art graph classification approaches, with the goal of answering the following questions: Q1 How does DIFFPOOL compare to other pooling methods proposed for GNNs?",
        "STRUCTURE2VEC (S2V) [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>] is a state-of-the-art graph representation learning algorithm that combines a latent variable model with GNNs. It uses global mean pooling.",
        "SORTPOOL [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>] applies a GNN architecture and performs a single layer of soft pooling followed by 1D convolution on sorted node embeddings.",
        "DIFFPOOL can be applied to other GNN architectures besides GRAPHSAGE to capture hierarchical structure in the graph data.",
        "We observe that even when learning cluster assignment based solely on the graph classification objective, DIFFPOOL can still capture the hierarchical community structure.",
        "By using the proposed pooling layer in conjunction with existing GNN models, we achieved new state-of-the-art results on several graph classification benchmarks.",
        "Interesting future directions include learning hard cluster assignments to further reduce computational cost in higher layers while ensuring differentiability, and applying the hierarchical pooling method to other downstream tasks that require modeling of the entire graph structure."
    ],
    "headline": "We propose DIFFPOOL, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Bianchini, M. Gori, and F. Scarselli. Processing directed acyclic graphs with recursive neural networks. IEEE Transactions on Neural Networks, 12(6):1464\u20131470, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bianchini%2C%20M.%20Gori%2C%20M.%20Scarselli%2C%20F.%20Processing%20directed%20acyclic%20graphs%20with%20recursive%20neural%20networks%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bianchini%2C%20M.%20Gori%2C%20M.%20Scarselli%2C%20F.%20Processing%20directed%20acyclic%20graphs%20with%20recursive%20neural%20networks%202001"
        },
        {
            "id": "2",
            "entry": "[2] K. M. Borgwardt and H.-P. Kriegel. Shortest-path kernels on graphs. In IEEE International Conference on Data Mining, pages 74\u201381, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borgwardt%2C%20K.M.%20Kriegel%2C%20H.-P.%20Shortest-path%20kernels%20on%20graphs%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borgwardt%2C%20K.M.%20Kriegel%2C%20H.-P.%20Shortest-path%20kernels%20on%20graphs%202005"
        },
        {
            "id": "3",
            "entry": "[3] K. M. Borgwardt, C. S. Ong, S. Sch\u00f6nauer, S. V. N. Vishwanathan, A. J. Smola, and H.P. Kriegel. Protein function prediction via graph kernels. Bioinformatics, 21(Supplement 1):i47\u2013i56, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borgwardt%2C%20K.M.%20Ong%2C%20C.S.%20Sch%C3%B6nauer%2C%20S.%20Vishwanathan%2C%20S.V.N.%20Protein%20function%20prediction%20via%20graph%20kernels%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borgwardt%2C%20K.M.%20Ong%2C%20C.S.%20Sch%C3%B6nauer%2C%20S.%20Vishwanathan%2C%20S.V.N.%20Protein%20function%20prediction%20via%20graph%20kernels%202005"
        },
        {
            "id": "4",
            "entry": "[4] M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Vandergheynst. Geometric deep learning: Going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18\u201342, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bronstein%2C%20M.M.%20Bruna%2C%20J.%20LeCun%2C%20Y.%20Szlam%2C%20A.%20Geometric%20deep%20learning%3A%20Going%20beyond%20euclidean%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bronstein%2C%20M.M.%20Bruna%2C%20J.%20LeCun%2C%20Y.%20Szlam%2C%20A.%20Geometric%20deep%20learning%3A%20Going%20beyond%20euclidean%20data%202017"
        },
        {
            "id": "5",
            "entry": "[5] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and deep locally connected networks on graphs. In International Conference on Learning Representations, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bruna%2C%20J.%20Zaremba%2C%20W.%20Szlam%2C%20A.%20LeCun%2C%20Y.%20Spectral%20networks%20and%20deep%20locally%20connected%20networks%20on%20graphs%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bruna%2C%20J.%20Zaremba%2C%20W.%20Szlam%2C%20A.%20LeCun%2C%20Y.%20Spectral%20networks%20and%20deep%20locally%20connected%20networks%20on%20graphs%202014"
        },
        {
            "id": "6",
            "entry": "[6] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1\u201327:27, 2011. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.",
            "url": "http://www.csie.ntu.edu.tw/~cjlin/libsvm",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20C.-C.%20Lin%2C%20C.-J.%20LIBSVM%3A%20A%20library%20for%20support%20vector%20machines%202011"
        },
        {
            "id": "7",
            "entry": "[7] H. Dai, B. Dai, and L. Song. Discriminative embeddings of latent variable models for structured data. In International Conference on Machine Learning, pages 2702\u20132711, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20H.%20Dai%2C%20B.%20Song%2C%20L.%20Discriminative%20embeddings%20of%20latent%20variable%20models%20for%20structured%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20H.%20Dai%2C%20B.%20Song%2C%20L.%20Discriminative%20embeddings%20of%20latent%20variable%20models%20for%20structured%20data%202016"
        },
        {
            "id": "8",
            "entry": "[8] M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems, pages 3844\u20133852, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Defferrard%2C%20M.%20Bresson%2C%20X.%20Vandergheynst%2C%20P.%20Convolutional%20neural%20networks%20on%20graphs%20with%20fast%20localized%20spectral%20filtering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Defferrard%2C%20M.%20Bresson%2C%20X.%20Vandergheynst%2C%20P.%20Convolutional%20neural%20networks%20on%20graphs%20with%20fast%20localized%20spectral%20filtering%202016"
        },
        {
            "id": "9",
            "entry": "[9] I. S. Dhillon, Y. Guan, and B. Kulis. Weighted graph cuts without eigenvectors a multilevel approach. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(11):1944\u20131957, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dhillon%2C%20I.S.%20Guan%2C%20Y.%20Kulis%2C%20B.%20Weighted%20graph%20cuts%20without%20eigenvectors%20a%20multilevel%20approach%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dhillon%2C%20I.S.%20Guan%2C%20Y.%20Kulis%2C%20B.%20Weighted%20graph%20cuts%20without%20eigenvectors%20a%20multilevel%20approach%202007"
        },
        {
            "id": "10",
            "entry": "[10] P. D. Dobson and A. J. Doig. Distinguishing enzyme structures from non-enzymes without alignments. Journal of Molecular Biology, 330(4):771 \u2013 783, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dobson%2C%20P.D.%20Doig%2C%20A.J.%20Distinguishing%20enzyme%20structures%20from%20non-enzymes%20without%20alignments%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dobson%2C%20P.D.%20Doig%2C%20A.J.%20Distinguishing%20enzyme%20structures%20from%20non-enzymes%20without%20alignments%202003"
        },
        {
            "id": "11",
            "entry": "[11] D. K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarell, T. Hirzel, A. Aspuru-Guzik, and R. P. Adams. Convolutional networks on graphs for learning molecular fingerprints. In Advances in Neural Information Processing Systems, pages 2224\u20132232, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duvenaud%2C%20D.K.%20Maclaurin%2C%20D.%20Iparraguirre%2C%20J.%20Bombarell%2C%20R.%20Convolutional%20networks%20on%20graphs%20for%20learning%20molecular%20fingerprints%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duvenaud%2C%20D.K.%20Maclaurin%2C%20D.%20Iparraguirre%2C%20J.%20Bombarell%2C%20R.%20Convolutional%20networks%20on%20graphs%20for%20learning%20molecular%20fingerprints%202015"
        },
        {
            "id": "12",
            "entry": "[12] A. Feragen, N. Kasenburg, J. Petersen, M. D. Bruijne, and K. M. Borgwardt. Scalable kernels for graphs with continuous attributes. In Advances in Neural Information Processing Systems, pages 216\u2013224, 2013. Erratum available at http://image.diku.dk/aasa/papers/graphkernels_nips_erratum.pdf.",
            "url": "http://image.diku.dk/aasa/papers/graphkernels_nips_erratum.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feragen%2C%20A.%20Kasenburg%2C%20N.%20Petersen%2C%20J.%20Bruijne%2C%20M.D.%20Scalable%20kernels%20for%20graphs%20with%20continuous%20attributes%202013"
        },
        {
            "id": "13",
            "entry": "[13] M. Fey, J. E. Lenssen, F. Weichert, and H. M\u00fcller. SplineCNN: Fast geometric deep learning with continuous B-spline kernels. In IEEE Conference on Computer Vision and Pattern Recognition, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fey%2C%20M.%20Lenssen%2C%20J.E.%20Weichert%2C%20F.%20M%C3%BCller%2C%20H.%20SplineCNN%3A%20Fast%20geometric%20deep%20learning%20with%20continuous%20B-spline%20kernels%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fey%2C%20M.%20Lenssen%2C%20J.E.%20Weichert%2C%20F.%20M%C3%BCller%2C%20H.%20SplineCNN%3A%20Fast%20geometric%20deep%20learning%20with%20continuous%20B-spline%20kernels%202018"
        },
        {
            "id": "14",
            "entry": "[14] A. Fout, J. Byrd, B. Shariat, and A. Ben-Hur. Protein interface prediction using graph convolutional networks. In Advances in Neural Information Processing Systems, pages 6533\u20136542, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fout%2C%20A.%20Byrd%2C%20J.%20Shariat%2C%20B.%20Ben-Hur%2C%20A.%20Protein%20interface%20prediction%20using%20graph%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fout%2C%20A.%20Byrd%2C%20J.%20Shariat%2C%20B.%20Ben-Hur%2C%20A.%20Protein%20interface%20prediction%20using%20graph%20convolutional%20networks%202017"
        },
        {
            "id": "15",
            "entry": "[15] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. Neural message passing for quantum chemistry. In International Conference on Machine Learning, pages 1263\u20131272, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilmer%2C%20J.%20Schoenholz%2C%20S.S.%20Riley%2C%20P.F.%20Vinyals%2C%20O.%20Neural%20message%20passing%20for%20quantum%20chemistry%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilmer%2C%20J.%20Schoenholz%2C%20S.S.%20Riley%2C%20P.F.%20Vinyals%2C%20O.%20Neural%20message%20passing%20for%20quantum%20chemistry%202017"
        },
        {
            "id": "16",
            "entry": "[16] W. L. Hamilton, R. Ying, and J. Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems, pages 1025\u20131035, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hamilton%2C%20W.L.%20Ying%2C%20R.%20Leskovec%2C%20J.%20Inductive%20representation%20learning%20on%20large%20graphs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hamilton%2C%20W.L.%20Ying%2C%20R.%20Leskovec%2C%20J.%20Inductive%20representation%20learning%20on%20large%20graphs%202017"
        },
        {
            "id": "17",
            "entry": "[17] W. L. Hamilton, R. Ying, and J. Leskovec. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin, 40(3):52\u201374, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hamilton%2C%20W.L.%20Ying%2C%20R.%20Leskovec%2C%20J.%20Representation%20learning%20on%20graphs%3A%20Methods%20and%20applications%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hamilton%2C%20W.L.%20Ying%2C%20R.%20Leskovec%2C%20J.%20Representation%20learning%20on%20graphs%3A%20Methods%20and%20applications%202017"
        },
        {
            "id": "18",
            "entry": "[18] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning, pages 448\u2013456, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "19",
            "entry": "[19] W. Jin, C. W. Coley, R. Barzilay, and T. S. Jaakkola. Predicting organic reaction outcomes with Weisfeiler-Lehman network. In Advances in Neural Information Processing Systems, pages 2604\u20132613, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jin%2C%20W.%20Coley%2C%20C.W.%20Barzilay%2C%20R.%20Jaakkola%2C%20T.S.%20Predicting%20organic%20reaction%20outcomes%20with%20Weisfeiler-Lehman%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jin%2C%20W.%20Coley%2C%20C.W.%20Barzilay%2C%20R.%20Jaakkola%2C%20T.S.%20Predicting%20organic%20reaction%20outcomes%20with%20Weisfeiler-Lehman%20network%202017"
        },
        {
            "id": "20",
            "entry": "[20] K. Kersting, N. M. Kriege, C. Morris, P. Mutzel, and M. Neumann. Benchmark data sets for graph kernels, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kersting%2C%20K.%20Kriege%2C%20N.M.%20Morris%2C%20C.%20Mutzel%2C%20P.%20Benchmark%20data%20sets%20for%20graph%20kernels%202016"
        },
        {
            "id": "21",
            "entry": "[21] T. N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20T.N.%20Welling%2C%20M.%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20T.N.%20Welling%2C%20M.%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017"
        },
        {
            "id": "22",
            "entry": "[22] N. M. Kriege, P.-L. Giscard, and R. Wilson. On valid optimal assignment kernels and applications to graph classification. In Advances in Neural Information Processing Systems, pages 1623\u20131631, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kriege%2C%20N.M.%20Giscard%2C%20P.-L.%20Wilson%2C%20R.%20On%20valid%20optimal%20assignment%20kernels%20and%20applications%20to%20graph%20classification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kriege%2C%20N.M.%20Giscard%2C%20P.-L.%20Wilson%2C%20R.%20On%20valid%20optimal%20assignment%20kernels%20and%20applications%20to%20graph%20classification%202016"
        },
        {
            "id": "23",
            "entry": "[23] A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, pages 1097\u20131105, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "24",
            "entry": "[24] T. Lei, W. Jin, R. Barzilay, and T. S. Jaakkola. Deriving neural architectures from sequence and graph kernels. In International Conference on Machine Learning, pages 2024\u20132033, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lei%2C%20T.%20Jin%2C%20W.%20Barzilay%2C%20R.%20Jaakkola%2C%20T.S.%20Deriving%20neural%20architectures%20from%20sequence%20and%20graph%20kernels%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lei%2C%20T.%20Jin%2C%20W.%20Barzilay%2C%20R.%20Jaakkola%2C%20T.S.%20Deriving%20neural%20architectures%20from%20sequence%20and%20graph%20kernels%202017"
        },
        {
            "id": "25",
            "entry": "[25] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Y.%20Tarlow%2C%20D.%20Brockschmidt%2C%20M.%20Zemel%2C%20R.%20Gated%20graph%20sequence%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Y.%20Tarlow%2C%20D.%20Brockschmidt%2C%20M.%20Zemel%2C%20R.%20Gated%20graph%20sequence%20neural%20networks%202016"
        },
        {
            "id": "26",
            "entry": "[26] R. Liao, M. Brockschmidt, D. Tarlow, A. L. Gaunt, R. Urtasun, and R. Zemel. Graph partition neural networks for semi-supervised classification. In International Conference on Learning Representations (Workshop Track), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liao%2C%20R.%20Brockschmidt%2C%20M.%20Tarlow%2C%20D.%20Gaunt%2C%20A.L.%20Graph%20partition%20neural%20networks%20for%20semi-supervised%20classification%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liao%2C%20R.%20Brockschmidt%2C%20M.%20Tarlow%2C%20D.%20Gaunt%2C%20A.L.%20Graph%20partition%20neural%20networks%20for%20semi-supervised%20classification%202018"
        },
        {
            "id": "27",
            "entry": "[27] A. Lusci, G. Pollastri, and P. Baldi. Deep architectures and deep learning in chemoinformatics: The prediction of aqueous solubility for drug-like molecules. Journal of Chemical Information and Modeling, 53(7):1563\u20131575, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lusci%2C%20A.%20Pollastri%2C%20G.%20Baldi%2C%20P.%20Deep%20architectures%20and%20deep%20learning%20in%20chemoinformatics%3A%20The%20prediction%20of%20aqueous%20solubility%20for%20drug-like%20molecules%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lusci%2C%20A.%20Pollastri%2C%20G.%20Baldi%2C%20P.%20Deep%20architectures%20and%20deep%20learning%20in%20chemoinformatics%3A%20The%20prediction%20of%20aqueous%20solubility%20for%20drug-like%20molecules%202013"
        },
        {
            "id": "28",
            "entry": "[28] C. Merkwirth and T. Lengauer. Automatic generation of complementary descriptors with molecular graph networks. Journal of Chemical Information and Modeling, 45(5):1159\u20131168, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Merkwirth%2C%20C.%20Lengauer%2C%20T.%20Automatic%20generation%20of%20complementary%20descriptors%20with%20molecular%20graph%20networks%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Merkwirth%2C%20C.%20Lengauer%2C%20T.%20Automatic%20generation%20of%20complementary%20descriptors%20with%20molecular%20graph%20networks%202005"
        },
        {
            "id": "29",
            "entry": "[29] M. Niepert, M. Ahmed, and K. Kutzkov. Learning convolutional neural networks for graphs. In International Conference on Machine Learning, pages 2014\u20132023, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Niepert%2C%20M.%20Ahmed%2C%20M.%20Kutzkov%2C%20K.%20Learning%20convolutional%20neural%20networks%20for%20graphs%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Niepert%2C%20M.%20Ahmed%2C%20M.%20Kutzkov%2C%20K.%20Learning%20convolutional%20neural%20networks%20for%20graphs%202014"
        },
        {
            "id": "30",
            "entry": "[30] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. Transactions on Neural Networks, 20(1):61\u201380, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scarselli%2C%20F.%20Gori%2C%20M.%20Tsoi%2C%20A.C.%20Hagenbuchner%2C%20M.%20The%20graph%20neural%20network%20model%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scarselli%2C%20F.%20Gori%2C%20M.%20Tsoi%2C%20A.C.%20Hagenbuchner%2C%20M.%20The%20graph%20neural%20network%20model%202009"
        },
        {
            "id": "31",
            "entry": "[31] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. van den Berg, I. Titov, and M. Welling. Modeling relational data with graph convolutional networks. In Extended Semantic Web Conference, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schlichtkrull%2C%20M.%20Kipf%2C%20T.N.%20Bloem%2C%20P.%20van%20den%20Berg%2C%20R.%20Modeling%20relational%20data%20with%20graph%20convolutional%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schlichtkrull%2C%20M.%20Kipf%2C%20T.N.%20Bloem%2C%20P.%20van%20den%20Berg%2C%20R.%20Modeling%20relational%20data%20with%20graph%20convolutional%20networks%202018"
        },
        {
            "id": "32",
            "entry": "[32] K. Sch\u00fctt, P. J. Kindermans, H. E. Sauceda, S. Chmiela, A. Tkatchenko, and K. R. M\u00fcller. SchNet: A continuous-filter convolutional neural network for modeling quantum interactions. In Advances in Neural Information Processing Systems, pages 992\u20131002, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sch%C3%BCtt%2C%20K.%20Kindermans%2C%20P.J.%20Sauceda%2C%20H.E.%20Chmiela%2C%20S.%20SchNet%3A%20A%20continuous-filter%20convolutional%20neural%20network%20for%20modeling%20quantum%20interactions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sch%C3%BCtt%2C%20K.%20Kindermans%2C%20P.J.%20Sauceda%2C%20H.E.%20Chmiela%2C%20S.%20SchNet%3A%20A%20continuous-filter%20convolutional%20neural%20network%20for%20modeling%20quantum%20interactions%202017"
        },
        {
            "id": "33",
            "entry": "[33] N. Shervashidze, P. Schweitzer, E. J. van Leeuwen, K. Mehlhorn, and K. M. Borgwardt. Weisfeiler-Lehman graph kernels. Journal of Machine Learning Research, 12:2539\u20132561, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shervashidze%2C%20N.%20Schweitzer%2C%20P.%20van%20Leeuwen%2C%20E.J.%20Mehlhorn%2C%20K.%20Weisfeiler-Lehman%20graph%20kernels%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shervashidze%2C%20N.%20Schweitzer%2C%20P.%20van%20Leeuwen%2C%20E.J.%20Mehlhorn%2C%20K.%20Weisfeiler-Lehman%20graph%20kernels%202011"
        },
        {
            "id": "34",
            "entry": "[34] N. Shervashidze, S. V. N. Vishwanathan, T. H. Petri, K. Mehlhorn, and K. M. Borgwardt. Efficient graphlet kernels for large graph comparison. In International Conference on Artificial Intelligence and Statistics, pages 488\u2013495, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shervashidze%2C%20N.%20Vishwanathan%2C%20S.V.N.%20Petri%2C%20T.H.%20Mehlhorn%2C%20K.%20Efficient%20graphlet%20kernels%20for%20large%20graph%20comparison%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shervashidze%2C%20N.%20Vishwanathan%2C%20S.V.N.%20Petri%2C%20T.H.%20Mehlhorn%2C%20K.%20Efficient%20graphlet%20kernels%20for%20large%20graph%20comparison%202009"
        },
        {
            "id": "35",
            "entry": "[35] M. Simonovsky and N. Komodakis. Dynamic edge-conditioned filters in convolutional neural networks on graphs. In IEEE Conference on Computer Vision and Pattern Recognition, pages 29\u201338, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonovsky%2C%20M.%20Komodakis%2C%20N.%20Dynamic%20edge-conditioned%20filters%20in%20convolutional%20neural%20networks%20on%20graphs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonovsky%2C%20M.%20Komodakis%2C%20N.%20Dynamic%20edge-conditioned%20filters%20in%20convolutional%20neural%20networks%20on%20graphs%202017"
        },
        {
            "id": "36",
            "entry": "[36] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Li\u00f2, and Y. Bengio. Graph attention networks. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=P%20Velickovic%20G%20Cucurull%20A%20Casanova%20A%20Romero%20P%20Li%C3%B2%20and%20Y%20Bengio%20Graph%20attention%20networks%20In%20International%20Conference%20on%20Learning%20Representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=P%20Velickovic%20G%20Cucurull%20A%20Casanova%20A%20Romero%20P%20Li%C3%B2%20and%20Y%20Bengio%20Graph%20attention%20networks%20In%20International%20Conference%20on%20Learning%20Representations%202018"
        },
        {
            "id": "37",
            "entry": "[37] S. Verma and Z.-L. Zhang. Graph capsule convolutional neural networks. arXiv preprint arXiv:1805.08090, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.08090"
        },
        {
            "id": "38",
            "entry": "[38] O. Vinyals, S. Bengio, and M. Kudlur. Order matters: Sequence to sequence for sets. In International Conference on Learning Representations, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20O.%20Bengio%2C%20S.%20Kudlur%2C%20M.%20Order%20matters%3A%20Sequence%20to%20sequence%20for%20sets%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20O.%20Bengio%2C%20S.%20Kudlur%2C%20M.%20Order%20matters%3A%20Sequence%20to%20sequence%20for%20sets%202015"
        },
        {
            "id": "39",
            "entry": "[39] P. Yanardag and S. V. N. Vishwanathan. A structural smoothing framework for robust graph comparison. In Advances in Neural Information Processing Systems, pages 2134\u20132142, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yanardag%2C%20P.%20Vishwanathan%2C%20S.V.N.%20A%20structural%20smoothing%20framework%20for%20robust%20graph%20comparison%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yanardag%2C%20P.%20Vishwanathan%2C%20S.V.N.%20A%20structural%20smoothing%20framework%20for%20robust%20graph%20comparison%202015"
        },
        {
            "id": "40",
            "entry": "[40] M. Zhang, Z. Cui, M. Neumann, and Y. Chen. An end-to-end deep learning architecture for graph classification. In AAAI Conference on Artificial Intelligence, 2018. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20M.%20Cui%2C%20Z.%20Neumann%2C%20M.%20Chen%2C%20Y.%20An%20end-to-end%20deep%20learning%20architecture%20for%20graph%20classification%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20M.%20Cui%2C%20Z.%20Neumann%2C%20M.%20Chen%2C%20Y.%20An%20end-to-end%20deep%20learning%20architecture%20for%20graph%20classification%202018"
        }
    ]
}
