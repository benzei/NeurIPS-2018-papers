{
    "filename": "7846-graphical-generative-adversarial-networks.pdf",
    "metadata": {
        "title": "Graphical Generative Adversarial Networks",
        "author": "Chongxuan LI, Max Welling, Jun Zhu, Bo Zhang",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7846-graphical-generative-adversarial-networks.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model structured data. Graphical-GAN conjoins the power of Bayesian networks on compactly representing the dependency structures among random variables and that of generative adversarial networks on learning expressive dependency functions. We introduce a structured recognition model to infer the posterior distribution of latent variables given observations. We generalize the Expectation Propagation (EP) algorithm to learn the generative model and recognition model jointly. Finally, we present two important instances of Graphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN), which can successfully learn the discrete and temporal structures on visual datasets, respectively."
    },
    "keywords": [
        {
            "term": "Canadian Institute for Advanced Research",
            "url": "https://en.wikipedia.org/wiki/Canadian_Institute_for_Advanced_Research"
        },
        {
            "term": "bayesian network",
            "url": "https://en.wikipedia.org/wiki/bayesian_network"
        },
        {
            "term": "Gaussian mixture model",
            "url": "https://en.wikipedia.org/wiki/Gaussian_mixture_model"
        },
        {
            "term": "latent variable",
            "url": "https://en.wikipedia.org/wiki/latent_variable"
        },
        {
            "term": "graphical model",
            "url": "https://en.wikipedia.org/wiki/graphical_model"
        },
        {
            "term": "expectation propagation",
            "url": "https://en.wikipedia.org/wiki/expectation_propagation"
        },
        {
            "term": "directed acyclic graph",
            "url": "https://en.wikipedia.org/wiki/directed_acyclic_graph"
        }
    ],
    "highlights": [
        "Deep implicit models [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>] have shown promise on synthesizing realistic images [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] and inferring latent variables [<a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>]",
        "Probabilistic graphical models [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] provide principle ways to incorporate the prior knowledge about the data structures but these models often lack the capability to deal with the complex data like images",
        "To conjoin the benefits of both worlds, we propose a flexible generative modelling framework called Graphical Generative Adversarial Networks (Graphical-GAN)",
        "Graphical-GAN does not focus on a specific structure, but provides a general way to deal with arbitrary structures that can be encoded as Bayesian networks",
        "This paper introduces a flexible generative modelling framework called Graphical Generative Adversarial Networks (Graphical-GAN)",
        "Empirical results of two instances show the promise of Graphical-GAN on learning interpretable representations and generating structured samples"
    ],
    "key_statements": [
        "Deep implicit models [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>] have shown promise on synthesizing realistic images [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] and inferring latent variables [<a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>]",
        "Probabilistic graphical models [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] provide principle ways to incorporate the prior knowledge about the data structures but these models often lack the capability to deal with the complex data like images",
        "To conjoin the benefits of both worlds, we propose a flexible generative modelling framework called Graphical Generative Adversarial Networks (Graphical-GAN)",
        "Graphical-GAN employs deep implicit likelihood functions, which makes the inference of the latent variables intractable and the likelihood-based learning method infeasible",
        "The recognition model is shared by all data points and often parameterized as a deep neural network",
        "Considering different dependencies among the variables, or equivalently Hs, we study two types of recognition models: the mean-field posteriors [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>] and the inverse factorizations [<a class=\"ref-link\" id=\"c39\" href=\"#r39\">39</a>]",
        "State Space GAN is an instance of the Graphical-GAN framework, which provides theoretical insights and a recognition model for inference",
        "Graphical-GAN does not focus on a specific structure, but provides a general way to deal with arbitrary structures that can be encoded as Bayesian networks",
        "We evaluate Gaussian Mixture GAN on the MNIST [<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>], SVHN [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>], CIFAR10 [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] and CelebA [<a class=\"ref-link\" id=\"c23\" href=\"#r23\">23</a>] datasets",
        "Graphical-GAN can infer the latent structures and generate structured samples without any regularization, which is required by existing models [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c42\" href=\"#r42\">42</a>];",
        "We focus on the unsupervised learning setting in Gaussian Mixture GAN",
        "We demonstrate the ability of Gaussian Mixture GAN-L to deal with more challenging datasets",
        "We show the samples of Gaussian Mixture GAN-L by varying K and linearly interpolating the latent variables in Appendix E",
        "Gaussian Mixture GAN-L outperforms GAN-G significantly in terms of preserving the same semantics and similar visual appearance. This is because the Gaussian mixture prior helps the model learn a more spread latent space with less ambiguous areas shared by samples in different classes",
        "This paper introduces a flexible generative modelling framework called Graphical Generative Adversarial Networks (Graphical-GAN)",
        "Empirical results of two instances show the promise of Graphical-GAN on learning interpretable representations and generating structured samples"
    ],
    "summary": [
        "Deep implicit models [<a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>] have shown promise on synthesizing realistic images [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c33\" href=\"#r33\">33</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>] and inferring latent variables [<a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>].",
        "Graphical-GAN uses deep implicit likelihood functions [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>] to model complex data.",
        "We present Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN) to learn the discrete and temporal structures on visual datasets, respectively.",
        "Graphical-GAN outperforms the baseline models on inference, generation and reconstruction tasks consistently and substantially.",
        "Graphical-GAN employs deep implicit likelihood functions, which makes the inference of the latent variables intractable and the likelihood-based learning method infeasible.",
        "Compared to [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>], Graphical-GAN is more flexible on the model definition and learning methods, and can deal with natural data.",
        "The recent work of [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>] and [<a class=\"ref-link\" id=\"c41\" href=\"#r41\">41</a>] perform Bayesian learning for GANs. In comparison, Graphical-GAN focuses on learning a probabilistic graphical model with latent variables instead of posterior inference on global parameters.",
        "SSGAN is an instance of the Graphical-GAN framework, which provides theoretical insights and a recognition model for inference.",
        "Graphical-GAN does not focus on a specific structure, but provides a general way to deal with arbitrary structures that can be encoded as Bayesian networks.",
        "Graphical-GAN can infer the latent structures and generate structured samples without any regularization, which is required by existing models [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>, <a class=\"ref-link\" id=\"c43\" href=\"#r43\">43</a>, <a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>, <a class=\"ref-link\" id=\"c42\" href=\"#r42\">42</a>];",
        "Graphical-GAN can outperform all baseline methods [<a class=\"ref-link\" id=\"c7\" href=\"#r7\">7</a>\u2013<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] in terms of inference accuracy, sample quality and reconstruction error consistently and substantially.",
        "This is because the Gaussian mixture prior helps the model learn a more spread latent space with less ambiguous areas shared by samples in different classes.",
        "Note that our problem is more challenging than those in existing methods [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>, <a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>] because the discriminator in Graphical-GAN needs to discriminate the latent variables besides the video frames.",
        "All models can generate reasonable samples of length 4 on both Moving MNIST and 3D chairs datasets, as shown in Fig. 5.",
        "If the structure of the data gets complicated, i.e. T = 16 on Moving MNIST and T = 31 on 3D chairs, all baseline models fail while SSGAN-L can still successfully generate meaningful videos, as shown in Fig. 6 and Appendix F, respectively.",
        "Compared with existing GAN models [<a class=\"ref-link\" id=\"c44\" href=\"#r44\">44</a>, <a class=\"ref-link\" id=\"c35\" href=\"#r35\">35</a>, <a class=\"ref-link\" id=\"c42\" href=\"#r42\">42</a>] on videos, SSGAN-L can learn interpretable features thanks to the factorial structure in each frame.",
        "Empirical results of two instances show the promise of Graphical-GAN on learning interpretable representations and generating structured samples.",
        "Possible extensions to Graphical-GAN include: generalized learning and inference algorithms, instances with more complicated structures and semi-supervised learning for structured data."
    ],
    "headline": "We propose Graphical Generative Adversarial Networks  to model structured data",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Mart\u00edn Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. TensorFlow: A system for large-scale machine learning. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20Mart%C3%ADn%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20TensorFlow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016"
        },
        {
            "id": "2",
            "entry": "[2] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein GAN. arXiv preprint arXiv:1701.07875, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.07875"
        },
        {
            "id": "3",
            "entry": "[3] Mathieu Aubry, Daniel Maturana, Alexei A Efros, Bryan C Russell, and Josef Sivic. Seeing 3D chairs: exemplar part-based 2D-3D alignment using a large dataset of cad models. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3762\u2013 3769, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aubry%2C%20Mathieu%20Maturana%2C%20Daniel%20Efros%2C%20Alexei%20A.%20Russell%2C%20Bryan%20C.%20Seeing%203D%20chairs%3A%20exemplar%20part-based%202D-3D%20alignment%20using%20a%20large%20dataset%20of%20cad%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aubry%2C%20Mathieu%20Maturana%2C%20Daniel%20Efros%2C%20Alexei%20A.%20Russell%2C%20Bryan%20C.%20Seeing%203D%20chairs%3A%20exemplar%20part-based%202D-3D%20alignment%20using%20a%20large%20dataset%20of%20cad%20models%202014"
        },
        {
            "id": "4",
            "entry": "[4] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "5",
            "entry": "[5] Imre Csisz\u00e1r, Paul C Shields, et al. Information theory and statistics: A tutorial. Foundations and Trends R in Communications and Information Theory, 1(4):417\u2013528, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Csisz%C3%A1r%2C%20Imre%20Shields%2C%20Paul%20C.%20Information%20theory%20and%20statistics%3A%20A%20tutorial.%20Foundations%20and%20Trends%20R%20in%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Csisz%C3%A1r%2C%20Imre%20Shields%2C%20Paul%20C.%20Information%20theory%20and%20statistics%3A%20A%20tutorial.%20Foundations%20and%20Trends%20R%20in%202004"
        },
        {
            "id": "6",
            "entry": "[6] Emily Denton and Vighnesh Birodkar. Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems, pages 4417\u20134426, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20Birodkar%2C%20Vighnesh%20Unsupervised%20learning%20of%20disentangled%20representations%20from%20video%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20Birodkar%2C%20Vighnesh%20Unsupervised%20learning%20of%20disentangled%20representations%20from%20video%202017"
        },
        {
            "id": "7",
            "entry": "[7] Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni, Kai Arulkumaran, and Murray Shanahan. Deep unsupervised clustering with Gaussian mixture variational autoencoders. arXiv preprint arXiv:1611.02648, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02648"
        },
        {
            "id": "8",
            "entry": "[8] Jeff Donahue, Philipp Kr\u00e4henb\u00fchl, and Trevor Darrell. Adversarial feature learning. arXiv preprint arXiv:1605.09782, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.09782"
        },
        {
            "id": "9",
            "entry": "[9] Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropietro, and Aaron Courville. Adversarially learned inference. arXiv preprint arXiv:1606.00704, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.00704"
        },
        {
            "id": "10",
            "entry": "[10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "11",
            "entry": "[11] Ferenc Husz\u00e1r. Variational inference using implicit distributions. arXiv preprint arXiv:1702.08235, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.08235"
        },
        {
            "id": "12",
            "entry": "[12] Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01144"
        },
        {
            "id": "13",
            "entry": "[13] Matthew Johnson, David K Duvenaud, Alex Wiltschko, Ryan P Adams, and Sandeep R Datta. Composing graphical models with neural networks for structured representations and fast inference. In Advances in neural information processing systems, pages 2946\u20132954, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Matthew%20Duvenaud%2C%20David%20K.%20Wiltschko%2C%20Alex%20Adams%2C%20Ryan%20P.%20Composing%20graphical%20models%20with%20neural%20networks%20for%20structured%20representations%20and%20fast%20inference%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Matthew%20Duvenaud%2C%20David%20K.%20Wiltschko%2C%20Alex%20Adams%2C%20Ryan%20P.%20Composing%20graphical%20models%20with%20neural%20networks%20for%20structured%20representations%20and%20fast%20inference%202016"
        },
        {
            "id": "14",
            "entry": "[14] Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to variational methods for graphical models. Machine learning, 37(2):183\u2013233, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jordan%2C%20Michael%20I.%20Ghahramani%2C%20Zoubin%20Jaakkola%2C%20Tommi%20S.%20Saul%2C%20Lawrence%20K.%20An%20introduction%20to%20variational%20methods%20for%20graphical%20models%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jordan%2C%20Michael%20I.%20Ghahramani%2C%20Zoubin%20Jaakkola%2C%20Tommi%20S.%20Saul%2C%20Lawrence%20K.%20An%20introduction%20to%20variational%20methods%20for%20graphical%20models%201999"
        },
        {
            "id": "15",
            "entry": "[15] Nal Kalchbrenner, Aaron van den Oord, Karen Simonyan, Ivo Danihelka, Oriol Vinyals, Alex Graves, and Koray Kavukcuoglu. Video pixel networks. arXiv preprint arXiv:1610.00527, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.00527"
        },
        {
            "id": "16",
            "entry": "[16] Theofanis Karaletsos. Adversarial message passing for graphical models. arXiv preprint arXiv:1612.05048, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.05048"
        },
        {
            "id": "17",
            "entry": "[17] Diederik Kingma and Max Welling. Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "18",
            "entry": "[18] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koller%2C%20Daphne%20Friedman%2C%20Nir%20Probabilistic%20graphical%20models%3A%20principles%20and%20techniques%202009"
        },
        {
            "id": "19",
            "entry": "[19] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "20",
            "entry": "[20] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20L%C3%A9on%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "21",
            "entry": "[21] Yingzhen Li, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, and Richard E Turner. Stochastic expectation propagation. In Advances in Neural Information Processing Systems, pages 2323\u20132331, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Yingzhen%20Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Turner%2C%20Richard%20E.%20Stochastic%20expectation%20propagation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Yingzhen%20Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Turner%2C%20Richard%20E.%20Stochastic%20expectation%20propagation%202015"
        },
        {
            "id": "22",
            "entry": "[22] Wu Lin, Nicolas Hubacher, and Mohammad Emtiyaz Khan. Variational message passing with structured inference networks. arXiv preprint arXiv:1803.05589, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.05589"
        },
        {
            "id": "23",
            "entry": "[23] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "24",
            "entry": "[24] Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial autoencoders. arXiv preprint arXiv:1511.05644, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05644"
        },
        {
            "id": "25",
            "entry": "[25] Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction beyond mean square error. arXiv preprint arXiv:1511.05440, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05440"
        },
        {
            "id": "26",
            "entry": "[26] Lars Mescheder, Sebastian Nowozin, and Andreas Geiger. Adversarial variational Bayes: Unifying variational autoencoders and generative adversarial networks. arXiv preprint arXiv:1701.04722, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.04722"
        },
        {
            "id": "27",
            "entry": "[27] Thomas P Minka. Expectation propagation for approximate bayesian inference. In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence, pages 362\u2013369. Morgan Kaufmann Publishers Inc., 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minka%2C%20Thomas%20P.%20Expectation%20propagation%20for%20approximate%20bayesian%20inference%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Minka%2C%20Thomas%20P.%20Expectation%20propagation%20for%20approximate%20bayesian%20inference%202001"
        },
        {
            "id": "28",
            "entry": "[28] Tom Minka. Divergence measures and message passing. Technical report, Microsoft Research, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minka%2C%20Tom%20Divergence%20measures%20and%20message%20passing%202005"
        },
        {
            "id": "29",
            "entry": "[29] Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv preprint arXiv:1610.03483, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.03483"
        },
        {
            "id": "30",
            "entry": "[30] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "31",
            "entry": "[31] Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-GAN: Training generative neural samplers using variational divergence minimization. In Advances in Neural Information Processing Systems, pages 271\u2013279, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nowozin%2C%20Sebastian%20Cseke%2C%20Botond%20Tomioka%2C%20Ryota%20f-GAN%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nowozin%2C%20Sebastian%20Cseke%2C%20Botond%20Tomioka%2C%20Ryota%20f-GAN%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016"
        },
        {
            "id": "32",
            "entry": "[32] Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard L Lewis, and Satinder Singh. Actionconditional video prediction using deep networks in atari games. In Advances in Neural Information Processing Systems, pages 2863\u20132871, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oh%2C%20Junhyuk%20Guo%2C%20Xiaoxiao%20Lee%2C%20Honglak%20Lewis%2C%20Richard%20L.%20Actionconditional%20video%20prediction%20using%20deep%20networks%20in%20atari%20games%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oh%2C%20Junhyuk%20Guo%2C%20Xiaoxiao%20Lee%2C%20Honglak%20Lewis%2C%20Richard%20L.%20Actionconditional%20video%20prediction%20using%20deep%20networks%20in%20atari%20games%202015"
        },
        {
            "id": "33",
            "entry": "[33] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "34",
            "entry": "[34] Yunus Saatci and Andrew G Wilson. Bayesian gan. In Advances in neural information processing systems, pages 3622\u20133631, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yunus%20Saatci%20and%20Andrew%20G%20Wilson%20Bayesian%20gan%20In%20Advances%20in%20neural%20information%20processing%20systems%20pages%2036223631%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yunus%20Saatci%20and%20Andrew%20G%20Wilson%20Bayesian%20gan%20In%20Advances%20in%20neural%20information%20processing%20systems%20pages%2036223631%202017"
        },
        {
            "id": "35",
            "entry": "[35] Masaki Saito and Eiichi Matsumoto. Temporal generative adversarial nets. arXiv preprint arXiv:1611.06624, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.06624"
        },
        {
            "id": "36",
            "entry": "[36] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pages 2234\u20132242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016"
        },
        {
            "id": "37",
            "entry": "[37] Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative adversarial networks. arXiv preprint arXiv:1511.06390, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06390"
        },
        {
            "id": "38",
            "entry": "[38] Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov. Unsupervised learning of video representations using LSTMs. In International Conference on Machine Learning, pages 843\u2013852, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Mansimov%2C%20Elman%20Salakhudinov%2C%20Ruslan%20Unsupervised%20learning%20of%20video%20representations%20using%20LSTMs%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Mansimov%2C%20Elman%20Salakhudinov%2C%20Ruslan%20Unsupervised%20learning%20of%20video%20representations%20using%20LSTMs%202015"
        },
        {
            "id": "39",
            "entry": "[39] Andreas Stuhlm\u00fcller, Jacob Taylor, and Noah Goodman. Learning stochastic inverses. In Advances in neural information processing systems, pages 3048\u20133056, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stuhlm%C3%BCller%2C%20Andreas%20Taylor%2C%20Jacob%20Goodman%2C%20Noah%20Learning%20stochastic%20inverses%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stuhlm%C3%BCller%2C%20Andreas%20Taylor%2C%20Jacob%20Goodman%2C%20Noah%20Learning%20stochastic%20inverses%202013"
        },
        {
            "id": "40",
            "entry": "[40] Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schoelkopf. Wasserstein autoencoders. arXiv preprint arXiv:1711.01558, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.01558"
        },
        {
            "id": "41",
            "entry": "[41] Dustin Tran, Rajesh Ranganath, and David M Blei. Hierarchical implicit models and likelihoodfree variational inference. arXiv preprint arXiv:1702.08896, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.08896"
        },
        {
            "id": "42",
            "entry": "[42] Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. Mocogan: Decomposing motion and content for video generation. arXiv preprint arXiv:1707.04993, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.04993"
        },
        {
            "id": "43",
            "entry": "[43] Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee. Decomposing motion and content for natural video sequence prediction. arXiv preprint arXiv:1706.08033, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.08033"
        },
        {
            "id": "44",
            "entry": "[44] Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. In Advances In Neural Information Processing Systems, pages 613\u2013621, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Generating%20videos%20with%20scene%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Generating%20videos%20with%20scene%20dynamics%202016"
        },
        {
            "id": "45",
            "entry": "[45] David Warde-Farley and Yoshua Bengio. Improving generative adversarial networks with denoising feature matching. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Warde-Farley%2C%20David%20Bengio%2C%20Yoshua%20Improving%20generative%20adversarial%20networks%20with%20denoising%20feature%20matching%202016"
        },
        {
            "id": "46",
            "entry": "[46] Tianfan Xue, Jiajun Wu, Katherine Bouman, and Bill Freeman. Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks. In Advances in Neural Information Processing Systems, pages 91\u201399, 2016. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xue%2C%20Tianfan%20Wu%2C%20Jiajun%20Bouman%2C%20Katherine%20Freeman%2C%20Bill%20Visual%20dynamics%3A%20Probabilistic%20future%20frame%20synthesis%20via%20cross%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xue%2C%20Tianfan%20Wu%2C%20Jiajun%20Bouman%2C%20Katherine%20Freeman%2C%20Bill%20Visual%20dynamics%3A%20Probabilistic%20future%20frame%20synthesis%20via%20cross%20convolutional%20networks%202016"
        }
    ]
}
