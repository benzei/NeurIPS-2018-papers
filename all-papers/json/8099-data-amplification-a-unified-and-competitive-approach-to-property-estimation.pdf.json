{
    "filename": "8099-data-amplification-a-unified-and-competitive-approach-to-property-estimation.pdf",
    "metadata": {
        "title": "Data Amplification: A Unified and Competitive Approach to Property Estimation",
        "author": "Yi HAO, Alon Orlitsky, Ananda Theertha Suresh, Yihong Wu",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8099-data-amplification-a-unified-and-competitive-approach-to-property-estimation.pdf"
        },
        "abstract": "Estimating properties of discrete distributions is a fundamental problem in statistical learning. We design the first unified, linear-time, competitive, property estimator that for a wide class of properties and for all underlying distributions uses just 2n\u221asamples to achieve the performance attained by the empirical estimator with n log n samples. This provides off-the-shelf, distribution-independent, \u201camplification\u201d of the amount of data available relative to common-practice estimators. We illustrate the estimator\u2019s practical advantages by comparing it to existing estimators for a wide variety of properties and distributions. In most cases, its performance with n samples is even as good as that of the empirical estimator with n log n samples, and for essentially all properties, its performance is comparable to that of the best existing estimator designed specifically for that property."
    },
    "keywords": [
        {
            "term": "discrete distribution",
            "url": "https://en.wikipedia.org/wiki/discrete_distribution"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        }
    ],
    "highlights": [
        ", where throughout the paper log is the natural logarithm, is the fundamental information measure arising in a variety of applications [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>]",
        "As we show in Section 8, it works well in practice, outperforming existing estimator and often working as well as the empirical estimator with even n log n samples",
        "We considered the fundamental learning problem of estimating properties of discrete distributions"
    ],
    "key_statements": [
        ", where throughout the paper log is the natural logarithm, is the fundamental information measure arising in a variety of applications [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>]",
        "As we show in Section 8, it works well in practice, outperforming existing estimator and often working as well as the empirical estimator with even n log n samples",
        "We considered the fundamental learning problem of estimating properties of discrete distributions"
    ],
    "summary": [
        ", where throughout the paper log is the natural logarithm, is the fundamental information measure arising in a variety of applications [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>].",
        "1\u2212e\u2212mpx m is the normalized expected number of distinct elements observed upon drawing Poi(m) independent samples, it arises in ecological [<a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>], genomic [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>], and database studies [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>].",
        "Many applications call for estimating properties of an unknown distribution p \u2208 DX from its samples.",
        "Other, properties, we would like to estimate its value based on samples from an underlying distribution.",
        "In the common property-estimation setting, the unknown distribution p generates n i.i.d. samples Xn \u223c pn, which in turn are used to estimate f (p).",
        "Data amplification Many modern applications, such as those arising in genomics and naturallanguage processing, concern properties of distributions whose support size k is comparable to or even larger than the number of samples n.",
        "Note that for some properties f , when the underlying distributions are limited to a fixed small support size, LfE (p, n) = \u0398(1/n) 1/log n.",
        "All properties described earlier: Shannon entropy, normalized support size, normalized suppport coverage, power sum, L1 distance and KL divergence satisfy these conditions, and f \u2217 applies to all of them.",
        "[<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>], that with O(k) samples, f E approximates a k-element distribution to a constant L1 distance, and estimates any Lipschitz property to a constant loss.",
        "It follows that f \u2217 estima\u221ates any Lipschitz property over a distribution of support size k to constant estimation loss with O(k/ log k) samples.",
        "(without even knowing that the entropy is bounded.) By contrast, the original min-max estimator results would still require the much larger \u03a9(k/ log k) samples.",
        "As shown the performance is often comparable to that of n log n samples.",
        "To ensure robustness of the results, we performed the comparisons for all the symmetric properties described in the introduction: entropy, support size, support coverage, power sums, and distance to uniformity.",
        "The only exception was PML that attempts to smooth the estimate, performed better on uniform, and near-uniform Dirichlet-drawn distributions for several properties.",
        "Even for normalized support size, Figure 2 shows that f \u2217 outperforms other estimators including those designed specifically for this property.",
        "Shannon-entropy estimator in [<a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>] by JVHW, the normalized-support-size estimator in [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>] and the entropy estimator in [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>] by WY, and the smoothed Good-Toulmin Estimator for normalized support coverage estimation [<a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>], slightly modified to account for previously-observed elements that may appear in the subsequent sample, by SGT.",
        "We designed a general estimator that for a wid\u221ae class of properties, uses only n samples to achieve the same accuracy as the plug-in estimator with n log n samples.",
        "It would be interesting to determine whether data amplification could be obtained for these properties as well"
    ],
    "headline": "As we show in Section 8, it works well in practice, outperforming existing estimator and often working as well as the empirical estimator with even n log n samples",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] COVER, T. M., & THOMAS, J. A. (2012). Elements of information theory. John Wiley & Sons.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=COVER%2C%20T.M.%20THOMAS%2C%20J.A.%20Elements%20of%20information%20theory%202012"
        },
        {
            "id": "2",
            "entry": "[2] GOOD, I. J. (1953). The population frequencies of species and the estimation of population parameters. Biometrika, 40(3-4), 237-264.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=GOOD%2C%20I.J.%20The%20population%20frequencies%20of%20species%20and%20the%20estimation%20of%20population%20parameters%201953",
            "oa_query": "https://api.scholarcy.com/oa_version?query=GOOD%2C%20I.J.%20The%20population%20frequencies%20of%20species%20and%20the%20estimation%20of%20population%20parameters%201953"
        },
        {
            "id": "3",
            "entry": "[3] MCNEIL, D. R. (1973). Estimating an author\u2019s vocabulary. Journal of the American Statistical Association, 68(341), 92-96.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=MCNEIL%2C%20D.R.%20Estimating%20an%20author%E2%80%99s%20vocabulary%201973",
            "oa_query": "https://api.scholarcy.com/oa_version?query=MCNEIL%2C%20D.R.%20Estimating%20an%20author%E2%80%99s%20vocabulary%201973"
        },
        {
            "id": "4",
            "entry": "[4] COLWELL, R. K., CHAO, A., GOTELLI, N. J., LIN, S. Y., MAO, C. X., CHAZDON, R. L., & LONGINO, J. T. (2012). Models and estimators linking individual-based and sample-based rarefaction, extrapolation and comparison of assemblages. Journal of plant ecology, 5(1), 3-21.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=COLWELL%2C%20R.K.%20CHAO%2C%20A.%20GOTELLI%2C%20N.J.%20LIN%2C%20S.Y.%20Models%20and%20estimators%20linking%20individual-based%20and%20sample-based%20rarefaction%2C%20extrapolation%20and%20comparison%20of%20assemblages%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=COLWELL%2C%20R.K.%20CHAO%2C%20A.%20GOTELLI%2C%20N.J.%20LIN%2C%20S.Y.%20Models%20and%20estimators%20linking%20individual-based%20and%20sample-based%20rarefaction%2C%20extrapolation%20and%20comparison%20of%20assemblages%202012"
        },
        {
            "id": "5",
            "entry": "[5] IONITA-LAZA, I., LANGE, C., & LAIRD, N. M. (2009). Estimating the number of unseen variants in the human genome. Proceedings of the National Academy of Sciences, 106(13), 5008-5013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=IONITA-LAZA%2C%20I.%20LANGE%2C%20C.%20LAIRD%2C%20N.M.%20Estimating%20the%20number%20of%20unseen%20variants%20in%20the%20human%20genome%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=IONITA-LAZA%2C%20I.%20LANGE%2C%20C.%20LAIRD%2C%20N.M.%20Estimating%20the%20number%20of%20unseen%20variants%20in%20the%20human%20genome%202009"
        },
        {
            "id": "6",
            "entry": "[6] HAAS, P. J., NAUGHTON, J. F., SESHADRI, S., & STOKES, L. (1995). Sampling-based estimation of the number of distinct values of an attribute. VLDB, Vol. 95, pp. 311-322.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=HAAS%2C%20P.J.%20NAUGHTON%2C%20J.F.%20SESHADRI%2C%20S.%20STOKES%2C%20L.%20Sampling-based%20estimation%20of%20the%20number%20of%20distinct%20values%20of%20an%20attribute%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=HAAS%2C%20P.J.%20NAUGHTON%2C%20J.F.%20SESHADRI%2C%20S.%20STOKES%2C%20L.%20Sampling-based%20estimation%20of%20the%20number%20of%20distinct%20values%20of%20an%20attribute%201995"
        },
        {
            "id": "7",
            "entry": "[7] R\u00c9NYI, A. (1961). On measures of entropy and information. HUNGARIAN ACADEMY OF SCIENCES Budapest Hungary.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=R%C3%89NYI%2C%20A.%20On%20measures%20of%20entropy%20and%20information.%20HUNGARIAN%20ACADEMY%20OF%20SCIENCES%20Budapest%20Hungary%201961"
        },
        {
            "id": "8",
            "entry": "[8] LOH, W. Y. (2011). Classification and regression trees. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 1(1), 14-23.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LOH%2C%20W.Y.%20Classification%20and%20regression%20trees%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LOH%2C%20W.Y.%20Classification%20and%20regression%20trees%202011"
        },
        {
            "id": "9",
            "entry": "[9] CANONNE, C. L. (2017). A Survey on Distribution Testing. Your Data is Big. But is it Blue.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CANONNE%2C%20C.L.%20A%20Survey%20on%20Distribution%20Testing.%20Your%20Data%20is%20Big%202017"
        },
        {
            "id": "10",
            "entry": "[10] LEHMANN, E. L., & ROMANO, J. P. (2006). Testing statistical hypotheses. Springer Science & Business Media.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LEHMANN%2C%20E.L.%20ROMANO%2C%20J.P.%20Testing%20statistical%20hypotheses%202006"
        },
        {
            "id": "11",
            "entry": "[11] KULLBACK, S., & LEIBLER, R. A. (1951). On information and sufficiency. The annals of mathematical statistics, 22(1), 79-86.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=KULLBACK%2C%20S.%20LEIBLER%2C%20R.A.%20On%20information%20and%20sufficiency%201951",
            "oa_query": "https://api.scholarcy.com/oa_version?query=KULLBACK%2C%20S.%20LEIBLER%2C%20R.A.%20On%20information%20and%20sufficiency%201951"
        },
        {
            "id": "12",
            "entry": "[12] S\u00c4RNDAL, C. E., SWENSSON, B., & WRETMAN, J. (2003). Model assisted survey sampling. Springer Science & Business Media.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=S%C3%84RNDAL%2C%20C.E.%20SWENSSON%2C%20B.%20WRETMAN%2C%20J.%20Model%20assisted%20survey%20sampling%202003"
        },
        {
            "id": "13",
            "entry": "[13] WU, Y., & YANG, P. (2016). Minimax rates of entropy estimation on large alphabets via best polynomial approximation, IEEE Transactions on Information Theory, 62(6), 3702-3720.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=WU%2C%20Y.%20YANG%2C%20P.%20Minimax%20rates%20of%20entropy%20estimation%20on%20large%20alphabets%20via%20best%20polynomial%20approximation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=WU%2C%20Y.%20YANG%2C%20P.%20Minimax%20rates%20of%20entropy%20estimation%20on%20large%20alphabets%20via%20best%20polynomial%20approximation%202016"
        },
        {
            "id": "14",
            "entry": "[14] WU, Y., & YANG, P. (2015). Chebyshev polynomials, moment matching, and optimal estimation of the unseen. ArXiv preprint arXiv:1504.01227.",
            "arxiv_url": "https://arxiv.org/pdf/1504.01227"
        },
        {
            "id": "15",
            "entry": "[15] ACHARYA, J., DAS, H., ORLITSKY, A., & SURESH, A. T. (2017). A unified maximum likelihood approach for estimating symmetric properties of discrete distributions. In International Conference on Machine Learning (pp. 11-21).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ACHARYA%2C%20J.%20DAS%2C%20H.%20ORLITSKY%2C%20A.%20SURESH%2C%20A.T.%20A%20unified%20maximum%20likelihood%20approach%20for%20estimating%20symmetric%20properties%20of%20discrete%20distributions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=ACHARYA%2C%20J.%20DAS%2C%20H.%20ORLITSKY%2C%20A.%20SURESH%2C%20A.T.%20A%20unified%20maximum%20likelihood%20approach%20for%20estimating%20symmetric%20properties%20of%20discrete%20distributions%202017"
        },
        {
            "id": "16",
            "entry": "[16] JIAO, J., HAN, Y., & WEISSMAN, T. (2016). Minimax estimation of the L1 distance. In Information Theory (ISIT), 2016 IEEE International Symposium on (pp. 750-754). IEEE.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=JIAO%2C%20J.%20HAN%2C%20Y.%20WEISSMAN%2C%20T.%20Minimax%20estimation%20of%20the%20L1%20distance%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=JIAO%2C%20J.%20HAN%2C%20Y.%20WEISSMAN%2C%20T.%20Minimax%20estimation%20of%20the%20L1%20distance%202016"
        },
        {
            "id": "17",
            "entry": "[17] TIMAN, A. F. (2014). Theory of approximation of functions of a real variable. Elsevier.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=TIMAN%2C%20A.F.%20Theory%20of%20approximation%20of%20functions%20of%20a%20real%20variable%202014"
        },
        {
            "id": "18",
            "entry": "[18] KORNE ICHUK, N. P. (1991). Exact constants in approximation theory. (Vol. 38). Cambridge University Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ICHUK%2C%20K.O.R.N.E.%20P%2C%20N.%20Exact%20constants%20in%20approximation%20theory%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=ICHUK%2C%20K.O.R.N.E.%20P%2C%20N.%20Exact%20constants%20in%20approximation%20theory%201991"
        },
        {
            "id": "19",
            "entry": "[19] VALIANT, G., & VALIANT, P. (2011). The power of linear estimators. In Foundations of Computer Science (FOCS), 2011 IEEE 52nd Annual Symposium on (pp. 403-412). IEEE.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=VALIANT%2C%20G.%20VALIANT%2C%20P.%20The%20power%20of%20linear%20estimators%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=VALIANT%2C%20G.%20VALIANT%2C%20P.%20The%20power%20of%20linear%20estimators%202011"
        },
        {
            "id": "20",
            "entry": "[20] HAN, Y., JIAO, J., & WEISSMAN, T. (2018). Local moment matching: A unified methodology for symmetric functional estimation and distribution estimation under Wasserstein distance. arXiv preprint arXiv:1802.08405.",
            "arxiv_url": "https://arxiv.org/pdf/1802.08405"
        },
        {
            "id": "21",
            "entry": "[21] KAMATH, S., ORLITSKY, A., PICHAPATI, D., & SURESH, A. T. (2015, June). On learning distributions from their samples. In Conference on Learning Theory (pp. 1066-1100).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=KAMATH%2C%20S.%20ORLITSKY%2C%20A.%20PICHAPATI%2C%20D.%20SURESH%2C%20A.T.%20On%20learning%20distributions%20from%20their%20samples%202015-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=KAMATH%2C%20S.%20ORLITSKY%2C%20A.%20PICHAPATI%2C%20D.%20SURESH%2C%20A.T.%20On%20learning%20distributions%20from%20their%20samples%202015-06"
        },
        {
            "id": "22",
            "entry": "[22] ORLITSKY, A., SURESH, A. T., & WU, Y. (2016). Optimal prediction of the number of unseen species. Proceedings of the National Academy of Sciences, 201607774.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ORLITSKY%2C%20A.%20SURESH%2C%20A.T.%20WU%2C%20Y.%20Optimal%20prediction%20of%20the%20number%20of%20unseen%20species%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=ORLITSKY%2C%20A.%20SURESH%2C%20A.T.%20WU%2C%20Y.%20Optimal%20prediction%20of%20the%20number%20of%20unseen%20species%202016"
        },
        {
            "id": "23",
            "entry": "[23] CARLTON, A. G. (1969). On the bias of information estimates. Psychological Bulletin, 71(2), 108.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CARLTON%2C%20A.G.%20On%20the%20bias%20of%20information%20estimates%201969",
            "oa_query": "https://api.scholarcy.com/oa_version?query=CARLTON%2C%20A.G.%20On%20the%20bias%20of%20information%20estimates%201969"
        },
        {
            "id": "24",
            "entry": "[24] CHUNG, F. R., & LU, L. (2017). Complex graphs and networks. (No. 107). American Mathematical Soc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CHUNG%2C%20F.R.%20LU%2C%20L.%20Complex%20graphs%20and%20networks%202017"
        },
        {
            "id": "25",
            "entry": "[25] BUSTAMANTE, J. (2017). Bernstein operators and their properties. Chicago.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=BUSTAMANTE%2C%20J.%20Bernstein%20operators%20and%20their%20properties%202017"
        },
        {
            "id": "26",
            "entry": "[26] WATSON, G. N. (1995). A treatise on the theory of Bessel functions. Cambridge University Press.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=WATSON%2C%20G.N.%20A%20treatise%20on%20the%20theory%20of%20Bessel%20functions%201995"
        },
        {
            "id": "27",
            "entry": "[27] JIAO, J., VENKAT, K., HAN, Y., & WEISSMAN, T. (2015). Minimax estimation of functionals of discrete distributions. IEEE Transactions on Information Theory, 61(5), 2835-2885.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=JIAO%2C%20J.%20VENKAT%2C%20K.%20HAN%2C%20Y.%20WEISSMAN%2C%20T.%20Minimax%20estimation%20of%20functionals%20of%20discrete%20distributions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=JIAO%2C%20J.%20VENKAT%2C%20K.%20HAN%2C%20Y.%20WEISSMAN%2C%20T.%20Minimax%20estimation%20of%20functionals%20of%20discrete%20distributions%202015"
        },
        {
            "id": "28",
            "entry": "[28] VALIANT, P., & VALIANT, G. (2013). Estimating the unseen: improved estimators for entropy and other properties. In Advances in Neural Information Processing Systems (pp. 2157-2165).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=VALIANT%2C%20P.%20VALIANT%2C%20G.%20Estimating%20the%20unseen%3A%20improved%20estimators%20for%20entropy%20and%20other%20properties%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=VALIANT%2C%20P.%20VALIANT%2C%20G.%20Estimating%20the%20unseen%3A%20improved%20estimators%20for%20entropy%20and%20other%20properties%202013"
        },
        {
            "id": "29",
            "entry": "[29] PANINSKI, L. (2003). Estimation of entropy and mutual information. Neural computation, 15(6), 1191-1253.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=PANINSKI%2C%20L.%20Estimation%20of%20entropy%20and%20mutual%20information%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=PANINSKI%2C%20L.%20Estimation%20of%20entropy%20and%20mutual%20information%202003"
        },
        {
            "id": "30",
            "entry": "[30] CARLTON, A. G. (1969). On the bias of information estimates. Psychological Bulletin, 71(2), 108.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CARLTON%2C%20A.G.%20On%20the%20bias%20of%20information%20estimates%201969",
            "oa_query": "https://api.scholarcy.com/oa_version?query=CARLTON%2C%20A.G.%20On%20the%20bias%20of%20information%20estimates%201969"
        },
        {
            "id": "31",
            "entry": "[31] GOOD, I. J. (1953). The population frequencies of species and the estimation of population parameters. Biometrika, 40(3-4), 237-264.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=GOOD%2C%20I.J.%20The%20population%20frequencies%20of%20species%20and%20the%20estimation%20of%20population%20parameters%201953",
            "oa_query": "https://api.scholarcy.com/oa_version?query=GOOD%2C%20I.J.%20The%20population%20frequencies%20of%20species%20and%20the%20estimation%20of%20population%20parameters%201953"
        },
        {
            "id": "32",
            "entry": "[32] CHAO, A. (1984). Nonparametric estimation of the number of classes in a population. Scandinavian Journal of Statistics, 265-270.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CHAO%2C%20A.%20Nonparametric%20estimation%20of%20the%20number%20of%20classes%20in%20a%20population%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=CHAO%2C%20A.%20Nonparametric%20estimation%20of%20the%20number%20of%20classes%20in%20a%20population%201984"
        },
        {
            "id": "33",
            "entry": "[33] CHAO, A. (2005). Species estimation and applications. Encyclopedia of statistical sciences.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=CHAO%2C%20A.%20Species%20estimation%20and%20applications.%20Encyclopedia%20of%20statistical%20sciences%202005"
        },
        {
            "id": "34",
            "entry": "[34] SMITH, E. P., & VAN BELLE, G. (1984). Nonparametric estimation of species richness. Biometrics, 119-129.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=SMITH%2C%20E.P.%20BELLE%2C%20V.A.N.%20G.%20Nonparametric%20estimation%20of%20species%20richness%201984",
            "oa_query": "https://api.scholarcy.com/oa_version?query=SMITH%2C%20E.P.%20BELLE%2C%20V.A.N.%20G.%20Nonparametric%20estimation%20of%20species%20richness%201984"
        },
        {
            "id": "35",
            "entry": "[35] ACHARYA, J., ORLITSKY, A., SURESH, A. T., & TYAGI, H. (2017). Estimating R\u00e9nyi entropy of discrete distributions. IEEE Transactions on Information Theory, 63(1), 38-56.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ACHARYA%2C%20J.%20ORLITSKY%2C%20A.%20SURESH%2C%20A.T.%20TYAGI%2C%20H.%20Estimating%20R%C3%A9nyi%20entropy%20of%20discrete%20distributions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=ACHARYA%2C%20J.%20ORLITSKY%2C%20A.%20SURESH%2C%20A.T.%20TYAGI%2C%20H.%20Estimating%20R%C3%A9nyi%20entropy%20of%20discrete%20distributions%202017"
        },
        {
            "id": "36",
            "entry": "[36] HAO, Y., & ORLITSKY, A. (2018, June). Adaptive estimation of generalized distance to uniformity. In 2018 IEEE International Symposium on Information Theory (ISIT) (pp. 10761080). IEEE.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=HAO%2C%20Y.%20ORLITSKY%2C%20A.%20Adaptive%20estimation%20of%20generalized%20distance%20to%20uniformity%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=HAO%2C%20Y.%20ORLITSKY%2C%20A.%20Adaptive%20estimation%20of%20generalized%20distance%20to%20uniformity%202018-06"
        },
        {
            "id": "37",
            "entry": "[37] BATU, T., & CANONNE, C. L. (2017, October). Generalized Uniformity Testing. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS) (pp. 880-889). IEEE. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=BATU%2C%20T.%20CANONNE%2C%20C.L.%20Generalized%20Uniformity%20Testing%202017-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=BATU%2C%20T.%20CANONNE%2C%20C.L.%20Generalized%20Uniformity%20Testing%202017-10"
        }
    ]
}
