{
    "filename": "8229-robustness-of-conditional-gans-to-noisy-labels.pdf",
    "metadata": {
        "title": "Robustness of conditional GANs to noisy labels",
        "author": "Kiran K. Thekumparampil, Ashish Khetan, Zinan Lin, Sewoong Oh",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8229-robustness-of-conditional-gans-to-noisy-labels.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We study the problem of learning conditional generators from noisy labeled samples, where the labels are corrupted by random noise. A standard training of conditional GANs will not only produce samples with wrong labels, but also generate poor quality samples. We consider two scenarios, depending on whether the noise model is known or not. When the distribution of the noise is known, we introduce a novel architecture which we call Robust Conditional GAN (RCGAN). The main idea is to corrupt the label of the generated sample before feeding to the adversarial discriminator, forcing the generator to produce samples with clean labels. This approach of passing through a matching noisy channel is justified by accompanying multiplicative approximation bounds between the loss of the RCGAN and the distance between the clean real distribution and the generator distribution. This shows that the proposed approach is robust, when used with a carefully chosen discriminator architecture, known as projection discriminator. When the distribution of the noise is not known, we provide an extension of our architecture, which we call RCGAN-U, that learns the noise model simultaneously while training the generator. We show experimentally on MNIST and CIFAR-10 datasets that both the approaches consistently improve upon baseline approaches, and RCGAN-U closely matches the performance of RCGAN."
    },
    "keywords": [
        {
            "term": "super resolution",
            "url": "https://en.wikipedia.org/wiki/super_resolution"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "Pittsburgh Supercomputing Center",
            "url": "https://en.wikipedia.org/wiki/Pittsburgh_Supercomputing_Center"
        }
    ],
    "highlights": [
        "Conditional generative adversarial networks (GAN) have been widely successful in several applications including improving image quality, semi-supervised learning, reinforcement learning, category transformation, style transfer, image de-noising, compression, in-painting, and super-resolution [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c48\" href=\"#r48\">48</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>, <a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c57\" href=\"#r57\">57</a>]",
        "When we have the knowledge of the confusion matrix C, we propose Robust Conditional generative adversarial networks (Robust Conditional generative adversarial networks) in Section 2",
        "We provide experimental results showing that performance gains similar to that of Robust Conditional generative adversarial networks can be achieved",
        "We propose Robust Conditional generative adversarial networks (RCGAN) architecture which has the following pre-processing, discriminator update, and generator update steps",
        "For Robust Conditional generative adversarial networks, we propose a popular state-of-the-art discriminator for conditional generative adversarial networks known as the projection discriminator [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>], parametrized by V \u2208 Rm\u00d7dV , v \u2208 Rdv , and \u03b8 \u2208 Rd\u03b8 : DV,v,\u03b8(x, y) = vec(y)T V \u03c8(x; \u03b8) + vT \u03c8 (x; \u03b8) , (10)",
        "Standard conditional generative adversarial networks can be sensitive to noise in the labels of the training data"
    ],
    "key_statements": [
        "Conditional generative adversarial networks (GAN) have been widely successful in several applications including improving image quality, semi-supervised learning, reinforcement learning, category transformation, style transfer, image de-noising, compression, in-painting, and super-resolution [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c48\" href=\"#r48\">48</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>, <a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c57\" href=\"#r57\">57</a>]",
        "When we have the knowledge of the confusion matrix C, we propose Robust Conditional generative adversarial networks (Robust Conditional generative adversarial networks) in Section 2",
        "We provide a finite sample generalization bound showing that the loss minimized in training Robust Conditional generative adversarial networks does generalize, and results in the learned distribution being close to the clean conditional distribution PX|Y (Theorem 3)",
        "We provide experimental results showing that performance gains similar to that of Robust Conditional generative adversarial networks can be achieved",
        "Motivated by the success of AmbientGAN in de-noising, we propose Robust Conditional generative adversarial networks",
        "We propose Robust Conditional generative adversarial networks (RCGAN) architecture which has the following pre-processing, discriminator update, and generator update steps",
        "We provide analyses of Robust Conditional generative adversarial networks on a distance that generalizes without any assumptions on the distribution of the real data as proven in [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>]: neural network distance",
        "For Robust Conditional generative adversarial networks, we propose a popular state-of-the-art discriminator for conditional generative adversarial networks known as the projection discriminator [<a class=\"ref-link\" id=\"c32\" href=\"#r32\">32</a>], parametrized by V \u2208 Rm\u00d7dV , v \u2208 Rdv , and \u03b8 \u2208 Rd\u03b8 : DV,v,\u03b8(x, y) = vec(y)T V \u03c8(x; \u03b8) + vT \u03c8 (x; \u03b8) , (10)",
        "We refer to Appendix I for a proof. This justifies the use of the proposed Robust Conditional generative adversarial networks which minimizes dF (Pn, Qn), as it leads to the generator Q being close to the real distribution P in neural network distance, dF (P, Q)",
        "We propose Robust Conditional generative adversarial networks-Unknown (RCGAN-U) algorithm which jointly estimates the real distribution P and the noise model C",
        "CIFAR-10 In Figure 3, we show the inception score [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>] and the label accuracy of the conditional generator for the four approaches: our proposed Robust Conditional generative adversarial networks and Robust Conditional generative adversarial networks-U, against the baselines Unbiased (Section 5) and Biased (Section 1) generative adversarial networks trained using CIFAR-10 images [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>], while varying the label accuracy of the real data under uniform flipping model",
        "Standard conditional generative adversarial networks can be sensitive to noise in the labels of the training data",
        "Inspired by AmbientGAN [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>], the main idea is to pair the generator output image with a label that is passed through a noisy channel, before feeding to the discriminator"
    ],
    "summary": [
        "Conditional generative adversarial networks (GAN) have been widely successful in several applications including improving image quality, semi-supervised learning, reinforcement learning, category transformation, style transfer, image de-noising, compression, in-painting, and super-resolution [<a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>, <a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>, <a class=\"ref-link\" id=\"c48\" href=\"#r48\">48</a>, <a class=\"ref-link\" id=\"c36\" href=\"#r36\">36</a>, <a class=\"ref-link\" id=\"c26\" href=\"#r26\">26</a>, <a class=\"ref-link\" id=\"c57\" href=\"#r57\">57</a>].",
        "When we have the knowledge of the confusion matrix C, we propose RCGAN (Robust Conditional GAN) in Section 2.",
        "We provide a finite sample generalization bound showing that the loss minimized in training RCGAN does generalize, and results in the learned distribution being close to the clean conditional distribution PX|Y (Theorem 3).",
        "We showcase the practical use of learned conditional GANs, by using it to fix the noisy labels in the training data.",
        "Training a conditional GAN with noisy samples results in a biased generator.",
        "We propose Robust Conditional GAN (RCGAN) architecture which has the following pre-processing, discriminator update, and generator update steps.",
        "According to PY and corresponding noisy labels are generated by corrupting the y according to the conditional distribution Cy which is the y-th row of the confusion matrix: max E [\u03c6 (D(x, y))] + E [\u03c6 (1 \u2212 D(G(z; y), y))] , D\u2208F (x,y)\u223cPX,Y",
        "When \u03bb = 0, we get the standard conditional GAN update steps, albeit one which tries to minimize discriminator loss between the noisy real distribution P and the distribution Q of the generator when the label is passed through the same noisy channel parameterized by C.",
        "In training GAN, we minimize the empirical neural network distance, dF (Pn, Qn), where Pn and Qn denote the empirical distribution of n samples.",
        "This justifies the use of the proposed RCGAN which minimizes dF (Pn, Qn), as it leads to the generator Q being close to the real distribution P in neural network distance, dF (P, Q).",
        "An immediate application of robust GANs is recovering the true labels of the noisy training data, which is an important and challenging problem in crowdsourcing.",
        "We propose a new meta-algorithm, which we call cGAN-label-recovery, which use any conditional generator G(z, y) trained on the noisy samples, to estimate the true label, as y, of a sample x using the following optimization.",
        "In the right panel of Figure 2 we compare the label recovery accuracy of the meta-algorithm using the five conditional GANs, on 500 randomly chosen noisy training samples.",
        "5.2 CIFAR-10 In Figure 3, we show the inception score [<a class=\"ref-link\" id=\"c40\" href=\"#r40\">40</a>] and the label accuracy of the conditional generator for the four approaches: our proposed RCGAN and RCGAN-U, against the baselines Unbiased (Section 5) and Biased (Section 1) GANs trained using CIFAR-10 images [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>], while varying the label accuracy of the real data under uniform flipping model.",
        "We showcase that the proposed architecture, when trained with a regularizer, has superior robustness on benchmark datasets"
    ],
    "headline": "We study the problem of learning conditional generators from noisy labeled samples, where the labels are corrupted by random noise",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas. Representation learning and adversarial generation of 3D point clouds. arXiv preprint arXiv:1707.02392, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.02392"
        },
        {
            "id": "2",
            "entry": "[2] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein GAN. arXiv preprint arXiv:1701.07875, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.07875"
        },
        {
            "id": "3",
            "entry": "[3] Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium in generative adversarial nets (GANs). arXiv preprint arXiv:1703.00573, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00573"
        },
        {
            "id": "4",
            "entry": "[4] Yu Bai, Tengyu Ma, and Andrej Risteski. Approximability of discriminators implies diversity in GANs. arXiv preprint arXiv:1806.10586, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.10586"
        },
        {
            "id": "5",
            "entry": "[5] David Berthelot, Tom Schumm, and Luke Metz. BEGAN: Boundary equilibrium generative adversarial networks. arXiv preprint arXiv:1703.10717, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.10717"
        },
        {
            "id": "6",
            "entry": "[6] G Biau, B Cadre, M Sangnier, and U Tanielian. Some theoretical properties of GANs. arXiv preprint arXiv:1803.07819, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.07819"
        },
        {
            "id": "7",
            "entry": "[7] Battista Biggio, Blaine Nelson, and Pavel Laskov. Support vector machines under adversarial label noise. In Asian Conference on Machine Learning, pages 97\u2013112, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Biggio%2C%20Battista%20Nelson%2C%20Blaine%20Laskov%2C%20Pavel%20Support%20vector%20machines%20under%20adversarial%20label%20noise%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Biggio%2C%20Battista%20Nelson%2C%20Blaine%20Laskov%2C%20Pavel%20Support%20vector%20machines%20under%20adversarial%20label%20noise%202011"
        },
        {
            "id": "8",
            "entry": "[8] Miko\u0142aj Binkowski, Dougal J Sutherland, Michael Arbel, and Arthur Gretton. Demystifying MMD GANs. arXiv preprint arXiv:1801.01401, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.01401"
        },
        {
            "id": "9",
            "entry": "[9] Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using generative models. arXiv preprint arXiv:1703.03208, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.03208"
        },
        {
            "id": "10",
            "entry": "[10] Ashish Bora, Eric Price, and Alexandros G Dimakis. AmbientGAN: Generative models from lossy measurements. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bora%2C%20Ashish%20Price%2C%20Eric%20Dimakis%2C%20Alexandros%20G.%20AmbientGAN%3A%20Generative%20models%20from%20lossy%20measurements%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bora%2C%20Ashish%20Price%2C%20Eric%20Dimakis%2C%20Alexandros%20G.%20AmbientGAN%3A%20Generative%20models%20from%20lossy%20measurements%202018"
        },
        {
            "id": "11",
            "entry": "[11] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20InfoGAN%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "12",
            "entry": "[12] Alexander Philip Dawid and Allan M Skene. Maximum likelihood estimation of observer error-rates using the em algorithm. Applied statistics, pages 20\u201328, 1979.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dawid%2C%20Alexander%20Philip%20Skene%2C%20Allan%20M.%20Maximum%20likelihood%20estimation%20of%20observer%20error-rates%20using%20the%20em%20algorithm%201979",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dawid%2C%20Alexander%20Philip%20Skene%2C%20Allan%20M.%20Maximum%20likelihood%20estimation%20of%20observer%20error-rates%20using%20the%20em%20algorithm%201979"
        },
        {
            "id": "13",
            "entry": "[13] Emily L Denton, Soumith Chintala, Rob Fergus, et al. Deep generative image models using a Laplacian pyramid of adversarial networks. In Advances in neural information processing systems, pages 1486\u20131494, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20L.%20Chintala%2C%20Soumith%20Fergus%2C%20Rob%20Deep%20generative%20image%20models%20using%20a%20Laplacian%20pyramid%20of%20adversarial%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20L.%20Chintala%2C%20Soumith%20Fergus%2C%20Rob%20Deep%20generative%20image%20models%20using%20a%20Laplacian%20pyramid%20of%20adversarial%20networks%202015"
        },
        {
            "id": "14",
            "entry": "[14] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "15",
            "entry": "[15] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of Wasserstein GANs. In Advances in Neural Information Processing Systems, pages 5769\u20135779, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20Wasserstein%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20Wasserstein%20GANs%202017"
        },
        {
            "id": "16",
            "entry": "[16] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks.%20arXiv%20p%202017"
        },
        {
            "id": "17",
            "entry": "[17] Alexia Jolicoeur-Martineau. The relativistic discriminator: a key element missing from standard GAN. arXiv preprint arXiv:1807.00734, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.00734"
        },
        {
            "id": "18",
            "entry": "[18] David R Karger, Sewoong Oh, and Devavrat Shah. Iterative learning for reliable crowdsourcing systems. In Advances in neural information processing systems, pages 1953\u20131961, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karger%2C%20David%20R.%20Oh%2C%20Sewoong%20Shah%2C%20Devavrat%20Iterative%20learning%20for%20reliable%20crowdsourcing%20systems%201953",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karger%2C%20David%20R.%20Oh%2C%20Sewoong%20Shah%2C%20Devavrat%20Iterative%20learning%20for%20reliable%20crowdsourcing%20systems%201953"
        },
        {
            "id": "19",
            "entry": "[19] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10196"
        },
        {
            "id": "20",
            "entry": "[20] Ashish Khetan, Zachary C Lipton, and Anima Anandkumar. Learning from noisy singly-labeled data. arXiv preprint arXiv:1712.04577, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.04577"
        },
        {
            "id": "21",
            "entry": "[21] Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jungkwon Lee, and Jiwon Kim. Learning to discover cross-domain relations with generative adversarial networks. arXiv preprint arXiv:1703.05192, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.05192"
        },
        {
            "id": "22",
            "entry": "[22] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "23",
            "entry": "[23] Murat Kocaoglu, Christopher Snyder, Alexandros G Dimakis, and Sriram Vishwanath. CausalGAN: Learning causal implicit generative models with adversarial training. arXiv preprint arXiv:1709.02023, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.02023"
        },
        {
            "id": "24",
            "entry": "[24] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "25",
            "entry": "[25] Yann LeCun. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998.",
            "url": "http://yann.lecun.com/exdb/mnist/"
        },
        {
            "id": "26",
            "entry": "[26] Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic single image super-resolution using a generative adversarial network. arXiv preprint, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network.%20arXiv%20p%202016"
        },
        {
            "id": "27",
            "entry": "[27] Xiaodan Liang, Lisa Lee, Wei Dai, and Eric P Xing. Dual motion GAN for future-flow embedded video prediction. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20Xiaodan%20Lee%2C%20Lisa%20Dai%2C%20Wei%20and%20Eric%20P%20Xing.%20Dual%20motion%202017"
        },
        {
            "id": "28",
            "entry": "[28] Zinan Lin, Ashish Khetan, Giulia Fanti, and Sewoong Oh. PacGAN: The power of two samples in generative adversarial networks. arXiv preprint arXiv:1712.04086, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.04086"
        },
        {
            "id": "29",
            "entry": "[29] Bing Liu, Yang Dai, Xiaoli Li, Wee Sun Lee, and Philip S Yu. Building text classifiers using positive and unlabeled examples. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on, pages 179\u2013186. IEEE, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Bing%20Dai%2C%20Yang%20Li%2C%20Xiaoli%20Lee%2C%20Wee%20Sun%20Building%20text%20classifiers%20using%20positive%20and%20unlabeled%20examples%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Bing%20Dai%2C%20Yang%20Li%2C%20Xiaoli%20Lee%2C%20Wee%20Sun%20Building%20text%20classifiers%20using%20positive%20and%20unlabeled%20examples%202003"
        },
        {
            "id": "30",
            "entry": "[30] Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "31",
            "entry": "[31] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05957"
        },
        {
            "id": "32",
            "entry": "[32] Takeru Miyato and Masanori Koyama. cGANs with projection discriminator. arXiv preprint arXiv:1802.05637, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05637"
        },
        {
            "id": "33",
            "entry": "[33] Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, and Sreeram Kannan. ClusterGAN: Latent space clustering in generative adversarial networks. arXiv preprint arXiv:1809.03627, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1809.03627"
        },
        {
            "id": "34",
            "entry": "[34] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels. In Advances in neural information processing systems, pages 1196\u20131204, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Natarajan%2C%20Nagarajan%20Dhillon%2C%20Inderjit%20S.%20Ravikumar%2C%20Pradeep%20K.%20Tewari%2C%20Ambuj%20Learning%20with%20noisy%20labels%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Natarajan%2C%20Nagarajan%20Dhillon%2C%20Inderjit%20S.%20Ravikumar%2C%20Pradeep%20K.%20Tewari%2C%20Ambuj%20Learning%20with%20noisy%20labels%202013"
        },
        {
            "id": "35",
            "entry": "[35] Anh Nguyen, Jason Yosinski, Yoshua Bengio, Alexey Dosovitskiy, and Jeff Clune. Plug & play generative networks: Conditional iterative generation of images in latent space. arXiv preprint arXiv:1612.00005, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.00005"
        },
        {
            "id": "36",
            "entry": "[36] Augustus Odena, Christopher Olah, and Jonathon Shlens. Conditional image synthesis with auxiliary classifier gans. arXiv preprint arXiv:1610.09585, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.09585"
        },
        {
            "id": "37",
            "entry": "[37] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "38",
            "entry": "[38] Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. Generative adversarial text to image synthesis. arXiv preprint arXiv:1605.05396, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.05396"
        },
        {
            "id": "39",
            "entry": "[39] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "40",
            "entry": "[40] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training GANs. In Advances in Neural Information Processing Systems, pages 2234\u20132242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20GANs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20GANs%202016"
        },
        {
            "id": "41",
            "entry": "[41] Maziar Sanjabi, Jimmy Ba, Meisam Razaviyayn, and Jason D Lee. Solving approximate Wasserstein GANs to stationarity. arXiv preprint arXiv:1802.08249, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.08249"
        },
        {
            "id": "42",
            "entry": "[42] Rajat Sen, Karthikeyan Shanmugam, Himanshu Asnani, Arman Rahimzamani, and Sreeram Kannan. Mimic and classify: A meta-algorithm for conditional independence testing. arXiv preprint arXiv:1806.09708, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.09708"
        },
        {
            "id": "43",
            "entry": "[43] Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh Susskind, Wenda Wang, and Russ Webb. Learning from simulated and unsupervised images through adversarial training. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 3, page 6, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shrivastava%2C%20Ashish%20Pfister%2C%20Tomas%20Tuzel%2C%20Oncel%20Susskind%2C%20Josh%20Learning%20from%20simulated%20and%20unsupervised%20images%20through%20adversarial%20training%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shrivastava%2C%20Ashish%20Pfister%2C%20Tomas%20Tuzel%2C%20Oncel%20Susskind%2C%20Josh%20Learning%20from%20simulated%20and%20unsupervised%20images%20through%20adversarial%20training%202017"
        },
        {
            "id": "44",
            "entry": "[44] Bharath K Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Sch\u00f6lkopf, and Gert RG Lanckriet. On integral probability metrics, \u03c6-divergences and binary classification. arXiv preprint arXiv:0901.2698, 2009.",
            "arxiv_url": "https://arxiv.org/pdf/0901.2698"
        },
        {
            "id": "45",
            "entry": "[45] Guillaume Stempfel and Liva Ralaivola. Learning kernel perceptrons on noisy data using random projections. In International Conference on Algorithmic Learning Theory, pages 328\u2013342.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stempfel%2C%20Guillaume%20Ralaivola%2C%20Liva%20Learning%20kernel%20perceptrons%20on%20noisy%20data%20using%20random%20projections",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stempfel%2C%20Guillaume%20Ralaivola%2C%20Liva%20Learning%20kernel%20perceptrons%20on%20noisy%20data%20using%20random%20projections"
        },
        {
            "id": "46",
            "entry": "[46] Guillaume Stempfel and Liva Ralaivola. Learning SVMs from sloppily labeled data. In International Conference on Artificial Neural Networks, pages 884\u2013893.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stempfel%2C%20Guillaume%20Ralaivola%2C%20Liva%20Learning%20SVMs%20from%20sloppily%20labeled%20data",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stempfel%2C%20Guillaume%20Ralaivola%2C%20Liva%20Learning%20SVMs%20from%20sloppily%20labeled%20data"
        },
        {
            "id": "47",
            "entry": "[47] Dougal J Sutherland, Hsiao-Yu Tung, Heiko Strathmann, Soumyajit De, Aaditya Ramdas, Alex Smola, and Arthur Gretton. Generative models and model criticism via optimized maximum mean discrepancy. arXiv preprint arXiv:1611.04488, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.04488"
        },
        {
            "id": "48",
            "entry": "[48] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks. arXiv preprint arXiv:1601.06759, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1601.06759"
        },
        {
            "id": "49",
            "entry": "[49] Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. In Advances In Neural Information Processing Systems, pages 613\u2013621, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Generating%20videos%20with%20scene%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Generating%20videos%20with%20scene%20dynamics%202016"
        },
        {
            "id": "50",
            "entry": "[50] Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. Learning a probabilistic latent space of object shapes via 3D generative-adversarial modeling. In Advances in Neural Information Processing Systems, pages 82\u201390, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20Bill%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203D%20generative-adversarial%20modeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20Bill%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203D%20generative-adversarial%20modeling%202016"
        },
        {
            "id": "51",
            "entry": "[51] Zhi Xu, Chengtao Li, and Stefanie Jegelka. Robust GANs against dishonest adversaries. arXiv preprint arXiv:1802.09700, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.09700"
        },
        {
            "id": "52",
            "entry": "[52] Raymond Yeh, Chen Chen, Teck Yian Lim, Mark Hasegawa-Johnson, and Minh N Do. Semantic image inpainting with perceptual and contextual losses. arXiv preprint arXiv:1607.07539, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.07539"
        },
        {
            "id": "53",
            "entry": "[53] Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. Self-attention generative adversarial networks. arXiv preprint arXiv:1805.08318, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.08318"
        },
        {
            "id": "54",
            "entry": "[54] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang Wang, and Dimitris Metaxas. StackGAN: Text to photo-realistic image synthesis with stacked generative adversarial networks. In IEEE Int. Conf. Comput. Vision (ICCV), pages 5907\u20135915, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Han%20Xu%2C%20Tao%20Li%2C%20Hongsheng%20Zhang%2C%20Shaoting%20Xiaolei%20Huang%2C%20Xiaogang%20Wang%2C%20and%20Dimitris%20Metaxas.%20StackGAN%3A%20Text%20to%20photo-realistic%20image%20synthesis%20with%20stacked%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Han%20Xu%2C%20Tao%20Li%2C%20Hongsheng%20Zhang%2C%20Shaoting%20Xiaolei%20Huang%2C%20Xiaogang%20Wang%2C%20and%20Dimitris%20Metaxas.%20StackGAN%3A%20Text%20to%20photo-realistic%20image%20synthesis%20with%20stacked%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "55",
            "entry": "[55] Pengchuan Zhang, Qiang Liu, Dengyong Zhou, Tao Xu, and Xiaodong He. On the discrimination-generalization tradeoff in GANs. arXiv preprint arXiv:1711.02771, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.02771"
        },
        {
            "id": "56",
            "entry": "[56] Jun-Yan Zhu, Philipp Kr\u00e4henb\u00fchl, Eli Shechtman, and Alexei A Efros. Generative visual manipulation on the natural image manifold. In European Conference on Computer Vision, pages 597\u2013613.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Shechtman%2C%20Eli%20and%20Alexei%20A%20Efros.%20Generative%20visual%20manipulation",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Shechtman%2C%20Eli%20and%20Alexei%20A%20Efros.%20Generative%20visual%20manipulation"
        },
        {
            "id": "57",
            "entry": "[57] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint arXiv:1703.10593, 2017. ",
            "arxiv_url": "https://arxiv.org/pdf/1703.10593"
        }
    ]
}
