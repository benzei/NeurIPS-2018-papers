{
    "filename": "7690-the-physical-systems-behind-optimization-algorithms.pdf",
    "metadata": {
        "title": "The Physical Systems Behind Optimization Algorithms",
        "author": "Lin Yang, Raman Arora, Vladimir braverman, Tuo Zhao",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7690-the-physical-systems-behind-optimization-algorithms.pdf"
        },
        "abstract": "We use differential equations based approaches to provide some physics insights into analyzing the dynamics of popular optimization algorithms in machine learning. In particular, we study gradient descent, proximal gradient descent, coordinate gradient descent, proximal coordinate gradient, and Newton\u2019s methods as well as their Nesterov\u2019s accelerated variants in a unified framework motivated by a natural connection of optimization algorithms to physical systems. Our analysis is applicable to more general algorithms and optimization problems beyond convexity and strong convexity, e.g. Polyak-\u0141ojasiewicz and error bound conditions (possibly nonconvex)."
    },
    "keywords": [
        {
            "term": "ordinary differential equation",
            "url": "https://en.wikipedia.org/wiki/ordinary_differential_equation"
        },
        {
            "term": "quadratic growth",
            "url": "https://en.wikipedia.org/wiki/quadratic_growth"
        },
        {
            "term": "differential equation",
            "url": "https://en.wikipedia.org/wiki/differential_equation"
        },
        {
            "term": "linear convergence",
            "url": "https://en.wikipedia.org/wiki/linear_convergence"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "optimization problem",
            "url": "https://en.wikipedia.org/wiki/optimization_problem"
        },
        {
            "term": "optimization algorithm",
            "url": "https://en.wikipedia.org/wiki/optimization_algorithm"
        },
        {
            "term": "gradient method",
            "url": "https://en.wikipedia.org/wiki/gradient_method"
        },
        {
            "term": "strong convexity",
            "url": "https://en.wikipedia.org/wiki/strong_convexity"
        }
    ],
    "highlights": [
        "We show that for a massless system, the convergence rate only depends on the gradient and smoothness of the function, whereas a massive particle system has an energy decay rate proportional to the ratio between the mass and damping coefficient",
        "Many machine learning problems can be cast into an optimization problem of the following form: x\u2217 = argmin f (x), (1.1)",
        "We further show that optimal algorithms such as Nesterov\u2019s accelerated gradient correspond to an oscillator system near critical damping",
        "The first-order optimization algorithms [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]; while the focus there is on bridging the gap between discrete algorithmic analysis and continuous approximation, we focus on understanding the physical systems behind the optimization algorithms",
        "Our analysis is inspired by [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], where the Nesterov\u2019s accelerated gradient algorithm for general convex function is approximated by an ordinary differential equation under the limit of infinitesimal time step",
        "The convergence of Nesterov\u2019s accelerated gradient has been studied for general convex functions in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], and is omitted. [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has shown that Nesterov\u2019s accelerated gradient achieves a linear convergence for strongly convex functions"
    ],
    "key_statements": [
        "We show that for a massless system, the convergence rate only depends on the gradient and smoothness of the function, whereas a massive particle system has an energy decay rate proportional to the ratio between the mass and damping coefficient",
        "Many machine learning problems can be cast into an optimization problem of the following form: x\u2217 = argmin f (x), (1.1)",
        "vanilla gradient descent is simple, intuitive, and easy to implement in practice",
        "Our Contribution (I): We provide novel physics-based insights into the differential equation approaches for optimization",
        "We further show that optimal algorithms such as Nesterov\u2019s accelerated gradient correspond to an oscillator system near critical damping",
        "Our Contribution (II): We provide new analysis for more general optimization problems beyond general convexity and strong convexity, as well as more general algorithms",
        "We present the extension to the nonsmooth composite optimization problem in Appendix",
        "The first-order optimization algorithms [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]; while the focus there is on bridging the gap between discrete algorithmic analysis and continuous approximation, we focus on understanding the physical systems behind the optimization algorithms",
        "We develop a unified representation for the continuous approximations of the aforementioned optimization algorithms",
        "Our analysis is inspired by [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], where the Nesterov\u2019s accelerated gradient algorithm for general convex function is approximated by an ordinary differential equation under the limit of infinitesimal time step",
        "We study the convergence of vanilla gradient descent for two classes of functions: (1) General convex function \u2014 [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has shown that vanilla gradient descent achieves O(L/k) convergence for general convex functions; (2) A class of functions satisfying the Polyak-\u0141ojasiewicz (P\u0141) condition, which is defined as follows [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>, <a class=\"ref-link\" id=\"c4\" href=\"#r4\">4</a>]",
        "We study the convergence of Nesterov\u2019s accelerated gradient for a class of convex functions satisfying the Polyak-\u0141ojasiewicz (P\u0141) condition",
        "The convergence of Nesterov\u2019s accelerated gradient has been studied for general convex functions in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], and is omitted. [<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has shown that Nesterov\u2019s accelerated gradient achieves a linear convergence for strongly convex functions",
        "Comparing with vanilla gradient descent, Nesterov\u2019s accelerated gradient improves the constant term on the convergence rate for convex functions satisfying P\u0141 condition from L/\u03bc to L/\u03bc",
        "Has proved the local quadratic convergence of the Newton\u2019s algorithm, which is better than our ordinary differential equation-type analysis"
    ],
    "summary": [
        "We show that for a massless system, the convergence rate only depends on the gradient and smoothness of the function, whereas a massive particle system has an energy decay rate proportional to the ratio between the mass and damping coefficient.",
        "Our analysis is inspired by [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], where the NAG algorithm for general convex function is approximated by an ordinary differential equation under the limit of infinitesimal time step.",
        "A simple harmonic oscillator would not be sufficient and does not correspond to a convergent algorithm, since damped harmonic oscillator; the system never stops: the particle at the equilibrium has the largest",
        "If an algorithm converges to optimal, a sufficient condition is that the corresponding potential energy V decreases over time.",
        "We say that an algorithm is (1/\u03b3)-convergent, if the potential energy decay rate is O(1/\u03b3).",
        "We study the convergence of NAG for a class of convex functions satisfying the Polyak-\u0141ojasiewicz (P\u0141) condition.",
        "The convergence of NAG has been studied for general convex functions in [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>], and is omitted.",
        "[<a class=\"ref-link\" id=\"c11\" href=\"#r11\">11</a>] has shown that NAG achieves a linear convergence for strongly convex functions.",
        "Comparing with VGD, NAG improves the constant term on the convergence rate for convex functions satisfying P\u0141 condition from L/\u03bc to L/\u03bc.",
        "Our proposed framework justifies the convergence analysis of the RCGD and ARCG algorithms.",
        "Note that our proposed ODE framework only proves a local linear convergence for Newton method under the strongly convex, smooth and self concordant conditions.",
        "Has proved the local quadratic convergence of the Newton\u2019s algorithm, which is better than our ODE-type analysis.",
        "We give a more detailed interpretation of our proposed system from a perspective of physics: Consequence of Particle Mass \u2014 As shown in Section 2, a massless particle system describes the simple gradient descent algorithm.",
        "Damping and Convergence Rate \u2014 For a quadratic potential exponential energy decay, where the exponent factor depends on",
        "For a potential function f satisfying convexity and \u03bc-P\u0141 condition, NAG",
        "Connecting P\u0141 Condition to Hooke\u2019s law \u2014 The \u03bc-P\u0141 and convex conditions together naturally mimic the property of a quadratic potential V , i.e., a damped harmonic oscillator.",
        "Displacement guarantees that the force field is strong enough, since the left hand side of the above equation is exactly the potential energy of a spring based on Hooke\u2019s law.",
        "The connection between the P\u0141 condition and the Hooke\u2019s law indicates that strong convexity is not the fundamental characterization of linear convergence."
    ],
    "headline": "Proximal gradient descent, coordinate gradient descent, proximal coordinate gradient, and Newton\u2019s methods as well as their Nesterov\u2019s accelerated variants in a unified framework motivated by a natural connection of optimization algorithms to physical systems",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Stewart N Ethier and Thomas G Kurtz. Markov processes: characterization and convergence, volume 282. John Wiley &amp; Sons, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ethier%2C%20Stewart%20N.%20Kurtz%2C%20Thomas%20G.%20Markov%20processes%3A%20characterization%20and%20convergence%2C%20volume%20282%202009"
        },
        {
            "id": "2",
            "entry": "[2] Olivier Fercoq and Peter Richt\u00e1rik. Accelerated, parallel, and proximal coordinate descent. SIAM Journal on Optimization, 25(4):1997\u20132023, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fercoq%2C%20Olivier%20Accelerated%2C%20Peter%20Richt%C3%A1rik%20parallel%20and%20proximal%20coordinate%20descent%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fercoq%2C%20Olivier%20Accelerated%2C%20Peter%20Richt%C3%A1rik%20parallel%20and%20proximal%20coordinate%20descent%202015"
        },
        {
            "id": "3",
            "entry": "[3] Pinghua Gong and Jieping Ye. Linear convergence of variance-reduced stochastic gradient without strong convexity. arXiv preprint arXiv:1406.1102, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1406.1102"
        },
        {
            "id": "4",
            "entry": "[4] Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximalgradient methods under the polyak-\u0142ojasiewicz condition. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 795\u2013811.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karimi%2C%20Hamed%20Nutini%2C%20Julie%20Schmidt%2C%20Mark%20Linear%20convergence%20of%20gradient%20and%20proximalgradient%20methods%20under%20the%20polyak-%C5%82ojasiewicz%20condition",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karimi%2C%20Hamed%20Nutini%2C%20Julie%20Schmidt%2C%20Mark%20Linear%20convergence%20of%20gradient%20and%20proximalgradient%20methods%20under%20the%20polyak-%C5%82ojasiewicz%20condition"
        },
        {
            "id": "5",
            "entry": "[5] Qihang Lin, Zhaosong Lu, and Lin Xiao. An accelerated proximal coordinate gradient method. In Advances in Neural Information Processing Systems, pages 3059\u20133067, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Qihang%20Lu%2C%20Zhaosong%20Xiao%2C%20Lin%20An%20accelerated%20proximal%20coordinate%20gradient%20method%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Qihang%20Lu%2C%20Zhaosong%20Xiao%2C%20Lin%20An%20accelerated%20proximal%20coordinate%20gradient%20method%202014"
        },
        {
            "id": "6",
            "entry": "[6] Ji Liu and Stephen J Wright. Asynchronous stochastic coordinate descent: Parallelism and convergence properties. SIAM Journal on Optimization, 25(1):351\u2013376, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ji%20Wright%2C%20Stephen%20J.%20Asynchronous%20stochastic%20coordinate%20descent%3A%20Parallelism%20and%20convergence%20properties%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ji%20Wright%2C%20Stephen%20J.%20Asynchronous%20stochastic%20coordinate%20descent%3A%20Parallelism%20and%20convergence%20properties%202015"
        },
        {
            "id": "7",
            "entry": "[7] Zhaosong Lu and Lin Xiao. On the complexity analysis of randomized block-coordinate descent methods. Mathematical Programming, 152(1-2):615\u2013642, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lu%2C%20Zhaosong%20Xiao%2C%20Lin%20On%20the%20complexity%20analysis%20of%20randomized%20block-coordinate%20descent%20methods%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lu%2C%20Zhaosong%20Xiao%2C%20Lin%20On%20the%20complexity%20analysis%20of%20randomized%20block-coordinate%20descent%20methods%202015"
        },
        {
            "id": "8",
            "entry": "[8] Zhi-Quan Luo and Paul Tseng. Error bounds and convergence analysis of feasible descent methods: a general approach. Annals of Operations Research, 46(1):157\u2013178, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20Zhi-Quan%20Tseng%2C%20Paul%20Error%20bounds%20and%20convergence%20analysis%20of%20feasible%20descent%20methods%3A%20a%20general%20approach%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20Zhi-Quan%20Tseng%2C%20Paul%20Error%20bounds%20and%20convergence%20analysis%20of%20feasible%20descent%20methods%3A%20a%20general%20approach%201993"
        },
        {
            "id": "9",
            "entry": "[9] I Necoara, Yu Nesterov, and F Glineur. Linear convergence of first order methods for nonstrongly convex optimization. arXiv preprint arXiv:1504.06298, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1504.06298"
        },
        {
            "id": "10",
            "entry": "[10] Yu Nesterov. Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM Journal on Optimization, 22(2):341\u2013362, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yu%20Efficiency%20of%20coordinate%20descent%20methods%20on%20huge-scale%20optimization%20problems%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yu%20Efficiency%20of%20coordinate%20descent%20methods%20on%20huge-scale%20optimization%20problems%202012"
        },
        {
            "id": "11",
            "entry": "[11] Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer Science & Business Media, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Introductory%20lectures%20on%20convex%20optimization%3A%20A%20basic%20course%2C%20volume%2087%202013"
        },
        {
            "id": "12",
            "entry": "[12] Jorge Nocedal and Stephen Wright. Numerical optimization. Springer Science &amp; Business Media, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nocedal%2C%20Jorge%20Wright%2C%20Stephen%20Numerical%20optimization%202006"
        },
        {
            "id": "13",
            "entry": "[13] Boris T Polyak. Some methods of speeding up the convergence of iteration methods. USSR Computational Mathematics and Mathematical Physics, 4(5):1\u201317, 1964.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Polyak%2C%20Boris%20T.%20Some%20methods%20of%20speeding%20up%20the%20convergence%20of%20iteration%20methods%201964",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Polyak%2C%20Boris%20T.%20Some%20methods%20of%20speeding%20up%20the%20convergence%20of%20iteration%20methods%201964"
        },
        {
            "id": "14",
            "entry": "[14] Boris Teodorovich Polyak. Gradient methods for minimizing functionals. Zhurnal Vychislitel\u2019noi Matematiki i Matematicheskoi Fiziki, 3(4):643\u2013653, 1963.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Polyak%2C%20Boris%20Teodorovich%20Gradient%20methods%20for%20minimizing%20functionals.%20Zhurnal%20Vychislitel%E2%80%99noi%20Matematiki%20i%201963",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Polyak%2C%20Boris%20Teodorovich%20Gradient%20methods%20for%20minimizing%20functionals.%20Zhurnal%20Vychislitel%E2%80%99noi%20Matematiki%20i%201963"
        },
        {
            "id": "15",
            "entry": "[15] Ralph Tyrell Rockafellar. Convex analysis. Princeton university press, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rockafellar%2C%20Ralph%20Tyrell%20Convex%20analysis%202015"
        },
        {
            "id": "16",
            "entry": "[16] Weijie Su, Stephen Boyd, and Emmanuel Candes. A differential equation for modeling nesterov\u2019s accelerated gradient method: theory and insights. In Advances in Neural Information Processing Systems, pages 2510\u20132518, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Su%2C%20Weijie%20Boyd%2C%20Stephen%20Candes%2C%20Emmanuel%20A%20differential%20equation%20for%20modeling%20nesterov%E2%80%99s%20accelerated%20gradient%20method%3A%20theory%20and%20insights%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Su%2C%20Weijie%20Boyd%2C%20Stephen%20Candes%2C%20Emmanuel%20A%20differential%20equation%20for%20modeling%20nesterov%E2%80%99s%20accelerated%20gradient%20method%3A%20theory%20and%20insights%202014"
        },
        {
            "id": "17",
            "entry": "[17] Andre Wibisono, Ashia C Wilson, and Michael I Jordan. A variational perspective on accelerated methods in optimization. arXiv preprint arXiv:1603.04245, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1603.04245"
        },
        {
            "id": "18",
            "entry": "[18] Ashia C Wilson, Benjamin Recht, and Michael I Jordan. A lyapunov analysis of momentum methods in optimization. arXiv preprint arXiv:1611.02635, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02635"
        },
        {
            "id": "19",
            "entry": "[19] Hui Zhang. New analysis of linear convergence of gradient-type methods via unifying error bound conditions. arXiv preprint arXiv:1606.00269, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.00269"
        },
        {
            "id": "20",
            "entry": "[20] Hui Zhang and Wotao Yin. Gradient methods for convex minimization: better rates under weaker conditions. arXiv preprint arXiv:1303.4645, 2013. ",
            "arxiv_url": "https://arxiv.org/pdf/1303.4645"
        }
    ]
}
