{
    "filename": "7683-differentially-private-contextual-linear-bandits.pdf",
    "metadata": {
        "title": "Differentially Private Contextual Linear Bandits",
        "author": "Roshan Shariff, Or Sheffet",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7683-differentially-private-contextual-linear-bandits.pdf"
        },
        "abstract": "We study the contextual linear bandit problem, a version of the standard stochastic multi-armed bandit (MAB) problem where a learner sequentially selects actions to maximize a reward which depends also on a user provided per-round context. Though the context is chosen arbitrarily or adversarially, the reward is assumed to be a stochastic function of a feature vector that encodes the context and selected action. Our goal is to devise private learners for the contextual linear bandit problem. We first show that using the standard definition of differential privacy results in linear regret. So instead, we adopt the notion of joint differential privacy, where we assume that the action chosen on day t is only revealed to user t and thus needn\u2019t be kept private that day, only on following days. We give a general scheme converting the classic linear-UCB algorithm into a joint differentially private algorithm using the tree-based algorithm [<a class=\"ref-link\" id=\"c10\" href=\"#r10\">10</a>, <a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]. We then apply either Gaussian noise or Wishart noise to achieve joint-differentially private algorithms and bound the resulting algorithms\u2019 regrets. In addition, we give the first lower bound on the additional regret any private algorithms for the MAB problem must incur."
    },
    "keywords": [
        {
            "term": "multi-armed bandit",
            "url": "https://en.wikipedia.org/wiki/multi-armed_bandit"
        },
        {
            "term": "feature vector",
            "url": "https://en.wikipedia.org/wiki/feature_vector"
        },
        {
            "term": "multi armed bandit",
            "url": "https://en.wikipedia.org/wiki/multi_armed_bandit"
        },
        {
            "term": "differential privacy",
            "url": "https://en.wikipedia.org/wiki/differential_privacy"
        }
    ],
    "highlights": [
        "The well-known stochastic multi-armed bandit (MAB) is a sequential decision-making task in which a learner repeatedly chooses an action and receives a noisy reward",
        "The contextual bandit problem is an extension of the multi-armed bandit problem, where the learner receives a context in each round, and the expected reward depends on both the context and the selected action",
        "It is common to model the task as a contextual linear bandit problem: Based on the user-given context, each action is mapped to a feature vector; the reward probability is assumed to depend on the same unknown linear function of the feature vector across all users",
        "Whereas all previous work on the private multi-armed bandit problem uses standard bounds, we show that any private algorithm must incur an additional regret of \u03a9(k log(n)/\u03b5)",
        "We show that any \u03b5-differentially private algorithm for the classic multi-armed bandit problem must incur an additional pseudo-regret of \u03a9(k log(n)/ ) on top of the standard regret bounds"
    ],
    "key_statements": [
        "The well-known stochastic multi-armed bandit (MAB) is a sequential decision-making task in which a learner repeatedly chooses an action and receives a noisy reward",
        "The contextual bandit problem is an extension of the multi-armed bandit problem, where the learner receives a context in each round, and the expected reward depends on both the context and the selected action",
        "It is common to model the task as a contextual linear bandit problem: Based on the user-given context, each action is mapped to a feature vector; the reward probability is assumed to depend on the same unknown linear function of the feature vector across all users",
        "Whereas all previous work on the private multi-armed bandit problem uses standard bounds, we show that any private algorithm must incur an additional regret of \u03a9(k log(n)/\u03b5)",
        "We show that any \u03b5-differentially private algorithm for the classic multi-armed bandit problem must incur an additional pseudo-regret of \u03a9(k log(n)/ ) on top of the standard regret bounds"
    ],
    "summary": [
        "The well-known stochastic multi-armed bandit (MAB) is a sequential decision-making task in which a learner repeatedly chooses an action and receives a noisy reward.",
        "We give upper and lower bounds for the problem of differentially private contextual linear bandits.",
        "When we discuss the impossibility of regret-minimization under standard differential privacy in Section 5, we revert back to a fixed action set A with an explicit per-round context ct .",
        "Whereas all previous work on the private MAB problem uses standard bounds, we show that any private algorithm must incur an additional regret of \u03a9(k log(n)/\u03b5).",
        "Further details about achieving differential privacy via additive noise and the tree-based algorithm appear in Section A of the supplementary material.",
        "If the optimal actions in every decision set Dt are separated from the sub-optimal actions by a reward gap of at least \u2206, with probability at least 1 \u2212 \u03b1 the pseudo-regret of Algorithm 1 satisfies",
        "Notice that Algorithm 1 uses its history of actions and rewards up to round t only via the confidence set Et , which is to say via Vt and ut , which are perturbations of the Gram matrix Gt and the vector ut X<t y<t , respectively; these determine \u03b2t .",
        "If the L2-norm of each row in the input is bounded by Lthen releasing the input\u2019s Gram matrix with added noise sampled from Wd+1(L 2I, k0) is (\u03b50, \u03b40)-differentially private, provided k0 \u2265 d + 1 + 28\u03b50\u22122 ln(4/\u03b40).",
        "Given that for each t the regularizers Ht, ht are taken by applying the tree-based algorithm with symmetrized shifted Gaussian noise whose entries are sampled i.i.d. from N (0, \u03c3n2oise), the following \u03c1min, \u03c1max, and \u03b3 are (\u03b1/2n)-accurate bounds:",
        "Applying Algorithm 1 where the regularizers Ht and ht are derived by applying the tree-based algorithm where each node holds a symmetrized matrix whose entries are sampled i.i.d. from N (0, \u03c3n2oise) and adding 2\u03a5I , we get a regret bound of",
        "The first, and probably the more obvious of the two, deals with the impossibility of obtaining sub-linear regret for the contextual bandit problem with the standard notion of differential privacy.",
        "For any \u03b5 < ln(2) and \u03b4 < 0.25, any (\u03b5, \u03b4)-differentially private algorithm A for the contextual bandit problem must incur pseudo-regret of \u03a9(n).",
        "We show that any \u03b5-differentially private algorithm for the classic MAB problem must incur an additional pseudo-regret of \u03a9(k log(n)/ ) on top of the standard regret bounds.",
        "Let A be any \u03b5-differentially private algorithm for the MAB problems with k arms whose expected regret is at most n3/4."
    ],
    "headline": "We study the contextual linear bandit problem, a version of the standard stochastic multi-armed bandit  problem where a learner sequentially selects actions to maximize a reward which depends on a user provided per-round context",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. In J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 24, pages 2312\u20132320. Curran Associates, Inc., 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbasi-Yadkori%2C%20Yasin%20P%C3%A1l%2C%20D%C3%A1vid%20Szepesv%C3%A1ri%2C%20Csaba%20Improved%20algorithms%20for%20linear%20stochastic%20bandits%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abbasi-Yadkori%2C%20Yasin%20P%C3%A1l%2C%20D%C3%A1vid%20Szepesv%C3%A1ri%2C%20Csaba%20Improved%20algorithms%20for%20linear%20stochastic%20bandits%202011"
        },
        {
            "id": "2",
            "entry": "[2] Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Online-to-confidence-set conversions and application to sparse stochastic bandits. In AISTATS, pages 1\u20139, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbasi-Yadkori%2C%20Yasin%20P%C3%A1l%2C%20D%C3%A1vid%20Szepesv%C3%A1ri%2C%20Csaba%20Online-to-confidence-set%20conversions%20and%20application%20to%20sparse%20stochastic%20bandits%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abbasi-Yadkori%2C%20Yasin%20P%C3%A1l%2C%20D%C3%A1vid%20Szepesv%C3%A1ri%2C%20Csaba%20Online-to-confidence-set%20conversions%20and%20application%20to%20sparse%20stochastic%20bandits%202012"
        },
        {
            "id": "3",
            "entry": "[3] Naoki Abe, Alan W. Biermann, and Philip M. Long. Reinforcement learning with immediate rewards and linear hypotheses. Algorithmica, 37(4):263\u2013293, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abe%2C%20Naoki%20Biermann%2C%20Alan%20W.%20Long%2C%20Philip%20M.%20Reinforcement%20learning%20with%20immediate%20rewards%20and%20linear%20hypotheses%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abe%2C%20Naoki%20Biermann%2C%20Alan%20W.%20Long%2C%20Philip%20M.%20Reinforcement%20learning%20with%20immediate%20rewards%20and%20linear%20hypotheses%202003"
        },
        {
            "id": "4",
            "entry": "[4] Rajeev Agrawal. Sample mean based index policies with O(log n) regret for the multi-armed bandit problem., volume 27, pages 1054\u20131078. Applied Probability Trust, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agrawal%2C%20Rajeev%20Sample%20mean%20based%20index%20policies%20with%20O%28log%20n%29%20regret%20for%20the%20multi-armed%20bandit%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agrawal%2C%20Rajeev%20Sample%20mean%20based%20index%20policies%20with%20O%28log%20n%29%20regret%20for%20the%20multi-armed%20bandit%201995"
        },
        {
            "id": "5",
            "entry": "[5] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. JMLR, 3:397\u2013422, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Auer%2C%20Peter%20Using%20confidence%20bounds%20for%20exploitation-exploration%20trade-offs%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Auer%2C%20Peter%20Using%20confidence%20bounds%20for%20exploitation-exploration%20trade-offs%202003"
        },
        {
            "id": "6",
            "entry": "[6] Peter Auer, Nicol\u00f2 Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. JMLR, 47(2-3):235\u2013256, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peter%20Auer%2C%20Nicol%C3%B2%20Cesa-Bianchi%20Fischer%2C%20Paul%20Finite-time%20analysis%20of%20the%20multiarmed%20bandit%20problem%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peter%20Auer%2C%20Nicol%C3%B2%20Cesa-Bianchi%20Fischer%2C%20Paul%20Finite-time%20analysis%20of%20the%20multiarmed%20bandit%20problem%202002"
        },
        {
            "id": "7",
            "entry": "[7] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In Proceedings of the 2014 IEEE 55th Annual Symposium on Foundations of Computer Science, FOCS \u201914, pages 464\u2013473, Washington, DC, USA, 2014. IEEE Computer Society. ISBN 978-1-4799-6517-5. doi: 10.1109/FOCS.2014.56.",
            "crossref": "https://dx.doi.org/10.1109/FOCS.2014.56",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/FOCS.2014.56"
        },
        {
            "id": "8",
            "entry": "[8] Donald A Berry and Bert Fristedt. Bandit problems: sequential allocation of experiments. London ; New York : Chapman and Hall, 1985.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berry%2C%20Donald%20A.%20Fristedt%2C%20Bert%20Bandit%20problems%3A%20sequential%20allocation%20of%20experiments%201985"
        },
        {
            "id": "9",
            "entry": "[9] Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. In Theory of Cryptography, Lecture Notes in Computer Science, pages 635\u2013658. Springer, Berlin, Heidelberg, November 2016. ISBN 978-3-662-53640-7 978-3-662-53641-4. doi: 10.1007/ 978-3-662-53641-4_24.",
            "crossref": "https://dx.doi.org/10.1007/978-3-662-53641-4_24",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/978-3-662-53641-4_24"
        },
        {
            "id": "10",
            "entry": "[10] T.-H. Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. In Automata, Languages and Programming, Lecture Notes in Computer Science, pages 405\u2013417. Springer, Berlin, Heidelberg, July 2010. ISBN 978-3-642-14161-4 978-3-642-14162-1. doi: 10.1007/978-3-642-14162-1_ 34.",
            "crossref": "https://dx.doi.org/10.1007/978-3-642-14162-1_",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/978-3-642-14162-1_"
        },
        {
            "id": "11",
            "entry": "[11] Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. Differentially private empirical risk minimization. J. Mach. Learn. Res., 12:1069\u20131109, July 2011. ISSN 1532-4435.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaudhuri%2C%20Kamalika%20Monteleoni%2C%20Claire%20Sarwate%2C%20Anand%20D.%20Differentially%20private%20empirical%20risk%20minimization%202011-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaudhuri%2C%20Kamalika%20Monteleoni%2C%20Claire%20Sarwate%2C%20Anand%20D.%20Differentially%20private%20empirical%20risk%20minimization%202011-07"
        },
        {
            "id": "12",
            "entry": "[12] Wei Chu, Lihong Li, Lev Reyzin, and Robert E. Schapire. Contextual bandits with linear payoff functions. In AISTATS, volume 15 of JMLR Proceedings, pages 208\u2013214, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chu%2C%20Wei%20Li%2C%20Lihong%20Reyzin%2C%20Lev%20Schapire%2C%20Robert%20E.%20Contextual%20bandits%20with%20linear%20payoff%20functions%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chu%2C%20Wei%20Li%2C%20Lihong%20Reyzin%2C%20Lev%20Schapire%2C%20Robert%20E.%20Contextual%20bandits%20with%20linear%20payoff%20functions%202011"
        },
        {
            "id": "13",
            "entry": "[13] Varsha Dani, Thomas Hayes, and Sham Kakade. Stochastic linear optimization under bandit feedback. In 21st Annual Conference on Learning Theory, pages 355\u2013366, January 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dani%2C%20Varsha%20Hayes%2C%20Thomas%20Kakade%2C%20Sham%20Stochastic%20linear%20optimization%20under%20bandit%20feedback%202008-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dani%2C%20Varsha%20Hayes%2C%20Thomas%20Kakade%2C%20Sham%20Stochastic%20linear%20optimization%20under%20bandit%20feedback%202008-01"
        },
        {
            "id": "14",
            "entry": "[14] C. Dwork, G. N. Rothblum, and S. Vadhan. Boosting and differential privacy. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, pages 51\u201360, October 2010. doi: 10.1109/FOCS.2010.12.",
            "crossref": "https://dx.doi.org/10.1109/FOCS.2010.12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/FOCS.2010.12"
        },
        {
            "id": "15",
            "entry": "[15] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, August 2014. ISSN 1551-305X, 1551-3068. doi: 10.1561/0400000042.",
            "crossref": "https://dx.doi.org/10.1561/0400000042",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1561/0400000042"
        },
        {
            "id": "16",
            "entry": "[16] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In Advances in Cryptology - EUROCRYPT 2006, Lecture Notes in Computer Science, pages 486\u2013503. Springer, Berlin, Heidelberg, May 2006. ISBN 978-3-540-34546-6 978-3-540-34547-3. doi: 10.1007/11761679_29.",
            "crossref": "https://dx.doi.org/10.1007/11761679_29",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/11761679_29"
        },
        {
            "id": "17",
            "entry": "[17] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography, Lecture Notes in Computer Science, pages 265\u2013 284. Springer, Berlin, Heidelberg, March 2006. ISBN 978-3-540-32731-8 978-3-540-32732-5. doi: 10.1007/11681878_14.",
            "crossref": "https://dx.doi.org/10.1007/11681878_14",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/11681878_14"
        },
        {
            "id": "18",
            "entry": "[18] Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. In Proceedings of the Forty-Second ACM Symposium on Theory of Computing, STOC \u201910, pages 715\u2013724, New York, NY, USA, 2010. ACM. ISBN 978-1-4503-0050-6. doi: 10.1145/1806689.1806787.",
            "crossref": "https://dx.doi.org/10.1145/1806689.1806787",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1806689.1806787"
        },
        {
            "id": "19",
            "entry": "[19] Cynthia Dwork, Kunal Talwar, Abhradeep Thakurta, and Li Zhang. Analyze Gauss: Optimal bounds for privacy-preserving principal component analysis. In Proceedings of the Forty-Sixth Annual ACM Symposium on Theory of Computing, STOC \u201914, pages 11\u201320, New York, NY, USA, 2014. ACM. ISBN 978-1-4503-2710-7. doi: 10.1145/2591796.2591883.",
            "crossref": "https://dx.doi.org/10.1145/2591796.2591883",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/2591796.2591883"
        },
        {
            "id": "20",
            "entry": "[20] Moritz Hardt and Kunal Talwar. On the geometry of differential privacy. In Proceedings of the Forty-Second ACM Symposium on Theory of Computing, STOC \u201910, pages 705\u2013714, New York, NY, USA, 2010. ACM. ISBN 978-1-4503-0050-6. doi: 10.1145/1806689.1806786.",
            "crossref": "https://dx.doi.org/10.1145/1806689.1806786",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1806689.1806786"
        },
        {
            "id": "21",
            "entry": "[21] Prateek Jain, Pravesh Kothari, and Abhradeep Thakurta. Differentially private online learning. In Conference on Learning Theory, pages 24.1\u201324.34, June 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jain%2C%20Prateek%20Kothari%2C%20Pravesh%20Thakurta%2C%20Abhradeep%20Differentially%20private%20online%20learning%202012-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jain%2C%20Prateek%20Kothari%2C%20Pravesh%20Thakurta%2C%20Abhradeep%20Differentially%20private%20online%20learning%202012-06"
        },
        {
            "id": "22",
            "entry": "[22] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. arXiv:1711.03908 [cs, math, stat], November 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.03908"
        },
        {
            "id": "23",
            "entry": "[23] Michael Kearns, Mallesh Pai, Aaron Roth, and Jonathan Ullman. Mechanism design in large games: Incentives and privacy. pages 403\u2013410. ACM Press, 2014. ISBN 978-1-4503-2698-8. doi: 10.1145/ 2554797.2554834.",
            "crossref": "https://dx.doi.org/10.1145/2554797.2554834"
        },
        {
            "id": "24",
            "entry": "[24] Tor Lattimore and Csaba Szepesv\u00e1ri. The end of optimism? an asymptotic analysis of finite-armed linear bandits. In AISTATS, pages 728\u2013737, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lattimore%2C%20Tor%20Szepesv%C3%A1ri%2C%20Csaba%20The%20end%20of%20optimism%3F%20an%20asymptotic%20analysis%20of%20finite-armed%20linear%20bandits%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lattimore%2C%20Tor%20Szepesv%C3%A1ri%2C%20Csaba%20The%20end%20of%20optimism%3F%20an%20asymptotic%20analysis%20of%20finite-armed%20linear%20bandits%202017"
        },
        {
            "id": "25",
            "entry": "[25] B. Laurent and P. Massart. Adaptive estimation of a quadratic functional by model selection. The Annals of Statistics, 28(5):1302\u20131338, October 2000. ISSN 0090-5364, 2168-8966. doi: 10.1214/aos/1015957395.",
            "crossref": "https://dx.doi.org/10.1214/aos/1015957395",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1214/aos/1015957395"
        },
        {
            "id": "26",
            "entry": "[26] Nikita Mishra and Abhradeep Thakurta. (Nearly) optimal differentially private stochastic multi-arm bandits. In Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence, UAI\u201915, pages 592\u2013601, Arlington, Virginia, United States, 2015. AUAI Press. ISBN 978-0-9966431-0-8.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mishra%2C%20Nikita%20Thakurta%2C%20Abhradeep%20%28Nearly%29%20optimal%20differentially%20private%20stochastic%20multi-arm%20bandits",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mishra%2C%20Nikita%20Thakurta%2C%20Abhradeep%20%28Nearly%29%20optimal%20differentially%20private%20stochastic%20multi-arm%20bandits"
        },
        {
            "id": "27",
            "entry": "[27] Seth Neel and Aaron Roth. Mitigating bias in adaptive data gathering via differential privacy. In ICML, pages 3717\u20133726, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neel%2C%20Seth%20Roth%2C%20Aaron%20Mitigating%20bias%20in%20adaptive%20data%20gathering%20via%20differential%20privacy%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neel%2C%20Seth%20Roth%2C%20Aaron%20Mitigating%20bias%20in%20adaptive%20data%20gathering%20via%20differential%20privacy%202018"
        },
        {
            "id": "28",
            "entry": "[28] Herbert Robbins. Some aspects of the sequential design of experiments. Bull. Amer. Math. Soc., 58(5): 527\u2013535, 09 1952.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robbins%2C%20Herbert%20Some%20aspects%20of%20the%20sequential%20design%20of%20experiments",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Robbins%2C%20Herbert%20Some%20aspects%20of%20the%20sequential%20design%20of%20experiments"
        },
        {
            "id": "29",
            "entry": "[29] Paat Rusmevichientong and John N. Tsitsiklis. Linearly parameterized bandits. Mathematics of Operations Research, 35(2):395\u2013411, April 2010. ISSN 0364-765X. doi: 10.1287/moor.1100.0446.",
            "crossref": "https://dx.doi.org/10.1287/moor.1100.0446",
            "arxiv_url": "https://arxiv.org/pdf/1100.0446"
        },
        {
            "id": "30",
            "entry": "[30] Or Sheffet. Private approximations of the 2nd-moment matrix using existing techniques in linear regression. arXiv:1507.00056 [cs], June 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.00056"
        },
        {
            "id": "31",
            "entry": "[31] Adam Smith and Abhradeep Thakurta. (Nearly) optimal algorithms for private online learning in fullinformation and bandit settings. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 2733\u20132741. Curran Associates, Inc., 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Smith%2C%20Adam%20Thakurta%2C%20Abhradeep%20%28Nearly%29%20optimal%20algorithms%20for%20private%20online%20learning%20in%20fullinformation%20and%20bandit%20settings%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Smith%2C%20Adam%20Thakurta%2C%20Abhradeep%20%28Nearly%29%20optimal%20algorithms%20for%20private%20online%20learning%20in%20fullinformation%20and%20bandit%20settings%202013"
        },
        {
            "id": "32",
            "entry": "[32] Terence Tao. Topics in Random Matrix Theory, volume 132. American Mathematical Society Providence, RI, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tao%2C%20Terence%20Topics%20in%20Random%20Matrix%20Theory%2C%20volume%20132%202012"
        },
        {
            "id": "33",
            "entry": "[33] Aristide C. Y. Tossou and Christos Dimitrakakis. Algorithms for differentially private multi-armed bandits. In Thirtieth AAAI Conference on Artificial Intelligence, March 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tossou%2C%20Aristide%20C.Y.%20Dimitrakakis%2C%20Christos%20Algorithms%20for%20differentially%20private%20multi-armed%20bandits%202016-03",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tossou%2C%20Aristide%20C.Y.%20Dimitrakakis%2C%20Christos%20Algorithms%20for%20differentially%20private%20multi-armed%20bandits%202016-03"
        },
        {
            "id": "34",
            "entry": "[34] Aristide C. Y. Tossou and Christos Dimitrakakis. Achieving privacy in the adversarial multi-armed bandit. arXiv:1701.04222 [cs], January 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.04222"
        },
        {
            "id": "35",
            "entry": "[35] Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv:1011.3027 [cs, math], November 2010.",
            "arxiv_url": "https://arxiv.org/pdf/1011.3027"
        },
        {
            "id": "36",
            "entry": "[36] Fuzhen Zhang. Matrix Theory: Basic Results and Techniques. Universitext. Springer, New York, 2nd edition, 2011. ISBN 978-1-4614-1098-0. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Fuzhen%20Matrix%20Theory%3A%20Basic%20Results%20and%20Techniques%202011"
        }
    ]
}
