{
    "filename": "7363-connectionist-temporal-classification-with-maximum-entropy-regularization.pdf",
    "metadata": {
        "title": "Connectionist Temporal Classification with Maximum Entropy Regularization",
        "author": "Hu Liu, Sheng Jin, Changshui Zhang",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7363-connectionist-temporal-classification-with-maximum-entropy-regularization.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Connectionist Temporal Classification (CTC) is an objective function for end-toend sequence learning, which adopts dynamic programming algorithms to directly learn the mapping between sequences. CTC has shown promising results in many sequence learning applications including speech recognition and scene text recognition. However, CTC tends to produce highly peaky and overconfident distributions, which is a symptom of overfitting. To remedy this, we propose a regularization method based on maximum conditional entropy which penalizes peaky distributions and encourages exploration. We also introduce an entropybased pruning method to dramatically reduce the number of CTC feasible paths by ruling out unreasonable alignments. Experiments on scene text recognition show that our proposed methods consistently improve over the CTC baseline without the need to adjust training settings. Code has been made publicly available at: https://github.com/liuhu-bigeye/enctc.crnn."
    },
    "keywords": [
        {
            "term": "language recognition",
            "url": "https://en.wikipedia.org/wiki/language_recognition"
        },
        {
            "term": "Multiple Instance Learning",
            "url": "https://en.wikipedia.org/wiki/Multiple_Instance_Learning"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "maximum likelihood estimation",
            "url": "https://en.wikipedia.org/wiki/maximum_likelihood_estimation"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "sequence learning",
            "url": "https://en.wikipedia.org/wiki/sequence_learning"
        },
        {
            "term": "text recognition",
            "url": "https://en.wikipedia.org/wiki/text_recognition"
        },
        {
            "term": "connectionist temporal classification",
            "url": "https://en.wikipedia.org/wiki/connectionist_temporal_classification"
        },
        {
            "term": "maximum entropy",
            "url": "https://en.wikipedia.org/wiki/maximum_entropy"
        }
    ],
    "highlights": [
        "Past few years have witnessed significant progress in sequence learning tasks",
        "As blanks are included in most of the feasible paths, dominant paths are often overwhelmed by blanks, interspersed by sharp spikes of non-blank labels, which is known as the Connectionist Temporal Classification peaky distribution problem [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>]",
        "In order to facilitate training and be more likely to find the feasible paths, we propose a regularization method based on maximum conditional entropy (EnCTC)",
        "We see that Equal Spacing CTC deformation and EnEsCTC produce more concentrated error signal, that is, the algorithms consider that the element at the head of the label sequence cannot appear at the rear of the input sequence, reducing the size of feasible path set",
        "The x-axis is the length of the input sequence, while the y-axis is the ratio of feasible path numbers of Equal Spacing CTC deformation to that of Connectionist Temporal Classification",
        "We have presented a novel maximum entropy based regularization for Connectionist Temporal Classification (EnCTC), which maintains reasonable possibilities among all the feasible paths, to enhance generalization and exploration"
    ],
    "key_statements": [
        "Past few years have witnessed significant progress in sequence learning tasks",
        "Connectionist Temporal Classification views the outputs of recurrent neural network as a probability distribution over all possible alignments and directly learns the mapping from input sequences to target sequences",
        "Connectionist Temporal Classification can be regarded as a kind of Multiple Instance Learning (MIL) [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]",
        "Once Connectionist Temporal Classification finds a dominant feasible path during the training process, the error signal will concentrate on the vicinity of this path, and the prediction of this feasible path will continuously strengthen until this path completely dominates the prediction output",
        "As blanks are included in most of the feasible paths, dominant paths are often overwhelmed by blanks, interspersed by sharp spikes of non-blank labels, which is known as the Connectionist Temporal Classification peaky distribution problem [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>, <a class=\"ref-link\" id=\"c22\" href=\"#r22\">22</a>]",
        "Motivated by the maximum entropy principle [<a class=\"ref-link\" id=\"c13\" href=\"#r13\">13</a>], we propose a maximum conditional entropy based regularization for Connectionist Temporal Classification (EnCTC)",
        "We propose an algorithm to limit the size of the Connectionist Temporal Classification feasible set by eliminating these unreasonable paths that seriously violate the equal spacing prior (EsCTC)",
        "(3) We provide polynomial-time dynamic programming algorithms for calculating entropy based regularization for CTC, Equal Spacing CTC deformation and their combination (EnEsCTC). (4) We validate the proposed methods on scene text recognition tasks and show that these methods are able to improve the baseline model without changing training settings.\n2 Related Work",
        "In order to facilitate training and be more likely to find the feasible paths, we propose a regularization method based on maximum conditional entropy (EnCTC)",
        "We see that Equal Spacing CTC deformation and EnEsCTC produce more concentrated error signal, that is, the algorithms consider that the element at the head of the label sequence cannot appear at the rear of the input sequence, reducing the size of feasible path set",
        "entropy based regularization for CTC strengthened the exploration during Connectionist Temporal Classification training process, producing a better and more reasonable alignment where each label occupies a certain range along the horizontal axis",
        "Equal Spacing CTC deformation eliminates unreasonable Connectionist Temporal Classification feasible paths based on the equal spacing prior, which results in a more accurate alignment",
        "The x-axis is the length of the input sequence, while the y-axis is the ratio of feasible path numbers of Equal Spacing CTC deformation to that of Connectionist Temporal Classification",
        "entropy based regularization for CTC instead regularizes the entropy of feasible paths, which is more reasonable for Connectionist Temporal Classification",
        "We have presented a novel maximum entropy based regularization for Connectionist Temporal Classification (EnCTC), which maintains reasonable possibilities among all the feasible paths, to enhance generalization and exploration"
    ],
    "summary": [
        "Past few years have witnessed significant progress in sequence learning tasks.",
        "We propose an algorithm to limit the size of the CTC feasible set by eliminating these unreasonable paths that seriously violate the equal spacing prior (EsCTC).",
        "The main contributions of this paper can be summarized as: (1) We propose a maximum conditional entropy regularization for CTC (EnCTC), which encourages exploration for CTC training and prevents peaky output distributions.",
        "(2) We derive from equal spacing prior a pruning algorithm (EsCTC) to effectively limit the size of CTC feasible set and give theoretical explanations from the perspective of maximum entropy.",
        "We instead regularize the entropy among the feasible paths of CTC to handle peaky distribution problem.",
        "In order to facilitate training and be more likely to find the feasible paths, we propose a regularization method based on maximum conditional entropy (EnCTC).",
        "The Equal Spacing CTC deformation (EsCTC) guides the end-to-end model training by optimizing the loss function: Lesctc = \u2212 log p\u03c4 (l|X)",
        "We combined the Equal Spacing CTC deformation with maximum conditional entropy regularization defined in section 3.3.",
        "We see that EsCTC and EnEsCTC produce more concentrated error signal, that is, the algorithms consider that the element at the head of the label sequence cannot appear at the rear of the input sequence, reducing the size of feasible path set.",
        "EnCTC strengthened the exploration during CTC training process, producing a better and more reasonable alignment where each label occupies a certain range along the horizontal axis.",
        "EsCTC eliminates unreasonable CTC feasible paths based on the equal spacing prior, which results in a more accurate alignment.",
        "The x-axis is the length of the input sequence, while the y-axis is the ratio of feasible path numbers of EsCTC to that of CTC.",
        "LS and CP directly regularize the model prediction at each time-step and improve the generalization of the CTC baseline.",
        "EnCTC instead regularizes the entropy of feasible paths, which is more reasonable for CTC.",
        "We have presented a novel maximum entropy based regularization for CTC (EnCTC), which maintains reasonable possibilities among all the feasible paths, to enhance generalization and exploration.",
        "We derive from equal spacing prior a pruning algorithm (EsCTC) to effectively reduce the space of the feasible set and give theoretical explanations from the perspective of maximum entropy.",
        "The experiments on scene text recognition benchmarks demonstrate that our proposed methods achieve superior performance than the baseline and show better generalization ability.",
        "We believe that the proposed regularization is general, which can be used to consistently improve the performance of the original CTC model"
    ],
    "headline": "We propose a regularization method based on maximum conditional entropy which penalizes peaky distributions and encourages exploration",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen, et al. Deep speech 2: End-to-end speech recognition in english and mandarin. In International Conference on Machine Learning (ICML), pages 173\u2013182, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amodei%2C%20Dario%20Ananthanarayanan%2C%20Sundaram%20Anubhai%2C%20Rishita%20Bai%2C%20Jingliang%20Deep%20speech%202%3A%20End-to-end%20speech%20recognition%20in%20english%20and%20mandarin%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Amodei%2C%20Dario%20Ananthanarayanan%2C%20Sundaram%20Anubhai%2C%20Rishita%20Bai%2C%20Jingliang%20Deep%20speech%202%3A%20End-to-end%20speech%20recognition%20in%20english%20and%20mandarin%202016"
        },
        {
            "id": "2",
            "entry": "[2] Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur, Yi Li, Hairong Liu, Sanjeev Satheesh, David Seetapun, Anuroop Sriram, et al. Exploring neural transducers for end-to-end speech recognition. Automatic Speech Recognition and Understanding Workshop (ASRU), pages 206\u2013213, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Battenberg%2C%20Eric%20Chen%2C%20Jitong%20Child%2C%20Rewon%20Coates%2C%20Adam%20Exploring%20neural%20transducers%20for%20end-to-end%20speech%20recognition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Battenberg%2C%20Eric%20Chen%2C%20Jitong%20Child%2C%20Rewon%20Coates%2C%20Adam%20Exploring%20neural%20transducers%20for%20end-to-end%20speech%20recognition%202017"
        },
        {
            "id": "3",
            "entry": "[3] Jan Chorowski and Navdeep Jaitly. Towards better decoding and language model integration in sequence to sequence models. arXiv preprint arXiv:1612.02695, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.02695"
        },
        {
            "id": "4",
            "entry": "[4] Runpeng Cui, Hu Liu, and Changshui Zhang. Recurrent convolutional neural networks for continuous sign language recognition by staged optimization. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1610\u20131618, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cui%2C%20Runpeng%20Liu%2C%20Hu%20Zhang%2C%20Changshui%20Recurrent%20convolutional%20neural%20networks%20for%20continuous%20sign%20language%20recognition%20by%20staged%20optimization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cui%2C%20Runpeng%20Liu%2C%20Hu%20Zhang%2C%20Changshui%20Recurrent%20convolutional%20neural%20networks%20for%20continuous%20sign%20language%20recognition%20by%20staged%20optimization%202017"
        },
        {
            "id": "5",
            "entry": "[5] Alex Graves and Faustino Gomez. Connectionist temporal classification:labelling unsegmented sequence data with recurrent neural networks. In International Conference on Machine Learning (ICML), pages 369\u2013376, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Gomez%2C%20Faustino%20Connectionist%20temporal%20classification%3Alabelling%20unsegmented%20sequence%20data%20with%20recurrent%20neural%20networks%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Gomez%2C%20Faustino%20Connectionist%20temporal%20classification%3Alabelling%20unsegmented%20sequence%20data%20with%20recurrent%20neural%20networks%202006"
        },
        {
            "id": "6",
            "entry": "[6] Alex Graves and Navdeep Jaitly. Towards end-to-end speech recognition with recurrent neural networks. In International Conference on Machine Learning (ICML), pages 1764\u20131772, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Jaitly%2C%20Navdeep%20Towards%20end-to-end%20speech%20recognition%20with%20recurrent%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Jaitly%2C%20Navdeep%20Towards%20end-to-end%20speech%20recognition%20with%20recurrent%20neural%20networks%202014"
        },
        {
            "id": "7",
            "entry": "[7] Alex Graves, Marcus Liwicki, Santiago Fern\u00e1ndez, Roman Bertolami, Horst Bunke, and J\u00fcrgen Schmidhuber. A novel connectionist system for unconstrained handwriting recognition. Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 31(5):855\u2013868, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A%20novel%20connectionist%20system%20for%20unconstrained%20handwriting%20recognition%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A%20novel%20connectionist%20system%20for%20unconstrained%20handwriting%20recognition%202009"
        },
        {
            "id": "8",
            "entry": "[8] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, et al. Deep speech: Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.5567"
        },
        {
            "id": "9",
            "entry": "[9] Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012.",
            "arxiv_url": "https://arxiv.org/pdf/1207.0580"
        },
        {
            "id": "10",
            "entry": "[10] De An Huang, Fei Fei Li, and Juan Carlos Niebles. Connectionist temporal modeling for weakly supervised action labeling. In European Conference on Computer Vision (ECCV), pages 137\u2013153, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20De%20An%20Li%2C%20Fei%20Fei%20Niebles%2C%20Juan%20Carlos%20Connectionist%20temporal%20modeling%20for%20weakly%20supervised%20action%20labeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20De%20An%20Li%2C%20Fei%20Fei%20Niebles%2C%20Juan%20Carlos%20Connectionist%20temporal%20modeling%20for%20weakly%20supervised%20action%20labeling%202016"
        },
        {
            "id": "11",
            "entry": "[11] Max Jaderberg, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Synthetic data and artificial neural networks for natural scene text recognition. arXiv preprint arXiv:1406.2227, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1406.2227"
        },
        {
            "id": "12",
            "entry": "[12] Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al. Spatial transformer networks. In Advances in Neural Information Processing Systems (NIPS), pages 2017\u20132025, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202017"
        },
        {
            "id": "13",
            "entry": "[13] Edwin T Jaynes. Information theory and statistical mechanics. Physical Review, 106(4):620, 1957.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaynes%2C%20Edwin%20T.%20Information%20theory%20and%20statistical%20mechanics%201957",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaynes%2C%20Edwin%20T.%20Information%20theory%20and%20statistical%20mechanics%201957"
        },
        {
            "id": "14",
            "entry": "[14] Dimosthenis Karatzas, Faisal Shafait, Seiichi Uchida, Masakazu Iwamura, Lluis Gomez i Bigorda, Sergi Robles Mestre, Joan Mas, David Fernandez Mota, Jon Almazan Almazan, and Lluis Pere De Las Heras. Icdar 2013 robust reading competition. In International Conference on Document Analysis and Recognition (ICDAR), pages 1484\u20131493, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karatzas%2C%20Dimosthenis%20Shafait%2C%20Faisal%20Uchida%2C%20Seiichi%20Iwamura%2C%20Masakazu%20robust%20reading%20competition%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karatzas%2C%20Dimosthenis%20Shafait%2C%20Faisal%20Uchida%2C%20Seiichi%20Iwamura%2C%20Masakazu%20robust%20reading%20competition%202013"
        },
        {
            "id": "15",
            "entry": "[15] Suyoun Kim, Michael L Seltzer, Jinyu Li, and Rui Zhao. Improved training for online end-to-end speech recognition systems. arXiv preprint arXiv:1711.02212, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.02212"
        },
        {
            "id": "16",
            "entry": "[16] Anders Krogh and John A Hertz. A simple weight decay can improve generalization. In Advances in Neural Information Processing Systems (NIPS), pages 950\u2013957, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krogh%2C%20Anders%20Hertz%2C%20John%20A.%20A%20simple%20weight%20decay%20can%20improve%20generalization%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krogh%2C%20Anders%20Hertz%2C%20John%20A.%20A%20simple%20weight%20decay%20can%20improve%20generalization%201992"
        },
        {
            "id": "17",
            "entry": "[17] Chen-Yu Lee and Simon Osindero. Recursive recurrent nets with attention modeling for ocr in the wild. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2231\u20132239, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Chen-Yu%20Osindero%2C%20Simon%20Recursive%20recurrent%20nets%20with%20attention%20modeling%20for%20ocr%20in%20the%20wild%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Chen-Yu%20Osindero%2C%20Simon%20Recursive%20recurrent%20nets%20with%20attention%20modeling%20for%20ocr%20in%20the%20wild%202016"
        },
        {
            "id": "18",
            "entry": "[18] Mengxi Lin, Nakamasa Inoue, and Koichi Shinoda. Ctc network with statistical language modeling for action sequence recognition in videos. In Thematic Workshops of ACM Multimedia, pages 393\u2013401, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lin%2C%20Mengxi%20Inoue%2C%20Nakamasa%20Shinoda%2C%20Koichi%20Ctc%20network%20with%20statistical%20language%20modeling%20for%20action%20sequence%20recognition%20in%20videos%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lin%2C%20Mengxi%20Inoue%2C%20Nakamasa%20Shinoda%2C%20Koichi%20Ctc%20network%20with%20statistical%20language%20modeling%20for%20action%20sequence%20recognition%20in%20videos%202017"
        },
        {
            "id": "19",
            "entry": "[19] Wei Liu, Chaofeng Chen, Kwan Yeek. Wong, Zhizhong Su, and Junyu Han. Star-net: A spatial attention residue network for scene text recognition. In British Machine Vision Conference (BMVC), pages 43.1\u201343.13, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Wei%20Chen%2C%20Chaofeng%20Wong%2C%20Kwan%20Yeek%20Su%2C%20Zhizhong%20Star-net%3A%20A%20spatial%20attention%20residue%20network%20for%20scene%20text%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Wei%20Chen%2C%20Chaofeng%20Wong%2C%20Kwan%20Yeek%20Su%2C%20Zhizhong%20Star-net%3A%20A%20spatial%20attention%20residue%20network%20for%20scene%20text%20recognition%202016"
        },
        {
            "id": "20",
            "entry": "[20] Simon M Lucas, Alex Panaretos, Luis Sosa, Anthony Tang, Shirley Wong, Robert Young, Kazuki Ashida, Hiroki Nagai, Masayuki Okamoto, Hiroaki Yamamoto, et al. Icdar 2003 robust reading competitions: entries, results, and future directions. International Journal of Document Analysis and Recognition (IJDAR), 7(2-3):105\u2013122, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lucas%2C%20Simon%20M.%20Panaretos%2C%20Alex%20Sosa%2C%20Luis%20Tang%2C%20Anthony%20robust%20reading%20competitions%3A%20entries%2C%20results%2C%20and%20future%20directions%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lucas%2C%20Simon%20M.%20Panaretos%2C%20Alex%20Sosa%2C%20Luis%20Tang%2C%20Anthony%20robust%20reading%20competitions%3A%20entries%2C%20results%2C%20and%20future%20directions%202003"
        },
        {
            "id": "21",
            "entry": "[21] Oded Maron and Tom\u00e1s Lozano-P\u00e9rez. A framework for multiple-instance learning. In Advances in Neural Information Processing Systems (NIPS), pages 570\u2013576, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maron%2C%20Oded%20Lozano-P%C3%A9rez%2C%20Tom%C3%A1s%20A%20framework%20for%20multiple-instance%20learning%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maron%2C%20Oded%20Lozano-P%C3%A9rez%2C%20Tom%C3%A1s%20A%20framework%20for%20multiple-instance%20learning%201998"
        },
        {
            "id": "22",
            "entry": "[22] Yajie Miao, Mohammad Gowayyed, and Florian Metze. Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding. In IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 167\u2013174, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miao%2C%20Yajie%20Gowayyed%2C%20Mohammad%20Metze%2C%20Florian%20Eesen%3A%20End-to-end%20speech%20recognition%20using%20deep%20rnn%20models%20and%20wfst-based%20decoding%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miao%2C%20Yajie%20Gowayyed%2C%20Mohammad%20Metze%2C%20Florian%20Eesen%3A%20End-to-end%20speech%20recognition%20using%20deep%20rnn%20models%20and%20wfst-based%20decoding%202015"
        },
        {
            "id": "23",
            "entry": "[23] David Miller, Ajit V Rao, Kenneth Rose, and Allen Gersho. A global optimization technique for statistical classifier design. IEEE Transactions on Signal Processing, 44(12):3108\u20133122, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miller%2C%20David%20Rao%2C%20Ajit%20V.%20Rose%2C%20Kenneth%20Gersho%2C%20Allen%20A%20global%20optimization%20technique%20for%20statistical%20classifier%20design%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miller%2C%20David%20Rao%2C%20Ajit%20V.%20Rose%2C%20Kenneth%20Gersho%2C%20Allen%20A%20global%20optimization%20technique%20for%20statistical%20classifier%20design%201996"
        },
        {
            "id": "24",
            "entry": "[24] Anand Mishra, Karteek Alahari, and C.V. Jawahar. Scene text recognition using higher order language priors. In British Machine Vision Conference (BMVC), 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mishra%2C%20Anand%20Alahari%2C%20Karteek%20Jawahar%2C%20C.V.%20Scene%20text%20recognition%20using%20higher%20order%20language%20priors%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mishra%2C%20Anand%20Alahari%2C%20Karteek%20Jawahar%2C%20C.V.%20Scene%20text%20recognition%20using%20higher%20order%20language%20priors%202012"
        },
        {
            "id": "25",
            "entry": "[25] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning (ICML), pages 1928\u20131937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "26",
            "entry": "[26] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20Adam%20Gross%2C%20Sam%20Chintala%2C%20Soumith%20Chanan%2C%20Gregory%20Automatic%20differentiation%20in%20pytorch%202017"
        },
        {
            "id": "27",
            "entry": "[27] Gabriel Pereyra, George Tucker, Jan Chorowski, \u0141ukasz Kaiser, and Geoffrey Hinton. Regularizing neural networks by penalizing confident output distributions. arXiv preprint arXiv:1701.06548, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1701.06548"
        },
        {
            "id": "28",
            "entry": "[28] Hasim Sak, F\u00e9lix de Chaumont Quitry, Tara Sainath, Kanishka Rao, et al. Acoustic modelling with cd-ctc-smbr lstm rnns. In IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 604\u2013609, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sak%2C%20Hasim%20de%20Chaumont%20Quitry%2C%20F%C3%A9lix%20Sainath%2C%20Tara%20Rao%2C%20Kanishka%20Acoustic%20modelling%20with%20cd-ctc-smbr%20lstm%20rnns%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sak%2C%20Hasim%20de%20Chaumont%20Quitry%2C%20F%C3%A9lix%20Sainath%2C%20Tara%20Rao%2C%20Kanishka%20Acoustic%20modelling%20with%20cd-ctc-smbr%20lstm%20rnns%202015"
        },
        {
            "id": "29",
            "entry": "[29] B. Shi, X. Bai, and C. Yao. An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition. Transactions on Pattern Analysis Machine Intelligence (TPAMI), 39(11):2298\u20132304, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shi%2C%20B.%20Bai%2C%20X.%20Yao%2C%20C.%20An%20end-to-end%20trainable%20neural%20network%20for%20image-based%20sequence%20recognition%20and%20its%20application%20to%20scene%20text%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shi%2C%20B.%20Bai%2C%20X.%20Yao%2C%20C.%20An%20end-to-end%20trainable%20neural%20network%20for%20image-based%20sequence%20recognition%20and%20its%20application%20to%20scene%20text%20recognition%202016"
        },
        {
            "id": "30",
            "entry": "[30] Baoguang Shi, Xinggang Wang, Pengyuan Lyu, Cong Yao, and Xiang Bai. Robust scene text recognition with automatic rectification. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 4168\u20134176, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shi%2C%20Baoguang%20Wang%2C%20Xinggang%20Lyu%2C%20Pengyuan%20Yao%2C%20Cong%20Robust%20scene%20text%20recognition%20with%20automatic%20rectification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shi%2C%20Baoguang%20Wang%2C%20Xinggang%20Lyu%2C%20Pengyuan%20Yao%2C%20Cong%20Robust%20scene%20text%20recognition%20with%20automatic%20rectification%202016"
        },
        {
            "id": "31",
            "entry": "[31] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2818\u20132826, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Vanhoucke%2C%20Vincent%20Ioffe%2C%20Sergey%20Shlens%2C%20Jon%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Vanhoucke%2C%20Vincent%20Ioffe%2C%20Sergey%20Shlens%2C%20Jon%20Rethinking%20the%20inception%20architecture%20for%20computer%20vision%202016"
        },
        {
            "id": "32",
            "entry": "[32] Ehsan Variani, Tom Bagby, Kamel Lahouel, Erik McDermott, and Michiel Bacchiani. Sampled connectionist temporal classification. In International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4959\u20134963, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Variani%2C%20Ehsan%20Bagby%2C%20Tom%20Lahouel%2C%20Kamel%20McDermott%2C%20Erik%20Sampled%20connectionist%20temporal%20classification%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Variani%2C%20Ehsan%20Bagby%2C%20Tom%20Lahouel%2C%20Kamel%20McDermott%2C%20Erik%20Sampled%20connectionist%20temporal%20classification%202018"
        },
        {
            "id": "33",
            "entry": "[33] Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus. Regularization of neural networks using dropconnect. In International Conference on Machine Learning (ICML), pages 1058\u20131066, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wan%2C%20Li%20Zeiler%2C%20Matthew%20Zhang%2C%20Sixin%20Cun%2C%20Yann%20Le%20Regularization%20of%20neural%20networks%20using%20dropconnect%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wan%2C%20Li%20Zeiler%2C%20Matthew%20Zhang%2C%20Sixin%20Cun%2C%20Yann%20Le%20Regularization%20of%20neural%20networks%20using%20dropconnect%202013"
        },
        {
            "id": "34",
            "entry": "[34] Kai Wang, Boris Babenko, and Serge Belongie. End-to-end scene text recognition. In International Conference on Computer Vision (ICCV), pages 1457\u20131464, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Kai%20Babenko%2C%20Boris%20Belongie%2C%20Serge%20End-to-end%20scene%20text%20recognition%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Kai%20Babenko%2C%20Boris%20Belongie%2C%20Serge%20End-to-end%20scene%20text%20recognition%202011"
        },
        {
            "id": "35",
            "entry": "[35] Tao Wang, David J Wu, Adam Coates, and Andrew Y Ng. End-to-end text recognition with convolutional neural networks. In International Conference on Pattern Recognition (ICPR), pages 3304\u20133308, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Tao%20Wu%2C%20David%20J.%20Coates%2C%20Adam%20and%20Andrew%20Y%20Ng.%20End-to-end%20text%20recognition%20with%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Tao%20Wu%2C%20David%20J.%20Coates%2C%20Adam%20and%20Andrew%20Y%20Ng.%20End-to-end%20text%20recognition%20with%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "36",
            "entry": "[36] Ronald J Williams and Jing Peng. Function optimization using connectionist reinforcement learning algorithms. Connection Science, 3(3):241\u2013268, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20Ronald%20J.%20Peng%2C%20Jing%20Function%20optimization%20using%20connectionist%20reinforcement%20learning%20algorithms%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20Ronald%20J.%20Peng%2C%20Jing%20Function%20optimization%20using%20connectionist%20reinforcement%20learning%20algorithms%201991"
        },
        {
            "id": "37",
            "entry": "[37] Matthew D Zeiler and Rob Fergus. Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557, 2013. ",
            "arxiv_url": "https://arxiv.org/pdf/1301.3557"
        }
    ]
}
