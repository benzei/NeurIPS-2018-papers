{
    "filename": "7876-the-limits-of-post-selection-generalization.pdf",
    "metadata": {
        "title": "The Limits of Post-Selection Generalization",
        "author": "Jonathan Ullman, Adam Smith, Kobbi Nissim, Uri Stemmer, Thomas Steinke",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7876-the-limits-of-post-selection-generalization.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "While statistics and machine learning offers numerous methods for ensuring generalization, these methods often fail in the presence of post selection\u2014the common practice in which the choice of analysis depends on previous interactions with the same dataset. A recent line of work has introduced powerful, general purpose algorithms that ensure a property called post hoc generalization (Cummings et al., COLT\u201916), which says that no person when given the output of the algorithm should be able to find any statistic for which the data differs significantly from the population it came from."
    },
    "keywords": [
        {
            "term": "common practice",
            "url": "https://en.wikipedia.org/wiki/common_practice"
        },
        {
            "term": "model selection",
            "url": "https://en.wikipedia.org/wiki/model_selection"
        },
        {
            "term": "differential privacy",
            "url": "https://en.wikipedia.org/wiki/differential_privacy"
        }
    ],
    "highlights": [
        "Consider a dataset X consisting of n independent samples from some unknown population P",
        "We show a tight lower bound on the error of any algorithm that satisfies post hoc generalization and answers adaptively chosen statistical queries, showing a strong barrier to progress in post selection data analysis",
        "How can we ensure that the conclusions drawn from X generalize to the population P? Despite decades of research in statistics and machine learning on methods for ensuring generalization, there is an increased recognition that many scientific findings do not generalize, with some even declaring this to be a \u201cstatistical crisis in science\u201d [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>]",
        "While there are many reasons a conclusion might fail to generalize, one that is receiving increasing attention is post-selection, in which the choice of method for analyzing the dataset depends on previous interactions with the same dataset",
        "Post-selection can arise from many common practices, such as variable selection, exploratory data analysis, and dataset re-use"
    ],
    "key_statements": [
        "Consider a dataset X consisting of n independent samples from some unknown population P",
        "We show a tight lower bound on the error of any algorithm that satisfies post hoc generalization and answers adaptively chosen statistical queries, showing a strong barrier to progress in post selection data analysis",
        "How can we ensure that the conclusions drawn from X generalize to the population P? Despite decades of research in statistics and machine learning on methods for ensuring generalization, there is an increased recognition that many scientific findings do not generalize, with some even declaring this to be a \u201cstatistical crisis in science\u201d [<a class=\"ref-link\" id=\"c14\" href=\"#r14\">14</a>]",
        "While there are many reasons a conclusion might fail to generalize, one that is receiving increasing attention is post-selection, in which the choice of method for analyzing the dataset depends on previous interactions with the same dataset",
        "Post-selection can arise from many common practices, such as variable selection, exploratory data analysis, and dataset re-use"
    ],
    "summary": [
        "Consider a dataset X consisting of n independent samples from some unknown population P.",
        "We show a tight lower bound on the error of any algorithm that satisfies post hoc generalization and answers adaptively chosen statistical queries, showing a strong barrier to progress in post selection data analysis.",
        "An algorithm M satisfies post hoc generalization if there is no way, given only the output of M(X), to identify any statistical query [<a class=\"ref-link\" id=\"c17\" href=\"#r17\">17</a>] such that the value of that query on the dataset is significantly different from its answer on the whole population.",
        "An algorithm M : X n \u2192 Y satisfies (\u03b5, \u03b4)-post hoc generalization if for every distribution P over X and every algorithm A that outputs a bounded function q : X \u2192 [\u22121, 1], if X \u223c P\u2297n, y \u223c M(X), and q \u223c A(y), P [|q(P) \u2212 q(X)| > \u03b5] \u2264",
        "Our first contribution is strong new lower bounds on any algorithm that satisfies post hoc generalization and answers a sequence of adaptively chosen statistical queries\u2014the setting introduced in Dwork et al [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>] and further studied in [<a class=\"ref-link\" id=\"c1\" href=\"#r1\">1</a>, <a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>, <a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>].",
        "If M takes a sample of size n, satisfies (\u03b5, \u03b4)-post hoc generalization, and for every distribution P over X = {\u00b11}k+O) and ev\u221aery data analyst A who asks k statistical queries, P \u2203j \u2208 [k], |qj(P) \u2212 a| > \u03b5 \u2264 \u03b4 n = \u03a9( k/\u03b52), where the probability is taken over X \u223c P\u2297n and the coins of M and A.",
        "If M takes a sample of size n, has polynomial running time, satisfies (\u03b5, \u03b4)-post hoc generalization, and for every distribution P over X = {\u00b11}kc+O) and eve\u221ary data analyst A who asks k statistical queries, P \u2203j \u2208 [k], |qj(P) \u2212 a| > \u03b5 \u2264 \u03b4, n = \u03a9( k/\u03b52), where the probability is taken over X \u223c P\u2297n and the coins of M and A.",
        ", M that take n samples from a distribution over X = {0, 1}O such that (1) each of these algorithms are (\u03b5, \u03b4)-post hoc generalizing for every \u03b4 > 0 and \u03b5 = O( log(n/\u03b4)/n.999), but (2) the composition (M1, .",
        "Computational post hoc generalization means that Definition 1.1 is satisfied when the algorithm A runs in polynomial time.",
        "We are interested in the ability of interactive algorithms satisfying post hoc generalization to answer a sequence of statistical queries.",
        "An algorithm M is (\u03b5, \u03b4)-post hoc generalizing for k adaptive queries over X given n samples if for every adversary A, P"
    ],
    "headline": "In this work we show several limitations on the power of algorithms satisfying post hoc generalization",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Raef Bassily, Kobbi Nissim, Adam D. Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In STOC, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bassily%2C%20Raef%20Nissim%2C%20Kobbi%20Smith%2C%20Adam%20D.%20Steinke%2C%20Thomas%20Algorithmic%20stability%20for%20adaptive%20data%20analysis%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bassily%2C%20Raef%20Nissim%2C%20Kobbi%20Smith%2C%20Adam%20D.%20Steinke%2C%20Thomas%20Algorithmic%20stability%20for%20adaptive%20data%20analysis%202016"
        },
        {
            "id": "2",
            "entry": "[2] Richard Berk, Lawrence Brown, Andreas Buja, Kai Zhang, Linda Zhao, et al. Valid postselection inference. The Annals of Statistics, 41(2):802\u2013837, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berk%2C%20Richard%20Brown%2C%20Lawrence%20Buja%2C%20Andreas%20Zhang%2C%20Kai%20Valid%20postselection%20inference%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Berk%2C%20Richard%20Brown%2C%20Lawrence%20Buja%2C%20Andreas%20Zhang%2C%20Kai%20Valid%20postselection%20inference%202013"
        },
        {
            "id": "3",
            "entry": "[3] Dan Boneh and James Shaw. Collusion-secure fingerprinting for digital data. IEEE Transactions on Information Theory, 44(5):1897\u20131905, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boneh%2C%20Dan%20Shaw%2C%20James%20Collusion-secure%20fingerprinting%20for%20digital%20data%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boneh%2C%20Dan%20Shaw%2C%20James%20Collusion-secure%20fingerprinting%20for%20digital%20data%201998"
        },
        {
            "id": "4",
            "entry": "[4] Andreas Buja, Richard Berk, Lawrence Brown, Edward George, Emil Pitkin, Mikhail Traskin, Linda Zhao, and Kai Zhang. Models as approximations: A conspiracy of random regressors and model deviations against classical inference in regression. Statistical Science, 1460, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Buja%2C%20Andreas%20Berk%2C%20Richard%20Brown%2C%20Lawrence%20George%2C%20Edward%20Models%20as%20approximations%3A%20A%20conspiracy%20of%20random%20regressors%20and%20model%20deviations%20against%20classical%20inference%20in%20regression%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Buja%2C%20Andreas%20Berk%2C%20Richard%20Brown%2C%20Lawrence%20George%2C%20Edward%20Models%20as%20approximations%3A%20A%20conspiracy%20of%20random%20regressors%20and%20model%20deviations%20against%20classical%20inference%20in%20regression%202015"
        },
        {
            "id": "5",
            "entry": "[5] Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. In SODA, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bun%2C%20Mark%20Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Make%20up%20your%20mind%3A%20The%20price%20of%20online%20queries%20in%20differential%20privacy%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bun%2C%20Mark%20Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Make%20up%20your%20mind%3A%20The%20price%20of%20online%20queries%20in%20differential%20privacy%202017"
        },
        {
            "id": "6",
            "entry": "[6] Mark Bun, Jonathan Ullman, and Salil P. Vadhan. Fingerprinting codes and the price of approximate differential privacy. In STOC, pages 1\u201310. ACM, May 31 \u2013 June 3 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bun%2C%20Mark%20Ullman%2C%20Jonathan%20Vadhan%2C%20Salil%20P.%20Fingerprinting%20codes%20and%20the%20price%20of%20approximate%20differential%20privacy%202014-05-31",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bun%2C%20Mark%20Ullman%2C%20Jonathan%20Vadhan%2C%20Salil%20P.%20Fingerprinting%20codes%20and%20the%20price%20of%20approximate%20differential%20privacy%202014-05-31"
        },
        {
            "id": "7",
            "entry": "[7] Rachel Cummings, Katrina Ligett, Kobbi Nissim, Aaron Roth, and Zhiwei Steven Wu. Adaptive learning with robust generalization guarantees. In COLT, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cummings%2C%20Rachel%20Ligett%2C%20Katrina%20Nissim%2C%20Kobbi%20Roth%2C%20Aaron%20Adaptive%20learning%20with%20robust%20generalization%20guarantees%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cummings%2C%20Rachel%20Ligett%2C%20Katrina%20Nissim%2C%20Kobbi%20Roth%2C%20Aaron%20Adaptive%20learning%20with%20robust%20generalization%20guarantees%202016"
        },
        {
            "id": "8",
            "entry": "[8] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. Generalization in adaptive data analysis and holdout reuse. In NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Feldman%2C%20Vitaly%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Generalization%20in%20adaptive%20data%20analysis%20and%20holdout%20reuse%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Feldman%2C%20Vitaly%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Generalization%20in%20adaptive%20data%20analysis%20and%20holdout%20reuse%202015"
        },
        {
            "id": "9",
            "entry": "[9] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. Preserving statistical validity in adaptive data analysis. In STOC, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Feldman%2C%20Vitaly%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Preserving%20statistical%20validity%20in%20adaptive%20data%20analysis%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Feldman%2C%20Vitaly%20Hardt%2C%20Moritz%20Pitassi%2C%20Toniann%20Preserving%20statistical%20validity%20in%20adaptive%20data%20analysis%202015"
        },
        {
            "id": "10",
            "entry": "[10] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In TCC, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20McSherry%2C%20Frank%20Nissim%2C%20Kobbi%20Smith%2C%20Adam%20Calibrating%20noise%20to%20sensitivity%20in%20private%20data%20analysis%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20McSherry%2C%20Frank%20Nissim%2C%20Kobbi%20Smith%2C%20Adam%20Calibrating%20noise%20to%20sensitivity%20in%20private%20data%20analysis%202006"
        },
        {
            "id": "11",
            "entry": "[11] Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. In FOCS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dwork%2C%20Cynthia%20Smith%2C%20Adam%20Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Robust%20traceability%20from%20trace%20amounts%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dwork%2C%20Cynthia%20Smith%2C%20Adam%20Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Robust%20traceability%20from%20trace%20amounts%202015"
        },
        {
            "id": "12",
            "entry": "[12] Bradley Efron. Estimation and accuracy after model selection. Journal of the American Statistical Association, 109(507):991\u20131007, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Efron%2C%20Bradley%20Estimation%20and%20accuracy%20after%20model%20selection%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Efron%2C%20Bradley%20Estimation%20and%20accuracy%20after%20model%20selection%202014"
        },
        {
            "id": "13",
            "entry": "[13] William Fithian, Dennis Sun, and Jonathan Taylor. Optimal inference after model selection. arXiv preprint arXiv:1410.2597, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1410.2597"
        },
        {
            "id": "14",
            "entry": "[14] Andrew Gelman and Eric Loken. The statistical crisis in science. Am Sci, 102(6):460, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Andrew%20Gelman%20and%20Eric%20Loken.%20The%20statistical%20crisis%20in%20science%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Andrew%20Gelman%20and%20Eric%20Loken.%20The%20statistical%20crisis%20in%20science%202014"
        },
        {
            "id": "15",
            "entry": "[15] Moritz Hardt and Jonathan Ullman. Preventing false discovery in interactive data analysis is hard. In FOCS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hardt%2C%20Moritz%20Ullman%2C%20Jonathan%20Preventing%20false%20discovery%20in%20interactive%20data%20analysis%20is%20hard%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hardt%2C%20Moritz%20Ullman%2C%20Jonathan%20Preventing%20false%20discovery%20in%20interactive%20data%20analysis%20is%20hard%202014"
        },
        {
            "id": "16",
            "entry": "[16] Clifford M Hurvich and Chih-Ling Tsai. The impact of model selection on inference in linear regression. The American Statistician, 44(3):214\u2013217, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hurvich%2C%20Clifford%20M.%20Tsai%2C%20Chih-Ling%20The%20impact%20of%20model%20selection%20on%20inference%20in%20linear%20regression%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hurvich%2C%20Clifford%20M.%20Tsai%2C%20Chih-Ling%20The%20impact%20of%20model%20selection%20on%20inference%20in%20linear%20regression%201990"
        },
        {
            "id": "17",
            "entry": "[17] Michael J. Kearns. Efficient noise-tolerant learning from statistical queries. In STOC, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kearns%2C%20Michael%20J.%20Efficient%20noise-tolerant%20learning%20from%20statistical%20queries%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kearns%2C%20Michael%20J.%20Efficient%20noise-tolerant%20learning%20from%20statistical%20queries%201993"
        },
        {
            "id": "18",
            "entry": "[18] Benedikt M P\u00f6tscher. Effects of model selection on inference. Econometric Theory, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=P%C3%B6tscher%2C%20Benedikt%20M.%20Effects%20of%20model%20selection%20on%20inference%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=P%C3%B6tscher%2C%20Benedikt%20M.%20Effects%20of%20model%20selection%20on%20inference%201991"
        },
        {
            "id": "19",
            "entry": "[19] Daniel Russo and James Zou. Controlling bias in adaptive data analysis using information theory. In AISTATS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20Daniel%20Zou%2C%20James%20Controlling%20bias%20in%20adaptive%20data%20analysis%20using%20information%20theory%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20Daniel%20Zou%2C%20James%20Controlling%20bias%20in%20adaptive%20data%20analysis%20using%20information%20theory%202016"
        },
        {
            "id": "20",
            "entry": "[20] Thomas Steinke and Jonathan Ullman. Interactive fingerprinting codes and the hardness of preventing false discovery. In COLT, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Interactive%20fingerprinting%20codes%20and%20the%20hardness%20of%20preventing%20false%20discovery%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Interactive%20fingerprinting%20codes%20and%20the%20hardness%20of%20preventing%20false%20discovery%202015"
        },
        {
            "id": "21",
            "entry": "[21] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. In FOCS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Tight%20lower%20bounds%20for%20differentially%20private%20selection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Steinke%2C%20Thomas%20Ullman%2C%20Jonathan%20Tight%20lower%20bounds%20for%20differentially%20private%20selection%202017"
        },
        {
            "id": "22",
            "entry": "[22] G\u00e1bor Tardos. Optimal probabilistic fingerprint codes. J. ACM, 55(2), 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tardos%2C%20G%C3%A1bor%20Optimal%20probabilistic%20fingerprint%20codes%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tardos%2C%20G%C3%A1bor%20Optimal%20probabilistic%20fingerprint%20codes%202008"
        },
        {
            "id": "23",
            "entry": "[23] Jonathan Taylor and Robert J Tibshirani. Statistical learning and selective inference. Proceedings of the National Academy of Sciences, 112(25):7629\u20137634, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Taylor%2C%20Jonathan%20Tibshirani%2C%20Robert%20J.%20Statistical%20learning%20and%20selective%20inference%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Taylor%2C%20Jonathan%20Tibshirani%2C%20Robert%20J.%20Statistical%20learning%20and%20selective%20inference%202015"
        },
        {
            "id": "24",
            "entry": "[24] Yu-Xiang Wang. New Paradigms and Optimality Guarantees in Statistical Learning and Estimation. PhD thesis, Carnegie Mellon University, 2017. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yu-Xiang%20New%20Paradigms%20and%20Optimality%20Guarantees%20in%20Statistical%20Learning%20and%20Estimation%202017"
        }
    ]
}
