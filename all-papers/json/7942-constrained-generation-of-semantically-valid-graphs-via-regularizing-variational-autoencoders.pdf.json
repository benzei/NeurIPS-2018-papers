{
    "filename": "7942-constrained-generation-of-semantically-valid-graphs-via-regularizing-variational-autoencoders.pdf",
    "metadata": {
        "title": "Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders",
        "author": "Tengfei Ma, Jie Chen, Cao Xiao",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7942-constrained-generation-of-semantically-valid-graphs-via-regularizing-variational-autoencoders.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Deep generative models have achieved remarkable success in various data domains, including images, time series, and natural languages. There remain, however, substantial challenges for combinatorial structures, including graphs. One of the key challenges lies in the difficulty of ensuring semantic validity in context. For example, in molecular graphs, the number of bonding-electron pairs must not exceed the valence of an atom; whereas in protein interaction networks, two proteins may be connected only when they belong to the same or correlated gene ontology terms. These constraints are not easy to be incorporated into a generative model. In this work, we propose a regularization framework for variational autoencoders as a step toward semantic validity. We focus on the matrix representation of graphs and formulate penalty terms that regularize the output distribution of the decoder to encourage the satisfaction of validity constraints. Experimental results confirm a much higher likelihood of sampling valid graphs in our approach, compared with others reported in the literature."
    },
    "keywords": [
        {
            "term": "natural language",
            "url": "https://en.wikipedia.org/wiki/natural_language"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "semantic validity",
            "url": "https://en.wikipedia.org/wiki/semantic_validity"
        },
        {
            "term": "molecular graph",
            "url": "https://en.wikipedia.org/wiki/molecular_graph"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "time series",
            "url": "https://en.wikipedia.org/wiki/time_series"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        }
    ],
    "highlights": [
        "The recent years have witnessed rapid progress in the development of deep generative models for a wide variety of data types, including continuous data and sequences",
        "Including generative adversarial networks (GAN) [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>] and variational autoencoders (VAE) [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>], learn a distribution parameterized by deep neural networks from a set of training examples",
        "Generating semantically valid graphs is a challenging subject for deep generative models",
        "Whereas substantial breakthrough is seen for molecular graphs, rarely a method is generalizable to a general graph",
        "In this work we propose a regularization framework for training variational autoencoders that encourages the satisfaction of validity constraints",
        "We demonstrate the effectiveness of the framework in two tasks: the generation of molecular graphs and that of node-compatible graphs"
    ],
    "key_statements": [
        "The recent years have witnessed rapid progress in the development of deep generative models for a wide variety of data types, including continuous data and sequences",
        "Including generative adversarial networks (GAN) [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>] and variational autoencoders (VAE) [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>], learn a distribution parameterized by deep neural networks from a set of training examples",
        "Generating semantically valid graphs is a challenging subject for deep generative models",
        "Whereas substantial breakthrough is seen for molecular graphs, rarely a method is generalizable to a general graph",
        "In this work we propose a regularization framework for training variational autoencoders that encourages the satisfaction of validity constraints",
        "We demonstrate the effectiveness of the framework in two tasks: the generation of molecular graphs and that of node-compatible graphs"
    ],
    "summary": [
        "The recent years have witnessed rapid progress in the development of deep generative models for a wide variety of data types, including continuous data and sequences.",
        "We propose a regularization framework for VAEs to generate semantically valid graphs.",
        "Examples of the constraints include graph connectivity, node label compatibility, as well as valence in the context of molecular graphs.",
        "We demonstrate the high probability of generating valid graphs under the proposed framework with two benchmark molecule data sets and a synthetic node-compatible data set.",
        "Our work formulates a regularization framework to impose constraints so that the sampled graphs are semantically valid.",
        "Another approach for graph generation is to produce nodes and edges sequentially [<a class=\"ref-link\" id=\"c24\" href=\"#r24\">24</a>, <a class=\"ref-link\" id=\"c29\" href=\"#r29\">29</a>].",
        "The goal of a generative model is to learn a probability distribution from a set of training graphs, such that one can sample new graphs from it.",
        "Such a variational treatment lands itself to an autoencoder, where the inference network encodes a training example G into a latent representation z, and the generative network decodes the latent z and reconstructs a graph from the probabilistic model G, such that it is as close to G as possible.",
        "We first generalize the Lagrangian function for an infinite constraint set, and use the generalization to motivate a sound approach for formulating regularization.",
        "Note that for graphs other than molecules, where the concept of valence does not exist, ghost nodes still must obey the constraint (9).",
        "For node-compatible graphs, we construct a synthetic data set by first generating random node labels, followed by connecting node pairs under certain probability if their labels are compatible.",
        "We generate 100,000 random node-compatible graphs.",
        "For each pair of nodes whose types are compatible according to D, we assign an edge with probability 0.4.",
        "The column \u201c% Valid\u201d denotes the percentage of valid graphs among those sampled from the prior, and the column \u201cELBO\u201d is the lower bound approximation of the log-evidence of the training data.",
        "We perform an experiment to show that the proposed regularization may be used to recover a graph that obeys the compatibility constraints.",
        "We generated another set of 10,000 graphs and randomly inserted edges for noncompatible node pairs.",
        "One sees that the proposed approach leads to a high probability of reconstructing valid graphs, whereas standard VAE fails in most of the cases.",
        "In this work we propose a regularization framework for training VAEs that encourages the satisfaction of validity constraints.",
        "We demonstrate the effectiveness of the framework in two tasks: the generation of molecular graphs and that of node-compatible graphs"
    ],
    "headline": "We propose a regularization framework for variational autoencoders as a step toward semantic validity",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Mart\u00edn Arjovsky and L\u00e9on Bottou. Towards principled methods for training generative adversarial networks. ICLR 17, abs/1701.04862, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20Mart%C3%ADn%20Bottou%2C%20L%C3%A9on%20Towards%20principled%20methods%20for%20training%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20Mart%C3%ADn%20Bottou%2C%20L%C3%A9on%20Towards%20principled%20methods%20for%20training%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "2",
            "entry": "[2] Mart\u00edn Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In ICML 17, 2017. URL http://proceedings.mlr.press/v70/arjovsky17a.html.",
            "url": "http://proceedings.mlr.press/v70/arjovsky17a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mart%C3%ADn%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "3",
            "entry": "[3] Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium in generative adversarial nets (GANs). In ICML 17, 2017. URL http://proceedings.mlr.press/v70/arora17a.html.",
            "url": "http://proceedings.mlr.press/v70/arora17a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20Sanjeev%20Ge%2C%20Rong%20Liang%2C%20Yingyu%20Ma%2C%20Tengyu%20Generalization%20and%20equilibrium%20in%20generative%20adversarial%20nets%20%28GANs%29%202017"
        },
        {
            "id": "4",
            "entry": "[4] Albert-Laszlo Barabasi and Reka Albert. Emergence of scaling in random networks. Science, 286(5439):509\u2013512, 1999. doi: 10.1126/science.286.5439.509.",
            "crossref": "https://dx.doi.org/10.1126/science.286.5439.509",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1126/science.286.5439.509"
        },
        {
            "id": "5",
            "entry": "[5] Esben Jannik Bjerrum and Richard Threlfall. Molecular generation with recurrent neural networks (rnns). CoRR, abs/1705.04612, 2017. URL http://arxiv.org/abs/1705.04612.",
            "url": "http://arxiv.org/abs/1705.04612",
            "arxiv_url": "https://arxiv.org/pdf/1705.04612"
        },
        {
            "id": "6",
            "entry": "[6] Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z\u00fcgner, and Stephan G\u00fcnnemann. GraphGAN: Generating graphs via random walks. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojchevski%2C%20Aleksandar%20Shchur%2C%20Oleksandr%20Z%C3%BCgner%2C%20Daniel%20G%C3%BCnnemann%2C%20Stephan%20GraphGAN%3A%20Generating%20graphs%20via%20random%20walks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bojchevski%2C%20Aleksandar%20Shchur%2C%20Oleksandr%20Z%C3%BCgner%2C%20Daniel%20G%C3%BCnnemann%2C%20Stephan%20GraphGAN%3A%20Generating%20graphs%20via%20random%20walks%202018"
        },
        {
            "id": "7",
            "entry": "[7] Yuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. CoRR, abs/1509.00519, 2015. URL http://arxiv.org/abs/1509.00519.",
            "url": "http://arxiv.org/abs/1509.00519",
            "arxiv_url": "https://arxiv.org/pdf/1509.00519"
        },
        {
            "id": "8",
            "entry": "[8] Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder. CoRR, abs/1611.02731, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02731"
        },
        {
            "id": "9",
            "entry": "[9] Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, and Le Song. Syntax-directed variational autoencoder for structured data. International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=SyqShMZRb.",
            "url": "https://openreview.net/forum?id=SyqShMZRb",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20Hanjun%20Tian%2C%20Yingtao%20Dai%2C%20Bo%20Skiena%2C%20Steven%20Syntax-directed%20variational%20autoencoder%20for%20structured%20data%202018"
        },
        {
            "id": "10",
            "entry": "[10] Micha\u00ebl Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. CoRR, abs/1606.09375, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.09375"
        },
        {
            "id": "11",
            "entry": "[11] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In NIPS 15. 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duvenaud%2C%20David%20K.%20Maclaurin%2C%20Dougal%20Iparraguirre%2C%20Jorge%20Bombarell%2C%20Rafael%20Convolutional%20networks%20on%20graphs%20for%20learning%20molecular%20fingerprints",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duvenaud%2C%20David%20K.%20Maclaurin%2C%20Dougal%20Iparraguirre%2C%20Jorge%20Bombarell%2C%20Rafael%20Convolutional%20networks%20on%20graphs%20for%20learning%20molecular%20fingerprints"
        },
        {
            "id": "12",
            "entry": "[12] P. Erdos and A R\u00e9nyi. On the evolution of random graphs. In PUBLICATION OF THE MATHEMATICAL INSTITUTE OF THE HUNGARIAN ACADEMY OF SCIENCES, pages 17\u201361, 1960.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=P.%20Erdos%20and%20A%20R%C3%A9nyi.%20On%20the%20evolution%20of%20random%20graphs.%20In%20PUBLICATION%20OF%20THE%20MATHEMATICAL%20INSTITUTE%20OF%20THE%20HUNGARIAN%20ACADEMY%20OF%20SCIENCES%201960"
        },
        {
            "id": "13",
            "entry": "[13] Alexander L. Gaunt, Marc Brockschmidt, Rishabh Singh, Nate Kushman, Pushmeet Kohli, Jonathan Taylor, and Daniel Tarlow. Terpret: A probabilistic programming language for program induction. CoRR, abs/1608.04428, 2016. URL http://arxiv.org/abs/1608.04428.",
            "url": "http://arxiv.org/abs/1608.04428",
            "arxiv_url": "https://arxiv.org/pdf/1608.04428"
        },
        {
            "id": "14",
            "entry": "[14] J. Gilmer, S.S. Schoenholz, P.F. Riley, O. Vinyals, and G.E. Dahl. Neural message passing for quantum chemistry. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilmer%2C%20J.%20Schoenholz%2C%20S.S.%20Riley%2C%20P.F.%20Vinyals%2C%20O.%20Neural%20message%20passing%20for%20quantum%20chemistry%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilmer%2C%20J.%20Schoenholz%2C%20S.S.%20Riley%2C%20P.F.%20Vinyals%2C%20O.%20Neural%20message%20passing%20for%20quantum%20chemistry%202017"
        },
        {
            "id": "15",
            "entry": "[15] Rafael G\u00f3mez-Bombarelli, David K. Duvenaud, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Jorge AguileraIparraguirre, Timothy D. Hirzel, Ryan P. Adams, and Al\u00e1n Aspuru-Guzik. Automatic chemical design using a data-driven continuous representation of molecules. CoRR, abs/1610.02415, 2016. URL http://arxiv.org/abs/1610.02415.",
            "url": "http://arxiv.org/abs/1610.02415",
            "arxiv_url": "https://arxiv.org/pdf/1610.02415"
        },
        {
            "id": "16",
            "entry": "[16] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS 14. 2014. URL http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.",
            "url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "17",
            "entry": "[17] Xiaojie Guo, Lingfei Wu, and Liang Zhao. Deep graph translation. arXiv preprint arXiv:1805.09980, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.09980"
        },
        {
            "id": "18",
            "entry": "[18] Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P. Xing. Toward controlled generation of text. In Proceedings of the 34th International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Zhiting%20Yang%2C%20Zichao%20Liang%2C%20Xiaodan%20Salakhutdinov%2C%20Ruslan%20Toward%20controlled%20generation%20of%20text%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Zhiting%20Yang%2C%20Zichao%20Liang%2C%20Xiaodan%20Salakhutdinov%2C%20Ruslan%20Toward%20controlled%20generation%20of%20text%202017"
        },
        {
            "id": "19",
            "entry": "[19] Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, and Eric P. Xing. On unifying deep generative models. CoRR, abs/1706.00550, 2017. URL http://arxiv.org/abs/1706.00550.",
            "url": "http://arxiv.org/abs/1706.00550",
            "arxiv_url": "https://arxiv.org/pdf/1706.00550"
        },
        {
            "id": "20",
            "entry": "[20] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1502.03167"
        },
        {
            "id": "21",
            "entry": "[21] John J. Irwin, Teague Sterling, Michael M. Mysinger, Erin S. Bolstad, and Ryan G. Coleman. ZINC: A free tool to discover chemistry for biology. Journal of Chemical Information and Modeling, 52(7), 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Irwin%2C%20John%20J.%20Sterling%2C%20Teague%20Mysinger%2C%20Michael%20M.%20Bolstad%2C%20Erin%20S.%20ZINC%3A%20A%20free%20tool%20to%20discover%20chemistry%20for%20biology%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Irwin%2C%20John%20J.%20Sterling%2C%20Teague%20Mysinger%2C%20Michael%20M.%20Bolstad%2C%20Erin%20S.%20ZINC%3A%20A%20free%20tool%20to%20discover%20chemistry%20for%20biology%202012"
        },
        {
            "id": "22",
            "entry": "[22] Natasha Jaques, Shixiang Gu, Richard E. Turner, and Douglas Eck. Tuning recurrent neural networks with reinforcement learning. CoRR, abs/1611.02796, 2016. URL http://arxiv.org/abs/1611.02796.",
            "url": "http://arxiv.org/abs/1611.02796",
            "arxiv_url": "https://arxiv.org/pdf/1611.02796"
        },
        {
            "id": "23",
            "entry": "[23] Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Junction tree variational autoencoder for molecular graph generation. CoRR, abs/1802.04364, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04364"
        },
        {
            "id": "24",
            "entry": "[24] Daniel D. Johnson. Learning graphical state transitions. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Daniel%20D.%20Learning%20graphical%20state%20transitions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Daniel%20D.%20Learning%20graphical%20state%20transitions%202017"
        },
        {
            "id": "25",
            "entry": "[25] Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2013. URL http://dblp.uni-trier.de/db/journals/corr/corr1312.html#KingmaW13.",
            "url": "http://dblp.uni-trier.de/db/journals/corr/corr1312.html#KingmaW13",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "26",
            "entry": "[26] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. CoRR, abs/1609.02907, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.02907"
        },
        {
            "id": "27",
            "entry": "[27] Matt J. Kusner, Brooks Paige, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Grammar variational autoencoder. In Proceedings of the 34th International Conference on Machine Learning, volume 70, pages 1945\u20131954, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matt%20J.%20Kusner%2C%20Brooks%20Paige%20Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Grammar%20variational%20autoencoder%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matt%20J.%20Kusner%2C%20Brooks%20Paige%20Hern%C3%A1ndez-Lobato%2C%20Jos%C3%A9%20Miguel%20Grammar%20variational%20autoencoder%202017"
        },
        {
            "id": "28",
            "entry": "[28] Yujia Li, Kevin Swersky, and Richard Zemel. Generative moment matching networks. In ICML 15, 2015. URL http://dl.acm.org/citation.cfm?id=3045118.3045301.",
            "url": "http://dl.acm.org/citation.cfm?id=3045118.3045301",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Yujia%20Swersky%2C%20Kevin%20Zemel%2C%20Richard%20Generative%20moment%20matching%20networks%202015"
        },
        {
            "id": "29",
            "entry": "[29] Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, and Peter Battaglia. Learning deep generative models of graphs, 2018. https://openreview.net/forum?id=Hy1d-ebAb.",
            "url": "https://openreview.net/forum?id=Hy1d-ebAb"
        },
        {
            "id": "30",
            "entry": "[30] Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nowozin%2C%20Sebastian%20Cseke%2C%20Botond%20Tomioka%2C%20Ryota%20f-gan%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nowozin%2C%20Sebastian%20Cseke%2C%20Botond%20Tomioka%2C%20Ryota%20f-gan%3A%20Training%20generative%20neural%20samplers%20using%20variational%20divergence%20minimization%202016"
        },
        {
            "id": "31",
            "entry": "[31] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015. URL http://arxiv.org/abs/1511.06434.",
            "url": "http://arxiv.org/abs/1511.06434",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "32",
            "entry": "[32] Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules. Scientific Data, 1, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ramakrishnan%2C%20Raghunathan%20Dral%2C%20Pavlo%20O.%20Rupp%2C%20Matthias%20von%20Lilienfeld%2C%20O.Anatole%20Quantum%20chemistry%20structures%20and%20properties%20of%20134%20kilo%20molecules%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ramakrishnan%2C%20Raghunathan%20Dral%2C%20Pavlo%20O.%20Rupp%2C%20Matthias%20von%20Lilienfeld%2C%20O.Anatole%20Quantum%20chemistry%20structures%20and%20properties%20of%20134%20kilo%20molecules%202014"
        },
        {
            "id": "33",
            "entry": "[33] Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20J.%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20J.%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016"
        },
        {
            "id": "34",
            "entry": "[34] F. Scarselli, M. Gori, A.C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scarselli%2C%20F.%20Gori%2C%20M.%20Tsoi%2C%20A.C.%20Hagenbuchner%2C%20M.%20The%20graph%20neural%20network%20model%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scarselli%2C%20F.%20Gori%2C%20M.%20Tsoi%2C%20A.C.%20Hagenbuchner%2C%20M.%20The%20graph%20neural%20network%20model%202009"
        },
        {
            "id": "35",
            "entry": "[35] Marwin H. S. Segler, Thierry Kogej, Christian Tyrchan, and Mark P. Waller. Generating focussed molecule libraries for drug discovery with recurrent neural networks. CoRR, abs/1701.01329, 2017. URL http://arxiv.org/abs/1701.01329.",
            "url": "http://arxiv.org/abs/1701.01329",
            "arxiv_url": "https://arxiv.org/pdf/1701.01329"
        },
        {
            "id": "36",
            "entry": "[36] Martin Simonovsky and Nikos Komodakis. GraphVAE: Towards generation of small graphs using variational autoencoders, 2018. https://openreview.net/forum?id=SJlhPMWAW.",
            "url": "https://openreview.net/forum?id=SJlhPMWAW"
        },
        {
            "id": "37",
            "entry": "[37] Sahar Tavakoli, Alireza Hajibagheri, and Gita Sukthankar. Learning social graph topologies using generative adversarial neural networks. In International Conference on Social Computing, Behavioral-Cultural Modeling & Prediction, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tavakoli%2C%20Sahar%20Hajibagheri%2C%20Alireza%20Sukthankar%2C%20Gita%20Learning%20social%20graph%20topologies%20using%20generative%20adversarial%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tavakoli%2C%20Sahar%20Hajibagheri%2C%20Alireza%20Sukthankar%2C%20Gita%20Learning%20social%20graph%20topologies%20using%20generative%20adversarial%20neural%20networks%202017"
        },
        {
            "id": "38",
            "entry": "[38] A\u00e4ron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. CoRR, abs/1609.03499, 2016. URL http://arxiv.org/abs/1609.03499.",
            "url": "http://arxiv.org/abs/1609.03499",
            "arxiv_url": "https://arxiv.org/pdf/1609.03499"
        },
        {
            "id": "39",
            "entry": "[39] A\u00e4ron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray Kavukcuoglu. Conditional image generation with pixelcnn decoders. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20den%20Oord%2C%20A%C3%A4ron%20Kalchbrenner%2C%20Nal%20Vinyals%2C%20Oriol%20Espeholt%2C%20Lasse%20Conditional%20image%20generation%20with%20pixelcnn%20decoders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20den%20Oord%2C%20A%C3%A4ron%20Kalchbrenner%2C%20Nal%20Vinyals%2C%20Oriol%20Espeholt%2C%20Lasse%20Conditional%20image%20generation%20with%20pixelcnn%20decoders%202016"
        },
        {
            "id": "40",
            "entry": "[40] Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. CoRR, abs/1609.02612, 2016. URL http://arxiv.org/abs/1609.02612.",
            "url": "http://arxiv.org/abs/1609.02612",
            "arxiv_url": "https://arxiv.org/pdf/1609.02612"
        },
        {
            "id": "41",
            "entry": "[41] David Weininger. SMILES, a chemical language and information system. 1. introduction to methodology and encoding rules. J. Chem. Inf. Comput. Sci., 28(1):31\u201336, February 1988. ISSN 0095-2338. doi: 10.1021/ci00057a005. URL http://dx.doi.org/10.1021/ci00057a005. ",
            "crossref": "https://dx.doi.org/10.1021/ci00057a005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1021/ci00057a005"
        }
    ]
}
