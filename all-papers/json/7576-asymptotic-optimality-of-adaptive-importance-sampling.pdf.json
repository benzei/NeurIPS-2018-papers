{
    "filename": "7576-asymptotic-optimality-of-adaptive-importance-sampling.pdf",
    "metadata": {
        "title": "Asymptotic optimality of adaptive importance sampling",
        "author": "Fran\u00e7ois Portier, Bernard Delyon",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7576-asymptotic-optimality-of-adaptive-importance-sampling.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Adaptive importance sampling (AIS) uses past samples to update the sampling policy qt at each stage t. Each stage t is formed with two steps : (i) to explore the space with nt points according to qt and (ii) to exploit the current amount of information to update the sampling policy. The very fundamental question raised in this paper concerns the behavior of empirical sums based on AIS. Without making any assumption on the allocation policy nt, the theory developed involves no restriction on the split of computational resources between the explore (i) and the exploit (ii) step. It is shown that AIS is asymptotically optimal : the asymptotic behavior of AIS is the same as some \u201coracle\u201d strategy that knows the targeted sampling policy from the beginning. From a practical perspective, weighted AIS is introduced, a new method that allows to forget poor samples from early stages."
    },
    "keywords": [
        {
            "term": "monte carlo integration",
            "url": "https://en.wikipedia.org/wiki/Monte_Carlo_Integration"
        },
        {
            "term": "importance sampling",
            "url": "https://en.wikipedia.org/wiki/importance_sampling"
        },
        {
            "term": "rejection sampling",
            "url": "https://en.wikipedia.org/wiki/rejection_sampling"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "monte carlo method",
            "url": "https://en.wikipedia.org/wiki/monte_carlo_method"
        }
    ],
    "highlights": [
        "The adaptive choice of a sampling policy lies at the heart of many fields of Machine Learning where former Monte Carlo experiments guide the forthcoming ones. This includes for instance reinforcment learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] where the optimal policy maximizes the reward; inference in Bayesian [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] or graphical models [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]; optimization based on stochastic gradient descent [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>] or without using the gradient [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]; rejection sampling [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>]",
        "Adaptive importance sampling (AIS) [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], which extends the basic Monte Carlo integration approach, offers a natural probabilistic framework to describe the evolution of sampling policies",
        "The importance sampling estimate of \u03c6 based on the sampling policy q, is given by n\u22121 n \u03c6 , (1)",
        "The sequence \u2282 N\u2217, called the allocation policy, contains the number of particles generated at each stage",
        "Folllowing the same spirit as [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], we study parametric Adaptive importance sampling as presented in the Adaptive importance sampling algorithm when the policy is chosen out of a parametric family of probability density functions"
    ],
    "key_statements": [
        "The adaptive choice of a sampling policy lies at the heart of many fields of Machine Learning where former Monte Carlo experiments guide the forthcoming ones. This includes for instance reinforcment learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>, <a class=\"ref-link\" id=\"c27\" href=\"#r27\">27</a>, <a class=\"ref-link\" id=\"c30\" href=\"#r30\">30</a>] where the optimal policy maximizes the reward; inference in Bayesian [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] or graphical models [<a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>]; optimization based on stochastic gradient descent [<a class=\"ref-link\" id=\"c34\" href=\"#r34\">34</a>] or without using the gradient [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>]; rejection sampling [<a class=\"ref-link\" id=\"c12\" href=\"#r12\">12</a>]",
        "Adaptive importance sampling (AIS) [<a class=\"ref-link\" id=\"c25\" href=\"#r25\">25</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], which extends the basic Monte Carlo integration approach, offers a natural probabilistic framework to describe the evolution of sampling policies",
        "The importance sampling estimate of \u03c6 based on the sampling policy q, is given by n\u22121 n \u03c6 , (1)",
        "The sequence \u2282 N\u2217, called the allocation policy, contains the number of particles generated at each stage",
        "Folllowing the same spirit as [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>, <a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>, <a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>], we study parametric Adaptive importance sampling as presented in the Adaptive importance sampling algorithm when the policy is chosen out of a parametric family of probability density functions",
        "A central limit theorem is established for the Adaptive importance sampling estimate It",
        "The parameter \u03b8 contains a location and a scale parameter \u03bc and \u03a3. This family has two advantages: the parameter \u03bd allows tuning for heavy tails, and estimation is easy because moments of q\u03b8 are explicitly related to \u03b8",
        "The risk function based on GMM or the Kullback-Leibler approach is derived from a certain targeted density f in such a way that if q\u03b8 = f , r(\u03b8) is a minimum",
        "We study a toy Gaussian example to illustrate the practical behavior of Adaptive importance sampling",
        "We consider a so called \u201coracle\u201d method : importance sampling with fix policy \u03c6\u03bc\u2217,\u03c3\u2217"
    ],
    "summary": [
        "The adaptive choice of a sampling policy lies at the heart of many fields of Machine Learning where former Monte Carlo experiments guide the forthcoming ones.",
        "The importance sampling estimate of \u03c6 based on the sampling policy q, is given by n\u22121 n \u03c6 , (1)",
        "Namely, the classical integration problem and the Bayesian estimation problem, are examples where the sampling policy can be chosen appropriately.",
        "The sequence \u2282 N\u2217, called the allocation policy, contains the number of particles generated at each stage.",
        "Among the update based on a parametric family, the convergence properties of the Kullback-Leibler divergence between the estimated and the targeted distribution are studied in [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>].",
        "A central limit theorem is established for the AIS estimate It. It involves high-level conditions on the sampling policy estimate qt.",
        "The high-level conditions are verified in the case of parametric sampling policies with updates taking place in a general framework inspired by the paradigm of empirical risk minimization.",
        "When \u03c6 : Rd \u2192 Rp with p = 1, consists in minimizing the variance over the class of sampling policies.",
        "The updates described before using GMM, the Kullback-Leibler divergence or the variance, all fit within the framework of empirical risk minimization, given by (6), which rewritten at the sample scale gives",
        "The proof follows from a standard approach from M -estimation theory [31, Theorem 5.7] but a particular attention shall be payed to the uniform law of large numbers because of the missing i.i.d. property of the sequences of interest.",
        "The risk function based on GMM or the Kullback-Leibler approach is derived from a certain targeted density f in such a way that if q\u03b8 = f , r(\u03b8) is a minimum.",
        "This means that asymptotically, AIS achives the same variance as the \u201coracle\u201d importance sampling method based on the sampler f .",
        "For normalized AIS, the asymptotic variance is uT VT )u, V and u are given in Corollary 1.",
        "Minimizing w.r.t. q\u03b8\u2217 , we obtain the result that the optimal sampling policy for normalized AIS is proportional to |\u03c6 \u2212 \u03c6\u03c0|\u03c0.",
        "In contrast with the approach in [<a class=\"ref-link\" id=\"c9\" href=\"#r9\">9</a>], because our weights are based on the estimated variance of \u03c0/qt\u22121, our proposal is free from the integrand \u03c6 and reflects the overall quality of the t-th sample.",
        "In section C of the supplementary file, other results considering the update of the variance within the student family are provided.",
        "We consider a so called \u201coracle\u201d method : importance sampling with fix policy \u03c6\u03bc\u2217,\u03c3\u2217 ."
    ],
    "headline": "Folllowing the same spirit as , we study parametric Adaptive importance sampling as presented in the Adaptive importance sampling algorithm when the policy is chosen out of a parametric family of probability density functions",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] R\u00e9mi Bardenet and Adrien Hardy. Monte carlo with determinantal point processes. arXiv preprint arXiv:1605.00361, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1605.00361"
        },
        {
            "id": "2",
            "entry": "[2] Olivier Capp\u00e9, Randal Douc, Arnaud Guillin, Jean-Michel Marin, and Christian P Robert. Adaptive importance sampling in general mixture classes. Statistics and Computing, 18(4):447\u2013 459, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Capp%C3%A9%2C%20Olivier%20Douc%2C%20Randal%20Guillin%2C%20Arnaud%20Marin%2C%20Jean-Michel%20Adaptive%20importance%20sampling%20in%20general%20mixture%20classes%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Capp%C3%A9%2C%20Olivier%20Douc%2C%20Randal%20Guillin%2C%20Arnaud%20Marin%2C%20Jean-Michel%20Adaptive%20importance%20sampling%20in%20general%20mixture%20classes%202008"
        },
        {
            "id": "3",
            "entry": "[3] Olivier Capp\u00e9, Arnaud Guillin, Jean-Michel Marin, and Christian P Robert. Population monte carlo. Journal of Computational and Graphical Statistics, 13(4):907\u2013929, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Capp%C3%A9%2C%20Olivier%20Guillin%2C%20Arnaud%20Marin%2C%20Jean-Michel%20Robert%2C%20Christian%20P.%20Population%20monte%20carlo%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Capp%C3%A9%2C%20Olivier%20Guillin%2C%20Arnaud%20Marin%2C%20Jean-Michel%20Robert%2C%20Christian%20P.%20Population%20monte%20carlo%202004"
        },
        {
            "id": "4",
            "entry": "[4] Nicolas Chopin. Central limit theorem for sequential monte carlo methods and its application to bayesian inference. The Annals of Statistics, 32(6):2385\u20132411, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chopin%2C%20Nicolas%20Central%20limit%20theorem%20for%20sequential%20monte%20carlo%20methods%20and%20its%20application%20to%20bayesian%20inference%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chopin%2C%20Nicolas%20Central%20limit%20theorem%20for%20sequential%20monte%20carlo%20methods%20and%20its%20application%20to%20bayesian%20inference%202004"
        },
        {
            "id": "5",
            "entry": "[5] Jean Cornuet, Jean-Michel Marin, Antonietta Mira, and Christian P Robert. Adaptive multiple importance sampling. Scandinavian Journal of Statistics, 39(4):798\u2013812, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cornuet%2C%20Jean%20Marin%2C%20Jean-Michel%20Mira%2C%20Antonietta%20Robert%2C%20Christian%20P.%20Adaptive%20multiple%20importance%20sampling%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cornuet%2C%20Jean%20Marin%2C%20Jean-Michel%20Mira%2C%20Antonietta%20Robert%2C%20Christian%20P.%20Adaptive%20multiple%20importance%20sampling%202012"
        },
        {
            "id": "6",
            "entry": "[6] Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Sequential monte carlo samplers. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68(3):411\u2013436, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Moral%2C%20Pierre%20Del%20Doucet%2C%20Arnaud%20Jasra%2C%20Ajay%20Sequential%20monte%20carlo%20samplers%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Moral%2C%20Pierre%20Del%20Doucet%2C%20Arnaud%20Jasra%2C%20Ajay%20Sequential%20monte%20carlo%20samplers%202006"
        },
        {
            "id": "7",
            "entry": "[7] Bernard Delyon, Fran\u00e7ois Portier, et al. Integral approximation by kernel smoothing. Bernoulli, 22(4):2177\u20132208, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Delyon%2C%20Bernard%20Portier%2C%20Fran%C3%A7ois%20Integral%20approximation%20by%20kernel%20smoothing%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Delyon%2C%20Bernard%20Portier%2C%20Fran%C3%A7ois%20Integral%20approximation%20by%20kernel%20smoothing%202016"
        },
        {
            "id": "8",
            "entry": "[8] Randal Douc, Arnaud Guillin, J-M Marin, and Christian P Robert. Convergence of adaptive mixtures of importance sampling schemes. The Annals of Statistics, pages 420\u2013448, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Douc%2C%20Randal%20Arnaud%20Guillin%2C%20J.-M.Marin%20Robert%2C%20Christian%20P.%20Convergence%20of%20adaptive%20mixtures%20of%20importance%20sampling%20schemes%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Douc%2C%20Randal%20Arnaud%20Guillin%2C%20J.-M.Marin%20Robert%2C%20Christian%20P.%20Convergence%20of%20adaptive%20mixtures%20of%20importance%20sampling%20schemes%202007"
        },
        {
            "id": "9",
            "entry": "[9] Randal Douc, Arnaud Guillin, J-M Marin, and Christian P Robert. Minimum variance importance sampling via population monte carlo. ESAIM: Probability and Statistics, 11:427\u2013447, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Douc%2C%20Randal%20Arnaud%20Guillin%2C%20J.-M.Marin%20Robert%2C%20Christian%20P.%20Minimum%20variance%20importance%20sampling%20via%20population%20monte%20carlo%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Douc%2C%20Randal%20Arnaud%20Guillin%2C%20J.-M.Marin%20Robert%2C%20Christian%20P.%20Minimum%20variance%20importance%20sampling%20via%20population%20monte%20carlo%202007"
        },
        {
            "id": "10",
            "entry": "[10] Randal Douc and Eric Moulines. Limit theorems for weighted samples with applications to sequential monte carlo methods. The Annals of Statistics, pages 2344\u20132376, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Randal%20Douc%20and%20Eric%20Moulines.%20Limit%20theorems%20for%20weighted%20samples%20with%20applications%20to%20sequential%20monte%20carlo%20methods%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Randal%20Douc%20and%20Eric%20Moulines.%20Limit%20theorems%20for%20weighted%20samples%20with%20applications%20to%20sequential%20monte%20carlo%20methods%202008"
        },
        {
            "id": "11",
            "entry": "[11] V\u00edctor Elvira, Luca Martino, David Luengo, and M\u00f3nica F Bugallo. Generalized multiple importance sampling. arXiv preprint arXiv:1511.03095, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.03095"
        },
        {
            "id": "12",
            "entry": "[12] Akram Erraqabi, Michal Valko, Alexandra Carpentier, and Odalric Maillard. Pliable rejection sampling. In International Conference on Machine Learning, pages 2121\u20132129, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Erraqabi%2C%20Akram%20Valko%2C%20Michal%20Carpentier%2C%20Alexandra%20Maillard%2C%20Odalric%20Pliable%20rejection%20sampling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Erraqabi%2C%20Akram%20Valko%2C%20Michal%20Carpentier%2C%20Alexandra%20Maillard%2C%20Odalric%20Pliable%20rejection%20sampling%202016"
        },
        {
            "id": "13",
            "entry": "[13] Michael Evans and Tim Swartz. Approximating integrals via Monte Carlo and deterministic methods. Oxford Statistical Science Series. Oxford University Press, Oxford, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Evans%2C%20Michael%20Swartz%2C%20Tim%20Approximating%20integrals%20via%20Monte%20Carlo%20and%20deterministic%20methods%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Evans%2C%20Michael%20Swartz%2C%20Tim%20Approximating%20integrals%20via%20Monte%20Carlo%20and%20deterministic%20methods%202000"
        },
        {
            "id": "14",
            "entry": "[14] John Geweke. Bayesian inference in econometric models using monte carlo integration. Econometrica: Journal of the Econometric Society, pages 1317\u20131339, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Geweke%2C%20John%20Bayesian%20inference%20in%20econometric%20models%20using%20monte%20carlo%20integration%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Geweke%2C%20John%20Bayesian%20inference%20in%20econometric%20models%20using%20monte%20carlo%20integration%201989"
        },
        {
            "id": "15",
            "entry": "[15] Heikki Haario, Eero Saksman, and Johanna Tamminen. An adaptive metropolis algorithm. Bernoulli, 7(2):223\u2013242, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Haario%2C%20Heikki%20Saksman%2C%20Eero%20Tamminen%2C%20Johanna%20An%20adaptive%20metropolis%20algorithm%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Haario%2C%20Heikki%20Saksman%2C%20Eero%20Tamminen%2C%20Johanna%20An%20adaptive%20metropolis%20algorithm%202001"
        },
        {
            "id": "16",
            "entry": "[16] John Michael Hammersley and David Christopher Handscomb. General principles of the monte carlo method. In Monte Carlo Methods, pages 50\u201375.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hammersley%2C%20John%20Michael%20Handscomb%2C%20David%20Christopher%20General%20principles%20of%20the%20monte%20carlo%20method",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hammersley%2C%20John%20Michael%20Handscomb%2C%20David%20Christopher%20General%20principles%20of%20the%20monte%20carlo%20method"
        },
        {
            "id": "17",
            "entry": "[17] Lars Peter Hansen. Large sample properties of generalized method of moments estimators. Econometrica: Journal of the Econometric Society, pages 1029\u20131054, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hansen%2C%20Lars%20Peter%20Large%20sample%20properties%20of%20generalized%20method%20of%20moments%20estimators%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hansen%2C%20Lars%20Peter%20Large%20sample%20properties%20of%20generalized%20method%20of%20moments%20estimators%201982"
        },
        {
            "id": "18",
            "entry": "[18] Tatsunori B Hashimoto, Steve Yadlowsky, and John C Duchi. Derivative free optimization via repeated classification. arXiv preprint arXiv:1804.03761, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.03761"
        },
        {
            "id": "19",
            "entry": "[19] Tang Jie and Pieter Abbeel. On a connection between importance sampling and the likelihood ratio policy gradient. In Advances in Neural Information Processing Systems, pages 1000\u20131008, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jie%2C%20Tang%20Abbeel%2C%20Pieter%20On%20a%20connection%20between%20importance%20sampling%20and%20the%20likelihood%20ratio%20policy%20gradient%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jie%2C%20Tang%20Abbeel%2C%20Pieter%20On%20a%20connection%20between%20importance%20sampling%20and%20the%20likelihood%20ratio%20policy%20gradient%202010"
        },
        {
            "id": "20",
            "entry": "[20] Tuen Kloek and Herman K Van Dijk. Bayesian estimates of equation system parameters: an application of integration by monte carlo. Econometrica: Journal of the Econometric Society, pages 1\u201319, 1978.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kloek%2C%20Tuen%20Dijk%2C%20Herman%20K.Van%20Bayesian%20estimates%20of%20equation%20system%20parameters%3A%20an%20application%20of%20integration%20by%20monte%20carlo%201978",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kloek%2C%20Tuen%20Dijk%2C%20Herman%20K.Van%20Bayesian%20estimates%20of%20equation%20system%20parameters%3A%20an%20application%20of%20integration%20by%20monte%20carlo%201978"
        },
        {
            "id": "21",
            "entry": "[21] Qi Lou, Rina Dechter, and Alexander T Ihler. Dynamic importance sampling for anytime bounds of the partition function. In Advances in Neural Information Processing Systems, pages 3199\u20133207, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lou%2C%20Qi%20Dechter%2C%20Rina%20Ihler%2C%20Alexander%20T.%20Dynamic%20importance%20sampling%20for%20anytime%20bounds%20of%20the%20partition%20function%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lou%2C%20Qi%20Dechter%2C%20Rina%20Ihler%2C%20Alexander%20T.%20Dynamic%20importance%20sampling%20for%20anytime%20bounds%20of%20the%20partition%20function%202017"
        },
        {
            "id": "22",
            "entry": "[22] Jean-Michel Marin, Pierre Pudlo, and Mohammed Sedki. Consistency of the adaptive multiple importance sampling. arXiv preprint arXiv:1211.2548, 2012.",
            "arxiv_url": "https://arxiv.org/pdf/1211.2548"
        },
        {
            "id": "23",
            "entry": "[23] Jan C Neddermeyer. Computationally efficient nonparametric importance sampling. Journal of the American Statistical Association, 104(486):788\u2013802, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neddermeyer%2C%20Jan%20C.%20Computationally%20efficient%20nonparametric%20importance%20sampling%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neddermeyer%2C%20Jan%20C.%20Computationally%20efficient%20nonparametric%20importance%20sampling%202009"
        },
        {
            "id": "24",
            "entry": "[24] Chris J. Oates, Mark Girolami, and Nicolas Chopin. Control functionals for Monte Carlo integration. J. R. Statist. Soc. B, 79(3):695\u2013718, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oates%2C%20Chris%20J.%20Girolami%2C%20Mark%20Chopin%2C%20Nicolas%20Control%20functionals%20for%20Monte%20Carlo%20integration%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oates%2C%20Chris%20J.%20Girolami%2C%20Mark%20Chopin%2C%20Nicolas%20Control%20functionals%20for%20Monte%20Carlo%20integration%202017"
        },
        {
            "id": "25",
            "entry": "[25] Man-Suk Oh and James O. Berger. Adaptive importance sampling in Monte Carlo integration. J. Statist. Comput. Simulation, 41(3-4):143\u2013168, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oh%2C%20Man-Suk%20Berger%2C%20James%20O.%20Adaptive%20importance%20sampling%20in%20Monte%20Carlo%20integration%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oh%2C%20Man-Suk%20Berger%2C%20James%20O.%20Adaptive%20importance%20sampling%20in%20Monte%20Carlo%20integration%201992"
        },
        {
            "id": "26",
            "entry": "[26] Art Owen and Yi Zhou. Safe and effective importance sampling. J. Amer. Statist. Assoc., 95(449):135\u2013143, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Owen%2C%20Art%20Zhou%2C%20Yi%20Safe%20and%20effective%20importance%20sampling%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Owen%2C%20Art%20Zhou%2C%20Yi%20Safe%20and%20effective%20importance%20sampling%202000"
        },
        {
            "id": "27",
            "entry": "[27] Jan Peters, Katharina M\u00fclling, and Yasemin Altun. Relative entropy policy search. In AAAI, pages 1607\u20131612.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peters%2C%20Jan%20M%C3%BClling%2C%20Katharina%20Altun%2C%20Yasemin%20Relative%20entropy%20policy%20search",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peters%2C%20Jan%20M%C3%BClling%2C%20Katharina%20Altun%2C%20Yasemin%20Relative%20entropy%20policy%20search"
        },
        {
            "id": "28",
            "entry": "[28] Fran\u00e7ois Portier and Johan Segers. Monte carlo integration with a growing number of control variates. arXiv preprint arXiv:1801.01797, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.01797"
        },
        {
            "id": "29",
            "entry": "[29] Jean-Francois Richard and Wei Zhang. Efficient high-dimensional importance sampling. Journal of Econometrics, 141(2):1385\u20131411, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Richard%2C%20Jean-Francois%20Zhang%2C%20Wei%20Efficient%20high-dimensional%20importance%20sampling%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Richard%2C%20Jean-Francois%20Zhang%2C%20Wei%20Efficient%20high-dimensional%20importance%20sampling%202007"
        },
        {
            "id": "30",
            "entry": "[30] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy optimization. In International Conference on Machine Learning, pages 1889\u20131897, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schulman%2C%20John%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Jordan%2C%20Michael%20Trust%20region%20policy%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schulman%2C%20John%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Jordan%2C%20Michael%20Trust%20region%20policy%20optimization%202015"
        },
        {
            "id": "31",
            "entry": "[31] A. W. van der Vaart. Asymptotic statistics, volume 3 of Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20der%20Vaart%2C%20A.W.%20Asymptotic%20statistics%2C%20volume%203%20of%20Cambridge%20Series%20in%20Statistical%20and%20Probabilistic%20Mathematics%201998"
        },
        {
            "id": "32",
            "entry": "[32] Eric Veach and Leonidas J Guibas. Optimally combining sampling techniques for monte carlo rendering. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, pages 419\u2013428. ACM, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Veach%2C%20Eric%20Guibas%2C%20Leonidas%20J.%20Optimally%20combining%20sampling%20techniques%20for%20monte%20carlo%20rendering%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Veach%2C%20Eric%20Guibas%2C%20Leonidas%20J.%20Optimally%20combining%20sampling%20techniques%20for%20monte%20carlo%20rendering%201995"
        },
        {
            "id": "33",
            "entry": "[33] Ping Zhang. Nonparametric importance sampling. J. Amer. Statist. Assoc., 91(435):1245\u20131253, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Ping%20Nonparametric%20importance%20sampling%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Ping%20Nonparametric%20importance%20sampling%201996"
        },
        {
            "id": "34",
            "entry": "[34] Peilin Zhao and Tong Zhang. Stochastic optimization with importance sampling for regularized loss minimization. In international conference on machine learning, pages 1\u20139, 2015. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Peilin%20Zhang%2C%20Tong%20Stochastic%20optimization%20with%20importance%20sampling%20for%20regularized%20loss%20minimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Peilin%20Zhang%2C%20Tong%20Stochastic%20optimization%20with%20importance%20sampling%20for%20regularized%20loss%20minimization%202015"
        }
    ]
}
