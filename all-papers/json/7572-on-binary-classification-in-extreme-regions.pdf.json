{
    "filename": "7572-on-binary-classification-in-extreme-regions.pdf",
    "metadata": {
        "title": "On Binary Classification in Extreme Regions",
        "author": "Hamid JALALZAI, Stephan Cl\u00e9men\u00e7on, Anne Sabourin",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7572-on-binary-classification-in-extreme-regions.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In pattern recognition, a random label Y is to be predicted based upon observing a random vector X valued in Rd with d \u2265 1 by means of a classification rule with minimum probability of error. In a wide variety of applications, ranging from finance/insurance to environmental sciences through teletraffic data analysis for instance, extreme (i.e. very large) observations X are of crucial importance, while contributing in a negligible manner to the (empirical) error however, simply because of their rarity. As a consequence, empirical risk minimizers generally perform very poorly in extreme regions. It is the purpose of this paper to develop a general framework for classification in the extremes. Precisely, under non-parametric heavy-tail assumptions for the class distributions, we prove that a natural and asymptotic notion of risk, accounting for predictive performance in extreme regions of the input space, can be defined and show that minimizers of an empirical version of a non-asymptotic approximant of this dedicated risk, based on a fraction of the largest observations, lead to classification rules with good generalization capacity, by means of maximal deviation inequalities in low probability regions. Beyond theoretical results, numerical experiments are presented in order to illustrate the relevance of the approach developed."
    },
    "keywords": [
        {
            "term": "k-nearest neighbors",
            "url": "https://en.wikipedia.org/wiki/k-nearest_neighbors"
        },
        {
            "term": "pattern recognition",
            "url": "https://en.wikipedia.org/wiki/pattern_recognition"
        },
        {
            "term": "random forest",
            "url": "https://en.wikipedia.org/wiki/random_forest"
        },
        {
            "term": "environmental science",
            "url": "https://en.wikipedia.org/wiki/environmental_science"
        },
        {
            "term": "empirical risk minimization",
            "url": "https://en.wikipedia.org/wiki/empirical_risk_minimization"
        },
        {
            "term": "heavy tail",
            "url": "https://en.wikipedia.org/wiki/heavy_tail"
        }
    ],
    "highlights": [
        "Because it covers a wide range of practical applications and its probabilistic theory can be straightforwardly extended to some extent to various other prediction problems, binary classification can be considered as the flagship problem in statistical learning",
        "With respect to the goal set above we investigate the performance of minimizer gn,\u03c4 of an empirical version of the risk LPt\u03c4 , where t\u03c4 is the (1 \u2212 \u03c4 ) quantile of the r.v",
        "Multivariate extreme value theory (MEVT) notions involved in the framework we develop are described in section 2, together with the probabilistic setup we consider for classification in the extremes",
        "\u221a The upper bound stated above shows that the learning rate is of order OP(1/ k), where k is the actual size of the training data set used to perform approximate empirical risk minimization in the extremes",
        "We have developed a rigorous probabilistic framework for binary classification in extreme regions, relying on the theory of regularly varying random vectors, and proved the accuracy of the ERM approach in this context, when the risk functional is computed from extreme observations only"
    ],
    "key_statements": [
        "Because it covers a wide range of practical applications and its probabilistic theory can be straightforwardly extended to some extent to various other prediction problems, binary classification can be considered as the flagship problem in statistical learning",
        "With respect to the goal set above we investigate the performance of minimizer gn,\u03c4 of an empirical version of the risk LPt\u03c4 , where t\u03c4 is the (1 \u2212 \u03c4 ) quantile of the r.v",
        "Multivariate extreme value theory (MEVT) notions involved in the framework we develop are described in section 2, together with the probabilistic setup we consider for classification in the extremes",
        "\u221a The upper bound stated above shows that the learning rate is of order OP(1/ k), where k is the actual size of the training data set used to perform approximate empirical risk minimization in the extremes",
        "The purpose of our experiments is to provide insights into the performance of the classifier gk on extreme regions constructed via Algorithm 1.The training set is ordered as in Step 1 of Algorithm 1",
        "We have developed a rigorous probabilistic framework for binary classification in extreme regions, relying on the theory of regularly varying random vectors, and proved the accuracy of the ERM approach in this context, when the risk functional is computed from extreme observations only"
    ],
    "summary": [
        "Because it covers a wide range of practical applications and its probabilistic theory can be straightforwardly extended to some extent to various other prediction problems, binary classification can be considered as the flagship problem in statistical learning.",
        "The general aim is to build from training data in the extreme region such that Xi > tn for a large threshold value tn > 0) a classifier gn(x) with risk Ltn defined in (2) being asymptotically minimum as tn \u2192 \u221e.",
        "Assumption 1 For all \u03c3 \u2208 {\u2212, +}, the conditional distribution of X given Y = \u03c31 is regularly varying with index 1 and angular measure \u03a6\u03c3): for A \u2282 [0, \u221e]d \\ {0} a measurable set such that 0 \u2208/ \u2202A and \u03bc(\u2202A) = 0, tP",
        "The goal pursued is to construct a classifier gn, based on the training examples Dn, minimizing the asymptotic risk in the extremes given by",
        "As shall be seen below, under appropriate and natural assumptions, classifiers with minimum asymptotic risk in the extremes are in 1-to-1 correspondence with solutions of the binary classification problem related to (X\u221e, Y\u221e).",
        "Considering a collection of such models, oracle inequalities guaranteeing the quasi-optimality of the rule minimizing the penalized empirical risk can be classically established by means of a slight modification of the argument of Theorem 2\u2019s proof, see e.g. Chapter 18 in [<a class=\"ref-link\" id=\"c5\" href=\"#r5\">5</a>].",
        "\u221a The upper bound stated above shows that the learning rate is of order OP(1/ k), where k is the actual size of the training data set used to perform approximate empirical risk minimization in the extremes.",
        "The purpose of our experiments is to provide insights into the performance of the classifier gk on extreme regions constructed via Algorithm 1.The training set is ordered as in Step 1 of Algorithm 1.",
        "To approximate of the asymptotic risk in the extremes L\u221e and illustrate the generalization ability of the proposed classifier in the extreme region, we consider decreasing subsets of T .",
        "For each class GS, the performance of gk) of both training and testing data, in other words classifies the projected datasets onto the unit sphere is compared with that of the classical version of the algorithm (RF or k-NN) taking as input the same training data but without the standardization and truncation steps neither the projection onto the unit sphere.",
        "We have developed a rigorous probabilistic framework for binary classification in extreme regions, relying on the theory of regularly varying random vectors, and proved the accuracy of the ERM approach in this context, when the risk functional is computed from extreme observations only.",
        "The present contribution may open a new line of research, insofar as progress can be naturally expected in the design of algorithmic learning methods tailored to extreme points and statistical issues such as estimation of the minimum risk in the extremes, L\u221e \u2217 , remain to be addressed"
    ],
    "headline": "Under non-parametric heavy-tail assumptions for the class distributions, we prove that a natural and asymptotic notion of risk, accounting for predictive performance in extreme regions of the input space, can be defined and show that minimizers of an empirical version of a non-asymptotic approximant of this dedicated risk, based on a fraction of the largest observations, lead to classification rules with good generalization capacity, by means of maximal deviation inequalities in low probability regions",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] C. Brownlees, E. Joly, and G. Lugosi. Empirical risk minimization for heavy-tailed losses. Ann. Statist., 43(6):2507\u20132536, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brownlees%2C%20C.%20Joly%2C%20E.%20Lugosi%2C%20G.%20Empirical%20risk%20minimization%20for%20heavy-tailed%20losses%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brownlees%2C%20C.%20Joly%2C%20E.%20Lugosi%2C%20G.%20Empirical%20risk%20minimization%20for%20heavy-tailed%20losses%202015"
        },
        {
            "id": "2",
            "entry": "[2] J.J. Cai, J.H.J. Einmahl, and L. De Haan. Estimation of extreme risk regions under multivariate regular variation. The Annals of Statistics, pages 1803\u20131826, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cai%2C%20J.J.%20Einmahl%2C%20J.H.J.%20Haan%2C%20L.De%20Estimation%20of%20extreme%20risk%20regions%20under%20multivariate%20regular%20variation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cai%2C%20J.J.%20Einmahl%2C%20J.H.J.%20Haan%2C%20L.De%20Estimation%20of%20extreme%20risk%20regions%20under%20multivariate%20regular%20variation%202011"
        },
        {
            "id": "3",
            "entry": "[3] A. Carpentier and M. Valko. Extreme bandits. In Advances in Neural Information Processing Systems 27, pages 1089\u20131097. Curran Associates, Inc., 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carpentier%2C%20A.%20Valko%2C%20M.%20Extreme%20bandits%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carpentier%2C%20A.%20Valko%2C%20M.%20Extreme%20bandits%202014"
        },
        {
            "id": "4",
            "entry": "[4] L. De Haan and S. Resnick. On regular variation of probability densities. Stochastic processes and their applications, 25:83\u201393, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Haan%2C%20L.De%20Resnick%2C%20S.%20On%20regular%20variation%20of%20probability%20densities.%20Stochastic%20processes%20and%20their%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Haan%2C%20L.De%20Resnick%2C%20S.%20On%20regular%20variation%20of%20probability%20densities.%20Stochastic%20processes%20and%20their%201987"
        },
        {
            "id": "5",
            "entry": "[5] L. Devroye, L. Gyorfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Applications of mathematics : stochastic modelling and applied probability. U.S. Government Printing Office, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Devroye%2C%20L.%20Gyorfi%2C%20L.%20Lugosi%2C%20G.%20A%20Probabilistic%20Theory%20of%20Pattern%20Recognition.%20Applications%20of%20mathematics%20%3A%20stochastic%20modelling%20and%20applied%20probability.%20U%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Devroye%2C%20L.%20Gyorfi%2C%20L.%20Lugosi%2C%20G.%20A%20Probabilistic%20Theory%20of%20Pattern%20Recognition.%20Applications%20of%20mathematics%20%3A%20stochastic%20modelling%20and%20applied%20probability.%20U%201996"
        },
        {
            "id": "6",
            "entry": "[6] N. Goix, A. Sabourin, and S. Clemencon. Sparse representation of multivariate extremes with applications to anomaly ranking. In Artificial Intelligence and Statistics, pages 75\u201383, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goix%2C%20N.%20Sabourin%2C%20A.%20Clemencon%2C%20S.%20Sparse%20representation%20of%20multivariate%20extremes%20with%20applications%20to%20anomaly%20ranking%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goix%2C%20N.%20Sabourin%2C%20A.%20Clemencon%2C%20S.%20Sparse%20representation%20of%20multivariate%20extremes%20with%20applications%20to%20anomaly%20ranking%202016"
        },
        {
            "id": "7",
            "entry": "[7] N. Goix, A. Sabourin, and S. Clemencon. Sparse representation of multivariate extremes with applications to anomaly detection. Journal of Multivariate Analysis, 161:12\u201331, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goix%2C%20N.%20Sabourin%2C%20A.%20Clemencon%2C%20S.%20Sparse%20representation%20of%20multivariate%20extremes%20with%20applications%20to%20anomaly%20detection%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goix%2C%20N.%20Sabourin%2C%20A.%20Clemencon%2C%20S.%20Sparse%20representation%20of%20multivariate%20extremes%20with%20applications%20to%20anomaly%20detection%202017"
        },
        {
            "id": "8",
            "entry": "[8] S. Mendelson. Learning without concentration for general loss functions. Probability Theory and Related Fields, 171(1):459\u2013502, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mendelson%2C%20S.%20Learning%20without%20concentration%20for%20general%20loss%20functions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mendelson%2C%20S.%20Learning%20without%20concentration%20for%20general%20loss%20functions%202018"
        },
        {
            "id": "9",
            "entry": "[9] K. Nakai and M. Kanehisa. A knowledge base for predicting protein localization sites in eukaryotic cells. Genomics, 14(4):897\u2013911, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nakai%2C%20K.%20Kanehisa%2C%20M.%20A%20knowledge%20base%20for%20predicting%20protein%20localization%20sites%20in%20eukaryotic%20cells%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nakai%2C%20K.%20Kanehisa%2C%20M.%20A%20knowledge%20base%20for%20predicting%20protein%20localization%20sites%20in%20eukaryotic%20cells%201992"
        },
        {
            "id": "10",
            "entry": "[10] Mesrob I Ohannessian and Munther A Dahleh. Rare probability estimation under regularly varying heavy tails. In Conference on Learning Theory, pages 21\u20131, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Mesrob%20I%20Ohannessian%20and%20Munther%20A%20Dahleh.%20Rare%20probability%20estimation%20under%20regularly%20varying%20heavy%20tails%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Mesrob%20I%20Ohannessian%20and%20Munther%20A%20Dahleh.%20Rare%20probability%20estimation%20under%20regularly%20varying%20heavy%20tails%202012"
        },
        {
            "id": "11",
            "entry": "[11] S. Resnick. Extreme Values, Regular Variation, and Point Processes. Springer Series in Operations Research and Financial Engineering, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=S%20Resnick%20Extreme%20Values%20Regular%20Variation%20and%20Point%20Processes%20Springer%20Series%20in%20Operations%20Research%20and%20Financial%20Engineering%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=S%20Resnick%20Extreme%20Values%20Regular%20Variation%20and%20Point%20Processes%20Springer%20Series%20in%20Operations%20Research%20and%20Financial%20Engineering%201987"
        },
        {
            "id": "12",
            "entry": "[12] Teemu Roos, Peter Grunwald, Petri Myllymaki, and Henry Tirri. Generalization to unseen cases. In Y. Weiss, B. Scholkopf, and J. C. Platt, editors, Advances in Neural Information Processing Systems 18, pages 1129\u20131136. MIT Press, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roos%2C%20Teemu%20Grunwald%2C%20Peter%20Myllymaki%2C%20Petri%20Tirri%2C%20Henry%20Generalization%20to%20unseen%20cases%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roos%2C%20Teemu%20Grunwald%2C%20Peter%20Myllymaki%2C%20Petri%20Tirri%2C%20Henry%20Generalization%20to%20unseen%20cases%202006"
        },
        {
            "id": "13",
            "entry": "[13] A. Stephenson. Simulating multivariate extreme value distributions of logistic type. Extremes, 6(1):49\u201359, 2003. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stephenson%2C%20A.%20Simulating%20multivariate%20extreme%20value%20distributions%20of%20logistic%20type%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stephenson%2C%20A.%20Simulating%20multivariate%20extreme%20value%20distributions%20of%20logistic%20type%202003"
        }
    ]
}
