{
    "filename": "7345-on-learning-markov-chains.pdf",
    "metadata": {
        "title": "On Learning Markov Chains",
        "author": "Yi HAO, Alon Orlitsky, Venkatadheeraj Pichapati",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7345-on-learning-markov-chains.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "The problem of estimating an unknown discrete distribution from its samples is a fundamental tenet of statistical learning. Over the past decade, it attracted significant research effort and has been solved for a variety of divergence measures. Surprisingly, an equally important problem, estimating an unknown Markov chain from its samples, is still far from understood. We consider two problems related to the min-max risk (expected loss) of estimating an unknown k-state Markov chain from its n sequential samples: predicting the conditional distribution of the next sample with respect to the KL-divergence, and estimating the transition matrix with respect to a natural loss induced by KL or a more general f -divergence measure. For the first measure, we determine the min-max prediction risk to within a linear factor in the alphabet size, showing it is \u03a9(k log log n/n) and O(k2 log log n/n). For the second, if the transition probabilities can be arbitrarily small, then only trivial uniform risk upper bounds can be derived. We therefore consider transition probabilities that are bounded away from zero, and resolve the problem for essentially all sufficiently smooth f -divergences, including KL-, L2-, Chi-squared, Hellinger, and Alpha-divergences."
    },
    "keywords": [
        {
            "term": "discrete distribution",
            "url": "https://en.wikipedia.org/wiki/discrete_distribution"
        },
        {
            "term": "upper bound",
            "url": "https://en.wikipedia.org/wiki/upper_bound"
        },
        {
            "term": "transition probability",
            "url": "https://en.wikipedia.org/wiki/transition_probability"
        },
        {
            "term": "probabilistic model",
            "url": "https://en.wikipedia.org/wiki/probabilistic_model"
        },
        {
            "term": "log log",
            "url": "https://en.wikipedia.org/wiki/log_log"
        },
        {
            "term": "markov chain",
            "url": "https://en.wikipedia.org/wiki/markov_chain"
        }
    ],
    "highlights": [
        "An i.i.d. process is defined by a single distribution p over [k], while a Markov chain is characterized by a transition probability matrix M over [k] \u00d7 [k]",
        "The proof of the upper bound relies on a concentration inequality for Markov chains in Mk\u03b4 , which can be informally expressed as",
        "We studied the problem of learning an unknown k-state Markov chain from its n sequential sample points",
        "Future directions include closing the gap in the prediction problem in Section 1, extending the results on the min-max estimation problem to other classes of Markov chains, and extending the work from the classical setting k n, to general k and n"
    ],
    "key_statements": [
        "An i.i.d. process is defined by a single distribution p over [k], while a Markov chain is characterized by a transition probability matrix M over [k] \u00d7 [k]",
        "The proof of the upper bound relies on a concentration inequality for Markov chains in Mk\u03b4 , which can be informally expressed as",
        "We studied the problem of learning an unknown k-state Markov chain from its n sequential sample points",
        "Future directions include closing the gap in the prediction problem in Section 1, extending the results on the min-max estimation problem to other classes of Markov chains, and extending the work from the classical setting k n, to general k and n"
    ],
    "summary": [
        "An i.i.d. process is defined by a single distribution p over [k], while a Markov chain is characterized by a transition probability matrix M over [k] \u00d7 [k].",
        ", Xn from an unknown i.i.d. process or Markov chain, a natural problem is to predict the sample point Xn+1.",
        "We define the estimation risk of Mgiven sample sequence Xn as the maximum expected loss over all states, \u03b5nL(M, M",
        "Related Work For any f -divergence, we denote the corresponding minimax prediction risk for an n-element sample over set P by \u03c1fn(P).",
        "Let Mk denote the collection of all the Markov chains over [k].",
        "Our first main result determines the dependence of \u03c1KnL(Mk) on both k and n, to within a factor of roughly k: Theorem 1 The minimax KL-prediction risk of Markov chains satisfies",
        "2.1 Add-constant estimators Given a sample sequence Xn from an i.i.d. process (p), let Ni denote the number of times symbol i appears in Xn. The classical empirical estimator estimates p by pXn (i)",
        "A standard lower-bound argument for minimax prediction risk uses the fact that \u03c1nKL (P )",
        "The upper-bound proof applies the following lemma that uniformly bounds the hitting probability of any k-state Markov chain.",
        "Analogous to Section 3, we use the following standard argument to lower bound the minimax risk \u03b5nL(M",
        "The proof of the upper bound relies on a concentration inequality for Markov chains in Mk\u03b4 , which can be informally expressed as",
        "Let Xn be a length-n sample sequence drawn from the Markov chain (M ).",
        "The plots use the following abbreviations: Theo for theoretical minimax-risk values; Real for real experimental results: using the estimators described in Sections 4 and 6; Pre for average prediction loss \u221aand Est for average estimation loss; Const for add-constant estimator; Prop for proposed add-Ni/k estimator described in Section 6; Hell, Chi, and Alpha(c) for Hellinger divergence, Chi-squared divergence, and Alpha-divergence with parameter c.",
        "Figure 1a shows the decay of the experimental and theoretical KL-prediction and KL-estimation losses with the sample size n.",
        "When the transition probabilities are bounded away from zero, we obtained nearly matching lower and upper bounds on the minimax risk for L2 and ordinary f -divergences.",
        "Future directions include closing the gap in the prediction problem in Section 1, extending the results on the min-max estimation problem to other classes of Markov chains, and extending the work from the classical setting k n, to general k and n."
    ],
    "headline": "For L2-distance corresponding to the squared Euclidean norm, we prove the following risk bounds",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Moein Falahatgar, Mesrob I. Ohannessian, and Alon Orlitsky. Near-optimal smoothing of structured conditional probability matrices? In In Advances in Neural Information Processing Systems (NIPS), pages 4860\u20134868, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Falahatgar%2C%20Moein%20Ohannessian%2C%20Mesrob%20I.%20Orlitsky%2C%20Alon%20Near-optimal%20smoothing%20of%20structured%20conditional%20probability%20matrices%3F%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Falahatgar%2C%20Moein%20Ohannessian%2C%20Mesrob%20I.%20Orlitsky%2C%20Alon%20Near-optimal%20smoothing%20of%20structured%20conditional%20probability%20matrices%3F%202016"
        },
        {
            "id": "2",
            "entry": "[2] Edgar Gilbert. Codes based on inaccurate source probabilities. IEEE Transactions on Information Theory, 17, 3:304\u2013314, 1971.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilbert%2C%20Edgar%20Codes%20based%20on%20inaccurate%20source%20probabilities%201971",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilbert%2C%20Edgar%20Codes%20based%20on%20inaccurate%20source%20probabilities%201971"
        },
        {
            "id": "3",
            "entry": "[3] Thomas Cover. Admissibility properties or gilbert\u2019s encoding for unknown source probabilities (corresp.). IEEE Transactions on Information Theory, 18.1:216\u2013217, 1972.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20Thomas%20Admissibility%20properties%20or%20gilbert%E2%80%99s%20encoding%20for%20unknown%20source%20probabilities%20%28corresp.%29%201972",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cover%2C%20Thomas%20Admissibility%20properties%20or%20gilbert%E2%80%99s%20encoding%20for%20unknown%20source%20probabilities%20%28corresp.%29%201972"
        },
        {
            "id": "4",
            "entry": "[4] Raphail Krichevsky and Victor Trofimov. The performance of universal encoding. IEEE Transactions on Information Theory, 27.2:199\u2013207, 1981.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krichevsky%2C%20Raphail%20Trofimov%2C%20Victor%20The%20performance%20of%20universal%20encoding%201981",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krichevsky%2C%20Raphail%20Trofimov%2C%20Victor%20The%20performance%20of%20universal%20encoding%201981"
        },
        {
            "id": "5",
            "entry": "[5] Dietrich Braess, J\u00fcrgen Forster, Tomas Sauer, and Hans U. Simon. How to achieve minimax expected kullback-leibler distance from an unknown finite distribution. In International Conference on Algorithmic Learning Theory, pages 380\u2013394.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Braess%2C%20Dietrich%20Forster%2C%20J%C3%BCrgen%20Sauer%2C%20Tomas%20Simon%2C%20Hans%20U.%20How%20to%20achieve%20minimax%20expected%20kullback-leibler%20distance%20from%20an%20unknown%20finite%20distribution",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Braess%2C%20Dietrich%20Forster%2C%20J%C3%BCrgen%20Sauer%2C%20Tomas%20Simon%2C%20Hans%20U.%20How%20to%20achieve%20minimax%20expected%20kullback-leibler%20distance%20from%20an%20unknown%20finite%20distribution"
        },
        {
            "id": "6",
            "entry": "[6] Liam Paninski. Variational minimax estimation of discrete distributions under kl loss. In Advances in Neural Information Processing Systems, pages 1033\u20131040, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paninski%2C%20Liam%20Variational%20minimax%20estimation%20of%20discrete%20distributions%20under%20kl%20loss%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Paninski%2C%20Liam%20Variational%20minimax%20estimation%20of%20discrete%20distributions%20under%20kl%20loss%202004"
        },
        {
            "id": "7",
            "entry": "[7] Dietrich Braess and Thomas Sauer. Bernstein polynomials and learning theory. Journal of Approximation Theory, 128(2):187\u2013206, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Braess%2C%20Dietrich%20Sauer%2C%20Thomas%20Bernstein%20polynomials%20and%20learning%20theory%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Braess%2C%20Dietrich%20Sauer%2C%20Thomas%20Bernstein%20polynomials%20and%20learning%20theory%202004"
        },
        {
            "id": "8",
            "entry": "[8] I. Csisz\u00e1r. Information type measures of differences of probability distribution and indirect observations. Studia Math. Hungarica, 2:299\u2013318, 1967.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Csisz%C3%A1r%2C%20I.%20Information%20type%20measures%20of%20differences%20of%20probability%20distribution%20and%20indirect%20observations%201967",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Csisz%C3%A1r%2C%20I.%20Information%20type%20measures%20of%20differences%20of%20probability%20distribution%20and%20indirect%20observations%201967"
        },
        {
            "id": "9",
            "entry": "[9] Frank Nielsen and Richard Nock. On the chi square and higher-order chi distances for approximating f-divergences. IEEE Signal Processing Letters, 21, no. 1:10\u201313, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nielsen%2C%20Frank%20Nock%2C%20Richard%20On%20the%20chi%20square%20and%20higher-order%20chi%20distances%20for%20approximating%20f-divergences%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nielsen%2C%20Frank%20Nock%2C%20Richard%20On%20the%20chi%20square%20and%20higher-order%20chi%20distances%20for%20approximating%20f-divergences%202014"
        },
        {
            "id": "10",
            "entry": "[10] Solomon Kullback and Richard A. Leibler. On information and sufficiency. The Annals of Mathematical Statistics, 22, no. 1:79\u201386, 1951.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kullback%2C%20Solomon%20Leibler%2C%20Richard%20A.%20On%20information%20and%20sufficiency%201951",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kullback%2C%20Solomon%20Leibler%2C%20Richard%20A.%20On%20information%20and%20sufficiency%201951"
        },
        {
            "id": "11",
            "entry": "[11] Mikhail S Nikulin. Hellinger distance. Encyclopedia of mathematics, 151, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nikulin%2C%20Mikhail%20S.%20Hellinger%20distance%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nikulin%2C%20Mikhail%20S.%20Hellinger%20distance%202001"
        },
        {
            "id": "12",
            "entry": "[12] Gavin E. Crooks. On measures of entropy and information. Tech. Note 9 (2017): v4, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crooks%2C%20Gavin%20E.%20On%20measures%20of%20entropy%20and%20information%202017"
        },
        {
            "id": "13",
            "entry": "[13] Sudeep Kamath, Alon Orlitsky, Dheeraj Pichapati, and Ananda Theertha Suresh. On learning distributions from their samples. In Annual Conference on Learning Theory (COLT), pages 1066\u20131100, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamath%2C%20Sudeep%20Orlitsky%2C%20Alon%20Pichapati%2C%20Dheeraj%20and%20Ananda%20Theertha%20Suresh.%20On%20learning%20distributions%20from%20their%20samples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamath%2C%20Sudeep%20Orlitsky%2C%20Alon%20Pichapati%2C%20Dheeraj%20and%20Ananda%20Theertha%20Suresh.%20On%20learning%20distributions%20from%20their%20samples%202015"
        },
        {
            "id": "14",
            "entry": "[14] Alon Orlitsky and Ananda Theertha Suresh. Competitive distribution estimation: Why is good-turing good. In Advances in Neural Information Processing Systems, pages 2143\u20132151, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=-%20Alon%20Orlitsky%20and%20Ananda%20Theertha%20Suresh.%20Competitive%20distribution%20estimation%3A%20Why%20is%20good-turing%20good%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=-%20Alon%20Orlitsky%20and%20Ananda%20Theertha%20Suresh.%20Competitive%20distribution%20estimation%3A%20Why%20is%20good-turing%20good%202015"
        },
        {
            "id": "15",
            "entry": "[15] Gregory Valiant and Paul Valiant. Instance optimal learning of discrete distributions. In 48th annual ACM symposium on Theory of Computing, pages 142\u2013155, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Valiant%2C%20Gregory%20Valiant%2C%20Paul%20Instance%20optimal%20learning%20of%20discrete%20distributions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Valiant%2C%20Gregory%20Valiant%2C%20Paul%20Instance%20optimal%20learning%20of%20discrete%20distributions%202016"
        },
        {
            "id": "16",
            "entry": "[16] Moein Falahatgar, Alon Orlitsky, Venkatadheeraj Pichapati, and Ananda Theertha Suresh. Learning markov distributions: Does estimation trump compression? In IEEE International Symposium on Information Theory (ISIT), pages 2689\u20132693, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Falahatgar%2C%20Moein%20Orlitsky%2C%20Alon%20Pichapati%2C%20Venkatadheeraj%20and%20Ananda%20Theertha%20Suresh.%20Learning%20markov%20distributions%3A%20Does%20estimation%20trump%20compression%3F%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Falahatgar%2C%20Moein%20Orlitsky%2C%20Alon%20Pichapati%2C%20Venkatadheeraj%20and%20Ananda%20Theertha%20Suresh.%20Learning%20markov%20distributions%3A%20Does%20estimation%20trump%20compression%3F%202016"
        },
        {
            "id": "17",
            "entry": "[17] Geoffrey Wolfer and Aryeh Kontorovich. Minimax learning of ergodic markov chains. arXiv:1809.05014, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1809.05014"
        },
        {
            "id": "18",
            "entry": "[18] Kai Lai Chung and Farid AitSahlia. Elementary probability theory: With stochastic processes and an introduction to mathematical finance. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Kai%20Lai%20AitSahlia%2C%20Farid%20Elementary%20probability%20theory%3A%20With%20stochastic%20processes%20and%20an%20introduction%20to%20mathematical%20finance%202012"
        },
        {
            "id": "19",
            "entry": "[19] Christopher M. Bishop and Tom M. Mitchell. Pattern recognition and machine learning. Springer, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bishop%2C%20Christopher%20M.%20Mitchell%2C%20Tom%20M.%20Pattern%20recognition%20and%20machine%20learning%202006"
        },
        {
            "id": "20",
            "entry": "[20] David A.Levin and Yuval Peres. Markov chains and mixing Times. American Mathematical Soc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levin%2C%20David%20A.%20Peres%2C%20Yuval%20Markov%20chains%20and%20mixing%20Times%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levin%2C%20David%20A.%20Peres%2C%20Yuval%20Markov%20chains%20and%20mixing%20Times%202017"
        },
        {
            "id": "21",
            "entry": "[21] James Norris, Yuval Peres, and Alex Zhai. Surprise probabilities in markov chains. Combinatorics, Probability and Computing, 26.4:603\u2013627, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Norris%2C%20James%20Peres%2C%20Yuval%20Zhai%2C%20Alex%20Surprise%20probabilities%20in%20markov%20chains%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Norris%2C%20James%20Peres%2C%20Yuval%20Zhai%2C%20Alex%20Surprise%20probabilities%20in%20markov%20chains%202017"
        },
        {
            "id": "22",
            "entry": "[22] Fan RK Chung and Linyuan Lu. Complex graphs and networks. American Mathematical Soc., 2006. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Fan%20R.K.%20Lu%2C%20Linyuan%20Complex%20graphs%20and%20networks%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chung%2C%20Fan%20R.K.%20Lu%2C%20Linyuan%20Complex%20graphs%20and%20networks%202006"
        }
    ]
}
