{
    "filename": "8045-efficient-online-portfolio-with-logarithmic-regret.pdf",
    "metadata": {
        "title": "Efficient Online Portfolio with Logarithmic Regret",
        "author": "Haipeng Luo, Chen-Yu Wei, Kai Zheng",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8045-efficient-online-portfolio-with-logarithmic-regret.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We study the decades-old problem of online portfolio management and propose the first algorithm with logarithmic regret that is not based on Cover\u2019s Universal Portfolio algorithm and admits much faster implementation. Specifically Universal Portfolio enjoys optimal regret O(N ln T ) for N financial instruments over T rounds, but requires log-concave sampling and has a large polynomial running time. Our algorithm, on the other hand, ensures a slightly larger but still logarithmic regret of O(N 2(ln T )4), and is based on the well-studied Online Mirror Descent framework with a novel regularizer that can be implemented via standard optimization methods in time O(T N 2.5) per round. The regret of all other existing works is either polynomial in T or has a potentially unbounded factor such as the inverse of the smallest price relative."
    },
    "keywords": [
        {
            "term": "financial instrument",
            "url": "https://en.wikipedia.org/wiki/financial_instrument"
        },
        {
            "term": "portfolio management",
            "url": "https://en.wikipedia.org/wiki/portfolio_management"
        },
        {
            "term": "online convex optimization",
            "url": "https://en.wikipedia.org/wiki/online_convex_optimization"
        }
    ],
    "highlights": [
        "We consider the well-known online portfolio management problem [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], where a learner has to sequentially decide how to allocate her wealth over a set of N financial instruments in order to maximize her return, importantly under no assumptions at all on how the market behaves",
        "We show in Table 1 the regret and time complexity of existing works and ours, where for Online Mirror Descent/FTRL-type algorithms we do a naive calculation of the running time based on the Interior Point Method [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], despite the possibility of even faster implementation",
        "We propose a more adaptive tuning schedule for these learning rates based on Eq (1), but the key idea is the same: increase the learning rate for a stock when its weight is small so that the algorithm learns faster in case the stock becomes better in the future",
        "Under the same condition on \u03b2 as for Online Newton Step, we prove the following key theorem for BARrier-Regularized Online Newton Step which highlights the important negative regret term obtained from the extra log-barrier regularizer",
        "We prove the claimed regret bound of ADA-BARrier-Regularized Online Newton Step",
        "We have shown that our new algorithm ADA-BARrier-Regularized Online Newton Step achieves logarithmic regret of O(N 24) for online portfolio with much faster running time compared to Universal Portfolio, the only previous algorithm with truly logarithmic regret"
    ],
    "key_statements": [
        "We consider the well-known online portfolio management problem [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], where a learner has to sequentially decide how to allocate her wealth over a set of N financial instruments in order to maximize her return, importantly under no assumptions at all on how the market behaves",
        "N N T N 2.5 of Online Newton Step with a small amount o\u221af uniform distribution, which after optimal trade-off can at best lead to a regret bound of O(N T ln T \u2212 128N )",
        "An earlier work [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] achieves a worse regret bound of O(G2N ln(N T )) via an efficient algorithm based on another well-known framework Follow-theRegularized-Leader (FTRL)",
        "Are there algorithms with optimal regret and similar or even better time complexity compared to Online Newton Step?",
        "We show in Table 1 the regret and time complexity of existing works and ours, where for Online Mirror Descent/FTRL-type algorithms we do a naive calculation of the running time based on the Interior Point Method [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], despite the possibility of even faster implementation",
        "Similar observations were made in previous work [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] for different problems in the bandit setting, where they introduced the log-barrier regularizer with increasing learning rate to explicitly ensure a large negative regret term based on the intuition above",
        "We propose a more adaptive tuning schedule for these learning rates based on Eq (1), but the key idea is the same: increase the learning rate for a stock when its weight is small so that the algorithm learns faster in case the stock becomes better in the future",
        "Under the same condition on \u03b2 as for Online Newton Step, we prove the following key theorem for BARrier-Regularized Online Newton Step which highlights the important negative regret term obtained from the extra log-barrier regularizer",
        "We prove the following key lemma based on the discussions above",
        "We prove the claimed regret bound of ADA-BARrier-Regularized Online Newton Step",
        "We have shown that our new algorithm ADA-BARrier-Regularized Online Newton Step achieves logarithmic regret of O(N 24) for online portfolio with much faster running time compared to Universal Portfolio, the only previous algorithm with truly logarithmic regret"
    ],
    "summary": [
        "We consider the well-known online portfolio management problem [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>], where a learner has to sequentially decide how to allocate her wealth over a set of N financial instruments in order to maximize her return, importantly under no assumptions at all on how the market behaves.",
        "The minimax optimal regret for this problem is O(N ln T ), achieved by Cover\u2019s Universal Portfolio algorithm [<a class=\"ref-link\" id=\"c8\" href=\"#r8\">8</a>].",
        "Time T 14N 4 N 3.5 T N 2.5 N N T N 2.5 of ONS with a small amount o\u221af uniform distribution, which after optimal trade-off can at best lead to a regret bound of O(N T ln T ).",
        "An earlier work [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>] achieves a worse regret bound of O(G2N ln(N T )) via an efficient algorithm based on another well-known framework Follow-theRegularized-Leader (FTRL).",
        "Are there algorithms with optimal regret and similar or even better time complexity compared to ONS?",
        "We make a significant step toward answering this question by proposing a simple algorithm with regret O(N 24) and time complexity O(T N 2.5) per round.",
        "We show in Table 1 the regret and time complexity of existing works and ours, where for OMD/FTRL-type algorithms we do a naive calculation of the running time based on the Interior Point Method [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>], despite the possibility of even faster implementation.",
        "3A recent work [<a class=\"ref-link\" id=\"c6\" href=\"#r6\">6</a>] uses a mixture of the Shannon entropy and log-barrier as the regularizer for a different problem.",
        "Similar observations were made in previous work [<a class=\"ref-link\" id=\"c2\" href=\"#r2\">2</a>, <a class=\"ref-link\" id=\"c21\" href=\"#r21\">21</a>] for different problems in the bandit setting, where they introduced the log-barrier regularizer with increasing learning rate to explicitly ensure a large negative regret term based on the intuition above.",
        "We call this algorithm BARrier-Regularized Online Newton Step (BARRONS).",
        "Under the same condition on \u03b2 as for ONS, we prove the following key theorem for BARRONS which highlights the important negative regret term obtained from the extra log-barrier regularizer.",
        "It is not hard to see that ut\u22121 will have similar total loss compared to the actual best CRP ut\u2217\u22121, leading to the desired regret bound overall.",
        "We prove the claimed regret bound of ADA-BARRONS.",
        "A\u2212t 1\u2207t, where \u03c6t is the log-barrier regularizer defined in the proof of Lemma 6.",
        "Analysis of ADA-BARRONS To prove Lemma 2, we make use of the following stability lemmas whose proofs are deferred to Appendix B.",
        "We have shown that our new algorithm ADA-BARRONS achieves logarithmic regret of O(N 24) for online portfolio with much faster running time compared to Universal Portfolio, the only previous algorithm with truly logarithmic regret.",
        "It is a conjecture that it might be impossible to have the optimal regret with O(N ) computations per round [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>]"
    ],
    "headline": "We study the decades-old problem of online portfolio management and propose the first algorithm with logarithmic regret that is not based on Cover\u2019s Universal Portfolio algorithm and admits much faster implementation",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] Jacob D Abernethy, Elad Hazan, and Alexander Rakhlin. Interior-point methods for fullinformation and bandit online learning. IEEE Transactions on Information Theory, 58(7):4164\u2013 4175, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abernethy%2C%20Jacob%20D.%20Hazan%2C%20Elad%20Rakhlin%2C%20Alexander%20Interior-point%20methods%20for%20fullinformation%20and%20bandit%20online%20learning%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abernethy%2C%20Jacob%20D.%20Hazan%2C%20Elad%20Rakhlin%2C%20Alexander%20Interior-point%20methods%20for%20fullinformation%20and%20bandit%20online%20learning%202012"
        },
        {
            "id": "2",
            "entry": "[2] Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, and Robert E Schapire. Corralling a band of bandit algorithms. In Conference on Learning Theory, pages 12\u201338, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Alekh%20Luo%2C%20Haipeng%20Neyshabur%2C%20Behnam%20Schapire%2C%20Robert%20E.%20Corralling%20a%20band%20of%20bandit%20algorithms%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Alekh%20Luo%2C%20Haipeng%20Neyshabur%2C%20Behnam%20Schapire%2C%20Robert%20E.%20Corralling%20a%20band%20of%20bandit%20algorithms%202017"
        },
        {
            "id": "3",
            "entry": "[3] Amit Agarwal and Elad Hazan. Efficient algorithms for online game playing and universal portfolio management. Electronic Colloquium on Computational Complexity, TR06-033, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Amit%20Hazan%2C%20Elad%20Efficient%20algorithms%20for%20online%20game%20playing%20and%20universal%20portfolio%20management%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Amit%20Hazan%2C%20Elad%20Efficient%20algorithms%20for%20online%20game%20playing%20and%20universal%20portfolio%20management%202005"
        },
        {
            "id": "4",
            "entry": "[4] Amit Agarwal, Elad Hazan, Satyen Kale, and Robert E Schapire. Algorithms for portfolio management based on the newton method. In Proceedings of the 23rd international conference on Machine learning, pages 9\u201316, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Amit%20Hazan%2C%20Elad%20Kale%2C%20Satyen%20Schapire%2C%20Robert%20E.%20Algorithms%20for%20portfolio%20management%20based%20on%20the%20newton%20method%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Amit%20Hazan%2C%20Elad%20Kale%2C%20Satyen%20Schapire%2C%20Robert%20E.%20Algorithms%20for%20portfolio%20management%20based%20on%20the%20newton%20method%202006"
        },
        {
            "id": "5",
            "entry": "[5] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20Stephen%20Vandenberghe%2C%20Lieven%20Convex%20optimization%202004"
        },
        {
            "id": "6",
            "entry": "[6] S\u00e9bastien Bubeck, Michael B. Cohen, and Yuanzhi Li. Sparsity, variance and curvature in multi-armed bandits. In International Conference on Algorithmic Learning Theory, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bubeck%2C%20S%C3%A9bastien%20Cohen%2C%20Michael%20B.%20Li%2C%20Yuanzhi%20Sparsity%2C%20variance%20and%20curvature%20in%20multi-armed%20bandits%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bubeck%2C%20S%C3%A9bastien%20Cohen%2C%20Michael%20B.%20Li%2C%20Yuanzhi%20Sparsity%2C%20variance%20and%20curvature%20in%20multi-armed%20bandits%202018"
        },
        {
            "id": "7",
            "entry": "[7] S\u00e9bastien Bubeck, Ronen Eldan, and Joseph Lehec. Sampling from a log-concave distribution with projected langevin monte carlo. arXiv preprint arXiv:1507.02564, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.02564"
        },
        {
            "id": "8",
            "entry": "[8] Thomas M Cover. Universal portfolios. Mathematical Finance, 1(1):1\u201329, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20Thomas%20M.%20Universal%20portfolios%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cover%2C%20Thomas%20M.%20Universal%20portfolios%201991"
        },
        {
            "id": "9",
            "entry": "[9] Thomas M Cover. Universal data compression and portfolio selection. In Foundations of Computer Science, 1996. Proceedings., 37th Annual Symposium on, pages 534\u2013538. IEEE, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20Thomas%20M.%20Universal%20data%20compression%20and%20portfolio%20selection%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cover%2C%20Thomas%20M.%20Universal%20data%20compression%20and%20portfolio%20selection%201996"
        },
        {
            "id": "10",
            "entry": "[10] Dylan J Foster, Zhiyuan Li, Thodoris Lykouris, Karthik Sridharan, and Eva Tardos. Learning in games: Robustness of fast convergence. In Advances in Neural Information Processing Systems, pages 4734\u20134742, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Foster%2C%20Dylan%20J.%20Li%2C%20Zhiyuan%20Lykouris%2C%20Thodoris%20Sridharan%2C%20Karthik%20Learning%20in%20games%3A%20Robustness%20of%20fast%20convergence%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Foster%2C%20Dylan%20J.%20Li%2C%20Zhiyuan%20Lykouris%2C%20Thodoris%20Sridharan%2C%20Karthik%20Learning%20in%20games%3A%20Robustness%20of%20fast%20convergence%202016"
        },
        {
            "id": "11",
            "entry": "[11] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119\u2013139, August 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20A%20decision-theoretic%20generalization%20of%20on-line%20learning%20and%20an%20application%20to%20boosting%201997-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20A%20decision-theoretic%20generalization%20of%20on-line%20learning%20and%20an%20application%20to%20boosting%201997-08"
        },
        {
            "id": "12",
            "entry": "[12] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169\u2013192, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Agarwal%2C%20Amit%20Kale%2C%20Satyen%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Agarwal%2C%20Amit%20Kale%2C%20Satyen%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007"
        },
        {
            "id": "13",
            "entry": "[13] Elad Hazan et al. Introduction to online convex optimization. Foundations and Trends R in Optimization, 2(3-4):157\u2013325, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Introduction%20to%20online%20convex%20optimization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Introduction%20to%20online%20convex%20optimization%202016"
        },
        {
            "id": "14",
            "entry": "[14] David P Helmbold, Robert E Schapire, Yoram Singer, and Manfred K Warmuth. On-line portfolio selection using multiplicative updates. Mathematical Finance, 8(4):325\u2013347, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Helmbold%2C%20David%20P.%20Schapire%2C%20Robert%20E.%20Singer%2C%20Yoram%20Warmuth%2C%20Manfred%20K.%20On-line%20portfolio%20selection%20using%20multiplicative%20updates%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Helmbold%2C%20David%20P.%20Schapire%2C%20Robert%20E.%20Singer%2C%20Yoram%20Warmuth%2C%20Manfred%20K.%20On-line%20portfolio%20selection%20using%20multiplicative%20updates%201998"
        },
        {
            "id": "15",
            "entry": "[15] Adam Kalai and Santosh Vempala. Efficient algorithms for universal portfolios. Journal of Machine Learning Research, 3(Nov):423\u2013440, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kalai%2C%20Adam%20Vempala%2C%20Santosh%20Efficient%20algorithms%20for%20universal%20portfolios%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kalai%2C%20Adam%20Vempala%2C%20Santosh%20Efficient%20algorithms%20for%20universal%20portfolios%202002"
        },
        {
            "id": "16",
            "entry": "[16] L\u00e1szl\u00f3 Lov\u00e1sz and Santosh Vempala. Fast algorithms for logconcave functions: Sampling, rounding, integration and optimization. In Foundations of Computer Science, 2006. FOCS\u201906. 47th Annual IEEE Symposium on, pages 57\u201368. IEEE, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lov%C3%A1sz%2C%20L%C3%A1szl%C3%B3%20Vempala%2C%20Santosh%20Fast%20algorithms%20for%20logconcave%20functions%3A%20Sampling%2C%20rounding%2C%20integration%20and%20optimization%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lov%C3%A1sz%2C%20L%C3%A1szl%C3%B3%20Vempala%2C%20Santosh%20Fast%20algorithms%20for%20logconcave%20functions%3A%20Sampling%2C%20rounding%2C%20integration%20and%20optimization%202006"
        },
        {
            "id": "17",
            "entry": "[17] Hariharan Narayanan and Alexander Rakhlin. Random walk approach to regret minimization. In Advances in Neural Information Processing Systems, pages 1777\u20131785, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Narayanan%2C%20Hariharan%20Rakhlin%2C%20Alexander%20Random%20walk%20approach%20to%20regret%20minimization%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Narayanan%2C%20Hariharan%20Rakhlin%2C%20Alexander%20Random%20walk%20approach%20to%20regret%20minimization%202010"
        },
        {
            "id": "18",
            "entry": "[18] Yurii Nesterov and Arkadii Nemirovskii. Interior-point polynomial algorithms in convex programming, volume 13.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Nemirovskii%2C%20Arkadii%20Interior-point%20polynomial%20algorithms",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Nemirovskii%2C%20Arkadii%20Interior-point%20polynomial%20algorithms"
        },
        {
            "id": "19",
            "entry": "[19] Laurent Orseau, Tor Lattimore, and Shane Legg. Soft-bayes: Prod for mixtures of experts with log-loss. In International Conference on Algorithmic Learning Theory, pages 372\u2013399, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Orseau%2C%20Laurent%20Lattimore%2C%20Tor%20Legg%2C%20Shane%20Soft-bayes%3A%20Prod%20for%20mixtures%20of%20experts%20with%20log-loss%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Orseau%2C%20Laurent%20Lattimore%2C%20Tor%20Legg%2C%20Shane%20Soft-bayes%3A%20Prod%20for%20mixtures%20of%20experts%20with%20log-loss%202017"
        },
        {
            "id": "20",
            "entry": "[20] Tim van Erven, Dirk van der Hoeven, and Wouter Koolen. personal communication, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20Erven%2C%20Tim%20van%20der%20Hoeven%2C%20Dirk%20Koolen%2C%20Wouter%20personal%20communication%202018"
        },
        {
            "id": "21",
            "entry": "[21] Chen-Yu Wei and Haipeng Luo. More adaptive algorithms for adversarial bandits. In Conference on Learning Theory, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wei%2C%20Chen-Yu%20Luo%2C%20Haipeng%20More%20adaptive%20algorithms%20for%20adversarial%20bandits%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wei%2C%20Chen-Yu%20Luo%2C%20Haipeng%20More%20adaptive%20algorithms%20for%20adversarial%20bandits%202018"
        },
        {
            "id": "22",
            "entry": "[22] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th International Conference on Machine Learning, pages 928\u2013936, 2003. ",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zinkevich%2C%20Martin%20Online%20convex%20programming%20and%20generalized%20infinitesimal%20gradient%20ascent%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zinkevich%2C%20Martin%20Online%20convex%20programming%20and%20generalized%20infinitesimal%20gradient%20ascent%202003"
        }
    ]
}
