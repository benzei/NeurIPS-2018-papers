{
    "filename": "8008-preference-based-adaptation-for-learning-objectives.pdf",
    "metadata": {
        "title": "Preference Based Adaptation for Learning Objectives",
        "author": "Yao-Xiang Ding, Zhi-Hua Zhou",
        "date": 2018,
        "identifiers": {
            "url": "https://papers.nips.cc/paper/8008-preference-based-adaptation-for-learning-objectives.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "In many real-world learning tasks, it is hard to directly optimize the true performance measures, meanwhile choosing the right surrogate objectives is also difficult. Under this situation, it is desirable to incorporate an optimization of objective process into the learning loop based on weak modeling of the relationship between the true measure and the objective. In this work, we discuss the task of objective adaptation, in which the learner iteratively adapts the learning objective to the underlying true objective based on the preference feedback from an oracle. We show that when the objective can be linearly parameterized, this preference based learning problem can be solved by utilizing the dueling bandit model. A novel sampling based algorithm DL2M is proposed to learn the optimal parameter, which enjoys strong theoretical guarantees and efficient empirical performance. To avoid learning a hypothesis from scratch after each objective function update, a boosting based hypothesis adaptation approach is proposed to efficiently adapt any pre-learned element hypotheses to the current objective. We apply the overall approach to multi-label learning, and show that the proposed approach achieves significant performance under various multi-label performance measures."
    },
    "keywords": [
        {
            "term": "performance measure",
            "url": "https://en.wikipedia.org/wiki/performance_measure"
        },
        {
            "term": "multi-objective optimization",
            "url": "https://en.wikipedia.org/wiki/multi-objective_optimization"
        },
        {
            "term": "bandit model",
            "url": "https://en.wikipedia.org/wiki/bandit_model"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "objective function",
            "url": "https://en.wikipedia.org/wiki/objective_function"
        }
    ],
    "highlights": [
        "Machine learning approaches have already been applied on many real-world tasks, in which the target is usually to optimize some task-specific performance measures",
        "We provide regret guarantee for the proposed algorithm, whose proof will be presented in a longer version of the paper. \u221a",
        "The DL2M algorithm is proposed under this setting, which can efficiently solve the objective adaptation problem based on the dueling bandit model",
        "The Adapt-Boost method is proposed in order to adapt the pre-learned element classifiers to the new objective with low cost",
        "To further investigate the objective adaptation problem, it is possible to relax the linear combinaiton formulation of the objective function adopted in this work"
    ],
    "key_statements": [
        "Machine learning approaches have already been applied on many real-world tasks, in which the target is usually to optimize some task-specific performance measures",
        "We provide regret guarantee for the proposed algorithm, whose proof will be presented in a longer version of the paper. \u221a",
        "The DL2M algorithm is proposed under this setting, which can efficiently solve the objective adaptation problem based on the dueling bandit model",
        "The Adapt-Boost method is proposed in order to adapt the pre-learned element classifiers to the new objective with low cost",
        "To further investigate the objective adaptation problem, it is possible to relax the linear combinaiton formulation of the objective function adopted in this work"
    ],
    "summary": [
        "Machine learning approaches have already been applied on many real-world tasks, in which the target is usually to optimize some task-specific performance measures.",
        "The target of objective adaptation is to learn the optimal w\u2217 which corresponds to the best trade-off leading to the optimal task performance measure.",
        "Since the target is to optimize the single total objective, directly utilizing multi-task learning approaches is invalid to our problem.",
        "Our approach utilizes a gradient boosting based learner, which can use any weak hypothesis for adaptation, and make the optimization much more efficient.",
        "A dueling bandit algorithm DL2M is proposed to learn the optimal weight vector w\u2217 from preference feedback to solve the objective adaptation task.",
        "The experimental results in Section 5 show that DL2M is efficient in finding the best arms, and we leave designing the optimal pure exploration algorithm for continuous dueling bandits a future work to investigate.",
        "H = [h1 h2 \u00b7 \u00b7 \u00b7 hN ]T the vector of all learned weak hypotheses and set w0 = 1, Adapt-Boost solves the following l1-regularized problem: Fw",
        "It can be seen that Adapt-Boost utilizes a boosting based process to gradually add the element and weak hypotheses into the learned hypothesis instead of explicitly setting their weights.",
        "Thanks to the flexability of choosing the weak learners and the efficiency of gradient boosting, we are able to solve complex hypothesis adaptation problems with low cost.",
        "The stochastic gradient descent (SGD) based LIMO algorithm is proposed to jointly optimize the both margins, in order to achieve good performance on different measures simultaneously.",
        "We will show that by utilizing DL2M and Adapt-Boost, we can automatically find the proper weights between the two margin losses in LIMO\u2019s objective, and efficiently adapt to different performance measures.",
        "The preference feedback is generated by testing the learned hypothesis on the validation set, and DL2M is utilized to update the objective for 20 iterations, with c = 0.05, \u03bb = 1.",
        "It can be seen that DL2M based method ADAPT-obj achieve better performance than LIMO, which assigns fixed weights to the two margin losses.",
        "It shows that by utilizing DL2M and Adapt-Boost, we can effectively solve the objective and hypothesis adaptation problem better and faster.",
        "The DL2M algorithm is proposed under this setting, which can efficiently solve the objective adaptation problem based on the dueling bandit model.",
        "The Adapt-Boost method is proposed in order to adapt the pre-learned element classifiers to the new objective with low cost.",
        "It is interesting to investigate Adapt-Boost on problems with larger scale, as well as to study its theoretical guarantees"
    ],
    "headline": "We show that when the objective can be linearly parameterized, this preference based learning problem can be solved by utilizing the dueling bandit model",
    "reference_links": [
        {
            "id": "Abbasi-Yadkori_et+al_2011_a",
            "entry": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. In NIPS, pages 2312\u20132320, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abbasi-Yadkori%2C%20Yasin%20P%C3%A1l%2C%20D%C3%A1vid%20Szepesv%C3%A1ri%2C%20Csaba%20Improved%20algorithms%20for%20linear%20stochastic%20bandits%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abbasi-Yadkori%2C%20Yasin%20P%C3%A1l%2C%20D%C3%A1vid%20Szepesv%C3%A1ri%2C%20Csaba%20Improved%20algorithms%20for%20linear%20stochastic%20bandits%202011"
        },
        {
            "id": "Abeille_2017_a",
            "entry": "Marc Abeille and Alessandro Lazaric. Linear Thompson Sampling Revisited. In AISTATS, pages 176\u2013184, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marc%20Abeille%20and%20Alessandro%20Lazaric%20Linear%20Thompson%20Sampling%20Revisited%20In%20AISTATS%20pages%20176184%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marc%20Abeille%20and%20Alessandro%20Lazaric%20Linear%20Thompson%20Sampling%20Revisited%20In%20AISTATS%20pages%20176184%202017"
        },
        {
            "id": "Agarwal_et+al_2014_a",
            "entry": "Alekh Agarwal, Ashwinkumar Badanidiyuru, Miroslav Dudik, Robert E Schapire, and Aleksandrs Slivkins. Robust multi-objective learning with mentor feedback. In COLT, pages 726\u2013741, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Agarwal%2C%20Alekh%20Badanidiyuru%2C%20Ashwinkumar%20Dudik%2C%20Miroslav%20Schapire%2C%20Robert%20E.%20Robust%20multi-objective%20learning%20with%20mentor%20feedback%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agarwal%2C%20Alekh%20Badanidiyuru%2C%20Ashwinkumar%20Dudik%2C%20Miroslav%20Schapire%2C%20Robert%20E.%20Robust%20multi-objective%20learning%20with%20mentor%20feedback%202014"
        },
        {
            "id": "Chapelle_et+al_2010_a",
            "entry": "Olivier Chapelle, Pannagadatta Shivaswamy, Srinivas Vadrevu, Kilian Weinberger, Ya Zhang, and Belle Tseng. Multi-task learning for boosting with application to web search ranking. In KDD, pages 1189\u20131198, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chapelle%2C%20Olivier%20Shivaswamy%2C%20Pannagadatta%20Vadrevu%2C%20Srinivas%20Weinberger%2C%20Kilian%20Multi-task%20learning%20for%20boosting%20with%20application%20to%20web%20search%20ranking%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chapelle%2C%20Olivier%20Shivaswamy%2C%20Pannagadatta%20Vadrevu%2C%20Srinivas%20Weinberger%2C%20Kilian%20Multi-task%20learning%20for%20boosting%20with%20application%20to%20web%20search%20ranking%202010"
        },
        {
            "id": "Evgeniou_2004_a",
            "entry": "Theodoros Evgeniou and Massimiliano Pontil. Regularized multi\u2013task learning. In KDD, pages 109\u2013117, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Evgeniou%2C%20Theodoros%20Pontil%2C%20Massimiliano%20Regularized%20multi%E2%80%93task%20learning%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Evgeniou%2C%20Theodoros%20Pontil%2C%20Massimiliano%20Regularized%20multi%E2%80%93task%20learning%202004"
        },
        {
            "id": "Flaxman_et+al_2005_a",
            "entry": "Abraham D Flaxman, Adam Tauman Kalai, and H Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In SODA, pages 385\u2013394, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Flaxman%2C%20Abraham%20D.%20Kalai%2C%20Adam%20Tauman%20McMahan%2C%20H.Brendan%20Online%20convex%20optimization%20in%20the%20bandit%20setting%3A%20gradient%20descent%20without%20a%20gradient%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Flaxman%2C%20Abraham%20D.%20Kalai%2C%20Adam%20Tauman%20McMahan%2C%20H.Brendan%20Online%20convex%20optimization%20in%20the%20bandit%20setting%3A%20gradient%20descent%20without%20a%20gradient%202005"
        },
        {
            "id": "Hazan_et+al_2007_a",
            "entry": "Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169\u2013192, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hazan%2C%20Elad%20Agarwal%2C%20Amit%20Kale%2C%20Satyen%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hazan%2C%20Elad%20Agarwal%2C%20Amit%20Kale%2C%20Satyen%20Logarithmic%20regret%20algorithms%20for%20online%20convex%20optimization%202007"
        },
        {
            "id": "Kumagai_2017_a",
            "entry": "Wataru Kumagai. Regret analysis for continuous dueling bandit. In NIPS, pages 1488\u20131497, 2017. Nan Li, Ivor W Tsang, and Zhi-Hua Zhou. Efficient optimization of performance measures by classifier adaptation. IEEE TPAMI, 35(6):1370\u20131382, 2013. Saharon Rosset, Ji Zhu, and Trevor Hastie. Boosting as a regularized path to a maximum margin classifier. JMLR, 5(Aug):941\u2013973, 2004. Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends\u20ddR",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumagai%2C%20Wataru%20Regret%20analysis%20for%20continuous%20dueling%20bandit%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumagai%2C%20Wataru%20Regret%20analysis%20for%20continuous%20dueling%20bandit%202017"
        },
        {
            "id": "Yue_et+al_2012_a",
            "entry": "in Machine Learning, 4(2):107\u2013194, 2012. Xi-Zhu Wu and Zhi-Hua Zhou. A unified view of multi-label performance measures. In ICML, pages 3780\u20133788, 2017. Yisong Yue and Thorsten Joachims. Interactively optimizing information retrieval systems as a dueling bandits problem. In ICML, pages 1201\u20131208, 2009. Yisong Yue, Josef Broder, Robert Kleinberg, and Thorsten Joachims. The k-armed dueling bandits problem. JCSS, 78(5):1538\u20131556, 2012. Lijun Zhang, Tianbao Yang, Rong Jin, Yichi Xiao, and Zhi-hua Zhou. Online stochastic linear optimization under one-bit feedback. In ICML, pages 392\u2013401, 2016. Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yue%2C%20Josef%20Broder%20Kleinberg%2C%20Robert%20Joachims%2C%20Thorsten%20Xi-Zhu%20Wu%20and%20Zhi-Hua%20Zhou.%20A%20unified%20view%20of%20multi-label%20performance%20measures%202012-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yue%2C%20Josef%20Broder%20Kleinberg%2C%20Robert%20Joachims%2C%20Thorsten%20Xi-Zhu%20Wu%20and%20Zhi-Hua%20Zhou.%20A%20unified%20view%20of%20multi-label%20performance%20measures%202012-06"
        },
        {
            "id": "ICML,_2003_a",
            "entry": "ICML, pages 928\u2013936, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ICML%20pages%20928936%202003"
        }
    ]
}
