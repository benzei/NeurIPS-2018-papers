{
    "filename": "7768-contour-location-via-entropy-reduction-leveraging-multiple-information-sources.pdf",
    "metadata": {
        "title": "Contour location via entropy reduction leveraging multiple information sources",
        "author": "Alexandre Marques, Remi Lam, Karen Willcox",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7768-contour-location-via-entropy-reduction-leveraging-multiple-information-sources.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "We introduce an algorithm to locate contours of functions that are expensive to evaluate. The problem of locating contours arises in many applications, including classification, constrained optimization, and performance analysis of mechanical and dynamical systems (reliability, probability of failure, stability, etc.). Our algorithm locates contours using information from multiple sources, which are available in the form of relatively inexpensive, biased, and possibly noisy approximations to the original function. Considering multiple information sources can lead to significant cost savings. We also introduce the concept of contour entropy, a formal measure of uncertainty about the location of the zero contour of a function approximated by a statistical surrogate model. Our algorithm locates contours efficiently by maximizing the reduction of contour entropy per unit cost."
    },
    "keywords": [
        {
            "term": "dynamical system",
            "url": "https://en.wikipedia.org/wiki/dynamical_system"
        },
        {
            "term": "Gaussian process",
            "url": "https://en.wikipedia.org/wiki/Gaussian_process"
        },
        {
            "term": "maximum likelihood estimates",
            "url": "https://en.wikipedia.org/wiki/Maximum_Likelihood_Estimate"
        },
        {
            "term": "Maximum a posteriori",
            "url": "https://en.wikipedia.org/wiki/Maximum_a_posteriori"
        },
        {
            "term": "support vector machine",
            "url": "https://en.wikipedia.org/wiki/support_vector_machine"
        }
    ],
    "highlights": [
        "We address this problem by introducing the CLoVER (Contour Location Via Entropy Reduction) algorithm",
        "Other algorithms address the problem of locating the contour of expensive-to-evaluate functions, and are based on two main techniques: Support Vector Machine (SVM) and Gaussian process (GP) surrogate",
        "Algorithms based on Gaussian process surrogates [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>\u2013<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] use the uncertainty encoded in the surrogate to make informed decisions about new evaluations, reducing the overall number of function evaluations needed to locate contours",
        "We show that CLoVER outperforms the algorithms of Refs. [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>\u2013<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] when applied to two problems involving a single information source",
        "CLoVER has three main components: (i) a statistical surrogate model that combines information from all M + 1 information sources, presented in Sect. 3.1, a measure of the entropy associated with the zero contour of g that can be computed from the surrogate, presented in Sect. 3.2, and an acquisition function that allows selecting evaluations that reduce this entropy measure, presented in Sect. 3.3",
        "We introduce the concept of contour entropy as the entropy of a discrete random variable associated with the uncertainty about the location of the zero contour of g, as follows"
    ],
    "key_statements": [
        "We address this problem by introducing the CLoVER (Contour Location Via Entropy Reduction) algorithm",
        "The concept of contour entropy, a measure of uncertainty about the location of the zero contour of a function approximated by a statistical surrogate model.\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00e9al, Canada",
        "Other algorithms address the problem of locating the contour of expensive-to-evaluate functions, and are based on two main techniques: Support Vector Machine (SVM) and Gaussian process (GP) surrogate",
        "Algorithms based on Gaussian process surrogates [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>\u2013<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] use the uncertainty encoded in the surrogate to make informed decisions about new evaluations, reducing the overall number of function evaluations needed to locate contours",
        "We show that CLoVER outperforms the algorithms of Refs. [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>\u2013<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] when applied to two problems involving a single information source",
        "CLoVER has three main components: (i) a statistical surrogate model that combines information from all M + 1 information sources, presented in Sect. 3.1, a measure of the entropy associated with the zero contour of g that can be computed from the surrogate, presented in Sect. 3.2, and an acquisition function that allows selecting evaluations that reduce this entropy measure, presented in Sect. 3.3",
        "We introduce the concept of contour entropy as the entropy of a discrete random variable associated with the uncertainty about the location of the zero contour of g, as follows",
        "To estimate the hyperparameters of \u03bc and \u03a3 , \u2208 [M ], we evaluate all other M information sources at the same location and compute the biases \u03b4 = y \u2212 y0, where y denotes data obtained by evaluating information sources",
        "Prescribe a set of points A \u2282 D which will be used as possible candidates for sampling.\n3",
        "We explore this example further in the supplementary material, where we compare CLoVER to competing algorithms in the case of a single information source",
        "To demonstrate the performance of CLoVER in the presence of multiple information sources, we introduce the following biased estimates of g: g1(x) = g(x) + sin",
        "We found this heuristics to be only appropriate for functions that are very smooth over D"
    ],
    "summary": [
        "We address this problem by introducing the CLoVER (Contour Location Via Entropy Reduction) algorithm.",
        "The concept of contour entropy, a measure of uncertainty about the location of the zero contour of a function approximated by a statistical surrogate model.",
        "An algorithm that locates contours of functions using multiple information sources via reduction of contour entropy.",
        "We use a statistical surrogate model to fit the available data and estimate the correlation between different information sources, and we choose the location for new evaluations as the maximizer of an acquisition function.",
        "Other algorithms address the problem of locating the contour of expensive-to-evaluate functions, and are based on two main techniques: Support Vector Machine (SVM) and Gaussian process (GP) surrogate.",
        "Algorithms based on GP surrogates [<a class=\"ref-link\" id=\"c15\" href=\"#r15\">15</a>\u2013<a class=\"ref-link\" id=\"c20\" href=\"#r20\">20</a>] use the uncertainty encoded in the surrogate to make informed decisions about new evaluations, reducing the overall number of function evaluations needed to locate contours.",
        "The acquisition function used in CLoVER is based on one-step look ahead reduction of contour entropy, a formal measure of uncertainty about the location of the contour.",
        "For each IS , the query cost function, 1The statistical model used in the present algorithm is the same introduced in [<a class=\"ref-link\" id=\"c3\" href=\"#r3\">3</a>], and we attempt to use a notation as similar as possible to this reference for the sake of consistency.",
        "We present the details of the CLoVER (Contour Location Via Entropy Reduction) algorithm.",
        "3.1, a measure of the entropy associated with the zero contour of g that can be computed from the surrogate, presented in Sect.",
        "CLoVER locates the zero contour by selecting samples that are likely reduce the contour entropy at each new iteration.",
        "To take advantage of the other M IS available, the algorithm performs observations that maximize the expected reduction in contour entropy, normalized by the query cost.",
        "To estimate the hyperparameters of \u03bc and \u03a3 , \u2208 [M ], we evaluate all other M information sources at the same location and compute the biases \u03b4 = y \u2212 y0, where y denotes data obtained by evaluating IS .",
        "We explore this example further in the supplementary material, where we compare CLoVER to competing algorithms in the case of a single information source.",
        "To demonstrate the performance of CLoVER in the presence of multiple information sources, we introduce the following biased estimates of g: g1(x) = g(x) + sin"
    ],
    "headline": "We introduce an algorithm to locate contours of functions that are expensive to evaluate",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] R. Lam, D. L. Allaire, and K. Willcox, \u201cMultifidelity optimization using statistical surrogate modeling for non-hierarchical information sources,\u201d in 56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference, AIAA, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lam%2C%20R.%20Allaire%2C%20D.L.%20Willcox%2C%20K.%20Multifidelity%20optimization%20using%20statistical%20surrogate%20modeling%20for%20non-hierarchical%20information%20sources%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lam%2C%20R.%20Allaire%2C%20D.L.%20Willcox%2C%20K.%20Multifidelity%20optimization%20using%20statistical%20surrogate%20modeling%20for%20non-hierarchical%20information%20sources%2C%202015"
        },
        {
            "id": "2",
            "entry": "[2] R. Lam, K. Willcox, and D. H. Wolpert, \u201cBayesian optimization with a finite budget: An approximate dynamic programming approach,\u201d in Advances in Neural Information Processing Systems 29, pp. 883\u2013891, Curran Associates, Inc., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lam%2C%20R.%20Willcox%2C%20K.%20Wolpert%2C%20D.H.%20Bayesian%20optimization%20with%20a%20finite%20budget%3A%20An%20approximate%20dynamic%20programming%20approach%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lam%2C%20R.%20Willcox%2C%20K.%20Wolpert%2C%20D.H.%20Bayesian%20optimization%20with%20a%20finite%20budget%3A%20An%20approximate%20dynamic%20programming%20approach%2C%202016"
        },
        {
            "id": "3",
            "entry": "[3] M. Poloczek, J. Wang, and P. Frazier, \u201cMulti-information source optimization,\u201d in Advances in Neural Information Processing Systems 30, pp. 4291\u20134301, Curran Associates, Inc., 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Poloczek%2C%20M.%20Wang%2C%20J.%20Frazier%2C%20P.%20Multi-information%20source%20optimization%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Poloczek%2C%20M.%20Wang%2C%20J.%20Frazier%2C%20P.%20Multi-information%20source%20optimization%2C%202017"
        },
        {
            "id": "4",
            "entry": "[4] T. M. Cover and J. A. Thomas, Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing). Wiley-Interscience, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20T.M.%20Thomas%2C%20J.A.%20Elements%20of%20Information%20Theory%20%28Wiley%20Series%20in%20Telecommunications%20and%20Signal%20Processing%29%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cover%2C%20T.M.%20Thomas%2C%20J.A.%20Elements%20of%20Information%20Theory%20%28Wiley%20Series%20in%20Telecommunications%20and%20Signal%20Processing%29%202006"
        },
        {
            "id": "5",
            "entry": "[5] A. I. Forrester, A. S\u00f3bester, and A. J. Keane, \u201cMulti-fidelity optimization via surrogate modelling,\u201d Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, vol. 463, no. 2088, pp. 3251\u20133269, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Forrester%2C%20A.I.%20S%C3%B3bester%2C%20A.%20Keane%2C%20A.J.%20Multi-fidelity%20optimization%20via%20surrogate%20modelling%2C%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Forrester%2C%20A.I.%20S%C3%B3bester%2C%20A.%20Keane%2C%20A.J.%20Multi-fidelity%20optimization%20via%20surrogate%20modelling%2C%202007"
        },
        {
            "id": "6",
            "entry": "[6] K. Swersky, J. Snoek, and R. P. Adams, \u201cMulti-task Bayesian optimization,\u201d in Advances in Neural Information Processing Systems 26, pp. 2004\u20132012, Curran Associates, Inc., 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Swersky%2C%20K.%20Snoek%2C%20J.%20Adams%2C%20R.P.%20Multi-task%20Bayesian%20optimization%2C%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Swersky%2C%20K.%20Snoek%2C%20J.%20Adams%2C%20R.P.%20Multi-task%20Bayesian%20optimization%2C%202013"
        },
        {
            "id": "7",
            "entry": "[7] C. Cortes and V. Vapnik, \u201cSupport-vector networks,\u201d Machine Learning, vol. 20, no. 3, pp. 273\u2013 297, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20C.%20Vapnik%2C%20V.%20Support-vector%20networks%2C%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20C.%20Vapnik%2C%20V.%20Support-vector%20networks%2C%201995"
        },
        {
            "id": "8",
            "entry": "[8] A. Basudhar, S. Missoum, and A. H. Sanchez, \u201cLimit state function identification using support vector machines for discontinuous responses and disjoint failure domains,\u201d Probabilistic Engineering Mechanics, vol. 23, no. 1, pp. 1 \u2013 11, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Basudhar%2C%20A.%20Missoum%2C%20S.%20Sanchez%2C%20A.H.%20Limit%20state%20function%20identification%20using%20support%20vector%20machines%20for%20discontinuous%20responses%20and%20disjoint%20failure%20domains%2C%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Basudhar%2C%20A.%20Missoum%2C%20S.%20Sanchez%2C%20A.H.%20Limit%20state%20function%20identification%20using%20support%20vector%20machines%20for%20discontinuous%20responses%20and%20disjoint%20failure%20domains%2C%202008"
        },
        {
            "id": "9",
            "entry": "[9] A. Basudhar and S. Missoum, \u201cAn improved adaptive sampling scheme for the construction of explicit boundaries,\u201d Structural and Multidisciplinary Optimization, vol. 42, no. 4, pp. 517\u2013529, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Basudhar%2C%20A.%20Missoum%2C%20S.%20An%20improved%20adaptive%20sampling%20scheme%20for%20the%20construction%20of%20explicit%20boundaries%2C%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Basudhar%2C%20A.%20Missoum%2C%20S.%20An%20improved%20adaptive%20sampling%20scheme%20for%20the%20construction%20of%20explicit%20boundaries%2C%202010"
        },
        {
            "id": "10",
            "entry": "[10] M. Lecerf, D. Allaire, and K. Willcox, \u201cMethodology for dynamic data-driven online flight capability estimation,\u201d AIAA Journal, vol. 53, no. 10, pp. 3073\u20133087, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lecerf%2C%20M.%20Allaire%2C%20D.%20Willcox%2C%20K.%20Methodology%20for%20dynamic%20data-driven%20online%20flight%20capability%20estimation%2C%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lecerf%2C%20M.%20Allaire%2C%20D.%20Willcox%2C%20K.%20Methodology%20for%20dynamic%20data-driven%20online%20flight%20capability%20estimation%2C%202015"
        },
        {
            "id": "11",
            "entry": "[11] G. Schohn and D. Cohn, \u201cLess is more: Active learning with support vector machines,\u201d in Proceedings of the 17th International Conference on Machine Learning (ICML 2000), (Stanford, CA), pp. 839\u2013846, Morgan Kaufmann, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schohn%2C%20G.%20Cohn%2C%20D.%20Less%20is%20more%3A%20Active%20learning%20with%20support%20vector%20machines%2C%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schohn%2C%20G.%20Cohn%2C%20D.%20Less%20is%20more%3A%20Active%20learning%20with%20support%20vector%20machines%2C%202000"
        },
        {
            "id": "12",
            "entry": "[12] S. Tong and D. Koller, \u201cSupport vector machine active learning with applications to text classification,\u201d Journal of Machine Learning Research, vol. 2, no. Nov, pp. 45\u201366, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tong%2C%20S.%20Koller%2C%20D.%20Support%20vector%20machine%20active%20learning%20with%20applications%20to%20text%20classification%2C%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tong%2C%20S.%20Koller%2C%20D.%20Support%20vector%20machine%20active%20learning%20with%20applications%20to%20text%20classification%2C%202001"
        },
        {
            "id": "13",
            "entry": "[13] M. K. Warmuth, G. R\u00e4tsch, M. Mathieson, J. Liao, and C. Lemmen, \u201cActive learning in the drug discovery process,\u201d in Advances in Neural Information Processing Systems 14, pp. 1449\u20131456, MIT Press, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Warmuth%2C%20M.K.%20R%C3%A4tsch%2C%20G.%20Mathieson%2C%20M.%20Liao%2C%20J.%20Active%20learning%20in%20the%20drug%20discovery%20process%2C%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Warmuth%2C%20M.K.%20R%C3%A4tsch%2C%20G.%20Mathieson%2C%20M.%20Liao%2C%20J.%20Active%20learning%20in%20the%20drug%20discovery%20process%2C%202002"
        },
        {
            "id": "14",
            "entry": "[14] C. Dribusch, S. Missoum, and P. Beran, \u201cA multifidelity approach for the construction of explicit decision boundaries: application to aeroelasticity,\u201d Structural and Multidisciplinary Optimization, vol. 42, pp. 693\u2013705, Nov 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dribusch%2C%20C.%20Missoum%2C%20S.%20Beran%2C%20P.%20A%20multifidelity%20approach%20for%20the%20construction%20of%20explicit%20decision%20boundaries%3A%20application%20to%20aeroelasticity%2C%202010-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dribusch%2C%20C.%20Missoum%2C%20S.%20Beran%2C%20P.%20A%20multifidelity%20approach%20for%20the%20construction%20of%20explicit%20decision%20boundaries%3A%20application%20to%20aeroelasticity%2C%202010-11"
        },
        {
            "id": "15",
            "entry": "[15] B. J. Bichon, M. S. Eldred, L. P. Swiler, S. Mahadevan, and J. M. McFarland, \u201cEfficient global reliability analysis for nonlinear implicit performance functions,\u201d AIAA Journal, vol. 46, no. 10, pp. 2459\u20132468, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bichon%2C%20B.J.%20Eldred%2C%20M.S.%20Swiler%2C%20L.P.%20Mahadevan%2C%20S.%20Efficient%20global%20reliability%20analysis%20for%20nonlinear%20implicit%20performance%20functions%2C%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bichon%2C%20B.J.%20Eldred%2C%20M.S.%20Swiler%2C%20L.P.%20Mahadevan%2C%20S.%20Efficient%20global%20reliability%20analysis%20for%20nonlinear%20implicit%20performance%20functions%2C%202008"
        },
        {
            "id": "16",
            "entry": "[16] P. Ranjan, D. Bingham, and G. Michailidis, \u201cSequential experiment design for contour estimation from complex computer codes,\u201d Technometrics, vol. 50, no. 4, pp. 527\u2013541, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ranjan%2C%20P.%20Bingham%2C%20D.%20Michailidis%2C%20G.%20Sequential%20experiment%20design%20for%20contour%20estimation%20from%20complex%20computer%20codes%2C%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ranjan%2C%20P.%20Bingham%2C%20D.%20Michailidis%2C%20G.%20Sequential%20experiment%20design%20for%20contour%20estimation%20from%20complex%20computer%20codes%2C%202008"
        },
        {
            "id": "17",
            "entry": "[17] V. Picheny, D. Ginsbourger, O. Roustant, R. T. Haftka, and N.-H. Kim, \u201cAdaptive designs of experiments for accurate approximation of a target region,\u201d Journal of Mechanical Design, vol. 132, Jun 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Picheny%2C%20V.%20Ginsbourger%2C%20D.%20Roustant%2C%20O.%20Haftka%2C%20R.T.%20Adaptive%20designs%20of%20experiments%20for%20accurate%20approximation%20of%20a%20target%20region%2C%202010-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Picheny%2C%20V.%20Ginsbourger%2C%20D.%20Roustant%2C%20O.%20Haftka%2C%20R.T.%20Adaptive%20designs%20of%20experiments%20for%20accurate%20approximation%20of%20a%20target%20region%2C%202010-06"
        },
        {
            "id": "18",
            "entry": "[18] J. Bect, D. Ginsbourger, L. Li, V. Picheny, and E. Vazquez, \u201cSequential design of computer experiments for the estimation of a probability of failure,\u201d Statistics and Computing, vol. 22, no. 3, pp. 773\u2013793, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bect%2C%20J.%20Ginsbourger%2C%20D.%20Li%2C%20L.%20Picheny%2C%20V.%20Sequential%20design%20of%20computer%20experiments%20for%20the%20estimation%20of%20a%20probability%20of%20failure%2C%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bect%2C%20J.%20Ginsbourger%2C%20D.%20Li%2C%20L.%20Picheny%2C%20V.%20Sequential%20design%20of%20computer%20experiments%20for%20the%20estimation%20of%20a%20probability%20of%20failure%2C%202012"
        },
        {
            "id": "19",
            "entry": "[19] C. Chevalier, J. Bect, D. Ginsbourger, E. Vazquez, V. Picheny, and Y. Richet, \u201cFast parallel Kriging-based stepwise uncertainty reduction with application to the identification of an excursion set,\u201d Technometrics, vol. 56, no. 4, pp. 455\u2013465, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chevalier%2C%20C.%20Bect%2C%20J.%20Ginsbourger%2C%20D.%20Vazquez%2C%20E.%20Fast%20parallel%20Kriging-based%20stepwise%20uncertainty%20reduction%20with%20application%20to%20the%20identification%20of%20an%20excursion%20set%2C%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chevalier%2C%20C.%20Bect%2C%20J.%20Ginsbourger%2C%20D.%20Vazquez%2C%20E.%20Fast%20parallel%20Kriging-based%20stepwise%20uncertainty%20reduction%20with%20application%20to%20the%20identification%20of%20an%20excursion%20set%2C%202014"
        },
        {
            "id": "20",
            "entry": "[20] H. Wang, G. Lin, and J. Li, \u201cGaussian process surrogates for failure detection: A bayesian experimental design approach,\u201d Journal of Computational Physics, vol. 313, pp. 247 \u2013 259, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20H.%20Lin%2C%20G.%20Li%2C%20J.%20Gaussian%20process%20surrogates%20for%20failure%20detection%3A%20A%20bayesian%20experimental%20design%20approach%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20H.%20Lin%2C%20G.%20Li%2C%20J.%20Gaussian%20process%20surrogates%20for%20failure%20detection%3A%20A%20bayesian%20experimental%20design%20approach%2C%202016"
        },
        {
            "id": "21",
            "entry": "[21] R. Stroh, J. Bect, S. Demeyer, N. Fischer, D. Marquis, and E. Vazquez, \u201cAssessing fire safety using complex numerical models with a Bayesian multi-fidelity approach,\u201d Fire Safety Journal, vol. 91, pp. 1016 \u2013 1025, 2017. Fire Safety Science: Proceedings of the 12th International Symposium.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stroh%2C%20R.%20Bect%2C%20J.%20Demeyer%2C%20S.%20Fischer%2C%20N.%20Assessing%20fire%20safety%20using%20complex%20numerical%20models%20with%20a%20Bayesian%20multi-fidelity%20approach%2C%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stroh%2C%20R.%20Bect%2C%20J.%20Demeyer%2C%20S.%20Fischer%2C%20N.%20Assessing%20fire%20safety%20using%20complex%20numerical%20models%20with%20a%20Bayesian%20multi-fidelity%20approach%2C%202017"
        },
        {
            "id": "22",
            "entry": "[22] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rasmussen%2C%20C.E.%20Williams%2C%20C.K.I.%20Gaussian%20Processes%20for%20Machine%20Learning%20%28Adaptive%20Computation%20and%20Machine%20Learning%29%202005"
        },
        {
            "id": "23",
            "entry": "[23] R. F. Heinemann and A. B. Poore, \u201cMultiplicity, stability, and oscillatory dynamics of the tubular reactor,\u201d Chemical Engineering Science, vol. 36, no. 8, pp. 1411 \u2013 1419, 1981.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heinemann%2C%20R.F.%20Poore%2C%20A.B.%20Multiplicity%2C%20stability%2C%20and%20oscillatory%20dynamics%20of%20the%20tubular%20reactor%2C%201981",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heinemann%2C%20R.F.%20Poore%2C%20A.B.%20Multiplicity%2C%20stability%2C%20and%20oscillatory%20dynamics%20of%20the%20tubular%20reactor%2C%201981"
        },
        {
            "id": "24",
            "entry": "[24] Y. B. Zhou, \u201cModel reduction for nonlinear dynamical systems with parametric uncertainties,\u201d Master\u2019s thesis, Massachusetts Institute of Technology, Cambridge, MA, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Y.B.%20Model%20reduction%20for%20nonlinear%20dynamical%20systems%20with%20parametric%20uncertainties%2C%202010"
        },
        {
            "id": "25",
            "entry": "[25] B. Peherstorfer, K. Willcox, and M. Gunzburger, \u201cOptimal model management for multifidelity Monte Carlo estimation,\u201d SIAM Journal on Scientific Computing, vol. 38, no. 5, pp. A3163\u2013 A3194, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peherstorfer%2C%20B.%20Willcox%2C%20K.%20Gunzburger%2C%20M.%20Optimal%20model%20management%20for%20multifidelity%20Monte%20Carlo%20estimation%2C%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peherstorfer%2C%20B.%20Willcox%2C%20K.%20Gunzburger%2C%20M.%20Optimal%20model%20management%20for%20multifidelity%20Monte%20Carlo%20estimation%2C%202016"
        },
        {
            "id": "26",
            "entry": "[26] S. Surjanovic and D. Bingham, \u201cVirtual Library of Simulation Experiments: Test Functions and Datasets, Optimization Test Problems, Emulation/Prediction Test Problems, Branin Function.\u201d Available at https://www.sfu.ca/~ssurjano/branin.html, last visited 2018-7-31. ",
            "url": "https://www.sfu.ca/~ssurjano/branin.html"
        }
    ]
}
