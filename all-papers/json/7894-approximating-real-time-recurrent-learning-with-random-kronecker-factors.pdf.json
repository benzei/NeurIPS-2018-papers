{
    "filename": "7894-approximating-real-time-recurrent-learning-with-random-kronecker-factors.pdf",
    "metadata": {
        "title": "Approximating Real-Time Recurrent Learning with Random Kronecker Factors",
        "author": "Asier Mujika, Florian Meier, Angelika Steger",
        "identifiers": {
            "url": "https://papers.nips.cc/paper/7894-approximating-real-time-recurrent-learning-with-random-kronecker-factors.pdf"
        },
        "journal": "Conference on Neural Information Processing Systems",
        "abstract": "Despite all the impressive advances of recurrent neural networks, sequential data is still in need of better modelling. Truncated backpropagation through time (TBPTT), the learning algorithm most widely used in practice, suffers from the truncation bias, which drastically limits its ability to learn long-term dependencies.The Real-Time Recurrent Learning algorithm (RTRL) addresses this issue, but its high computational requirements make it infeasible in practice. The Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRL with a smaller runtime and memory cost, but with the disadvantage of obtaining noisy gradients that also limit its practical applicability. In this paper we propose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kronecker product decomposition to approximate the gradients for a large class of RNNs. We show that KF-RTRL is an unbiased and memory efficient online learning algorithm. Our theoretical analysis shows that, under reasonable assumptions, the noise introduced by our algorithm is not only stable over time but also asymptotically much smaller than the one of the UORO algorithm. We also confirm these theoretical results experimentally. Further, we show empirically that the KF-RTRL algorithm captures long-term dependencies and almost matches the performance of TBPTT on real world tasks by training Recurrent Highway Networks on a synthetic string memorization task and on the Penn TreeBank task, respectively. These results indicate that RTRL based approaches might be a promising future alternative to TBPTT."
    },
    "keywords": [
        {
            "term": "penn treebank",
            "url": "https://en.wikipedia.org/wiki/Penn_Treebank"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        }
    ],
    "highlights": [
        "Processing sequential data is a central problem in the field of machine learning",
        "We propose the KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] online learning algorithm. We theoretically prove that our algorithm is unbiased and under reasonable assumptions the noise is stable over time and asymptotically by a factor n smaller than the noise of Unbiased Online Recurrent Optimization. We test KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] on a binary string memorization task where our networks can learn dependencies of up to 36 steps. We evaluate in character-level Penn TreeBank, where the performance of KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] almost matches the one of Truncated BackPropagation Through Time [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] for 25 steps. We empirically confirm that the variance of KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] is stable over time and that increasing the number of units does not increase the noise significantly.\n2 Related Work",
        "For the class of Recurrent Neural Networks defined in Lemma 1, the estimate G\u2032t obtained by the KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] algorithm satisfies\n1",
        "We have presented the KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] online learning algorithm",
        "We have proven that it approximates Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] in an unbiased way, and that under reasonable assumptions the noise is stable over time and much smaller than the one of Unbiased Online Recurrent Optimization, the only other previously known unbiased Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>]",
        "An RHN trained with KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] effectively captures long-term dependencies"
    ],
    "key_statements": [
        "Processing sequential data is a central problem in the field of machine learning",
        "We propose the KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] online learning algorithm. We theoretically prove that our algorithm is unbiased and under reasonable assumptions the noise is stable over time and asymptotically by a factor n smaller than the noise of Unbiased Online Recurrent Optimization. We test KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] on a binary string memorization task where our networks can learn dependencies of up to 36 steps. We evaluate in character-level Penn TreeBank, where the performance of KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] almost matches the one of Truncated BackPropagation Through Time [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] for 25 steps. We empirically confirm that the variance of KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] is stable over time and that increasing the number of units does not increase the noise significantly.\n2 Related Work",
        "For the class of Recurrent Neural Networks defined in Lemma 1, the estimate G\u2032t obtained by the KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] algorithm satisfies\n1",
        "KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] is well suited for learning long-term dependencies and almost matches the performance of Truncated BackPropagation Through Time [<a class=\"ref-link\" id=\"c18\" href=\"#r18\">18</a>] on a complex real world task, that is, character level language modeling",
        "We have presented the KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] online learning algorithm",
        "We have proven that it approximates Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] in an unbiased way, and that under reasonable assumptions the noise is stable over time and much smaller than the one of Unbiased Online Recurrent Optimization, the only other previously known unbiased Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>]",
        "An RHN trained with KF-Real-Time Recurrent Learning [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] effectively captures long-term dependencies"
    ],
    "summary": [
        "Processing sequential data is a central problem in the field of machine learning.",
        "This algorithm allows online updates of the parameters and learning arbitrarily long-term dependencies by exploiting the recurrent structure of the network for forward propagation of the gradient.",
        "RTRL [<a class=\"ref-link\" id=\"c19\" href=\"#r19\">19</a>] is an online learning algorithm for RNNs. Contrary to TBPPT, no previous inputs or network states need to be stored.",
        "At any time-step t, RTRL only requires the hidden state ht, input xt and dht\u22121 d\u03b8 in order to compute dht d\u03b8",
        "RTRL obtains the exact gradient Gt for each time-step and enables online updates of the parameters.",
        "The sum of two rank-one matrices HtGt\u22121 + Ft is approximated by a rank-one matrix yielding the estimate Gt of Gt. The estimate Gt is provably unbiased and the UORO update requires the same run-time and memory as updating the RNN [<a class=\"ref-link\" id=\"c16\" href=\"#r16\">16</a>].",
        "Our proposed Kronecker Factored RTRL algorithm (KF-RTRL) is an online learning algorithm for RNNs, which does not require storing any previous inputs or network states.",
        "For the class of RNNs defined in Lemma 1, the estimate G\u2032t obtained by the KF-RTRL algorithm satisfies",
        "One time-step of the KF-RTRL algorithm requires O(n3) operations and O(n2) memory.",
        "KF-RTRL is well suited for learning long-term dependencies and almost matches the performance of TBPTT on a complex real world task, that is, character level language modeling.",
        "At any time-step t, KF-RTRL maintains a vector ut and a matrix At, such that Gt\u2032 = ut \u2297 At satisfies E[G\u2032t] = Gt. Both HtGt\u2032\u22121 and Ft are factored as a Kronecker product, and the sum of these two Kronecker products is approximated by one Kronecker product.",
        "\u2013 input xt, target yt, previous recurrent state ht\u22121 and parameters \u03b8 \u2013 ut\u22121 and At\u22121 such that E [ut\u22121 \u2297 At\u22121] = Gt\u22121 \u2013 SGDopt and \u03b7t+1: stochastic optimizer and its learning rate",
        "The KF-RTRL algorithms requires that in one time-step each parameter only affects one element of the hidden state.",
        "For sufficiently large networks the scaling of the KF-RTRL run-time improves by using fast matrix multiplication algorithms.",
        "Truncated BPTT outperforms both online learning algorithms, but KF-RTRL almost reaches its performance and considerably outperforms UORO.",
        "Figure 3(b) shows that the variance of KF-RTRL and UORO-AVG are almost unaffected by the number of units, while UORO degrades more quickly as the network size increases.",
        "One might attempt to improve the run-time of KF-RTRL by using approximate matrix multiplication algorithms or inducing properties on the Ht matrix that allow for fast matrix multiplications, like sparsity or low-rank.",
        "It almost matches the performance of TBPTT in a standard RNN benchmark, character level language modeling on Penn TreeBank"
    ],
    "headline": "In this paper we propose the Kronecker Factored Real-Time Recurrent Learning   algorithm that uses a Kronecker product decomposition to approximate the gradients for a large class of Recurrent Neural Networks",
    "reference_links": [
        {
            "id": "1",
            "entry": "[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensorflow: A system for large-scale machine learning. In OSDI, volume 16, pages 265\u2013283, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20M.%20Barham%2C%20P.%20Chen%2C%20J.%20Chen%2C%20Z.%20Tensorflow%3A%20A%20system%20for%20large-scale%20machine%20learning%202016"
        },
        {
            "id": "2",
            "entry": "[2] Y. Bengio, P. Simard, and P. Frasconi. Learning long-term dependencies with gradient descent is difficult. IEEE transactions on neural networks, 5(2):157\u2013166, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Y.%20Simard%2C%20P.%20Frasconi%2C%20P.%20Learning%20long-term%20dependencies%20with%20gradient%20descent%20is%20difficult%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Y.%20Simard%2C%20P.%20Frasconi%2C%20P.%20Learning%20long-term%20dependencies%20with%20gradient%20descent%20is%20difficult%201994"
        },
        {
            "id": "3",
            "entry": "[3] T. Catfolis. A method for improving the real-time recurrent learning algorithm. Neural Networks, 6(6):807\u2013821, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Catfolis%2C%20T.%20A%20method%20for%20improving%20the%20real-time%20recurrent%20learning%20algorithm%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Catfolis%2C%20T.%20A%20method%20for%20improving%20the%20real-time%20recurrent%20learning%20algorithm%201993"
        },
        {
            "id": "4",
            "entry": "[4] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20short-term%20memory%201997"
        },
        {
            "id": "5",
            "entry": "[5] M. Jaderberg, W. M. Czarnecki, S. Osindero, O. Vinyals, A. Graves, D. Silver, and K. Kavukcuoglu. Decoupled neural interfaces using synthetic gradients. arXiv preprint arXiv:1608.05343, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.05343"
        },
        {
            "id": "6",
            "entry": "[6] H. Jaeger. The \u201cecho state\u201d approach to analysing and training recurrent neural networks-with an erratum note. Bonn, Germany: German National Research Center for Information Technology GMD Technical Report, 148(34):13, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaeger%2C%20H.%20The%20%E2%80%9Cecho%20state%E2%80%9D%20approach%20to%20analysing%20and%20training%20recurrent%20neural%20networks-with%20an%20erratum%20note%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaeger%2C%20H.%20The%20%E2%80%9Cecho%20state%E2%80%9D%20approach%20to%20analysing%20and%20training%20recurrent%20neural%20networks-with%20an%20erratum%20note%202001"
        },
        {
            "id": "7",
            "entry": "[7] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "8",
            "entry": "[8] M. Luko\u0161evicius and H. Jaeger. Reservoir computing approaches to recurrent neural network training. Computer Science Review, 3(3):127\u2013149, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luko%C5%A1evicius%2C%20M.%20Jaeger%2C%20H.%20Reservoir%20computing%20approaches%20to%20recurrent%20neural%20network%20training%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luko%C5%A1evicius%2C%20M.%20Jaeger%2C%20H.%20Reservoir%20computing%20approaches%20to%20recurrent%20neural%20network%20training%202009"
        },
        {
            "id": "9",
            "entry": "[9] W. Maass, T. Natschl\u00e4ger, and H. Markram. Real-time computing without stable states: A new framework for neural computation based on perturbations. Neural computation, 14(11): 2531\u20132560, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Maass%2C%20W.%20Natschl%C3%A4ger%2C%20T.%20Markram%2C%20H.%20Real-time%20computing%20without%20stable%20states%3A%20A%20new%20framework%20for%20neural%20computation%20based%20on%20perturbations%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Maass%2C%20W.%20Natschl%C3%A4ger%2C%20T.%20Markram%2C%20H.%20Real-time%20computing%20without%20stable%20states%3A%20A%20new%20framework%20for%20neural%20computation%20based%20on%20perturbations%202002"
        },
        {
            "id": "10",
            "entry": "[10] M. P. Marcus, M. A. Marcinkiewicz, and B. Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313\u2013330, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcus%2C%20M.P.%20Marcinkiewicz%2C%20M.A.%20Santorini%2C%20B.%20Building%20a%20large%20annotated%20corpus%20of%20english%3A%20The%20penn%20treebank%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcus%2C%20M.P.%20Marcinkiewicz%2C%20M.A.%20Santorini%2C%20B.%20Building%20a%20large%20annotated%20corpus%20of%20english%3A%20The%20penn%20treebank%201993"
        },
        {
            "id": "11",
            "entry": "[11] G. Melis, C. Dyer, and P. Blunsom. On the state of the art of evaluation in neural language models. arXiv preprint arXiv:1707.05589, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.05589"
        },
        {
            "id": "12",
            "entry": "[12] S. Merity, N. S. Keskar, and R. Socher. An analysis of neural language modeling at multiple scales. arXiv preprint arXiv:1803.08240, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.08240"
        },
        {
            "id": "13",
            "entry": "[13] T. Mikolov, I. Sutskever, A. Deoras, H.-S. Le, S. Kombrink, and J. Cernocky. Subword language modeling with neural networks. preprint (http://www.fit.vutbr.cz/imikolov/rnnlm/char.pdf), 2012.",
            "url": "http://www.fit.vutbr.cz/imikolov/rnnlm/char.pdf"
        },
        {
            "id": "14",
            "entry": "[14] Y. Ollivier, C. Tallec, and G. Charpiat. Training recurrent networks online without backtracking. arXiv preprint arXiv:1507.07680, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1507.07680"
        },
        {
            "id": "15",
            "entry": "[15] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-propagating errors. nature, 323(6088):533, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rumelhart%2C%20D.E.%20Hinton%2C%20G.E.%20Williams%2C%20R.J.%20Learning%20representations%20by%20back-propagating%20errors%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rumelhart%2C%20D.E.%20Hinton%2C%20G.E.%20Williams%2C%20R.J.%20Learning%20representations%20by%20back-propagating%20errors%201986"
        },
        {
            "id": "16",
            "entry": "[16] C. Tallec and Y. Ollivier. Unbiased online recurrent optimization. arXiv preprint arXiv:1702.05043, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.05043"
        },
        {
            "id": "17",
            "entry": "[17] C. Tallec and Y. Ollivier. Unbiasing truncated backpropagation through time. arXiv preprint arXiv:1705.08209, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.08209"
        },
        {
            "id": "18",
            "entry": "[18] R. J. Williams and J. Peng. An efficient gradient-based algorithm for on-line training of recurrent network trajectories. Neural Computation, 2:490\u2013501, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20R.J.%20Peng%2C%20J.%20An%20efficient%20gradient-based%20algorithm%20for%20on-line%20training%20of%20recurrent%20network%20trajectories%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20R.J.%20Peng%2C%20J.%20An%20efficient%20gradient-based%20algorithm%20for%20on-line%20training%20of%20recurrent%20network%20trajectories%201990"
        },
        {
            "id": "19",
            "entry": "[19] R. J. Williams and D. Zipser. A learning algorithm for continually running fully recurrent neural networks. Neural computation, 1(2):270\u2013280, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20R.J.%20Zipser%2C%20D.%20A%20learning%20algorithm%20for%20continually%20running%20fully%20recurrent%20neural%20networks%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20R.J.%20Zipser%2C%20D.%20A%20learning%20algorithm%20for%20continually%20running%20fully%20recurrent%20neural%20networks%201989"
        },
        {
            "id": "20",
            "entry": "[20] J. G. Zilly, R. K. Srivastava, J. Koutn\u00edk, and J. Schmidhuber. Recurrent highway networks. arXiv preprint arXiv:1607.03474, 2016. ",
            "arxiv_url": "https://arxiv.org/pdf/1607.03474"
        }
    ]
}
